{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall\n",
      "-------\n",
      "Total number of tensorflow issues:19929\n",
      "Total number of rust issues:19115\n",
      "Total number of kubernetes issues:19836\n",
      "Total number of flutter issues:13207\n",
      "Total number of ohmyzsh issues:1608\n",
      "Total number of electron issues:5433\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook for GitHub issue data analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "ROOT = os.environ.get(\"ROOT\")  # remember to set your root path in `.env`; refer to installation.\n",
    "\n",
    "# English repo - train sets\n",
    "df_tensorflow = pd.read_json(f'{ROOT}/data/eng_labelled/raw/tensorflow.json')\n",
    "df_rust = pd.read_json(f'{ROOT}/data/eng_labelled/raw/rust.json')\n",
    "df_kubernetes = pd.read_json(f'{ROOT}/data/eng_labelled/raw/kubernetes.json')\n",
    "\n",
    "# English repo - test sets\n",
    "df_flutter = pd.read_json(f'{ROOT}/data/eng_labelled/raw/flutter.json')\n",
    "df_ohmyzsh = pd.read_json(f'{ROOT}/data/eng_labelled/raw/ohmyzsh.json')\n",
    "df_electron = pd.read_json(f'{ROOT}/data/eng_labelled/raw/electron.json')\n",
    "\n",
    "num_row_tensorflow = len(df_tensorflow.index)\n",
    "num_row_rust = len(df_rust.index)\n",
    "num_row_kubernetes = len(df_kubernetes.index)\n",
    "num_row_flutter = len(df_flutter.index)\n",
    "num_row_ohmyzsh = len(df_ohmyzsh.index)\n",
    "num_row_electron = len(df_electron.index)\n",
    "\n",
    "print('Overall')\n",
    "print('-------')\n",
    "print('Total number of tensorflow issues:' + str(num_row_tensorflow))\n",
    "print('Total number of rust issues:' + str(num_row_rust))\n",
    "print('Total number of kubernetes issues:' + str(num_row_kubernetes))\n",
    "print('Total number of flutter issues:' + str(num_row_flutter))\n",
    "print('Total number of ohmyzsh issues:' + str(num_row_ohmyzsh))\n",
    "print('Total number of electron issues:' + str(num_row_electron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature word frequencies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('S', 102839),\n",
       " ('std', 30577),\n",
       " ('I', 23962),\n",
       " ('1', 20116),\n",
       " ('0', 19339),\n",
       " ('rust', 16952),\n",
       " ('Ratio', 16915),\n",
       " ('num_rational', 16900),\n",
       " ('https', 16294),\n",
       " ('error', 15932),\n",
       " ('mut', 15331),\n",
       " ('io', 13541),\n",
       " ('fn', 12151),\n",
       " ('com', 11544),\n",
       " ('type', 11210),\n",
       " ('2', 10817),\n",
       " ('iter', 10749),\n",
       " ('use', 10397),\n",
       " ('would', 10074),\n",
       " ('rs', 10064),\n",
       " ('kubernetes', 9504),\n",
       " ('github', 9172),\n",
       " ('src', 8564),\n",
       " ('x', 8488),\n",
       " ('The', 8314),\n",
       " ('version', 8283),\n",
       " ('Take', 8144),\n",
       " ('like', 8060),\n",
       " ('tensorflow', 7972),\n",
       " ('This', 7863),\n",
       " ('code', 7697),\n",
       " ('let', 7690),\n",
       " ('feature', 7464),\n",
       " ('T', 7082),\n",
       " ('3', 7050),\n",
       " ('self', 6957),\n",
       " ('tf', 6904),\n",
       " ('lang', 6448),\n",
       " ('impl', 6440),\n",
       " ('main', 6112),\n",
       " ('test', 5773),\n",
       " ('str', 5445),\n",
       " ('4', 5252),\n",
       " ('note', 5235),\n",
       " ('_', 5161),\n",
       " ('rustc', 5155),\n",
       " ('pub', 5154),\n",
       " ('using', 5117),\n",
       " ('It', 4857),\n",
       " ('foo', 4808)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data = []\n",
    "doc_data = []\n",
    "bug_data = []\n",
    "\n",
    "for _, row in df_kubernetes.iterrows():\n",
    "    # feature\n",
    "    if row['labels'] == 'kind/feature' or row['labels'] == 'kind/api-change': \n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    # bug\n",
    "    if row['labels'] == 'kind/bug' or row['labels'] == 'kind/failing-test': \n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    # doc\n",
    "    if row['labels'] == 'kind/documentation': \n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "\n",
    "for _, row in df_rust.iterrows():\n",
    "    # feature\n",
    "    if row['labels'] == 'C-feature-request' or row['labels'] == 'C-feature-accepted' or row['labels'] == 'C-enhancement': \n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    # bug\n",
    "    if row['labels'] == 'C-bug': \n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    # doc\n",
    "    if row['labels'] == 'T-doc': \n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "\n",
    "for _, row in df_tensorflow.iterrows():\n",
    "    if row['labels'] == 'type:feature':\n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    elif row['labels'] == 'type:docs-feature' or row['labels'] == 'type:docs-bug':\n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    else:\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "        \n",
    "print(\"Feature word frequencies:\")\n",
    "feature_freq = FreqDist(feature_data)\n",
    "feature_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc word frequencies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('https', 6039),\n",
       " ('tensorflow', 5905),\n",
       " ('0', 4509),\n",
       " ('I', 4366),\n",
       " ('1', 4238),\n",
       " ('tf', 4108),\n",
       " ('org', 3080),\n",
       " ('com', 2965),\n",
       " ('docs', 2482),\n",
       " ('documentation', 2449),\n",
       " ('rust', 2393),\n",
       " ('github', 2373),\n",
       " ('issue', 2341),\n",
       " ('2', 2271),\n",
       " ('python', 2174),\n",
       " ('www', 2160),\n",
       " ('The', 2140),\n",
       " ('kubernetes', 1975),\n",
       " ('example', 1901),\n",
       " ('version', 1716),\n",
       " ('code', 1659),\n",
       " ('doc', 1609),\n",
       " ('use', 1545),\n",
       " ('lang', 1448),\n",
       " ('keras', 1274),\n",
       " ('master', 1230),\n",
       " ('issues', 1224),\n",
       " ('TensorFlow', 1211),\n",
       " ('10', 1202),\n",
       " ('3', 1162),\n",
       " ('io', 1159),\n",
       " ('x', 1143),\n",
       " ('guide', 1138),\n",
       " ('blob', 1125),\n",
       " ('py', 1120),\n",
       " ('std', 1101),\n",
       " ('defined', 1038),\n",
       " ('name', 1015),\n",
       " ('html', 975),\n",
       " ('api_docs', 950),\n",
       " ('error', 922),\n",
       " ('This', 901),\n",
       " ('link', 901),\n",
       " ('md', 897),\n",
       " ('would', 887),\n",
       " ('source', 883),\n",
       " ('node', 879),\n",
       " ('go', 869),\n",
       " ('using', 864),\n",
       " ('line', 864)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Doc word frequencies:\")\n",
    "doc_freq = FreqDist(doc_data)\n",
    "doc_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug word frequencies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', 253466),\n",
       " ('1', 194895),\n",
       " ('tensorflow', 171648),\n",
       " ('I', 102266),\n",
       " ('2', 87713),\n",
       " ('tf', 85691),\n",
       " ('lib', 80044),\n",
       " ('version', 78021),\n",
       " ('_', 76386),\n",
       " ('go', 69370),\n",
       " ('kubernetes', 66147),\n",
       " ('3', 62546),\n",
       " ('10', 62036),\n",
       " ('src', 60323),\n",
       " ('python', 58129),\n",
       " ('py', 57376),\n",
       " ('io', 54209),\n",
       " ('https', 52507),\n",
       " ('error', 49243),\n",
       " ('com', 49031),\n",
       " ('packages', 45272),\n",
       " ('k8s', 44950),\n",
       " ('cc', 44819),\n",
       " ('line', 44224),\n",
       " ('6', 42701),\n",
       " ('std', 41638),\n",
       " ('core', 41189),\n",
       " ('rustc', 40748),\n",
       " ('7', 40310),\n",
       " ('File', 39638),\n",
       " ('self', 38992),\n",
       " ('4', 38968),\n",
       " ('model', 37947),\n",
       " ('rs', 37914),\n",
       " ('5', 37169),\n",
       " ('build', 36568),\n",
       " ('x86_64', 36135),\n",
       " ('C', 35588),\n",
       " ('name', 35288),\n",
       " ('TensorFlow', 35132),\n",
       " ('code', 34867),\n",
       " ('home', 33926),\n",
       " ('site', 33896),\n",
       " ('github', 33425),\n",
       " ('16', 32758),\n",
       " ('8', 32220),\n",
       " ('11', 31765),\n",
       " ('python3', 31586),\n",
       " ('use', 31543),\n",
       " ('local', 31523)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Bug word frequencies:\")\n",
    "bug_freq = FreqDist(bug_data)\n",
    "bug_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mappings = {\n",
    "    \"tf\": {\n",
    "        \"feature\": [\"type:feature\"],\n",
    "        \"bug\": [\"type:bug\"],\n",
    "        \"doc\": [\"type:docs-feature\", \"type:docs-bug\"],\n",
    "        \"repo\": df_tensorflow\n",
    "    },\n",
    "    \"rust\": {\n",
    "        \"feature\": [\"C-feature-request\", \"C-feature-accepted\", \"C-enhancement\"],\n",
    "        \"bug\": [\"C-bug\"],\n",
    "        \"doc\": [\"T-doc\"],\n",
    "        \"repo\": df_rust\n",
    "    },\n",
    "    \"kubernetes\": {\n",
    "        \"feature\": [\"kind/feature\", \"kind/api-change\"],\n",
    "        \"bug\": [\"kind/bug\"],\n",
    "        \"doc\": [\"kind/documentation\"],\n",
    "        \"repo\": df_kubernetes\n",
    "    }\n",
    "}\n",
    "\n",
    "test_mappings = {\n",
    "    \"flutter\": {\n",
    "        \"feature\": ['severe: new feature'],\n",
    "        \"bug\": [\"severe: crash\", \"severe: fatal crash\", \"severe: rendering\"],\n",
    "        \"doc\": [\"documentation\"],\n",
    "        \"repo\": df_flutter\n",
    "    },\n",
    "    \"ohmyzsh\": {\n",
    "        \"feature\": [\"Feature\", \"Enhancement\"],\n",
    "        \"bug\": [\"Bug\"],\n",
    "        \"doc\": [\"Type: documentation\"],\n",
    "        \"repo\": df_ohmyzsh,\n",
    "    },\n",
    "    \"electron\": {\n",
    "        \"feature\": [\"enhancement :sparkles:\"],\n",
    "        \"bug\": [\"bug :beetle:\", \"crash :boom:\"],\n",
    "        \"doc\": [\"documentation :notebook:\"],\n",
    "        \"repo\": df_electron\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:2461\n",
      "Number of bug issues:6190\n",
      "Number of doc issues:1648\n",
      "Total issues:10299\n",
      "-------------------------\n",
      "rust issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:10163\n",
      "Number of bug issues:7049\n",
      "Number of doc issues:766\n",
      "Total issues:17978\n",
      "-------------------------\n",
      "kubernetes issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:4302\n",
      "Number of bug issues:10422\n",
      "Number of doc issues:968\n",
      "Total issues:15692\n",
      "-------------------------\n",
      "Overall issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:16926\n",
      "Number of bug issues:23661\n",
      "Number of doc issues:3382\n",
      "Total issues:43969\n",
      "-------------------------\n",
      "% of feature issues:0.38495303509290635\n",
      "% of bug issues:0.5381291364370352\n",
      "% of doc issues:0.07691782847005844\n",
      "-------------------------\n",
      "flutter issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:4387\n",
      "Number of bug issues:4318\n",
      "Number of doc issues:1102\n",
      "Total issues:9807\n",
      "-------------------------\n",
      "ohmyzsh issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:431\n",
      "Number of bug issues:308\n",
      "Number of doc issues:23\n",
      "Total issues:762\n",
      "-------------------------\n",
      "electron issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:1424\n",
      "Number of bug issues:3735\n",
      "Number of doc issues:274\n",
      "Total issues:5433\n",
      "-------------------------\n",
      "Overall issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:6242\n",
      "Number of bug issues:8361\n",
      "Number of doc issues:1399\n",
      "Total issues:16002\n",
      "-------------------------\n",
      "% of feature issues:0.39007624046994127\n",
      "% of bug issues:0.5224971878515186\n",
      "% of doc issues:0.08742657167854018\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "def analysis(mappings):\n",
    "    total_features = 0\n",
    "    total_bugs = 0\n",
    "    total_docs = 0\n",
    "    for repo_label, repo in mappings.items():\n",
    "        repo_features = 0\n",
    "        repo_bugs = 0\n",
    "        repo_docs = 0\n",
    "        for _, row in repo[\"repo\"].iterrows():\n",
    "            if row['labels'] in repo[\"feature\"]: repo_features += 1\n",
    "            elif row['labels'] in repo[\"bug\"]: repo_bugs += 1\n",
    "            elif row['labels'] in repo[\"doc\"]: repo_docs += 1\n",
    "        \n",
    "        print(f'{repo_label} issue analysis')\n",
    "        print('-------------------------')\n",
    "        print('Number of feature issues:' + str(repo_features))\n",
    "        print('Number of bug issues:' + str(repo_bugs))\n",
    "        print('Number of doc issues:' + str(repo_docs))\n",
    "        print('Total issues:' + str(repo_features + repo_bugs + repo_docs))        \n",
    "        print('-------------------------')\n",
    "        \n",
    "        total_features += repo_features\n",
    "        total_bugs += repo_bugs\n",
    "        total_docs += repo_docs\n",
    "        \n",
    "    total = total_features + total_bugs + total_docs\n",
    "    print(f'Overall issue analysis')\n",
    "    print('-------------------------')\n",
    "    print('Number of feature issues:' + str(total_features))\n",
    "    print('Number of bug issues:' + str(total_bugs))\n",
    "    print('Number of doc issues:' + str(total_docs))\n",
    "    print('Total issues:' + str(total))\n",
    "    \n",
    "    print('-------------------------')\n",
    "    print('% of feature issues:' + str(total_features / total))\n",
    "    print('% of bug issues:' + str(total_bugs / total))\n",
    "    print('% of doc issues:' + str(total_docs / total))\n",
    "    print('-------------------------')\n",
    "        \n",
    "        \n",
    "analysis(train_mappings)\n",
    "analysis(test_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# German repo\n",
    "df_corona_widget = pd.read_json('./data/de_unlabelled/corona-widget.json')\n",
    "df_open_wb = pd.read_json('./data/de_unlabelled/openWB.json')\n",
    "\n",
    "num_corona_widget = len(df_corona_widget.index)\n",
    "num_open_wb = len(df_open_wb)\n",
    "\n",
    "print('German repo issue analysis')\n",
    "print('--------------------------')\n",
    "print('Total number of corona widget issues:' + str(num_corona_widget))\n",
    "print('Total number of openWB issues:' + str(num_open_wb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French repo issue analysis\n",
      "--------------------------\n",
      "Total number of DVF-app issues:104\n",
      "Total number of Grafikart issues:313\n",
      "Total number of azure docs issues:247\n",
      "Total number of bcdlibre issues:36\n"
     ]
    }
   ],
   "source": [
    "# French repo\n",
    "df_dvf_app = pd.read_json('./data/fr_unlabelled/DVF-app.json')\n",
    "df_grafikart = pd.read_json('./data/fr_unlabelled/Grafikart.fr.json')\n",
    "df_azure_docs = pd.read_json('./data/fr_unlabelled/azure-docs.fr-fr.json')\n",
    "df_bcdlibre = pd.read_json('./data/fr_unlabelled/bcdlibre.json')\n",
    "\n",
    "num_row_dvf_app = len(df_dvf_app.index)\n",
    "num_grafikart = len(df_grafikart.index)\n",
    "num_azure_docs = len(df_azure_docs.index)\n",
    "num_bcdlibre = len(df_bcdlibre.index)\n",
    "\n",
    "print('French repo issue analysis')\n",
    "print('--------------------------')\n",
    "print('Total number of DVF-app issues:' + str(num_row_dvf_app))\n",
    "print('Total number of Grafikart issues:' + str(num_grafikart))\n",
    "print('Total number of azure docs issues:' + str(num_azure_docs))\n",
    "print('Total number of bcdlibre issues:' + str(num_bcdlibre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
