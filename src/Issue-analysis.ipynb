{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached https://files.pythonhosted.org/packages/32/2e/e4585559237787966aad0f8fd0fc31df1c4c9eb0e62de458c5b6cde954eb/python_dotenv-0.15.0-py2.py3-none-any.whl\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-0.15.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall\n",
      "-------\n",
      "Total number of tensorflow issues:19438\n",
      "Total number of rust issues:13657\n",
      "Total number of kubernetes issues:19255\n",
      "Total number of flutter issues:12574\n",
      "Total number of ohmyzsh issues:1370\n",
      "Total number of electron issues:4943\n"
     ]
    }
   ],
   "source": [
    "# Jupyter Notebook for GitHub issue data analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "ROOT = os.environ.get(\"ROOT\")  # remember to set your root path in `.env`; refer to installation.\n",
    "\n",
    "# English repo - train sets\n",
    "df_tensorflow = pd.read_json(f'{ROOT}/data/eng_labelled/remove_duplicates/tensorflow_removed_dups.json')\n",
    "df_rust = pd.read_json(f'{ROOT}/data/eng_labelled/remove_duplicates/rust_removed_dups.json')\n",
    "df_kubernetes = pd.read_json(f'{ROOT}/data/eng_labelled/remove_duplicates/kubernetes_removed_dups.json')\n",
    "\n",
    "# English repo - test sets\n",
    "df_flutter = pd.read_json(f'{ROOT}/data/eng_labelled/remove_duplicates/flutter_removed_dups.json')\n",
    "df_ohmyzsh = pd.read_json(f'{ROOT}/data/eng_labelled/remove_duplicates/ohmyzsh_removed_dups.json')\n",
    "df_electron = pd.read_json(f'{ROOT}/data/eng_labelled/remove_duplicates/electron_removed_dups.json')\n",
    "\n",
    "num_row_tensorflow = len(df_tensorflow.index)\n",
    "num_row_rust = len(df_rust.index)\n",
    "num_row_kubernetes = len(df_kubernetes.index)\n",
    "num_row_flutter = len(df_flutter.index)\n",
    "num_row_ohmyzsh = len(df_ohmyzsh.index)\n",
    "num_row_electron = len(df_electron.index)\n",
    "\n",
    "print('Overall')\n",
    "print('-------')\n",
    "print('Total number of tensorflow issues:' + str(num_row_tensorflow))\n",
    "print('Total number of rust issues:' + str(num_row_rust))\n",
    "print('Total number of kubernetes issues:' + str(num_row_kubernetes))\n",
    "print('Total number of flutter issues:' + str(num_row_flutter))\n",
    "print('Total number of ohmyzsh issues:' + str(num_row_ohmyzsh))\n",
    "print('Total number of electron issues:' + str(num_row_electron))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature word frequencies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('S', 102839),\n",
       " ('std', 30577),\n",
       " ('I', 23962),\n",
       " ('1', 20116),\n",
       " ('0', 19339),\n",
       " ('rust', 16952),\n",
       " ('Ratio', 16915),\n",
       " ('num_rational', 16900),\n",
       " ('https', 16294),\n",
       " ('error', 15932),\n",
       " ('mut', 15331),\n",
       " ('io', 13541),\n",
       " ('fn', 12151),\n",
       " ('com', 11544),\n",
       " ('type', 11210),\n",
       " ('2', 10817),\n",
       " ('iter', 10749),\n",
       " ('use', 10397),\n",
       " ('would', 10074),\n",
       " ('rs', 10064),\n",
       " ('kubernetes', 9504),\n",
       " ('github', 9172),\n",
       " ('src', 8564),\n",
       " ('x', 8488),\n",
       " ('The', 8314),\n",
       " ('version', 8283),\n",
       " ('Take', 8144),\n",
       " ('like', 8060),\n",
       " ('tensorflow', 7972),\n",
       " ('This', 7863),\n",
       " ('code', 7697),\n",
       " ('let', 7690),\n",
       " ('feature', 7464),\n",
       " ('T', 7082),\n",
       " ('3', 7050),\n",
       " ('self', 6957),\n",
       " ('tf', 6904),\n",
       " ('lang', 6448),\n",
       " ('impl', 6440),\n",
       " ('main', 6112),\n",
       " ('test', 5773),\n",
       " ('str', 5445),\n",
       " ('4', 5252),\n",
       " ('note', 5235),\n",
       " ('_', 5161),\n",
       " ('rustc', 5155),\n",
       " ('pub', 5154),\n",
       " ('using', 5117),\n",
       " ('It', 4857),\n",
       " ('foo', 4808),\n",
       " ('time', 4778),\n",
       " ('one', 4750),\n",
       " ('trait', 4745),\n",
       " ('5', 4712),\n",
       " ('could', 4580),\n",
       " ('org', 4553),\n",
       " ('name', 4338),\n",
       " ('e', 4336),\n",
       " ('Empty', 4320),\n",
       " ('expected', 4311),\n",
       " ('Chain', 4271),\n",
       " ('example', 4266),\n",
       " ('NoData', 4176),\n",
       " ('A', 4063),\n",
       " ('new', 4057),\n",
       " ('function', 4039),\n",
       " ('What', 3937),\n",
       " ('struct', 3889),\n",
       " ('i32', 3874),\n",
       " ('issues', 3873),\n",
       " ('core', 3856),\n",
       " ('cc', 3802),\n",
       " ('lib', 3778),\n",
       " ('g', 3712),\n",
       " ('current', 3705),\n",
       " ('value', 3651),\n",
       " ('If', 3602),\n",
       " ('get', 3537),\n",
       " ('8', 3533),\n",
       " ('found', 3479)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data = []\n",
    "doc_data = []\n",
    "bug_data = []\n",
    "other_data = []\n",
    "\n",
    "for _, row in df_kubernetes.iterrows():\n",
    "    # feature\n",
    "    if row['labels'] == 'kind/feature' or row['labels'] == 'kind/api-change': \n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    elif row['labels'] == 'kind/bug' or row['labels'] == 'kind/failing-test':\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    elif row['labels'] == 'kind/documentation': \n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    else:\n",
    "        other_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        other_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "\n",
    "for _, row in df_rust.iterrows():\n",
    "    if row['labels'] == 'C-feature-request' or row['labels'] == 'C-feature-accepted' or row['labels'] == 'C-enhancement': \n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    elif row['labels'] == 'C-bug': \n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    elif row['labels'] == 'T-doc': \n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    else:\n",
    "        other_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        other_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "\n",
    "for _, row in df_tensorflow.iterrows():\n",
    "    if row['labels'] == 'type:feature':\n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        feature_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    elif row['labels'] == 'type:docs-feature' or row['labels'] == 'type:docs-bug':\n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        doc_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    elif row['labels'] == 'type:others':\n",
    "        other_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        other_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "    else:\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['title']) if w not in stop])\n",
    "        bug_data.extend([w for w in tokenizer.tokenize(row['body']) if w not in stop])\n",
    "        \n",
    "print(\"Feature word frequencies:\")\n",
    "feature_freq = FreqDist(feature_data)\n",
    "feature_freq.most_common(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc word frequencies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('https', 6039),\n",
       " ('tensorflow', 5905),\n",
       " ('0', 4509),\n",
       " ('I', 4366),\n",
       " ('1', 4238),\n",
       " ('tf', 4108),\n",
       " ('org', 3080),\n",
       " ('com', 2965),\n",
       " ('docs', 2482),\n",
       " ('documentation', 2449),\n",
       " ('rust', 2393),\n",
       " ('github', 2373),\n",
       " ('issue', 2341),\n",
       " ('2', 2271),\n",
       " ('python', 2174),\n",
       " ('www', 2160),\n",
       " ('The', 2140),\n",
       " ('kubernetes', 1975),\n",
       " ('example', 1901),\n",
       " ('version', 1716),\n",
       " ('code', 1659),\n",
       " ('doc', 1609),\n",
       " ('use', 1545),\n",
       " ('lang', 1448),\n",
       " ('keras', 1274),\n",
       " ('master', 1230),\n",
       " ('issues', 1224),\n",
       " ('TensorFlow', 1211),\n",
       " ('10', 1202),\n",
       " ('3', 1162),\n",
       " ('io', 1159),\n",
       " ('x', 1143),\n",
       " ('guide', 1138),\n",
       " ('blob', 1125),\n",
       " ('py', 1120),\n",
       " ('std', 1101),\n",
       " ('defined', 1038),\n",
       " ('name', 1015),\n",
       " ('html', 975),\n",
       " ('api_docs', 950),\n",
       " ('error', 922),\n",
       " ('This', 901),\n",
       " ('link', 901),\n",
       " ('md', 897),\n",
       " ('would', 887),\n",
       " ('source', 883),\n",
       " ('node', 879),\n",
       " ('go', 869),\n",
       " ('using', 864),\n",
       " ('line', 864),\n",
       " ('self', 855),\n",
       " ('model', 854),\n",
       " ('API', 843),\n",
       " ('needs', 822),\n",
       " ('src', 820),\n",
       " ('v1', 808),\n",
       " ('lib', 783),\n",
       " ('get', 737),\n",
       " ('examples', 723),\n",
       " ('If', 720),\n",
       " ('k8s', 716),\n",
       " ('kubectl', 706),\n",
       " ('It', 698),\n",
       " ('URL', 693),\n",
       " ('file', 692),\n",
       " ('like', 690),\n",
       " ('5', 690),\n",
       " ('user', 665),\n",
       " ('data', 660),\n",
       " ('Description', 653),\n",
       " ('build', 647),\n",
       " ('e', 646),\n",
       " ('pull', 645),\n",
       " ('4', 641),\n",
       " ('site', 633),\n",
       " ('7', 623),\n",
       " ('13', 619),\n",
       " ('changing', 619),\n",
       " ('image', 613),\n",
       " ('one', 611)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Doc word frequencies:\")\n",
    "doc_freq = FreqDist(doc_data)\n",
    "doc_freq.most_common(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug word frequencies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', 249166),\n",
       " ('1', 191927),\n",
       " ('tensorflow', 167661),\n",
       " ('I', 99559),\n",
       " ('2', 86060),\n",
       " ('tf', 83433),\n",
       " ('lib', 79166),\n",
       " ('version', 77218),\n",
       " ('_', 76315),\n",
       " ('go', 69267),\n",
       " ('kubernetes', 66144),\n",
       " ('10', 61516),\n",
       " ('3', 61310),\n",
       " ('src', 60296),\n",
       " ('python', 56982),\n",
       " ('py', 56140),\n",
       " ('io', 54143),\n",
       " ('https', 51810),\n",
       " ('error', 48827),\n",
       " ('com', 48499),\n",
       " ('k8s', 44949),\n",
       " ('packages', 44434),\n",
       " ('cc', 43561),\n",
       " ('line', 43438),\n",
       " ('6', 41978),\n",
       " ('std', 41567),\n",
       " ('rustc', 40748),\n",
       " ('core', 40293),\n",
       " ('7', 39673),\n",
       " ('File', 38906),\n",
       " ('4', 38125),\n",
       " ('self', 38008),\n",
       " ('rs', 37914),\n",
       " ('model', 36816),\n",
       " ('5', 36499),\n",
       " ('build', 36375),\n",
       " ('x86_64', 36124),\n",
       " ('C', 35133),\n",
       " ('name', 34814),\n",
       " ('TensorFlow', 34267),\n",
       " ('code', 34256),\n",
       " ('home', 33767),\n",
       " ('site', 33185),\n",
       " ('github', 33094),\n",
       " ('16', 31958),\n",
       " ('8', 31602),\n",
       " ('11', 31256),\n",
       " ('local', 31231),\n",
       " ('python3', 31154),\n",
       " ('use', 30915),\n",
       " ('usr', 30484),\n",
       " ('12', 30310),\n",
       " ('rust', 30112),\n",
       " ('test', 29384),\n",
       " ('v1', 29291),\n",
       " ('keras', 29257),\n",
       " ('bug', 28323),\n",
       " ('linux', 27878),\n",
       " ('source', 27463),\n",
       " ('e', 27197),\n",
       " ('import', 27064),\n",
       " ('04', 26412),\n",
       " ('g', 25911),\n",
       " ('14', 25870),\n",
       " ('2020', 25377),\n",
       " ('node', 24648),\n",
       " ('file', 24428),\n",
       " ('using', 23934),\n",
       " ('kubelet', 23484),\n",
       " ('18', 22615),\n",
       " ('9', 22210),\n",
       " ('type', 22167),\n",
       " ('run', 21857),\n",
       " ('ty', 21782),\n",
       " ('x', 21729),\n",
       " ('device', 21671),\n",
       " ('The', 21668),\n",
       " ('lite', 21637),\n",
       " ('2019', 21341),\n",
       " ('master', 20947)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Bug word frequencies:\")\n",
    "bug_freq = FreqDist(bug_data)\n",
    "bug_freq.most_common(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Other word frequencies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0', 18760),\n",
       " ('1', 13986),\n",
       " ('kubernetes', 11471),\n",
       " ('go', 9528),\n",
       " ('I', 8421),\n",
       " ('io', 6878),\n",
       " ('https', 6510),\n",
       " ('10', 6122),\n",
       " ('k8s', 5792),\n",
       " ('com', 5703),\n",
       " ('2', 5242),\n",
       " ('kubelet', 4985),\n",
       " ('master', 4871),\n",
       " ('kube', 4782),\n",
       " ('github', 4093),\n",
       " ('tensorflow', 3991),\n",
       " ('v1', 3963),\n",
       " ('version', 3914),\n",
       " ('3', 3777),\n",
       " ('src', 3427),\n",
       " ('01', 3308),\n",
       " ('name', 2955),\n",
       " ('use', 2878),\n",
       " ('11', 2874),\n",
       " ('cluster', 2827),\n",
       " ('16', 2749),\n",
       " ('kubectl', 2685),\n",
       " ('4', 2625),\n",
       " ('node', 2616),\n",
       " ('error', 2509),\n",
       " ('pod', 2408),\n",
       " ('service', 2287),\n",
       " ('tf', 2264),\n",
       " ('pkg', 2109),\n",
       " ('rust', 2078),\n",
       " ('19', 2053),\n",
       " ('The', 1995),\n",
       " ('x', 1990),\n",
       " ('18', 1979),\n",
       " ('test', 1961),\n",
       " ('5', 1942),\n",
       " ('15', 1935),\n",
       " ('code', 1925),\n",
       " ('get', 1906),\n",
       " ('apiserver', 1894),\n",
       " ('7', 1891),\n",
       " ('default', 1891),\n",
       " ('20', 1868),\n",
       " ('14', 1859),\n",
       " ('server', 1837),\n",
       " ('api', 1833),\n",
       " ('12', 1825),\n",
       " ('lib', 1816),\n",
       " ('8', 1810),\n",
       " ('Kubernetes', 1807),\n",
       " ('docker', 1757),\n",
       " ('6', 1750),\n",
       " ('file', 1735),\n",
       " ('etc', 1733),\n",
       " ('17', 1705),\n",
       " ('cc', 1677),\n",
       " ('system', 1676),\n",
       " ('00', 1652),\n",
       " ('08', 1590),\n",
       " ('22', 1583),\n",
       " ('type', 1575),\n",
       " ('local', 1489),\n",
       " ('using', 1488),\n",
       " ('pods', 1486),\n",
       " ('true', 1450),\n",
       " ('21', 1441),\n",
       " ('e', 1437),\n",
       " ('core', 1423),\n",
       " ('image', 1414),\n",
       " ('If', 1392),\n",
       " ('py', 1383),\n",
       " ('What', 1369),\n",
       " ('07', 1368),\n",
       " ('06', 1361),\n",
       " ('run', 1359)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Other word frequencies:\")\n",
    "other_freq = FreqDist(other_data)\n",
    "other_freq.most_common(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mappings = {\n",
    "    \"tf\": {\n",
    "        \"feature\": [\"type:feature\"],\n",
    "        \"bug\": [\"type:bug\"],\n",
    "        \"doc\": [\"type:docs-feature\", \"type:docs-bug\"],\n",
    "        \"repo\": df_tensorflow\n",
    "    },\n",
    "    \"rust\": {\n",
    "        \"feature\": [\"C-feature-request\", \"C-feature-accepted\", \"C-enhancement\"],\n",
    "        \"bug\": [\"C-bug\"],\n",
    "        \"doc\": [\"T-doc\"],\n",
    "        \"repo\": df_rust\n",
    "    },\n",
    "    \"kubernetes\": {\n",
    "        \"feature\": [\"kind/feature\", \"kind/api-change\"],\n",
    "        \"bug\": [\"kind/bug\"],\n",
    "        \"doc\": [\"kind/documentation\"],\n",
    "        \"repo\": df_kubernetes\n",
    "    }\n",
    "}\n",
    "\n",
    "test_mappings = {\n",
    "    \"flutter\": {\n",
    "        \"feature\": ['severe: new feature'],\n",
    "        \"bug\": [\"severe: crash\", \"severe: fatal crash\", \"severe: rendering\"],\n",
    "        \"doc\": [\"documentation\"],\n",
    "        \"repo\": df_flutter\n",
    "    },\n",
    "    \"ohmyzsh\": {\n",
    "        \"feature\": [\"Feature\", \"Enhancement\"],\n",
    "        \"bug\": [\"Bug\"],\n",
    "        \"doc\": [\"Type: documentation\"],\n",
    "        \"repo\": df_ohmyzsh,\n",
    "    },\n",
    "    \"electron\": {\n",
    "        \"feature\": [\"enhancement :sparkles:\"],\n",
    "        \"bug\": [\"bug :beetle:\", \"crash :boom:\"],\n",
    "        \"doc\": [\"documentation :notebook:\"],\n",
    "        \"repo\": df_electron\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:2314\n",
      "Number of bug issues:6063\n",
      "Number of doc issues:1431\n",
      "Total issues:9808\n",
      "-------------------------\n",
      "rust issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:5376\n",
      "Number of bug issues:6843\n",
      "Number of doc issues:301\n",
      "Total issues:12520\n",
      "-------------------------\n",
      "kubernetes issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:4061\n",
      "Number of bug issues:10172\n",
      "Number of doc issues:878\n",
      "Total issues:15111\n",
      "-------------------------\n",
      "Overall issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:11751\n",
      "Number of bug issues:23078\n",
      "Number of doc issues:2610\n",
      "Total issues:37439\n",
      "-------------------------\n",
      "% of feature issues:0.3138705627821256\n",
      "% of bug issues:0.6164160367531184\n",
      "% of doc issues:0.069713400464756\n",
      "-------------------------\n",
      "flutter issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:4197\n",
      "Number of bug issues:4044\n",
      "Number of doc issues:933\n",
      "Total issues:9174\n",
      "-------------------------\n",
      "ohmyzsh issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:294\n",
      "Number of bug issues:209\n",
      "Number of doc issues:21\n",
      "Total issues:524\n",
      "-------------------------\n",
      "electron issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:1283\n",
      "Number of bug issues:3458\n",
      "Number of doc issues:202\n",
      "Total issues:4943\n",
      "-------------------------\n",
      "Overall issue analysis\n",
      "-------------------------\n",
      "Number of feature issues:5774\n",
      "Number of bug issues:7711\n",
      "Number of doc issues:1156\n",
      "Total issues:14641\n",
      "-------------------------\n",
      "% of feature issues:0.3943719691277918\n",
      "% of bug issues:0.526671675432006\n",
      "% of doc issues:0.07895635544020217\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "def analysis(mappings):\n",
    "    total_features = 0\n",
    "    total_bugs = 0\n",
    "    total_docs = 0\n",
    "    for repo_label, repo in mappings.items():\n",
    "        repo_features = 0\n",
    "        repo_bugs = 0\n",
    "        repo_docs = 0\n",
    "        for _, row in repo[\"repo\"].iterrows():\n",
    "            if row['labels'] in repo[\"feature\"]: repo_features += 1\n",
    "            elif row['labels'] in repo[\"bug\"]: repo_bugs += 1\n",
    "            elif row['labels'] in repo[\"doc\"]: repo_docs += 1\n",
    "        \n",
    "        print(f'{repo_label} issue analysis')\n",
    "        print('-------------------------')\n",
    "        print('Number of feature issues:' + str(repo_features))\n",
    "        print('Number of bug issues:' + str(repo_bugs))\n",
    "        print('Number of doc issues:' + str(repo_docs))\n",
    "        print('Total issues:' + str(repo_features + repo_bugs + repo_docs))        \n",
    "        print('-------------------------')\n",
    "        \n",
    "        total_features += repo_features\n",
    "        total_bugs += repo_bugs\n",
    "        total_docs += repo_docs\n",
    "        \n",
    "    total = total_features + total_bugs + total_docs\n",
    "    print(f'Overall issue analysis')\n",
    "    print('-------------------------')\n",
    "    print('Number of feature issues:' + str(total_features))\n",
    "    print('Number of bug issues:' + str(total_bugs))\n",
    "    print('Number of doc issues:' + str(total_docs))\n",
    "    print('Total issues:' + str(total))\n",
    "    \n",
    "    print('-------------------------')\n",
    "    print('% of feature issues:' + str(total_features / total))\n",
    "    print('% of bug issues:' + str(total_bugs / total))\n",
    "    print('% of doc issues:' + str(total_docs / total))\n",
    "    print('-------------------------')\n",
    "        \n",
    "        \n",
    "analysis(train_mappings)\n",
    "analysis(test_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# German repo\n",
    "df_corona_widget = pd.read_json('./data/de_unlabelled/corona-widget.json')\n",
    "df_open_wb = pd.read_json('./data/de_unlabelled/openWB.json')\n",
    "\n",
    "num_corona_widget = len(df_corona_widget.index)\n",
    "num_open_wb = len(df_open_wb)\n",
    "\n",
    "print('German repo issue analysis')\n",
    "print('--------------------------')\n",
    "print('Total number of corona widget issues:' + str(num_corona_widget))\n",
    "print('Total number of openWB issues:' + str(num_open_wb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French repo issue analysis\n",
      "--------------------------\n",
      "Total number of DVF-app issues:104\n",
      "Total number of Grafikart issues:313\n",
      "Total number of azure docs issues:247\n",
      "Total number of bcdlibre issues:36\n"
     ]
    }
   ],
   "source": [
    "# French repo\n",
    "df_dvf_app = pd.read_json('./data/fr_unlabelled/DVF-app.json')\n",
    "df_grafikart = pd.read_json('./data/fr_unlabelled/Grafikart.fr.json')\n",
    "df_azure_docs = pd.read_json('./data/fr_unlabelled/azure-docs.fr-fr.json')\n",
    "df_bcdlibre = pd.read_json('./data/fr_unlabelled/bcdlibre.json')\n",
    "\n",
    "num_row_dvf_app = len(df_dvf_app.index)\n",
    "num_grafikart = len(df_grafikart.index)\n",
    "num_azure_docs = len(df_azure_docs.index)\n",
    "num_bcdlibre = len(df_bcdlibre.index)\n",
    "\n",
    "print('French repo issue analysis')\n",
    "print('--------------------------')\n",
    "print('Total number of DVF-app issues:' + str(num_row_dvf_app))\n",
    "print('Total number of Grafikart issues:' + str(num_grafikart))\n",
    "print('Total number of azure docs issues:' + str(num_azure_docs))\n",
    "print('Total number of bcdlibre issues:' + str(num_bcdlibre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
