[
    {
        "title": "Add riscv64 backend for node.js",
        "body": "Hi all,\r\n   I am a developer about v8 for riscv64  and v8 for riscv64  patch had been upstreamed into google repo. \r\n   I want to add support for node.js. I have build success locally.  \r\n   And what should i  do before opening a pr to submit it ? \r\n",
        "labels": "feature request",
        "id": 42845
    },
    {
        "title": "Command-line parameter to force \"module\" instead of \"commonjs\" type?",
        "body": "I'm aware that I can name a file with `.mjs` or set `\"type\": \"module\"` in package.json. I'm also aware of the `--input-type=module` CLI parameter.\r\n\r\nWhat I'm not understanding is, why isn't there a way to pass a parameter flag to force module interpretation for the `.js` file I specify? Was there a reason that `--input-type` can only be used with string input and not to control module interpretation of a `.js` file?\r\n\r\nI tried searching old issues to find this discussed but my searching failed me. I feel certain it must have been intentionally omitted, but I'm just trying to understand why?",
        "labels": "feature request",
        "id": 42846
    },
    {
        "title": "Configure post resolution aliasing",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nCurrently Policies can emulate much behaviors of import maps. However, I have identified that a specific kind of relative mapping such as an import map of the following form:\r\n\r\n```json\r\n{\r\n  \"scopes\": {\r\n    \"/\": {\r\n      \"./foo\": \"./foo/v1.js\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nCannot be emulated.\r\n\r\nThis is because import maps do not apply import map aliasing prior to url canonicalization. This is because without aliasing the only resolution applied for the web is url canonicalization. In terms of Loaders, this interception is applied after  a `resolve()` and uses either the original specifier if unable to resolve or the resolved resulting URL if able to resolve.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nPolicies currently only apply interception prior to canonicalization, but should allow interception after resolution. This likely needs to ensure any ESM Loader designs properly can compose against the feature. Current composition with Policies and Loaders is that Loaders are able to act both prior to and after policies as a delegated function call. It is my assumption that we can preserve this behavior as the following:\r\n\r\n```\r\n0. Given an import resolution request\r\n1. Apply current \"dependencies\" feature of policies\r\n  i. Resolve to string if target is a string\r\n  ii. Perform *node* resolution if target is `true`\r\n  iii. Error otherwise\r\n3. *NEW* apply ??? feature to alias the resolved path from #1 and/or #2\r\n```\r\n\r\nNote, with the feature design above a policy would not be able to intercept \"bare\" imports at the proper time to preempt the default *node* resolution algorithm. Perhaps a better design could be found.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nStill designing, open to any alternatives.",
        "labels": "feature request",
        "id": 42847
    },
    {
        "title": "Feature request: provide deep (recursive) fs.writeFile()",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nHaving to write the same boilerplate for writing a file to a directory that doesn't yet exist over and over again.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nIdeally, I'd be able to use `fs.writeFile()` (or `fs.writeFileSync()`) with the `{ recursive: true }` option that's available on [`fs.mkdir()`](https://nodejs.org/api/fs.html#fs_fs_mkdir_path_options_callback) and its friends.\r\n\r\n```\r\nconst path = require('path')\r\n\r\nconst resolvedPath = path.resolve('./somePath')\r\nconst data = {\r\n  some: 'data'\r\n}\r\n\r\nfs.writeFile(path, data, { recursive: true }, (error) => {\r\n  if (error) throw error\r\n})\r\n```\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\n- Checking if the directory exits recursively then writing the file if that succeeds\r\n  - This is annoying and frankly ugly boilerplate for a common operation.\r\n- Using community tooling\r\n  - Since this is an extension of a core method, I don't particularly feel great about taking on a third-party dependency to fill a gap so I can be relatively lazy. \r\n  - This is also an option that could theoretically benefit anyone writing files to a directory that may not exist. I think that filling that gap in our own API rather than pushing folks to community tools will be a win for end-users' time in addition to their dependency tree.",
        "labels": "feature request",
        "id": 42848
    },
    {
        "title": "Add abortSignal to every request handler",
        "body": "If you come from the world of Service Worker and acts a bit like a man in the middle by inspecting every network request that goes in and out  or you are working with the fetch api then you will see that the spec specifies that every Request has an associated AbortSignal.\r\n\r\n```js\r\n// you can construct one on your own\r\nnew window.Request('/').signal instanceof AbortSignal // yields true\r\n\r\n// FYI, this is not the same signal that have been passed in as an argument\r\nvar { signal } = new AbortController()\r\nnew window.Request('/', { signal }).signal === signal // yields false\r\n```\r\n\r\nNow what can this be used for? Well, getting things from the database or convert some file as long as the user is connected\r\nI think we should make the request handler a tiny bit more like the service worker by adding in a abortSignal into every request handler.\r\nI wish i could do something like: \r\n```js\r\nhttp.createServer((req, res) => {\r\n  mongodb.getUser(userId, { signal: req.signal })\r\n})\r\n\r\n// Same service worker equivalent \r\nself.on('fetch', evt => {\r\n  evt.respondWith(fetch(getUserRequest, { signal: evt.request.signal }))\r\n})\r\n```\r\nif a client abort or disconnect then so should the call for retrieving something from the database",
        "labels": "feature request",
        "id": 42849
    },
    {
        "title": "doc: DEP0066 is slightly incorrect",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v15.11.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux nuc 5.4.0-65-generic #73~18.04.1-Ubuntu SMP Tue Jan 19 09:02:24 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: http.ClientRequest\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/deprecations.html#deprecations_dep0066_outgoingmessage_prototype_headers_outgoingmessage_prototype_headernames\r\n\r\n## Description\r\n\r\n[DEP0066](https://nodejs.org/api/deprecations.html#deprecations_dep0066_outgoingmessage_prototype_headers_outgoingmessage_prototype_headernames) implies that using `OutgoingMessage.prototype.getHeaderNames()` is equivalent to the now deprecated `OutgoingMessage.prototype._headerNames` property which is not the case.\r\n\r\n`OutgoingMessage.prototype._headerNames` contains a mapping from lowercase to the exact header names that were sent with the request:\r\n\r\n```\r\n{authorization: \"Authorization\", host: \"Host\"}\r\n```\r\n\r\nWhere `OutgoingMessage.prototype.getHeaderNames()` returns only lowercase names.\r\n\r\nThe now deprecated `_headerNames` property is useful in http debug logging modules that print the exact header names being sent, as some servers are still picky about those. Not having access to the actual header names will make debugging harder, assuming node still sends the headers as they are sent through the `http.request` method.\r\n\r\nBesides the documentation being misleading about this I'd like to know if there is a way to access the headers being sent going forward, since `_headerNames` is now deprecated.",
        "labels": "feature request",
        "id": 42850
    },
    {
        "title": "ERR_MODULE_NOT_FOUND: add a property to exception object to hold failing import's argument",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI am developing a framework that uses node as a host for user scripts. The framework loads them dynamically with the async `import()` function, and the userscripts can also import other modules with `import` statement.\r\n\r\nWhen I call that `import()` function, I basically want to rethrow all errors thrown by it, **except** for one very specific condition: when the `import()` function fails with `ERR_MODULE_NOT_FOUND` because the userscript file itself wasn't present in the location just tried. The userscript might still be found in some other search path, which is why its absence in any given candidate location is not an error. If however the `import()` function failed with `ERR_MODULE_NOT_FOUND` because some **other** module **imported** by the userscript was not found, then I want to rethrow that error.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd a property to the exception object thrown for `ERR_MODULE_NOT_FOUND` that will hold the exact value of the argument that was given to the failing `import` function or statement.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI considered checking for existence first and then attempting to `import()`, but that is a known antipattern.\r\n\r\nI considered parsing the `message` or `stack` property, but that would be a hack. These properties are probably locale dependent and their format is not set in stone.\r\n\r\nI looked into custom loaders and found the subject difficult, scary, apparently indefinitely experimental, and an overkill for this particular purpose. I need a simple and reliable way.",
        "labels": "feature request",
        "id": 42851
    },
    {
        "title": "Transfer child process stderr/stdout to Worker?",
        "body": "Is/could it be possible to transfer the stderr/stdout fd of a child process (`child_process.spawn(...)`) to a Worker and have the worker read the output?\r\n\r\ni.e. instead of:\r\n\r\n```js\r\nconst proc = cp.spawn(...)\r\nconst worker = new Worker(..., { stdin: true })\r\nproc.stdout.pipe(worker.stdin)\r\n\r\n// Worker\r\n\r\nconst src = process.stdin\r\n```\r\n\r\nto do something like:\r\n\r\n```js\r\nconst proc = cp.spawn(...)\r\nconst worker = new Worker(..., { workerData: {fd: proc.stdout.fd }, transferList: [proc.stdout.fd] })\r\n\r\n// Worker\r\n\r\nconst src = something(workerData.fd) // Maybe new Socket({ fd })?\r\n```",
        "labels": "feature request",
        "id": 42852
    },
    {
        "title": "Lookup user name by uid, group name from gid, or vice-versa",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI would like to get \r\n* username from uid, or vice-versa\r\n* group name from gid, or vice-versa\r\n\r\nto show names in CLI app that handles files.\r\nIIUC, nodejs offers `fs.stat` or variants that can retrieve uid/gid, but these methods can not retrieve username/group name.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nI think `os` module is a good place to have these feature.\r\nI imagine interfaces something like:\r\n```javascript\r\nos.userid(\"john\") // returns 1001\r\nos.username(1001) // returns john\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nCurrently, I am using https://github.com/cinderblock/node-userid which provides id/name conversion.\r\nHowever, it lacks Windows OS support.\r\n",
        "labels": "feature request",
        "id": 42853
    },
    {
        "title": "late code injection",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, a node process cannot receive and execute custom code after it has started. For monitoring tools, a common use case is to be able to attach to an arbitrary process, inject a (tracing) code, instruct the runtime to execute that, and optionally detach from the process.\r\n\r\n**Describe the solution you'd like**\r\n - define a mechanism to interrupt the runtime (signals in platforms where supported)\r\n - specify a Javascript interface for the code injection:\r\n   - the signal is delegated to a Javascript handler function\r\n   - a module with a predefined name (such as `agent`) is loaded\r\n   - a function with a predefined name (such as `execute`) is executed\r\n   - a user can define this module and place it in the search path, prior to signalling\r\n   - upon completion, the module is unloaded\r\n - define security restrictions (only requests from matching UID / GID allowed)\r\n\r\n**Describe alternatives you've considered**\r\n - modify the application and integrate with the monitoring tools\r\n - define a specific function in the application that receives code at runtime\r\n\r\n",
        "labels": "feature request",
        "id": 42854
    },
    {
        "title": "Vendor Events on NPM",
        "body": "Context: https://github.com/browserify/events/issues/79\r\n\r\nIt would be useful if `events` was vendored in a similar way to `readable-stream`.\r\n\r\nI have brought this possibility up in the events repo https://github.com/browserify/events ( https://www.npmjs.com/package/events )\r\n\r\nThis should be pretty straightforward given `events` is _mostly_ self contained.\r\n\r\ncc @goto-bus-stop :) \r\n\r\n",
        "labels": "feature request",
        "id": 42855
    },
    {
        "title": "Load NODE_OPTIONS from a file",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nCurrently there are useful node options(https://nodejs.org/api/cli.html#cli_node_options_options) I would like to be able to easily specify project wide like `--max-old-space-size` and `--preserve-symlinks` but there is not really a way to do it through the repository only through `NODE_OPTIONS` or by specifying it by hand every time an npm script is defined which is not convenient for large sized monorepos.\r\n \r\n**Describe the solution you'd like**\r\nI would like to be able to specify those options in a file that, if present, `node` will try to read the options from it. The name could be for example `.node_options`. Each option will be specified per line and will override every other option specified through `NODE_OPTIONS` env var or directly passed when invoking the node binary.\r\n\r\n**Describe alternatives you've considered**\r\nRight now that is non easy way to accomplish the use case that I have.\r\n",
        "labels": "feature request",
        "id": 42856
    },
    {
        "title": "Add on/off to EventSignal?",
        "body": "Would if make sense to add on/off as aliases to addEventListener/removeEventListener?\r\n\r\nI'm ending up writing quite a bit of code that checks for either since usually I like to implement api's to support both EventEmitter and AbortSignal. Having the aliases would make code much easier and less error prone.",
        "labels": "feature request",
        "id": 42857
    },
    {
        "title": "Add functions to register \"then\" and \"catch\" handlers with promise",
        "body": "\r\n**Is your feature request related to a problem? Please describe.**\r\nI would like to be able to add \"then\" and \"catch\" handlers to promises that JS functions return to C++.\r\n\r\n**Describe the solution you'd like**\r\nI would like functions like this (obviously with naming subject to change):\r\n\r\n```c++\r\ntypedef void (*promise_success_callback)(napi_env env,\r\n                                         napi_value success_value,\r\n                                         void* data);\r\n\r\ntypedef void (*promise_failure_callback)(napi_env env,\r\n                                         napi_value error_value,\r\n                                         void* data);\r\n\r\nnapi_status napi_add_promise_success_callback(napi_env env,\r\n                                              napi_value promise,\r\n                                              promise_success_callback success_callback,\r\n                                              void* data);\r\n\r\nnapi_status napi_add_promise_failure_callback(napi_env env,\r\n                                              napi_value promise,\r\n                                              promise_failure_callback failure_callback,\r\n                                              void* data);\r\n```\r\nAn additional function could be\r\n\r\n```c++\r\ntypedef void (*promise_fulfilled_callback)(napi_env env,\r\n                                           napi_value error_value,\r\n                                           napi_value success_value,\r\n                                           void* data);\r\n\r\nnapi_status napi_add_promise_fulfilled_callback(napi_env env,\r\n                                                napi_value promise,\r\n                                                promise_fulfilled_callback fulfilled_callback,\r\n                                                void* data);\r\n```\r\nor\r\n\r\n```c++\r\nnapi_status napi_add_promise_fulfilled_callbacks(napi_env env,\r\n                                                 napi_value promise,\r\n                                                 promise_failure_callback failure_callback,\r\n                                                 promise_success_callback success_callback,\r\n                                                 void* data);\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nIn the meantime, I am using the `memcpy` trick to convert a `napi_value` promise to a v8::Promise and then using the v8::Promise::{Then|Catch} methods to handle the promise fulfillment.\r\n",
        "labels": "feature request",
        "id": 42858
    },
    {
        "title": "Built in cross-platform nodejs version manager",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\nNo.\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n`node update` command. Updates NodeJS whilst still keeping global modules installed. Has to be cross-platform.\r\nKinda like rustup, but, for NodeJS & cross platform\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\nnvm-windows except it breaks and make you re-install global packages.",
        "labels": "feature request",
        "id": 42859
    },
    {
        "title": "Special threat for outgoing information and for ingoing information trought IPC",
        "body": "Sockets for receiving information will have single threat special for itself, if information arrived on socked, data will be merged to main threat, same for outgoing sockets but there data will be send along with doing another process.\r\n\r\nOn those CPU's with some cores and twice as much threats, it could highly reduce latency of interprocess communication.\r\n\r\nPlease consider this as serious thing. Like that, you have l1 core, for both threats if I'm not correct correct me, but those data get diverged and merged at L1 cache instantly, and it'll work better.\r\n\r\nIf we have one process, that has something like input of 42k objects of simple graph nodes per second, and it have to deliver it to database, it's faster if receiving runs in one threat, sorting in another and sending in another... \r\n\r\nLike this, we can use Ryzen and Threadripper technologies of IPC that works on basis of streams, which is very efficient for stream processors, if they're split into various processes, and therefore we can achieve maximum of node's performance.\r\n\r\nEven for tasks like getting distribution of change from processor trough websockets, it's better, because distribution runs in single threat, and another threat on processor can still react on change or whatever, or it can actually change, while the alternative threat is delivering chance in cycles of threat syncs and split... \r\n\r\nEssentially, when you send to by socket, you read data that are arranged by set of pointers to be read from memory, now it's same threat in new node it can be another, therefore it just reads data that are not writtable, because if those data was written in there would be new pointer to their copy where write happened.\r\n\r\nWhere we're recieving, we got this one threat, that's pumping data into proccess, and on every sync, therefore something like one line of stdout to another stdin, can be being loading on one threat, while another is sorting just loaded data, therefore it's twice that fast.\r\n\r\nPlease code it, I don't orientate in this C++ mess node is. It's like function calls and stuff doesn't make sense to me and it'll take me like two weeks to code this, and I have better stuff to do.",
        "labels": "feature request",
        "id": 42860
    },
    {
        "title": "DNS: Add support for Recursion / Full Answer",
        "body": "dns.resolve() returns the final A answer. Often when there is a CNAME which is very common these days, it could be useful to see the full chain.\r\n\r\nThis issue is to suggest showing the full Answer in the response\r\n\r\n\r\nThe below code returns the A record \"13.234.176.102\"\r\nconst { Resolver } = require('dns').promises;\r\nconst resolver = new Resolver();\r\nresolver.setServers(['8.8.8.8']);\r\n\r\nresolver.resolve4('www.github.com').then((addresses) => {\r\n  console.log(addresses);\r\n});\r\n\r\ndig however shows the full/chain answer\r\n\r\n;; ANSWER SECTION:\r\nwww.github.com.         3600    IN      CNAME   github.com.\r\ngithub.com.             60      IN      A       13.234.210.38\r\n\r\nI am not able to fully figure out if this is easily supported by relying on c-ares's ares_mkquery() via the parameter rd or not\r\n",
        "labels": "feature request",
        "id": 42861
    },
    {
        "title": "[Feature] Expose getOptionValue via process.getOptionValue",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\n**Use case:** I'm trying to implement `\"exports\"` support inside the [PnP resolver](https://yarnpkg.com/features/pnp) which patches the Node resolution algorithm and I want it to be as Node-compliant as possible. For that, I need to implement the [resolving user conditions](https://nodejs.org/api/packages.html#packages_resolving_user_conditions) part via the `--conditions` flag. The problem is that Node gives me no easy way to access the resolved value of a flag (as far as I'm aware).\r\n\r\n**Problem:**\r\n\r\nNode option values can come from 2 different places (as far as I'm aware): the arguments passed to the node binary and `NODE_OPTIONS`.\r\n\r\nNode currently has an internal function called [`getOptionValue`](https://github.com/nodejs/node/blob/2af43f65055de2817eb7907d3a3d3b3a3de127f5/lib/internal/options.js#L8) that returns the value of an option, resolving both the arguments passed to the node binary and `NODE_OPTIONS`. \r\n\r\n`getOptionValue` is only exported in `internal/options`, so it can't be accessed.\r\n\r\nAlso, `getOptionValue` uses a native implementation via `getOptions` from the `options` internal binding which isn't whitelisted, so modules can't access it via `process.binding` to reimplement `getOptionValue`.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like a way to be able use `getOptionValue`, and the most straightforward way I could think of is exposing it on `process` via `process.getOptionValue`.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nManually parse both `process.execArgv` and `process.env.NODE_OPTIONS`.\r\n",
        "labels": "feature request",
        "id": 42862
    },
    {
        "title": "Buffer.alloc does not accept BigInt data type for \"size\" argument",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.5.0\r\n* **Platform**: Windows\r\n* **Subsystem**: none\r\n\r\n### What steps will reproduce the bug?\r\n\r\nPlease add support for BigInt data type to Buffer.alloc method.  The first argument of that method is for buffer size and it takes an integer, but only supports *number* data types.  BigInt value throws an error.\r\n\r\nhttps://nodejs.org/dist/latest-v15.x/docs/api/buffer.html#buffer_static_method_buffer_alloc_size_fill_encoding\r\n",
        "labels": "feature request",
        "id": 42863
    },
    {
        "title": "Feature request: packaged applications (WARC archives?)",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nWe're distributing Yarn as a single-file script. While it's great for accessibility, it has an impact on the boot time since Node needs to parse the whole file before even starting to execute it. Additionally, the file is larger than it needs to be because various binary payloads have to be encoded as base64.\r\n\r\n**Describe the solution you'd like**\r\n\r\nWe'd like to eventually distribute Yarn as a packaged application. Imagine an archive with the source code, and we would call this archive like any other. For Node, the archive would be treated as a directory: `node ./yarn.warc/index.js`. Given that [WARC](http://iipc.github.io/warc-specifications/) is on its path to standardization, it seems the most consensual choice.\r\n\r\n**Prior work**\r\n\r\nYarn already provides in-zip filesystem access for the packages it installs. If Node is interested to use Zip instead of WARC we could provide our implementation, which closely follow Node's APIs.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nSupporting the [`__halt_compiler`](https://www.php.net/manual/en/function.halt-compiler.php) directive would be another way to delegate this responsibility to userland. It would likely be much easier to implement, and would allow for greater flexibility, and tbh I'd very much prefer this approach. Unfortunately, it may require work on the parser level, and I think that would bring it to v8, possibly TC39 lands. Given that the context is almost exclusively relevant to Node, I'm worried it wouldn't go anywhere.",
        "labels": "feature request",
        "id": 42864
    },
    {
        "title": "REQ: custom configurability of the node module resolution algorithm",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nIn the JavaScript ecosystem, there are many problems that could, in theory, be fixed with custom user-defined module resolution configuration.\r\n\r\n- **Aliasing a module**\r\n  When aliasing a module, you must tell *every tool* that you use how to find an aliased module. For example, to switch a project from React to Preact (a high-level, common use-case), you must configure **Webpack**, **Typescript** (or alternatives e.g. Flow) if you use types, **Webpack** (or alternatives e.g. Snowpack) you use for bundling how to find the module, *Eslint** (or alternatives) on how to find the new module so you don't get IDE errors.\r\n  This divide in the ecosystem makes aliasing as a whole, very unfriendly and prone to errors.\r\n\r\n- **Ecosystem unity**\r\n  When attempting to import a resource, every tool much agree on how to find it (as mentioned previously). If you use **svgr**, a library to turn SVG into React components (a high-level, relatively common problem), every tool must agree on how to import it. If you use **Typescript**, you must create `.d.ts` files so that correct intellisense and typing can be provided. If you use a bundler such as **webpack**, you must tell it to use a loader to transform the svg files so that they can be bundled.\r\n\r\n- **Better monorepo support**\r\n  Attempting to make monorepos in JS (i.e. multiple projects sharing code) requires immense amounts of effort, and is not at all comparable to the beautiful experience you get from languages such as Rust or C#. In my experience, getting monorepos to work require cooperation from the package manager (which Yarn thankfully supports) and cooperation from your tooling. In my specific usecase, I have my source code in a `src` directory with `package.json` outside of it. By utilizing symlinks to point to the directory containing the package.json, I had to add `/src` to my import path to get tooling such as Typescript and Webpack to recognize where the code was. Despite attempting to use export maps, [this is not supported](https://github.com/microsoft/TypeScript/issues/33079).\r\n\r\n- **Solving node_modules**\r\n  With the ability to override the module resolution algorithm, `node_modules` would no longer need to be a painpoint for developers.\r\n\r\n  In today's world, `node_modules` is a source of frustration for many developers. It is very IO heavy to setup, it wastes a lot of space for a developer, and it can get out of sync with dependencies listed in `package.json`. By allowing the module resolution algorithm to be configurable, it would allow massive improvements to the ecosystem as a whole, as individual solutions to the problem could be made to work with the module resolution algorithm, and thus with any and all infrastructure that support the new configurable module resolution algorithm.\r\n  \r\n  For example, [Yarn PnP](https://classic.yarnpkg.com/en/docs/pnp/) is a solution to the node_modules problem, but lacks the ecosystem-wide compatibility to take off. Projects such as **pnpm** aren't perfect solutions but it does tackle the flattening of node_modules by utilizing symlinks in a way that node, and other projects that *properly implement* the node module resolution algorithm can find the modules. However, this is not without its drawbacks, as existing infrastructure that *improperly implements* the node module resolution algorithm [will break if the modules are not as it expects](https://github.com/pnpm/pnpm/issues/1496).\r\n\r\n**Describe the solution you'd like**\r\nMy suggestion to this problem is to have a `.resolve.js` file inside of `node_modules` that will execute to resolve the path for a module, that yields a single export with a function that, given the current script path and module name to be found, will yield a promise to the path to another path that is resolvable. For example, consider the following structure:\r\n\r\n```\r\n/node_modules/is-number/index.js\r\n/node_modules/.resolve.js\r\n/index.js\r\n```\r\n\r\n```js\r\n// /node_modules/is-number/index.js\r\nmodule.exports = (num) => {\r\n\treturn typeof num === \"number\"; // simple implementation for this example\r\n}\r\n```\r\n\r\n```js\r\n// .resolve.js\r\nmodule.exports = async function(moduleName, scriptPath) {\r\n\treturn `./${moduleName}/`\r\n};\r\n```\r\n\r\n```js\r\nconst isNumber = require(\"is-number\");\r\n\r\nconsole.log(isNumber(1));\r\nconsole.log(isNumber(\"not a number\"));\r\n```\r\n\r\nRunning `node /index.js` would roughly lead to the following code being executed\r\n\r\n```\r\nrequire(\"is-number\");\r\n-> /node_modules/.resolve.js\r\n-> require(\"./is-number/\")\r\n-> -> require(\"./is-number/index.js\")\r\n```\r\n\r\nThis solution offers 100% customizability of the code being required.\r\n\r\n**Describe alternatives you've considered**\r\nIdeally, a solution that is easily statically analyzable and thus easily implementable in languages without requiring a NodeJS runtime would be most ideal. However, due to the possible unforeseen innovations that may be created and require custom functionality AND requirement of other vendors implementing the changes Node has (which [we cannot expect vendors to do](https://github.com/microsoft/TypeScript/issues/33079)), it would be the simplest and most ecosystem-wide compatible have a JS file that executes to automatically resolve the paths of modules.\r\n\r\nThe asynchronous nature of the require code is so that asynchronous calls can be made rather than synchornous ones (i.e. `fs.readFile` vs `fs.readFileSync`), but given that `require` is synchronous this may have to be altered.\r\n\r\nThe reasoning for `.resolve.js` to be inside `node_modules` is that it's a file that shouldn't be committed - rather, package manages such as `yarn` or `npm` could auto generate this file. Perhaps it might be better to include it next to `package.json` so it does get committed however, as the current tooling environment doesn't seem very co-existant and other projects would likely require their own boilerplate to be inserted.\r\n\r\nThe path to the current script being an argument to the function is suggested so that implementing custom node_modules algorithms can be context aware about the caller. The usecase in mind that this would be useful for, is proper versioning support of modules. Consider the following scenario, where a project looks as such:\r\n\r\n```\r\n/node_modules/is-number/7.0.0/index.js\r\n/node_modules/is-number/6.0.0/index.js\r\n/node_modules/depends-on-is-number-6/index.js\r\n/node_modules/.resolve.js\r\n/index.js\r\n```\r\n\r\nThe dependency `depends-on-is-number-6` could make a call to `require(\"is-number\")`, and `.resolve.js` could yield `./is-number/6.0.0/index.js` to NodeJS and thus maintain a flat `node_modules` structure. A more realistic example, would be a package manager that stores several versions of their packages in a cache, and redirecting imports to the correct location.\r\n\r\nOverall, there's ***a lot*** of remaining bike-shedding to be done since this is something especially important to get right for ecosystem unity, however it'd all be for naught if this idea is deemed unworthy.",
        "labels": "feature request",
        "id": 42865
    },
    {
        "title": "Provide an easy utility to issue a HTTP redirect + HTTP2 server push",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nHTTP2 server push is underutilized. I am realizing that it is hard to realize all the places where one could use it. One thing where I see it being useful almost always by default is to minimize the latency which happens after a HTTP redirect. HTTP redirect means that there is additional 2 hop latency before real data starts getting to the client. We can minimize that to 1 hop if at the same time as we issue a HTTP redirect, we also start pushing the HTTP response of the URI to which the HTTP redirect goes.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI suggest that `http.ServerResponse` gets additional method like `redirect` which sets relevant HTTP header in the response, but also that if the connection is HTTP2 connection, starts pushing the response (if the redirect target is local server).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThis could be implemented in a library, but I think having tighter support for HTTP2 in node core would be better to popularize it.",
        "labels": "feature request",
        "id": 42866
    },
    {
        "title": "WebAssembly compiled module cache",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nLarge WASM modules take a while to compile, impacting startup times. Browsers solve this problem by caching compiled module data.\r\n\r\nWebAssembly is a promising media for software distribution. It makes sense to compile for WebAssembly once, instead of shipping multiple binaries for each supported CPU architecture / OS pair, doesn't it? There's a growing number of tools targeting this particular segment, e.g. https://wasmer.io.\r\n\r\nNode.js has unique advantages as a WASM runner:\r\n\r\n * WASI as a standardised interface for interfacing with the OS (e.g. accessing files, etc.) is insufficient for most practical needs. With Node, one can leverage a plethora of high quality battle-tested cross platform libraries.\r\n\r\n * V8 is top notch! It beats competing WASM engines in terms of compile times, resource consumption and the footprint of compiled WASM files (a single data point: V8 produces 160MiB for a 50MiB WASM file, a competitor generates 1+GiB).\r\n\r\n * NPM is super robust. Competitors have their own package managers but not particularly reliable ones.\r\n\r\nThe only component missing in Node.js is a compiled module cache.\r\n\r\nIt takes 47s to compile the previously mentioned 50MiB WASM file. With a cache POC, the startup time is reduced to under 1s.\r\n\r\n**Describe the solution you'd like**\r\n\r\n```js\r\nrequire('wasm/cache').loadFile('module.wasm')\r\n```\r\n\r\nas a cache-enabled moral equivalent of\r\n\r\n```js\r\nWebAssembly.compile(require('fs').readFileSync('module.wasm'))\r\n```\r\n\r\nCache files to be stored in OS-mandated cache directory, e.g. `~/.cache/node/wasm-cache` on Linux.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIt used to be possible to serialise a WebAssembly module to a file explicitly. #18265\r\n\r\nIt stopped working since Node.js 13 due to changes in V8 and there's no way to make it work again.\r\n\r\nInstead of introducing a new API, it is possible to enhance `WebAssembly.compile`/`WebAssembly.compileStreaming`. Unfortunately, it's hard to come up with a good cache key. We could `sha256` the data, but that's inefficient.",
        "labels": "feature request",
        "id": 42867
    },
    {
        "title": "Flag to disable const enforcement",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThis sounds silly as I'm the biggest cheerleader for `const` but I do run into one situation.\r\n\r\nI like to do repl-driven-development where I have my code file along with a side-by-side repl that I can throw lines or regions to with a keystroke. Unfortunately, if the line in question uses `const`, this will fail since I'm trying to redeclare `const`.\r\n\r\n**Describe the solution you'd like**\r\nI would like to be able to add a flag to this nodejs session - perhaps `--loose-declarations` or `--const-and-let-as-var` and have `const` (and ideally `let`) work the same as `var`\r\n\r\n**Describe alternatives you've considered**\r\nAlternately, this could be set with an environment variable or simply be the default in repl sessions. It would be great to get it rolled into v8 and have it also work in devtools on web, but that's probably asking too much",
        "labels": "feature request",
        "id": 42868
    },
    {
        "title": "[FR] Support linking against dynamic runtime for library builds",
        "body": "I do not see a build option to instruct the compiler to build using dynamic runtime dll's (i.e. /MD).  It just defaults to static.  This makes it very difficult to integrate with projects that are configured for dynamic runtimes.  To clarify, I am using vcbuild.bat to launch configure.py",
        "labels": "feature request",
        "id": 42869
    },
    {
        "title": "doc: Expect nodejs doc site to have an api search feature.",
        "body": "",
        "labels": "feature request",
        "id": 42870
    },
    {
        "title": "fs.readSync & fs.read position argument does not support BigInt",
        "body": "* **Version**: v14.10.1\r\n* **Platform**: Linux edef72861714 4.14.152-127.182.amzn2.x86_64 #1 SMP Thu Nov 14 17:32:43 UTC 2019 x86_64 GNU/Linux\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nreadSync(reader, buffer, 0, 12, BigInt(position))           \r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEverytime.\r\n\r\n### What is the expected behavior?\r\n\r\nIt should read from the position in the file, and it will if you use `Number(position)` on a BigInt position.\r\n\r\n### What do you see instead?\r\n\r\nThe call reads data into the buffer but it begins at position 0 in the file instead of at the position noted in the BigInt.",
        "labels": "feature request",
        "id": 42871
    },
    {
        "title": "[FR] Simple standard IO processing (see also V8's `readline` and `print`)",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nHello, I'd like to suggest Node to adopt some sort of a simple way to process standard io.\r\n\r\nC has\r\n\r\n```c\r\n#include <stdio.h>\r\n\r\nint x;\r\nchar* s;\r\nscanf(\"%d %s\", &x, &s);\r\nprintf(\"%d %s\", x, s);\r\n```\r\n\r\nC++ has\r\n\r\n```cpp\r\n#include <iostream>\r\nusing namespace std;\r\n\r\nint x;\r\nstring s;\r\ncin >> x >> x;\r\ncout << x << \" \" << s;\r\n```\r\n\r\nand many more languages alike.\r\n\r\nThe point being -- it's fast and simple. Why would you need that? Well, there are cases where processing standard input (and output) should be as simple and as quick as possible -- simple one-off scripts and also competitive programming contests.\r\n\r\nFor example, the defacto competitive programming platform \"codeforces\" allows node as one of it's languages, and actually uses V8 to run the submitted solution under the hood ([example submission](https://codeforces.com/contest/1199/submission/58184695)).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nUsing V8 is better than the shenanigans you need to do with nodejs today;\r\n\r\nIt's simpler, but could still be improved:\r\n\r\n```js\r\nlet line = readline().split(\" \"); // must also assume that both inputs were on the same line, only separated by a single space :/  \r\nlet x = parseInt(line[0], 10);\r\nlet y = line[1];\r\nprint(x, y);\r\n```\r\n\r\nThis solution from V8 helps -- in a competitive programming setting, you avoid the need to write your solution twice -- once using node's `readline` utility way while debugging locally, and then rewriting it to work with V8's `readline` before submitting.\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe issue here is that V8 is not even closely as popular as node to the average user, and compiling it takes a lot.\r\n\r\nHaving the utility in node would be definitely provide better DX. And I think we don't necessarily need to have the same exact `readline` utility as V8 -- it'd be incompatible anyway, right?\r\n\r\nI was thinking about global utility function(s) to process IO the same way C/C++ and many other languages have -- read one thing until you see any amount of spaces (`\\s` `\\n` `\\t` etc.), ignore the spaces and if called again - read the next meaningful input. Additionally, having an automatic (type-inferred) or a manual yet simple way to parse the input's type (string / number etc.) would be amazing!\r\n\r\n",
        "labels": "feature request",
        "id": 42872
    },
    {
        "title": "POSIX fork and node ",
        "body": "Given https://chromium-review.googlesource.com/c/v8/v8/+/2416501 is soon to be merged we could start exploring native POSIX fork support for node (under some experimental flag - single threaded platform does come with some limitation) \r\n\r\nI was wondering if this is something the community is interested in. \r\n\r\nNote I maintain https://github.com/rubyjs/mini_racer where I very much need this feature, but I could imagine the node community may (or may not) also be interested in this feature.",
        "labels": "feature request",
        "id": 42873
    },
    {
        "title": "querystring.stringify does not support BigInt",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\n```js\r\n> querystring.stringify({a: 12345678901234567n})\r\n'a='\r\n```\r\n\r\nit should print `a=12345678901234567`\r\n\r\n**Describe the solution you'd like**\r\n\r\nsupport `bigint` in additional to `string`, `number` and `boolean`.\r\n\r\ni.e., in [`stringifyPrimitive`](https://github.com/nodejs/node/blob/39a7f7663e8f70fc774105d8fa41b8e4cc69149f/lib/querystring.js#L158-L166) encode any value where `typeof v  == 'bigint'` as `'' + v`, the same as `'number'`.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo.\r\n",
        "labels": "feature request",
        "id": 42874
    },
    {
        "title": "feature request: raw curves",
        "body": "See: https://github.com/nodejs/node/discussions/36000",
        "labels": "feature request",
        "id": 42875
    },
    {
        "title": "Allow specifying static libraries",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThere's no *problem*/blocker that this feature request would solve. Currently, there exists `configure` options that allow specifying paths to shared libraries for c-ares, openssl, and others.\r\n\r\nWith the `--fully-static` option, it would save compilation time to allow also allow specifying paths to pre-existing static libraries of dependencies, and also set appropriate include paths.\r\n\r\n**Describe the solution you'd like**\r\nPerhaps something more like how CMAKE works (I'm not a CMAKE fan myself, but they do handle this aspect well) where the `configure` script will search system-installed libraries for node's dependencies and apply the compilation options accordingly if it finds them.\r\n\r\nOtherwise, provide `configure` options like those given for other dependencies that allow specifying the path to the static libraries.\r\n\r\nWould this also require modifications to the include paths? Would it be safe to assume /usr/include works? I'm not sure how platform-dependent the `configure` script becomes at this point.\r\n\r\n**Describe alternatives you've considered**\r\nI had started digging into the individual `ninja` files I had generated post-`configure`. But there's just so many `ninja` targets and it is far too easy to miss specifying a static library while performing a link step or an include path for compiling amidst all these ninja files.\r\n",
        "labels": "feature request",
        "id": 42876
    },
    {
        "title": "Need access to uv_backend_fd on windows",
        "body": "In the context of [node-gtk](https://github.com/romgrk/node-gtk), I need acces to the `uv_backend_fd()` value. On the microsoft windows operating system, the current version of libuv doesn't return an appropriate value. The master branch of libuv however contains what is needed to retrieve the windows equivalent. What would it take to upgrade to the next version of libuv?\r\n\r\nRelevant discussions:\r\n - https://github.com/libuv/libuv/pull/1007\r\n - https://github.com/libuv/libuv/issues/1597\r\n - https://github.com/romgrk/node-gtk/issues/241",
        "labels": "feature request",
        "id": 42877
    },
    {
        "title": "A C++ API for near heap limit notification",
        "body": "For context see the twitter thread https://twitter.com/JoyeeCheung/status/1319346028076621825\r\n\r\nThis needs to be implemented by us because V8 replaces the callback if you add another one from C++, so the users may step on our toes since our timing of adding and removing these callbacks should be opaque to them. And this should be a C++ API because returning to JS execution in the callback (which is usually triggered during GC) is unsafe.",
        "labels": "feature request",
        "id": 42878
    },
    {
        "title": "fs: add cp method",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWhenever I need to copy a directory to another destiny, I need to use an alternative library to do this.\r\n\r\n**Describe the solution you'd like**\r\nAdd cp (Unix Name) method to fs, with the same utility of [cp Unix](https://en.wikipedia.org/wiki/Cp_(Unix)), he can be like:\r\n\r\n| Parameters                |\r\n|------------------------|\r\n| src: PathLike              |\r\n| dest: PathLike            | \r\n| options: CpOptions   | \r\n\r\n**Describe alternatives you've considered**\r\nLibrary [npc](https://github.com/AvianFlu/ncp) and [fs-extra](https://github.com/jprichardson/node-fs-extra).\r\n",
        "labels": "feature request",
        "id": 42879
    },
    {
        "title": "Enable Dark Mode for NodeJS docs",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nPlease enable dark mode for [node docs](https://nodejs.org/api/) like the [nodejs.dev](https://nodejs.dev/learn) website.\r\n\r\n",
        "labels": "feature request",
        "id": 42880
    },
    {
        "title": "Support for executing Node.js fs functions as sudo ",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nThe inability to execute Node.js `fs` functions with sudo (as admin) limits the applications built on Node.js. Nowadays, a lot of applications are built with Electron (which comes with Node.js), This feature would allow us to build more advanced apps with Node.js.\r\n\r\n**Describe the solution you'd like**\r\nExample;\r\n\r\n1. A function executed with option `asAdmin: true` requests the system password dialog:\r\n```\r\nfs.readdirSync('/media/sharedDrive/', { asAdmin: true, adminAccessTimeout: 15 * 1000 * 60 })\r\n```\r\n2. User enters their password\r\n3. On success, execute the function with admin rights.\r\n\r\n**Describe alternatives you've considered**\r\nN/A",
        "labels": "feature request",
        "id": 42881
    },
    {
        "title": "Provide getSource method that supports both es-module and commonjs",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI am developing a build tool similar to [vite](https://github.com/vitejs/vite). I need to obtain the source code of the module according to the requested module path or module name. If it is es-module, it will return directly, if it is commonjs, it will be converted to es-module through rollup and then returned.\r\n\r\nTherefore, I need a method that can resolve module source code on demand based on module path or module name. My assumption is as follows:\r\n\r\n##### 1ï¼ŒAdd the features of returning the source code in the import method\r\n```js\r\n// import lodash from \"lodash\"\r\nconst code = await import(\"lodash\").then(r=>r.code());\r\n\r\n// or:  import get from \"lodash/get\"\r\nconst code = await import(\"lodash/get\").then(r=>r.code());\r\n\r\n// or:  import { get } from \"lodash\"\r\nconst code = await import(\"lodash\").then(r=>r.get).then(r=>r.code());\r\n\r\n// or:  import * as _ from \"lodash\"\r\nconst code = await import(\"lodash\").then(r=>r.all()).then(r=>r.code());\r\n\r\n\r\n// and then\r\nif(!code.isEsModule()){\r\n   // rollup transform to es-module...\r\n}\r\n\r\n// cache code, no more need to transform for next time...\r\n\r\n```\r\n\r\n##### 2ï¼ŒProvide new methods to support this feature\r\n```js\r\nconst code = await getSource(\"lodash\");\r\n...\r\n// same as above\r\n```\r\nI noticed that in the latest document, node provides a similar getSource method to obtain module code, but it only supports es-module, and it is not yet mature.\r\n\r\nIf this feature is supported, a new build tool will soon appear on the front end, similar to [vite](https://github.com/vitejs/vite) and [snowpack](https://github.com/pikapkg/snowpack), and people will abandon the bulky and slow webpack.\r\n\r\nHope team can provide perfect support.\r\n\r\n",
        "labels": "feature request",
        "id": 42882
    },
    {
        "title": "Add a way to \"unhandle\" unhandledRejection",
        "body": "I've been making a little cancellation solution for some of my own code, and would like a mechanism to be able to abort functions by way of cancellation.\r\n\r\nI've been modeling it somewhat on `AbortController`/`AbortSignal`/`AbortError`, but I have a bit of a problem when it comes to the error part.\r\n\r\nIn particular, I would like to be able to define a `CancellationError`, which does not trigger unhandled rejection.\r\n\r\nIn the browser this is fairly simple enough as one can do:\r\n\r\n```js\r\nclass CancellationError {\r\n  // ...\r\n}\r\n\r\n// this ensures any cancelled promises that are discarded do not trigger an unhandledrejection\r\nwindow.addEventListener('unhandledrejection', (event) => {\r\n  if (event.reason instanceof CancellationError) {\r\n    event.preventDefault();\r\n    event.stopImmediatePropagation();\r\n  }\r\n});\r\n```\r\n\r\nHowever in Node, I'm not sure how to emulate this, as without a mechanism like `event.preventDefault()` we can't easily have a way to continue with the default behaviour if the reason is not a `CancellationError`.\r\n\r\nI'd like to propose adding some mechanism to continue with the default behaviour of the `unhandledRejection` event (or at least continue to the next listener). Perhaps something like:\r\n\r\n```js\r\nprocess.on('unhandledRejection', (reason, _promise, retrigger) => {\r\n  if (reason instanceof CancellationError) {\r\n    // If a CancellationError then we can simply throw away the promise\r\n    return;\r\n  }\r\n  retrigger(); // Otherwise continue with the default behaviour set by --unhandledRejections\r\n});\r\n```",
        "labels": "feature request",
        "id": 42883
    },
    {
        "title": "Allow to ensure a process will exit and warn for remaining async operations if any",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nWhen you write a complex node program, with a lot of lib & external service usage (databases...), you still want your process to exit cleanly.\r\nThe recommended way is of course to stop all async actions, active connection & socket listen and let the process stop\r\n```javascript\r\nasync onSignal() {\r\n    try {\r\n        await server.stop();\r\n        await database.stop();\r\n\r\n        console.log('All resources cleaned up, process should now exit');\r\n        // Process should now exit\r\n    } catch (e) {\r\n        // Undefined behaviour\r\n        console.error(e);\r\n        process.exit(1);\r\n    }\r\n}\r\n```\r\n\r\nSometimes, because of badly cleaned resources, the process won't exit at all. This could lead to service degradation, as the process won't restart until it's stopped, but is not responding to user requests anymore.\r\n\r\nIt might then be tempting to add a `process.exit()` at the end of the normal stop process. It would solve the service degradation issue, but also hides the underlying issue (service not cleaned up).\r\n\r\nIn my experience, those issues mostly happen in production, with resources not cleaned after database / upstream service reconnection due to network errors and long running processes. Those issues are not easily reproducible in a test environment.\r\n\r\n**Describe the solution you'd like**\r\nI would see 2 possible solutions:\r\n * Have a `process.ensureExit()` function, that would check for remaining async operations, warn if there is any, and exit anyway.\r\n * Have a `process.tryExit()` function, that would throw if a clean exit is not possible, letting the user handle this case (writing special logs, more clean-up attempts...)",
        "labels": "feature request",
        "id": 42884
    },
    {
        "title": "Update HTTP/2 server settings after `.listen()`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently it is possible to create an HTTP/2 in the following way:\r\n\r\n```js\r\nconst server = http2.createSecureServer({\r\n\tsettings: {\r\n\t\tmaxConcurrentStreams: 1000\r\n\t},\r\n\tkey,\r\n\tcert\r\n});\r\n```\r\n\r\nLet's assume you're having a server and it detected it's low on resources. Limiting `maxConcurrentStreams` could have a positive impact. Unfortunately it's not possible at the moment.\r\n\r\n**Describe the solution you'd like**\r\n\r\n```js\r\nserver.updateSettings({\r\n\tmaxConcurrentStreams: 100\r\n});\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNone yet.\r\n",
        "labels": "feature request",
        "id": 42885
    },
    {
        "title": "Enable building with shared uvwasi library.",
        "body": "Nodejs depends on uvwasi, libuv, brotli.  It can be build to use the shared-libraries for libuv, ICU, brotli, c-ares.\r\n\r\n* Enable building with shared uvwasi library.",
        "labels": "feature request",
        "id": 42886
    },
    {
        "title": "Feature Request: sync and async zlib.* instances without streams",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI have a need to inflate/deflate chunks of data and get the result immediately/easily. The streaming interface makes this a bit cumbersome and has caused issues in the past (e.g. the changing of flushing behavior with multiple writes within a major node version).\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe solution I'd like would essentially be a hybrid between `zlib.Deflate`/`zlib.Inflate`/etc. and the one-off `zlib.*` functions. It would be like the `zlib.Deflate`/`zlib.Inflate` instances in that it would keep a zlib context around for reuse, but like the one-off functions in that it would only be used to process a single chunk. You could almost put this feature inside the one-off functions and just allow them to accept a pre-created zlib context (another API would need to be added to do this too).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI'm currently having to use the streaming interface which is less than ideal to say the least and is more prone to regressions because of the additional machinery (streams) involved. However I really do not want to have to maintain this extra complexity.\r\n\r\nI've also considered just writing some binding code to do what I want, but I'd rather not have to force end users to have to compile to be able to use compression in my project, especially for something that should be easily achievable in node.",
        "labels": "feature request",
        "id": 42887
    },
    {
        "title": "Feature request: ChildProcess 'spawn' event",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nAfter calling `child_process.spawn`, I'd like to know when the child process has successfully spawned and there's no longer the possibility of an 'error' event from failing to spawn (i.e. error type # 1 in [the docs for that 'error' event](https://nodejs.org/api/child_process.html#child_process_event_error), e.g. `EPERM`, `ENOENT`).\r\n\r\nCurrently I just wait 100 milliseconds (after calling `child_process.spawn`), and if the child process hasn't emitted an 'error' event by that time, I assume it spawned successfully. My code looks something like this:\r\n\r\n```js\r\nconst { spawn } = require('child_process');\r\nconst { promisify } = require('util');\r\nconst { once } = require('events');\r\nconst timeout = promisify(setTimeout);\r\n\r\nasync function doSomethingWithChildProcess(){\r\n  const subprocess = spawn(...spawnArgs));\r\n  await Promise.race([\r\n    timeout(100),\r\n    once(subprocess, 'error').then(([error]) => Promise.reject(error))\r\n  ]);\r\n  // now do something with the running child process...\r\n}\r\n```\r\n\r\nThis seems to work, but I'm not sure how reliable it is, and anyways, it is certainly a hack. \r\nI'm wondering if there could be a better (more correct) way..\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nIs there some point of execution in Node where we know there was no error spawning the child process?\r\n\r\nIf so, we could introduce a new 'spawn' event for the [ChildProcess class](https://nodejs.org/api/child_process.html#child_process_class_childprocess), to be emitted at that point in execution?\r\n\r\nThat would remove the need for the unreliable hack I described above.\r\n\r\nIt would also work nicely with Node.js's [`events.once` function](https://nodejs.org/api/events.html#events_events_once_emitter_name). For example, the code from above could be updated like this:\r\n\r\n```diff\r\n const { spawn } = require('child_process');\r\n-const { promisify } = require('util');\r\n const { once } = require('events');\r\n-const timeout = promisify(setTimeout);\r\n\r\n async function doSomethingWithChildProcess(){\r\n   const subprocess = spawn(...spawnArgs);\r\n-  await Promise.race([\r\n-    timeout(100),\r\n-    once(subprocess, 'error').then(([error]) => Promise.reject(error))\r\n-  ]);\r\n+  await once(subprocess, 'spawn');\r\n   // now do something with the running child process...\r\n }\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nJust the hack I described above (of expecting any error spawning to happen within 100 milliseconds of calling `child_process.spawn`).\r\n\r\nI can't think of any other possible solutions at this time.",
        "labels": "feature request",
        "id": 42888
    },
    {
        "title": "module: improve error decoration for cjs named exports for multi-line import statements",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.11.0\r\n* **Platform**: Darwin *** 19.6.0 Darwin Kernel Version 19.6.0: Thu Jun 18 20:49:00 PDT 2020; root:xnu-6153.141.1~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: modules\r\n\r\n### What steps will reproduce the bug?\r\n\r\nFailing test can be found here: https://github.com/ctavan/node/commit/ba9e73414eb5181873332da917defc25d1034afa\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n\r\nWhen trying to import named exports from a CommonJS module, there's usually a helpful error message which is assembled here: https://github.com/nodejs/node/blob/ed8af4e93831d3cf21d5562e900371d796b5fa20/lib/internal/modules/esm/module_job.js#L102-L124\r\n\r\n### What do you see instead?\r\n\r\nWhen using multi-line import statements like:\r\n\r\n```js\r\nimport {\r\n  comeOn,\r\n  rightNow,\r\n} from './fail.cjs';\r\n```\r\n\r\nthe following regex does not match:\r\n\r\nhttps://github.com/nodejs/node/blob/ed8af4e93831d3cf21d5562e900371d796b5fa20/lib/internal/modules/esm/module_job.js#L112\r\n\r\nand the following error is produced:\r\n\r\n```\r\nTypeError: Cannot read property '0' of null\r\n      at ModuleJob._instantiate (internal/modules/esm/module_job.js:112:77)\r\n      at async ModuleJob.run (internal/modules/esm/module_job.js:137:5)\r\n      at async Loader.import (internal/modules/esm/loader.js:165:24)\r\n      at async rejects.name (file:///***/node/test/es-module/test-esm-cjs-named-error.mjs:56:3)\r\n      at async waitForActual (assert.js:721:5)\r\n      at async rejects (assert.js:830:25),\r\n```\r\n\r\n### Additional information\r\n\r\nI would love to contribute a fix for this issue, however I need some guidance on how to proceed. The problem I see is that the full error stack only contains the first line of the multi-line import statement:\r\n\r\n```js\r\n[\r\n  'file:///***/node/test/fixtures/es-modules/package-cjs-named-error/multi-line.mjs:2',\r\n  '  comeOn,',\r\n  '  ^^^^^^',\r\n  \"SyntaxError: The requested module './fail.cjs' does not provide an export named 'comeOn'\",\r\n  '    at ModuleJob._instantiate (internal/modules/esm/module_job.js:98:21)',\r\n  '    at async ModuleJob.run (internal/modules/esm/module_job.js:141:5)',\r\n  '    at async Loader.import (internal/modules/esm/loader.js:165:24)',\r\n  '    at async rejects.name (file:///***/node/test/es-module/test-esm-cjs-named-error.mjs:56:3)',\r\n  '    at async waitForActual (assert.js:721:5)',\r\n  '    at async rejects (assert.js:830:25)'\r\n]\r\n```\r\n\r\nSo while the goal of the additional error decoration which was added in #33256 seems to be to provide a copy & pastable solution, I don't see how this could be achieved with the error information at hand when the error comes from a multi-line import statement.\r\n\r\nOptions that come to my mind:\r\n- Just resort to the original error?\r\n- Skip the example if it cannot be generated from the error stack, see: https://github.com/ctavan/node/commit/248eadadaf218088624f4c237a29befcc9dae66c\r\n- Produce something like the following, even though it's incomplete:\r\n    ```js\r\n      import pkg from './fail.cjs';\r\n      const { comeOn } = pkg;\r\n    ```\r\n- Produce the correct example, which would probably involve using an actual parser to read the full failing import statement.\r\n\r\n/cc @MylesBorins",
        "labels": "feature request",
        "id": 42889
    },
    {
        "title": "createReadStream/createWriteStream should support FileHandle",
        "body": "Currently only raw file descriptors are supported. Should we allow for a `FileHandle` to be passed as `fd`?",
        "labels": "feature request",
        "id": 42890
    },
    {
        "title": "better esm interop without package.json",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nThe problem is that many ESM codebases do use .js endings and no additional package.json inside the ESM build this makes them out of the box not useable via npm install \r\n\r\n**Describe the solution you'd like**\r\nSimply try to use ESM by Default and only if that fails try to require. stop warning like this should be commonjs module'\r\n\r\n\r\n**Describe alternatives you've considered**\r\nA good alternate would be to allow import myStuff from 'mypackage/file.js#!esm' in the url of the module to simply indicate that we want to load it as ESM\r\n\r\n\r\nAt present you can not run much esm code inside nodejs.",
        "labels": "feature request",
        "id": 42891
    },
    {
        "title": "add convenience-event \"readall\" to emit entire responseText from http.IncomingMessage",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\ni want to simplify parsing short text/json messages from http-requests w/o chunk-parsing boilerplate (precedent in browser-env: `XMLHttpRequest.responseText` and `await fetch(<url>).json()`\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\nhere is a working polyfill to patch `http.IncomingMessage.prototype.addListener` with `readall` event:\r\n\r\n```javascript\r\n\"use strict\";\r\n// readall-polyfill\r\n(function readallPolyfill() {\r\n    let addListenerNew;\r\n    let addListenerOld;\r\n    let http;\r\n    http = require(\"http\");\r\n    addListenerOld = http.IncomingMessage.prototype.addListener;\r\n    addListenerNew = function (...argList) {\r\n    /*\r\n     * this function will extend addListener with new readall-evt\r\n     * example: response.on(\"readall\", function (responseText) {...});\r\n     */\r\n        let callback;\r\n        let chunkList;\r\n        let evt;\r\n        let isText;\r\n        [\r\n            evt, callback\r\n        ] = argList;\r\n        // default-handling\r\n        if (evt !== \"readall\") {\r\n            return addListenerOld.apply(this, argList);\r\n        }\r\n        // handle text-encoding\r\n        isText = this._readableState.decoder;\r\n        // handle readall-evt\r\n        chunkList = (\r\n            isText\r\n            ? \"\"\r\n            : []\r\n        );\r\n        this.on(\"data\", function (chunk) {\r\n            if (isText) {\r\n                chunkList += chunk;\r\n            } else {\r\n                chunkList.push(chunk);\r\n            }\r\n        });\r\n        this.on(\"end\", function () {\r\n            callback(\r\n                isText\r\n                ? chunkList\r\n                : Buffer.concat(chunkList)\r\n            );\r\n        });\r\n    };\r\n    http.IncomingMessage.prototype.addListener = addListenerNew;\r\n    http.IncomingMessage.prototype.on = addListenerNew;\r\n}());\r\n\r\n// test with setEncoding()\r\nrequire(\"https\").request(\"https://www.example.com\", function (res) {\r\n    res.setEncoding(\"utf8\");\r\n    res.on(\"readall\", function (responseText) {\r\n        console.log(\r\n            responseText.slice(0, 10)\r\n        );\r\n        // stdout - \"<!doctype \"\r\n    })\r\n}).end()\r\n\r\n// test with JSON.parse\r\nrequire(\"https\").request(\"https://registry.npmjs.org/\", function (res) {\r\n    res.on(\"readall\", function (responseRaw) {\r\n        let responseJson;\r\n        responseJson = JSON.parse(responseRaw);\r\n        console.log({\r\n            db_name: responseJson.db_name,\r\n            doc_count: responseJson.doc_count\r\n        });\r\n        // stdout - \"{ db_name: 'registry', doc_count: 1802108 }\"\r\n    })\r\n}).end()\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\nhere is above test-code using vanilla nodejs, where i have to deal with chunk-parsing boilerplate\r\n```javascript\r\n\"use strict\";\r\n\r\n// test with setEncoding() with chunk-parsing boilerplate\r\nrequire(\"https\").request(\"https://www.example.com\", function (res) {\r\n    res.setEncoding(\"utf8\");\r\n\r\n    // chunk-parsing boilerplate - start\r\n    let responseText;\r\n    responseText = \"\";\r\n    res.on(\"data\", function (chunk) {\r\n        responseText += chunk;\r\n    });\r\n    // chunk-parsing boilerplate - end\r\n\r\n    res.on(\"end\", function () {\r\n        console.log(\r\n            responseText.slice(0, 10)\r\n        );\r\n        // stdout - \"<!doctype \"\r\n    })\r\n}).end()\r\n\r\n// test with JSON.parse with chunk-parsing boilerplate\r\nrequire(\"https\").request(\"https://registry.npmjs.org/\", function (res) {\r\n\r\n    // chunk-parsing boilerplate - start\r\n    let responseRaw;\r\n    responseRaw = [];\r\n    res.on(\"data\", function (chunk) {\r\n        responseRaw.push(chunk);\r\n    });\r\n    // chunk-parsing boilerplate - end\r\n\r\n    res.on(\"end\", function () {\r\n        let responseJson;\r\n        responseJson = JSON.parse(Buffer.concat(responseRaw));\r\n        console.log({\r\n            db_name: responseJson.db_name,\r\n            doc_count: responseJson.doc_count\r\n        });\r\n        // stdout - \"{ db_name: 'registry', doc_count: 1802108 }\"\r\n    })\r\n}).end()\r\n```\r\n",
        "labels": "feature request",
        "id": 42892
    },
    {
        "title": "child_process.execSync should return object with std of plain stdout",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI wanted to run sequentially a series of processes and check their exit code and stderr to make a decision whether the run command failed or not. In my case exit code=0 and anything in stderr having `warning` substring should be considered as fail.\r\n\r\nWhen I needed to run just one command I happily used the following code:\r\n```js\r\nchildProcess.exec(command, (err, stdout, stderr) => {\r\n    if (err || (stderr && stderr.toLowerCase().includes('warning'))) {\r\n        console.error('Failed due to:');\r\n        console.error(stderr);\r\n        process.exit(1);\r\n    }\r\n\r\n    console.log('OK\\n');\r\n    process.exit(0);\r\n});\r\n```\r\nWhen the task changed and I needed to run few commands in a row I decided to use synchronous version of that method:\r\n```js\r\n    try {\r\n        const stdout = childProcess.execSync(command, { encoding: 'utf8' }); // can't get stderr\r\n    } catch (err) {\r\n        const { status, stderr } = err;\r\n        if (status > 0 || (stderr && stderr.toLowerCase().includes('warning'))) {\r\n            console.error('Failed due to:');\r\n            console.error(stderr);\r\n            process.exit(1);\r\n        }\r\n    }\r\n\r\n    console.log('OK');\r\n```\r\nHowever using that code I can't check stderr when no exception is thrown.\r\n\r\n**Describe the solution you'd like**\r\nI'd like `childProcess.execSync` to return an object containing `status`/`code`, `stderr`, `stdout` and other fields similar to returned object in `child_process.spawnSync` (https://nodejs.org/api/child_process.html#child_process_child_process_spawnsync_command_args_options): \r\n```\r\n* pid <number> Pid of the child process.\r\n* output <Array> Array of results from stdio output.\r\n* stdout <Buffer> | <string> The contents of output[1].\r\n* stderr <Buffer> | <string> The contents of output[2].\r\n* status <number> | <null> The exit code of the subprocess, or null if the subprocess terminated due to a signal.\r\n* signal <string> | <null> The signal used to kill the subprocess, or null if the subprocess did not terminate due to a signal.\r\n* error <Error> The error object if the child process failed or timed out.\r\n``` \r\n\r\n**Describe alternatives you've considered**\r\nAlternatives:\r\n1) Use asynchronous version (`childProcess.exec`) and rewrite the code to work in asynchronous manner\r\n2) Use `childProcess.spawnSync` with `shell=true`\r\n",
        "labels": "feature request",
        "id": 42893
    },
    {
        "title": "--require doesn't work with import",
        "body": "* **Version**: 12.18.3\r\n* **Platform**: macOS 10.15.6\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\nRun `node` with `--require` and `--experimental-specifier-resolution=node`\r\n\r\nAn example can be found [here](https://github.com/daveisfera/test_import_preload) when running `npm test`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways\r\n\r\n### What is the expected behavior?\r\nThere's a way to preload a file using `import` rather than `require`\r\n\r\n### What do you see instead?\r\n```\r\ninternal/modules/cjs/loader.js:1154\r\n      throw new ERR_REQUIRE_ESM(filename, parentPath, packageJsonPath);\r\n      ^\r\n\r\nError [ERR_REQUIRE_ESM]: Must use import to load ES Module: /Users/dlj/projects/test_import_preload/preload.js\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1154:13)\r\n    at Module.load (internal/modules/cjs/loader.js:986:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:879:14)\r\n    at Module.require (internal/modules/cjs/loader.js:1026:19)\r\n    at Module._preloadModules (internal/modules/cjs/loader.js:1278:12)\r\n    at loadPreloadModules (internal/bootstrap/pre_execution.js:439:5)\r\n    at prepareMainThreadExecution (internal/bootstrap/pre_execution.js:71:3)\r\n    at internal/main/run_main_module.js:7:1 {\r\n  code: 'ERR_REQUIRE_ESM'\r\n}\r\nnpm ERR! Test failed.  See above for more details.\r\n```\r\n\r\n### Additional information\r\nIt would be nice if there was a `--import` or if `--require` worked with `import`s",
        "labels": "feature request",
        "id": 42894
    },
    {
        "title": "Implement Promise.any",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nGetting the first promise to fulfill.\r\n\r\n**Describe the solution you'd like**\r\n\r\n[Promise.any](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/any) should be implemented.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n[p-any](https://github.com/sindresorhus/p-any) does something similar but is not spec-compliant.\r\n\r\n**Dependent features**\r\n\r\n- [Implement `AggregateError`](https://github.com/nodejs/node/issues/35044)\r\n",
        "labels": "feature request",
        "id": 42895
    },
    {
        "title": "Implement AggregateError",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nAggregating multiple errors into one.\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe [AggregateError](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/AggregateError) subclass should be implemented. This is an important stepping stone for also implementing [Promise.any](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/any) which uses this.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n[aggregate-error](https://github.com/sindresorhus/aggregate-error) does something similar but is not spec-compliant.\r\n",
        "labels": "feature request",
        "id": 42896
    },
    {
        "title": "node --help command too much text in description",
        "body": "for this command `node --help`...\r\nis there anyone can update it like `deno` or `go` one?\r\nbecause `node --help` now like a bit messy and there is a lot of text there\r\n\r\nthanks!\r\n",
        "labels": "feature request",
        "id": 42897
    },
    {
        "title": "WASI as a build platform",
        "body": "I think it is possible because current macOS support is via LLVM toolchain that could target webassembly and WASI (but I have no idea about the process).\r\n\r\nBenefits:\r\n* Custom hardware that can run webassembly will be able to use nodejs without official support (mobiles, embedded devices, ...)\r\n* Use nodejs (and couple of server side only packages) in browser.\r\n* Use in future [wasm-container](https://adlrocha.substack.com/p/adlrocha-can-wasm-become-the-new)\r\n* And almost any benefit wasm and WASI have for the server side\r\n",
        "labels": "feature request",
        "id": 42898
    },
    {
        "title": "Built-in low-cost async to sync method",
        "body": "reduce unstable conditions caused by such hacking\r\nhttps://npm.im/deasync\r\n\r\n```js\r\nimport { deasync, depromise } from \"util\";\r\n\r\nconst sleepWithSync = deasync((timeout, done) => { setTimeout(done, timeout) });\r\nconst promiseWithSync = depromise(async (input) => input)\r\n\r\nsleepWithSync(1000)\r\npromiseWithSync(1) == 1\r\n// sync done\r\n```",
        "labels": "feature request",
        "id": 42899
    },
    {
        "title": "Add conditions to require.resolve options",
        "body": "There is PR was implemented to support custom user `--conditions`\r\nhttps://github.com/nodejs/node/pull/34637\r\n\r\nI wonder why not add this param to `require.resolve` `options`, which now contains only `paths`, this would allow using require in some custom resolution scenarios, where it is not possible to use cli flag.\r\n\r\nBut also probably it should not fully mimic `--conditions` which still puts leaves `require` and `node` conditions preferable, but this option should allow overriding the full list of the used condition while resolution.\r\n\r\n@guybedford ",
        "labels": "feature request",
        "id": 42900
    },
    {
        "title": "Request new HTTPS error message on incomplete credentials",
        "body": "I am requesting additional error messaging.\r\n\r\nAn HTTPS server requires credentials.  See the documentation for `https.createServer`: https://nodejs.org/dist/latest-v14.x/docs/api/https.html#https_https_createserver_options_requestlistener\r\n\r\n```javascript\r\n// curl -k https://localhost:8000/\r\nconst https = require('https');\r\nconst fs = require('fs');\r\n\r\nconst options = {\r\n  key: fs.readFileSync('test/fixtures/keys/agent2-key.pem'),\r\n  cert: fs.readFileSync('test/fixtures/keys/agent2-cert.pem')\r\n};\r\n\r\nhttps.createServer(options, (req, res) => {\r\n  res.writeHead(200);\r\n  res.end('hello world\\n');\r\n}).listen(8000);\r\n```\r\n\r\nIn the case of this code example from the documentation the credentials are passed in as the `options` object and the minimally required keys are `key` and `cert`.\r\n\r\n**Could there be error messaging if the options object contains either `key` assigned to a PEM formatted string or `cert` assigned to a PEM formatted string but not both?**  The assumption is that a user would supply options that contain both of those keys with complete values or neither of those object keys due to an alternate format of credential.\r\n\r\nAt present incomplete credentials does not halt Node from launching the HTTPS server, but no remote agent will respect that server.  Any connection to that server will be broken with a protocol mismatch error on the remote end.  The server is completely broken without any indication from the server side and with only incomplete messaging on the remote end.",
        "labels": "feature request",
        "id": 42901
    },
    {
        "title": "Pipeline error causing stream",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\nCurrently, there is no way to determine which stream in the pipeline function raised an error. In many cases, it would be helpful for the user, because they would get more insight as to what caused the error.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n[PR 34](https://github.com/mafintosh/pump/pull/34) of the pump module was able to implement this.\r\n",
        "labels": "feature request",
        "id": 42902
    },
    {
        "title": "Built-in method to escape shell arguments",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nYes, I was using `execa` which is a light wrapper for `childProcess.spawn` to execute a script (call it `./scripts/configure`) which took user input as an argument. One of my users supplied `\"Users & Permissions Management\"` as that input, which caused the script to hang as the resulting spawned process was: \r\n\r\n```\r\n./scripts/configure Users & Permissions Management\r\n```\r\n\r\nI realised as soon as the bug was reported that I should've escaped the string passed into my function that called `execa`, so then I looked for modules to correctly escape shell arguments, and they seem pretty complex. Which leads to the question: do I really want to depend on a third-party module to correctly escape shell arguments? Am I just trading one security risk for another?\r\n\r\n**Describe the solution you'd like**\r\n\r\nHave a method like `childProcess.escapeArgument(arg: string): string` which correctly escapes the given value such that it is just a string for all terminals (cross-platform).\r\n\r\n**Clarification:** I am not arguing for childProcess.spawn to escape arguments into strings by default, as that'd be a breaking change, even though it would likely be for the best (if you wanna pass multiple arguments, use the array syntax, not a string). Instead, I'm just asking for a method built-in that's well tested to escape an argument into a string argument for a shell command. \r\n\r\n**Describe alternatives you've considered**\r\n\r\n[Various NPM modules](https://github.com/nodejs/node/issues/34840#issuecomment-676398171), writing it myself, etc. All just shift the security responsibility to arguably worse places. This seems like due to the security benefits it can give, it'd be a good candidate for being a built-in function, ideally backported to LTS's\r\n",
        "labels": "feature request",
        "id": 42903
    },
    {
        "title": "Reduce the memory consumption of each Worker Thread",
        "body": "Hi,\r\n-- Please describe the problem you are trying to solve.\r\nWe are building a Node.js based _on-premise_ application that needs to run in a memory restricted environment. The application uses its own implementation of worker threads because it was developed before the addition of worker threads to Node.js. We are looking to migrate our implementation which is becoming harder and harder to maintain (syncing our code  with the Node.js versions) to the built in implementation. Our application starts numerous worker threads therefore the memory utilization per one worker thread is critical. In our implementation of worker threads we emphasized the reduction of memory consumption but payed in the fact that our worker thread could not access the Node.js standard APIs. Furthermore, our implementation is somewhat tailored to our use-case and lacks the flexibility of the standard implementation (e.g. we will not be able to use \"import\" and we have our own implementation of \"require\").  \r\n\r\nI have migrated all of the relevant code to use the native worker threads but now each worker thread utilizes almost 3 times more memory than in our implementation. I must add that the general structure of our implementation is not dissimilar to the native one and it uses a libuv event loop and v8 Isolates separation in a similar fashion.\r\n\r\nI ran some tests with an empty worker thread starting up every 10 seconds (i.e. new worker thread that does nothing infinitely starts every 10 seconds) and here are the results of the memory utilization of that process:\r\n\r\n![New worker thread every 10 seconds](https://user-images.githubusercontent.com/1912858/90477513-301d5880-e134-11ea-9b67-a66fedfa8cf4.png)\r\nTest was run with Node.js 12.8.3 on a Windows 10 machine.\r\n\r\nAs you can see a Node.js process without any worker threads running takes ~11mb and starting a worker thread utilizes almost as much memory as the full process.\r\n\r\n-- Please describe the desired behavior.\r\nWe would like to reduce the utilization of the memory per worker thread. Any reduction would be greatly appreciated.  I did some investigation as to what exactly causing each worker thread to use as much memory as the entire process but did not reach any conclusive results (I am not an expert in this area and unfortunately the person who implemented our worker threads variant has left the company). I suspect that each worker thread loads all of Node.js native library separately into its memory which could explain why each worker thread has the same memory usage as the entire process (i.e. the main thread). Maybe there is some way to use the same native (C code) across all worker threads to save on memory consumption (again, I am not an expert in C programming so I might be writing nonsense here).\r\n\r\n-- Please describe alternative solutions or features you have considered.\r\nCurrently our only alternative is to stay with our implementation.\r\n\r\nThank you.",
        "labels": "feature request",
        "id": 42904
    },
    {
        "title": "DNS resolution over specific interface",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nOn a system with multiple network interfaces, I would like to make DNS resolution requests over a specific interface.\r\n\r\nI have a problem similar to #14617.  Consider a Linux server with 2 interfaces, primary `eth0` and a backup internet connection using a LTE modem on `eth1`.  The system's default route is over `eth0`, and in normal operation all traffic goes over that interface.\r\n\r\nIf the primary connection is unavailable, I want to be able to make certain requests from my node program over the backup connection.  However, the backup connection is metered, so I don't want a systemwide failover; only specific, high-priority requests should go over the backup.\r\n\r\nWith the [appropriate alternate IP routing table and rules configured](https://serverfault.com/a/1032226/48050), this works for TCP sockets if you set [`localAddress` when calling `connect(opts)`](https://nodejs.org/api/net.html#net_socket_connect_options_connectlistener) and already know the destination address.  However, I need a way to resolve DNS over the backup connection if necessary â€” and separately from the system's default resolv.conf settings.\r\n\r\n**Describe the solution you'd like**\r\nThis could be accomplished similarly to the `localAddress` option available to TCP sockets.  (There's also `bind(port, address)` available to UDP sockets.)\r\n\r\neg:\r\n\r\n```js\r\nconst dns = require('dns');\r\nconst resolver = new dns.Resolver({ localAddress: '192.168.0.x' });\r\nresolver.setServers(['8.8.8.8']);\r\nresolver.resolve4(â€¦);\r\n```\r\n\r\nI *think* this would be as simple as calling [`ares_set_local_ip4`](https://manpages.debian.org/testing/libc-ares-dev/ares_set_local_ip4.3.en.html)/[`ares_set_local_ip6`](https://manpages.debian.org/testing/libc-ares-dev/ares_set_local_ip6.3.en.html) somewhere in [cares_wrap.cc](https://github.com/nodejs/node/blob/master/src/cares_wrap.cc).",
        "labels": "feature request",
        "id": 42905
    },
    {
        "title": "Absolute Windows paths are handled as invalid URL path in ESM import()",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.8v0\r\n* **Platform**: Windows\r\n* **Subsystem**:\r\n\r\nRelated: https://github.com/nodejs/node/issues/31710\r\n\r\n### What steps will reproduce the bug?\r\n\r\nWindows paths are interpreted as invalid file URL. In Linux and Mac, the issue can't be reproduced.\r\n\r\nFail\r\n```js\r\nawait import(\"D:\\repositories\\fastify-autoload\\routes\\hello.mjs\")\r\n```\r\n\r\nWorks\r\n```js\r\nawait import(url.pathToFileURL(\"D:\\repositories\\fastify-autoload\\routes\\hello.mjs\").href)\r\n```\r\n\r\n## Root cause\r\n\r\nhttps://github.com/nodejs/node/issues/31710#issuecomment-587211387\r\n\r\n### What is the expected behavior?\r\n\r\nInterpret windows paths as valid URL paths so we can provide consistent cross-platform behaviour.\r\n\r\n### What do you see instead?\r\n\r\n```\r\nError [ERR_UNSUPPORTED_ESM_URL_SCHEME]: Only file and data URLs are supported by the default ESM loader\r\n    at Loader.defaultResolve [as _resolve] (internal/modules/esm/resolve.js:698:11)\r\n    at Loader.resolve (internal/modules/esm/loader.js:82:40)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:226:28)\r\n    at Loader.import (internal/modules/esm/loader.js:161:28)\r\n    at importModuleDynamically (internal/modules/cjs/loader.js:1144:27)\r\n    at exports.importModuleDynamicallyCallback (internal/process/esm_loader.js:27:14)\r\n    at loadPlugin (D:\\repositories\\fastify-autoload\\index.js:118:5)\r\n    at D:\\repositories\\fastify-autoload\\index.js:28:12\r\n    at Array.map (<anonymous>)\r\n    at fastifyAutoload (D:\\repositories\\fastify-autoload\\index.js:27:29) {\r\n  code: 'ERR_UNSUPPORTED_ESM_URL_SCHEME'\r\n}\r\n```\r\n\r\n@mcollina ",
        "labels": "feature request",
        "id": 42906
    },
    {
        "title": "fix system, i imported crypto package and the nodejs replaced it",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n![image](https://user-images.githubusercontent.com/69520693/89941329-89acf100-dc23-11ea-9af5-9952a63aaf12.png)\r\npls just make it not replace the actual good package\r\n`else if (command === `say` && AImodule) {\r\n\t\t\t\t\tsetTimeout(function() {\r\n\t\t\t\t\t\tmykey = crypto.createCipher('aes-128-cbc', 'mypassword');\r\n\t\t\t\t\t\tmystr = mykey.update(onearg, 'utf8', 'dec')\r\n\t\t\t\t\t\tmystr += mykey.final('dec');\r\n\t\t\t\t\t\tmystr1 = mystr.slice(0, (Math.round(mystr.length / 3)));\r\n\t\t\t\t\t\tmystr2 = mystr.slice((Math.round(mystr.length / 3)), (Math.round(mystr.length / 3 * 2)));\r\n\t\t\t\t\t\tmystr3 = mystr.slice((Math.round(mystr.length / 3 * 2)), mystr.length);\r\n\t\t\t\t\t\twhile (mystr1 > 1) {\r\n\t\t\t\t\t\t\tmystr1 = mystr1 / 10\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\twhile (mystr2 > 1) {\r\n\t\t\t\t\t\t\tmystr2 = mystr2 / 10\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\twhile (mystr3 > 1) {\r\n\t\t\t\t\t\t\tmystr3 = mystr3 / 10\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tmykey = crypto.createDecipher('aes-128-cbc', 'mypassword');\r\n\t\t\t\t\t\tmystr = mykey.update(inputAI(mystr1,mystr2,mystr3), 'dec', 'utf8')\r\n\t\t\t\t\t\tmystr += mykey.final('utf8');\r\n\t\t\t\t\t\tchannel.send(`Message:\\`\\`\\`mystr\\`\\`\\``);\r\n\t\t\t\t\t}, 0);\r\n\t\t\t\t}`\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nmy bot won't work, it is supposed to work based a neural network and i am using the crypto command since i didn't find anything else to fully convert a string to decimal\r\n\r\n**Describe the solution you'd like**\r\nto work properly as the crypto package so nobody needs to update, will work properly only if the crypto package is imported with a -l as legacy\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n",
        "labels": "feature request",
        "id": 42907
    },
    {
        "title": "A new event to the process. The log event",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nA way to check when something is logged to stdout\r\n\r\n**Describe the solution you'd like**\r\n\r\nWhenever something is written to process.stdout, the log event is emitted with whatever is written into stdout.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nN/A",
        "labels": "feature request",
        "id": 42908
    },
    {
        "title": "Worker thread aborts on terminate if native node module has an open async handle",
        "body": "* **Version**: `v14.6.0, v12.14.1`\r\n* **Platform**: `4.15.0-1091-oem #101-Ubuntu SMP Thu Jun 25 17:55:29 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: `worker_threads`\r\n\r\n### What steps will reproduce the bug?\r\nI have opened up a repository [here](https://github.com/implausible/native-node-worker-thread-aborts-on-terminate) that can be used to reliably crash node. Follow the steps in `README.md` to replicate.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nThis reproduces so long as a native node module has an active async handle for async completion.\r\n\r\n### What is the expected behavior?\r\nWorker thread should not terminate until all handles are cleaned up. Modules should be able to exit gracefully when terminate is requested.\r\n\r\n```\r\nnpm test\r\n\r\n> native-node-tests@1.0.0 test /home/tylerw/github/test/native-node-tests\r\n> node -e \"w = new (require('worker_threads').Worker)('./runDoAsyncThing.js'); setTimeout(w.terminate.bind(w), 2000);\"\r\n\r\nEntering execute thread\r\n```\r\n\r\n### What do you see instead?\r\n\r\n```\r\nnpm test\r\n\r\n> native-node-tests@1.0.0 test /home/tylerw/github/test/native-node-tests\r\n> node -e \"w = new (require('worker_threads').Worker)('./runDoAsyncThing.js'); setTimeout(w.terminate.bind(w), 2000);\"\r\n\r\nEntering execute thread\r\nuv loop at [0x7f18151e1ad8] has open handles:\r\nuv loop at [0x7f18151e1ad8] has 0 open handles in total\r\nnode[23076]: ../src/debug_utils.cc:322:void node::CheckedUvLoopClose(uv_loop_t*): Assertion `0 && \"uv_loop_close() while having open handles\"' failed.\r\n 1: 0x9fb000 node::Abort() [node]\r\n 2: 0x9fb07e  [node]\r\n 3: 0x98e9f1  [node]\r\n 4: 0xab2e44 node::worker::Worker::Run() [node]\r\n 5: 0xab2e88  [node]\r\n 6: 0x7f1817de06db  [/lib/x86_64-linux-gnu/libpthread.so.0]\r\n 7: 0x7f1817b09a3f clone [/lib/x86_64-linux-gnu/libc.so.6]\r\nAborted (core dumped)\r\nnpm ERR! Test failed.  See above for more details.\r\n```",
        "labels": "feature request",
        "id": 42909
    },
    {
        "title": "Porting over the Web Audio API",
        "body": "As of now, it is very difficult to play audio in Node.js. Most solutions suggested on the [Stackoverflow question](https://stackoverflow.com/questions/12543237/play-audio-with-node-js) require using native modules and have all broken in one way or another. Community implementations of the Web Audio API have made good progress but are incomplete and buggy. My experience using [web-audio-api](https://www.npmjs.com/package/web-audio-api) has not been good.\r\n\r\nNode.js should port over the [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API) present in browsers so that the same functionality can be achieved on the client-end, or at the very least provide middleware for piping audio streams to hardware, like [speaker](https://www.npmjs.com/package/speaker).",
        "labels": "feature request",
        "id": 42910
    },
    {
        "title": "Add a native support of Argon2 hashing algorithm",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently Node.js provides a native support of `scrypt`, which is good but isn't the most secure option.\r\n\r\n**Describe the solution you'd like**\r\nIt would be great to have a native support of `argon2` via `crypto` module, just like `scrypt` has nowadays.\r\n\r\n**Describe alternatives you've considered**\r\nAn [`argon2`](https://www.npmjs.com/package/argon2) npm module for Node.js.",
        "labels": "feature request",
        "id": 42911
    },
    {
        "title": " Should we add a new api, \"tls.Server.prototype.removeContexts(servername)\" and \"tls.Server.prototype.replaceContext(servername,context)\" ?",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nhttps://github.com/nodejs/node/issues/34110\r\nhttps://github.com/nodejs/node/pull/34444\r\n\r\nAfter adding the context with \"tls.Server.prototype.addContext\", the context corresponding to the specified servername cannot be deleted. Should we add a new api, \"tls.Server.prototype.removeContexts(servername)\"?\r\n\r\n\r\nThis is useful on HTTPS servers that need to replace ssl/tls certificates frequently, such as using \"let's encrypt\". When the certificate needs to be replaced, you don't want to restart the HTTPS server, you just need to replace the certificate and key.\r\n\r\nIf multiple secure contexts are added to the same domain name\r\n, the last one added should take effect,\r\n\r\nWith frequent ssl/tls certificate updates, addContext is called constantly. If the old context is not deleted, the old context will take up more and more memory space, and they are useless.  Eventually lead to memory leaks or even memory overflow.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\n add a new api, \"tls.Server.prototype.removeContexts(servername)\"\r\n\r\nthe all contexts corresponding to the specified servername should be deleted.\r\n\r\n Should we add a new api, \"tls.Server.prototype.removeContexts(servername)\" and \"tls.Server.prototype.replaceContext(servername,context)\" ?\r\n\r\n\r\n\"tls.Server.prototype.replaceContext(servername,context)\"  Its role should be the operation of \"tls.Server.prototype.removeContexts(servername)\" and \"tls.Server.prototype.addContext(servername,context)\"\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\n\r\n\r\n```js\r\n\r\n const server = https.createServer();\r\nconst hostname = 'foo.bar.com';\r\nconst keypath = 'key.pem';\r\nconst certpath = 'cert.pem';\r\nfunction debounce(callback, timeout) {\r\n    let timer;\r\n    return function (...args) {\r\n        timer && clearTimeout(timer);\r\n        timer = setTimeout(callback, timeout, ...args);\r\n    };\r\n}\r\nconst reloadcertkey = debounce(function () {\r\n    let key = fs.readFileSync(keypath);\r\n    let cert = fs.readFileSync(certpath);\r\n    let context = tls.createSecureContext({\r\n        key,\r\n        cert\r\n        \r\n    });\r\n    server.removeContexts(hostname, );\r\n    server.addContext(hostname, context);\r\n}, 1000);\r\nreloadcertkey();\r\nfs.watch(keypath, reloadcertkey);\r\nfs.watch(certpath, reloadcertkey);\r\n```\r\n\r\n```js\r\n\r\n const server = https.createServer();\r\nconst hostname = 'foo.bar.com';\r\nconst keypath = 'key.pem';\r\nconst certpath = 'cert.pem';\r\nfunction debounce(callback, timeout) {\r\n    let timer;\r\n    return function (...args) {\r\n        timer && clearTimeout(timer);\r\n        timer = setTimeout(callback, timeout, ...args);\r\n    };\r\n}\r\nconst reloadcertkey = debounce(function () {\r\n    let key = fs.readFileSync(keypath);\r\n    let cert = fs.readFileSync(certpath);\r\n    let context = tls.createSecureContext({\r\n        key,\r\n        cert\r\n        \r\n    });\r\n    \r\n    server.replaceContext(hostname, context);\r\n}, 1000);\r\nreloadcertkey();\r\nfs.watch(keypath, reloadcertkey);\r\nfs.watch(certpath, reloadcertkey);\r\n```",
        "labels": "feature request",
        "id": 42912
    },
    {
        "title": "Add experimental support for io_uring",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\nRecent Linux kernel (5.1+) includes io_uring, a new non-blocking I/O subsystem, which might serve as a more efficient alternative to epoll. We could benefit from it and get a performance improvement in network I/O scenarios with high volume of concurrent connections and/or for fs operations.\r\n\r\nOf course, in Node.js case we need changes made in libuv. There is an ongoing experiment aimed to add support for io_uring in libuv: https://github.com/libuv/libuv/pull/2322\r\n\r\nAs this feature should be experimental (at least initially), io_uring mode could be activated under a new flag.\r\n\r\nThe goal of this issue is to improve visibility of the libuv experiment and gather some feedback.",
        "labels": "feature request",
        "id": 42913
    },
    {
        "title": "Uncatchable UnhandledPromiseRejectionWarning caused by asynchronous listeners on parentPort inside worker",
        "body": "* **Version**: 12.18.2\r\n* **Platform**: Macbook-Pro.local 19.5.0 Darwin Kernel Version 19.5.0\r\n\r\n### What steps will reproduce the bug?\r\n1) create an index.js file and a worker.js file in the same directory\r\n\r\n2) Copy the following code into index.js:\r\n\r\n```\r\nconst { Worker } = require('worker_threads');\r\nconst os = require('os');\r\nconst path = require('path');\r\nconst numCPUs = os.cpus().length - 2;\r\n\r\nconst jobs = [\r\n  {num: 0},\r\n  {num: 1},\r\n  {num: 2},\r\n  {num: 3},\r\n  {num: 4},\r\n  {num: 5},\r\n  {num: 6},\r\n  {num: 7},\r\n  {num: 8},\r\n  {num: 9}\r\n];\r\n\r\ntest().then(() => console.log('done')).catch(e => {\r\n  console.log('tremendous error');\r\n  console.log(e);\r\n});\r\nasync function test() {\r\n  console.log('building workers');\r\n  const workers = [];\r\n  for (let i = 0; i < numCPUs; i++) {\r\n    let worker = new Worker(path.join(__dirname, 'worker.js'));\r\n    workers.push(worker);\r\n  }\r\n\r\n  console.log('starting jobs, # jobs: ', jobs.length);\r\n  console.log('num of cpus: ', numCPUs);\r\n  await runJobs({workers, jobs});\r\n}\r\n\r\nasync function runJobs ({ workers, jobs }) {\r\n    /** Do your work here **/\r\n    let numJobsDone = 0;\r\n    let results = [];\r\n    let numJobsStarted = 0;\r\n    while (numJobsDone < jobs.length) {\r\n      let promises = [];\r\n      for ( let i = 0; i < workers.length; i++) {\r\n        let worker = workers[i];\r\n        if (!jobs[numJobsStarted]) continue;\r\n        let job = jobs[numJobsStarted];\r\n        numJobsStarted++;\r\n        promises.push(new Promise((resolve, reject) => {\r\n          worker\r\n            .on('message', msg => {\r\n              console.log(msg, i, msg.num);\r\n              numJobsDone++;\r\n              resolve(msg);\r\n            })\r\n            .on('error', error => {\r\n              console.log(error);\r\n              numJobsDone++;\r\n              reject(error);\r\n            })\r\n            .on('exit', code => {\r\n              if (code !== 1) {\r\n                reject(`Got a funky exit code: ${code}`);\r\n              }\r\n            });\r\n\r\n          worker.postMessage(job);\r\n        }));\r\n      }\r\n      await Promise.allSettled(promises).then(results => {\r\n        console.log(`Received ${results.length} results back`);\r\n      });\r\n\r\n      console.log('numDone: ', numJobsDone);\r\n      console.log('numStarted: ', numJobsStarted);\r\n      console.log('numJobs: ', jobs.length);\r\n      console.log();\r\n    }\r\n}\r\n```\r\n\r\n3) paste the following code into worker.js:\r\n\r\n```\r\nconst { parentPort } = require('worker_threads');\r\n\r\nparentPort.on('message', async job => {\r\n  /** Destructure the property \"num\" - Simulating getting properties off\r\n   * the passed in object **/\r\n  const { num } = job;\r\n\r\n  /** Simulate doing intensive asynchronous task here **/\r\n  await delay(1000);\r\n\r\n  /** Send back message, when num === 3 should emit error that triggers\r\n   * .on('error') listener in index.js **/\r\n  if (num !== 3) {\r\n    parentPort.postMessage(job);\r\n  } else throw new Error(`it was not found: ${JSON.stringify(job)}`);\r\n});\r\n\r\nasync function delay(ms) {\r\n  return new Promise(resolve => setTimeout(resolve, ms));\r\n}\r\n```\r\n\r\n4) execute index.js\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n As written above, will always produce uncaught exception. Make the parentPort listener in worker.js synchronous and error is correctly caught by the .on('error') listener on line 55 of index.js\r\n\r\n### What is the expected behavior?\r\n I expect the `.on('error')` event to fire on line 55 of index.js when the job with num: 3 throws an error inside of worker.js, and the `Promise.allSettled().then(results)` to invoke and the promise with job`{num: 3}` to be unfulfilled and present inside of the array of `results` returned by Promise.allSettled when an asynchronous listener to the parentPort is used inside of worker.js.\r\n\r\n### What do you see instead?\r\n an Uncaught error exception caused by the .on('error') listener not catching the error thrown from the worker.js;\r\n\r\n### Additional information:\r\n If you just remove the async keyword in the listener of worker.js (line 3) and comment out line 9 `await delay(1000);` inside of worker.js the error caused by job {num: 3} is properly caught by the .on('error') handler and the unfulfilled promise appears in the allSettled.then of line 69 in index.js the code continues and exits gracefully.\r\n\r\nI don't think that it is intended behavior for the worker.js to only be able to run synchronous listeners to the parentPort. Is this intended behavior? If so, how can I run asynchronous tasks inside of the worker_thread and properly catch errors without bringing down the entire process?\r\n",
        "labels": "feature request",
        "id": 42914
    },
    {
        "title": "N-API: implement something like `yield`",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI work primarily on Messenger Desktop which is an electron app with a number of native plugins. We were using N-API before the promise APIs were available and we found it a nice usability/readability upgrade when we were able to switch from callbacks to those for our functions that complete a single time.\r\n\r\n**Describe the solution you'd like**\r\nI am hoping we could have the same kind of usability/readability win for our functions that generate values over time. The end result I want is that JS sees a `function*` and on the C side we have something like this:\r\n\r\n```\r\nnapi_value api(napi_env env, napi_callback_info info) {\r\n  // One-time setup:\r\n  napi_generator generator;\r\n  napi_value functionStar;\r\n  napi_create_generator(env, &generator, &functionStar);\r\n\r\n  // setup async_work\r\n\r\n  return functionStar;\r\n}\r\n\r\nvoid async_work(napi_generator generator) {\r\n  // calculate value or errror, be on JS thread\r\n  // success with intermediate value:\r\n  napi_generate_value(env, generator, value, false);\r\n  // success with final value:\r\n  napi_generate_value(env, generator, value, true);\r\n  // failure\r\n  napi_generate_error(env, generator, error);\r\n}\r\n```\r\n\r\nIt will be an error to call any `napi_generate_` function for a generator after calling either `napi_generate_value(env, generator, ..., true);` or `napi_generate_error(env, generator, ...);`\r\n\r\n**Describe alternatives you've considered**\r\nWe're currently having our generators accept callbacks and invoking them. It works but this would be cleaner.",
        "labels": "feature request",
        "id": 42915
    },
    {
        "title": "Expose the `url-to-options` function from `internal/url.js`",
        "body": "**Is your feature request related to a problem? Please describe.** \r\n\r\nhttps://github.com/nodejs/node/issues/14570#issuecomment-657638743\r\n\r\n**Describe the solution you'd like**\r\n\r\nExpose the `urlToOptions` module so it can be imported e.g. `const {urlToOptions} = require('url');`\r\n\r\nThat way we could easily convert a URL instance without duplicating the code like [this](https://github.com/szmarczak/http2-wrapper/blob/v1.0.0-beta.5.2/source/utils/url-to-options.js).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo, duplicates increase the package size.\r\n",
        "labels": "feature request",
        "id": 42916
    },
    {
        "title": "Expose the `errors` module from the `internal` directory",
        "body": "**Is your feature request related to a problem? Please describe.** \r\n\r\nhttps://github.com/nodejs/node/issues/14570#issuecomment-657638743\r\n\r\n**Describe the solution you'd like**\r\n\r\nExpose the `errors` module so it can be imported e.g. `const errors = require('errors');`\r\n\r\nThat way we could easily throw Node.js errors without duplicating them like [this](https://github.com/szmarczak/http2-wrapper/blob/v1.0.0-beta.5.2/source/utils/errors.js).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo, duplicates increase the package size.\r\n",
        "labels": "feature request",
        "id": 42917
    },
    {
        "title": "Allow to trust certificate without adding full chain of trust",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, you have to put the full chain of trust, if you want to trust one certificate.\r\n\r\nFor example, if you have that chain of trust\r\n\r\n* CertHost: valid for *.myhost.com, signed by CertIntermediate\r\n* CertIntermediate: signed by CertRoot\r\n* CertRoot: self-signed by CertRoot\r\n\r\nCurrently you have to add all three certificates to the ca trust: CertHost, CertIntermediate, CertRoot\r\n\r\nThe problem is, that now we trust everything, that is signed by CertIntermediate and CertRoot, even we don't want that, and only want to trust CertHost. So we are trusting thousands and more certificates.\r\n\r\n**Describe the solution you'd like**\r\nProviding at least an optional configuration, that allows to trust also just certificates like CertHost without providing CertIntermediate and CertRoot. Hence we have really control about what kind of certificates we trust and are able to trust only a few.",
        "labels": "feature request",
        "id": 42918
    },
    {
        "title": "Allow to disable the default ca trust completely",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently there are only two options regarding the default ca trust used by nodejs\r\n\r\n* `--use-bundled-ca` (default) - Using the hardcoded ca trust: <https://github.com/nodejs/node/blob/master/src/node_root_certs.h>\r\n* ` --use-openssl-ca` - Using the openssl default ca trust\r\n\r\nSo there is no out of the box chance to disable the default trust.\r\nAccording to <https://github.com/nodejs/node/issues/4175#issuecomment-238211757> you have to override it manually\r\n\r\n```js\r\nhttps.globalAgent.options.ca = [];\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nFrom security and operation perspective it would be even better per default not having any trust cas at all, but that would be a huge, breaking change.\r\n\r\nSo at least an option like `--use-no-ca` would be very helpful here\r\n\r\n",
        "labels": "feature request",
        "id": 42919
    },
    {
        "title": "User Mode Install for Windows",
        "body": "A lot of Windows programs offer a user mode install, where the program gets installed into %LOCALAPPDATA%\\Programs instead of the legacy C:\\Program Files\\ folder which requires local administrative access. Some examples of such programs as VSCode and Python. It would be nice if the Windows Installer for nodejs offered a user mode install option which did not require administrative access.\r\n\r\nThe installer could either offer the option to install in user mode, or check to see if it can elevate, and if not default to %LOCALAPPDATA%\\Programs\\nodejs",
        "labels": "feature request",
        "id": 42920
    },
    {
        "title": "Crypto: CMAC support",
        "body": "<!--\nThank you for suggesting an idea to make Node.js better.\n\nPlease fill in as much of the template below as you're able.\n-->\n\n**Is your feature request related to a problem? Please describe.**\nNo\n\n**Describe the solution you'd like**\nOpenSSL already supports CMAC, but Node doesn't implement it. We use smartcards that only support CMAC, not HMAC, and our current solution is hacky.\n\n**Describe alternatives you've considered**\nSo far we've just hashed the message and encrypted the key with a secret.",
        "labels": "feature request",
        "id": 42921
    },
    {
        "title": "Export Version 2 PKCS #8 Private Keys",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently, NodeJS exports PKCS 8 private keys as Version 1 `PrivateKeyInfo` objects, but as of 2010, [RFC 5958](https://tools.ietf.org/html/rfc5958) specifies Version 2. This only differs from Version 1 by optionally including the public key at the end of the object, and, of course, the version number being incremented.\r\n\r\n**Describe the solution you'd like**\r\nThe ability to export Version 2 PKCS 8 Private Keys. All keys can be exported to Version 2 because the included public key at the end is still optional in Version 2. If it is too much work to generate public keys for all algorithms, the public key can be generated just for selected algorithms (presumably those most commonly used, such as RSA and DSA).\r\n\r\nThis would change [Crypto.KeyObject.export()](https://nodejs.org/dist/latest-v14.x/docs/api/crypto.html#crypto_keyobject_export_options) by adding a new export type: `pkcs8v2`. Again, if the public key cannot be generated, it will simply not be included in the export.\r\n\r\n**Describe alternatives you've considered**\r\nThere are no native alternatives. You would have to use third-party crypto libraries to generate PKCS 8 Version 2 keys.\r\n",
        "labels": "feature request",
        "id": 42922
    },
    {
        "title": "http2: support adding never-index header fields",
        "body": "As part of the HTTP2 (and HTTP3) spec, some headers can be sent as `Literal Header Field Never Indexed`\r\n \r\nhttps://www.rfc-editor.org/rfc/rfc7541.html#section-6.2.3\r\n\r\nThis can be used for security reasons to avoid `CRIME` (Compression Ratio Info-leak Made Easy) attacks to expose sensitive information. \r\n\r\nPoints of interest are:\r\n\r\n* [What flag to set for nghttp2](https://nghttp2.org/documentation/enums.html#c.NGHTTP2_NV_FLAG_NO_INDEX)\r\n* [How we compile a header from JS](https://github.com/nodejs/node/blob/241ed44a0b06db45c97681c164fc1098e7c9f0d2/lib/internal/http2/util.js#L439)\r\n* [How we submit responses to nghttp2](https://github.com/nodejs/node/blob/f63436d190b60e12131036aa9d1888d9023e9127/src/node_http2.cc#L2001)\r\n\r\nIt'll help diagnose https://github.com/nodejs/node/issues/28632\r\n ",
        "labels": "feature request",
        "id": 42923
    },
    {
        "title": "implement process.exitWithException()",
        "body": "In the stalled PR https://github.com/nodejs/node/pull/25715, @Fishrock123 was working to introduce a new API... from the original description:\r\n\r\n> Adds a public way to access node::FatalException from javascript, as process.exitWithException().\r\n>\r\n> If an error stack is available on the value, this method of exiting does not add additional context, unlike regular re-throwing, yet also uses the regular error printing logic. This behavior is particularly desirable when doing 'fatal exits' from the unhandledRejection event.\r\n\r\nWhile the PR had plenty of support to move forward, there was an edge case around the `uncaughtException` event handler that would need to be worked through in order for it to move forward.\r\n\r\nThe original PR stalled out and has been closed, but given the support the idea had, I wanted to make sure to open a Feature Request issue in case someone else wanted to pick up the work and move it forward.",
        "labels": "feature request",
        "id": 42924
    },
    {
        "title": "Imply ES6 module package, when package.json contanis 'module':...",
        "body": "In my package.json I have `'type':'module'` and in my code I write `import babel from '@rollup/plugin-babel`.  The [package.json of the latter](https://github.com/rollup/plugins/blob/master/packages/babel/package.json) contains `\"main\": \"dist/index.js\", \"module\": \"dist/index.es.js\"` but there is no `'type':'module'`.  In turn nodejs concludes that `@rollup/plugin-babel` is commonjs and there is no way to use the default import from `dist/index.es.js`.  This means I have to write `babel.default` in my code and I cannot use `import {babel} from '@rollup/plugin-html`.\r\n\r\nâ€¢ When NodeJS imports a package(.json) that contains 'main' and 'module' fields, but no 'type' field, from a package containing `'type':'module'`, implicitly conclude that the imported package is an ES6 module.",
        "labels": "feature request",
        "id": 42925
    },
    {
        "title": "Adding middleware functions in EventEmitter .on()",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nIn SocketIO it would be useful to be able to add middleware functions to specific events. The sockets use the EventEmitter. \r\n\r\n\r\n**Describe the solution you'd like**\r\nIn a regular express app it is possible to add middleware to specific endpoints like so: \r\n\r\n```\r\nfunction someFunc(req, res, next) {\r\n    // doing something\r\n   next()\r\n}\r\napp.get('/users', someFunc, (req, res) => { res.send('someData')})\r\n```\r\n\r\n\r\nIt would be logical to also be able to do it with SocketIO:\r\n\r\n```\r\nfunction someFunc(data, next) {\r\n    // doing something\r\n   next()\r\n}\r\nfunction someFunc2(data, next) {\r\n    // doing something\r\n   next()\r\n}\r\nsocket.on('users', someFunc, someFunc2, (data) => { /*doing something*/})\r\n\r\n```\r\n**Why it would be used**\r\nThis could be useful to add callbacks to endpoints to check if a user is authenticated or has enough credits before using the endpoint for example. Instead of having a global middleware that is checked for every endpoint.\r\n\r\nSo by implementing these extra middleware to be added in the EventEmitter.on() function it could have the same behavior as the express routes and still maintain the same behavior with just one function. \r\n\r\n**Describe alternatives you've considered**\r\n\r\n- using the socket.use(fn) function would bring a lot of overhead as it would call the middleware every time for every endpoint.\r\n(added: )\r\n- it could also be a SocketIO feature, though I think it could also be useful for other applications where specific handling per event endpoint is needed.\r\n- It could be possible to create a wrapper function like `socket.on('users', functionWrapper( fn1, fn2, fn3))` though it would be cleaner to be able to directly put the functions in the `.on()` function.\r\n\r\n**example + further implementation/usage info**\r\n[JSFIDDLE](https://jsfiddle.net/dirvann/5p42j9ze/2/)\r\n[comment below](https://github.com/nodejs/node/issues/33932#issuecomment-646027458)",
        "labels": "feature request",
        "id": 42926
    },
    {
        "title": "Add an `executable` property or an `isExecutable` method to fs Stats class",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nAn easy to easy API for determining if a file is executable based on its `fs.Stats`. \r\n\r\n**Describe the solution you'd like**\r\nDerived from Ruby: https://www.rubydoc.info/stdlib/core/File%2FStat:executable%3F I've created a rough implementation. It hasn't been tested.\r\n\r\n```js\r\nfunction isExecutable (stat: fs.Stats) {\r\n\tconst S_IXUGO = fs.constants.S_IXUSR | fs.constants.S_IXGRP | fs.constants.S_IXOTH\r\n\tconst euid = process.geteuid()\r\n\tif (euid === 0) {\r\n\t\treturn stat.mode & S_IXUGO ? true : false\r\n\t} else if (stat.uid === euid) {\r\n\t\treturn stat.mode & fs.constants.S_IXUSR ? true : false\r\n\t} else if (stat.gid === process.getgid() || stat.gid === process.getegid()) {\r\n\t\treturn stat.mode & fs.constants.S_IXGRP ? true : false \r\n\t} else if (!(stat.mode & fs.constants.S_IXOTH)) {\r\n\t\treturn false\r\n\t} else {\r\n\t\treturn true\r\n\t}\r\n}\r\n```\r\n\r\nI'll be happy to work on the PR if maintainers thinks its a worthwhile addition to fs\r\n",
        "labels": "feature request",
        "id": 42927
    },
    {
        "title": "assert.match should return match result",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI was using `assert(haystack.match(/needle/));` in my unit tests, and I found that `assert.match(haystack, /needle/);` produced much cleaner errors. +1, suggest to move to stable.\r\n\r\nHowever, in a small handful of cases, I was also using the match results later on in the test, like so:\r\n\r\n```javascript\r\nconst m = haystack.match(/nee(\\d+)le/);\r\nassert(m);\r\n// ...\r\nassert(haystack2.match(m[1]));\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nIf I could rescue the match results from `assert.match`, and if the `regexp` argument could be a string, this code could be simplified:\r\n\r\n```javascript\r\nconst m = assert.match(haystack, /nee(\\d+)le/);\r\n// ...\r\nassert.match(haystack2, m[1]);\r\n```\r\n\r\n\r\n**Describe alternatives you've considered**\r\nThis feature simply leads to cleaner tests.\r\n\r\nPossible downsides are that people may overlook assert calls used like this, because they always expect \"assert\" to work like a C assertion, or having a return value is too inconsistent with the rest of the library.",
        "labels": "feature request",
        "id": 42928
    },
    {
        "title": "node process does not reflect timezone changes",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.17.0\r\n* **Platform**: Linux 5.4.0-33-generic # 37-Ubuntu SMP Thu May 21 12:53:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Platform**: Linux 3.16.0-4.9-amd64 # 1 SMP Debian 3.16.7-ckt25-1 (2018-11-21) x86_64 GNU/Linux\r\n(it reproduces on both platforms)\r\n* **Subsystem**: ?\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n- open two terminals locally on machine\r\n- run `node` on terminal 1\r\n- `new Date().getTimezoneOffset()`\r\n- change timezone in terminal 2\r\n- ask for `new Date().getTimezoneOffset()` in node in terminal 1 again\r\n- **note that timezone change is not reflected**\r\n- exit node process in terminal 1 and enter `node` again (another `node` process)\r\n- now `new Date().getTimezoneOffset()` reflects the new timezone\r\n- **note that this not-reflecting-new-timezone thing affects creating new dates and any other date operations. `getTimezoneOffset()` is just a sample**\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nalways reproduces, no required condition.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nTo reflect and update timezone of node process, when timezone of system is changed.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nI see the old timezone.\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\nThis bug has been created and reported previously, as I read, some people mentioned that the main bug is with V8, and linked to some bugs there. By the way, all previous reported bugs were closed. I link to everything I found here:\r\nhttps://github.com/nodejs/node/issues/4022\r\nhttps://github.com/nodejs/node/pull/20026\r\nhttps://github.com/nodejs/node/issues/19974\r\nhttps://github.com/nodejs/node/issues/3449\r\n\r\nI created this issue as some time has passed and honestly, I couldn't find out why the previous issues were closed, and V8 discussions were beyond my knowledge.\r\n\r\n### What is the matter?\r\n\r\nWe have a system, a rather big one, composed of different programming languages and technologies, all components of our system works fine when timezone changes, except nodejs. There are solutions like https://github.com/evanlucas/reset-date-cache, but suppose node queries sql queries and created date objects from timestamps in sql tables, and timezone needs  to  be kept updated. the only way to keep it updated is to reset cache on each page request, which as noted in https://github.com/evanlucas/reset-date-cache: \r\n> The underlying call being made is quite expensive so it should only be used where absolutely necessary.\r\n\r\n### Screenshot of reproduction\r\n\r\n![Screenshot from 2020-06-09 18-58-34](https://user-images.githubusercontent.com/5755214/84143307-65883480-aa67-11ea-8013-e2f28ce24671.png)\r\n",
        "labels": "feature request",
        "id": 42929
    },
    {
        "title": "Expose the existing mechanisms behind `assert.deepEqual`",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nI've been working on a testing tools set as part of some new proprietary ecosystem \r\n(with the intent to open-source elements from it once they are stable enough in their form and require less maintenance, but so far it's proprietary :( ).\r\nAs part of this testing framework, I need to perform a deep comparison of objects.\r\n\r\nAs a start - I got `assert.deepEqual` - which is great. However - it ends with an exception.\r\nSometimes I would like to manage the exception myself - I just need the indication.\r\n\r\nI decided to open this issue when I came across more use-cases:\r\n - data healer - need to act on a decision if a model does not comply with expected values.\r\n   For this - we need a form of `containsEql`.\r\n - suite setup & teardown - need to add test-fixture data, and validate that essential objects are part of the target env (e.g. object describing super-user, or root categories, root tags, etc).\r\n \r\nIn all of the cases, it's beneficial to be able to perform both `containsEql` and `deepEqual`.\r\n\r\nI did see `util.isDeepStrictEqual` - and despite the confusing name that gave me hope.\r\n\r\n(I mean, it took me a lot of tries to understand that `strict` does not mean reference-comparison, but comparison without conversion of values. The first time I saw it I struggled to understand what it means - does it compare shallow copies? I had to try and see for myself. Anyway - I'm side tracking)\r\n\r\n**Describe the solution you'd like**\r\nI would propose on the same spirit of `util.isDeepStrictEqual(..)`\r\n`util.isDeepStrictContain(..)`\r\n\r\nI also saw the underlying mechanisms with the `bStirct` flag, and thought it could also be useful to let users inject it if they so choose, but I'm not sure about the names or the form it should take.\r\n\r\nI'll be happy to start work on it if we can agree on the form it should take.\r\n\r\nI mean, the mechanisms are there, and their functionality is all well-tested.\r\nWe just need to feature them and add only tests that show they are available, or even reuse parts of the existing tests - but expect a boolean instead of an error.\r\n\r\n**Describe alternatives you've considered**\r\nAll current alternatives come from userland codes, which basically duplicate the same logic and introduce their own takes and flavors. Which is a pity...\r\nWe have that logic in `node`, and it's a good logic that runs deep and already serves now a role in APIs used by userland.\r\n",
        "labels": "feature request",
        "id": 42930
    },
    {
        "title": "Improvements of OSS-Fuzz integration",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nThis feature is not related to a problem. \r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nThis feature asks for tighter integration with continuous fuzzing via OSS-Fuzz. In this PR https://github.com/google/oss-fuzz/pull/3860#issuecomment-638747166 I integrated NodeJS with fuzzing and so far it was used to capture this bug https://github.com/nodejs/node/pull/33640 \r\nHowever, the current integration could be improved and it would be desirable to cover more of NodeJS with fuzzers, as briefly discussed with @bnoordhuis in the above PR. Specifically, there are two core parts where the integration with OSS-Fuzz can improve: (1) integrating the build procedure with the OSS-Fuzz environment more closely with the NodeJS environment and (2) building more fuzzers. \r\n\r\nRegarding part 1 then the current strategy (`build.sh` here https://github.com/google/oss-fuzz/pull/3860/files) compiles the NodeJS core in an awkward manner by first running `make` without any proper OSS-Fuzz flags and then re-comiling the `.cc` files of `node/src` with the proper OSS-Fuzz flags, in order to create a static archive. \r\nThe OSS-Fuzz environment sets the following environment variables when compiling the fuzzers to something similar to this:\r\n```\r\nexport CC=clang\r\nexport CXX=clang++\r\nexport CFLAGS=\"-O1 -fno-omit-frame-pointer -gline-tables-only -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION -fsanitize=address -fsanitize-address-use-after-scope -fsanitize=fuzzer-no-link\"\r\nexport CXXFLAGS=\"-O1 -fno-omit-frame-pointer -gline-tables-only -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION -fsanitize=address -fsanitize-address-use-after-scope -fsanitize=fuzzer-no-link -stdlib=libc++\"\r\nexport LIB_FUZZING_ENGINE=\"-fsanitize=fuzzer\"\r\n```\r\nIt would be nice if the build process of NodeJS can integrate a fuzzing part which enables us to compile with the OSS-Fuzz variables (`CFLAGS`, `CXXFLAGS` and `LIB_FUZZING_ENGINE`) above. The `LIB_FUZZING_ENGINE` variable is only used for linking the final fuzzer and should not be used on any of the compiled libraries. Also note that to get the fuzzers compiled properly they should be compiled against static libraries. As I see the desired goal is, therefore, to have the files in `node/src` be compiled with the `CFLAGS` and `CXXFLAGS` variables above.\r\n\r\nRegarding part 2 then I can certainly start writing more fuzzers and covering more of the NodeJS code, but if you have any suggestions of good APIs for fuzzing then here would be a good place to write I think. ",
        "labels": "feature request",
        "id": 42931
    },
    {
        "title": "Promise-friendly stream.pipeline and stream.finished",
        "body": "I often use `stream.pipeline` in async functions, and it's always a bit painful to have to promisify it.\r\nWhat about exporting a promisified version from the `stream` module directly?\r\nI haven't opened an issue or PR before because I don't have a good idea for the name, but maybe somebody else does!\r\n\r\n@nodejs/streams ",
        "labels": "feature request",
        "id": 42932
    },
    {
        "title": "Enable hooks in fs.statWatchers",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPeople sometimes will encounter the error that `System limit for number of file watchers reached.`. If we enable users to add hooks in fs.statWatchers, they could track the codes that which module call `fs.watchFile` many times\r\n\r\n**Describe the solution you'd like**\r\n```js\r\nconst { statWatchers, watchFile } = require(â€˜fsâ€™)\r\nstatWatchers.on(â€˜statAddâ€™, () => {})\r\nstatWatchers.on(â€˜statRemoveâ€™, () => {})\r\n\r\nwatchFile(â€˜xxxâ€˜, () => {})\r\n```\r\n\r\nRelated code\r\nhttps://github.com/nodejs/node/blob/9949a2e1e3100c4ff1f228bac57c1af95cdc3e9d/lib/fs.js#L1458\r\n",
        "labels": "feature request",
        "id": 42933
    },
    {
        "title": "feature-request fs.fileWrite with option.mkdirp",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\ni am author of npm-package istanbul-lite.\r\nwhen creating coverage-reports and artifacts,\r\nits common to lazily write data to file-directories that have yet to be created.\r\n\r\n**Describe the solution you'd like**\r\n\r\nadd extra boolean `<options>.mkdirp` to functions `fs.writeFile` and `fs.writeFileSync`,\r\nthat will lazily create missing file-directories when writing to file.\r\nthe common-use-case are:\r\n- lazily generate directories when writing coverage-report of instrumented files\r\n- lazily generate directories when writing artifacts in ci and testing\r\n- lazily generate directories when scaffolding new web-projects\r\n\r\n**Describe alternatives you've considered**\r\n\r\ni currently use this helper-function in all my projects,\r\nto lazily generate directories when writing artifacts and coverage-reports.\r\n```javascript\r\n    function fsWriteFileWithMkdirpSync (file, data) {\r\n    /*\r\n     * this function will sync write <data> to <file> with \"mkdir -p\"\r\n     */\r\n        let fs;\r\n        // do nothing if module does not exist\r\n        try {\r\n            fs = require(\"fs\");\r\n        } catch (ignore) {\r\n            return;\r\n        }\r\n        // try to write file\r\n        try {\r\n            fs.writeFileSync(file, data);\r\n            return true;\r\n        } catch (ignore) {\r\n            // mkdir -p\r\n            fs.mkdirSync(require(\"path\").dirname(file), {\r\n                recursive: true\r\n            });\r\n            // rewrite file\r\n            fs.writeFileSync(file, data);\r\n            return true;\r\n        }\r\n    };\r\n```\r\n",
        "labels": "feature request",
        "id": 42934
    },
    {
        "title": "http2 can't send window_update frame",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI'm trying to send a window_update frame using the http2 module.\r\n\r\n**Describe the solution you'd like**\r\nA way to send the window_update frame\r\n\r\n**Describe alternatives you've considered**\r\nLooking into the source code I couldn't find a way to send it, the documentation also doesn't say anything about it. If it is already possible to send it, forgive me.\r\n",
        "labels": "feature request",
        "id": 42935
    },
    {
        "title": "add 'maxHeaderSize' to 'http2'",
        "body": "*This is a feature request for adding `maxHeaderSize` in `http2` as quoted below*\r\n\r\n***\r\nSounds good to me â€“ `maxHeaderSize` could be added along with that. :+1:\r\n\r\n_Originally posted by @addaleax in https://github.com/nodejs/node/issues/32388#issuecomment-601667748_",
        "labels": "feature request",
        "id": 42936
    },
    {
        "title": "Does a `postTask` API make sense for Node.js (in any way)?",
        "body": "Hey, web browsers and framework vendors are working on a `postTask` API for dispatching tasks with particular priorities.\r\n\r\nIt is specified [here](https://github.com/WICG/main-thread-scheduling/) and here is a basic example:\r\n\r\n```js\r\n// https://github.com/WICG/main-thread-scheduling/blob/master/sample-code/scheduling-tasks.html\r\nscheduler.postTask(() => 'This should be line 3', {priority: 'background'});\r\nscheduler.postTask(() => 'This should be line 2', {priority: 'user-visible'});\r\nscheduler.postTask(() => 'This should be line 1', {priority: 'user-blocking'});\r\n\r\n// https://github.com/WICG/main-thread-scheduling/blob/master/sample-code/controlling-scheduled-tasks.html\r\n// a taskController is also an AbortController which we are considering\r\nconst controller = new TaskController('background');\r\nlet result = scheduler.postTask(() => {}, {signal: controller.signal});\r\n// control priority later\r\nheaderController.setPriority('user-blocking');\r\n```\r\n\r\nI opened an [issue](https://github.com/WICG/main-thread-scheduling/issues/17) for Node.js use cases there. Copying it here:\r\n\r\nI've been thinking of exploring adopting this API or experimenting with it in Node.js with the use case I've been thinking about is similar main thread contention. I have a server that serves a large number of users. That server needs to manage QoS of various levels of requests. Some requests should be very fast while for other requests I really wouldn't mind the users to wait a few milliseconds.\r\n\r\nFor example if I have a request that hashes an image and stores it for later retrieval - it might be OK for that request to wait until the CPU is idle. Work that takes more than a few milliseconds typically gets put in a (persistent) queue on servers but there is certain work I probably wouldn't mind waiting for.\r\n\r\nThe same goes for CLI tools, webpack might be interested in performing certain kinds of analysis in a lower priority than actually outputting the compiled code. TypeScript might \"emit\" before it's done type-checking to give users a snappier experience etc.\r\n\r\nThe main issue I see here is that Node.js already exposes threads and processes (with worker_threads and child_process) - so users already have access to the operating system scheduler. That said, it would be cool if some code could be made universal and shared here.\r\n\r\n-----\r\n\r\ncc @shaseley, @sebmarkbage and @acdlite from the `postTask` side and @addaleax @bridgear @nodejs/workers @nodejs/open-standards from the Node side.\r\n\r\n----\r\n\r\nIs this interesting or relevant at all for Node.js and if so should we eventually strive to adopt it?",
        "labels": "feature request",
        "id": 42937
    },
    {
        "title": "ASLR (pie) disabled in v12 Linux amd64 build from nodejs.org",
        "body": "```console\r\n$ pwn checksec ./node/node-v12.16.3-linux-x64/bin/node\r\n[*] '/home/pdxjohnny/Downloads/node/node-v12.16.3-linux-x64/bin/node'\r\n    Arch:     amd64-64-little\r\n    RELRO:    Full RELRO\r\n    Stack:    Canary found\r\n    NX:       NX enabled\r\n    PIE:      No PIE (0x400000)  # <---- ASLR disabled\r\n```\r\n\r\nI see there was some discussion on this back in 2016, but I couldn't really follow, it also looks like `-pie` still exists in some of the build files. Just wanted to report in case it's off by mistake.",
        "labels": "feature request",
        "id": 42938
    },
    {
        "title": "TCP/UDP socket type selection inconsistency",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n`dgram.Socket` requires the socket type (`udp4` or `udp6`) to be provided in its constructor (`dgram.createSocket`), and uses this socket type regardless of the local and remote addresses.\r\n\r\n`net.Socket` does not require the socket type to be provided in advance, and performs `dns.lookup()` with the `family` parameter given in `net.Socket#connect()` to determine the socket type. Unlike `dgram.Socket`, it performs socket binding when a connection is requested, so the local address/port can also be provided as parameters if needed, but the socket type is still determined by the remote host (which makes sense as `net.Server` deals with bound but unconnected sockets). \r\n\r\n`net.Server` uses an IPv6 socket by default, unless an IPv4 address is explicitly provided in `net.Server#listen()`.\r\n\r\nThis results in inconsistent default behavior when comparing TCP and UDP, both for servers and clients. It should be possible to have the UDP socket type be determined by the provided addresses, both for servers and clients.\r\n\r\nEven if `udp6` is chosen, which would in theory work the same for both types of remote addresses, the DNS resolution is inconsistent for TCP/UDP clients. TCP resolution defaults to family type 0, while UDP would use family type 6, so the resulting IP address will be different if the nameserver normally resolves to IPv4 first.\r\n\r\nSee [lib/internal/dgram.js#newHandle](https://github.com/nodejs/node/blob/94e5b5c77dade0d8f7358c66144b75c369679cab/lib/internal/dgram.js#L26), [lib/net.js#internalConnect](https://github.com/nodejs/node/blob/94e5b5c77dade0d8f7358c66144b75c369679cab/lib/net.js#L844) and [lib/net.js#createServerHandle](https://github.com/nodejs/node/blob/94e5b5c77dade0d8f7358c66144b75c369679cab/lib/net.js#L1189).\r\n\r\n**Describe the solution you'd like**\r\n- `dgram.Socket` should not require a socket type in its constructor.\r\n- `dgram.Socket#bind()` should match the `net.Server#listen()` behavior and use an IPv6 socket by default, unless and IPv4 address is explicitly provided.\r\n- `dgram.Socket#connect()` should match the `net.Socket#connect()` behavior and resolve the remote address to determine the socket type, crucially before the `bind()` call is made.\r\n- If the socket is already bound when `connect()` is called, the functionality should remain as it is currently, where the `dns.lookup()` call is made with the family parameter set. If only IPv6 is resolved on an IPv4 bound socket, an error is thrown.\r\n- The socket type currently provided in the constructor could set an internal default address for cases when no local or remote addresses are provided to `bind()` and `connect()`, until this method is deprecated, after which the default address would become ::1 in both cases.\r\n\r\n**Describe alternatives you've considered**\r\n- `dns.lookup()` can be performed manually before the socket is created to decide `udp4`/`udp6`, but this greatly complicates the socket creation flow. This could be moved to `dgram.createConnection` or similar, but this wouldn't fully solve the TCP/UDP client inconsistency.\r\n- If using IPv6 by default is acceptable, the `lookup` parameter of `dgram.createSocket` can be set to a wrapper around the default `dns.lookup()`, with the family type set to 0 instead of 6 and if the result is IPv4 it can be manually mapped to IPv6. This again complicates the socket creation flow.\r\n- The previous alternative could be simplified if `family` and `hints` could be provided as is possible in `net.Socket#connect()`, but this doesn't solve the core problem.",
        "labels": "feature request",
        "id": 42939
    },
    {
        "title": "repl: export isRecoverableError",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'd like to be able to use node's `isRecoverableError` function when working with REPL. Since we are adding additional eval (as recommended in #29719), we are not able to take advantage of the built in one and have to write our own where as the functionality we want is exactly the same as node's native functionality for this function.\r\n\r\n**Describe the solution you'd like**\r\n```js\r\nconst repl, { REPLServer } = require('repl')\r\n\r\nconst r = repl.start({\r\n  prompt: `$ mongosh > `,\r\n  ignoreUndefined: true\r\n});\r\n\r\nconst originalEval = util.promisify(r.eval);\r\n\r\nconst customEval = async(input, context, filename, callback) => {\r\n  let result;\r\n  let err = null;\r\n  try {\r\n    result = await ShellEvaluator.customEval(originalEval, input, context, filename);\r\n  } catch (e) {\r\n    if (repl.isRecoverableError(e, input)) { // use isRecoverableError from node\r\n      return callback(new repl.Recoverable(e))\r\n    } else {\r\n      err = e\r\n    }\r\n  }\r\n  callback(err, result)\r\n};\r\n\r\nr.eval = customEval;\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nI currently just took out `isRecoverableError` and published it as [standalone](github.com/mongodb-js/is-recoverable-error) to get the same functionality. Ideally would be good to deprecate it and use exactly what's in node. ",
        "labels": "feature request",
        "id": 42940
    },
    {
        "title": "Support query parameters (and hash) in CLI paths",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nI am interested in having my scripts respond to arguments supplied by the calling file, rather than for the application as a whole (i.e., checking the likes of `new URL(import.meta.url).searchParams.get('someParam')` rather than `process.argv`).\r\n\r\nThis works well when a file imports another. In polyglot files too, it works to get the query string and hash in the browser (Chrome or Firefox at least) no matter whether the import originates in HTML or in JavaScript.\r\n\r\nBut I get a `MODULE_NOT_FOUND` error when trying the likes of:\r\n\r\n```shell\r\nnode --experimental-modules  index.mjs?someParam=1\r\n```\r\n\r\n...apparently as it is looking for a file here rather than a (portion of) a URL.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAllow the supplied file to be treated as a URL at least as far as the query string and any hash.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIt duplicates effort to add special `process.argv` handling (and it could interfere if the same file is used in an application which has a different root file yet checks `process.argv` as well as `import.meta.url`).\r\n\r\nThanks!",
        "labels": "feature request",
        "id": 42941
    },
    {
        "title": "Add --error-on-warn to vcbuild.bat",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nAdd the `--error-on-warn` flag that was introduced in https://github.com/nodejs/node/pull/32685 to vcbuild.bat\r\n\r\n**Describe the solution you'd like**\r\nWhen `--error-on-warn` flag is specified any compiler warnings should fail the build.\r\n\r\n",
        "labels": "feature request",
        "id": 42942
    },
    {
        "title": "respose.setHeader() should return response to allow chaining",
        "body": "Currently, response.setHeader() doesn't return anything. It really should simply return the response to allow chainings like `response.setHeader(xxx).send(yyy)`",
        "labels": "feature request",
        "id": 42943
    },
    {
        "title": "Unref FSWatcher",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, when you do `fs.watchFile(...)` the process will run forever.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA possibility to `watcher.unref()` would be great.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n```js\r\nconst watchFile = (path, callback, onError) => {\r\n\tlet previousTime = null;\r\n\r\n\tconst interval = setInterval(async () => {\r\n\t\ttry {\r\n\t\t\tconst {mtimeMs} = await stat(path);\r\n\r\n\t\t\tif (previousTime !== null && mtimeMs !== previousTime) {\r\n\t\t\t\tcallback(mtimeMs, previousTime);\r\n\t\t\t}\r\n\r\n\t\t\tpreviousTime = mtimeMs;\r\n\t\t} catch (error) {\r\n\t\t\tclearInterval(interval);\r\n\r\n\t\t\t// The error part is off the Node.js API\r\n\t\t\tonError(error);\r\n\t\t}\r\n\t}, 1000 * 60).unref();\r\n};\r\n```\r\n\r\nEdit: [seems like the code above is completely unnecessary :man_facepalming:](https://github.com/nodejs/node/issues/33096#issuecomment-620565757)",
        "labels": "feature request",
        "id": 42944
    },
    {
        "title": "Add riscv64 backend for node.js",
        "body": "Hi all,\r\n   I am a developer about v8 for riscv64  and v8 for riscv64  patch had been upstreamed into google repo. \r\n   I want to add support for node.js. I have build success locally.  \r\n   And what should i  do before opening a pr to submit it ? \r\n",
        "labels": "feature request",
        "id": 42945
    },
    {
        "title": "Command-line parameter to force \"module\" instead of \"commonjs\" type?",
        "body": "I'm aware that I can name a file with `.mjs` or set `\"type\": \"module\"` in package.json. I'm also aware of the `--input-type=module` CLI parameter.\r\n\r\nWhat I'm not understanding is, why isn't there a way to pass a parameter flag to force module interpretation for the `.js` file I specify? Was there a reason that `--input-type` can only be used with string input and not to control module interpretation of a `.js` file?\r\n\r\nI tried searching old issues to find this discussed but my searching failed me. I feel certain it must have been intentionally omitted, but I'm just trying to understand why?",
        "labels": "feature request",
        "id": 42946
    },
    {
        "title": "Configure post resolution aliasing",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nCurrently Policies can emulate much behaviors of import maps. However, I have identified that a specific kind of relative mapping such as an import map of the following form:\r\n\r\n```json\r\n{\r\n  \"scopes\": {\r\n    \"/\": {\r\n      \"./foo\": \"./foo/v1.js\"\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nCannot be emulated.\r\n\r\nThis is because import maps do not apply import map aliasing prior to url canonicalization. This is because without aliasing the only resolution applied for the web is url canonicalization. In terms of Loaders, this interception is applied after  a `resolve()` and uses either the original specifier if unable to resolve or the resolved resulting URL if able to resolve.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nPolicies currently only apply interception prior to canonicalization, but should allow interception after resolution. This likely needs to ensure any ESM Loader designs properly can compose against the feature. Current composition with Policies and Loaders is that Loaders are able to act both prior to and after policies as a delegated function call. It is my assumption that we can preserve this behavior as the following:\r\n\r\n```\r\n0. Given an import resolution request\r\n1. Apply current \"dependencies\" feature of policies\r\n  i. Resolve to string if target is a string\r\n  ii. Perform *node* resolution if target is `true`\r\n  iii. Error otherwise\r\n3. *NEW* apply ??? feature to alias the resolved path from #1 and/or #2\r\n```\r\n\r\nNote, with the feature design above a policy would not be able to intercept \"bare\" imports at the proper time to preempt the default *node* resolution algorithm. Perhaps a better design could be found.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nStill designing, open to any alternatives.",
        "labels": "feature request",
        "id": 42947
    },
    {
        "title": "Feature request: provide deep (recursive) fs.writeFile()",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nHaving to write the same boilerplate for writing a file to a directory that doesn't yet exist over and over again.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nIdeally, I'd be able to use `fs.writeFile()` (or `fs.writeFileSync()`) with the `{ recursive: true }` option that's available on [`fs.mkdir()`](https://nodejs.org/api/fs.html#fs_fs_mkdir_path_options_callback) and its friends.\r\n\r\n```\r\nconst path = require('path')\r\n\r\nconst resolvedPath = path.resolve('./somePath')\r\nconst data = {\r\n  some: 'data'\r\n}\r\n\r\nfs.writeFile(path, data, { recursive: true }, (error) => {\r\n  if (error) throw error\r\n})\r\n```\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\n- Checking if the directory exits recursively then writing the file if that succeeds\r\n  - This is annoying and frankly ugly boilerplate for a common operation.\r\n- Using community tooling\r\n  - Since this is an extension of a core method, I don't particularly feel great about taking on a third-party dependency to fill a gap so I can be relatively lazy. \r\n  - This is also an option that could theoretically benefit anyone writing files to a directory that may not exist. I think that filling that gap in our own API rather than pushing folks to community tools will be a win for end-users' time in addition to their dependency tree.",
        "labels": "feature request",
        "id": 42948
    },
    {
        "title": "Add abortSignal to every request handler",
        "body": "If you come from the world of Service Worker and acts a bit like a man in the middle by inspecting every network request that goes in and out  or you are working with the fetch api then you will see that the spec specifies that every Request has an associated AbortSignal.\r\n\r\n```js\r\n// you can construct one on your own\r\nnew window.Request('/').signal instanceof AbortSignal // yields true\r\n\r\n// FYI, this is not the same signal that have been passed in as an argument\r\nvar { signal } = new AbortController()\r\nnew window.Request('/', { signal }).signal === signal // yields false\r\n```\r\n\r\nNow what can this be used for? Well, getting things from the database or convert some file as long as the user is connected\r\nI think we should make the request handler a tiny bit more like the service worker by adding in a abortSignal into every request handler.\r\nI wish i could do something like: \r\n```js\r\nhttp.createServer((req, res) => {\r\n  mongodb.getUser(userId, { signal: req.signal })\r\n})\r\n\r\n// Same service worker equivalent \r\nself.on('fetch', evt => {\r\n  evt.respondWith(fetch(getUserRequest, { signal: evt.request.signal }))\r\n})\r\n```\r\nif a client abort or disconnect then so should the call for retrieving something from the database",
        "labels": "feature request",
        "id": 42949
    },
    {
        "title": "doc: DEP0066 is slightly incorrect",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v15.11.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux nuc 5.4.0-65-generic #73~18.04.1-Ubuntu SMP Tue Jan 19 09:02:24 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: http.ClientRequest\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/deprecations.html#deprecations_dep0066_outgoingmessage_prototype_headers_outgoingmessage_prototype_headernames\r\n\r\n## Description\r\n\r\n[DEP0066](https://nodejs.org/api/deprecations.html#deprecations_dep0066_outgoingmessage_prototype_headers_outgoingmessage_prototype_headernames) implies that using `OutgoingMessage.prototype.getHeaderNames()` is equivalent to the now deprecated `OutgoingMessage.prototype._headerNames` property which is not the case.\r\n\r\n`OutgoingMessage.prototype._headerNames` contains a mapping from lowercase to the exact header names that were sent with the request:\r\n\r\n```\r\n{authorization: \"Authorization\", host: \"Host\"}\r\n```\r\n\r\nWhere `OutgoingMessage.prototype.getHeaderNames()` returns only lowercase names.\r\n\r\nThe now deprecated `_headerNames` property is useful in http debug logging modules that print the exact header names being sent, as some servers are still picky about those. Not having access to the actual header names will make debugging harder, assuming node still sends the headers as they are sent through the `http.request` method.\r\n\r\nBesides the documentation being misleading about this I'd like to know if there is a way to access the headers being sent going forward, since `_headerNames` is now deprecated.",
        "labels": "feature request",
        "id": 42950
    },
    {
        "title": "ERR_MODULE_NOT_FOUND: add a property to exception object to hold failing import's argument",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI am developing a framework that uses node as a host for user scripts. The framework loads them dynamically with the async `import()` function, and the userscripts can also import other modules with `import` statement.\r\n\r\nWhen I call that `import()` function, I basically want to rethrow all errors thrown by it, **except** for one very specific condition: when the `import()` function fails with `ERR_MODULE_NOT_FOUND` because the userscript file itself wasn't present in the location just tried. The userscript might still be found in some other search path, which is why its absence in any given candidate location is not an error. If however the `import()` function failed with `ERR_MODULE_NOT_FOUND` because some **other** module **imported** by the userscript was not found, then I want to rethrow that error.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd a property to the exception object thrown for `ERR_MODULE_NOT_FOUND` that will hold the exact value of the argument that was given to the failing `import` function or statement.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI considered checking for existence first and then attempting to `import()`, but that is a known antipattern.\r\n\r\nI considered parsing the `message` or `stack` property, but that would be a hack. These properties are probably locale dependent and their format is not set in stone.\r\n\r\nI looked into custom loaders and found the subject difficult, scary, apparently indefinitely experimental, and an overkill for this particular purpose. I need a simple and reliable way.",
        "labels": "feature request",
        "id": 42951
    },
    {
        "title": "Transfer child process stderr/stdout to Worker?",
        "body": "Is/could it be possible to transfer the stderr/stdout fd of a child process (`child_process.spawn(...)`) to a Worker and have the worker read the output?\r\n\r\ni.e. instead of:\r\n\r\n```js\r\nconst proc = cp.spawn(...)\r\nconst worker = new Worker(..., { stdin: true })\r\nproc.stdout.pipe(worker.stdin)\r\n\r\n// Worker\r\n\r\nconst src = process.stdin\r\n```\r\n\r\nto do something like:\r\n\r\n```js\r\nconst proc = cp.spawn(...)\r\nconst worker = new Worker(..., { workerData: {fd: proc.stdout.fd }, transferList: [proc.stdout.fd] })\r\n\r\n// Worker\r\n\r\nconst src = something(workerData.fd) // Maybe new Socket({ fd })?\r\n```",
        "labels": "feature request",
        "id": 42952
    },
    {
        "title": "Lookup user name by uid, group name from gid, or vice-versa",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI would like to get \r\n* username from uid, or vice-versa\r\n* group name from gid, or vice-versa\r\n\r\nto show names in CLI app that handles files.\r\nIIUC, nodejs offers `fs.stat` or variants that can retrieve uid/gid, but these methods can not retrieve username/group name.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nI think `os` module is a good place to have these feature.\r\nI imagine interfaces something like:\r\n```javascript\r\nos.userid(\"john\") // returns 1001\r\nos.username(1001) // returns john\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nCurrently, I am using https://github.com/cinderblock/node-userid which provides id/name conversion.\r\nHowever, it lacks Windows OS support.\r\n",
        "labels": "feature request",
        "id": 42953
    },
    {
        "title": "late code injection",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, a node process cannot receive and execute custom code after it has started. For monitoring tools, a common use case is to be able to attach to an arbitrary process, inject a (tracing) code, instruct the runtime to execute that, and optionally detach from the process.\r\n\r\n**Describe the solution you'd like**\r\n - define a mechanism to interrupt the runtime (signals in platforms where supported)\r\n - specify a Javascript interface for the code injection:\r\n   - the signal is delegated to a Javascript handler function\r\n   - a module with a predefined name (such as `agent`) is loaded\r\n   - a function with a predefined name (such as `execute`) is executed\r\n   - a user can define this module and place it in the search path, prior to signalling\r\n   - upon completion, the module is unloaded\r\n - define security restrictions (only requests from matching UID / GID allowed)\r\n\r\n**Describe alternatives you've considered**\r\n - modify the application and integrate with the monitoring tools\r\n - define a specific function in the application that receives code at runtime\r\n\r\n",
        "labels": "feature request",
        "id": 42954
    },
    {
        "title": "Vendor Events on NPM",
        "body": "Context: https://github.com/browserify/events/issues/79\r\n\r\nIt would be useful if `events` was vendored in a similar way to `readable-stream`.\r\n\r\nI have brought this possibility up in the events repo https://github.com/browserify/events ( https://www.npmjs.com/package/events )\r\n\r\nThis should be pretty straightforward given `events` is _mostly_ self contained.\r\n\r\ncc @goto-bus-stop :) \r\n\r\n",
        "labels": "feature request",
        "id": 42955
    },
    {
        "title": "Load NODE_OPTIONS from a file",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nCurrently there are useful node options(https://nodejs.org/api/cli.html#cli_node_options_options) I would like to be able to easily specify project wide like `--max-old-space-size` and `--preserve-symlinks` but there is not really a way to do it through the repository only through `NODE_OPTIONS` or by specifying it by hand every time an npm script is defined which is not convenient for large sized monorepos.\r\n \r\n**Describe the solution you'd like**\r\nI would like to be able to specify those options in a file that, if present, `node` will try to read the options from it. The name could be for example `.node_options`. Each option will be specified per line and will override every other option specified through `NODE_OPTIONS` env var or directly passed when invoking the node binary.\r\n\r\n**Describe alternatives you've considered**\r\nRight now that is non easy way to accomplish the use case that I have.\r\n",
        "labels": "feature request",
        "id": 42956
    },
    {
        "title": "Add on/off to EventSignal?",
        "body": "Would if make sense to add on/off as aliases to addEventListener/removeEventListener?\r\n\r\nI'm ending up writing quite a bit of code that checks for either since usually I like to implement api's to support both EventEmitter and AbortSignal. Having the aliases would make code much easier and less error prone.",
        "labels": "feature request",
        "id": 42957
    },
    {
        "title": "Add functions to register \"then\" and \"catch\" handlers with promise",
        "body": "\r\n**Is your feature request related to a problem? Please describe.**\r\nI would like to be able to add \"then\" and \"catch\" handlers to promises that JS functions return to C++.\r\n\r\n**Describe the solution you'd like**\r\nI would like functions like this (obviously with naming subject to change):\r\n\r\n```c++\r\ntypedef void (*promise_success_callback)(napi_env env,\r\n                                         napi_value success_value,\r\n                                         void* data);\r\n\r\ntypedef void (*promise_failure_callback)(napi_env env,\r\n                                         napi_value error_value,\r\n                                         void* data);\r\n\r\nnapi_status napi_add_promise_success_callback(napi_env env,\r\n                                              napi_value promise,\r\n                                              promise_success_callback success_callback,\r\n                                              void* data);\r\n\r\nnapi_status napi_add_promise_failure_callback(napi_env env,\r\n                                              napi_value promise,\r\n                                              promise_failure_callback failure_callback,\r\n                                              void* data);\r\n```\r\nAn additional function could be\r\n\r\n```c++\r\ntypedef void (*promise_fulfilled_callback)(napi_env env,\r\n                                           napi_value error_value,\r\n                                           napi_value success_value,\r\n                                           void* data);\r\n\r\nnapi_status napi_add_promise_fulfilled_callback(napi_env env,\r\n                                                napi_value promise,\r\n                                                promise_fulfilled_callback fulfilled_callback,\r\n                                                void* data);\r\n```\r\nor\r\n\r\n```c++\r\nnapi_status napi_add_promise_fulfilled_callbacks(napi_env env,\r\n                                                 napi_value promise,\r\n                                                 promise_failure_callback failure_callback,\r\n                                                 promise_success_callback success_callback,\r\n                                                 void* data);\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nIn the meantime, I am using the `memcpy` trick to convert a `napi_value` promise to a v8::Promise and then using the v8::Promise::{Then|Catch} methods to handle the promise fulfillment.\r\n",
        "labels": "feature request",
        "id": 42958
    },
    {
        "title": "Built in cross-platform nodejs version manager",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\nNo.\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n`node update` command. Updates NodeJS whilst still keeping global modules installed. Has to be cross-platform.\r\nKinda like rustup, but, for NodeJS & cross platform\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\nnvm-windows except it breaks and make you re-install global packages.",
        "labels": "feature request",
        "id": 42959
    },
    {
        "title": "Special threat for outgoing information and for ingoing information trought IPC",
        "body": "Sockets for receiving information will have single threat special for itself, if information arrived on socked, data will be merged to main threat, same for outgoing sockets but there data will be send along with doing another process.\r\n\r\nOn those CPU's with some cores and twice as much threats, it could highly reduce latency of interprocess communication.\r\n\r\nPlease consider this as serious thing. Like that, you have l1 core, for both threats if I'm not correct correct me, but those data get diverged and merged at L1 cache instantly, and it'll work better.\r\n\r\nIf we have one process, that has something like input of 42k objects of simple graph nodes per second, and it have to deliver it to database, it's faster if receiving runs in one threat, sorting in another and sending in another... \r\n\r\nLike this, we can use Ryzen and Threadripper technologies of IPC that works on basis of streams, which is very efficient for stream processors, if they're split into various processes, and therefore we can achieve maximum of node's performance.\r\n\r\nEven for tasks like getting distribution of change from processor trough websockets, it's better, because distribution runs in single threat, and another threat on processor can still react on change or whatever, or it can actually change, while the alternative threat is delivering chance in cycles of threat syncs and split... \r\n\r\nEssentially, when you send to by socket, you read data that are arranged by set of pointers to be read from memory, now it's same threat in new node it can be another, therefore it just reads data that are not writtable, because if those data was written in there would be new pointer to their copy where write happened.\r\n\r\nWhere we're recieving, we got this one threat, that's pumping data into proccess, and on every sync, therefore something like one line of stdout to another stdin, can be being loading on one threat, while another is sorting just loaded data, therefore it's twice that fast.\r\n\r\nPlease code it, I don't orientate in this C++ mess node is. It's like function calls and stuff doesn't make sense to me and it'll take me like two weeks to code this, and I have better stuff to do.",
        "labels": "feature request",
        "id": 42960
    },
    {
        "title": "DNS: Add support for Recursion / Full Answer",
        "body": "dns.resolve() returns the final A answer. Often when there is a CNAME which is very common these days, it could be useful to see the full chain.\r\n\r\nThis issue is to suggest showing the full Answer in the response\r\n\r\n\r\nThe below code returns the A record \"13.234.176.102\"\r\nconst { Resolver } = require('dns').promises;\r\nconst resolver = new Resolver();\r\nresolver.setServers(['8.8.8.8']);\r\n\r\nresolver.resolve4('www.github.com').then((addresses) => {\r\n  console.log(addresses);\r\n});\r\n\r\ndig however shows the full/chain answer\r\n\r\n;; ANSWER SECTION:\r\nwww.github.com.         3600    IN      CNAME   github.com.\r\ngithub.com.             60      IN      A       13.234.210.38\r\n\r\nI am not able to fully figure out if this is easily supported by relying on c-ares's ares_mkquery() via the parameter rd or not\r\n",
        "labels": "feature request",
        "id": 42961
    },
    {
        "title": "[Feature] Expose getOptionValue via process.getOptionValue",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\n**Use case:** I'm trying to implement `\"exports\"` support inside the [PnP resolver](https://yarnpkg.com/features/pnp) which patches the Node resolution algorithm and I want it to be as Node-compliant as possible. For that, I need to implement the [resolving user conditions](https://nodejs.org/api/packages.html#packages_resolving_user_conditions) part via the `--conditions` flag. The problem is that Node gives me no easy way to access the resolved value of a flag (as far as I'm aware).\r\n\r\n**Problem:**\r\n\r\nNode option values can come from 2 different places (as far as I'm aware): the arguments passed to the node binary and `NODE_OPTIONS`.\r\n\r\nNode currently has an internal function called [`getOptionValue`](https://github.com/nodejs/node/blob/2af43f65055de2817eb7907d3a3d3b3a3de127f5/lib/internal/options.js#L8) that returns the value of an option, resolving both the arguments passed to the node binary and `NODE_OPTIONS`. \r\n\r\n`getOptionValue` is only exported in `internal/options`, so it can't be accessed.\r\n\r\nAlso, `getOptionValue` uses a native implementation via `getOptions` from the `options` internal binding which isn't whitelisted, so modules can't access it via `process.binding` to reimplement `getOptionValue`.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like a way to be able use `getOptionValue`, and the most straightforward way I could think of is exposing it on `process` via `process.getOptionValue`.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nManually parse both `process.execArgv` and `process.env.NODE_OPTIONS`.\r\n",
        "labels": "feature request",
        "id": 42962
    },
    {
        "title": "Buffer.alloc does not accept BigInt data type for \"size\" argument",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.5.0\r\n* **Platform**: Windows\r\n* **Subsystem**: none\r\n\r\n### What steps will reproduce the bug?\r\n\r\nPlease add support for BigInt data type to Buffer.alloc method.  The first argument of that method is for buffer size and it takes an integer, but only supports *number* data types.  BigInt value throws an error.\r\n\r\nhttps://nodejs.org/dist/latest-v15.x/docs/api/buffer.html#buffer_static_method_buffer_alloc_size_fill_encoding\r\n",
        "labels": "feature request",
        "id": 42963
    },
    {
        "title": "Feature request: packaged applications (WARC archives?)",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nWe're distributing Yarn as a single-file script. While it's great for accessibility, it has an impact on the boot time since Node needs to parse the whole file before even starting to execute it. Additionally, the file is larger than it needs to be because various binary payloads have to be encoded as base64.\r\n\r\n**Describe the solution you'd like**\r\n\r\nWe'd like to eventually distribute Yarn as a packaged application. Imagine an archive with the source code, and we would call this archive like any other. For Node, the archive would be treated as a directory: `node ./yarn.warc/index.js`. Given that [WARC](http://iipc.github.io/warc-specifications/) is on its path to standardization, it seems the most consensual choice.\r\n\r\n**Prior work**\r\n\r\nYarn already provides in-zip filesystem access for the packages it installs. If Node is interested to use Zip instead of WARC we could provide our implementation, which closely follow Node's APIs.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nSupporting the [`__halt_compiler`](https://www.php.net/manual/en/function.halt-compiler.php) directive would be another way to delegate this responsibility to userland. It would likely be much easier to implement, and would allow for greater flexibility, and tbh I'd very much prefer this approach. Unfortunately, it may require work on the parser level, and I think that would bring it to v8, possibly TC39 lands. Given that the context is almost exclusively relevant to Node, I'm worried it wouldn't go anywhere.",
        "labels": "feature request",
        "id": 42964
    },
    {
        "title": "REQ: custom configurability of the node module resolution algorithm",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nIn the JavaScript ecosystem, there are many problems that could, in theory, be fixed with custom user-defined module resolution configuration.\r\n\r\n- **Aliasing a module**\r\n  When aliasing a module, you must tell *every tool* that you use how to find an aliased module. For example, to switch a project from React to Preact (a high-level, common use-case), you must configure **Webpack**, **Typescript** (or alternatives e.g. Flow) if you use types, **Webpack** (or alternatives e.g. Snowpack) you use for bundling how to find the module, *Eslint** (or alternatives) on how to find the new module so you don't get IDE errors.\r\n  This divide in the ecosystem makes aliasing as a whole, very unfriendly and prone to errors.\r\n\r\n- **Ecosystem unity**\r\n  When attempting to import a resource, every tool much agree on how to find it (as mentioned previously). If you use **svgr**, a library to turn SVG into React components (a high-level, relatively common problem), every tool must agree on how to import it. If you use **Typescript**, you must create `.d.ts` files so that correct intellisense and typing can be provided. If you use a bundler such as **webpack**, you must tell it to use a loader to transform the svg files so that they can be bundled.\r\n\r\n- **Better monorepo support**\r\n  Attempting to make monorepos in JS (i.e. multiple projects sharing code) requires immense amounts of effort, and is not at all comparable to the beautiful experience you get from languages such as Rust or C#. In my experience, getting monorepos to work require cooperation from the package manager (which Yarn thankfully supports) and cooperation from your tooling. In my specific usecase, I have my source code in a `src` directory with `package.json` outside of it. By utilizing symlinks to point to the directory containing the package.json, I had to add `/src` to my import path to get tooling such as Typescript and Webpack to recognize where the code was. Despite attempting to use export maps, [this is not supported](https://github.com/microsoft/TypeScript/issues/33079).\r\n\r\n- **Solving node_modules**\r\n  With the ability to override the module resolution algorithm, `node_modules` would no longer need to be a painpoint for developers.\r\n\r\n  In today's world, `node_modules` is a source of frustration for many developers. It is very IO heavy to setup, it wastes a lot of space for a developer, and it can get out of sync with dependencies listed in `package.json`. By allowing the module resolution algorithm to be configurable, it would allow massive improvements to the ecosystem as a whole, as individual solutions to the problem could be made to work with the module resolution algorithm, and thus with any and all infrastructure that support the new configurable module resolution algorithm.\r\n  \r\n  For example, [Yarn PnP](https://classic.yarnpkg.com/en/docs/pnp/) is a solution to the node_modules problem, but lacks the ecosystem-wide compatibility to take off. Projects such as **pnpm** aren't perfect solutions but it does tackle the flattening of node_modules by utilizing symlinks in a way that node, and other projects that *properly implement* the node module resolution algorithm can find the modules. However, this is not without its drawbacks, as existing infrastructure that *improperly implements* the node module resolution algorithm [will break if the modules are not as it expects](https://github.com/pnpm/pnpm/issues/1496).\r\n\r\n**Describe the solution you'd like**\r\nMy suggestion to this problem is to have a `.resolve.js` file inside of `node_modules` that will execute to resolve the path for a module, that yields a single export with a function that, given the current script path and module name to be found, will yield a promise to the path to another path that is resolvable. For example, consider the following structure:\r\n\r\n```\r\n/node_modules/is-number/index.js\r\n/node_modules/.resolve.js\r\n/index.js\r\n```\r\n\r\n```js\r\n// /node_modules/is-number/index.js\r\nmodule.exports = (num) => {\r\n\treturn typeof num === \"number\"; // simple implementation for this example\r\n}\r\n```\r\n\r\n```js\r\n// .resolve.js\r\nmodule.exports = async function(moduleName, scriptPath) {\r\n\treturn `./${moduleName}/`\r\n};\r\n```\r\n\r\n```js\r\nconst isNumber = require(\"is-number\");\r\n\r\nconsole.log(isNumber(1));\r\nconsole.log(isNumber(\"not a number\"));\r\n```\r\n\r\nRunning `node /index.js` would roughly lead to the following code being executed\r\n\r\n```\r\nrequire(\"is-number\");\r\n-> /node_modules/.resolve.js\r\n-> require(\"./is-number/\")\r\n-> -> require(\"./is-number/index.js\")\r\n```\r\n\r\nThis solution offers 100% customizability of the code being required.\r\n\r\n**Describe alternatives you've considered**\r\nIdeally, a solution that is easily statically analyzable and thus easily implementable in languages without requiring a NodeJS runtime would be most ideal. However, due to the possible unforeseen innovations that may be created and require custom functionality AND requirement of other vendors implementing the changes Node has (which [we cannot expect vendors to do](https://github.com/microsoft/TypeScript/issues/33079)), it would be the simplest and most ecosystem-wide compatible have a JS file that executes to automatically resolve the paths of modules.\r\n\r\nThe asynchronous nature of the require code is so that asynchronous calls can be made rather than synchornous ones (i.e. `fs.readFile` vs `fs.readFileSync`), but given that `require` is synchronous this may have to be altered.\r\n\r\nThe reasoning for `.resolve.js` to be inside `node_modules` is that it's a file that shouldn't be committed - rather, package manages such as `yarn` or `npm` could auto generate this file. Perhaps it might be better to include it next to `package.json` so it does get committed however, as the current tooling environment doesn't seem very co-existant and other projects would likely require their own boilerplate to be inserted.\r\n\r\nThe path to the current script being an argument to the function is suggested so that implementing custom node_modules algorithms can be context aware about the caller. The usecase in mind that this would be useful for, is proper versioning support of modules. Consider the following scenario, where a project looks as such:\r\n\r\n```\r\n/node_modules/is-number/7.0.0/index.js\r\n/node_modules/is-number/6.0.0/index.js\r\n/node_modules/depends-on-is-number-6/index.js\r\n/node_modules/.resolve.js\r\n/index.js\r\n```\r\n\r\nThe dependency `depends-on-is-number-6` could make a call to `require(\"is-number\")`, and `.resolve.js` could yield `./is-number/6.0.0/index.js` to NodeJS and thus maintain a flat `node_modules` structure. A more realistic example, would be a package manager that stores several versions of their packages in a cache, and redirecting imports to the correct location.\r\n\r\nOverall, there's ***a lot*** of remaining bike-shedding to be done since this is something especially important to get right for ecosystem unity, however it'd all be for naught if this idea is deemed unworthy.",
        "labels": "feature request",
        "id": 42965
    },
    {
        "title": "Provide an easy utility to issue a HTTP redirect + HTTP2 server push",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nHTTP2 server push is underutilized. I am realizing that it is hard to realize all the places where one could use it. One thing where I see it being useful almost always by default is to minimize the latency which happens after a HTTP redirect. HTTP redirect means that there is additional 2 hop latency before real data starts getting to the client. We can minimize that to 1 hop if at the same time as we issue a HTTP redirect, we also start pushing the HTTP response of the URI to which the HTTP redirect goes.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI suggest that `http.ServerResponse` gets additional method like `redirect` which sets relevant HTTP header in the response, but also that if the connection is HTTP2 connection, starts pushing the response (if the redirect target is local server).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThis could be implemented in a library, but I think having tighter support for HTTP2 in node core would be better to popularize it.",
        "labels": "feature request",
        "id": 42966
    },
    {
        "title": "WebAssembly compiled module cache",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nLarge WASM modules take a while to compile, impacting startup times. Browsers solve this problem by caching compiled module data.\r\n\r\nWebAssembly is a promising media for software distribution. It makes sense to compile for WebAssembly once, instead of shipping multiple binaries for each supported CPU architecture / OS pair, doesn't it? There's a growing number of tools targeting this particular segment, e.g. https://wasmer.io.\r\n\r\nNode.js has unique advantages as a WASM runner:\r\n\r\n * WASI as a standardised interface for interfacing with the OS (e.g. accessing files, etc.) is insufficient for most practical needs. With Node, one can leverage a plethora of high quality battle-tested cross platform libraries.\r\n\r\n * V8 is top notch! It beats competing WASM engines in terms of compile times, resource consumption and the footprint of compiled WASM files (a single data point: V8 produces 160MiB for a 50MiB WASM file, a competitor generates 1+GiB).\r\n\r\n * NPM is super robust. Competitors have their own package managers but not particularly reliable ones.\r\n\r\nThe only component missing in Node.js is a compiled module cache.\r\n\r\nIt takes 47s to compile the previously mentioned 50MiB WASM file. With a cache POC, the startup time is reduced to under 1s.\r\n\r\n**Describe the solution you'd like**\r\n\r\n```js\r\nrequire('wasm/cache').loadFile('module.wasm')\r\n```\r\n\r\nas a cache-enabled moral equivalent of\r\n\r\n```js\r\nWebAssembly.compile(require('fs').readFileSync('module.wasm'))\r\n```\r\n\r\nCache files to be stored in OS-mandated cache directory, e.g. `~/.cache/node/wasm-cache` on Linux.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIt used to be possible to serialise a WebAssembly module to a file explicitly. #18265\r\n\r\nIt stopped working since Node.js 13 due to changes in V8 and there's no way to make it work again.\r\n\r\nInstead of introducing a new API, it is possible to enhance `WebAssembly.compile`/`WebAssembly.compileStreaming`. Unfortunately, it's hard to come up with a good cache key. We could `sha256` the data, but that's inefficient.",
        "labels": "feature request",
        "id": 42967
    },
    {
        "title": "Flag to disable const enforcement",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThis sounds silly as I'm the biggest cheerleader for `const` but I do run into one situation.\r\n\r\nI like to do repl-driven-development where I have my code file along with a side-by-side repl that I can throw lines or regions to with a keystroke. Unfortunately, if the line in question uses `const`, this will fail since I'm trying to redeclare `const`.\r\n\r\n**Describe the solution you'd like**\r\nI would like to be able to add a flag to this nodejs session - perhaps `--loose-declarations` or `--const-and-let-as-var` and have `const` (and ideally `let`) work the same as `var`\r\n\r\n**Describe alternatives you've considered**\r\nAlternately, this could be set with an environment variable or simply be the default in repl sessions. It would be great to get it rolled into v8 and have it also work in devtools on web, but that's probably asking too much",
        "labels": "feature request",
        "id": 42968
    },
    {
        "title": "[FR] Support linking against dynamic runtime for library builds",
        "body": "I do not see a build option to instruct the compiler to build using dynamic runtime dll's (i.e. /MD).  It just defaults to static.  This makes it very difficult to integrate with projects that are configured for dynamic runtimes.  To clarify, I am using vcbuild.bat to launch configure.py",
        "labels": "feature request",
        "id": 42969
    },
    {
        "title": "doc: Expect nodejs doc site to have an api search feature.",
        "body": "",
        "labels": "feature request",
        "id": 42970
    },
    {
        "title": "fs.readSync & fs.read position argument does not support BigInt",
        "body": "* **Version**: v14.10.1\r\n* **Platform**: Linux edef72861714 4.14.152-127.182.amzn2.x86_64 #1 SMP Thu Nov 14 17:32:43 UTC 2019 x86_64 GNU/Linux\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nreadSync(reader, buffer, 0, 12, BigInt(position))           \r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEverytime.\r\n\r\n### What is the expected behavior?\r\n\r\nIt should read from the position in the file, and it will if you use `Number(position)` on a BigInt position.\r\n\r\n### What do you see instead?\r\n\r\nThe call reads data into the buffer but it begins at position 0 in the file instead of at the position noted in the BigInt.",
        "labels": "feature request",
        "id": 42971
    },
    {
        "title": "[FR] Simple standard IO processing (see also V8's `readline` and `print`)",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nHello, I'd like to suggest Node to adopt some sort of a simple way to process standard io.\r\n\r\nC has\r\n\r\n```c\r\n#include <stdio.h>\r\n\r\nint x;\r\nchar* s;\r\nscanf(\"%d %s\", &x, &s);\r\nprintf(\"%d %s\", x, s);\r\n```\r\n\r\nC++ has\r\n\r\n```cpp\r\n#include <iostream>\r\nusing namespace std;\r\n\r\nint x;\r\nstring s;\r\ncin >> x >> x;\r\ncout << x << \" \" << s;\r\n```\r\n\r\nand many more languages alike.\r\n\r\nThe point being -- it's fast and simple. Why would you need that? Well, there are cases where processing standard input (and output) should be as simple and as quick as possible -- simple one-off scripts and also competitive programming contests.\r\n\r\nFor example, the defacto competitive programming platform \"codeforces\" allows node as one of it's languages, and actually uses V8 to run the submitted solution under the hood ([example submission](https://codeforces.com/contest/1199/submission/58184695)).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nUsing V8 is better than the shenanigans you need to do with nodejs today;\r\n\r\nIt's simpler, but could still be improved:\r\n\r\n```js\r\nlet line = readline().split(\" \"); // must also assume that both inputs were on the same line, only separated by a single space :/  \r\nlet x = parseInt(line[0], 10);\r\nlet y = line[1];\r\nprint(x, y);\r\n```\r\n\r\nThis solution from V8 helps -- in a competitive programming setting, you avoid the need to write your solution twice -- once using node's `readline` utility way while debugging locally, and then rewriting it to work with V8's `readline` before submitting.\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe issue here is that V8 is not even closely as popular as node to the average user, and compiling it takes a lot.\r\n\r\nHaving the utility in node would be definitely provide better DX. And I think we don't necessarily need to have the same exact `readline` utility as V8 -- it'd be incompatible anyway, right?\r\n\r\nI was thinking about global utility function(s) to process IO the same way C/C++ and many other languages have -- read one thing until you see any amount of spaces (`\\s` `\\n` `\\t` etc.), ignore the spaces and if called again - read the next meaningful input. Additionally, having an automatic (type-inferred) or a manual yet simple way to parse the input's type (string / number etc.) would be amazing!\r\n\r\n",
        "labels": "feature request",
        "id": 42972
    },
    {
        "title": "POSIX fork and node ",
        "body": "Given https://chromium-review.googlesource.com/c/v8/v8/+/2416501 is soon to be merged we could start exploring native POSIX fork support for node (under some experimental flag - single threaded platform does come with some limitation) \r\n\r\nI was wondering if this is something the community is interested in. \r\n\r\nNote I maintain https://github.com/rubyjs/mini_racer where I very much need this feature, but I could imagine the node community may (or may not) also be interested in this feature.",
        "labels": "feature request",
        "id": 42973
    },
    {
        "title": "querystring.stringify does not support BigInt",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\n```js\r\n> querystring.stringify({a: 12345678901234567n})\r\n'a='\r\n```\r\n\r\nit should print `a=12345678901234567`\r\n\r\n**Describe the solution you'd like**\r\n\r\nsupport `bigint` in additional to `string`, `number` and `boolean`.\r\n\r\ni.e., in [`stringifyPrimitive`](https://github.com/nodejs/node/blob/39a7f7663e8f70fc774105d8fa41b8e4cc69149f/lib/querystring.js#L158-L166) encode any value where `typeof v  == 'bigint'` as `'' + v`, the same as `'number'`.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo.\r\n",
        "labels": "feature request",
        "id": 42974
    },
    {
        "title": "feature request: raw curves",
        "body": "See: https://github.com/nodejs/node/discussions/36000",
        "labels": "feature request",
        "id": 42975
    },
    {
        "title": "Allow specifying static libraries",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThere's no *problem*/blocker that this feature request would solve. Currently, there exists `configure` options that allow specifying paths to shared libraries for c-ares, openssl, and others.\r\n\r\nWith the `--fully-static` option, it would save compilation time to allow also allow specifying paths to pre-existing static libraries of dependencies, and also set appropriate include paths.\r\n\r\n**Describe the solution you'd like**\r\nPerhaps something more like how CMAKE works (I'm not a CMAKE fan myself, but they do handle this aspect well) where the `configure` script will search system-installed libraries for node's dependencies and apply the compilation options accordingly if it finds them.\r\n\r\nOtherwise, provide `configure` options like those given for other dependencies that allow specifying the path to the static libraries.\r\n\r\nWould this also require modifications to the include paths? Would it be safe to assume /usr/include works? I'm not sure how platform-dependent the `configure` script becomes at this point.\r\n\r\n**Describe alternatives you've considered**\r\nI had started digging into the individual `ninja` files I had generated post-`configure`. But there's just so many `ninja` targets and it is far too easy to miss specifying a static library while performing a link step or an include path for compiling amidst all these ninja files.\r\n",
        "labels": "feature request",
        "id": 42976
    },
    {
        "title": "Need access to uv_backend_fd on windows",
        "body": "In the context of [node-gtk](https://github.com/romgrk/node-gtk), I need acces to the `uv_backend_fd()` value. On the microsoft windows operating system, the current version of libuv doesn't return an appropriate value. The master branch of libuv however contains what is needed to retrieve the windows equivalent. What would it take to upgrade to the next version of libuv?\r\n\r\nRelevant discussions:\r\n - https://github.com/libuv/libuv/pull/1007\r\n - https://github.com/libuv/libuv/issues/1597\r\n - https://github.com/romgrk/node-gtk/issues/241",
        "labels": "feature request",
        "id": 42977
    },
    {
        "title": "A C++ API for near heap limit notification",
        "body": "For context see the twitter thread https://twitter.com/JoyeeCheung/status/1319346028076621825\r\n\r\nThis needs to be implemented by us because V8 replaces the callback if you add another one from C++, so the users may step on our toes since our timing of adding and removing these callbacks should be opaque to them. And this should be a C++ API because returning to JS execution in the callback (which is usually triggered during GC) is unsafe.",
        "labels": "feature request",
        "id": 42978
    },
    {
        "title": "fs: add cp method",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWhenever I need to copy a directory to another destiny, I need to use an alternative library to do this.\r\n\r\n**Describe the solution you'd like**\r\nAdd cp (Unix Name) method to fs, with the same utility of [cp Unix](https://en.wikipedia.org/wiki/Cp_(Unix)), he can be like:\r\n\r\n| Parameters                |\r\n|------------------------|\r\n| src: PathLike              |\r\n| dest: PathLike            | \r\n| options: CpOptions   | \r\n\r\n**Describe alternatives you've considered**\r\nLibrary [npc](https://github.com/AvianFlu/ncp) and [fs-extra](https://github.com/jprichardson/node-fs-extra).\r\n",
        "labels": "feature request",
        "id": 42979
    },
    {
        "title": "Enable Dark Mode for NodeJS docs",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nPlease enable dark mode for [node docs](https://nodejs.org/api/) like the [nodejs.dev](https://nodejs.dev/learn) website.\r\n\r\n",
        "labels": "feature request",
        "id": 42980
    },
    {
        "title": "Support for executing Node.js fs functions as sudo ",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nThe inability to execute Node.js `fs` functions with sudo (as admin) limits the applications built on Node.js. Nowadays, a lot of applications are built with Electron (which comes with Node.js), This feature would allow us to build more advanced apps with Node.js.\r\n\r\n**Describe the solution you'd like**\r\nExample;\r\n\r\n1. A function executed with option `asAdmin: true` requests the system password dialog:\r\n```\r\nfs.readdirSync('/media/sharedDrive/', { asAdmin: true, adminAccessTimeout: 15 * 1000 * 60 })\r\n```\r\n2. User enters their password\r\n3. On success, execute the function with admin rights.\r\n\r\n**Describe alternatives you've considered**\r\nN/A",
        "labels": "feature request",
        "id": 42981
    },
    {
        "title": "Provide getSource method that supports both es-module and commonjs",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI am developing a build tool similar to [vite](https://github.com/vitejs/vite). I need to obtain the source code of the module according to the requested module path or module name. If it is es-module, it will return directly, if it is commonjs, it will be converted to es-module through rollup and then returned.\r\n\r\nTherefore, I need a method that can resolve module source code on demand based on module path or module name. My assumption is as follows:\r\n\r\n##### 1ï¼ŒAdd the features of returning the source code in the import method\r\n```js\r\n// import lodash from \"lodash\"\r\nconst code = await import(\"lodash\").then(r=>r.code());\r\n\r\n// or:  import get from \"lodash/get\"\r\nconst code = await import(\"lodash/get\").then(r=>r.code());\r\n\r\n// or:  import { get } from \"lodash\"\r\nconst code = await import(\"lodash\").then(r=>r.get).then(r=>r.code());\r\n\r\n// or:  import * as _ from \"lodash\"\r\nconst code = await import(\"lodash\").then(r=>r.all()).then(r=>r.code());\r\n\r\n\r\n// and then\r\nif(!code.isEsModule()){\r\n   // rollup transform to es-module...\r\n}\r\n\r\n// cache code, no more need to transform for next time...\r\n\r\n```\r\n\r\n##### 2ï¼ŒProvide new methods to support this feature\r\n```js\r\nconst code = await getSource(\"lodash\");\r\n...\r\n// same as above\r\n```\r\nI noticed that in the latest document, node provides a similar getSource method to obtain module code, but it only supports es-module, and it is not yet mature.\r\n\r\nIf this feature is supported, a new build tool will soon appear on the front end, similar to [vite](https://github.com/vitejs/vite) and [snowpack](https://github.com/pikapkg/snowpack), and people will abandon the bulky and slow webpack.\r\n\r\nHope team can provide perfect support.\r\n\r\n",
        "labels": "feature request",
        "id": 42982
    },
    {
        "title": "Add a way to \"unhandle\" unhandledRejection",
        "body": "I've been making a little cancellation solution for some of my own code, and would like a mechanism to be able to abort functions by way of cancellation.\r\n\r\nI've been modeling it somewhat on `AbortController`/`AbortSignal`/`AbortError`, but I have a bit of a problem when it comes to the error part.\r\n\r\nIn particular, I would like to be able to define a `CancellationError`, which does not trigger unhandled rejection.\r\n\r\nIn the browser this is fairly simple enough as one can do:\r\n\r\n```js\r\nclass CancellationError {\r\n  // ...\r\n}\r\n\r\n// this ensures any cancelled promises that are discarded do not trigger an unhandledrejection\r\nwindow.addEventListener('unhandledrejection', (event) => {\r\n  if (event.reason instanceof CancellationError) {\r\n    event.preventDefault();\r\n    event.stopImmediatePropagation();\r\n  }\r\n});\r\n```\r\n\r\nHowever in Node, I'm not sure how to emulate this, as without a mechanism like `event.preventDefault()` we can't easily have a way to continue with the default behaviour if the reason is not a `CancellationError`.\r\n\r\nI'd like to propose adding some mechanism to continue with the default behaviour of the `unhandledRejection` event (or at least continue to the next listener). Perhaps something like:\r\n\r\n```js\r\nprocess.on('unhandledRejection', (reason, _promise, retrigger) => {\r\n  if (reason instanceof CancellationError) {\r\n    // If a CancellationError then we can simply throw away the promise\r\n    return;\r\n  }\r\n  retrigger(); // Otherwise continue with the default behaviour set by --unhandledRejections\r\n});\r\n```",
        "labels": "feature request",
        "id": 42983
    },
    {
        "title": "Allow to ensure a process will exit and warn for remaining async operations if any",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nWhen you write a complex node program, with a lot of lib & external service usage (databases...), you still want your process to exit cleanly.\r\nThe recommended way is of course to stop all async actions, active connection & socket listen and let the process stop\r\n```javascript\r\nasync onSignal() {\r\n    try {\r\n        await server.stop();\r\n        await database.stop();\r\n\r\n        console.log('All resources cleaned up, process should now exit');\r\n        // Process should now exit\r\n    } catch (e) {\r\n        // Undefined behaviour\r\n        console.error(e);\r\n        process.exit(1);\r\n    }\r\n}\r\n```\r\n\r\nSometimes, because of badly cleaned resources, the process won't exit at all. This could lead to service degradation, as the process won't restart until it's stopped, but is not responding to user requests anymore.\r\n\r\nIt might then be tempting to add a `process.exit()` at the end of the normal stop process. It would solve the service degradation issue, but also hides the underlying issue (service not cleaned up).\r\n\r\nIn my experience, those issues mostly happen in production, with resources not cleaned after database / upstream service reconnection due to network errors and long running processes. Those issues are not easily reproducible in a test environment.\r\n\r\n**Describe the solution you'd like**\r\nI would see 2 possible solutions:\r\n * Have a `process.ensureExit()` function, that would check for remaining async operations, warn if there is any, and exit anyway.\r\n * Have a `process.tryExit()` function, that would throw if a clean exit is not possible, letting the user handle this case (writing special logs, more clean-up attempts...)",
        "labels": "feature request",
        "id": 42984
    },
    {
        "title": "Update HTTP/2 server settings after `.listen()`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently it is possible to create an HTTP/2 in the following way:\r\n\r\n```js\r\nconst server = http2.createSecureServer({\r\n\tsettings: {\r\n\t\tmaxConcurrentStreams: 1000\r\n\t},\r\n\tkey,\r\n\tcert\r\n});\r\n```\r\n\r\nLet's assume you're having a server and it detected it's low on resources. Limiting `maxConcurrentStreams` could have a positive impact. Unfortunately it's not possible at the moment.\r\n\r\n**Describe the solution you'd like**\r\n\r\n```js\r\nserver.updateSettings({\r\n\tmaxConcurrentStreams: 100\r\n});\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNone yet.\r\n",
        "labels": "feature request",
        "id": 42985
    },
    {
        "title": "Enable building with shared uvwasi library.",
        "body": "Nodejs depends on uvwasi, libuv, brotli.  It can be build to use the shared-libraries for libuv, ICU, brotli, c-ares.\r\n\r\n* Enable building with shared uvwasi library.",
        "labels": "feature request",
        "id": 42986
    },
    {
        "title": "Feature Request: sync and async zlib.* instances without streams",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI have a need to inflate/deflate chunks of data and get the result immediately/easily. The streaming interface makes this a bit cumbersome and has caused issues in the past (e.g. the changing of flushing behavior with multiple writes within a major node version).\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe solution I'd like would essentially be a hybrid between `zlib.Deflate`/`zlib.Inflate`/etc. and the one-off `zlib.*` functions. It would be like the `zlib.Deflate`/`zlib.Inflate` instances in that it would keep a zlib context around for reuse, but like the one-off functions in that it would only be used to process a single chunk. You could almost put this feature inside the one-off functions and just allow them to accept a pre-created zlib context (another API would need to be added to do this too).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI'm currently having to use the streaming interface which is less than ideal to say the least and is more prone to regressions because of the additional machinery (streams) involved. However I really do not want to have to maintain this extra complexity.\r\n\r\nI've also considered just writing some binding code to do what I want, but I'd rather not have to force end users to have to compile to be able to use compression in my project, especially for something that should be easily achievable in node.",
        "labels": "feature request",
        "id": 42987
    },
    {
        "title": "Feature request: ChildProcess 'spawn' event",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nAfter calling `child_process.spawn`, I'd like to know when the child process has successfully spawned and there's no longer the possibility of an 'error' event from failing to spawn (i.e. error type # 1 in [the docs for that 'error' event](https://nodejs.org/api/child_process.html#child_process_event_error), e.g. `EPERM`, `ENOENT`).\r\n\r\nCurrently I just wait 100 milliseconds (after calling `child_process.spawn`), and if the child process hasn't emitted an 'error' event by that time, I assume it spawned successfully. My code looks something like this:\r\n\r\n```js\r\nconst { spawn } = require('child_process');\r\nconst { promisify } = require('util');\r\nconst { once } = require('events');\r\nconst timeout = promisify(setTimeout);\r\n\r\nasync function doSomethingWithChildProcess(){\r\n  const subprocess = spawn(...spawnArgs));\r\n  await Promise.race([\r\n    timeout(100),\r\n    once(subprocess, 'error').then(([error]) => Promise.reject(error))\r\n  ]);\r\n  // now do something with the running child process...\r\n}\r\n```\r\n\r\nThis seems to work, but I'm not sure how reliable it is, and anyways, it is certainly a hack. \r\nI'm wondering if there could be a better (more correct) way..\r\n\r\n\r\n**Describe the solution you'd like**\r\n\r\nIs there some point of execution in Node where we know there was no error spawning the child process?\r\n\r\nIf so, we could introduce a new 'spawn' event for the [ChildProcess class](https://nodejs.org/api/child_process.html#child_process_class_childprocess), to be emitted at that point in execution?\r\n\r\nThat would remove the need for the unreliable hack I described above.\r\n\r\nIt would also work nicely with Node.js's [`events.once` function](https://nodejs.org/api/events.html#events_events_once_emitter_name). For example, the code from above could be updated like this:\r\n\r\n```diff\r\n const { spawn } = require('child_process');\r\n-const { promisify } = require('util');\r\n const { once } = require('events');\r\n-const timeout = promisify(setTimeout);\r\n\r\n async function doSomethingWithChildProcess(){\r\n   const subprocess = spawn(...spawnArgs);\r\n-  await Promise.race([\r\n-    timeout(100),\r\n-    once(subprocess, 'error').then(([error]) => Promise.reject(error))\r\n-  ]);\r\n+  await once(subprocess, 'spawn');\r\n   // now do something with the running child process...\r\n }\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nJust the hack I described above (of expecting any error spawning to happen within 100 milliseconds of calling `child_process.spawn`).\r\n\r\nI can't think of any other possible solutions at this time.",
        "labels": "feature request",
        "id": 42988
    },
    {
        "title": "module: improve error decoration for cjs named exports for multi-line import statements",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.11.0\r\n* **Platform**: Darwin *** 19.6.0 Darwin Kernel Version 19.6.0: Thu Jun 18 20:49:00 PDT 2020; root:xnu-6153.141.1~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: modules\r\n\r\n### What steps will reproduce the bug?\r\n\r\nFailing test can be found here: https://github.com/ctavan/node/commit/ba9e73414eb5181873332da917defc25d1034afa\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n\r\nWhen trying to import named exports from a CommonJS module, there's usually a helpful error message which is assembled here: https://github.com/nodejs/node/blob/ed8af4e93831d3cf21d5562e900371d796b5fa20/lib/internal/modules/esm/module_job.js#L102-L124\r\n\r\n### What do you see instead?\r\n\r\nWhen using multi-line import statements like:\r\n\r\n```js\r\nimport {\r\n  comeOn,\r\n  rightNow,\r\n} from './fail.cjs';\r\n```\r\n\r\nthe following regex does not match:\r\n\r\nhttps://github.com/nodejs/node/blob/ed8af4e93831d3cf21d5562e900371d796b5fa20/lib/internal/modules/esm/module_job.js#L112\r\n\r\nand the following error is produced:\r\n\r\n```\r\nTypeError: Cannot read property '0' of null\r\n      at ModuleJob._instantiate (internal/modules/esm/module_job.js:112:77)\r\n      at async ModuleJob.run (internal/modules/esm/module_job.js:137:5)\r\n      at async Loader.import (internal/modules/esm/loader.js:165:24)\r\n      at async rejects.name (file:///***/node/test/es-module/test-esm-cjs-named-error.mjs:56:3)\r\n      at async waitForActual (assert.js:721:5)\r\n      at async rejects (assert.js:830:25),\r\n```\r\n\r\n### Additional information\r\n\r\nI would love to contribute a fix for this issue, however I need some guidance on how to proceed. The problem I see is that the full error stack only contains the first line of the multi-line import statement:\r\n\r\n```js\r\n[\r\n  'file:///***/node/test/fixtures/es-modules/package-cjs-named-error/multi-line.mjs:2',\r\n  '  comeOn,',\r\n  '  ^^^^^^',\r\n  \"SyntaxError: The requested module './fail.cjs' does not provide an export named 'comeOn'\",\r\n  '    at ModuleJob._instantiate (internal/modules/esm/module_job.js:98:21)',\r\n  '    at async ModuleJob.run (internal/modules/esm/module_job.js:141:5)',\r\n  '    at async Loader.import (internal/modules/esm/loader.js:165:24)',\r\n  '    at async rejects.name (file:///***/node/test/es-module/test-esm-cjs-named-error.mjs:56:3)',\r\n  '    at async waitForActual (assert.js:721:5)',\r\n  '    at async rejects (assert.js:830:25)'\r\n]\r\n```\r\n\r\nSo while the goal of the additional error decoration which was added in #33256 seems to be to provide a copy & pastable solution, I don't see how this could be achieved with the error information at hand when the error comes from a multi-line import statement.\r\n\r\nOptions that come to my mind:\r\n- Just resort to the original error?\r\n- Skip the example if it cannot be generated from the error stack, see: https://github.com/ctavan/node/commit/248eadadaf218088624f4c237a29befcc9dae66c\r\n- Produce something like the following, even though it's incomplete:\r\n    ```js\r\n      import pkg from './fail.cjs';\r\n      const { comeOn } = pkg;\r\n    ```\r\n- Produce the correct example, which would probably involve using an actual parser to read the full failing import statement.\r\n\r\n/cc @MylesBorins",
        "labels": "feature request",
        "id": 42989
    },
    {
        "title": "createReadStream/createWriteStream should support FileHandle",
        "body": "Currently only raw file descriptors are supported. Should we allow for a `FileHandle` to be passed as `fd`?",
        "labels": "feature request",
        "id": 42990
    },
    {
        "title": "better esm interop without package.json",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nThe problem is that many ESM codebases do use .js endings and no additional package.json inside the ESM build this makes them out of the box not useable via npm install \r\n\r\n**Describe the solution you'd like**\r\nSimply try to use ESM by Default and only if that fails try to require. stop warning like this should be commonjs module'\r\n\r\n\r\n**Describe alternatives you've considered**\r\nA good alternate would be to allow import myStuff from 'mypackage/file.js#!esm' in the url of the module to simply indicate that we want to load it as ESM\r\n\r\n\r\nAt present you can not run much esm code inside nodejs.",
        "labels": "feature request",
        "id": 42991
    },
    {
        "title": "add convenience-event \"readall\" to emit entire responseText from http.IncomingMessage",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\ni want to simplify parsing short text/json messages from http-requests w/o chunk-parsing boilerplate (precedent in browser-env: `XMLHttpRequest.responseText` and `await fetch(<url>).json()`\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\nhere is a working polyfill to patch `http.IncomingMessage.prototype.addListener` with `readall` event:\r\n\r\n```javascript\r\n\"use strict\";\r\n// readall-polyfill\r\n(function readallPolyfill() {\r\n    let addListenerNew;\r\n    let addListenerOld;\r\n    let http;\r\n    http = require(\"http\");\r\n    addListenerOld = http.IncomingMessage.prototype.addListener;\r\n    addListenerNew = function (...argList) {\r\n    /*\r\n     * this function will extend addListener with new readall-evt\r\n     * example: response.on(\"readall\", function (responseText) {...});\r\n     */\r\n        let callback;\r\n        let chunkList;\r\n        let evt;\r\n        let isText;\r\n        [\r\n            evt, callback\r\n        ] = argList;\r\n        // default-handling\r\n        if (evt !== \"readall\") {\r\n            return addListenerOld.apply(this, argList);\r\n        }\r\n        // handle text-encoding\r\n        isText = this._readableState.decoder;\r\n        // handle readall-evt\r\n        chunkList = (\r\n            isText\r\n            ? \"\"\r\n            : []\r\n        );\r\n        this.on(\"data\", function (chunk) {\r\n            if (isText) {\r\n                chunkList += chunk;\r\n            } else {\r\n                chunkList.push(chunk);\r\n            }\r\n        });\r\n        this.on(\"end\", function () {\r\n            callback(\r\n                isText\r\n                ? chunkList\r\n                : Buffer.concat(chunkList)\r\n            );\r\n        });\r\n    };\r\n    http.IncomingMessage.prototype.addListener = addListenerNew;\r\n    http.IncomingMessage.prototype.on = addListenerNew;\r\n}());\r\n\r\n// test with setEncoding()\r\nrequire(\"https\").request(\"https://www.example.com\", function (res) {\r\n    res.setEncoding(\"utf8\");\r\n    res.on(\"readall\", function (responseText) {\r\n        console.log(\r\n            responseText.slice(0, 10)\r\n        );\r\n        // stdout - \"<!doctype \"\r\n    })\r\n}).end()\r\n\r\n// test with JSON.parse\r\nrequire(\"https\").request(\"https://registry.npmjs.org/\", function (res) {\r\n    res.on(\"readall\", function (responseRaw) {\r\n        let responseJson;\r\n        responseJson = JSON.parse(responseRaw);\r\n        console.log({\r\n            db_name: responseJson.db_name,\r\n            doc_count: responseJson.doc_count\r\n        });\r\n        // stdout - \"{ db_name: 'registry', doc_count: 1802108 }\"\r\n    })\r\n}).end()\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\nhere is above test-code using vanilla nodejs, where i have to deal with chunk-parsing boilerplate\r\n```javascript\r\n\"use strict\";\r\n\r\n// test with setEncoding() with chunk-parsing boilerplate\r\nrequire(\"https\").request(\"https://www.example.com\", function (res) {\r\n    res.setEncoding(\"utf8\");\r\n\r\n    // chunk-parsing boilerplate - start\r\n    let responseText;\r\n    responseText = \"\";\r\n    res.on(\"data\", function (chunk) {\r\n        responseText += chunk;\r\n    });\r\n    // chunk-parsing boilerplate - end\r\n\r\n    res.on(\"end\", function () {\r\n        console.log(\r\n            responseText.slice(0, 10)\r\n        );\r\n        // stdout - \"<!doctype \"\r\n    })\r\n}).end()\r\n\r\n// test with JSON.parse with chunk-parsing boilerplate\r\nrequire(\"https\").request(\"https://registry.npmjs.org/\", function (res) {\r\n\r\n    // chunk-parsing boilerplate - start\r\n    let responseRaw;\r\n    responseRaw = [];\r\n    res.on(\"data\", function (chunk) {\r\n        responseRaw.push(chunk);\r\n    });\r\n    // chunk-parsing boilerplate - end\r\n\r\n    res.on(\"end\", function () {\r\n        let responseJson;\r\n        responseJson = JSON.parse(Buffer.concat(responseRaw));\r\n        console.log({\r\n            db_name: responseJson.db_name,\r\n            doc_count: responseJson.doc_count\r\n        });\r\n        // stdout - \"{ db_name: 'registry', doc_count: 1802108 }\"\r\n    })\r\n}).end()\r\n```\r\n",
        "labels": "feature request",
        "id": 42992
    },
    {
        "title": "child_process.execSync should return object with std of plain stdout",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI wanted to run sequentially a series of processes and check their exit code and stderr to make a decision whether the run command failed or not. In my case exit code=0 and anything in stderr having `warning` substring should be considered as fail.\r\n\r\nWhen I needed to run just one command I happily used the following code:\r\n```js\r\nchildProcess.exec(command, (err, stdout, stderr) => {\r\n    if (err || (stderr && stderr.toLowerCase().includes('warning'))) {\r\n        console.error('Failed due to:');\r\n        console.error(stderr);\r\n        process.exit(1);\r\n    }\r\n\r\n    console.log('OK\\n');\r\n    process.exit(0);\r\n});\r\n```\r\nWhen the task changed and I needed to run few commands in a row I decided to use synchronous version of that method:\r\n```js\r\n    try {\r\n        const stdout = childProcess.execSync(command, { encoding: 'utf8' }); // can't get stderr\r\n    } catch (err) {\r\n        const { status, stderr } = err;\r\n        if (status > 0 || (stderr && stderr.toLowerCase().includes('warning'))) {\r\n            console.error('Failed due to:');\r\n            console.error(stderr);\r\n            process.exit(1);\r\n        }\r\n    }\r\n\r\n    console.log('OK');\r\n```\r\nHowever using that code I can't check stderr when no exception is thrown.\r\n\r\n**Describe the solution you'd like**\r\nI'd like `childProcess.execSync` to return an object containing `status`/`code`, `stderr`, `stdout` and other fields similar to returned object in `child_process.spawnSync` (https://nodejs.org/api/child_process.html#child_process_child_process_spawnsync_command_args_options): \r\n```\r\n* pid <number> Pid of the child process.\r\n* output <Array> Array of results from stdio output.\r\n* stdout <Buffer> | <string> The contents of output[1].\r\n* stderr <Buffer> | <string> The contents of output[2].\r\n* status <number> | <null> The exit code of the subprocess, or null if the subprocess terminated due to a signal.\r\n* signal <string> | <null> The signal used to kill the subprocess, or null if the subprocess did not terminate due to a signal.\r\n* error <Error> The error object if the child process failed or timed out.\r\n``` \r\n\r\n**Describe alternatives you've considered**\r\nAlternatives:\r\n1) Use asynchronous version (`childProcess.exec`) and rewrite the code to work in asynchronous manner\r\n2) Use `childProcess.spawnSync` with `shell=true`\r\n",
        "labels": "feature request",
        "id": 42993
    },
    {
        "title": "--require doesn't work with import",
        "body": "* **Version**: 12.18.3\r\n* **Platform**: macOS 10.15.6\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\nRun `node` with `--require` and `--experimental-specifier-resolution=node`\r\n\r\nAn example can be found [here](https://github.com/daveisfera/test_import_preload) when running `npm test`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways\r\n\r\n### What is the expected behavior?\r\nThere's a way to preload a file using `import` rather than `require`\r\n\r\n### What do you see instead?\r\n```\r\ninternal/modules/cjs/loader.js:1154\r\n      throw new ERR_REQUIRE_ESM(filename, parentPath, packageJsonPath);\r\n      ^\r\n\r\nError [ERR_REQUIRE_ESM]: Must use import to load ES Module: /Users/dlj/projects/test_import_preload/preload.js\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1154:13)\r\n    at Module.load (internal/modules/cjs/loader.js:986:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:879:14)\r\n    at Module.require (internal/modules/cjs/loader.js:1026:19)\r\n    at Module._preloadModules (internal/modules/cjs/loader.js:1278:12)\r\n    at loadPreloadModules (internal/bootstrap/pre_execution.js:439:5)\r\n    at prepareMainThreadExecution (internal/bootstrap/pre_execution.js:71:3)\r\n    at internal/main/run_main_module.js:7:1 {\r\n  code: 'ERR_REQUIRE_ESM'\r\n}\r\nnpm ERR! Test failed.  See above for more details.\r\n```\r\n\r\n### Additional information\r\nIt would be nice if there was a `--import` or if `--require` worked with `import`s",
        "labels": "feature request",
        "id": 42994
    },
    {
        "title": "Implement Promise.any",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nGetting the first promise to fulfill.\r\n\r\n**Describe the solution you'd like**\r\n\r\n[Promise.any](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/any) should be implemented.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n[p-any](https://github.com/sindresorhus/p-any) does something similar but is not spec-compliant.\r\n\r\n**Dependent features**\r\n\r\n- [Implement `AggregateError`](https://github.com/nodejs/node/issues/35044)\r\n",
        "labels": "feature request",
        "id": 42995
    },
    {
        "title": "Implement AggregateError",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nAggregating multiple errors into one.\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe [AggregateError](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/AggregateError) subclass should be implemented. This is an important stepping stone for also implementing [Promise.any](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/any) which uses this.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n[aggregate-error](https://github.com/sindresorhus/aggregate-error) does something similar but is not spec-compliant.\r\n",
        "labels": "feature request",
        "id": 42996
    },
    {
        "title": "node --help command too much text in description",
        "body": "for this command `node --help`...\r\nis there anyone can update it like `deno` or `go` one?\r\nbecause `node --help` now like a bit messy and there is a lot of text there\r\n\r\nthanks!\r\n",
        "labels": "feature request",
        "id": 42997
    },
    {
        "title": "WASI as a build platform",
        "body": "I think it is possible because current macOS support is via LLVM toolchain that could target webassembly and WASI (but I have no idea about the process).\r\n\r\nBenefits:\r\n* Custom hardware that can run webassembly will be able to use nodejs without official support (mobiles, embedded devices, ...)\r\n* Use nodejs (and couple of server side only packages) in browser.\r\n* Use in future [wasm-container](https://adlrocha.substack.com/p/adlrocha-can-wasm-become-the-new)\r\n* And almost any benefit wasm and WASI have for the server side\r\n",
        "labels": "feature request",
        "id": 42998
    },
    {
        "title": "Built-in low-cost async to sync method",
        "body": "reduce unstable conditions caused by such hacking\r\nhttps://npm.im/deasync\r\n\r\n```js\r\nimport { deasync, depromise } from \"util\";\r\n\r\nconst sleepWithSync = deasync((timeout, done) => { setTimeout(done, timeout) });\r\nconst promiseWithSync = depromise(async (input) => input)\r\n\r\nsleepWithSync(1000)\r\npromiseWithSync(1) == 1\r\n// sync done\r\n```",
        "labels": "feature request",
        "id": 42999
    },
    {
        "title": "Add conditions to require.resolve options",
        "body": "There is PR was implemented to support custom user `--conditions`\r\nhttps://github.com/nodejs/node/pull/34637\r\n\r\nI wonder why not add this param to `require.resolve` `options`, which now contains only `paths`, this would allow using require in some custom resolution scenarios, where it is not possible to use cli flag.\r\n\r\nBut also probably it should not fully mimic `--conditions` which still puts leaves `require` and `node` conditions preferable, but this option should allow overriding the full list of the used condition while resolution.\r\n\r\n@guybedford ",
        "labels": "feature request",
        "id": 43000
    },
    {
        "title": "Request new HTTPS error message on incomplete credentials",
        "body": "I am requesting additional error messaging.\r\n\r\nAn HTTPS server requires credentials.  See the documentation for `https.createServer`: https://nodejs.org/dist/latest-v14.x/docs/api/https.html#https_https_createserver_options_requestlistener\r\n\r\n```javascript\r\n// curl -k https://localhost:8000/\r\nconst https = require('https');\r\nconst fs = require('fs');\r\n\r\nconst options = {\r\n  key: fs.readFileSync('test/fixtures/keys/agent2-key.pem'),\r\n  cert: fs.readFileSync('test/fixtures/keys/agent2-cert.pem')\r\n};\r\n\r\nhttps.createServer(options, (req, res) => {\r\n  res.writeHead(200);\r\n  res.end('hello world\\n');\r\n}).listen(8000);\r\n```\r\n\r\nIn the case of this code example from the documentation the credentials are passed in as the `options` object and the minimally required keys are `key` and `cert`.\r\n\r\n**Could there be error messaging if the options object contains either `key` assigned to a PEM formatted string or `cert` assigned to a PEM formatted string but not both?**  The assumption is that a user would supply options that contain both of those keys with complete values or neither of those object keys due to an alternate format of credential.\r\n\r\nAt present incomplete credentials does not halt Node from launching the HTTPS server, but no remote agent will respect that server.  Any connection to that server will be broken with a protocol mismatch error on the remote end.  The server is completely broken without any indication from the server side and with only incomplete messaging on the remote end.",
        "labels": "feature request",
        "id": 43001
    },
    {
        "title": "Pipeline error causing stream",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\nCurrently, there is no way to determine which stream in the pipeline function raised an error. In many cases, it would be helpful for the user, because they would get more insight as to what caused the error.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n[PR 34](https://github.com/mafintosh/pump/pull/34) of the pump module was able to implement this.\r\n",
        "labels": "feature request",
        "id": 43002
    },
    {
        "title": "Built-in method to escape shell arguments",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nYes, I was using `execa` which is a light wrapper for `childProcess.spawn` to execute a script (call it `./scripts/configure`) which took user input as an argument. One of my users supplied `\"Users & Permissions Management\"` as that input, which caused the script to hang as the resulting spawned process was: \r\n\r\n```\r\n./scripts/configure Users & Permissions Management\r\n```\r\n\r\nI realised as soon as the bug was reported that I should've escaped the string passed into my function that called `execa`, so then I looked for modules to correctly escape shell arguments, and they seem pretty complex. Which leads to the question: do I really want to depend on a third-party module to correctly escape shell arguments? Am I just trading one security risk for another?\r\n\r\n**Describe the solution you'd like**\r\n\r\nHave a method like `childProcess.escapeArgument(arg: string): string` which correctly escapes the given value such that it is just a string for all terminals (cross-platform).\r\n\r\n**Clarification:** I am not arguing for childProcess.spawn to escape arguments into strings by default, as that'd be a breaking change, even though it would likely be for the best (if you wanna pass multiple arguments, use the array syntax, not a string). Instead, I'm just asking for a method built-in that's well tested to escape an argument into a string argument for a shell command. \r\n\r\n**Describe alternatives you've considered**\r\n\r\n[Various NPM modules](https://github.com/nodejs/node/issues/34840#issuecomment-676398171), writing it myself, etc. All just shift the security responsibility to arguably worse places. This seems like due to the security benefits it can give, it'd be a good candidate for being a built-in function, ideally backported to LTS's\r\n",
        "labels": "feature request",
        "id": 43003
    },
    {
        "title": "Reduce the memory consumption of each Worker Thread",
        "body": "Hi,\r\n-- Please describe the problem you are trying to solve.\r\nWe are building a Node.js based _on-premise_ application that needs to run in a memory restricted environment. The application uses its own implementation of worker threads because it was developed before the addition of worker threads to Node.js. We are looking to migrate our implementation which is becoming harder and harder to maintain (syncing our code  with the Node.js versions) to the built in implementation. Our application starts numerous worker threads therefore the memory utilization per one worker thread is critical. In our implementation of worker threads we emphasized the reduction of memory consumption but payed in the fact that our worker thread could not access the Node.js standard APIs. Furthermore, our implementation is somewhat tailored to our use-case and lacks the flexibility of the standard implementation (e.g. we will not be able to use \"import\" and we have our own implementation of \"require\").  \r\n\r\nI have migrated all of the relevant code to use the native worker threads but now each worker thread utilizes almost 3 times more memory than in our implementation. I must add that the general structure of our implementation is not dissimilar to the native one and it uses a libuv event loop and v8 Isolates separation in a similar fashion.\r\n\r\nI ran some tests with an empty worker thread starting up every 10 seconds (i.e. new worker thread that does nothing infinitely starts every 10 seconds) and here are the results of the memory utilization of that process:\r\n\r\n![New worker thread every 10 seconds](https://user-images.githubusercontent.com/1912858/90477513-301d5880-e134-11ea-9b67-a66fedfa8cf4.png)\r\nTest was run with Node.js 12.8.3 on a Windows 10 machine.\r\n\r\nAs you can see a Node.js process without any worker threads running takes ~11mb and starting a worker thread utilizes almost as much memory as the full process.\r\n\r\n-- Please describe the desired behavior.\r\nWe would like to reduce the utilization of the memory per worker thread. Any reduction would be greatly appreciated.  I did some investigation as to what exactly causing each worker thread to use as much memory as the entire process but did not reach any conclusive results (I am not an expert in this area and unfortunately the person who implemented our worker threads variant has left the company). I suspect that each worker thread loads all of Node.js native library separately into its memory which could explain why each worker thread has the same memory usage as the entire process (i.e. the main thread). Maybe there is some way to use the same native (C code) across all worker threads to save on memory consumption (again, I am not an expert in C programming so I might be writing nonsense here).\r\n\r\n-- Please describe alternative solutions or features you have considered.\r\nCurrently our only alternative is to stay with our implementation.\r\n\r\nThank you.",
        "labels": "feature request",
        "id": 43004
    },
    {
        "title": "DNS resolution over specific interface",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nOn a system with multiple network interfaces, I would like to make DNS resolution requests over a specific interface.\r\n\r\nI have a problem similar to #14617.  Consider a Linux server with 2 interfaces, primary `eth0` and a backup internet connection using a LTE modem on `eth1`.  The system's default route is over `eth0`, and in normal operation all traffic goes over that interface.\r\n\r\nIf the primary connection is unavailable, I want to be able to make certain requests from my node program over the backup connection.  However, the backup connection is metered, so I don't want a systemwide failover; only specific, high-priority requests should go over the backup.\r\n\r\nWith the [appropriate alternate IP routing table and rules configured](https://serverfault.com/a/1032226/48050), this works for TCP sockets if you set [`localAddress` when calling `connect(opts)`](https://nodejs.org/api/net.html#net_socket_connect_options_connectlistener) and already know the destination address.  However, I need a way to resolve DNS over the backup connection if necessary â€” and separately from the system's default resolv.conf settings.\r\n\r\n**Describe the solution you'd like**\r\nThis could be accomplished similarly to the `localAddress` option available to TCP sockets.  (There's also `bind(port, address)` available to UDP sockets.)\r\n\r\neg:\r\n\r\n```js\r\nconst dns = require('dns');\r\nconst resolver = new dns.Resolver({ localAddress: '192.168.0.x' });\r\nresolver.setServers(['8.8.8.8']);\r\nresolver.resolve4(â€¦);\r\n```\r\n\r\nI *think* this would be as simple as calling [`ares_set_local_ip4`](https://manpages.debian.org/testing/libc-ares-dev/ares_set_local_ip4.3.en.html)/[`ares_set_local_ip6`](https://manpages.debian.org/testing/libc-ares-dev/ares_set_local_ip6.3.en.html) somewhere in [cares_wrap.cc](https://github.com/nodejs/node/blob/master/src/cares_wrap.cc).",
        "labels": "feature request",
        "id": 43005
    },
    {
        "title": "Absolute Windows paths are handled as invalid URL path in ESM import()",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.8v0\r\n* **Platform**: Windows\r\n* **Subsystem**:\r\n\r\nRelated: https://github.com/nodejs/node/issues/31710\r\n\r\n### What steps will reproduce the bug?\r\n\r\nWindows paths are interpreted as invalid file URL. In Linux and Mac, the issue can't be reproduced.\r\n\r\nFail\r\n```js\r\nawait import(\"D:\\repositories\\fastify-autoload\\routes\\hello.mjs\")\r\n```\r\n\r\nWorks\r\n```js\r\nawait import(url.pathToFileURL(\"D:\\repositories\\fastify-autoload\\routes\\hello.mjs\").href)\r\n```\r\n\r\n## Root cause\r\n\r\nhttps://github.com/nodejs/node/issues/31710#issuecomment-587211387\r\n\r\n### What is the expected behavior?\r\n\r\nInterpret windows paths as valid URL paths so we can provide consistent cross-platform behaviour.\r\n\r\n### What do you see instead?\r\n\r\n```\r\nError [ERR_UNSUPPORTED_ESM_URL_SCHEME]: Only file and data URLs are supported by the default ESM loader\r\n    at Loader.defaultResolve [as _resolve] (internal/modules/esm/resolve.js:698:11)\r\n    at Loader.resolve (internal/modules/esm/loader.js:82:40)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:226:28)\r\n    at Loader.import (internal/modules/esm/loader.js:161:28)\r\n    at importModuleDynamically (internal/modules/cjs/loader.js:1144:27)\r\n    at exports.importModuleDynamicallyCallback (internal/process/esm_loader.js:27:14)\r\n    at loadPlugin (D:\\repositories\\fastify-autoload\\index.js:118:5)\r\n    at D:\\repositories\\fastify-autoload\\index.js:28:12\r\n    at Array.map (<anonymous>)\r\n    at fastifyAutoload (D:\\repositories\\fastify-autoload\\index.js:27:29) {\r\n  code: 'ERR_UNSUPPORTED_ESM_URL_SCHEME'\r\n}\r\n```\r\n\r\n@mcollina ",
        "labels": "feature request",
        "id": 43006
    },
    {
        "title": "fix system, i imported crypto package and the nodejs replaced it",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n![image](https://user-images.githubusercontent.com/69520693/89941329-89acf100-dc23-11ea-9af5-9952a63aaf12.png)\r\npls just make it not replace the actual good package\r\n`else if (command === `say` && AImodule) {\r\n\t\t\t\t\tsetTimeout(function() {\r\n\t\t\t\t\t\tmykey = crypto.createCipher('aes-128-cbc', 'mypassword');\r\n\t\t\t\t\t\tmystr = mykey.update(onearg, 'utf8', 'dec')\r\n\t\t\t\t\t\tmystr += mykey.final('dec');\r\n\t\t\t\t\t\tmystr1 = mystr.slice(0, (Math.round(mystr.length / 3)));\r\n\t\t\t\t\t\tmystr2 = mystr.slice((Math.round(mystr.length / 3)), (Math.round(mystr.length / 3 * 2)));\r\n\t\t\t\t\t\tmystr3 = mystr.slice((Math.round(mystr.length / 3 * 2)), mystr.length);\r\n\t\t\t\t\t\twhile (mystr1 > 1) {\r\n\t\t\t\t\t\t\tmystr1 = mystr1 / 10\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\twhile (mystr2 > 1) {\r\n\t\t\t\t\t\t\tmystr2 = mystr2 / 10\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\twhile (mystr3 > 1) {\r\n\t\t\t\t\t\t\tmystr3 = mystr3 / 10\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\tmykey = crypto.createDecipher('aes-128-cbc', 'mypassword');\r\n\t\t\t\t\t\tmystr = mykey.update(inputAI(mystr1,mystr2,mystr3), 'dec', 'utf8')\r\n\t\t\t\t\t\tmystr += mykey.final('utf8');\r\n\t\t\t\t\t\tchannel.send(`Message:\\`\\`\\`mystr\\`\\`\\``);\r\n\t\t\t\t\t}, 0);\r\n\t\t\t\t}`\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nmy bot won't work, it is supposed to work based a neural network and i am using the crypto command since i didn't find anything else to fully convert a string to decimal\r\n\r\n**Describe the solution you'd like**\r\nto work properly as the crypto package so nobody needs to update, will work properly only if the crypto package is imported with a -l as legacy\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n",
        "labels": "feature request",
        "id": 43007
    },
    {
        "title": "A new event to the process. The log event",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nA way to check when something is logged to stdout\r\n\r\n**Describe the solution you'd like**\r\n\r\nWhenever something is written to process.stdout, the log event is emitted with whatever is written into stdout.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nN/A",
        "labels": "feature request",
        "id": 43008
    },
    {
        "title": "Worker thread aborts on terminate if native node module has an open async handle",
        "body": "* **Version**: `v14.6.0, v12.14.1`\r\n* **Platform**: `4.15.0-1091-oem #101-Ubuntu SMP Thu Jun 25 17:55:29 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: `worker_threads`\r\n\r\n### What steps will reproduce the bug?\r\nI have opened up a repository [here](https://github.com/implausible/native-node-worker-thread-aborts-on-terminate) that can be used to reliably crash node. Follow the steps in `README.md` to replicate.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nThis reproduces so long as a native node module has an active async handle for async completion.\r\n\r\n### What is the expected behavior?\r\nWorker thread should not terminate until all handles are cleaned up. Modules should be able to exit gracefully when terminate is requested.\r\n\r\n```\r\nnpm test\r\n\r\n> native-node-tests@1.0.0 test /home/tylerw/github/test/native-node-tests\r\n> node -e \"w = new (require('worker_threads').Worker)('./runDoAsyncThing.js'); setTimeout(w.terminate.bind(w), 2000);\"\r\n\r\nEntering execute thread\r\n```\r\n\r\n### What do you see instead?\r\n\r\n```\r\nnpm test\r\n\r\n> native-node-tests@1.0.0 test /home/tylerw/github/test/native-node-tests\r\n> node -e \"w = new (require('worker_threads').Worker)('./runDoAsyncThing.js'); setTimeout(w.terminate.bind(w), 2000);\"\r\n\r\nEntering execute thread\r\nuv loop at [0x7f18151e1ad8] has open handles:\r\nuv loop at [0x7f18151e1ad8] has 0 open handles in total\r\nnode[23076]: ../src/debug_utils.cc:322:void node::CheckedUvLoopClose(uv_loop_t*): Assertion `0 && \"uv_loop_close() while having open handles\"' failed.\r\n 1: 0x9fb000 node::Abort() [node]\r\n 2: 0x9fb07e  [node]\r\n 3: 0x98e9f1  [node]\r\n 4: 0xab2e44 node::worker::Worker::Run() [node]\r\n 5: 0xab2e88  [node]\r\n 6: 0x7f1817de06db  [/lib/x86_64-linux-gnu/libpthread.so.0]\r\n 7: 0x7f1817b09a3f clone [/lib/x86_64-linux-gnu/libc.so.6]\r\nAborted (core dumped)\r\nnpm ERR! Test failed.  See above for more details.\r\n```",
        "labels": "feature request",
        "id": 43009
    },
    {
        "title": "Porting over the Web Audio API",
        "body": "As of now, it is very difficult to play audio in Node.js. Most solutions suggested on the [Stackoverflow question](https://stackoverflow.com/questions/12543237/play-audio-with-node-js) require using native modules and have all broken in one way or another. Community implementations of the Web Audio API have made good progress but are incomplete and buggy. My experience using [web-audio-api](https://www.npmjs.com/package/web-audio-api) has not been good.\r\n\r\nNode.js should port over the [Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API) present in browsers so that the same functionality can be achieved on the client-end, or at the very least provide middleware for piping audio streams to hardware, like [speaker](https://www.npmjs.com/package/speaker).",
        "labels": "feature request",
        "id": 43010
    },
    {
        "title": "Add a native support of Argon2 hashing algorithm",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently Node.js provides a native support of `scrypt`, which is good but isn't the most secure option.\r\n\r\n**Describe the solution you'd like**\r\nIt would be great to have a native support of `argon2` via `crypto` module, just like `scrypt` has nowadays.\r\n\r\n**Describe alternatives you've considered**\r\nAn [`argon2`](https://www.npmjs.com/package/argon2) npm module for Node.js.",
        "labels": "feature request",
        "id": 43011
    },
    {
        "title": " Should we add a new api, \"tls.Server.prototype.removeContexts(servername)\" and \"tls.Server.prototype.replaceContext(servername,context)\" ?",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nhttps://github.com/nodejs/node/issues/34110\r\nhttps://github.com/nodejs/node/pull/34444\r\n\r\nAfter adding the context with \"tls.Server.prototype.addContext\", the context corresponding to the specified servername cannot be deleted. Should we add a new api, \"tls.Server.prototype.removeContexts(servername)\"?\r\n\r\n\r\nThis is useful on HTTPS servers that need to replace ssl/tls certificates frequently, such as using \"let's encrypt\". When the certificate needs to be replaced, you don't want to restart the HTTPS server, you just need to replace the certificate and key.\r\n\r\nIf multiple secure contexts are added to the same domain name\r\n, the last one added should take effect,\r\n\r\nWith frequent ssl/tls certificate updates, addContext is called constantly. If the old context is not deleted, the old context will take up more and more memory space, and they are useless.  Eventually lead to memory leaks or even memory overflow.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\n add a new api, \"tls.Server.prototype.removeContexts(servername)\"\r\n\r\nthe all contexts corresponding to the specified servername should be deleted.\r\n\r\n Should we add a new api, \"tls.Server.prototype.removeContexts(servername)\" and \"tls.Server.prototype.replaceContext(servername,context)\" ?\r\n\r\n\r\n\"tls.Server.prototype.replaceContext(servername,context)\"  Its role should be the operation of \"tls.Server.prototype.removeContexts(servername)\" and \"tls.Server.prototype.addContext(servername,context)\"\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\n\r\n\r\n```js\r\n\r\n const server = https.createServer();\r\nconst hostname = 'foo.bar.com';\r\nconst keypath = 'key.pem';\r\nconst certpath = 'cert.pem';\r\nfunction debounce(callback, timeout) {\r\n    let timer;\r\n    return function (...args) {\r\n        timer && clearTimeout(timer);\r\n        timer = setTimeout(callback, timeout, ...args);\r\n    };\r\n}\r\nconst reloadcertkey = debounce(function () {\r\n    let key = fs.readFileSync(keypath);\r\n    let cert = fs.readFileSync(certpath);\r\n    let context = tls.createSecureContext({\r\n        key,\r\n        cert\r\n        \r\n    });\r\n    server.removeContexts(hostname, );\r\n    server.addContext(hostname, context);\r\n}, 1000);\r\nreloadcertkey();\r\nfs.watch(keypath, reloadcertkey);\r\nfs.watch(certpath, reloadcertkey);\r\n```\r\n\r\n```js\r\n\r\n const server = https.createServer();\r\nconst hostname = 'foo.bar.com';\r\nconst keypath = 'key.pem';\r\nconst certpath = 'cert.pem';\r\nfunction debounce(callback, timeout) {\r\n    let timer;\r\n    return function (...args) {\r\n        timer && clearTimeout(timer);\r\n        timer = setTimeout(callback, timeout, ...args);\r\n    };\r\n}\r\nconst reloadcertkey = debounce(function () {\r\n    let key = fs.readFileSync(keypath);\r\n    let cert = fs.readFileSync(certpath);\r\n    let context = tls.createSecureContext({\r\n        key,\r\n        cert\r\n        \r\n    });\r\n    \r\n    server.replaceContext(hostname, context);\r\n}, 1000);\r\nreloadcertkey();\r\nfs.watch(keypath, reloadcertkey);\r\nfs.watch(certpath, reloadcertkey);\r\n```",
        "labels": "feature request",
        "id": 43012
    },
    {
        "title": "Add experimental support for io_uring",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\nRecent Linux kernel (5.1+) includes io_uring, a new non-blocking I/O subsystem, which might serve as a more efficient alternative to epoll. We could benefit from it and get a performance improvement in network I/O scenarios with high volume of concurrent connections and/or for fs operations.\r\n\r\nOf course, in Node.js case we need changes made in libuv. There is an ongoing experiment aimed to add support for io_uring in libuv: https://github.com/libuv/libuv/pull/2322\r\n\r\nAs this feature should be experimental (at least initially), io_uring mode could be activated under a new flag.\r\n\r\nThe goal of this issue is to improve visibility of the libuv experiment and gather some feedback.",
        "labels": "feature request",
        "id": 43013
    },
    {
        "title": "Uncatchable UnhandledPromiseRejectionWarning caused by asynchronous listeners on parentPort inside worker",
        "body": "* **Version**: 12.18.2\r\n* **Platform**: Macbook-Pro.local 19.5.0 Darwin Kernel Version 19.5.0\r\n\r\n### What steps will reproduce the bug?\r\n1) create an index.js file and a worker.js file in the same directory\r\n\r\n2) Copy the following code into index.js:\r\n\r\n```\r\nconst { Worker } = require('worker_threads');\r\nconst os = require('os');\r\nconst path = require('path');\r\nconst numCPUs = os.cpus().length - 2;\r\n\r\nconst jobs = [\r\n  {num: 0},\r\n  {num: 1},\r\n  {num: 2},\r\n  {num: 3},\r\n  {num: 4},\r\n  {num: 5},\r\n  {num: 6},\r\n  {num: 7},\r\n  {num: 8},\r\n  {num: 9}\r\n];\r\n\r\ntest().then(() => console.log('done')).catch(e => {\r\n  console.log('tremendous error');\r\n  console.log(e);\r\n});\r\nasync function test() {\r\n  console.log('building workers');\r\n  const workers = [];\r\n  for (let i = 0; i < numCPUs; i++) {\r\n    let worker = new Worker(path.join(__dirname, 'worker.js'));\r\n    workers.push(worker);\r\n  }\r\n\r\n  console.log('starting jobs, # jobs: ', jobs.length);\r\n  console.log('num of cpus: ', numCPUs);\r\n  await runJobs({workers, jobs});\r\n}\r\n\r\nasync function runJobs ({ workers, jobs }) {\r\n    /** Do your work here **/\r\n    let numJobsDone = 0;\r\n    let results = [];\r\n    let numJobsStarted = 0;\r\n    while (numJobsDone < jobs.length) {\r\n      let promises = [];\r\n      for ( let i = 0; i < workers.length; i++) {\r\n        let worker = workers[i];\r\n        if (!jobs[numJobsStarted]) continue;\r\n        let job = jobs[numJobsStarted];\r\n        numJobsStarted++;\r\n        promises.push(new Promise((resolve, reject) => {\r\n          worker\r\n            .on('message', msg => {\r\n              console.log(msg, i, msg.num);\r\n              numJobsDone++;\r\n              resolve(msg);\r\n            })\r\n            .on('error', error => {\r\n              console.log(error);\r\n              numJobsDone++;\r\n              reject(error);\r\n            })\r\n            .on('exit', code => {\r\n              if (code !== 1) {\r\n                reject(`Got a funky exit code: ${code}`);\r\n              }\r\n            });\r\n\r\n          worker.postMessage(job);\r\n        }));\r\n      }\r\n      await Promise.allSettled(promises).then(results => {\r\n        console.log(`Received ${results.length} results back`);\r\n      });\r\n\r\n      console.log('numDone: ', numJobsDone);\r\n      console.log('numStarted: ', numJobsStarted);\r\n      console.log('numJobs: ', jobs.length);\r\n      console.log();\r\n    }\r\n}\r\n```\r\n\r\n3) paste the following code into worker.js:\r\n\r\n```\r\nconst { parentPort } = require('worker_threads');\r\n\r\nparentPort.on('message', async job => {\r\n  /** Destructure the property \"num\" - Simulating getting properties off\r\n   * the passed in object **/\r\n  const { num } = job;\r\n\r\n  /** Simulate doing intensive asynchronous task here **/\r\n  await delay(1000);\r\n\r\n  /** Send back message, when num === 3 should emit error that triggers\r\n   * .on('error') listener in index.js **/\r\n  if (num !== 3) {\r\n    parentPort.postMessage(job);\r\n  } else throw new Error(`it was not found: ${JSON.stringify(job)}`);\r\n});\r\n\r\nasync function delay(ms) {\r\n  return new Promise(resolve => setTimeout(resolve, ms));\r\n}\r\n```\r\n\r\n4) execute index.js\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n As written above, will always produce uncaught exception. Make the parentPort listener in worker.js synchronous and error is correctly caught by the .on('error') listener on line 55 of index.js\r\n\r\n### What is the expected behavior?\r\n I expect the `.on('error')` event to fire on line 55 of index.js when the job with num: 3 throws an error inside of worker.js, and the `Promise.allSettled().then(results)` to invoke and the promise with job`{num: 3}` to be unfulfilled and present inside of the array of `results` returned by Promise.allSettled when an asynchronous listener to the parentPort is used inside of worker.js.\r\n\r\n### What do you see instead?\r\n an Uncaught error exception caused by the .on('error') listener not catching the error thrown from the worker.js;\r\n\r\n### Additional information:\r\n If you just remove the async keyword in the listener of worker.js (line 3) and comment out line 9 `await delay(1000);` inside of worker.js the error caused by job {num: 3} is properly caught by the .on('error') handler and the unfulfilled promise appears in the allSettled.then of line 69 in index.js the code continues and exits gracefully.\r\n\r\nI don't think that it is intended behavior for the worker.js to only be able to run synchronous listeners to the parentPort. Is this intended behavior? If so, how can I run asynchronous tasks inside of the worker_thread and properly catch errors without bringing down the entire process?\r\n",
        "labels": "feature request",
        "id": 43014
    },
    {
        "title": "N-API: implement something like `yield`",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI work primarily on Messenger Desktop which is an electron app with a number of native plugins. We were using N-API before the promise APIs were available and we found it a nice usability/readability upgrade when we were able to switch from callbacks to those for our functions that complete a single time.\r\n\r\n**Describe the solution you'd like**\r\nI am hoping we could have the same kind of usability/readability win for our functions that generate values over time. The end result I want is that JS sees a `function*` and on the C side we have something like this:\r\n\r\n```\r\nnapi_value api(napi_env env, napi_callback_info info) {\r\n  // One-time setup:\r\n  napi_generator generator;\r\n  napi_value functionStar;\r\n  napi_create_generator(env, &generator, &functionStar);\r\n\r\n  // setup async_work\r\n\r\n  return functionStar;\r\n}\r\n\r\nvoid async_work(napi_generator generator) {\r\n  // calculate value or errror, be on JS thread\r\n  // success with intermediate value:\r\n  napi_generate_value(env, generator, value, false);\r\n  // success with final value:\r\n  napi_generate_value(env, generator, value, true);\r\n  // failure\r\n  napi_generate_error(env, generator, error);\r\n}\r\n```\r\n\r\nIt will be an error to call any `napi_generate_` function for a generator after calling either `napi_generate_value(env, generator, ..., true);` or `napi_generate_error(env, generator, ...);`\r\n\r\n**Describe alternatives you've considered**\r\nWe're currently having our generators accept callbacks and invoking them. It works but this would be cleaner.",
        "labels": "feature request",
        "id": 43015
    },
    {
        "title": "Expose the `url-to-options` function from `internal/url.js`",
        "body": "**Is your feature request related to a problem? Please describe.** \r\n\r\nhttps://github.com/nodejs/node/issues/14570#issuecomment-657638743\r\n\r\n**Describe the solution you'd like**\r\n\r\nExpose the `urlToOptions` module so it can be imported e.g. `const {urlToOptions} = require('url');`\r\n\r\nThat way we could easily convert a URL instance without duplicating the code like [this](https://github.com/szmarczak/http2-wrapper/blob/v1.0.0-beta.5.2/source/utils/url-to-options.js).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo, duplicates increase the package size.\r\n",
        "labels": "feature request",
        "id": 43016
    },
    {
        "title": "Expose the `errors` module from the `internal` directory",
        "body": "**Is your feature request related to a problem? Please describe.** \r\n\r\nhttps://github.com/nodejs/node/issues/14570#issuecomment-657638743\r\n\r\n**Describe the solution you'd like**\r\n\r\nExpose the `errors` module so it can be imported e.g. `const errors = require('errors');`\r\n\r\nThat way we could easily throw Node.js errors without duplicating them like [this](https://github.com/szmarczak/http2-wrapper/blob/v1.0.0-beta.5.2/source/utils/errors.js).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo, duplicates increase the package size.\r\n",
        "labels": "feature request",
        "id": 43017
    },
    {
        "title": "Allow to trust certificate without adding full chain of trust",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, you have to put the full chain of trust, if you want to trust one certificate.\r\n\r\nFor example, if you have that chain of trust\r\n\r\n* CertHost: valid for *.myhost.com, signed by CertIntermediate\r\n* CertIntermediate: signed by CertRoot\r\n* CertRoot: self-signed by CertRoot\r\n\r\nCurrently you have to add all three certificates to the ca trust: CertHost, CertIntermediate, CertRoot\r\n\r\nThe problem is, that now we trust everything, that is signed by CertIntermediate and CertRoot, even we don't want that, and only want to trust CertHost. So we are trusting thousands and more certificates.\r\n\r\n**Describe the solution you'd like**\r\nProviding at least an optional configuration, that allows to trust also just certificates like CertHost without providing CertIntermediate and CertRoot. Hence we have really control about what kind of certificates we trust and are able to trust only a few.",
        "labels": "feature request",
        "id": 43018
    },
    {
        "title": "Allow to disable the default ca trust completely",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently there are only two options regarding the default ca trust used by nodejs\r\n\r\n* `--use-bundled-ca` (default) - Using the hardcoded ca trust: <https://github.com/nodejs/node/blob/master/src/node_root_certs.h>\r\n* ` --use-openssl-ca` - Using the openssl default ca trust\r\n\r\nSo there is no out of the box chance to disable the default trust.\r\nAccording to <https://github.com/nodejs/node/issues/4175#issuecomment-238211757> you have to override it manually\r\n\r\n```js\r\nhttps.globalAgent.options.ca = [];\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nFrom security and operation perspective it would be even better per default not having any trust cas at all, but that would be a huge, breaking change.\r\n\r\nSo at least an option like `--use-no-ca` would be very helpful here\r\n\r\n",
        "labels": "feature request",
        "id": 43019
    },
    {
        "title": "User Mode Install for Windows",
        "body": "A lot of Windows programs offer a user mode install, where the program gets installed into %LOCALAPPDATA%\\Programs instead of the legacy C:\\Program Files\\ folder which requires local administrative access. Some examples of such programs as VSCode and Python. It would be nice if the Windows Installer for nodejs offered a user mode install option which did not require administrative access.\r\n\r\nThe installer could either offer the option to install in user mode, or check to see if it can elevate, and if not default to %LOCALAPPDATA%\\Programs\\nodejs",
        "labels": "feature request",
        "id": 43020
    },
    {
        "title": "Crypto: CMAC support",
        "body": "<!--\nThank you for suggesting an idea to make Node.js better.\n\nPlease fill in as much of the template below as you're able.\n-->\n\n**Is your feature request related to a problem? Please describe.**\nNo\n\n**Describe the solution you'd like**\nOpenSSL already supports CMAC, but Node doesn't implement it. We use smartcards that only support CMAC, not HMAC, and our current solution is hacky.\n\n**Describe alternatives you've considered**\nSo far we've just hashed the message and encrypted the key with a secret.",
        "labels": "feature request",
        "id": 43021
    },
    {
        "title": "Export Version 2 PKCS #8 Private Keys",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nCurrently, NodeJS exports PKCS 8 private keys as Version 1 `PrivateKeyInfo` objects, but as of 2010, [RFC 5958](https://tools.ietf.org/html/rfc5958) specifies Version 2. This only differs from Version 1 by optionally including the public key at the end of the object, and, of course, the version number being incremented.\r\n\r\n**Describe the solution you'd like**\r\nThe ability to export Version 2 PKCS 8 Private Keys. All keys can be exported to Version 2 because the included public key at the end is still optional in Version 2. If it is too much work to generate public keys for all algorithms, the public key can be generated just for selected algorithms (presumably those most commonly used, such as RSA and DSA).\r\n\r\nThis would change [Crypto.KeyObject.export()](https://nodejs.org/dist/latest-v14.x/docs/api/crypto.html#crypto_keyobject_export_options) by adding a new export type: `pkcs8v2`. Again, if the public key cannot be generated, it will simply not be included in the export.\r\n\r\n**Describe alternatives you've considered**\r\nThere are no native alternatives. You would have to use third-party crypto libraries to generate PKCS 8 Version 2 keys.\r\n",
        "labels": "feature request",
        "id": 43022
    },
    {
        "title": "http2: support adding never-index header fields",
        "body": "As part of the HTTP2 (and HTTP3) spec, some headers can be sent as `Literal Header Field Never Indexed`\r\n \r\nhttps://www.rfc-editor.org/rfc/rfc7541.html#section-6.2.3\r\n\r\nThis can be used for security reasons to avoid `CRIME` (Compression Ratio Info-leak Made Easy) attacks to expose sensitive information. \r\n\r\nPoints of interest are:\r\n\r\n* [What flag to set for nghttp2](https://nghttp2.org/documentation/enums.html#c.NGHTTP2_NV_FLAG_NO_INDEX)\r\n* [How we compile a header from JS](https://github.com/nodejs/node/blob/241ed44a0b06db45c97681c164fc1098e7c9f0d2/lib/internal/http2/util.js#L439)\r\n* [How we submit responses to nghttp2](https://github.com/nodejs/node/blob/f63436d190b60e12131036aa9d1888d9023e9127/src/node_http2.cc#L2001)\r\n\r\nIt'll help diagnose https://github.com/nodejs/node/issues/28632\r\n ",
        "labels": "feature request",
        "id": 43023
    },
    {
        "title": "implement process.exitWithException()",
        "body": "In the stalled PR https://github.com/nodejs/node/pull/25715, @Fishrock123 was working to introduce a new API... from the original description:\r\n\r\n> Adds a public way to access node::FatalException from javascript, as process.exitWithException().\r\n>\r\n> If an error stack is available on the value, this method of exiting does not add additional context, unlike regular re-throwing, yet also uses the regular error printing logic. This behavior is particularly desirable when doing 'fatal exits' from the unhandledRejection event.\r\n\r\nWhile the PR had plenty of support to move forward, there was an edge case around the `uncaughtException` event handler that would need to be worked through in order for it to move forward.\r\n\r\nThe original PR stalled out and has been closed, but given the support the idea had, I wanted to make sure to open a Feature Request issue in case someone else wanted to pick up the work and move it forward.",
        "labels": "feature request",
        "id": 43024
    },
    {
        "title": "Imply ES6 module package, when package.json contanis 'module':...",
        "body": "In my package.json I have `'type':'module'` and in my code I write `import babel from '@rollup/plugin-babel`.  The [package.json of the latter](https://github.com/rollup/plugins/blob/master/packages/babel/package.json) contains `\"main\": \"dist/index.js\", \"module\": \"dist/index.es.js\"` but there is no `'type':'module'`.  In turn nodejs concludes that `@rollup/plugin-babel` is commonjs and there is no way to use the default import from `dist/index.es.js`.  This means I have to write `babel.default` in my code and I cannot use `import {babel} from '@rollup/plugin-html`.\r\n\r\nâ€¢ When NodeJS imports a package(.json) that contains 'main' and 'module' fields, but no 'type' field, from a package containing `'type':'module'`, implicitly conclude that the imported package is an ES6 module.",
        "labels": "feature request",
        "id": 43025
    },
    {
        "title": "Adding middleware functions in EventEmitter .on()",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nIn SocketIO it would be useful to be able to add middleware functions to specific events. The sockets use the EventEmitter. \r\n\r\n\r\n**Describe the solution you'd like**\r\nIn a regular express app it is possible to add middleware to specific endpoints like so: \r\n\r\n```\r\nfunction someFunc(req, res, next) {\r\n    // doing something\r\n   next()\r\n}\r\napp.get('/users', someFunc, (req, res) => { res.send('someData')})\r\n```\r\n\r\n\r\nIt would be logical to also be able to do it with SocketIO:\r\n\r\n```\r\nfunction someFunc(data, next) {\r\n    // doing something\r\n   next()\r\n}\r\nfunction someFunc2(data, next) {\r\n    // doing something\r\n   next()\r\n}\r\nsocket.on('users', someFunc, someFunc2, (data) => { /*doing something*/})\r\n\r\n```\r\n**Why it would be used**\r\nThis could be useful to add callbacks to endpoints to check if a user is authenticated or has enough credits before using the endpoint for example. Instead of having a global middleware that is checked for every endpoint.\r\n\r\nSo by implementing these extra middleware to be added in the EventEmitter.on() function it could have the same behavior as the express routes and still maintain the same behavior with just one function. \r\n\r\n**Describe alternatives you've considered**\r\n\r\n- using the socket.use(fn) function would bring a lot of overhead as it would call the middleware every time for every endpoint.\r\n(added: )\r\n- it could also be a SocketIO feature, though I think it could also be useful for other applications where specific handling per event endpoint is needed.\r\n- It could be possible to create a wrapper function like `socket.on('users', functionWrapper( fn1, fn2, fn3))` though it would be cleaner to be able to directly put the functions in the `.on()` function.\r\n\r\n**example + further implementation/usage info**\r\n[JSFIDDLE](https://jsfiddle.net/dirvann/5p42j9ze/2/)\r\n[comment below](https://github.com/nodejs/node/issues/33932#issuecomment-646027458)",
        "labels": "feature request",
        "id": 43026
    },
    {
        "title": "Add an `executable` property or an `isExecutable` method to fs Stats class",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nAn easy to easy API for determining if a file is executable based on its `fs.Stats`. \r\n\r\n**Describe the solution you'd like**\r\nDerived from Ruby: https://www.rubydoc.info/stdlib/core/File%2FStat:executable%3F I've created a rough implementation. It hasn't been tested.\r\n\r\n```js\r\nfunction isExecutable (stat: fs.Stats) {\r\n\tconst S_IXUGO = fs.constants.S_IXUSR | fs.constants.S_IXGRP | fs.constants.S_IXOTH\r\n\tconst euid = process.geteuid()\r\n\tif (euid === 0) {\r\n\t\treturn stat.mode & S_IXUGO ? true : false\r\n\t} else if (stat.uid === euid) {\r\n\t\treturn stat.mode & fs.constants.S_IXUSR ? true : false\r\n\t} else if (stat.gid === process.getgid() || stat.gid === process.getegid()) {\r\n\t\treturn stat.mode & fs.constants.S_IXGRP ? true : false \r\n\t} else if (!(stat.mode & fs.constants.S_IXOTH)) {\r\n\t\treturn false\r\n\t} else {\r\n\t\treturn true\r\n\t}\r\n}\r\n```\r\n\r\nI'll be happy to work on the PR if maintainers thinks its a worthwhile addition to fs\r\n",
        "labels": "feature request",
        "id": 43027
    },
    {
        "title": "assert.match should return match result",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI was using `assert(haystack.match(/needle/));` in my unit tests, and I found that `assert.match(haystack, /needle/);` produced much cleaner errors. +1, suggest to move to stable.\r\n\r\nHowever, in a small handful of cases, I was also using the match results later on in the test, like so:\r\n\r\n```javascript\r\nconst m = haystack.match(/nee(\\d+)le/);\r\nassert(m);\r\n// ...\r\nassert(haystack2.match(m[1]));\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nIf I could rescue the match results from `assert.match`, and if the `regexp` argument could be a string, this code could be simplified:\r\n\r\n```javascript\r\nconst m = assert.match(haystack, /nee(\\d+)le/);\r\n// ...\r\nassert.match(haystack2, m[1]);\r\n```\r\n\r\n\r\n**Describe alternatives you've considered**\r\nThis feature simply leads to cleaner tests.\r\n\r\nPossible downsides are that people may overlook assert calls used like this, because they always expect \"assert\" to work like a C assertion, or having a return value is too inconsistent with the rest of the library.",
        "labels": "feature request",
        "id": 43028
    },
    {
        "title": "node process does not reflect timezone changes",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.17.0\r\n* **Platform**: Linux 5.4.0-33-generic # 37-Ubuntu SMP Thu May 21 12:53:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Platform**: Linux 3.16.0-4.9-amd64 # 1 SMP Debian 3.16.7-ckt25-1 (2018-11-21) x86_64 GNU/Linux\r\n(it reproduces on both platforms)\r\n* **Subsystem**: ?\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n- open two terminals locally on machine\r\n- run `node` on terminal 1\r\n- `new Date().getTimezoneOffset()`\r\n- change timezone in terminal 2\r\n- ask for `new Date().getTimezoneOffset()` in node in terminal 1 again\r\n- **note that timezone change is not reflected**\r\n- exit node process in terminal 1 and enter `node` again (another `node` process)\r\n- now `new Date().getTimezoneOffset()` reflects the new timezone\r\n- **note that this not-reflecting-new-timezone thing affects creating new dates and any other date operations. `getTimezoneOffset()` is just a sample**\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nalways reproduces, no required condition.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nTo reflect and update timezone of node process, when timezone of system is changed.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nI see the old timezone.\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\nThis bug has been created and reported previously, as I read, some people mentioned that the main bug is with V8, and linked to some bugs there. By the way, all previous reported bugs were closed. I link to everything I found here:\r\nhttps://github.com/nodejs/node/issues/4022\r\nhttps://github.com/nodejs/node/pull/20026\r\nhttps://github.com/nodejs/node/issues/19974\r\nhttps://github.com/nodejs/node/issues/3449\r\n\r\nI created this issue as some time has passed and honestly, I couldn't find out why the previous issues were closed, and V8 discussions were beyond my knowledge.\r\n\r\n### What is the matter?\r\n\r\nWe have a system, a rather big one, composed of different programming languages and technologies, all components of our system works fine when timezone changes, except nodejs. There are solutions like https://github.com/evanlucas/reset-date-cache, but suppose node queries sql queries and created date objects from timestamps in sql tables, and timezone needs  to  be kept updated. the only way to keep it updated is to reset cache on each page request, which as noted in https://github.com/evanlucas/reset-date-cache: \r\n> The underlying call being made is quite expensive so it should only be used where absolutely necessary.\r\n\r\n### Screenshot of reproduction\r\n\r\n![Screenshot from 2020-06-09 18-58-34](https://user-images.githubusercontent.com/5755214/84143307-65883480-aa67-11ea-8013-e2f28ce24671.png)\r\n",
        "labels": "feature request",
        "id": 43029
    },
    {
        "title": "Expose the existing mechanisms behind `assert.deepEqual`",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nI've been working on a testing tools set as part of some new proprietary ecosystem \r\n(with the intent to open-source elements from it once they are stable enough in their form and require less maintenance, but so far it's proprietary :( ).\r\nAs part of this testing framework, I need to perform a deep comparison of objects.\r\n\r\nAs a start - I got `assert.deepEqual` - which is great. However - it ends with an exception.\r\nSometimes I would like to manage the exception myself - I just need the indication.\r\n\r\nI decided to open this issue when I came across more use-cases:\r\n - data healer - need to act on a decision if a model does not comply with expected values.\r\n   For this - we need a form of `containsEql`.\r\n - suite setup & teardown - need to add test-fixture data, and validate that essential objects are part of the target env (e.g. object describing super-user, or root categories, root tags, etc).\r\n \r\nIn all of the cases, it's beneficial to be able to perform both `containsEql` and `deepEqual`.\r\n\r\nI did see `util.isDeepStrictEqual` - and despite the confusing name that gave me hope.\r\n\r\n(I mean, it took me a lot of tries to understand that `strict` does not mean reference-comparison, but comparison without conversion of values. The first time I saw it I struggled to understand what it means - does it compare shallow copies? I had to try and see for myself. Anyway - I'm side tracking)\r\n\r\n**Describe the solution you'd like**\r\nI would propose on the same spirit of `util.isDeepStrictEqual(..)`\r\n`util.isDeepStrictContain(..)`\r\n\r\nI also saw the underlying mechanisms with the `bStirct` flag, and thought it could also be useful to let users inject it if they so choose, but I'm not sure about the names or the form it should take.\r\n\r\nI'll be happy to start work on it if we can agree on the form it should take.\r\n\r\nI mean, the mechanisms are there, and their functionality is all well-tested.\r\nWe just need to feature them and add only tests that show they are available, or even reuse parts of the existing tests - but expect a boolean instead of an error.\r\n\r\n**Describe alternatives you've considered**\r\nAll current alternatives come from userland codes, which basically duplicate the same logic and introduce their own takes and flavors. Which is a pity...\r\nWe have that logic in `node`, and it's a good logic that runs deep and already serves now a role in APIs used by userland.\r\n",
        "labels": "feature request",
        "id": 43030
    },
    {
        "title": "Improvements of OSS-Fuzz integration",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nThis feature is not related to a problem. \r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nThis feature asks for tighter integration with continuous fuzzing via OSS-Fuzz. In this PR https://github.com/google/oss-fuzz/pull/3860#issuecomment-638747166 I integrated NodeJS with fuzzing and so far it was used to capture this bug https://github.com/nodejs/node/pull/33640 \r\nHowever, the current integration could be improved and it would be desirable to cover more of NodeJS with fuzzers, as briefly discussed with @bnoordhuis in the above PR. Specifically, there are two core parts where the integration with OSS-Fuzz can improve: (1) integrating the build procedure with the OSS-Fuzz environment more closely with the NodeJS environment and (2) building more fuzzers. \r\n\r\nRegarding part 1 then the current strategy (`build.sh` here https://github.com/google/oss-fuzz/pull/3860/files) compiles the NodeJS core in an awkward manner by first running `make` without any proper OSS-Fuzz flags and then re-comiling the `.cc` files of `node/src` with the proper OSS-Fuzz flags, in order to create a static archive. \r\nThe OSS-Fuzz environment sets the following environment variables when compiling the fuzzers to something similar to this:\r\n```\r\nexport CC=clang\r\nexport CXX=clang++\r\nexport CFLAGS=\"-O1 -fno-omit-frame-pointer -gline-tables-only -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION -fsanitize=address -fsanitize-address-use-after-scope -fsanitize=fuzzer-no-link\"\r\nexport CXXFLAGS=\"-O1 -fno-omit-frame-pointer -gline-tables-only -DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION -fsanitize=address -fsanitize-address-use-after-scope -fsanitize=fuzzer-no-link -stdlib=libc++\"\r\nexport LIB_FUZZING_ENGINE=\"-fsanitize=fuzzer\"\r\n```\r\nIt would be nice if the build process of NodeJS can integrate a fuzzing part which enables us to compile with the OSS-Fuzz variables (`CFLAGS`, `CXXFLAGS` and `LIB_FUZZING_ENGINE`) above. The `LIB_FUZZING_ENGINE` variable is only used for linking the final fuzzer and should not be used on any of the compiled libraries. Also note that to get the fuzzers compiled properly they should be compiled against static libraries. As I see the desired goal is, therefore, to have the files in `node/src` be compiled with the `CFLAGS` and `CXXFLAGS` variables above.\r\n\r\nRegarding part 2 then I can certainly start writing more fuzzers and covering more of the NodeJS code, but if you have any suggestions of good APIs for fuzzing then here would be a good place to write I think. ",
        "labels": "feature request",
        "id": 43031
    },
    {
        "title": "Promise-friendly stream.pipeline and stream.finished",
        "body": "I often use `stream.pipeline` in async functions, and it's always a bit painful to have to promisify it.\r\nWhat about exporting a promisified version from the `stream` module directly?\r\nI haven't opened an issue or PR before because I don't have a good idea for the name, but maybe somebody else does!\r\n\r\n@nodejs/streams ",
        "labels": "feature request",
        "id": 43032
    },
    {
        "title": "Enable hooks in fs.statWatchers",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPeople sometimes will encounter the error that `System limit for number of file watchers reached.`. If we enable users to add hooks in fs.statWatchers, they could track the codes that which module call `fs.watchFile` many times\r\n\r\n**Describe the solution you'd like**\r\n```js\r\nconst { statWatchers, watchFile } = require(â€˜fsâ€™)\r\nstatWatchers.on(â€˜statAddâ€™, () => {})\r\nstatWatchers.on(â€˜statRemoveâ€™, () => {})\r\n\r\nwatchFile(â€˜xxxâ€˜, () => {})\r\n```\r\n\r\nRelated code\r\nhttps://github.com/nodejs/node/blob/9949a2e1e3100c4ff1f228bac57c1af95cdc3e9d/lib/fs.js#L1458\r\n",
        "labels": "feature request",
        "id": 43033
    },
    {
        "title": "feature-request fs.fileWrite with option.mkdirp",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\ni am author of npm-package istanbul-lite.\r\nwhen creating coverage-reports and artifacts,\r\nits common to lazily write data to file-directories that have yet to be created.\r\n\r\n**Describe the solution you'd like**\r\n\r\nadd extra boolean `<options>.mkdirp` to functions `fs.writeFile` and `fs.writeFileSync`,\r\nthat will lazily create missing file-directories when writing to file.\r\nthe common-use-case are:\r\n- lazily generate directories when writing coverage-report of instrumented files\r\n- lazily generate directories when writing artifacts in ci and testing\r\n- lazily generate directories when scaffolding new web-projects\r\n\r\n**Describe alternatives you've considered**\r\n\r\ni currently use this helper-function in all my projects,\r\nto lazily generate directories when writing artifacts and coverage-reports.\r\n```javascript\r\n    function fsWriteFileWithMkdirpSync (file, data) {\r\n    /*\r\n     * this function will sync write <data> to <file> with \"mkdir -p\"\r\n     */\r\n        let fs;\r\n        // do nothing if module does not exist\r\n        try {\r\n            fs = require(\"fs\");\r\n        } catch (ignore) {\r\n            return;\r\n        }\r\n        // try to write file\r\n        try {\r\n            fs.writeFileSync(file, data);\r\n            return true;\r\n        } catch (ignore) {\r\n            // mkdir -p\r\n            fs.mkdirSync(require(\"path\").dirname(file), {\r\n                recursive: true\r\n            });\r\n            // rewrite file\r\n            fs.writeFileSync(file, data);\r\n            return true;\r\n        }\r\n    };\r\n```\r\n",
        "labels": "feature request",
        "id": 43034
    },
    {
        "title": "http2 can't send window_update frame",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI'm trying to send a window_update frame using the http2 module.\r\n\r\n**Describe the solution you'd like**\r\nA way to send the window_update frame\r\n\r\n**Describe alternatives you've considered**\r\nLooking into the source code I couldn't find a way to send it, the documentation also doesn't say anything about it. If it is already possible to send it, forgive me.\r\n",
        "labels": "feature request",
        "id": 43035
    },
    {
        "title": "add 'maxHeaderSize' to 'http2'",
        "body": "*This is a feature request for adding `maxHeaderSize` in `http2` as quoted below*\r\n\r\n***\r\nSounds good to me â€“ `maxHeaderSize` could be added along with that. :+1:\r\n\r\n_Originally posted by @addaleax in https://github.com/nodejs/node/issues/32388#issuecomment-601667748_",
        "labels": "feature request",
        "id": 43036
    },
    {
        "title": "Does a `postTask` API make sense for Node.js (in any way)?",
        "body": "Hey, web browsers and framework vendors are working on a `postTask` API for dispatching tasks with particular priorities.\r\n\r\nIt is specified [here](https://github.com/WICG/main-thread-scheduling/) and here is a basic example:\r\n\r\n```js\r\n// https://github.com/WICG/main-thread-scheduling/blob/master/sample-code/scheduling-tasks.html\r\nscheduler.postTask(() => 'This should be line 3', {priority: 'background'});\r\nscheduler.postTask(() => 'This should be line 2', {priority: 'user-visible'});\r\nscheduler.postTask(() => 'This should be line 1', {priority: 'user-blocking'});\r\n\r\n// https://github.com/WICG/main-thread-scheduling/blob/master/sample-code/controlling-scheduled-tasks.html\r\n// a taskController is also an AbortController which we are considering\r\nconst controller = new TaskController('background');\r\nlet result = scheduler.postTask(() => {}, {signal: controller.signal});\r\n// control priority later\r\nheaderController.setPriority('user-blocking');\r\n```\r\n\r\nI opened an [issue](https://github.com/WICG/main-thread-scheduling/issues/17) for Node.js use cases there. Copying it here:\r\n\r\nI've been thinking of exploring adopting this API or experimenting with it in Node.js with the use case I've been thinking about is similar main thread contention. I have a server that serves a large number of users. That server needs to manage QoS of various levels of requests. Some requests should be very fast while for other requests I really wouldn't mind the users to wait a few milliseconds.\r\n\r\nFor example if I have a request that hashes an image and stores it for later retrieval - it might be OK for that request to wait until the CPU is idle. Work that takes more than a few milliseconds typically gets put in a (persistent) queue on servers but there is certain work I probably wouldn't mind waiting for.\r\n\r\nThe same goes for CLI tools, webpack might be interested in performing certain kinds of analysis in a lower priority than actually outputting the compiled code. TypeScript might \"emit\" before it's done type-checking to give users a snappier experience etc.\r\n\r\nThe main issue I see here is that Node.js already exposes threads and processes (with worker_threads and child_process) - so users already have access to the operating system scheduler. That said, it would be cool if some code could be made universal and shared here.\r\n\r\n-----\r\n\r\ncc @shaseley, @sebmarkbage and @acdlite from the `postTask` side and @addaleax @bridgear @nodejs/workers @nodejs/open-standards from the Node side.\r\n\r\n----\r\n\r\nIs this interesting or relevant at all for Node.js and if so should we eventually strive to adopt it?",
        "labels": "feature request",
        "id": 43037
    },
    {
        "title": "ASLR (pie) disabled in v12 Linux amd64 build from nodejs.org",
        "body": "```console\r\n$ pwn checksec ./node/node-v12.16.3-linux-x64/bin/node\r\n[*] '/home/pdxjohnny/Downloads/node/node-v12.16.3-linux-x64/bin/node'\r\n    Arch:     amd64-64-little\r\n    RELRO:    Full RELRO\r\n    Stack:    Canary found\r\n    NX:       NX enabled\r\n    PIE:      No PIE (0x400000)  # <---- ASLR disabled\r\n```\r\n\r\nI see there was some discussion on this back in 2016, but I couldn't really follow, it also looks like `-pie` still exists in some of the build files. Just wanted to report in case it's off by mistake.",
        "labels": "feature request",
        "id": 43038
    },
    {
        "title": "TCP/UDP socket type selection inconsistency",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n`dgram.Socket` requires the socket type (`udp4` or `udp6`) to be provided in its constructor (`dgram.createSocket`), and uses this socket type regardless of the local and remote addresses.\r\n\r\n`net.Socket` does not require the socket type to be provided in advance, and performs `dns.lookup()` with the `family` parameter given in `net.Socket#connect()` to determine the socket type. Unlike `dgram.Socket`, it performs socket binding when a connection is requested, so the local address/port can also be provided as parameters if needed, but the socket type is still determined by the remote host (which makes sense as `net.Server` deals with bound but unconnected sockets). \r\n\r\n`net.Server` uses an IPv6 socket by default, unless an IPv4 address is explicitly provided in `net.Server#listen()`.\r\n\r\nThis results in inconsistent default behavior when comparing TCP and UDP, both for servers and clients. It should be possible to have the UDP socket type be determined by the provided addresses, both for servers and clients.\r\n\r\nEven if `udp6` is chosen, which would in theory work the same for both types of remote addresses, the DNS resolution is inconsistent for TCP/UDP clients. TCP resolution defaults to family type 0, while UDP would use family type 6, so the resulting IP address will be different if the nameserver normally resolves to IPv4 first.\r\n\r\nSee [lib/internal/dgram.js#newHandle](https://github.com/nodejs/node/blob/94e5b5c77dade0d8f7358c66144b75c369679cab/lib/internal/dgram.js#L26), [lib/net.js#internalConnect](https://github.com/nodejs/node/blob/94e5b5c77dade0d8f7358c66144b75c369679cab/lib/net.js#L844) and [lib/net.js#createServerHandle](https://github.com/nodejs/node/blob/94e5b5c77dade0d8f7358c66144b75c369679cab/lib/net.js#L1189).\r\n\r\n**Describe the solution you'd like**\r\n- `dgram.Socket` should not require a socket type in its constructor.\r\n- `dgram.Socket#bind()` should match the `net.Server#listen()` behavior and use an IPv6 socket by default, unless and IPv4 address is explicitly provided.\r\n- `dgram.Socket#connect()` should match the `net.Socket#connect()` behavior and resolve the remote address to determine the socket type, crucially before the `bind()` call is made.\r\n- If the socket is already bound when `connect()` is called, the functionality should remain as it is currently, where the `dns.lookup()` call is made with the family parameter set. If only IPv6 is resolved on an IPv4 bound socket, an error is thrown.\r\n- The socket type currently provided in the constructor could set an internal default address for cases when no local or remote addresses are provided to `bind()` and `connect()`, until this method is deprecated, after which the default address would become ::1 in both cases.\r\n\r\n**Describe alternatives you've considered**\r\n- `dns.lookup()` can be performed manually before the socket is created to decide `udp4`/`udp6`, but this greatly complicates the socket creation flow. This could be moved to `dgram.createConnection` or similar, but this wouldn't fully solve the TCP/UDP client inconsistency.\r\n- If using IPv6 by default is acceptable, the `lookup` parameter of `dgram.createSocket` can be set to a wrapper around the default `dns.lookup()`, with the family type set to 0 instead of 6 and if the result is IPv4 it can be manually mapped to IPv6. This again complicates the socket creation flow.\r\n- The previous alternative could be simplified if `family` and `hints` could be provided as is possible in `net.Socket#connect()`, but this doesn't solve the core problem.",
        "labels": "feature request",
        "id": 43039
    },
    {
        "title": "repl: export isRecoverableError",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'd like to be able to use node's `isRecoverableError` function when working with REPL. Since we are adding additional eval (as recommended in #29719), we are not able to take advantage of the built in one and have to write our own where as the functionality we want is exactly the same as node's native functionality for this function.\r\n\r\n**Describe the solution you'd like**\r\n```js\r\nconst repl, { REPLServer } = require('repl')\r\n\r\nconst r = repl.start({\r\n  prompt: `$ mongosh > `,\r\n  ignoreUndefined: true\r\n});\r\n\r\nconst originalEval = util.promisify(r.eval);\r\n\r\nconst customEval = async(input, context, filename, callback) => {\r\n  let result;\r\n  let err = null;\r\n  try {\r\n    result = await ShellEvaluator.customEval(originalEval, input, context, filename);\r\n  } catch (e) {\r\n    if (repl.isRecoverableError(e, input)) { // use isRecoverableError from node\r\n      return callback(new repl.Recoverable(e))\r\n    } else {\r\n      err = e\r\n    }\r\n  }\r\n  callback(err, result)\r\n};\r\n\r\nr.eval = customEval;\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nI currently just took out `isRecoverableError` and published it as [standalone](github.com/mongodb-js/is-recoverable-error) to get the same functionality. Ideally would be good to deprecate it and use exactly what's in node. ",
        "labels": "feature request",
        "id": 43040
    },
    {
        "title": "Support query parameters (and hash) in CLI paths",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nI am interested in having my scripts respond to arguments supplied by the calling file, rather than for the application as a whole (i.e., checking the likes of `new URL(import.meta.url).searchParams.get('someParam')` rather than `process.argv`).\r\n\r\nThis works well when a file imports another. In polyglot files too, it works to get the query string and hash in the browser (Chrome or Firefox at least) no matter whether the import originates in HTML or in JavaScript.\r\n\r\nBut I get a `MODULE_NOT_FOUND` error when trying the likes of:\r\n\r\n```shell\r\nnode --experimental-modules  index.mjs?someParam=1\r\n```\r\n\r\n...apparently as it is looking for a file here rather than a (portion of) a URL.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAllow the supplied file to be treated as a URL at least as far as the query string and any hash.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIt duplicates effort to add special `process.argv` handling (and it could interfere if the same file is used in an application which has a different root file yet checks `process.argv` as well as `import.meta.url`).\r\n\r\nThanks!",
        "labels": "feature request",
        "id": 43041
    },
    {
        "title": "Add --error-on-warn to vcbuild.bat",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nAdd the `--error-on-warn` flag that was introduced in https://github.com/nodejs/node/pull/32685 to vcbuild.bat\r\n\r\n**Describe the solution you'd like**\r\nWhen `--error-on-warn` flag is specified any compiler warnings should fail the build.\r\n\r\n",
        "labels": "feature request",
        "id": 43042
    },
    {
        "title": "respose.setHeader() should return response to allow chaining",
        "body": "Currently, response.setHeader() doesn't return anything. It really should simply return the response to allow chainings like `response.setHeader(xxx).send(yyy)`",
        "labels": "feature request",
        "id": 43043
    },
    {
        "title": "Unref FSWatcher",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently, when you do `fs.watchFile(...)` the process will run forever.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA possibility to `watcher.unref()` would be great.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n```js\r\nconst watchFile = (path, callback, onError) => {\r\n\tlet previousTime = null;\r\n\r\n\tconst interval = setInterval(async () => {\r\n\t\ttry {\r\n\t\t\tconst {mtimeMs} = await stat(path);\r\n\r\n\t\t\tif (previousTime !== null && mtimeMs !== previousTime) {\r\n\t\t\t\tcallback(mtimeMs, previousTime);\r\n\t\t\t}\r\n\r\n\t\t\tpreviousTime = mtimeMs;\r\n\t\t} catch (error) {\r\n\t\t\tclearInterval(interval);\r\n\r\n\t\t\t// The error part is off the Node.js API\r\n\t\t\tonError(error);\r\n\t\t}\r\n\t}, 1000 * 60).unref();\r\n};\r\n```\r\n\r\nEdit: [seems like the code above is completely unnecessary :man_facepalming:](https://github.com/nodejs/node/issues/33096#issuecomment-620565757)",
        "labels": "feature request",
        "id": 43044
    },
    {
        "title": "`dns.promises.Resolver`  does not have a `.cancel()` method",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nYou cannot cancel pending DNS queries using `dns.promises.Resolver`. Note that `dns.Resolver` has a `.cancel()` method, but the async version does not.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThere are no alternatives yet.\r\n",
        "labels": "feature request",
        "id": 43045
    },
    {
        "title": "[discuss] event loop idle metrics",
        "body": "@trevnorris is working on [landing a change](https://github.com/libuv/libuv/pull/2725) to libuv that will track and report the amount of time the event loop spends in idle time. It's an extremely useful metric that can provide for us a measurement of \"event loop utilization\". In a world of worker threads, monitoring CPU no longer becomes an effective way of monitoring performance and event loop delay is not enough on it's own, so having a built in mechanism for measuring event loop utilization would be fantastic. While there is some work still to be done to get the PR landed in libuv and get that new libuv version landed in core, I did want to briefly discuss how the new metric should be exposed in core.\r\n\r\nIn [this comment](https://github.com/libuv/libuv/pull/2725#issuecomment-616850183) @trevnorris suggests a simple `performance.idleTime()` that returns the direct value of this metric, which records the cumulative time spent in idle since the loop was configured to track. To calculate event loop utilization, however, we also need to know how long the event loop has been running (well, to be specific, how long it's been since the loop was configured to collect the data, which can be turned on but not turned off). Assuming we started the loop and started collecting the metric from the start, we do already record the start time of the event loop (using the performance milestones) so someone could calculate the utilization on their own by accessing those values. However, I think it might make more sense for us to just do the calculation for users and provide an API like `performance.idleTime()` that returns an object with two values `{ idle: n, utilization: y }` where `idle` is the raw idle time and `utilization` is the calculated utilization value. The API should be very low cost to sample using AliasedArray or AliasedStruct as a backing. \r\n\r\n/cc @nodejs/diagnostics @addaleax @mcollina ",
        "labels": "feature request",
        "id": 43046
    },
    {
        "title": "Customizable console.group indentation",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nThe [indentation width used by `console.group`](https://github.com/nodejs/node/blob/05aa67a/lib/internal/console/constructor.js#L406) is too small for me.\r\n\r\n**Describe the solution you'd like**\r\nCustomizable indentation width. Perhaps with a Node flag or env variable as we probably won't want to modify the `console.group` API.\r\n\r\n---\r\n\r\nAs a hacky workaround, I'm currently overwriting `console.group`:\r\n```\r\nconst kGroupIndent = Object.getOwnPropertySymbols(console).find(s => s.description === 'kGroupIndent');\r\nconst increaseIndentBy = '  ';\r\nconst { group, groupEnd } = console;\r\nconsole.group = function () {\r\n\tgroup.apply(this, arguments);\r\n\tthis[kGroupIndent] += increaseIndentBy;\r\n};\r\nconsole.groupEnd = function () {\r\n\tgroupEnd.apply(this, arguments);\r\n\tthis[kGroupIndent] = this[kGroupIndent].slice(0, this[kGroupIndent].length - increaseIndentBy.length);\r\n};\r\n```",
        "labels": "feature request",
        "id": 43047
    },
    {
        "title": "REPL: on macOS, option + delete should delete the entire word",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen I'm using the Node.js REPL, I often run the last command with a few modifications. The REPL already supports `Alt`/`Option`/`âŒ¥` + arrow keys for jumping back and forth across words, but to replace a long identifier or string, I have to hold the `Delete` key for a few seconds.\r\n\r\nIt would be great if `Option`+`Delete` deleted the previous word (to the same point that `Option`+`Left Arrow Key` jumps). Currently, only the last character is deleted.\r\n\r\n**Describe the solution you'd like**\r\nIn the REPL on macOS, holding `Option` and pressing the `Delete` key should delete the word.\r\n\r\n**Describe alternatives you've considered**\r\nIf the Node.js REPL supported \"hold shift to select\", I would expect to be able to select the text to be deleted with `Shift`+`Option`+`Arrow Key`. Though, since the `Shift` key currently doesn't cause any selection, I imagine that's a more complicated feature request than adding support for just the `Option`+`Delete` key combination. ",
        "labels": "feature request",
        "id": 43048
    },
    {
        "title": "Undocumented inability to put REPL in ES module context",
        "body": "There does not appear to be a way to put the REPL in ES module context.\r\n\r\nThe closest you'll get to it seems to be by running:\r\n\r\n1. `node --experimental-repl-await`\r\n2. `await import('./foo.mjs')`\r\n\r\nGive it a try and you'll see that evaluating `import.meta` throws this error:\r\n\r\n```console\r\nimport.meta\r\n       ^^^^\r\n\r\nUncaught SyntaxError: Cannot use 'import.meta' outside a module\r\n```\r\n\r\nI'd like this issue to discuss whether or not this limitation is presently documented somewhere or should be illuminated in https://nodejs.org/api/esm.html or elsewhere.\r\n\r\nNote: this issue isn't about executing code with `--eval` using the `--input-type=module` flag.",
        "labels": "feature request",
        "id": 43049
    },
    {
        "title": "http.createServer highwatermark config",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nhttp.get allows you to set highwatermark values as of node 13.x. Both IncomingMessage and OutgoingMessage supports setting hwm values in config, those settings are also applied to socket. why can't we do the same for http.createServer\r\nnodejs/node#30135\r\n\r\n**Describe the solution you'd like**\r\nset highwatermark and enable objectMode for response (writable). \r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n",
        "labels": "feature request",
        "id": 43050
    },
    {
        "title": "Passing optional argument for detecting the error value in promisify",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nIf I have a callback function that doesn't return `err` as the first argument in the callback function, then I have to write my own function to wrap that callback function into a promise. I think this customizability should be present in the `promisify` to handle these cases. It won't break the existing flow as default behavior can be of using the first argument as `error` value for rejection.\r\n\r\n**Describe the solution you'd like**\r\n\r\nTaking an optional argument in `promisify` to enable the use of other than the first argument for error callback (which in turn is used for promise rejection). Something on the lines of this\r\n```javascript\r\n        if (values.length < index)\r\n          index = 0;\r\n        const errValue = values[index];\r\n        if (errValue) {\r\n          return reject(errValue);\r\n        }\r\n        if (argumentNames !== undefined && values.length > 1) {\r\n          const obj = {};\r\n          for (let i = 0; i < argumentNames.length; i++)\r\n            if (i != index)\r\n              obj[argumentNames[i]] = values[i];\r\n          resolve(obj);\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nOne can write the same logic which is written in the internal method but it is just duplication of logic and can be put into a central place so that `util.promisify` can be leveraged in custom scenarios as well.",
        "labels": "feature request",
        "id": 43051
    },
    {
        "title": "console.deep",
        "body": "During development, I often add another method to the console object which I find very useful and I think that it would be a nice feature to have available natively.\r\n\r\n`console.deep = obj => console.dir(obj, {depth: null, colors: true});`",
        "labels": "feature request",
        "id": 43052
    },
    {
        "title": "Add support for assigning names to worker_threads",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n1. Having the ability to easily name threads would improve/simplify looking at the resource usage while monitoring/debugging in htop (with \"Show custom thread names\") enabled.\r\n2. Commonly used process exporter https://github.com/ncabatoff/process-exporter could expose thread names for prometheus and other monitoring tools in human readable format\r\n\r\n**Describe the solution you'd like**\r\n- accept name or customName in the options object in `new Worker` constructor\r\n- add .setName(<string>) or .setCustomName(<string>) to the worker class\r\n- the above format should be fully backwards compatible\r\n\r\n**Describe alternatives you've considered**\r\nHaven't considered any alternatives at the moment.\r\nI am not sure if process.execArgv can be leveraged here to set a thread name as an alternative way of setting it.",
        "labels": "feature request",
        "id": 43053
    },
    {
        "title": "crypto: poly1305 not supported as hmac",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI can't use poly1305 separately from chacha20-poly1305. Some algorithms (e.g. chacha20-poly1305 in OpenSSH) require the operations to be separate due to limitations/restrictions of chacha20-poly1305 as defined in RFC 7539.\r\n\r\n**Describe the solution you'd like**\r\nTo be able to use poly1305 as efficiently as possible, whether it's via `crypto.createHmac()` or `crypto.sign()` or something else.\r\n\r\n**Describe alternatives you've considered**\r\nUnfortunately there are none, except doing poly1305 in pure javascript, which I assume is going to be pretty slow in comparison.\r\n",
        "labels": "feature request",
        "id": 43054
    },
    {
        "title": "Add maxHeadersCount support for http(s)2 server",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nIn http(s)1, user can limit `server.maxHeadersCount` for server, to avoid malicious request (like hash collision attack), because normal headers wont be more than 20 in fact.\r\n\r\nBut in http(s)2, user has no chance to prevent parse that, even if user check `request.rawHeaders.length/2>2000 && response.writeHead(400)`, the `request.headers` already been parsed.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd `server.maxHeadersCount`, just like http(s)1 did.\r\n\r\n**Describe alternatives you've considered**\r\n",
        "labels": "feature request",
        "id": 43055
    },
    {
        "title": "Consider something clever for extension-less executables",
        "body": "It would be nice if ECMAScript shebang files with no extension\r\na. worked :)\r\nb. were assumed to be modules for Node.js current+\r\n\r\nEspecially for server people that have lots of command-line scripts\r\n\r\nAnd I think we should plan for a future without require\r\n\r\nexhibit:\r\n<pre><strong>\r\nnode --print '\"#!/usr/bin/env node\\n// node --experimental-modules e\\nimport {inspect} from QutilQ\\nconsole.log(`${inspect(QabcQ)}`)\".replace(/Q/g, String.fromCharCode(39))' >e && chmod +x e\r\n./e</strong>\r\n(node:38910) Warning: To load an ES module, set \"type\": \"module\" in the package.json or use the .mjs extension.\r\n/opt/foxyboy/sw/pri/subtree/ecmascript2049/packages/e:3\r\nimport {inspect} from 'util'\r\n^^^^^^\r\n\r\nSyntaxError: Cannot use import statement outside a module\r\n    at wrapSafe (internal/modules/cjs/loader.js:1063:16)\r\n    at Module._compile (internal/modules/cjs/loader.js:1111:27)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1167:10)\r\n    at Module.load (internal/modules/cjs/loader.js:996:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:896:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12)\r\n    at internal/main/run_main_module.js:17:47\r\n<strong>$ cat e</strong>\r\n#!/usr/bin/env node\r\n// node --experimental-modules e\r\nimport {inspect} from 'util'\r\nconsole.log(`${inspect('abc')}`)\r\n</pre>\r\n\r\nThis shebang no work either:\r\n#!/usr/local/bin/node --experimental-modules\r\n\r\nThe solutions at present is to:\r\n1. use .mjs extension\r\n2. symlink to a file that has .mjs extension. Not portable, I suppose, on certain file systems from up north and Applish implementations of WebDAV\r\n3. have a package.json in the same or superior directory. May cause unforeseen troubles\r\n4. symlink to a directory with a package.json. Possibly not portable\r\n\r\n**node -v && uname -a**\r\nv13.11.0\r\nDarwin c87m1.local 19.3.0 Darwin Kernel Version 19.3.0: Thu Jan  9 20:58:23 PST 2020; root:xnu-6153.81.5~1/RELEASE_X86_64 x86_64\r\n\r\nA related trouble is if you happen to have a native-code dependency. requires node_modules and such",
        "labels": "feature request",
        "id": 43056
    },
    {
        "title": "type: module should also enable experimental-json-modules",
        "body": "When Dennis Ritchie came up with the shebang in 1979, he did not consider Node.js v12.0.0\r\n\r\nSo on the shebang line **#!/usr/bin/env node** you cannot provide arguments\r\n\r\nIf you do a different shebang line, it is no longer portable to macOS or Android\r\n\r\nTherefore, adding type:module to package.json should enable every reasonable experimental module feature, in particular **experimental-json-modules** if it doesn't break us, it will make us stronger\r\n\r\nPeople who do not want this behavior should use an intermediate script or custom command-line like json importers have to do now\r\n\r\nnode -v && uname -a\r\nv13.11.0\r\nDarwin c87m1.local 19.3.0 Darwin Kernel Version 19.3.0: Thu Jan  9 20:58:23 PST 2020; root:xnu-6153.81.5~1/RELEASE_X86_64 x86_64",
        "labels": "feature request",
        "id": 43057
    },
    {
        "title": "minor request on logging classes",
        "body": "When logging object, functions and classes you sometimes see function and classes being printed the same way as such:\r\n\r\n![SkaÌˆrmavbild 2020-03-14 kl  21 28 43](https://user-images.githubusercontent.com/1148376/76689886-d5d71380-663a-11ea-96f2-7a0029a6f72b.png)\r\n\r\nI wish they where a bit more distinguish if it is a function or a class so you know if you have to call the <s>\"function\"</s> class with the `new` keyword and expect something back\r\nkinda like chrome's devtool:\r\n\r\n![SkaÌˆrmavbild 2020-03-14 kl  21 32 30](https://user-images.githubusercontent.com/1148376/76689940-74fc0b00-663b-11ea-8188-41408d8aa765.png)\r\n\r\nwith the prefixed `class` and `f` in the beginning\r\n\r\nmaybe with an other color (same as the number color - orange) or like my atom editor:\r\n![SkaÌˆrmavbild 2020-03-14 kl  21 38 41](https://user-images.githubusercontent.com/1148376/76689997-3e72c000-663c-11ea-8f09-62031f31b067.png)\r\n\r\nit's not so much about styling, (the above are just some suggestions) \r\nthe request feature is just more about distinguish  classes from functions in the terminal\r\n\r\n(don't mind as much if this is being discarded and closed since it's not so important to me - just wishful)",
        "labels": "feature request",
        "id": 43058
    },
    {
        "title": "Worker Threads: Add transferList to Worker constructor options",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nBased on the current documentation listed [here](https://nodejs.org/api/worker_threads.html#worker_threads_new_worker_filename_options), it doesn't seem possible to specify a `transferList` on the Worker constructor. This prohibits passing `transferList` items such as `MessagePort`. Attempts to pass a `MessagePort` within the Workers `workerData` currently results in the following error.\r\n```\r\nTypeError: MessagePort was found in message but not listed in transferList\r\n```\r\n**Describe the solution you'd like**\r\n\r\nGiven the current error, and if its technically feasible to do so...being able to supply a `transferList` on the `Worker` constructor would be helpful in initializing the Worker immediately with a `MessagePort` rather than sending the `MessagePort` on a subsequent `postMessage(...)`. Perhaps something like the following could be allowed.\r\n\r\n```javascript\r\nconst channel = new MessageChannel()\r\nconst workerData = { port: channel.port1 }\r\nconst transferList = [channel.port1]\r\nconst worker = new Worker('./worker.js', { workerData, transferList  })\r\n```\r\n\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIt is entirely possible to work around this by sending a `MessagePort` in a subsequent `postMessage(..., transferList)`. However it doing so involves async initialization of the `Worker` which is less desirable than initializing immediately on the `Worker` constructor.\r\n",
        "labels": "feature request",
        "id": 43059
    },
    {
        "title": "child_process, expose a raw exit code",
        "body": "I'd like to have a feature in node to access the raw exit status of the program, for a better emscripten system() implementation. Right now emscripten's system implementation is repacking the exit code to return it in the \"waitpid\" format as required by POSIX. However, this only POSIX specific and doesn't make much sense e.g. on Windows, but we also don't want to return values that doesn't match when compiling and running the C program natively since it could cause incompatibility. Thus having access to raw exit code of a child program from node would be best approach to go here!\r\n\r\nSee the emscripten system implementation and related node / libuv discussion here:\r\nhttps://github.com/emscripten-core/emscripten/pull/10547",
        "labels": "feature request",
        "id": 43060
    },
    {
        "title": "Ability for async functions to retreive their CLS context",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\nRight now, the `AsyncLocalStorage` object needs to be externally available for the async functions to avail the store.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nImplement a `getContextCLS` API that returns the `AsyncLocalStorage` object under which this asynchronous call was initiated. Return undefined, if it was not run under `AsyncLocalStorage` semantics.\r\n\r\nIllustration:\r\n\r\n```js\r\nconst { AsyncLocalStorage } = require('async_hooks');\r\n\r\nfunction main() {\r\n  const cls1 = new AsyncLocalStorage();\r\n  const cls2 = new AsyncLocalStorage();\r\n  cls1.run(() => {\r\n    const store = cls1.getStore()\r\n    store.set('x', 'y')\r\n    setTimeout(foo, 1000)\r\n  })\r\n  \r\n  cls2.run(() => {\r\n    const store = cls2.getStore()\r\n    store.set('x', 'z')\r\n    setTimeout(foo, 1000)\r\n  })\r\n}\r\n\r\n\r\nfunction foo() {\r\n  // obtain the cls object here that this async call was part of\r\n  // for example:\r\n  // const cls = getContextCLS()\r\n  //  const store = cls.getStore()\r\n  //  console.log(store.get('x')\r\n  // prints 'y' and 'z' as and when those are called.\r\n}\r\n\r\nmain()\r\n```\r\nUse case: in a concurrent workload scenario, it is not easy to maintain `AsyncLocalStorage` objects globally, and across multiple async function families.\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\nAlternative is to share these objects globally (which is not very attractive)",
        "labels": "feature request",
        "id": 43061
    },
    {
        "title": "Solid Node.js with official type system support",
        "body": "## Is your feature request related to a problem? Please describe.\r\n\r\nWhile js became more and more popular, typescript and flow appears to deal with  stability and maintainability for large projects, yet we lack support for type definitions for Node.js core api. I think the needs goes strong and strong, one proof is that https://www.npmjs.com/package/@types/node has reached 23 million download weekly.\r\n\r\nCommunity already has `@type/node`, should we really support it in core ?\r\nI think we should, here are the reasons:\r\n\r\n### It's not reflect the api change quickly enough\r\nFor example, the `wasi` api takes some time added to the repo.\r\nApis like newly or changed takes time to get adopted, developers will has\r\nto wait for this.\r\n\r\n### It's not related to Node.js version consistently\r\nthis package doesn't related Node.js versions. But we has lts, latest and other versions, this can be problematic and got surprised behavior. If we have \r\nofficial support, developers can choose the related version and got precise result.\r\n\r\n### other\r\nIt's only for typescript. We can expand our official type system to flow or other newly solutions.\r\nAlso contribute to this package is too much pain.\r\n\r\n## Describe the solution you'd like\r\n\r\nI am thinking we generate types file from our markdown doc or js source file (the `libs` folder ), not sure whether this eventually can work. Another solution is we invent a new dsl :)\r\n\r\nEventually we should make should publish types package when we release a new Node.js version.\r\n\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43062
    },
    {
        "title": "Feature Request: way to merge streams like pumpify(a, b)",
        "body": "* **Version**: v13.6.0\r\n* **Platform**: Linux 535297d0ce81 4.19.0-4-amd64 #1 SMP Debian 4.19.28-2 (2019-03-15) x86_64 GNU/Linux\r\n* **Subsystem**: stream\r\n\r\n### What steps will reproduce the bug?\r\n\r\n    const stream = require('stream');\r\n    \r\n    // two different transforms (these work)\r\n    const transform_double = new stream.Transform({\r\n        transform(chunk, encoding, callback) {\r\n            this.push(chunk);\r\n            this.push(chunk);\r\n            callback();\r\n        }\r\n    });\r\n    const transform_uppercase = new stream.Transform({\r\n        transform(chunk, encoding, callback) {\r\n            this.push(chunk.toString().toUpperCase());\r\n            callback();\r\n        }\r\n    });\r\n    \r\n    // compose the transforms\r\n    const parser = stream.pipeline(transform_double, transform_uppercase, ()=>0);\r\n    \r\n    // run stdin through it\r\n    process.stdin.pipe(parser).pipe(process.stdout);\r\n\r\nThen pipe some text to it eg: `echo \"foo\" | node reproduce.js`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nalways\r\n\r\n### What is the expected behavior?\r\n\r\nThe text sent in should go through both transformations, eg output \"FOOFOO\"\r\n\r\n### What do you see instead?\r\n\r\nThe text piped in is only sent to the last transformation, eg output \"FOO\"\r\n\r\n### Additional information\r\n\r\nThe docs here don't say what this function returns:\r\nhttps://nodejs.org/api/stream.html#stream_stream_pipeline_streams_callback\r\n\r\nI'm saying that it should return a duplex stream so I can read and write to the ends of the pipeline.",
        "labels": "feature request",
        "id": 43063
    },
    {
        "title": "Support AbortSignals in async API",
        "body": "[AbortSignals](https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal) are used in fetch to abort a request. They are useful to close requests if they don't happen to be necessary. AbortSignals are not widely used yet in the JavaScript ecosystem but they seem like they could be useful if they would find a wider adoption.\r\n\r\nA node.js API that comes to mind is if a web framework would provide an abort signal that this could be comfortable to be used as a means to abort a file stream:\r\n\r\n```javascript\r\ncreateReadStream('file.bin', { signal: req.signal }).pipe(res)\r\n```\r\n\r\nOther places this might be if there was an abort signal for the process that could be used instead of `process.on('SIGTERM', ...)`, ex.:\r\n\r\n```javascript\r\nawait readFile('file.bin', { signal: process.abortSignal })\r\n```\r\n\r\nWhich could be an easy means to stop allocating money if a CLI tool is used to read a very large file by accident.\r\n\r\nAt the current point I am not sure at how many places this would be useful, or how useful it would be at each case, but I think opening the discussion has merit.",
        "labels": "feature request",
        "id": 43064
    },
    {
        "title": "httpAgent.absoluteMaxSockets ",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\nWe are trying to ensure the maximum number of active connections from NodeJS to backend systems is maintained.  `httpAgent.maxSockets` behaves at a \"per origin\" level which is also dynamic and not completely deterministic.  This makes it difficult to create logic and patterns as the number of connections grows.  Instead we propose `absoluteMaxSockets` (or some other clever name), that enforces a maximum number of active sockets regardless of the origin.  \r\n\r\nDoing this now is possible in the user space, but requires a great deal of code and logic to bind to each and every socket connection event and do the counting and enforcement, etc.\r\n\r\n**Describe the solution you'd like**\r\nAssuming `httpAgent.absoluteMaxSockets` is implemented, if the number of open sockets across all origins grows beyond this number, the http agent would first attempt to check and see if any sockets can be closed, and if so attempt to close those sockets prior to opening a new one.\r\nAssuming one cannot be open, an exception would be thrown at the time a request is made since a new socket connection cannot be opened.\r\n\r\n**Describe alternatives you've considered**\r\nAs mentioned, we could implement this in user space, but it's tricky and cumbersome.\r\n",
        "labels": "feature request",
        "id": 43065
    },
    {
        "title": "Using node --flag, check if loaded dependencies versions match expected versions",
        "body": "Of course, NPM + package.json are not Node.js perse - so this feature would have to work independently of a package manager.\r\n\r\nI put the question on SO:\r\nhttps://stackoverflow.com/questions/60367401/throw-error-if-loaded-package-version-does-not-match-package-version-in-package\r\n\r\nPerhaps there could be some declarative file like package.json that told Node.js what version of a package should be loaded at runtime. The main motivation is to prevent accidentally using the wrong version of a library when running code - this happens often because `node_modules` is not in version control for most users.\r\n\r\nFor a language that's not compiled, this would help I think. The most common use case is doing:\r\n\r\n```bash\r\ngit pull\r\nnode .\r\n```\r\n\r\ninstead of doing\r\n\r\n```bash\r\ngit pull\r\nnpm i\r\nnode .\r\n```\r\n\r\nthere might be other solutions to this problem and I am interesting in discussing alternatives I guess.",
        "labels": "feature request",
        "id": 43066
    },
    {
        "title": "Same second parameter type on assert.throws and asserts.doesNotThrow",
        "body": "The type of the second parameter in function `assert.doesNotThrow`, is `<RegExp> | <Function>`,\r\nbut the in the function `assert.throws`, it be `<RegExp> | <Function> | <Object> | <Error>`.\r\n\r\nThey would be the completely opposite function I think.\r\n\r\nrelated doc: \r\n- https://nodejs.org/dist/latest-v13.x/docs/api/assert.html#assert_assert_throws_fn_error_message\r\n- https://nodejs.org/dist/latest-v13.x/docs/api/assert.html#assert_assert_doesnotthrow_fn_error_message\r\n\r\n**Describe the solution you'd like**\r\n\r\nsupport parameter `error` for type `<Object>` and `<Error>`.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nenhance code\r\n\r\nhttps://github.com/nodejs/node/blob/1c4e984ed970612f129db2ba6f684311418ed3a2/lib/assert.js#L802-L825\r\n",
        "labels": "feature request",
        "id": 43067
    },
    {
        "title": "Proposal: Implament dynamic import from urls via fetch include relativ path support",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI want to host my own files on my own server and import them via https including relative path support without resolving the dependency tree myself. at present I have coded a userland ESM loader using the data: URL string argument syntax with dynamic import() the dataUrl syntax already supports Node Resolve Algorithm but NOT Relative paths as the dataUrl has no knowledge where it comes from\r\n\r\nso I would need to fetch the URL to get the string representation to replace relative URLs with the right location and then load that and loop over all dependencies that are relative.\r\n\r\n**Describe the solution you'd like**\r\nImplement nativ support for relative module resolution when using import. and even better Implement the whole feature import('https://myscript') and I would love when file:// is also supported in the same fashion maybe I need to split that over many proposals what do you think?\r\n\r\ndeno at present is using parcel a JSBundler for that to fetch resources and evaluate complete dependency tree upfront execution and evaluation.\r\n\r\nso I propose to add that ability to the loader itself it should remember on call via a URL the origin location and handle relative module resolution like it would do it local \r\n\r\n**Describe alternatives you've considered**\r\nas described at the problem section I have experimented with my userland loader https://github.com/direktspeed/esm-loader and adding module resolution via rollup, for example, would solve the problem but that can be maybe better implemented inside node itself\r\n",
        "labels": "feature request",
        "id": 43068
    },
    {
        "title": "Proposal: Implament https://www.w3.org/DOM/",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWe Will Solve API Incompatiblity Related to Browser Environments \r\n\r\n**Describe the solution you'd like**\r\nImplamenting a JSDOM like environment directly into node we could introduce something as easy as a api that takes a url and that gets Rendered Into JSDOM with its own context the DOM with its whole API that also reduces the need for other browser compatible API's that would without this context make no sence.\r\n\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\nThe Alternate at present is to run your code in chrome headless to have it isolated and behave like in the browser and later get the results.\r\n\r\nhttps://developers.google.com/web/tools/puppeteer/articles/ssr",
        "labels": "feature request",
        "id": 43069
    },
    {
        "title": "Evaluate node core modules within a `vm.Context`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nOne of Jest's longest-standing issue are about globals in tests being different from Node's, see https://github.com/facebook/jest/issues/2549.\r\n\r\nShort example illustrating the problem:\r\n\r\n```js\r\nconst {createContext, compileFunction} = require('vm');\r\n\r\nconst context = createContext({});\r\n\r\nconst code = `\r\n  const fs = require('fs');\r\n  const assert = require('assert');\r\n\r\n  try {\r\n    fs.readFileSync('/some/faulty/path', 'utf8')\r\n  } catch (error) {\r\n    assert(error instanceof Error)\r\n  }\r\n`;\r\n\r\nconst compiledFunction = compileFunction(code, ['require'], {\r\n  parsingContext: context,\r\n});\r\n\r\ncompiledFunction(require);\r\n```\r\n\r\nRun this example, and the `instanceof` test will fail. Remove `parsingContext` option, and it will pass.\r\n\r\n**Describe the solution you'd like**\r\n\r\nJest implements its own `require` etc, which works great most of the time, but in the case of node core modules, it fallbacks to requiring the module outside of the context. AFAIK the JS source of the node core modules are embedded in the binary of Node, so we cannot read them and pass them though `compileFunction`, `SourceTextModule` or some such ourselves so the globals would be the same.\r\n\r\nIt would be great if Node provided some API allowing the JS of core modules to be evaluated within a `vm.Context`.\r\n\r\n(I had originally given up on this, but seeing as #30709 solves the super old #855 I thought maybe we might be lucky enough that this is possible as well? ðŸ˜€)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nWe have tried to mess around with setting `Symbol.hasInstance` and just injecting globals from the outside (although that breaks the encapsulation we're aiming for by using separate `Context`s in the first place) without luck. It's also a moving target as we'd have to add that property to all globals.\r\n\r\n---\r\n\r\nFWIW the Jest issue has a $500 bounty which I'd be happy to give to someone solving this in core, or the JS Foundation if that's more correct.",
        "labels": "feature request",
        "id": 43070
    },
    {
        "title": "Modules preloading suggestion",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nNot exactly a problem. Maybe something that will make life easier. Currently to require modules before executing a script we need to run `node` with the `-r` flag and it might become harder to maintain if we need to require multiple modules.\r\n\r\nPeople usually use this option like a \"bootstraper\" or for running setup scripts (i.e. `dotenv/config`).\r\n\r\n**Describe the solution you'd like**\r\nI'd like to have a place to specify, in order and separated by a new line, the modules needed to be required before executing scripts. Something like:\r\n\r\n```\r\ndotenv/config\r\ntsconfig-paths/register\r\n```\r\n\r\nAnd then something like that to run scripts:\r\n\r\n`node --requirements-file requirements.txt my-script.js`\r\n\r\nWe could even maybe ignore the flag altogether if the requirements file -- which has yet to be named -- exists.\r\n\r\n**Describe alternatives you've considered**\r\nI'm doing something sorta like that on [this repository](https://github.com/zaguiini/nodejs-ts-boilerplate/blob/master/package.json#L9) of mine. Take a look.\r\n",
        "labels": "feature request",
        "id": 43071
    },
    {
        "title": "vm: ProvideÂ aÂ way toÂ replace theÂ underlying globalÂ object ofÂ theÂ GlobalProxy",
        "body": "## Is your feature request related to a problem? Please describe.\r\n\r\nIâ€™veÂ been lookingÂ into whatâ€™sÂ needed toÂ implement properÂ navigation inÂ [**JSDOM**](https://github.com/jsdom/jsdom).\r\n\r\nThis requires replacing theÂ underlying `[[Window]]` instance ofÂ theÂ `WindowProxy`.\r\n\r\n## Describe the solution you'd like\r\n\r\nTheÂ desiredÂ solution wouldÂ be anÂ APIÂ exposed onÂ `vm.Context`Â (<https://github.com/nodejs/node/pull/30709>) thatÂ wouldÂ perform aÂ newÂ `makeContext`Â call, replacingÂ theÂ underlying `#global`Â privateÂ field andÂ `[[Window]]` privateÂ slot ofÂ theÂ `WindowProxy`, whileÂ ensuringÂ that theÂ following testÂ passes:\r\n\r\n<details>\r\n<summary><code>globalProxy.test.js</code></summary>\r\n<p></p>\r\n\r\n```js\r\nconst { createWindow, navigateWindow } = require(\"./windows.js\");\r\nconst symbolProp = Symbol(\"non-configurable\")\r\n\r\nconst {\r\n\tvmContext,\r\n\tglobalImpl,\r\n\tglobalObject,\r\n\tglobalProxy,\r\n} = createWindow({ url: \"http://example.org/\" });\r\n\r\nassert.strictEqual(globalProxy.origin, \"http://example.org\");\r\n\r\n// `globalProxy[symbolProp]` doesn't exist:\r\nassert.strictEqual(Object.getOwnPropertyDescriptor(globalProxy, symbolProp), undefined);\r\nassert.strictEqual(Object.getOwnPropertyDescriptor(globalObject, symbolProp), undefined);\r\n\r\nObject.defineProperty(globalProxy, symbolProp, { value: \"non-configurable\" });\r\n\r\n// `globalProxy[symbolProp]` is now a non-configurable own property of `globalObject`:\r\nassert.strictEqual(Object.getOwnPropertyDescriptor(globalProxy, symbolProp).configurable, false);\r\nassert.strictEqual(Object.getOwnPropertyDescriptor(globalObject, symbolProp).configurable, false);\r\n\r\nconst {\r\n\tnewGlobalImpl,\r\n\tnewGlobalObject,\r\n} = navigateWindow(vmContext, { url: \"https://example.org/\" });\r\nconst newGlobalProxy = vm.runInContext(\"this\", vmContext);\r\n\r\nassert.strictEqual(globalProxy, newGlobalProxy);\r\nassert.strictEqual(globalProxy.origin, \"https://example.org\");\r\nassert.notStrictEqual(globalObject, newGlobalObject);\r\nassert.notStrictEqual(globalImpl, newGlobalImpl);\r\n\r\n// `globalProxy[symbolProp]` doesn't exist anymore, as the proxy target is now `newGlobalObject`:\r\nassert.strictEqual(Object.getOwnPropertyDescriptor(globalProxy, symbolProp), undefined);\r\nassert.strictEqual(Object.getOwnPropertyDescriptor(newGlobalObject, symbolProp), undefined);\r\n\r\n// `globalObject[symbolProp]` is still the old non-configurable own property:\r\nassert.strictEqual(Object.getOwnPropertyDescriptor(globalObject, symbolProp).configurable, false);\r\n```\r\n</details>\r\n\r\n<details>\r\n<summary><code>windows.js</code> (NewÂ API isÂ calledÂ here)</summary>\r\n<p></p>\r\n\r\n```js\r\nfunction setupWindow(window, globalProxy, options, vmContext) {\r\n\tinstallInterfaces(window);\r\n\tObject.setPrototypeOf(window, window.Window.prototype);\r\n\tWindow.setup(\r\n\t\t/* globalObject */ window,\r\n\t\t/* wrapperInstance */ window,\r\n\t\t/* constructorArgs */ undefined,\r\n\t\t/* privateData */ { globalProxy, options, vmContext }\r\n\t);\r\n}\r\n\r\nexports.createWindow = (options = {}) => {\r\n\tlet vmContext = new vm.Context({ origin: computeOrigin(options.url) });\r\n\tlet window = context.global;\r\n\tlet globalProxy = vm.runInContext(\"this\", vmContext);\r\n\r\n\tsetupWindow(window, vmContext, globalProxy, options)\r\n\treturn {\r\n\t\tvmContext,\r\n\t\tglobalImpl: idlUtils.implForWrapper(window),\r\n\t\tglobalObject: window,\r\n\t\tglobalProxy\r\n\t}\r\n}\r\n\r\nexports.navigateWindow = (vmContext, options = {}) => {\r\n\t// New API is called here:\r\n\tvmContext.createNewGlobalObject({ origin: computeOrigin(options.url) });\r\n\r\n\tlet window = context.global;\r\n\r\n\tsetupWindow(window, vmContext, globalProxy, options);\r\n\treturn {\r\n\t\tnewGlobalImpl: idlUtils.implForWrapper(window),\r\n\t\tnewGlobalObject: window\r\n\t}\r\n}\r\n```\r\n</details>\r\n\r\n## Describe alternatives you've considered\r\n\r\n1. Just replace the `WindowImpl` instance.\r\n   <dl>\r\n   <dt>Pros:<dd>\r\n\r\n   - Simple to implement.\r\n\r\n   <dt>Cons:<dd>\r\n\r\n   - Keeps global properties from previous runs.\r\n\r\n   <dt>Conclusion:<dd>\r\n\r\n   Viable only for when `runScripts` isn't enabled, though it might be better to use option 3 even in this case.\r\n   </dl>\r\n\r\n2. UseÂ `Reflect.deleteProperty` andÂ `WebIDLWindow.setup` toÂ try andÂ reset asÂ much ofÂ theÂ `Window` globalÂ object asÂ possible (won'tÂ beÂ able toÂ delete nonâ€‘configurableÂ properties, suchÂ asÂ theÂ `symbolProp` shownÂ in theÂ aboveÂ example).\r\n   <dl>\r\n   <dt>Pros:<dd>\r\n\r\n   - Resets most of the global object.\r\n\r\n   <dt>Cons:<dd>\r\n\r\n   - Harder to implement.\r\n   - Results in a global which is in a broken state.\r\n\r\n   <dt>Conclusion:<dd>\r\n\r\n   Iâ€™d rather implement alternative 3.\r\n   </dl>\r\n\r\n3. Implement aÂ custom `WindowProxy` thatÂ makes allÂ propertiesÂ configurable, whileÂ keepingÂ track ofÂ whichÂ ones shouldÂ beÂ treated asÂ non-configurable.\r\n   <dl>\r\n   <dt>Pros:<dd>\r\n\r\n   - Supports fully re-setting the global object.\r\n\r\n   <dt>Cons:<dd>\r\n\r\n   - Hard to implement.\r\n   - Not fully spec compliant.\r\n   - `with`Â andÂ Proxies areÂ currentlyÂ incompatible (<https://github.com/nodejs/node/issues/30985>), thisÂ canÂ be workedÂ around usingÂ `Symbol.unscopables`.\r\n\r\n   <dt>Conclusion:<dd>\r\n\r\n   Iâ€™llÂ probably implementÂ this after <https://github.com/jsdom/jsdom/pull/2835> is merged forÂ **Node**Â versions withoutÂ <https://github.com/nodejs/node/pull/30709>.\r\n   </dl>",
        "labels": "feature request",
        "id": 43072
    },
    {
        "title": "expose SSL_export_keying_material via Node API (e.g. like SSL_get_shared_sigalgs) ",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'm trying to generate a check sum that is based on the keying material (https://stackoverflow.com/questions/60232165/ssl-export-keying-material-in-node-js). Right now node has no method to call this function, or any other way of retrieving this information.\r\n\r\n**Describe the solution you'd like**\r\nExpose an api like the GetSharedSigalgs that offers a way to access the native SSL export keying material method.\r\nsee https://nodejs.org/api/tls.html#tls_tlssocket_getsharedsigalgs\r\nfor the keying material method see https://www.openssl.org/docs/man1.0.2/man3/SSL_export_keying_material.html\r\n\r\n**Describe alternatives you've considered**\r\nI tried to get this kind of information via 'keylog' event, but this is never emitted in my scenario. I also believe (couldn't verify though), that this is something else than the exporting keying material function offers, due to the fact that I cannot provide any label to \"keylog\" which is mandatory for the keying material method.\r\n\r\nSubsystem: tls (tls.TLSSocket)",
        "labels": "feature request",
        "id": 43073
    },
    {
        "title": "add debug logs to _stream_writable",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nIn debugging some Node.js stream related code, I'm getting debug logs for the readable stream, but not seeing any for the writable. Upon further investigation I found that there are no debug logs set up in writable stream. \r\n\r\nhttps://github.com/nodejs/node/blob/master/lib/_stream_writable.js\r\n\r\n**Describe the solution you'd like**\r\nAdd some nice logging to _stream_writable similar to _stream_readable.",
        "labels": "feature request",
        "id": 43074
    },
    {
        "title": "util.inspect should visually format numbers differently than booleans",
        "body": "Regarding this issue:\r\nhttps://github.com/nodejs/help/issues/2462\r\n\r\nnumbers and booleans are both yellow. seems odd. why wouldn't the 3 primitive primitives be different colors by default?\r\n\r\nright now:\r\n\r\n\r\n> strings: green\r\n> booleans: yellow\r\n> numbers: yellow\r\n\r\n\r\nsuggested:\r\n\r\n> strings: green\r\n> booleans: yellow\r\n> numbers: blue\r\n\r\n\r\nfor example this is happening now:\r\n\r\n<img width=\"225\" alt=\"Screen Shot 2020-02-07 at 11 31 26 AM\" src=\"https://user-images.githubusercontent.com/11139560/74060071-0d98ce80-499e-11ea-9561-4f1ad72a9cc5.png\">\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43075
    },
    {
        "title": "How much is my memory?",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: linux / all\r\n* **Subsystem**: process\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThis is opened for 3 reasons:\r\n - help progress #23277\r\n - gather intelligence on internal memory management where I may have lack of clarity\r\n - help clearly define process's memory usage - for future support and documentation (specifically for cloud workloads where usage has bearings on billing)\r\n\r\n$ cat foo.cc\r\n```c\r\n#include <stdlib.h>\r\n#include <unistd.h>\r\n#include <stdio.h>\r\n#include <malloc.h>\r\n\r\nvoid *list[1024 * 1024];\r\n\r\nint r() {\r\n  // add a one so as to never return 0\r\n  return 1 + random() % 137;\r\n}\r\n\r\nint main() {\r\n  // use calloc so that the pages are 'touched'.\r\n  for(int i=0;i< 1024 * 1024;i++)\r\n    list[i] = calloc(r(), 1);\r\n  for(int i=0;i< 1024 * 1024;i++)\r\n    free(list[i]);\r\n  sleep(60 * 1000);\r\n}\r\n```\r\n\r\nA linux (RHEL 8) observation:\r\nThe static memory usage (without the callocs) of this code is 12 MB\r\n - 8 MB for the array (64-bit, so 8 * 1MB)\r\n - 4 MB for a.out + libc + ...\r\n\r\ntop output after the program runs and sleeps for enough time:\r\n```\r\n$ top -p 6777\r\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                            \r\n 6777 root      20   0   99772  96344    932 S   0.0   5.1   0:00.16 a.out \r\n\r\n$ cat /proc/meminfo | grep MemFree\r\nMemFree:         1637932 kB\r\n$\r\n```\r\n\r\ntop output after the system is heavily `loaded`:\r\n```\r\ntop -p 6777\r\n  PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND                            \r\n 6777 root      20   0   99772      0      0 S   0.0   0.0   0:00.16 a.out \r\n$ cat /proc/meminfo | grep MemFree\r\nMemFree:           70444 kB\r\n```\r\n\r\n`pmap` shows 85 MB is still mapped into the process, matching with `top`.\r\n\r\n```\r\n0000000002c7c000  87384K rw---   [ anon ]\r\n```\r\n\r\nObservations:\r\n - `rss` stays high (~ virtual memory) for ever, if there is no load in the system\r\n - virtual memory stays high even after all the allocated memory is freed.\r\n - all numbers tally: 85 for the dynamic memory + 12 for the static part = 97, as shown in top\r\n\r\n\r\nProblems / questions:\r\n - what is a meaningful measure of program's memory usage? we can say these are the values we get from the OS, and leave it for the user to interpret those, but that does not help them enough. `rss` is a function of not only on the program's activity with memory, but also to other parts of the system. `virtual memory` on the other hand was apparently the sum of allocations (malloc/calloc/mmap...) in the program, but looks like it is not, and depends on the glibc's memory management implementations and its discretion as to when to retain and when to release chunks back to OS, and as to what size of chunks qualify for removal, and may be also depend on the memory usage hueristics as well! When I used 4K chunks for calloc/free, I got different results.\r\n\r\nIn Cloud workloads this has implications. A user would want to minimize memory tagged against their process and would do everything in their application to achieve that, but due the dependency on the system load and allocation caching behavior, this would not translate well?\r\n\r\n - memory leak definition becomes loose and detection becomes less comprehensive. Plurality of tools profiling the app from different angles would bring-in mutually contradicting results? For example: in a batch process, a code that genuinely leaks an MB versus an MB that is cached in malloc arenas - what is the difference from outside, and why should I worry more about the former and not worry about the later?\r\n\r\n - I read about wss (working set size) - that is a true measure of how much memory the program is actively engaged in. The idea looks like tracking paging-in; as that would be a true reflection of the program's needs. I don't find an API for this, nor a platform-neutral way to obtain this. Even if we could, this has an issue - the value is transient, as it depends on the history of usage, not the current state?",
        "labels": "feature request",
        "id": 43076
    },
    {
        "title": "test: individual test run on Windows does not report segfaults",
        "body": "Just leaving this here as it's not something I can get to just yet but I will be looking at it. Currently when running an individual test case on Windows (e.g. `Release\\node test\\parallel\\test-whatever`, if Node.js crashes during the run it just aborts with no obvious indicator of the crash. This is typical on Windows, unfortunately, when not using a debug build. Since we're wrapping the test process anyway when there are `Flags:` in the test file, it would make sense to also check the exit code of the child process on Windows to report if the process exited due to a fault.",
        "labels": "feature request",
        "id": 43077
    },
    {
        "title": "TLS 1.3 ESNI",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\nTLS 1.3 ESNI, is there any plan to implement the esni in near future? \r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n",
        "labels": "feature request",
        "id": 43078
    },
    {
        "title": "Suggestion: clone variable",
        "body": "Hey, I think clone variable is very common, I think there should be syntax for creating another pointer easier",
        "labels": "feature request",
        "id": 43079
    },
    {
        "title": "Self referential modules not supported in repl or `-r`",
        "body": "If you attempt to `require('package-name')` using v13.7.0 in the repl it will fail with a 'MODULE_NOT_FOUND' error.\r\n\r\n```js\r\n// index.js\r\nconsole.log('yay')\r\n// package.json\r\n{\r\n  \"name\": \"ohno\",\r\n  \"main\": \"./index.js\"\r\n}\r\n```\r\n```bash\r\n$ node\r\n> require('ohno')\r\n```\r\n> Uncaught Error: Cannot find module 'ohno'\r\n> Require stack:\r\n> - <repl>\r\n>     at Function.Module._resolveFilename (internal/modules/cjs/loader.js:980:15)\r\n>     at Function.Module._load (internal/modules/cjs/loader.js:862:27)\r\n>     at Module.require (internal/modules/cjs/loader.js:1040:19)\r\n>     at require (internal/modules/cjs/helpers.js:72:18) {\r\n>   code: 'MODULE_NOT_FOUND',\r\n>   requireStack: [ '<repl>' ]\r\n> }\r\n\r\n```bash\r\n$ node -r ./index.js\r\nyay\r\n```\r\n```bash\r\n$ node -r ohno\r\n```\r\n> internal/modules/cjs/loader.js:983\r\n>   throw err;\r\n>   ^\r\n> \r\n> Error: Cannot find module 'ohno'\r\n> Require stack:\r\n> - internal/preload\r\n>     at Function.Module._resolveFilename (internal/modules/cjs/loader.js:980:15)\r\n>     at Function.Module._load (internal/modules/cjs/loader.js:862:27)\r\n>     at Module.require (internal/modules/cjs/loader.js:1040:19)\r\n>     at Module._preloadModules (internal/modules/cjs/loader.js:1296:12)\r\n>     at loadPreloadModules (internal/bootstrap/pre_execution.js:435:5)\r\n>     at prepareMainThreadExecution (internal/bootstrap/pre_execution.js:68:3)\r\n>     at internal/main/repl.js:18:1 {\r\n>   code: 'MODULE_NOT_FOUND',\r\n>   requireStack: [ 'internal/preload' ]\r\n> }",
        "labels": "feature request",
        "id": 43080
    },
    {
        "title": "Make stream internal methods support promises / async await",
        "body": "Hello all,\r\nIt would be great if streams internal methods such as `_write`, `_transform` would support also a promise based implementation.\r\n\r\nTo clarify what I mean, here's an example.\r\n\r\nClassic implementation of a writable streams that receives objects containing a `path` and a `content` and it will write a file with such content for every received chunk.\r\n\r\n## Classic implementation\r\n\r\n```javascript\r\nimport { Writable } from 'stream'\r\nimport { promises as fs } from 'fs'\r\nimport { dirname } from 'path'\r\nimport mkdirp from 'mkdirp'\r\n\r\nexport class ToFileStream extends Writable {\r\n  constructor (opts) {\r\n    super({ ...opts, objectMode: true })\r\n  }\r\n\r\n  async _write (chunk, encoding, cb) {\r\n    mkdirp(dirname(chunk.path), (err) => {\r\n      if (err) {\r\n        return cb(err)\r\n      }\r\n\r\n      fs.writeFile(chunk.path, chunk.content, cb)\r\n    })\r\n  }\r\n}\r\n```\r\n\r\nNice and standard, but as it happens with callback-based APIs, it's easy to end up with a callback hell situation and repeated code in case of conditional asynchronous work.\r\n\r\n## Desired implementation\r\n\r\n**This does not work as of today**\r\n\r\n```javascript\r\nimport { Writable } from 'stream'\r\nimport { promises as fs } from 'fs'\r\nimport { dirname } from 'path'\r\nimport mkdirp from 'mkdirp-promise'\r\n\r\nexport class ToFileStream extends Writable {\r\n  constructor (opts) {\r\n    super({ ...opts, objectMode: true })\r\n  }\r\n\r\n  async _write (chunk, encoding) {\r\n    await mkdirp(dirname(chunk.path))\r\n    return fs.writeFile(chunk.path, chunk.content)\r\n  }\r\n}\r\n```\r\n\r\nThis would feel quite clean and standard for those used to the `async` `await` style\r\n\r\n## What we can do today\r\n\r\n```javascript\r\nimport { Writable } from 'stream'\r\nimport { promises as fs } from 'fs'\r\nimport { dirname } from 'path'\r\nimport mkdirp from 'mkdirp-promise'\r\n\r\nexport class ToFileStream extends Writable {\r\n  constructor (opts) {\r\n    super({ ...opts, objectMode: true })\r\n  }\r\n\r\n  async _write (chunk, encoding, cb) {\r\n    try {\r\n      await mkdirp(dirname(chunk.path))\r\n      await fs.writeFile(chunk.path, chunk.content)\r\n      cb()\r\n    } catch (err) {\r\n      cb(err)\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nIn a situation with a lot of callbacks this might help to remove the nesting, but it still feels weird to (and hard to read) to mix `async` `await` style with callbacks.\r\n\r\n---\r\n\r\nWhat do you think? Would this be something feasible without breaking existing streams implementations?",
        "labels": "feature request",
        "id": 43081
    },
    {
        "title": "API proposal: async readableStream.readLine([encoding])",
        "body": "\r\nThere could be a convenience (async) function <code>readableStream.readLine()</code> to read a line of text from a readableStream. If it isn't immediately available, it waits until it is. Ofc., you can already do such things today using the existing APIs (and adding your own code to that), though I do think it wouldn't hurt offering such a convenience function.\r\n\r\nAlso, I'm aware of the <code>require('readline')</code> module. However, it's got its disadvantages as you risk draining too much of your original readableStream. (readline's internal lookahead). Consider you might need an easy & quick way of reading a line of text, and want to mix readableStream.readLine() with other calls that read binary data from the stream.\r\n\r\n",
        "labels": "feature request",
        "id": 43082
    },
    {
        "title": "Add utils.types.isArray, .isFunction and .isPlainObject",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nReliably detecting the actual intrinsic type of an object, e.g. for serialisation of arbitrary JS datastructures. (It is especially important to be able to reliably detect types which cannot be successfully serialised.)\r\n\r\n**Describe the solution you'd like**\r\nAdd `util.types.isArray` and `util.types.isFunction`, analogous to the existing `util.types` predicates, and a `util.types.isPlainObject` which returns `true` iff its argument is an Object which is not any other typeâ€”i.e., was created by `{}`, `new Object()`, `Object.create()`, or one of the other builtin functions which creates an object via [the ObjectCreate specification method](https://tc39.es/ecma262/#sec-objectcreate) called with an empty *internalSlotsList*.\r\n\r\n**Describe alternatives you've considered**\r\n`Object.prototype.toString` returns the desired information in most cases, but can be spoofed by setting `value[Symbol.toStringTag]`, and does not detect proxies.\r\n\r\nPresumably `.isArray` was originally omitted from `util.types` because `Array.isArray` exists, but note that `Array.isArray(new Proxy([], {}))` returns true, while (e.g.) `util.types.isMap(new Proxy(new Map(), {}))` returns false.  A reasonable approximation can be polylfilled:\r\n\r\n```JS\r\nutils.types.isArray = function isArray(value) {\r\n  return Array.isArray(value) && !util.types.isProxy(value);\r\n}\r\n```\r\n\r\nâ€¦but it would seem more elegant and reliable (not to mention consistent) to have a dedicated predicate on `util.types`.\r\n\r\nSimilarly, `.isFunction` can be approximated with `typeof(value) === 'function' && !util.types.isProxy(value)`, but again this is inelegant.\r\n\r\nFinally, detecting plain objects reliably appears to be very difficult at present; at best you can check to make sure that `typeof value === 'object' && value !== null` and then ensure that `utils.typeof[X](vaue)` returns false for all `X`.\r\n\r\n**Additional note**\r\nIt could be useful to have finer-grained detection of function types, e.g. `isAnyFunction`, `isNativeFunction`, `isPlainFunction` (or `isNonNativeFunction`), `isCallableFunction`, `isConstructibleFunction` etc.â€”though these are arguably of less utility because, with the exception of (non-native) functions defined in the global scope, it's not generally possible to reliably recreate a function object.\r\n",
        "labels": "feature request",
        "id": 43083
    },
    {
        "title": "How to control v8::Context created by node_worker?",
        "body": "* **Scope**: code & embedding\r\n\r\nHi,\r\nWhen new worker created, I want to add v8 object into the global object.\r\nHave a any idea intercepting node::NewContext?\r\nMy goal is implement virtual filesystem.",
        "labels": "feature request",
        "id": 43084
    },
    {
        "title": "OS API is missing available memory call in NodeJS",
        "body": "* **Version**: all\r\n* **Platform**: Unix\r\n* **Subsystem**: -\r\n\r\nThe free commands says actually that I have 1832 MBs available, which is the free amount + some part of the buff/cache that can be cleared directly when needed.\r\n\r\nThe free column should be small, since this is memory which is not used is simply wasted. Available memory is the amount of memory which is available for allocation to a new process or to existing processes.\r\n \r\n```\r\n$ free -m\r\n              total        used        free      shared  buff/cache   available\r\nMem:           7971        5907         149         135        1914        1832\r\nSwap:          9541        2122        7419\r\n```\r\n\r\nKnowing all this, the NodeJs OS API (`var os = require('os')`) only provides `os.freemem` and `os.totalmem`. The free memory NodeJS API call indeed shows the same value as what the free command gives me. But the OS API does **NOT** have any call like: `os.availablemem` or something simular.\r\n\r\n**Bottom-line:** I'm missing the *available* memory call in NodeJS. Which is often way more useful.\r\n\r\nFor info: \r\n\r\n* [Free memory unix C implementation in Node](https://github.com/nodejs/node/blob/master/deps/uv/src/unix/sysinfo-memory.c#L32)\r\n\r\nRegards,\r\nMelroy van den Berg\r\n",
        "labels": "feature request",
        "id": 43085
    },
    {
        "title": "Emit event when code in vm is fully executed",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nThere is no way to know if the script running in vm is fully executed or not. Of course, all synchronous tasks are immediately executed when `runInContext` is called. But since [all contexts share the event loop](https://github.com/nodejs/node/issues/3020#issuecomment-144117993), we cannot tell if there are any more callbacks (of the vm code) in the event loop. (e.g. a `setTimeout` callback)\r\n\r\n**Describe the solution you'd like**\r\n`vm.Script` should use a separate event loop and emit an event when there are no more callbacks left.\r\n\r\n**Describe alternatives you've considered**\r\nAs [bnoordhuis](https://github.com/bnoordhuis) stated, we can [add bookkeeping to every call into the VM](https://github.com/nodejs/node/issues/3020#issuecomment-144117993).\r\n",
        "labels": "feature request",
        "id": 43086
    },
    {
        "title": "Get access to raw cli argument string",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI'm working on my own programming language, and I'd like to be able to create\r\nan interpreter in node.js that would accept this input:\r\n\r\n```\r\nnode my-interpreter.mjs eval \"Two times \" ++ Pi ++ \" equals \" ++ (2 * Pi)\r\n> Two times 3.14159 equals 6.28319\r\n```\r\n\r\nAnything beyond `node my-interpreter.mjs eval` is code written in my programming\r\nlanguage. I need this input in raw form to be able to parse the code. It is not possible\r\nto reconstruct the code from `process.argv`.\r\n\r\n**Describe the solution you'd like**\r\nA string property like `rawArgv` on `process` variable.\r\n\r\n**Describe alternatives you've considered**\r\nIt would be possible to put the whole code in quotes and escape all quotes in the code, but in my view this would make the command-line \"API\" much uglier.\r\n",
        "labels": "feature request",
        "id": 43087
    },
    {
        "title": "accept Directory File Descriptors as a base for fs open & readdir",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nAt present opening files & looking at directories in Node.js requires passing in the full path. These operations would ideally also be able to accept directory file descriptors as options to them.\r\n\r\nThis helps alleviate a number of hairly race conditions. If directories are being moved around, the directory file descriptors will remain stable. Without this capability, it's not possible for a program to tell whether it's going to be writing to the same directory or not.\r\n\r\nThere are some performance advantages here too. Rather than having to walk up the file path, files can be opened directly from the starting directory file descriptor's location.\r\n\r\nThis is also useful for sandboxing & security. Applications can pass around directory file descriptors to each other or between modules, rather than having to reveal full paths to each other.\r\n\r\nFinally, this capability would greatly ease interoperation with upcoming specifications such as WASI, which already use this file-descriptor based mode for all their operations. Both [__wasi_fd_open](https://github.com/WebAssembly/WASI/blob/master/phases/snapshot/docs/wasi_unstable_preview1.md#__wasi_path_open) and [__wasi_fd_readdir](https://github.com/WebAssembly/WASI/blob/master/phases/snapshot/docs/wasi_unstable_preview1.md#__wasi_fd_readdir) require a starting directory file descriptor to work from. This is an integral part of their security model, part of the \"capability\" system of the api.\r\n\r\nIt's less explicit, but the design of the [native file system](https://github.com/WICG/native-file-system) specification for the web also works in a similar manner, where one never opens a full path, they only open things inside the tree of whatever handles (file or directory descriptors) that the page already has access to.\r\n\r\n**Describe the solution you'd like**\r\nI would like to see variants of or options to fs open/readdir that accept a starting directory fd, rather than requiring the full path to be passed in. In *nix land, this is done via `openat()` and using `fdopendir()` instead of `open()` and `opendir()`.\r\n\r\nThis should give Node.js API capabilities that resemble how other js platforms are handling opening things, which should yield performance gains for users, freedom from an assortment of nasty race condition, & potentially some \"capabilities\" based security/sandboxing possibilities.\r\n\r\n**Describe alternatives you've considered**\r\n....\r\n\r\nI believe changes to libuv would be required. As for platform support, there is a [Stackoverflow discussing Windows parallels](https://stackoverflow.com/questions/32138524/is-there-a-windows-equivalent-of-openat). Support most *nix'es is [reported to be good](https://stackoverflow.com/a/32137401/72070).\r\n\r\n/cc @cjihrig because he's been working on WASI a bunch & specifically in node. ",
        "labels": "feature request",
        "id": 43088
    },
    {
        "title": "Long stack traces in core",
        "body": "With all the work currently being done around async_hooks and stack trace enhancement through e.g. source maps, Iâ€™m wondering whether we should bring official long stack trace support into core.\r\n\r\nIâ€™d personally love to see it â€“ Iâ€™m certainly biased, but for debugging flaky tests alone it would make things a lot easier to not to have to pull in an external utility for that (or to have to write an ad-hoc one).\r\n\r\nAlternatives would be to keep these utilities in userland and/or to just vendor one in but keep developing it outside of core. In particular the latter also seems good to me.\r\n\r\n@nodejs/async_hooks @bcoe @AndreasMadsen ",
        "labels": "feature request",
        "id": 43089
    },
    {
        "title": "Extend default logger with configuration",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nIn GCP cloud functions we need logged output to be in a particular format if we want to have accurate log levels and properly rendered results in stackdriver. In the past this was done by monkey patching console.log... which makes me sad.\r\n\r\n**Describe the solution you'd like**\r\n\r\n[Java has a solution to this problem.](https://docs.oracle.com/javase/10/core/java-logging-overview.htm#GUID-B83B652C-17EA-48D9-93D2-563AE1FF8EDA__CONFIGURATIONFILE-4C48BDCE) Specifically they allow for a configuration file that can be used to modify the default behavior of the logger.\r\n\r\nI'm curious if node would benefit from a similar feature\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\nThis could also potentially be solved within the WHATWG console spec... happy to explore that as a path as well",
        "labels": "feature request",
        "id": 43090
    },
    {
        "title": "Worker threads: ability for tooling to pass data to workers and inject NODE_OPTIONS",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nnyc 15 is moving away from `spawn-wrap`, will use `process-on-spawn` and `node-preload` in it's place.  These two modules ensure nyc gets properly loaded into new processes, but they do not help with worker threads (note spawn-wrap also did nothing to help with worker threads).  I'd like to add worker thread support to nyc.\r\n\r\n**Describe the solution you'd like**\r\nnyc needs to pass data to worker threads without requiring modifications to arguments of `new Worker(...)` run by the code being tested.  An idea I have:\r\n```js\r\nprocess.on('worker', options => {\r\n\toptions.platformData('nyc', nycConfigClonableObject);\r\n\toptions.nodeOptions.push('--require', require.resolve('./lib/wrap-thread.js'));\r\n});\r\n```\r\n\r\nThe above code assumes that `new Worker()` internally calculates `options.nodeOptions` based on the `env.NODE_OPTIONS` passed to it (see also #29117).  This would allow nyc to inject preload modules if necessary without altering the `process.env` of the new thread.\r\n\r\n**Describe alternatives you've considered**\r\nSetting platform data during process startup could work for some use cases:\r\n```js\r\nconst threads = require('worker_threads');\r\nthreads.platformData('nyc', dataNeededToInitializeNYC);\r\nthreads.platformNodeOptions.push('--require', require.resolve('./wrap-thread.js')));\r\n```\r\n\r\nThis would work for nyc but maybe another tool would need to calculate the object needed for platformData at the time of `new Worker()`.  This is why my proposal is for 'worker spawn' hooks to ensure this is useful for more than just nyc.  I'm also unsure how `platformNodeOptions` would be incorporated into the `env.NODE_OPTIONS` given to `new Worker()`.\r\n\r\n---\r\n\r\nI considered patching the `worker_threads` core module.  `worker.SHARE_ENV` is very problematic for this approach as it eliminates the possibility of using environmental variables to get nyc options into the worker threads.  We would likely need to patch `new Worker()` to wrap worker data so that `options.workerData = {userData: options.workerData, nycData}`, then `require('worker_threads').workerData` would be patched to return the `userData` subproperty and we'd create a `require('worker_threads').nycData` export.  This seems like it would be very messy, especially if any other tooling had a need to patch `workerData` in a similar way.  I'm really not interested in this approach even if it could be forced to work.\r\n\r\nCC @addaleax @arcanis @nodejs/tooling",
        "labels": "feature request",
        "id": 43091
    },
    {
        "title": "net.createConnection needs an option to set the permissions of a named pipe",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**:\r\n\r\n13.3.0\r\n\r\n* **Platform**:\r\n\r\nLinux\r\n\r\n* **Subsystem**:\r\n\r\nDebian\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nIf I were to create a \"server\" for IPC using a named pipe like:\r\n\r\n```\r\nconst ipc_server = net.createServer((c) => {\r\n        // 'connection' listener.\r\n        console.log('ipc client connected');\r\n        c.on('end', () => {\r\n                console.log('ipc client disconnected');\r\n        });\r\n        c.write('hello\\r\\n');\r\n        c.pipe(c);\r\n});\r\n\r\nipc_server.listen('/tmp/collect.sock', () => {\r\n        console.log('ipc connected at /tmp/pipe_name.sock');\r\n});\r\n```\r\n\r\nThere are permission issues if I am accessing that named pipe from a process which has a different linux profile permission mask than the user which started the server.\r\n\r\nIt would be really nice to just have the ability to set the permissions on the named pipe file when creating the server with ```net.createServer()```.\r\n\r\nYou get something like this when trying to connect to the named pipe in a process ran by a user with different permissions on his account.\r\n\r\n```\r\nipc client error { Error: connect EACCES /tmp/pipe_name.sock\r\n    at PipeConnectWrap.afterConnect [as oncomplete] (net.js:1106:14)\r\n  errno: 'EACCES',\r\n  code: 'EACCES',\r\n  syscall: 'connect',\r\n  address: '/tmp/pipe_name.sock' }\r\n```",
        "labels": "feature request",
        "id": 43092
    },
    {
        "title": "introduced fine-grained ability to control TCP socket establishment",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThere is a class of connection errors we see related to blackholed connections that I am currently unable to simulate in node. A mock server is able to blackhole any data after a connection is established, but gives me very little control over establishment of the connection.\r\n\r\n**Describe the solution you'd like**\r\nSome sort of API which would allow me to control an incoming connection prior to establishing the connection. At very least, some sort of ability to introduce a delay before `uv_accept` is called to simulate a very slow server or a black hole. \r\n\r\n**Describe alternatives you've considered**\r\nafaict, this is not possible with Node's current API. I would have to write an addon using something like libuv, or just use another language/environment to write this server. Additionally, I can simulate the initial connection failure by attempting a connection to some unroutable address (e.g. `240.0.0.0/4`)",
        "labels": "feature request",
        "id": 43093
    },
    {
        "title": "Ability to suppress warnings by type (or just experimental warnings)",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'd like to suppress experimental warnings while still seeing any other errors.  In particular when I am using native ES modules I do not want the experimental warning printed for every process, but I do want unrelated warnings to still be printed.\r\n\r\n**Describe the solution you'd like**\r\nAllow `--no-warnings` to optionally accept an option string such as `--no-warnings=type1,type2`.  Using `--no-warnings` without any option would continue to disable all warnings.  This would allow `--no-warnings=ExperimentalWarning` to suppress ExperimentalWarning only.\r\n\r\n**Describe alternatives you've considered**\r\n`--no-experimental-warnings` or a similarly named new flag could be created.  This has the drawback that `node --no-experimental-warnings` on node.js 13.3.0 exit with an error where `--no-warnings=ExperimentalWarnings` will not currently error (it causes all warnings to be ignored).\r\n\r\nIn my own repo which uses ES modules I've created `suppress-experimental.cjs` which gets loaded with `NODE_OPTIONS='--require=./suppress-experimental.cjs'`:\r\n```js\r\n'use strict';\r\n\r\nconst {emitWarning} = process;\r\n\r\nprocess.emitWarning = (warning, ...args) => {\r\n\tif (args[0] === 'ExperimentalWarning') {\r\n\t\treturn;\r\n\t}\r\n\r\n\tif (args[0] && typeof args[0] === 'object' && args[0].type === 'ExperimentalWarning') {\r\n\t\treturn;\r\n\t}\r\n\r\n\treturn emitWarning(warning, ...args);\r\n};\r\n```\r\n\r\nObviously patching node.js internals like this is undesirable but it accomplishes my goal.",
        "labels": "feature request",
        "id": 43094
    },
    {
        "title": "perf_hooks: trace http statistics with `trace_events`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nWe could trace user timings emitted by `perf_hooks` with `trace_events` flag: `node --trace-event-categories node.perf`. \r\nSince `http` also supports to be observed with `perf_hooks` (https://github.com/nodejs/node/pull/28486), it might be useful to be traced by `--trace-event-categories` too.\r\n\r\n**Describe the solution you'd like**\r\n`node --trace-event-categories node.http` could export events emitted by `http` module.\r\n\r\n**Describe alternatives you've considered**\r\nIf I got it right, there is no userspace API to record trace events manually.",
        "labels": "feature request",
        "id": 43095
    },
    {
        "title": "Worker instantiation from URLs",
        "body": "When creating workers from within modules, we don't have `__filename` or `__dirname` so rather have to rely on import.meta.url, something like:\r\n\r\n```js\r\nimport { Worker } from 'worker_threads';\r\nimport { fileURLToPath } from 'url';\r\nnew Worker(fileURLToPath(import.meta.url));\r\n```\r\n\r\nTo avoid the `fileURLToPath` call being necessary here, should we consider supporting URLs as input into `new Worker`?",
        "labels": "feature request",
        "id": 43096
    },
    {
        "title": "Add __dirname and __filename on ES Modules",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nIt's a feature request.\r\n\r\n**Describe the solution you'd like**\r\nWould be nice to add __dirname, and __filename. to ES Modules, I've read the [docs](https://nodejs.org/dist/latest-v13.x/docs/api/esm.html#esm_no_code_require_code_code_exports_code_code_module_exports_code_code_filename_code_code_dirname_code), but also read [TC39 proposal](https://github.com/tc39/proposal-import-meta#introducing-lexical-variables-in-another-way), they don't decline using this variables.\r\n\r\n**Describe alternatives you've considered**\r\nI have no idea. By the way, I've added `__filename` and `__dirname` properties to `import.meta` instead of suggestion of [how to get these values](https://nodejs.org/dist/latest-v13.x/docs/api/esm.html#esm_no_code_require_code_code_exports_code_code_module_exports_code_code_filename_code_code_dirname_code).\r\n",
        "labels": "feature request",
        "id": 43097
    },
    {
        "title": "esm: invalid extension error should provide parent context in error",
        "body": "* **Version**: v13.2.0\r\n* **Platform**: Windows 10, 64-bit\r\n* **Subsystem**: N/A\r\n\r\n<!-- Please provide more details below this comment. -->\r\nWhen trying to import a JSON file, the error message provided is the following:\r\n```\r\n(node:7004) ExperimentalWarning: The ESM module loader is experimental.\r\ninternal/modules/run_main.js:50\r\n    internalBinding('errors').triggerUncaughtException(\r\n                              ^\r\n\r\nTypeError [ERR_UNKNOWN_FILE_EXTENSION]: Unknown file extension: C:\\Users\\Mercy\\Desktop\\New folder\\node_modules\\patron.js\\package.json\r\n    at Loader.resolve [as _resolve] (internal/modules/esm/default_resolve.js:114:13)\r\n    at Loader.resolve (internal/modules/esm/loader.js:74:33)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:148:40)\r\n    at ModuleWrap.<anonymous> (internal/modules/esm/module_job.js:41:40)\r\n    at link (internal/modules/esm/module_job.js:40:36) {\r\n  code: 'ERR_UNKNOWN_FILE_EXTENSION'\r\n}\r\n```\r\n\r\n**How to reproduce:**\r\n1. Create test.mjs with `import './package.json'`\r\n2. Run `node test.mjs`\r\n\r\nTo help debug this error we should ensure it provides the name of the parent module that attempted the file extension load - something like `imported from /path/to/test.mjs`.",
        "labels": "feature request",
        "id": 43098
    },
    {
        "title": "Skip expressions inspection in REPL",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nIn the REPL, it's annoying to have undesired verbose outputs, for example:\r\n```js\r\nmoment = require('moment-timezone'); // I don't want any output\r\n// this shows many many lines\r\n// that I don't really want\r\n// to see\r\nm=moment()\r\n// again, many lines\r\n// I don't even see anymore my previous inputs\r\n```\r\n**Describe the solution you'd like**\r\nWhat would be great, is if the line ends with `;` we turn off inspect\r\nSo I'd just need to type:\r\n```js\r\nmoment = require('moment-timezone'); // no output below\r\nm=moment(); // no output below\r\nm.date()\r\n// 29\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nI can terminate the line with  `;''` to skip the ouput, `void` is less easy to use, because it has to be put at the beginning, and wrapped in parenthesis for assignments\r\n```js\r\nvoid (m=moment())\r\nm=moment(); ''\r\n```",
        "labels": "feature request",
        "id": 43099
    },
    {
        "title": "child_process kill() swallows synchronously known problems (does not error out)",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v12.13.1\r\n* **Platform**: Linux 5.3.11\r\n* **Subsystem**: child_process\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nSee https://gist.github.com/jgehrcke/ab4656353c1155173d2dde5ffceb0d0b for repro code. The output when executing this:\r\n```\r\n$ node kill_no_pid_repro_js.js \r\n2019-11-26T16:49:50.509Z info: waiting for the startup error to be handled\r\n2019-11-26T16:49:50.511Z info: loop iteration\r\n2019-11-26T16:49:50.514Z error: 'error' handler: Error: spawn does-not-exist-- ENOENT\r\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:264:19)\r\n    at onErrorNT (internal/child_process.js:456:16)\r\n    at processTicksAndRejections (internal/process/task_queues.js:80:21) {\r\n  errno: 'ENOENT',\r\n  code: 'ENOENT',\r\n  syscall: 'spawn does-not-exist--',\r\n  path: 'does-not-exist--',\r\n  spawnargs: []\r\n}\r\n2019-11-26T16:49:50.521Z error: child process startup error\r\n2019-11-26T16:49:50.521Z info: send SIGTERM\r\n2019-11-26T16:49:51.523Z info: send SIGTERM\r\n```\r\n\r\nThe log output with millisecond resolution shows the chronological order of events.\r\n\r\nIn the repro code I use an asynchronous startup error detection technique, using the \"error\" event. In the log output we can see that this event is being caught, indicating ENOENT (command/executable not found, as desired in this repro). That's great.\r\n\r\nAfter this one can still call the [`kill()` method](https://nodejs.org/api/child_process.html#child_process_subprocess_kill_signal\r\n) on the process. The call \"succeeds\", silently swallowing a problem. The problem as I would put it into words: \"there is no process that you can kill here\", and that problem should _not_ be silently swallowed, because it makes it too easy to write code with race conditions.\r\n\r\nI believe that this should be considered a bug in NodeJS: this is a programmer error, i.e. this should throw an Error, as it would in other programming environments. If unhandled, this should crash the code, indicating to the programmer that their assumption that the process is alive was wrong. The programmer should be required to explicitly handle an error thrown by `kill()`.\r\n\r\nIt's not necessary to demonstrate the struggle, but maybe makes it easier to understand: the repro code calls kill() another time, about 1 second after the startup error had happened. That kill() also swallows the problem.\r\n\r\nI don't know if internally the `kill()` method just is a noop in this case (where the runtime knows that there is no PID to issue a `kill()` system call to), or if it actually calls the system call and then swallows the ENOENT. But in both cases it makes a conscious choice, knows about the absence of the process, and hides the erroneous attempt from the programmer.\r\n\r\nThere could be two ways to check for the error synchronously:\r\n- The underlying `kill()` system call does fail with ENOENT, if it is even executed.\r\n- If the underlying `kill()` system call is not executed then the runtime seems to have internal state about the fact that the process is not there (I am pretty sure that this is what's happening, see my code comments in the repro code). That state could be used.\r\n\r\nIt is documented that \r\n\r\n> The ChildProcess object may emit an 'error' event if the signal cannot be delivered\r\n\r\nIf this is meant to be _the_ only, reliable, documented way to find out that a `kill()` failed (not quite clear from the documentation) then I think the repro code is also quite insightful: in the repro code that event handler is not called after the erroneous `kill()`. That's in fact proven by the additional 1-second wait, during which I would expect that handler to be called.\r\n\r\nIn the repro code comments I have pointed out that the runtime magically detects that the child process is gone, and it terminates the code pre-maturely, to prevent an indefinitely long wait from happening.\r\n\r\nThat is, I think this issue mainly reveals a rather mean inconsistency where the runtime sometimes seems to consider the fact that there is no process, and sometimes it doesn't, making it difficult to write robust child process management code.\r\n\r\nNote: currently there does not seem to be a documented synchronous way to detect a child process startup error (upon common system call errors such as ENOENT and EACCES), and no documented synchronous way to check for process \"liveness\", although both could be done synchronously with \"fast\" system calls. This might be strongly related to this topic here. Related: https://github.com/eclipse-theia/theia/pull/3447 and https://github.com/nodejs/help/issues/1191.",
        "labels": "feature request",
        "id": 43100
    },
    {
        "title": "createRequire should have a createImport equivalent",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nRight now we can easily require files relative to a given location. The same isn't possible for `import`. One possible use case is \"import third party tool X relative to the working directory from within a globally installed CLI tool\".\r\n\r\nExample: https://github.com/zeit/now/blob/7e75d8c1a3485b7121f919e5035dc174ae9d629a/packages/now-next/src/dev-server.ts#L14\r\n\r\n**Describe the solution you'd like**\r\n\r\n```js\r\nimport {createImport} from 'module';\r\nimport {pathToFileURL} from 'url';\r\nimport {resolve as resolvePath} from 'path';\r\n\r\nconst $import = createImport(pathToFileURL(resolvePath('.app'));\r\nconst {default as next} = await $import('next');\r\n$import.meta.url; // file:///path/to/cwd/.app\r\n```\r\n\r\nNote: `$import.meta` exposes the same API as the usual `import.meta` but would get a clean copy. It would *not* be the same object as the meta object for `file:///path/to/cwd/.app` if a module with that URL actually exists.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nOne alternative would be to use `require` for resolution but that has the downside of not matching what `import` resolution would do. It would also not give access to the `import.meta` APIs.\r\n\r\n```js\r\nimport {createRequire} from 'module';\r\nimport {fileURLToPath, pathToFileURL} from 'url';\r\nimport {resolve as resolvePath} from 'path';\r\n\r\nfunction createImport(base) {\r\n  const req = createRequire(fileURLToPath(base));\r\n  return function __import(specifier) {\r\n    return import(pathToFileURL(req.resolve(specifier)));\r\n  };\r\n}\r\n\r\nconst $import = createImport(pathToFileURL(resolvePath('.app'));\r\nconst {default as next} = await $import('next');\r\n```",
        "labels": "feature request",
        "id": 43101
    },
    {
        "title": "Better not found errors for ESM",
        "body": "When not using a file extension in ESM - eg `import pkg from './path'` we currently just throw a straightforward not found error. As proposed by @MylesBorins in https://github.com/nodejs/modules/issues/443 it would be useful to enhance this error message.\r\n\r\nIdeally the error message should run the CJS resolver and say \"the CJS resolver would have resolved this module to ...\". We actually previously had this code path implemented by @bmeck but it seems to have got lost along the way. See the early implementation at https://github.com/nodejs/node/pull/14369/files#diff-3e94629c67625a2547d1507d0a547211R20.\r\n\r\nSorry @bmeck I think I might have dropped this and forgot to add it back when refactoring error codes to be standard. That was bad.",
        "labels": "feature request",
        "id": 43102
    },
    {
        "title": "Impossible to make a HTTP request if response headers include control characters",
        "body": "#### Version\r\n\r\n```bash\r\n$ node -v\r\nv13.1.0\r\n$ uname -a                                                                                                                                                                                                                                         06:58:36\r\nDarwin Admins-MacBook-Pro.local 19.0.0 Darwin Kernel Version 19.0.0: Wed Sep 25 20:18:50 PDT 2019; root:xnu-6153.11.26~2/RELEASE_X86_64 x86_64\r\n\r\n```\r\n\r\n#### Code\r\n\r\n```js\r\nrequire('https')\r\n  .get('https://www.megaplextheatres.com/api/theatres/all', (response) => {\r\n    console.log('OK');\r\n  })\r\n  .on('error', (error) => {\r\n    console.error(error);\r\n  });\r\n\r\n```\r\n\r\n#### Actual\r\n\r\nError:\r\n\r\n```\r\nError: Parse Error: Invalid header value char\r\n    at TLSSocket.socketOnData (_http_client.js:454:22)\r\n    at TLSSocket.emit (events.js:210:5)\r\n    at addChunk (_stream_readable.js:326:12)\r\n    at readableAddChunk (_stream_readable.js:301:11)\r\n    at TLSSocket.Readable.push (_stream_readable.js:235:10)\r\n    at TLSWrap.onStreamRead (internal/stream_base_commons.js:182:23) {\r\n  bytesParsed: 722,\r\n  code: 'HPE_INVALID_HEADER_TOKEN',\r\n  reason: 'Invalid header value char',\r\n  rawPacket: <Buffer 48 54 54 50 2f 31 2e 31 20 32 30 30 20 4f 4b 0d 0a 54 72 61 6e 73 66 65 72 2d 45 6e 63 6f 64 69 6e 67 3a 20 63 68 75 6e 6b 65 64 0d 0a 43 6f 6e 74 65 ... 1402 more bytes>\r\n}\r\n\r\n```\r\n\r\n#### Expected\r\n\r\n\"OK\" or an error with an access to the raw HTTP response, so that I could at least somehow parse the response myself.\r\n\r\n#### Workarounds\r\n\r\nNone known to me.\r\n\r\nPreviously it was possible to workaround it using `--http-parser=legacy`.\r\n\r\n```bash\r\n$ node -v\r\nv12.11.1\r\n$ node --http-parser=legacy test.js\r\nOK\r\n\r\n```\r\n\r\nThis stopped working in v13.\r\n\r\nPrevious it was possible to override the default HTTP parser.\r\n\r\n```js\r\nprocess.binding('http_parser').HTTPParser = require('http-parser-js').HTTPParser;\r\n\r\nrequire('https')\r\n  .get('https://www.megaplextheatres.com/api/theatres/all', (response) => {\r\n    console.log('OK');\r\n  })\r\n  .on('error', (error) => {\r\n    console.error(error);\r\n  });\r\n\r\n```\r\n\r\n```bash\r\n$ node -v\r\nv10.17.0\r\n$ node test-using-http-parser-js.js\r\nOK\r\n\r\n```\r\n\r\nThis stopped working in v12.\r\n\r\nThis issue did not exist in Node.js v10.\r\n\r\n#### Related issues\r\n\r\n* https://github.com/nodejs/node/issues/22064#issuecomment-519675190\r\n* https://github.com/sindresorhus/got/issues/855",
        "labels": "feature request",
        "id": 43103
    },
    {
        "title": "worker: process.argv for workers",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n`process.argv` is commonly used in Node.js. Right now there is only `execArgv` for altering how node instance works, which will be filtered `process.argv` with these only Node.js understands.\r\n\r\n**Describe the solution you'd like**\r\nAdd an option `argv` to `Worker` constructor's second argument.\r\n```js\r\nnew Worker(__filename, { argv: ['foo', 'bar'] })\r\nif (!isMainThread) {\r\n  console.log(process.argv) // ['foo', 'bar']\r\n}\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nJust use option `workerData` in `Worker` constructor's second argument.",
        "labels": "feature request",
        "id": 43104
    },
    {
        "title": "Make Http2Session maximum invalid frame count configurable",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWe have flaky https://github.com/nodejs/node/issues/29802 that doesn't hit the needed amount of invalid frames and crashes with OOM which may be solved by decreasing the amount of maximum invalid frames for that test.\r\nIt may prove useful for people to be able to configure how many invalid frames they want to tolerate though I don't think it'll be a popular feature.\r\nAt the same time, it shouldn't add too much of a maintenance burden to us.\r\n\r\n**Describe the solution you'd like**\r\nProbably option of `maxSessionInvalidFrames` (comepletely open to better names) to `http2.createServer()`/`http2.createSecureServer()` and possibly `http2.connect()`. I don't think this needs to be changed on the go and can be set upon server creation, though dynamic change may be useful.\r\n\r\nThough I'm not sure how to pass that to our  C++-land `Http2Session`? (via `js_fields_`; property on Http2Session accessible from JS; constructor param?)\r\n\r\n**Describe alternatives you've considered**\r\nNone probably, it's hardcoded so it can stay that way.\r\n\r\n/cc @addaleax as the one who added invalid frame counting.\r\n/cc @nodejs/http2 ",
        "labels": "feature request",
        "id": 43105
    },
    {
        "title": "Ecstatic is deprecated, can Node.js have a built-in static server? ",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nI was working with Node.js and I wanted to have a quick lightweight reliable http server for my website on digital-ocean. I choose `npm install http-server` turns out the core library just got recently deprecated after setting it all up, even tho it is #1 on Google and has lots of downloads and the library owner warns users NOT to use it.\r\n\r\nBut if you look at the Node.js counterparts... Python3, PHP, dotNETcore, they all have a built-in static server. For Node.js I have to download+install `express` or download/npx/install `http-server` which is a wrapped around a deprecated static-server `node-ecstatic` (https://github.com/jfhbrook/node-ecstatic)......\r\n\r\nBesides that, I think built-in standard static-server a very powerful tool for every Node.js developers to have at their disposal. Why should Python3, dotNET core, PHP all have their own built-in static server but not Node.js?\r\n\r\nI don't think this should be an accepted disadvantage of Node.js...\r\n\r\n**Describe the solution you'd like**\r\n\r\nOfficial api for simple, quick, functional supported static http server, similar as Python 3, .NET Core etc.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nRelying on additional/external tools which you have to download and install.\r\n\r\nI'm looking at Express, or even installing Python or .NET Core...\r\n",
        "labels": "feature request",
        "id": 43106
    },
    {
        "title": "Expose `request._header` as a public member",
        "body": "It would be very helpful when debugging. Also Got uses this to provide `uploadProgress` callback:\r\n\r\nhttps://github.com/sindresorhus/got/blob/13c0990c1a139d517c9d50869bec3ef33dec9aed/source/progress.ts#L66-L84",
        "labels": "feature request",
        "id": 43107
    },
    {
        "title": "emitter.stopImmediatePropagation()",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\nReference:\r\n[https://developer.mozilla.org/en-US/docs/Web/API/Event/stopImmediatePropagation](https://developer.mozilla.org/en-US/docs/Web/API/Event/stopImmediatePropagation)\r\n\r\nSeems we can implement this function. Any idea?\r\n\r\nHere is a stand alone simplified EventEmitter written in ES6 class style, which shows how stopImmediatePropagation works.\r\n```js\r\nclass EventEmitter {\r\n\t\r\n\tstatic _maxListeners = 10;\r\n\t\r\n\tstatic get maxListeners() {\r\n\t\treturn this._maxListeners;\r\n\t}\r\n\t\r\n\tstatic set maxListeners(num) {\r\n\t\tif (typeof num === 'number' && num > 0) {\r\n\t\t\treturn this._maxListeners = num;\r\n\t\t}\r\n\t}\r\n\t\r\n\t#events = Object.create(null);\r\n\r\n\t#maxListeners = undefined;\r\n\t\r\n\temit(event, ...args) {\r\n\t\tconst listener = this.#events[event];\r\n\t\tif (listener && this.#stopImmediatePropagation === false) {\r\n\t\t\tif (typeof listener === 'function') {\r\n\t\t\t\targs.length ? listener.apply(this, args) : listener.call(this);\r\n\t\t\t} else { \r\n\t\t\t\tif (args.length) {\r\n\t\t\t\t\tfor (let each of listener.slice()) {\r\n  \t\t\t\t\t\teach.apply(this, args);\r\n\t\t\t\t\t\tif (this.#stopImmediatePropagation === true) {\r\n\t\t\t\t\t\t\tthis.#stopImmediatePropagation = false;\r\n\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t} else {\r\n\t\t\t\t\tfor (let each of listener.slice()) {\r\n  \t\t\t\t\t\teach.call(this);\r\n\t\t\t\t\t\tif (this.#stopImmediatePropagation === true) {\r\n\t\t\t\t\t\t\tthis.#stopImmediatePropagation = false;\r\n\t\t\t\t\t\t\tbreak;\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\treturn true;\r\n\t\t}\r\n\t\tif (event === 'error') {\r\n\t\t\thandleError(args[0]);\r\n\t\t}\r\n\t\treturn false;\r\n\t}\r\n\t\r\n\ton(event, listener) {\r\n\t\treturn addListener(this, this.#events, event, listener, false);\r\n\t}\r\n\t\r\n\t#stopImmediatePropagation = false;\r\n\t\r\n\tstopImmediatePropagation(){\r\n\t\tthis.#stopImmediatePropagation =  true;\r\n\t}\r\n\t\t\r\n\tget addListener() {\r\n\t\treturn this.on;\r\n\t}\r\n\t\r\n\toff(event, listener) {\r\n\t\tremoveListener(this.#events, event, listener);\r\n\t\treturn this;\r\n\t}\r\n\t\r\n\tget removeListener() {\r\n\t\treturn this.off;\r\n\t}\r\n\t\r\n\tget maxListeners() {\r\n\t\treturn this.#maxListeners || this.constructor.maxListeners;\r\n\t}\r\n\t\r\n\tset maxListeners(num) {\r\n\t\tif (typeof num === 'number' && num > 0)\r\n\t\t\treturn this.#maxListeners = num;\r\n\t}\r\n\t\r\n\teventNames() {\r\n\t\treturn Reflect.ownKeys(this.#events);\r\n\t}\r\n\t\r\n\tlistenerCount(event) {\r\n\t\tconst listener = this.#events[event];\r\n\t\tif (listener) {\r\n\t\t\treturn (typeof listener === 'function') ? 1 : listener.length;\r\n\t\t}\r\n\t\treturn 0;\r\n\t}\r\n\t\r\n\tlisteners(event) {\r\n\t\tconst listener = this.#events[event];\r\n\t\tif (listener){\r\n\t\t\treturn (typeof listener === 'function') ? listener : listener.slice();\r\n\t\t}\r\n\t\treturn [];\r\n\t}\r\n\t\r\n\tprependListener(event, listener) {\r\n\t\treturn addListener(this, this.#events, event, listener, true);\r\n\t}\r\n\t\r\n\tawait(event) {\r\n\t\tvar _resolve, _reject; \r\n\t\treturn new Promise(\r\n\t\t\t(resolve, reject) => {\r\n\t\t\t\t_resolve = resolve;\r\n\t\t\t\t_reject = reject;\r\n\t\t\t\tthis.on(event, resolve);\r\n\t\t\t\tif (event !== 'error') {\r\n\t\t\t\t\tthis.on('error', reject);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t).finally(\r\n\t\t\t() => {\r\n\t\t\t\tthis.off(event, _resolve);\r\n\t\t\t\tif (event !== 'error') {\r\n\t\t\t\t\tthis.off('error', _reject);\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t);\r\n\t}\r\n}\r\n\r\nmodule.exports = EventEmitter;\r\n\r\nfunction addListener(emitter, events, event, listener, prepend) {\r\n\tif (event && typeof listener === 'function') {\r\n\t\tvar existing = events[event];\r\n\t\tif (existing) {\r\n\t\t\tif (typeof existing === 'function') {\r\n\t\t\t\texisting = events[event] = prepend ? [listener, existing] : [existing, listener];\r\n\t\t\t} else {\r\n\t\t\t\tprepend ? existing.unshift(listener) : existing.push(listener);\r\n\t\t\t}\r\n\t\t\tif (existing.length > emitter.maxListeners) {\r\n\t\t\t\t\tconsole.log('Too many event listeners added. Set maxListeners to increase limit.');\r\n\t\t\t}\r\n\t\t} else {\r\n\t\t\tevents[event] = listener;\r\n\t\t}\r\n\t}\r\n\treturn emitter;\r\n}\r\n\r\nfunction removeListener(events, event, listener) {\r\n\tconst existing = events[event];\r\n\tif (existing) {\r\n\t\tif (listener === undefined || existing === listener) {\r\n\t\t\tdelete events[event];\r\n\t\t} else {\r\n\t\t\tlet index = existing.lastIndexOf(listener),\r\n\t\t\t\tlen = existing.length;\r\n\t\t\tif (index >= 0) {\r\n\t\t\t\tif (len-- > 2) {\r\n\t\t\t\t\tif (index > 0) {\r\n\t\t\t\t\t\twhile (index < len) {\r\n\t\t\t\t\t\t\texisting[index++] = existing[index];\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t\texisting.pop();\r\n\t\t\t\t\t} else {\r\n\t\t\t\t\t\texisting.shift();\r\n\t\t\t\t\t}\r\n\t\t\t\t} else { \r\n\t\t\t\t\tevents[event] = existing[1 - index];\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}\r\n\r\nfunction handleError(error) {\r\n\tif (error instanceof Error) {\r\n\t\tthrow error;\r\n\t}\r\n\tthrow error ? new Error(error) : new Error(); \t\r\n}\r\n\r\nfunction f(){\r\n\tconsole.log('f');\r\n}\r\n\r\nfunction g(){\r\n\tconsole.log('g');\r\n}\r\n\r\nfunction br(){\r\n\tconsole.log('br');\r\n\tthis.stopImmediatePropagation();\r\n}\r\n\r\nvar e = new EventEmitter;\r\n\r\ne.on('event', f)\r\ne.on('event', br);\r\ne.on('event', g);\r\ne.emit('event');",
        "labels": "feature request",
        "id": 43108
    },
    {
        "title": "util.inspect getters ignored on class instance",
        "body": "* **Version**: v12.12.0\r\n* **Platform**: Darwin mba4.local 18.7.0 Darwin Kernel Version 18.7.0\r\n* **Subsystem**: util.inspect\r\n\r\n`getters:true` works correctly on a plain object: \r\n\r\n```js\r\nconst util = require('util')\r\nutil.inspect.defaultOptions.getters = true\r\n\r\nconst object = {\r\n  get test () {\r\n    return 'test'\r\n  }\r\n}\r\nconsole.log(object)\r\n```\r\n\r\nOutput: \r\n\r\n```\r\n{ test: [Getter: 'test'] }\r\n```\r\n\r\nBut the same operation on a class instance fails to print the getter.\r\n\r\n```js\r\nclass Something {\r\n  get test () {\r\n    return 'test'\r\n  }\r\n}\r\n\r\nconst something = new Something()\r\nconsole.log(something)\r\n```\r\n\r\nOutput: \r\n\r\n```\r\nSomething {}\r\n```\r\n\r\nThe output I expect to see is:\r\n\r\n```\r\nSomething { test: [Getter: 'test'] }\r\n```",
        "labels": "feature request",
        "id": 43109
    },
    {
        "title": "Add Buffer.address to get the reference address of a Buffer",
        "body": "Feature request:\r\nSo currently i'm working with an application where I need to send the address of a node Buffer to a  ioctl() to communicate with a linux device driver correctly. \r\n\r\nCurrently every Buffer allocated gets an address reference, example in a 32-bit architecture : \r\n```javascript\r\nvar myBuf = Buffer.alloc(1);\r\nconsole.log(myBuf); // prints Buffer where 0x210c378 may be the memory address\r\n// Result:  \r\n// <Buffer 00>\r\n```\r\n\r\nThe idea is to provide a function that returns the address of the Buffer (e.g. **Buffer.address**) example:\r\n```javascript\r\nvar myBuf = Buffer.alloc(1);\r\nconsole.log(myBuf);\r\nconsole.log(myBuf.address); // should include all left zeros\r\n// Result:\r\n// <Buffer 00>\r\n// 0210c378\r\n```\r\n\r\nTherefore if I want to make a structure that in C/C++ looks like this\r\n```C\r\nstruct myStruct {\r\n  char *tx;\r\n  int value;\r\n}\r\n```\r\n\r\nThen in node I can create the structure like this\r\n```javascript\r\nvar tx = Buffer.from([1, 2, 3, 4]);                // char tx[4], an example\r\nvar pointerToTx = Buffer.from(tx.address,'hex');   // char *tx\r\nvar value = Buffer.alloc(4);                       // int value\r\nvar myStruct = Buffer.concat([pointerToTx, value]) // struct myStruct {char *tx, int value}\r\nconsole.log(myStruct);  // prints pointer address and a int value buffer\r\n// Result: \r\n// <Buffer 02 10 c3 78 00 00 00 00> \r\n```\r\n\r\nThe current way of getting the address is using napi/nan modules. I believe at some point there was an implementation in node for getting the memory address of Buffers but not sure. If there is already an implementation for this then please let me know. \r\n",
        "labels": "feature request",
        "id": 43110
    },
    {
        "title": "Feature Request: Option to configure `highWaterMark` of HTTP `response`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nWe have a Node service that loads a bunch of data over an HTTP connection using Server-Sent Events. We noticed, when comparing to implementations in other languages, that the data we receive winds up being in many more \"chunks\" in Node which leads to some performance issues.\r\n\r\nAfter some digging, it seems that the issue is that `http.ServerResponse` received when using `http.request()` uses [the default `highWaterMark` value of `16kb`](https://nodejs.org/api/stream.html#stream_new_stream_readable_options) inherited from the default `ReadableStream` class. This is much smaller than some of the messages we're processing which we believe is the cause of the perf issues since we must reconstruct the messages before parsing them fully.\r\n\r\n**Describe the solution you'd like**\r\n\r\nIdeally, an option to configure the `highWaterMark` size of a `response` when calling `http.request`.\r\n\r\nIt might be that there is a way to do what we need here, but I was not able to find it if so. So I'm open to feedback on that front.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nSome way to override the default `highWaterMark` size of a stream (e.g., a CLI option), but that feels more expansive than needed.\r\n\r\nThanks in advance for your help/consideration ðŸ˜ƒ ",
        "labels": "feature request",
        "id": 43111
    },
    {
        "title": "Add RFC 8032 / RFC 7748 (Elliptic Curves for Security) to crypto.getCurves()",
        "body": "Run this code (I'm using Node.js 12.13.0 from `deb.nodesource.com`):\r\n\r\n```javascript\r\nconst crypto = require('crypto');\r\nconsole.log(crypto.getCurves());\r\n```\r\n\r\nAbsent from this list are the curves recommended in [RFC 7748](https://tools.ietf.org/html/rfc7748) (Elliptic Curves for Security). Additionally, [RFC 8032](https://tools.ietf.org/html/rfc8032)  (EdDSA) is not supported either.\r\n\r\nFor ECDH, I would expect to see `x25519` and `x448` in the list.\r\nFor signatures, I would expect to see `ed25519` and `ed448` as well.\r\n\r\nNote: These types are documented elsewhere:\r\n\r\n* https://nodejs.org/api/crypto.html#crypto_keyobject_asymmetrickeytype\r\n* https://nodejs.org/api/crypto.html#crypto_crypto_generatekeypair_type_options_callback\r\n",
        "labels": "feature request",
        "id": 43112
    },
    {
        "title": "--disallow-code-generation-from-strings doesn't work with NODE_OPTIONS",
        "body": "Hello.\r\n\r\nWorking: `node --disallow-code-generation-from-strings index.js`\r\nNot working: `NODE_OPTIONS=--disallow-code-generation-from-strings node index.js`\r\n\r\nIm getting error: `node: --disallow-code-generation-from-strings is not allowed in NODE_OPTIONS`\r\n\r\nSo its not possible to set  --disallow-code-generation-from-strings in NODE_OPTIONS var.\r\n\r\nIs this by design?\r\n\r\nThank you.",
        "labels": "feature request",
        "id": 43113
    },
    {
        "title": "worker thread expose its tid",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nI write program under linux, and I want to collect metrics (like cpu times, ctx switch, memory usage, ...) of the specified worker thread by the tid.\r\n\r\nIt seems impossible to get the statistics information provided by the os of the given thread by using a `worker.threadId`, and it is only make sense within the process.\r\n\r\nMaybe we could expose a new property to return the `tid` assigned by os, such as `worker.tid`?\r\n\r\nThen, we could hold the tid to get more stats under `/proc` or do something else meaningful.\r\n\r\n**Describe the solution you'd like**\r\n\r\nMake a system call (224) under linux is enough.\r\n\r\n```c\r\n#include <unistd.h>\r\n#include <sys/syscall.h>\r\n\r\nvoid *worker_thread()\r\n{\r\n  int tid = syscall(__NR_gettid);\r\n}\r\n```\r\n\r\nor `pthread_self()` (but this return a address, need some trick to pick the os level tid)",
        "labels": "feature request",
        "id": 43114
    },
    {
        "title": "Implement DGRAM type sockets for IPC (unix)",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI want to talk to `/dev/log` using unix sockets (ipc), but most linux flavors this is a socket of type SOCK_DGRAM\r\n\r\n**Describe the solution you'd like**\r\nplease make it possible to have ipc sockets of type DGRAM in node (now it is only of type SOCK_STREAM)\r\n\r\n**Describe alternatives you've considered**\r\nwe can use UDP, (we talk to syslog deamon listens on port 514 and listens on `/dev/log`) but we run the risk of messages being dropped when logging  in high loaded machines\r\n",
        "labels": "feature request",
        "id": 43115
    },
    {
        "title": "makeDuplexPair should be the default stream paradigm",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n## Is your feature request related to a problem? Please describe.\r\nThe Readable and Writable objects are not well encapsulated: I can inject data into a Readable stream by calling `Readable#push`, and I can read data from a Writable stream by monkey-patching `Writable#_read`.\r\n\r\nFurther, these interfaces are not symmetrical. If I want to make data available on a readable side, why not use the write API? This is how it works on every other application: If a client creates a TCP stream, there's one \"writable\" side, and one \"readable\" side; yet if I want to make both sides in the same process, I have to use a different API, for some reason.\r\n\r\n## Describe the solution you'd like\r\nthe Node.js stream library should include `DuplexPair` and `SimplexPair` objects, or equivalent factory functions.\r\n\r\n```javascript\r\ninterface SimplexPair {\r\n   Readable readable;\r\n   Writable writable;\r\n}\r\ninterface DuplexPair {\r\n   Duplex client;\r\n   Duplex server;\r\n}\r\n```\r\n\r\n### SimplexPair\r\n\r\nSimplexPair creates two different but related objects, one Readable and one Writable; anything written to the Writable side is made available on the Readable side. For encapsulation, the objects would not have public references to each other, and there would be no way to make data available on the readable side without access to the writable side.\r\n\r\n\r\n### DuplexPair\r\n\r\nDuplexPair is the same, but both sides are writable and readable.\r\n\r\n### PassThrough streams\r\n\r\nThis paradigm should not be new to Node.js developers; a PassThrough stream is just a special case of SimplexPair where both sides are exposed on a single Duplex object.\r\n\r\n### Transform streams\r\n\r\nTransform streams generate two pairs, and returns one from each:\r\n\r\n```javascript\r\nfunction ROT13Pair(){\r\n  const input = new SimplexPair;\r\n  const output = new SimplexPair;\r\n  input.readable.on('data', function(buf){\r\n    output.writable.write(buf.toString().replace(/[a-zA-Z]/g, function(c){\r\n      const d = c.charCodeAt(0) + 13;\r\n      return String.fromCharCode( ((c<=\"Z\")?90:122)>=d ? d : d-26 );\r\n    }));\r\n  });\r\n  return {\r\n    writable: input.writable,\r\n    readable: output.readable,\r\n  };\r\n}\r\nconst { writable, readable } = new ROT13Pair;\r\nprocess.stdin.pipe(writable);\r\nreadable.pipe(process.stdout);\r\n```\r\n\r\nThis pattern is repeatable to any level:\r\n```javascript\r\nfunction ROT26Pair(){\r\n  const input = new ROT13Pair;\r\n  const output = new ROT13Pair;\r\n  input.readable.pipe(output.writable);\r\n  return {\r\n    writable: input.writable,\r\n    readable: output.readable,\r\n  };\r\n}\r\nconst { writable, readable } = new ROT26Pair;\r\nprocess.stdin.pipe(writable);\r\nreadable.pipe(process.stdout);\r\n```\r\n... although I'm not sure how practical this particular example would be in production.\r\n\r\nI would bet this style could also result in a modest performance improvement, since much of the logic around buffering and flow control could be re-implemented.",
        "labels": "feature request",
        "id": 43116
    },
    {
        "title": "Calculating rolling hashes",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen uploading a large file to Google Drive via Google Drive API, it is recommended to upload in chunks, so that sending can be resumed if transfer of a particular chunk fails ([Google API docs](https://developers.google.com/drive/api/v3/manage-uploads#resumable)).\r\n\r\nAfter transfer of each chunk, the API returns the MD5 hash of all data transferred to date (i.e. of all chunks up to and including the last one). NB This is not documented, but appears in an `x-range-md5` HTTP response header.\r\n\r\nIt would be useful to be able to verify that hash after transfer of each chunk, in order to know if a chunk has been corrupted in transmission. It would then be possible to transfer the chunk again.\r\n\r\nThis is not feasible to do in Node at present. You can verify the final hash after the very last chunk and make sure it matches for the entire file. That ensures data integrity. But if it doesn't match, you don't know which chunk of the file was corrupted, and have to start the upload again from the beginning (expensive when the file is 100GB!)\r\n\r\n**Describe the solution you'd like**\r\n\r\nSome way to calculate \"rolling\" hashes. i.e. call `hash.digest()` but then still be able to do further calls to `hash.update()` and call `hash.digest()` again.\r\n\r\nPossible ways to achieve this:\r\n\r\n1. Keep the internal state of the hash after call to `.digest()`, so it can be reused.\r\n2. Add a `hash.copy()` method which clones the hash so you can call `.digest()` on the clone, and still retain a \"live\" hash which you can continue to `.update()`.\r\n3. As (1) but only enable this feature if `crypto.createHash()` called with a `reuseable` option.\r\n\r\n@sam-github raised the possibility of a `.copy()` method in https://github.com/nodejs/node/issues/25857#issuecomment-459540310.\r\n\r\nHere's how that would work for my use case:\r\n\r\n```js\r\n// NB Simplified code\r\nconst CHUNK_SIZE = 256 * 1024; // 256 KiB\r\n\r\nasync function upload(path, size) {\r\n  const hash = crypto.createHash('md5');\r\n\r\n  for (const start = 0; start < size; start += CHUNK_SIZE) {\r\n    const end = start + CHUNK_SIZE - 1;\r\n    const stream = fs.createReadStream(path, {start, end})\r\n      .pipe(new stream.Transform({\r\n        transform(data, encoding, cb) {\r\n          hash.update(data);\r\n          this.push(data);\r\n          cb();\r\n        }\r\n      });\r\n\r\n    const md5FromApi = await transferChunkToGoogleDrive(stream, start, end);\r\n    const md5Actual = hash.copy().digest('hex');\r\n    if (md5FromApi !== md5Actual) {\r\n      // Rather than throwing, we could transfer last chunk again.\r\n      // This logic omitted to keep example short.\r\n      throw new Error(`Transfer failed on chunk ${start}-${end}`);\r\n    }\r\n}\r\n```\r\n\r\nThe `hash.copy()` call will no doubt have a performance penalty, but this is outweighed in this case by the cost of having to start an upload again from the beginning if the file is large.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAn alternative is to use a JS implementation of MD5, where you can access the internal state of a hash and clone it. I suspect performance would be much worse than Node's native methods though.",
        "labels": "feature request",
        "id": 43117
    },
    {
        "title": "fs.isWatchAvailable()  [capabilities check for fs.watch()]",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nThe `fs.watch()` File System method is handy and useful. Application and module developers are incented to use it for its advantages over `fs.watchFile()`. However, it is inconsistent across platforms, and the documentation states that it \"is unavailable in some situations.\"\r\n\r\nApplication developers lack a good way of knowing whether the API is even available, making it diffucult to write portable JavaScript code. The [documentation ](https://nodejs.org/api/fs.html#fs_availability) does a nice job of hitting some of the platforms and conditions, but it would be tedious for a developer to write logic around this, not to mention managing periodic updates as new conditions/platforms are added. \r\n\r\n\r\n**Describe the solution you'd like**\r\nI'd like for a new method to be available in `fs` to check whether `watch()` is available. That way, portable code can be written that \"falls back\" to `fs.watchFile()` if feasible. \r\n\r\nNot only would this enable portability, it would enable OS-specific conditions to be checked within the Node.js implementation. For example, the AIX implementation could check whether AHAFS is enabled. \r\n\r\nEven further, if the new `isWatchAvailable()` method could take a directory as a parameter, then its implementation could also check whether `fs.watch()` would function on objects within that directory (and therefore say \"no\" for SMB shares, etc). \r\n\r\n**Describe alternatives you've considered**\r\nImplementations could throw a specific Exception/Error if the platform doesn't support `fs.watch()`. However, it seems like the behavior is completely unspecified when the function is not available. \r\n\r\n",
        "labels": "feature request",
        "id": 43118
    },
    {
        "title": "Expose whether a TLS server requested a client certificate",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI'm making TLS connections to various servers, and for both successful & failing connections I want to know whether the servers requested a client certificate.\r\n\r\nFor context: my app is an MITM proxy, and I want to be able to warn the downstream user when they might want to configure a client certificate.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like a way to know whether the server requested a client cert during the handshake. This is data that's received by node (or at least, by OpenSSL) alongside the initial hello, but it's not exposed in any way that I can see.\r\n\r\nThere's also probably other handshake metadata that would be interesting to expose too, which might be worth considering in future, but nothing that's immediately useful to me right this second.\r\n\r\nA `handshakeStarted` event on sockets that exposes the data received from the server for inspection would work, for example, or alternatively a `tlsSocket.clientCertificateRequested` boolean would be fine too (as long as its available regardless of subsequent errors).\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAs far as I can tell, there's no way to do this right now other than manually collecting the entire TLS handshake data myself and parsing it from scratch in JS. That sounds like an major undertaking, and significant duplication of work since node is clearly parsing this data already.\r\n\r\nFor servers that outright reject connections without certificates it might be possible to infer the cause from the error details, but that's a limited case and not reliable. Discussed on SO too, with no useful result as yet: https://stackoverflow.com/questions/58283656/how-to-tell-if-a-tls-server-requested-a-client-certificate\r\n",
        "labels": "feature request",
        "id": 43119
    },
    {
        "title": "import(cjs) with query strings has odd behavior",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 12.11.1\r\n* **Platform**: Windows 10\r\n* **Subsystem**: ES modules\r\n\r\nFrom https://github.com/eslint/eslint/pull/12333\r\n\r\nRepro https://github.com/mysticatea/import-cjs-issue\r\n\r\n### Description\r\n\r\nI tried to import packages without import cache. From the document, it looks I should use query strings.\r\n\r\n```js\r\n    await import(\"x-esm\") //â†’ Found as expected\r\n    await import(\"./node_modules/x-esm/index.js?q=0\") //â†’ Found and `x-esm` re-ran as expected\r\n    await import(\"./node_modules/x-esm/index.js?q=1\") //â†’ Found and `x-esm` re-ran as expected\r\n```\r\n\r\n`x-esm` is an ES module package. It worked as expected.\r\n\r\n```js\r\n    const cjs = await import(\"x-cjs\") //â†’ Found as expected\r\n    const cjs0 = await import(\"./node_modules/x-cjs/index.js?q=0\") //â†’ Found but `x-cjs` didn't re-run\r\n    const cjs1 = await import(\"./node_modules/x-cjs/index.js?q=1\") //â†’ Found but `x-cjs` didn't re-run\r\n    console.log(cjs === cjs0, cjs === cjs1, cjs0 === cjs1) //â†’ all are false but `x-cjs` didn't run three times\r\n```\r\n\r\n`x-cjs` is a CJS package. The result was odd. The `console.log()` in `x-cjs` package ran only one time, but the returned values are different for each query string.\r\n\r\nI found the entry of `x-cjs` in `require.cache`. However, the cache entry is odd as well. It's different from `require(\"x-cjs\")`, the entry doesn't have `parent` property and the `module.children` of `test.js` is still empty.\r\n\r\nAnyway, I tried to remove the cache entry.\r\n\r\n```js\r\n    console.log(\"---- remove 'require.cache' ----\")\r\n    delete require.cache[require.resolve(\"x-cjs\")]\r\n    await import(\"x-cjs\") //â†’ Found but `x-cjs` didn't re-run\r\n    await import(\"./node_modules/x-cjs/index.js?q=0\") //â†’ Found but `x-cjs` didn't re-run\r\n    await import(\"./node_modules/x-cjs/index.js?q=1\") //â†’ Found but `x-cjs` didn't re-run\r\n    await import(\"./node_modules/x-cjs/index.js?q=2\") //â†’ Found and `x-cjs` re-ran as expected\r\n    await import(\"./node_modules/x-cjs/index.js?q=3\") //â†’ Found but `x-cjs` didn't re-run\r\n```\r\n\r\nCryptic. I guess this behavior is:\r\n\r\n- `import(cjs)` has cache apart from `require.cache`.\r\n- The `import(cjs)` cache is created from `require.cache`.\r\n- It runs CJS package only if `require.cache` entry was not found.\r\n- The `import(cjs)` cache is not removed even if `require.cache` entry deleted.\r\n\r\nTherefore, I have to do the following steps if I want to import packages without cache.\r\n\r\n1. Find the main file of the package because I cannot put query strings to the package name.\r\n   ```js\r\n   const url = \"file:\" + require.resolve(packageName) + uniqueQueryString;\r\n   ```\r\n1. Import it.\r\n   ```js\r\n   const ret = await import(url);\r\n   ```\r\n1. Delete `require.cache` entry.\r\n   ```js\r\n   delete require.cache[require.resolve(packageName)];\r\n   ```\r\n\r\n### Questions\r\n\r\n1. Is it intentional behavior that `import(cjs)` creates incomplete `require.cache` entries?\r\n1. If yes, is it intentional behavior that `import(cjs)` with query strings returns different objects for the same CJS package?\r\n\r\nI'm guessing that `import(cjs)` should not create any `require.cache` entries, and `import(cjs)` with query strings re-runs CJS packages as same as ES packages.",
        "labels": "feature request",
        "id": 43120
    },
    {
        "title": "display node.js version (process.version) at the end of stacktraces",
        "body": "This could be added with a flag, and later turned off with a flag if you don't want to see it.\r\n\r\nwith this in mind:\r\nhttps://github.com/nodejs/help/issues/2204\r\n\r\nthe current stacktrace is:\r\n\r\n```console\r\nSyntaxError: Invalid or unexpected token\r\nat Module._compile (internal/modules/cjs/loader.js:723:23)\r\nat Object.Module._extensions..js (internal/modules/cjs/loader.js:789:10)\r\nat Module.load (internal/modules/cjs/loader.js:653:32)\r\nat tryModuleLoad (internal/modules/cjs/loader.js:593:12)\r\nat Function.Module._load (internal/modules/cjs/loader.js:585:3)\r\nat Function.Module.runMain (internal/modules/cjs/loader.js:831:12)\r\nat startup (internal/bootstrap/node.js:283:19)\r\nat bootstrapNodeJSCore (internal/bootstrap/node.js:622:3)\r\n```\r\n\r\nit would be interesting if it looked like:\r\n\r\n```console\r\nSyntaxError: Invalid or unexpected token\r\nat Module._compile (internal/modules/cjs/loader.js:723:23)\r\nat Object.Module._extensions..js (internal/modules/cjs/loader.js:789:10)\r\nat Module.load (internal/modules/cjs/loader.js:653:32)\r\nat tryModuleLoad (internal/modules/cjs/loader.js:593:12)\r\nat Function.Module._load (internal/modules/cjs/loader.js:585:3)\r\nat Function.Module.runMain (internal/modules/cjs/loader.js:831:12)\r\nat startup (internal/bootstrap/node.js:283:19)\r\nat bootstrapNodeJSCore (internal/bootstrap/node.js:622:3)\r\nvia node.js version: 12.3.4\r\n```\r\n\r\nor whatever\r\n\r\njust an idea, not sure if it's possible/desirable to implement",
        "labels": "feature request",
        "id": 43121
    },
    {
        "title": "Repl: Access default evaluation function within custom evaluation function",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI am trying to extend the Node REPL with some extra functionality, so I'd like to use a custom evaluation function to short-circuit the default evaluation *but* have that custom function be able to defer control back to the default evaluation if need be.\r\n**Describe the solution you'd like**\r\nRight now calling the callback that is passed in to the custom evaluation function just returns. I'd like to be able to access the [default eval function](https://github.com/nodejs/node/blob/master/lib/repl.js#L281) from the custom evaluation function so I can parse the shell input for my special commands, but if it doesn't match, then have it behave as if it didn't have a custom evaluation function at all. Maybe a reference to that function can go inside the context? \r\n\r\n**Describe alternatives you've considered**\r\nForking, not using a custom eval function at all (so much more work!). Perhaps I'm missing how to access the function but it's possible already, in which case, apologies!",
        "labels": "feature request",
        "id": 43122
    },
    {
        "title": "Cryptographically secure random integer in range",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nThere is no API to obtain a random integer within a range. It's a common enough problem to deal with (e.g. to implement other algorithms like [Fisherâ€“Yates shuffle](https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle)) and [easy to get wrong](https://stackoverflow.com/questions/10984974/why-do-people-say-there-is-modulo-bias-when-using-a-random-number-generator). Most other runtimes/languages implement this in their standard library.\r\n\r\n**Describe the solution you'd like**\r\n\r\n```javascript\r\n// something like:\r\nconst randomInt = require('crypto').randomInt\r\n\r\nconst min = 0\r\nconst max = 10\r\nrandomInt(min, max, cb)\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI'm not sure about the internal implementation but I gave it a stab here: https://github.com/olalonde/crypto-range. http://www.pcg-random.org/posts/bounded-rands.html has a nice overview of different techniques (my implementation is probably not the most efficient).",
        "labels": "feature request",
        "id": 43123
    },
    {
        "title": "Verification of client cert checks issuer chain past trusted CA",
        "body": "* **Version**: v12.10.0\r\n* **Platform**: Linux birch 4.15.0-1044-aws #46-Ubuntu SMP Thu Jul 4 13:38:28 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: tls or crypto\r\n\r\nWhen calling ```socket.renegotiate({requestCert: true, rejectUnauthorized: true}, cbFunc)```, the client certificate is verified against the trusted certs passed to the ```ca``` option of ```https.createServer()```.  This process fails if the entire chain cannot be verified to a self-signed certificate (i.e. a root cert), with ```socket.authorizationError``` set to ```UNABLE_TO_GET_ISSUER_CERT```.  I suspect this is a problem even without trying to use renegotiation.\r\n\r\nHere's why this is a problem:  my employer has about 3 million users with smartcards, each of which has 3-4 user certificates - one for email encryption, one for identity proofing, one for digital signatures, etc.  These certificates are issued by different intermediate CAs, but the intermediate CA certificates are issued by a single root CA.  \r\n\r\nWhen the https.server requests a client cert, it passes the DN of all trusted CAs to the client.  If the root CA is included, then the browser will prompt the user to select which certificate to send, which will be all available certs on the smartcard (ID, email, and signature), and the user will often pick the \"wrong\" cert.\r\n\r\nAlternatively, if only the desired intermediate CAs are trusted (the ID CA, say), then the user will only be presented the single user-certificate that was issued by that CA, but verification will fail, presumably because the trusted intermediate CA cert cannot be verified up to a self-signed root.\r\n\r\nI think this is actually a limitation in ``SSL_get_verify_result()`` - that it only accepts self-signed certs as trust anchors - which doesn't align with RFC 5280, which says \"The selection of a trust anchor is a matter of policy: it could be  the top CA in a hierarchical PKI, the CA that issued the verifier's own certificate(s), or any other CA in a network PKI.\"\r\n\r\nAlternatively, is there a way to limit the list of allowable CAs presented in the requestClientCert message to a subset of the trusted CAs?",
        "labels": "feature request",
        "id": 43124
    },
    {
        "title": "Extending Buffer constructor API",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\nOpening a can of worms, I suspect, or else rehashing an idea that's already been considered and rejected, but hoping not....\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nBuffer constructor has been deprecated since v6.0.0. Tons of code in the ecosystem still uses it though and that's seemingly never going to change. In an attempt to support the new APIs in both old and new versions of Node.js, packages like https://www.npmjs.com/package/safe-buffer have been introduced. But there's still a ton of Buffer constructor stuff out there.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\nIn current versions of Node.js, `new Buffer(num)` is zero-filled. So, the issue with revealing leftover memory contents is mitigated. However, there are still issues around getting an unexpected input type (e.g., number when you expect a string). With the newer APIs, `Buffer.from()` cannot get a number and `Buffer.alloc()` cannot get a string. A `TypeError` is thrown if that happens.\r\n\r\nInstead of trying to get older packages to use `safe-buffer`, which means adding a dependency and rewriting some code that may be using the `Buffer` constructor in a perfectly safe way, it may be more palatable to add an `options` argument to `Buffer` constructor allowing the programmer to identify the expected type. So, for example, `new Buffer(50, { expect: 'number' });` would be fine, but `new Buffer('abc', { expect: 'number' });` would throw. (Obviously, there's bike-shedding to be done on the property name and accepted values. I'm just trying to verify the basic concept with this issue.)\r\n\r\nThe main advantage this has to other approaches possible now is that it can be added to code that runs old versions of Node.js harmlessly. The option will be ignored in that case. No need to add a dependency or change any other lines of code. I'm (naively?) optimistic that some package maintainers who have been resistant to `safe-buffer` or simply moving to `Buffer.from()`/`Buffer.alloc()` might look more positively on changing their code to use the option on the grounds that it improves security for people running newer versions of Node.js without impacting older versions (the way a switch to `Buffer.from()`/`Buffer.alloc()` would), without adding dependencies they didn't need before, and so on. It's purely additive and a security win. Sure, people running Node.js 0.10.x won't get any additional protection but they'll be no worse off and it should be easier with this for module maintainers to use the new API feature while maintaining backward compatibility.\r\n\r\nBiggest disadvantage I can think of now is more API surface-area to maintain and multiple ways to do the same thing. FWIW, I guess if I could go back in time, this is probably what I'd propose instead of `Buffer.from()`/`Buffer.alloc()`. Was this already considered and rejected at some point? Am I being too optimistic? \r\n\r\nWould be interested in opinions from prolific module maintainers who were greatly inconvenienced when Node.js 7.0.0 went out with a runtime deprecation warning for `Buffer` constructor. I'm not proposing putting a deprecation like that back here, but I want to know if they'd be more likely to accept PRs with this API than they are for PRs that use `safe-buffer` or PRs that switch to `Buffer.from()`/`Buffer.alloc()`. Or not really because some folks have scores or even hundreds of modules that might be subject to these kinds of updates and merging+publishing would be time-consuming and people have other priorities? /ping @substack @mafintosh @feross (who, yes, I know writes/maintains `safe-buffer`)\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n\r\nDoing nothing is the primary alternative.",
        "labels": "feature request",
        "id": 43125
    },
    {
        "title": "console: add support for %c style formatter in console.log()",
        "body": "Node's console currently supports a number of formatters, [`s, j, d, o, O, i, f`](https://github.com/nodejs/node/blob/908292cf1f551c614a733d858528ffb13fb3a524/lib/internal/util/inspect.js#L1433-L1584).  However, it doesn't support `%c`:\r\n\r\n```\r\n> console.log('%cHello World', 'color:green; background:yellow;')\r\n%cHello World color:green; background:yellow;\r\n```\r\n\r\nThe same code in Safari, Firefox, and Chrome does this:\r\n\r\n<img width=\"1225\" alt=\"Screen Shot 2019-09-18 at 3 55 58 PM\" src=\"https://user-images.githubusercontent.com/427398/65181697-9df56780-da2d-11e9-9867-4c0f172f3ec8.png\">\r\n\r\nThe [Console spec doesn't give a ton of help on what `%c` should do](https://console.spec.whatwg.org/#formatter), other than to say that it \"Applies provided CSS.\"\r\n\r\nObviously there are aspects of this that don't make sense in the terminal vs. a browser, but perhaps some of it does?  It would be nice if node's `console` could do more than ignore `%c`.\r\n\r\nApologies if this has come up in the past and been rejected.  I wasn't able to find a previous discussion.",
        "labels": "feature request",
        "id": 43126
    },
    {
        "title": "Unified utc nanoseconds timestamp: os.get_utc_time()",
        "body": "**Problem**\r\n\r\n`python3` has possibility running following construct:\r\n```\r\nfrom datetime import datetime\r\nprint({'timestamp':str(int(datetime.utcnow().timestamp() * (10**9)))})\r\n```\r\n\r\nThat would output JSON-like structore: `{'timestamp': '1567658264143923968'}`\r\n\r\nNow I want to get similar result in Node.JS 12.\r\n\r\n- I need a string\r\n- I need UTC stamp since 1970, but not since machine boot\r\n- Error no more than last 4 digits (microseconds precision or better)\r\n\r\n---\r\n**Possible solution**\r\n\r\n- WinAPI has `GetSystemTimePreciseAsFileTime`\r\n- *nix has `clock_gettime(CLOCK_MONOTONIC)`\r\n\r\nbot are os-stuff and has to be exposed through this module like `os.get_utc_time()`, in a single unified function, that returns corresponding bigint. that's superobvious and supersimple to implement\r\n\r\n---\r\n**Alternatives you've considered**\r\n\r\n- Date.now()+\"000000\" shows that it lacks last 6 digits (millis), but the task was 4 (micros or better)\r\n\r\n- `process.hrtime.bigint()` returns machine uptime, not UTC-1970",
        "labels": "feature request",
        "id": 43127
    },
    {
        "title": "[Proposal] Embed SQLite in NODEJS CORE",
        "body": "> **Is your feature request related to a problem? Please describe.**\r\n\r\nNodeJS is close being the perfect swiss army knife of zero-admin deployable microservices and applications.\r\nThe only thing missing is a built-in database.\r\n\r\n> **Describe the solution you'd like**\r\n\r\nAdopting SQLite.h/.c and exposing it to JS will result in NodeJS being the best \"batteries included\" environment ever.\r\n\r\n> **Describe alternatives you've considered**\r\n\r\nEncrypted versions of SQLite could be considered. At a later time.\r\nAnd, no. node-gyp is not an option.\r\n\r\n\r\nR.\r\n",
        "labels": "feature request",
        "id": 43128
    },
    {
        "title": "Add constructor to tls.Certificate",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI would like to parse an x509 certificate to be able to show its fingerprint to the user. Most NPM packages that parse certificates have failing npm install on Windows due to build issues w.r.t. different versions of OpenSSL.   \r\n\r\n**Describe the solution you'd like**\r\nThe node TLS module already has a Certificate interface that contains everything I need. I just need it to be a class so that I can also load a given certificate string into it instead of just getting this interface from the TLS connection.\r\n\r\nIt would seem that the node implementation already has certificate parsing available internally.\r\n\r\n**Describe alternatives you've considered**\r\nNPM packages x509 (doesn't build),  x509.js  (contains crypto library in github repo),  x509-ts (un-finished),  various forks of x509 \r\n\r\n",
        "labels": "feature request",
        "id": 43129
    },
    {
        "title": "Put datagram-Unix-socket client back into Node.js",
        "body": "# Background\r\n1. The best way to write to syslog on macOS and Linux is to use Unix-sockets\r\n2. syslog sockets are /dev/log for Linux and /var/run/syslog on macOS. In the default configuration on on both OSs, sockets are udp only\r\n# Issue\r\n3. unix.createSocket('unix_dgram'â€¦ was removed from Node.js around 2011 due to some peculiar Windows-based reasoning\r\n4. Therefore, use of datagram-Unix-sockets now requires native C++ code\r\n5. For people that make single-file self-contained executable using Node.js, native modules is problems and often do not upgrade as new Node.js releases become available\r\n6. The bigger issue is why can I not use any c/POSIX call without native code? That drawback will push people to golang that has a better story. One could think of an api descriptor object in ECMAScript covering simpler cases that throws on invocation when any argument does not match up\r\n7. Like us Noders don't have ping either\r\n8. Node 12 changes everything. It's a great time to right old wrongs\r\n\r\n**Describe the solution you'd like**\r\n9. An immediate solution is to put Unix-socket unix_dgram back into vanilla Node.js\r\n\r\n**Describe alternatives you've considered**\r\n10. Right now I use the node-unix-dgram package containing the former Node.js code\r\n",
        "labels": "feature request",
        "id": 43130
    },
    {
        "title": "[NETWORK] OCSP stapling missing in TLS Client Hello",
        "body": "Problem:\r\nThe requests I make from `https.request` do not send the `Extension: status_request` in the Client Hello at the TLS level. The resource i'm trying to reach is behind a WAF that checks the integrity of the TLS request. As a result, I am being firewalled and thus, cannot access the API.\r\n\r\nAs seen on [this stack overflow topic](https://stackoverflow.com/questions/57436880/true-difference-between-httprequest-and-xmlhttprequest), the Node request does not include `Extension: status_request` as curl and Firefox do.\r\nWith further research, I found this [Wikipedia: OCSP_stapling](https://en.m.wikipedia.org/wiki/OCSP_stapling) article, in the `Solution` section :\r\n> the TLS client must explicitly include a Certificate Status Request extension in its ClientHello TLS/SSL handshake message\r\n\r\nRequest with Firefox : \r\n![image](https://user-images.githubusercontent.com/8834915/63751313-63296500-c8af-11e9-8236-ab92d93f3332.png)\r\nRequest with Curl : \r\n![image](https://user-images.githubusercontent.com/8834915/63751348-76d4cb80-c8af-11e9-8e9c-ecb54835045f.png)\r\nRequest with Node : \r\n![image](https://user-images.githubusercontent.com/8834915/63751365-805e3380-c8af-11e9-896c-abea64891545.png)\r\n\r\nThanks for reading me.\r\n",
        "labels": "feature request",
        "id": 43131
    },
    {
        "title": "crypto.generateKeyPair(t) should have option to pass random seed data",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n\r\nFeature:-\r\ncrypto.generateKeyPair(type, options, callback) \r\n\r\nThe above method should have an option to pass 128 or 256 bits of random seed so that \r\neverytime we give that seed to this function we will have the same private and public key pairs.\r\n\r\nFor applications which needs end to end encryption specifically in bitcoin space it is really helpful to create same keys from the bip39 mnemonic and use it for end to end encryption between various devices.\r\n\r\nAlternatives :-\r\nFor now i am using https://github.com/VirgilSecurity/virgil-crypto this library for doing end to end encryption tasks. \r\n\r\nIn their public docs we are not able to find the exact method i am asking for but if we see their code base there is a method virgilCrypto.generateKeysFromKeyMaterial(\"STRING\")\r\n\r\nSo it can be used as \r\n\r\nconst VirgilCrypto =require('virgil-crypto');\r\nconst bip39 = require('bip39');\r\n\r\nconst mnemonic = bip39.generateMnemonic();\r\n\r\nconst seed = bip39.mnemonicToSeedHex(mnemonic);\r\n\r\nconst virgilCrypto = new VirgilCrypto.VirgilCrypto();\r\n\r\nconst keyPair = virgilCrypto.generateKeysFromKeyMaterial(seed);\r\n\r\nconst privateKey = virgilCrypto.exportPrivateKey(keyPair.privateKey);\r\nconst publicKey  = virgilCrypto.exportPublicKey(keyPair.publicKey);\r\n\r\nI am looking to have same sort of method for nodejs crypto module. \r\n\r\nThanks\r\n\r\n",
        "labels": "feature request",
        "id": 43132
    },
    {
        "title": "Ability to trigger --inspect --inspect-brk from code",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nYes, I've a node.js CLI app which I'd like to enable debugging off via setting `DEBUG=my-cli` before running my program; As it uses `#!` and other things, I can't set the flags to the `node` executable.\r\n\r\nI have discovered I can start the inspector programmatically, but not in `--inspect-brk` mode, so my program runs and exits before I can connect to the inspector.\r\n\r\n```\r\nif (process.env.DEBUG && process.env.DEBUG.includes(\"my-cli\")) {\r\n  process.kill(process.pid, \"SIGUSR1\");\r\n}\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nIdeally, it'd be great to have some sort of API like: `Inspector.start()` or `Inspector.start({ break: true })` to start the inspector and also make it break-point immediately, even though no clients are yet connected to the inspector.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThere's not really other alternatives, other than doing:\r\n```\r\nnode --inspect --inspect-brk ./bin/run ...\r\n```\r\n\r\nI don't think I can do:\r\n\r\n```\r\nnode --inspect --inspect-brk my-cli\r\n```\r\n\r\nWhich isn't ideal, as it's leaking internals of how my package works to consumers, whereas `DEBUG=my-cli my-cli` doesn't",
        "labels": "feature request",
        "id": 43133
    },
    {
        "title": "Detect when version is incompatible with `engines` field in package.json",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nCurrently there is no standard way for the author of an app to specify which versions of node are expected/required.  Author's are left to their own devices for ways to enforce this.\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe [hopefully] obvious approach to this is to leverage the  `engines` field in package.json.   It already serves much the same purpose for NPM.  Node, however, ignores this field entirely.\r\n\r\nNode should inspect the applicable package.json file (the same file it already looks to for `main` and `exports` fields) to see if a `engines.node` version is defined.  If so, it should apply the standard `semver` semantics to determine if the current version is incompatible with the `engines` version.  If so, it should throw `Error('Invalid node version.  Current version is ${process.version}, but ${package.json path} engines.node requires ${package.json engines.node}.')`\r\n\r\nWhile this won't be catchable via try-catch (error will occur outside context of user script), it should be trappable via `process.on('uncaughtException')`.\r\n\r\n**Describe alternatives you've considered**\r\nThe `runtime-engine-check` module provides similar behavior\r\n\r\nEdit: Some supporting material:\r\n* [Heroku uses engines.node](https://devcenter.heroku.com/articles/nodejs-support#specifying-a-node-js-version) \r\n* [Firebase uses engines.node](https://firebase.google.com/docs/functions/manage-functions#set_nodejs_version)\r\n* [SO question (and answer)](https://stackoverflow.com/a/41620850/109538) with ad-hoc code for this\r\n* ... and, fwiw, [the Reddit thread](https://www.reddit.com/r/node/comments/ctex4e/should_i_use_nvm_use_ltsdubnium_or_nvm_use_10_and/) discussing nvm version declaration and updating that prompted this report.",
        "labels": "feature request",
        "id": 43134
    },
    {
        "title": "crypto: expose tls's x509 Certificate Object",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nSeveral use-cases for getting x509 certificate information need to be solved by requiring an asn.1 module, defining the structure and undergoing slow, inefficient and error prone parsing.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSeeing how you can already get [parsed certificate](https://nodejs.org/api/tls.html#tls_certificate_object) information from a `tlsSocket` I wonder if an API like this could be exposed\r\n\r\n```js\r\nconst { X509Certificate } = require('crypto')\r\n\r\nconst cert = new X509Certificate(/* Buffer|string */);\r\n\r\n// from tls' Certificate Object docs\r\n// { subject:\r\n//    { OU: [ 'Domain Control Validated', 'PositiveSSL Wildcard' ],\r\n//      CN: '*.nodejs.org' },\r\n//   issuer:\r\n//    { C: 'GB',\r\n//      ST: 'Greater Manchester',\r\n//      L: 'Salford',\r\n//      O: 'COMODO CA Limited',\r\n//      CN: 'COMODO RSA Domain Validation Secure Server CA' },\r\n//   subjectaltname: 'DNS:*.nodejs.org, DNS:nodejs.org',\r\n//   infoAccess:\r\n//    { 'CA Issuers - URI':\r\n//       [ 'http://crt.comodoca.com/COMODORSADomainValidationSecureServerCA.crt' ],\r\n//      'OCSP - URI': [ 'http://ocsp.comodoca.com' ] },\r\n// modulus: 'B56CE45CB740B09A13F64AC543B712FF9EE8E4C284B542A1708A27E82A8D151CA178153E12E6DDA15BF70FFD96CB8A88618641BDFCCA03527E665B70D779C8A349A6F88FD4EF6557180BD4C98192872BCFE3AF56E863C09DDD8BC1EC58DF9D94F914F0369102B2870BECFA1348A0838C9C49BD1C20124B442477572347047506B1FCD658A80D0C44BCC16BC5C5496CFE6E4A8428EF654CD3D8972BF6E5BFAD59C93006830B5EB1056BBB38B53D1464FA6E02BFDF2FF66CD949486F0775EC43034EC2602AEFBF1703AD221DAA2A88353C3B6A688EFE8387811F645CEED7B3FE46E1F8B9F59FAD028F349B9BC14211D5830994D055EEA3D547911E07A0ADDEB8A82B9188E58720D95CD478EEC9AF1F17BE8141BE80906F1A339445A7EB5B285F68039B0F294598A7D1C0005FC22B5271B0752F58CCDEF8C8FD856FB7AE21C80B8A2CE983AE94046E53EDE4CB89F42502D31B5360771C01C80155918637490550E3F555E2EE75CC8C636DDE3633CFEDD62E91BF0F7688273694EEEBA20C2FC9F14A2A435517BC1D7373922463409AB603295CEB0BB53787A334C9CA3CA8B30005C5A62FC0715083462E00719A8FA3ED0A9828C3871360A73F8B04A4FC1E71302844E9BB9940B77E745C9D91F226D71AFCAD4B113AAF68D92B24DDB4A2136B55A1CD1ADF39605B63CB639038ED0F4C987689866// 743A68769CC55847E4A06D6E2E3F1',\r\n//   exponent: '0x10001',\r\n//   pubkey: <Buffer ... >,\r\n//   valid_from: 'Aug 14 00:00:00 2017 GMT',\r\n//   valid_to: 'Nov 20 23:59:59 2019 GMT',\r\n//   fingerprint: '01:02:59:D9:C3:D2:0D:08:F7:82:4E:44:A4:B4:53:C5:E2:3A:87:4D',\r\n//   fingerprint256: '69:AE:1A:6A:D4:3D:C6:C1:1B:EA:C6:23:DE:BA:2A:14:62:62:93:5C:7A:EA:06:41:9B:0B:BC:87:CE:48:4E:02',\r\n//   ext_key_usage: [ '1.3.6.1.5.5.7.3.1', '1.3.6.1.5.5.7.3.2' ],\r\n//   serialNumber: '66593D57F20CBC573E433381B5FEC280',\r\n//   raw: <Buffer ... > }\r\n```",
        "labels": "feature request",
        "id": 43135
    },
    {
        "title": "Add information about which linux process fired a signal",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe application I'm running receives a `SIGPIPE` signal and I don't know how to trace within node from which process I received this signal.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdd support for reading e.g. the PID of the `siginfo_t` structure node receives.\r\n\r\nI found an example on Stackoverflow, written in C, where someone achieves this, but my C skills are not good enough yet to write a PR: https://stackoverflow.com/questions/4974140/get-pid-of-the-process-which-has-triggered-some-signal#answer-10364949\r\n\r\nI though of giving this information on as an argument to the function registered for the event. Something that would be printed out by: `process.on('SIGPIPE', (...args) => { console.log(args) })`. It could return an object containing the full `siginfo_t` structure.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI currently am running `sudo strace -p {Node-PID} -tt -e 'trace=!all'` which should print all signals and their origin process. Since this is a separate application I have to keep running, I'd like to let my node process print this information.",
        "labels": "feature request",
        "id": 43136
    },
    {
        "title": "Save REPL history before evaluating input",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'm currently working with big files and try to manipulate them with a few JS lines here and there and sometimes the REPL crashes because it's running out of memory - which is fine, that's just the way it is.\r\n\r\nBut what I noticed here is that the REPL is not saving the executed line to the history unless it's still alive after evaluating it (so I pretty much lose the line that is causing the termination / segfault / / OOM /whatever).\r\n\r\n\r\n**Describe the solution you'd like**\r\nI would like to propose to change the history logic so that it first appends to history (and saves the file?) and then executes the input.\r\n\r\nConsidering an *async* approach should be a good idea. In case of huge histories or slow disks, the evaluation of a command should not be delayed because the history isn't being written to file yet.\r\n\r\n**Describe alternatives you've considered**\r\nI'm not quite sure what else one could do other than making sure the REPL won't crash ðŸ˜€\r\n\r\n---\r\nFor the record and link relations, I previously posted that [here](https://github.com/nodejs/repl/issues/38) *before* I noticed that that repository features a rewrite ðŸ˜¥",
        "labels": "feature request",
        "id": 43137
    },
    {
        "title": "Straight-forward way to reimplement `fs.promises.open`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI have a PR open against `graceful-fs` which (among other updates) adds support for `fs.promises`.  A sticky point is the implementation of `gracefulFS.promises.open`.  We need this to create an object that extends `FileHandle` from `lib/internal/fs/promises.js`.\r\n\r\n**Describe the solution you'd like**\r\nDirectly expose `class FileHandle` from `internal/fs/promises.js` as `fs.promises.FileHandle` to allow extending.  Alter the constructor to detect a numeric `filehandle`:\r\n```js\r\nclass FileHandle {\r\n  constructor(filehandle) {\r\n    if (typeof filehandle === 'number') {\r\n      filehandle = new binding.FileHandle(filehandle);\r\n    }\r\n    // validate (filehandle instanceof binding.FileHandle)?\r\n    this[kHandle] = filehandle;\r\n  }\r\n\r\n  // ... clipped ...\r\n}\r\n```\r\n\r\nThis would allow implementing a user-space `fs.promises.open` with a function based on a promisified `fs.open` function.  In this scheme setting `fs.promises.FileHandle` would not alter the functionality of `fs.promises.open`.\r\n\r\n```js\r\nconst promiseOpen = promisify(gracefulFS.open);\r\n\r\nclass GracefulFileHandle extends fs.promises.FileHandle {\r\n  // override methods as needed\r\n}\r\n\r\nconst myPromises  = {\r\n  ...fs.promises, // simplified copy of default functions for demo\r\n  FileHandle: GracefulFileHandle,\r\n  async open(...args) {\r\n    return new GracefulFileHandle(await promiseOpen(...args));\r\n  }\r\n};\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nCurrent PR at isaacs/node-graceful-fs#173 does some very ugly stuff in [promises.js](https://github.com/isaacs/node-graceful-fs/blob/4d8ddeb6c5a07656842dad924f8af0b7c4db2807/promises.js) to implement `fs.promises.open` which resolves to an extended class based on fs.promises.FileHandle.  First it retrieves the C++ file handle class from `process.binding('fs').FileHandle` even though `process.binding` is heading for deprecation.  Worse it uses `fs.promises.open(__filename, 'r')` to create a filehandle which is used to retrieve `class FileHandle` from `lib/internal/fs/promises.js`, then extends that class.  A temporary `promises.open` method is created which awaits creation of the real method.  This hacky method would be required to support `require('graceful-fs').promises` for current versions of node.js, but it would be nice if `fs.promises.FileHandle` could be detected to avoid all the hacks/deprecated API's.\r\n\r\nI had considered a completely user-space implementation of `gracefulFS.promises` based on `util.promisify` but this would get really messy to reimplement `fs.promises` functions which accept `filehandle`, would potentially cause file handles returned by `gracefulFS.promises.open` to be incompatible with native `fs.promises` methods.  `fs.promises.readFile` for example accepts a filehandle as the first argument, I'm unsure how it would react to a userspace implementation of the file handle.  The user-space implementation would also fail to close FD's upon garbage collection (I don't agree with this auto-close feature but it exists).",
        "labels": "feature request",
        "id": 43138
    },
    {
        "title": "Flag for disabling WebAssembly support",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI want to disable WebAssembly support for testing purposes\r\n\r\n**Describe the solution you'd like**\r\nSet a CLI flag like `--disable-webassembly`\r\nor\r\nset an environment variable like `DISABLE_WEBASSEMBLY`\r\n\r\n**Describe alternatives you've considered**\r\n* deleting `global.WebAssembly` (really bad solution)",
        "labels": "feature request",
        "id": 43139
    },
    {
        "title": "Allow customizable time units in console.time",
        "body": "## The Problem\r\nI am trying to output time taken in seconds using the built in `console.time()` and `console.timeEnd()` functions.\r\nCurrently, my code and output looks like this:\r\n```javascript\r\nconsole.time('Time taken');\r\n// do things\r\nconsole.timeEnd('Time taken');\r\n```\r\nOutput: `Time taken: 34239.098ms`\r\n\r\n## The Solution\r\nI would like to be able to pass in an optional parameter to `console.timeEnd()` to be able to output the results in different units of time rather than milliseconds.\r\nExample:\r\n```javascript\r\nconsole.time('Time taken');\r\n// do things\r\nconsole.timeEnd('Time taken', 's'); // or 'ms', 'm', 'h', 'd'...\r\n```\r\nOutput: `Time taken: 34.239s`\r\n\r\n## Current Alternative\r\nThis is the best alternative that I've currently found:\r\n```javascript\r\nconst begin = Date.now();\r\n// do things\r\nconst end = Date.now();\r\nconst elapsedTime = (end-begin) / 1000;\r\nconsole.log(`Time taken: ${elapsedTime}s`);\r\n```\r\nOutput: `Time taken: 34.239s`\r\n\r\n### Conclusion\r\nNormally I do use milliseconds with my output - and it should remain the default. However I have come across numerous asynchronous processes I'd like to easily measure final time for. Reading 12168532.35ms instead of 3.38h is slightly more difficult.\r\n\r\nThanks for your consideration!",
        "labels": "feature request",
        "id": 43140
    },
    {
        "title": "Error should have a toJSON implementation?",
        "body": "Just playing with some code and discovered that JSON.stringify called against Error instances are empty objects which seems weird since message and stack are string properties? And since errors are usually of interest.\r\n\r\n```js\r\nconsole.log(JSON.stringify(new Error('foo')));  //  {}\r\n\r\n\r\nclass Foo extends Error {\r\n  \r\n  constructor() {\r\n    super(...arguments);\r\n  }\r\n  \r\n  toJSON() {\r\n    return {\r\n      message: this.message,\r\n      stack: this.stack\r\n    }\r\n  }\r\n  \r\n}\r\n\r\nconsole.log(JSON.stringify(new Foo('foo')));   // now we have some output\r\n```\r\n\r\nmaybe the Error class should come with a toJSON implementation?\r\n",
        "labels": "feature request",
        "id": 43141
    },
    {
        "title": "Is it possible to have a parameter to control the number of differential displays in the Assert module?",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI have two content very big of files, I want to be able to control the amount of difference in command line output when comparing them, as they may have many differences.\r\n\r\n**Describe the solution you'd like**\r\nThere is a parameter to control the number of differences display. \r\n\r\n**Describe alternatives you've considered**\r\nCurrently, splitting the file into multiple blocks, compare some content at a time.",
        "labels": "feature request",
        "id": 43142
    },
    {
        "title": "VTune breaking Node.JS issue has been fixed in V8 repo, but the fix patch was not cherry-picked by Node.JS repo",
        "body": "* **Version**:\r\nv13.0.0-pre\r\n\r\n* **Platform**:\r\n 4.18.0-25-generic #26~18.04.1-Ubuntu SMP Thu Jun 27 07:28:31 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n* **Subsystem**:\r\nJIT\r\n\r\n* **Issue**:\r\nVTune profiling is removed from Node.js due to its broken support (commit: 88bac02beeef603a756486a484a5c01446672a3a). \r\n\r\nThis problem has been fixed in V8 (commit: f044f91d87f80d59b4a65799149fa38fa6d67cd7). However Node didnâ€™t cherry-pick this patch.\r\n\r\nThe root cause of this issue was that,  when VTune JIT support is enabled, the WasmEngine of an Isolate tries to enable code logging by EnableCodeLogging() method. This multithreaded method requires a Mutex for safety. However, as the WasmEngine is not created, the Mutex of it is not initialized. An attempt of acquiring this Mutex results in an error. The bug is fixed by creating WasmEngine before it enables code logging.\r\n\r\nThe fix was that, \r\n```\r\n   if (event_handler) {\r\n-    isolate_->wasm_engine()->EnableCodeLogging(isolate_);\r\n+    if (isolate_->wasm_engine() != nullptr) {\r\n+      isolate_->wasm_engine()->EnableCodeLogging(isolate_);\r\n+    }\r\n     jit_logger_.reset(new JitLogger(isolate_, event_handler));\r\n     AddCodeEventListener(jit_logger_.get());\r\n     if (options & kJitCodeEventEnumExisting) {\r\n```\r\nTracked by:\r\n```\r\nChange-Id: I59e749190288ec412f6661233e8f62b0dff3cd7f\r\n    Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/1337376\r\n    Reviewed-by: Clemens Hammacher <clemensh@chromium.org>\r\n    Commit-Queue: Clemens Hammacher <clemensh@chromium.org>\r\n    Cr-Commit-Position: refs/heads/master@{#60060}\r\n```\r\n\r\nVTune is a useful tool to profile Node app performance bottleneck and microarchitecture breakdown. Could you please review this issue and cherry-pick the patch to re-enable VTune profiling in Node.JS? Thank you.",
        "labels": "feature request",
        "id": 43143
    },
    {
        "title": "stream: suggestion stream._writeMany",
        "body": "Currently the `stream.writev` API has two drawbacks:\r\n\r\n- It requires adding properties to the input array (`allBuffers`).\r\n- It will always creates an array copy. \r\n- The array entries must be allocated objects.\r\n\r\nIt would be nice if user space could just create the correctly formatted array without having to perform any allocations, copies and transformations. \r\n\r\nIn order to not break anything I suggest a new signature `writev` maybe called `writeMany`?\r\n\r\nWhich would look something like:\r\n\r\n```js\r\nStream._writeMany = function (chunks, allBuffers, cb) {\r\n}\r\n```\r\n\r\ne.g.\r\n\r\n```js\r\nconst chunks = [];\r\nfor (const { chunk } of data) {\r\n  chunks.push(chunk);\r\n}\r\nw._writeMany(chunks, true, cb);\r\n```\r\n\r\n```js\r\nconst chunks = [];\r\nfor (const { chunk, encoding } of data) {\r\n  chunks.push(chunk, encoding);\r\n}\r\nw._writeMany(chunks, false, cb);\r\n```\r\n\r\nLooking at the current `Writable` implementation, the `writev` scenario will always create two \"unnecessary\" array copies in order to pass the chunks. Furthermore all the array entries are allocated objects.",
        "labels": "feature request",
        "id": 43144
    },
    {
        "title": "stream: writableError & readableError",
        "body": "Would be useful if streams kept track of what error it emitted if it errored.\r\n\r\nFor example this would allow async iterators to re-throw errors when creating an iterator to an already destroyed/errored stream.\r\n\r\nWe already have the `_writableState.errorEmitted` which we could re-use to store the error instead of a boolean.",
        "labels": "feature request",
        "id": 43145
    },
    {
        "title": "[Suggestion] Add option to allow setting process name based on --inspect-brk=0 random port",
        "body": "Currently when using `--inspect-brk=0` tools like VSCode are [unable to](https://github.com/microsoft/vscode/issues/52373) effectively auto attach debuggers to them.\r\n\r\nIt is also particularly [hard to have a cross platform way](https://github.com/microsoft/vscode/issues/78460) of detecting node processes that can be attached to when `NODE_OPTIONS=` is used.\r\n\r\nI'd like to propose adding another option such as `--inspect-set-process-title=pattern` which sets the process title to the given pattern where some things like the websocket name and port can be replaced in the pattern.\r\n\r\ne.g.:\r\n\r\n```bash\r\n# Where %port% gets replaced with the debugging port\r\n$ node --inspect-brk=0 --inspect-set-process-title=\"node:vscode-auto-attach-port=%port%\"\r\n# Or where %websocketUrl% is replaced with the websocket url\r\n$ node --inspect-brk=0 --inspect-set-process-title=\"node:vscode-auto-attach-w=%websocketUrl%\r\n```\r\n\r\nThis could also work with the existing `--title` option when using `--inspect-brk`, I don't have a strong preference for a specific solution.",
        "labels": "feature request",
        "id": 43146
    },
    {
        "title": "n-api: add method to get own property names",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nYes. The need is to only examine properties owned by the object, not properties found on Object.prototype. The C++ API in use before N-API had a GetOwnPropertyNames() method. That appears to be missing from N-API.\r\n\r\n**Describe the solution you'd like**\r\nIdeally, a method like this:\r\n\r\n```c\r\nnapi_status napi_get_own_property_names(napi_env env,\r\n                                        napi_value object,\r\n                                        napi_value* result);\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n(1) call napi_get_property_names() and then call napi_has_own_property() on each entry as you iterate through the provided array. If you need to allocate memory for each entry, however, you either need to iterate through the array twice (once to get the number of owned properties and once to do stuff with the array) or you need to over-allocate memory.\r\n\r\n(2) call \"Object.getOwnPropertyNames()\" directly. This requires calling napi_get_global(), napi_get_named_property() twice (once to get \"Object\" and the second to get \"getOwnPropertyNames\") and then call napi_call_function() -- which is a lot of calls to do one common operation.\r\n",
        "labels": "feature request",
        "id": 43147
    },
    {
        "title": "Support TLS 1.3 0-RTT",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\nI apologize if this is already possible in Node.js, I looked into the TLS and HTTP/HTTP2 docs and didn't find anything.\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nTLS 1.3 adds support for 0-RTT. This can reduce the time needed to setup an HTTPS connection significantly.\r\n \r\n**Describe the solution you'd like**\r\nAllow HTTPS servers to choose whether they want to respond to early data on a per request basis. This allows server authors to respond to 0-RTT only for \"safe\" requests (e.g. [cloudflare does this only for GET requests with no query parameters](https://blog.cloudflare.com/introducing-0-rtt/)).\r\n\r\nI don't know how exactly this would look like in Node, but maybe it could be a property on `http.IncomingMessage` and `http2.Http2ServerRequest`.\r\n",
        "labels": "feature request",
        "id": 43148
    },
    {
        "title": "TLS: keys from engines?",
        "body": "As far as I can see NodeJS TLS does support OpenSSL engines. But it looks like it only supports them for certificates.\r\n\r\nMy use-case is a private key managed inside an engine. What I would do, e.g. with libcurl is\r\n\r\n```\r\n// load the engine\r\ncurl_easy_setopt(curl, CURLOPT_SSLENGINE, \"mycoolengine\");\r\n\r\n// set it as a default engine\r\ncurl_easy_setopt(curl, CURLOPT_SSLENGINE_DEFAULT, 1L);\r\n\r\n// tell libcurl that private key is managed by the engine\r\ncurl_easy_setopt(curl, CURLOPT_SSLKEYTYPE, \"ENG\");\r\n\r\n// set key name (arbitrary string, interpreted by the engine)\r\ncurl_easy_setopt(curl, CURLOPT_SSLKEY, \"myenginekeyname\");\r\n```\r\n\r\nWith nodejs it goes like:\r\n\r\n```\r\n> tls_ctx = tls.createSecureContext({\"clientCertEngine\":\"mycoolengine\", \"key\":\"myenginekeyname\"})\r\n\r\nError: error:0906D06C:PEM routines:PEM_read_bio:no start line\r\n    at Object.createSecureContext (_tls_common.js:104:17)\r\n```\r\nSo looks like it tries to interpret `\"myenginekeyname\"` as PEM. Am I doing something wrong, or is this use-case not supported at all?\r\n\r\nThanks!\r\n",
        "labels": "feature request",
        "id": 43149
    },
    {
        "title": "Provide highest created directory from recursive fs.mkdir",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'm investigating migration of some code from `mkdirp` to native `fs.mkdir`.  The issue is that I need to know the highest level directory created, which is not possible with native recursive fs.mkdir.  So if `./new-dir` does not exist and I create `./new-dir/subdir/subdir` I need to know that `./new-dir` was created so I can chown it.  `mkdirp` provides the required return value.  fs.mkdir does not provide any value so it is impossible to use the recursive `fs.mkdir` when I need to control ownership of all created directories.\r\n\r\n**Describe the solution you'd like**\r\nAdd a value to the `fs.mkdir` callback for the first directory created.\r\n\r\n**Describe alternatives you've considered**\r\nMaybe `fs.mkdir` could accept a `uid` and `gid` options to perform chown actions internally?  I tried `make-dir` but this returns the original argument instead of the highest path.  `make-dir` also uses the native fs.mkdir in node.js 10.12.0+ so I don't think it's currently possible for it to replicate the return value of `mkdirp`.\r\n\r\nCC @bcoe",
        "labels": "feature request",
        "id": 43150
    },
    {
        "title": "Feature request: os: os.availableProcessors()",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nIt's unable to get actual available amount of processors in a docker container running on image `node:10.16.0`, of which cpus is limited by [docker container resource constraints](https://docs.docker.com/config/containers/resource_constraints/). For detail information, please have a look at issue [#28762](https://github.com/nodejs/node/issues/28762).\r\n\r\n**Describe the solution you'd like**\r\nProvide `os.availableProcessors()` api to get the actual available amount of processors.\r\n\r\n**Describe alternatives you've considered**\r\nIf possible, it's better to fix the output of `os.cpus().length`, e.g. by using `Proxy` to change the value of `length` property. Because most node modules use `os.cpus().length` to decide how many processes it should fork, which may exceed the limitation of cpus in the docker container.",
        "labels": "feature request",
        "id": 43151
    },
    {
        "title": "Contexts created with vm.createContext() do not define the URL() constructor",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v12.6.0 (also seen in 10.13.0)\r\n* **Platform**: Darwin Davids-MacBook-Pro.local 18.5.0 Darwin Kernel Version 18.5.0: Mon Mar 11 20:40:32 PDT 2019; root:xnu-4903.251.3~3/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nI've created a simple testing framework that runs tests using vm.Script.runInContext(). Now I'm writing tests for code that uses the whatwg URL API. If I use `vm.createContext()`, the created context does not define the URL() constructor. But if I pass in the URL constructor with `vm.createContext({URL})`, then I have a situation where arrays returned by URLSearchParams methods are defined using the Array.prototype object from outside the context, and my tests are trying to compare those to arrays defined inside the context with a different Array.prototype object. So because I have two arrays with different prototypes, `assert.deepStrictEqual()` thinks they are not the same.\r\n\r\nI'd argue that the underlying bug here is that URL should be automatically defined in newly created contexts without having to be passed in.  Or maybe this is a bug in `assert.deepStrictEqual()` and it is stricter than it ought to be in this cross-context situation? \r\n\r\nIn any case, here is an example that reproduces the issue for me:\r\n\r\n```\r\nconst vm = require('vm');\r\n\r\n// URL is not defined inside the context, and I can't require it, so\r\n// I need to pass it to the context from outside. But it returns arrays\r\n// using the Array class from outside the context.\r\nlet context = vm.createContext({require, URL, externalArray:Array});\r\n\r\nlet script = new vm.Script(`\r\n    const assert = require('assert');\r\n    let url = new URL('http://example.com');\r\n    url.searchParams.append('x', '1');\r\n    url.searchParams.append('x', '2');\r\n    let actual = url.searchParams.getAll('x'); // Uses array class from outside\r\n    let expected = ['1', '2'];                 // Uses array class from inside\r\n    assert(Array.isArray(actual));                                // passes\r\n    assert.deepStrictEqual(Array.from(actual), expected);         // passes\r\n    assert.deepStrictEqual(actual, externalArray.from(expected)); // passes\r\n    assert.deepStrictEqual([...actual], expected);                // passes\r\n    assert.deepStrictEqual(actual, expected);               // fails\r\n    assert.equal(Object.getPrototypeOf(actual),             // also fails\r\n                 Object.getPrototypeOf(expected)); \r\n`);\r\n\r\nscript.runInContext(context);\r\n```\r\n",
        "labels": "feature request",
        "id": 43152
    },
    {
        "title": "crypto: support extendable-output functions (shake128, shake256)",
        "body": "\r\n* **Node.js Version**:10.16.0\r\n* **OS**:windows 10\r\n* **Scope (install, code, runtime, meta, other?)**:runtime\r\n* **Module (and version) (if relevant)**:crypto\r\n\r\nThe shake128 and shake256 hash functions allow you to specify the size of the digest, however the createHash call doesn't seem to allow setting those options. \r\n```js\r\n        const hash = crypto.createHash('shake128');\r\n        hash.update('blabadeblablabla');\r\n        console.log( hash.digest('hex') );\r\n```",
        "labels": "feature request",
        "id": 43153
    },
    {
        "title": "attach `req` as `res.req`",
        "body": "I'd like to propose attaching the `IncomingMessage` (`req`) object in an HTTP server  to the `ServerResponse` (`res`) object:\r\n\r\n```js\r\nres.req = req\r\n```\r\n\r\nBecause it is often the case that when creating a response you need to access information related to the request itself. \r\n\r\n(If you read on you'll notice that all of the popular frameworks do this under the covers, and that Node's internal logic also uses this connection, but that it's not available for smaller utilities in userland.)\r\n\r\n---\r\n\r\n### The current state of things.\r\n\r\nAs things stand right now, for HTTP response-related logic you often end up needing to have access to the `req` object too to handle a variety of edge-case situations, which leads to either verbosity or inconsistency, and either wayâ€¦ confusion.\r\n\r\nFor example, imagine writing a `sendJson` helper:\r\n\r\n```js\r\nfunction sendJson(res, status, json, options = {}) {\r\n  const { spaces = 2, pretty = true } = options\r\n  let string\r\n\r\n  if (pretty) {\r\n    string = JSON.stringify(json, value, spaces)\r\n  } else {\r\n    string = JSON.stringify(json)\r\n  }\r\n\r\n  res.statusCode = status\r\n  res.setHeader('Content-Length', Buffer.byteLength(string))\r\n  res.setHeader('Content-Type', 'application/json; charset=utf-8')\r\n  res.end(string)\r\n}\r\n```\r\n\r\nAll seems fine. But this doesn't account for `HEAD` requests that should not include a body. To fix this you'd have to add `(req, ...)` to the signature, which is unintuitive. This is a frequent issue with HTTP-related utilities, and it part of the reason why you end up _having_ to reach for a framework, instead of seeing a proliferation of small, useful HTTP functions.\r\n\r\n### All the major userland frameworks do this already.\r\n\r\nThis has already been established as a common practice in userland, because of how often you need to tweak a response based on the request. \r\n\r\n- [Express](https://github.com/expressjs/express) attaches it as [`res.req`](https://github.com/expressjs/express/blob/3ed5090ca91f6a387e66370d57ead94d886275e1/lib/middleware/init.js#L31-L32).\r\n- [Fastify](https://github.com/fastify/fastify) attaches it as [`reply.request`](https://github.com/fastify/fastify/blob/093e18de2d37d559004f89d2c437478040913969/lib/reply.js#L55-L68).\r\n- [Hapi](https://github.com/hapijs/hapi) attaches it as [`h.request`](https://github.com/hapijs/hapi/blob/93378b243e064c961a42fae2e4e72ed874d4588b/lib/toolkit.js#L150-L159) and [`response.request`](https://github.com/hapijs/hapi/blob/93378b243e064c961a42fae2e4e72ed874d4588b/lib/response.js#L28-L35).\r\n- [Koa](https://github.com/koajs/koa) attaches it as [`response.request`](https://github.com/koajs/koa/blob/ff70bdc75a30a37f63fc1f7d8cbae3204df3d982/lib/application.js#L160-L169).\r\n- [Restify](https://github.com/restify/node-restify) attaches it as [`res.req`](https://github.com/restify/node-restify/blob/c5a07c5822c1ef52a840ae6d4ed11f2334f81472/lib/server.js#L1255).\r\n\r\nOften times the `req` is needed only for HTTP-specific plumbing edge cases (like checking `HEAD` or `OPTIONS` requests) that are not immediately obvious to the user's mental model. Which is why it's helpful if HTTP logic can access it implicitly for the edge cases where it's required.\r\n\r\nMost of these frameworks also do the reverse, attaching the response to the request for parallelism/consistency.\r\n\r\n### Technically, you can already do the reverse.\r\n\r\nYou can actually already do the reverseâ€”accessing the `res` object from the `req` without a framework, by using the `req.connection._httpMessage` property. Now, this isn't exactly encouraged seeing as it's an undocumented property, but it shows that it's not out of the question to create these kinds of links between these two objects.\r\n\r\n### Why not always pass `req` into helpers?\r\n\r\nA counter-argument would be to say that `req` should just be passed into any helper that needs to use properties from it. This sounds reasonable at first, but the issue with this approach is that it leads to mismatch with user expectations.\r\n\r\nThe solutions become inconsistent because access to the `req` isn't **always** required. For example, consider a few different helpers for setting the correct headers on a response:\r\n\r\n- A simple `setHeader(res, name, value)` helper doesn't need the `req`, because it just sets the value to whatever was passed in.\r\n- But a `setCors(res, options)` helper would actually need to be `setCors(req, res, options)` because you need to determine if the request used the `OPTIONS` method. \r\n- A `setAuthenciate(res, scheme, options)` helper also doesn't need the `req` object.\r\n- But a `setRequestId(res, options)` would need the `req` to default the ID in case it was already set.\r\n\r\nThe exact nature of the examples is irrelevantâ€”they could be implemented in many different ways. But the point is that access to `req` is required in certain situations when building a response, but not in others. Which leads to APIs that are inconsistent in signature between `(res, ...)` and `(req, res, ...)`, causing confusion.\r\n\r\nAnd it's often required for low-level, edge-case HTTP behaviors that most users of these modules ideally don't need to think about, because they are HTTP plumbing.\r\n\r\nYou might argue that then all response-related helpers should include `(req, res, ...)` to keep it consistent. But if you consider things like `sendJson(res, status, json, options)`, adding an extra `(req, ...)` to every arguments list becomes tedious. Especially so for helpers that don't use the `req` at all, and are just forced to add it for consistency for others. It feels pretty dumb to have to do `getBasicAuth(req, res)` just because the library needs consistency to handle ~10â€“20% cases.\r\n\r\nThis awkwardness is why the major HTTP frameworks for Node have all included a way to access the request from the response themselves. They know that for users it's much simpler to think about working on _either_ the request or the response. But that edge cases require having access to both objects at once.\r\n\r\n### Node's core uses the \"reference\" itself internally.\r\n\r\nWhen creating the `res` object in the first place, Node's core has access to `req`. And it actually does some of the same exact things that are being advocated for here, by calculating some internal logic for the response based on the request.\r\n\r\nhttps://github.com/nodejs/node/blob/a013aa0f5eba9915e2c996e32281433f72d495ae/lib/_http_server.js#L148\r\n\r\nhttps://github.com/nodejs/node/blob/a013aa0f5eba9915e2c996e32281433f72d495ae/lib/_http_server.js#L155-L156\r\n\r\nhttps://github.com/nodejs/node/blob/a013aa0f5eba9915e2c996e32281433f72d495ae/lib/_http_server.js#L713-L716\r\n\r\nThese are all internal situations where specific response-related logic is being calculated by the request metadata and attached to `res` for future use. It just happens that Node already has the `req` in scope when creating the `res`. But it would be nice for userland to be able to do the same sorts of things with the `res` only.\r\n\r\n### This would open up new userland abilities.\r\n\r\nRight now HTTP-related pieces of userland are almost exclusively handled by large monolithic frameworks like Express or Hapi. This is partly because there doesn't exist a simpler, Lodash-like set of utilities for handling HTTP requests in a simple functional way. Being able to link `req` and `res` would make building an intuitive library like this _much_ easier.\r\n\r\nNot only does this allow for people to opt-out of using a framework. But, more importantly, it allows other utilities to be built in a framework-agnostic way.\r\n\r\nYou could imagineâ€¦\r\n\r\n![image](https://user-images.githubusercontent.com/311752/102029742-a39b4380-3d7d-11eb-9ee2-86af6fcea7de.png)\r\n\r\nâ€¦a world where the frameworks themselves aren't necessary. This would be helpful Lambda-like situations, or for simply adding extra HTTP-aware logic to adjacent domains, or just for keeping things extremely simple while prototyping. A lot of different use cases would benefit.\r\n\r\nA good example of this is [Vercel's built-in HTTP modifications](https://vercel.com/blog/vercel-node-helpers). These kinds of behaviors are happening all over the place in the FaaS world, and only further fragment Node's HTTP handling. It would be amazing if non-monolithic solutions to this problem could thrive.\r\n\r\n---\r\n\r\n### In summary...\r\n\r\nAttaching `res.req` is a simple addition to Node's core that would make writing HTTP servers _without_ needing a framework easier, which is especially helpful for writing framework-agnostic utilities, or in Lambda-like environments where you need smaller dependencies, or in performance-critical situations where framework overhead is harmful. All major userland HTTP frameworks already all do this.\r\n\r\nIt would also make it possible for userland to step up and create a nice set of _framework-agnostic_ helper modules (eg. `setCors`, or `setRequestId`), without forcing them to have more confusing APIs than their framework-coupled counterpartsâ€”since at the moment they can't benefit from the link.\r\n\r\nI hope that all makes sense. I think this would a small change, but one that unlocks a lot of value in userland at many layers of the stack.\r\n\r\nThanks for reading!",
        "labels": "feature request",
        "id": 43154
    },
    {
        "title": "Cluster: can't listen worker SIGTERM from master side",
        "body": "* **Version**: 10.16.0\r\n* **Platform**: Ubuntu 18.04 (Linux 4.15.0-54-generic x86_64)\r\n* **Subsystem**: cluster\r\n\r\nHello, how is going?\r\n\r\nI prefer let some code with comments instead of explaining a lot.\r\n\r\n```js\r\nconst cluster = require('cluster');\r\n\r\nif(cluster.isMaster) {\r\n\tconsole.log('master pid', process.pid);\r\n\r\n\tlet worker = cluster.fork();\r\n\r\n\t//it's never called\r\n\tworker.process.on('SIGTERM', () => {\r\n\t\tconsole.log('worker sigterm');\r\n\t\tworker.disconnect();\r\n\t});\r\n\r\n\t//kill -s SIGTERM [worker pid]\r\n\t//normally called by other process but to automate the kill\r\n\tsetTimeout(() => process.kill(worker.process.pid, 'SIGTERM'), 1000);\r\n\treturn;\r\n}\r\n\r\nconsole.log('worker pid', process.pid);\r\n\r\nlet interval = setInterval(() => {}, 100); //it can be a server (shared port)\r\n\r\ncluster.worker.on('disconnect', () => {\r\n\tconsole.log('worker disconnect');\r\n\tclearInterval(interval); //cleanup so exit naturally\r\n});\r\n```\r\n\r\nActual output:\r\n```\r\nmaster pid 15210\r\nworker pid 15217\r\n```\r\n\r\nShould be:\r\n```\r\nmaster pid 15210\r\nworker pid 15217\r\nworker sigterm\r\nworker disconnect\r\n```\r\n\r\nWhy `worker.process.on` doesn't catch `SIGTERM` event?\r\n\r\nMy workaround it's listening SIGTERM from worker side and sending a message to master, for me works perfect but I want to avoid doing messaging because it's for a library and it can make conflict with user code. Obviously also I want to know why doesn't work in the another way.\r\n\r\nAnyway, thanks!",
        "labels": "feature request",
        "id": 43155
    },
    {
        "title": "Create fs utility which can modify a file in-place",
        "body": "I am specifically looking for a feature which can allow me to remove old lines from a log file. I read that `sed -i` can remove lines from a file in-place (without reading the whole file splitting by line and then shifting off lines and then overwriting the file).\r\n\r\nSo it looks like:\r\n\r\n```\r\n\r\nmy_file.log\r\n---\r\na\r\nb\r\nc\r\nd\r\n\r\nwe call fs.removeBytesSync(0,2)\r\nmy_file.log\r\n---\r\nb\r\nc\r\nd\r\n\r\nwe call fs.removeBytesSync(0,2)\r\nmy_file.log\r\n---\r\nc\r\nd\r\n\r\n\r\nwe call fs.removeBytesSync(0,2)\r\nmy_file.log\r\n---\r\nd\r\n\r\n```\r\n\r\nTo determine how many bytes to remove to represent a line, we can do this:\r\n\r\n```js\r\n\r\nconst fs = require('fs');\r\nconst v= fs.readFileSync('./my-file.log', {start:0, end: 4000, encoding:'utf8'});\r\nconst lines = v.split('\\n');\r\nconst firstLineBytes = Buffer.from(lines.shift() + '\\n').length;\r\nconsole.log(firstLineBytes);\r\n```\r\n\r\n_but I don't know how to delete bytes from a file in place with Node.js._\r\n\r\n",
        "labels": "feature request",
        "id": 43156
    },
    {
        "title": "re2 as safer opt-in regexp engine replacement ?",
        "body": "Since v8 won't work around the exponential backtracking issue:\r\nhttps://bugs.chromium.org/p/v8/issues/detail?id=6872\r\nthis would address\r\nhttps://github.com/nodejs/node/issues/9337\r\nwithout imposing nor actually breaking anything.\r\n\r\nI find it extremely bad - and a reason for people to criticize node - that developers can so easily make their applications vulnerable to that kind of DOS.\r\n\r\nAlso note that v8 authors are even blogging (and this is very interesting) about it (last week !):\r\nhttps://medium.com/@erik_68861/regexp-backtracking-in-loops-and-how-we-can-optimize-it-away-ef3b2590f87e\r\nso \"just wait\" might even be a solution...",
        "labels": "feature request",
        "id": 43157
    },
    {
        "title": "perf_hooks: expose `performance` global",
        "body": "Browsers export a [`performance`](https://developer.mozilla.org/en-US/docs/Web/API/Performance) global, and I think we should too if the [`perf_hooks` module](https://nodejs.org/api/perf_hooks.html) is stable enough (and can be lifted from experimental stability) to allow easy usage in isomorphic scripts.",
        "labels": "feature request",
        "id": 43158
    },
    {
        "title": "Support file descriptors as `fs.copyFile`/etc. sources and destinations",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI have a file descriptor that I acquired, in hopes to avoid race conditions with the underlying directory moving out from under my feet and to avoid an otherwise unnecessary `fs.lstat` call. (All I'm doing is verifying it's accessible as a file or directory.) Conveniently, I can pass this file descriptor directly to `fs.readFile` if it's something I want to parse, but for some files, like images, I want to copy them directly.\r\n\r\n**Describe the solution you'd like**\r\nI'd like to pass the above descriptor directly to `fs.copyFile` as `fs.copyFile(sourceFd, target)`. My personal use case is that of needing a source file descriptor, but I could see the use case of a target file descriptor, too. (Think: frequent writes, safe replace if outdated via stat + copyFile.)\r\n\r\n**Describe alternatives you've considered**\r\nCurrently, if I want to reuse the descriptor and copy the file directly, I have to do something similar to `stream.finished(fs.createReadStream(null, {fd}), fs.createWriteStream(target), callback)` to do this. This code probably looks familiar, since that's literally the kind of repetitive code that was converted into `fs.copyFile`.\r\n\r\n**Edit:** fix passing file descriptor.",
        "labels": "feature request",
        "id": 43159
    },
    {
        "title": "Stream: Merge/Mutation/Inflation Stream",
        "body": "# Merge/Mutation/Inflation Stream\r\n*I don't know what to call it... Merge Stream for now I guess*\r\n\r\nA Merge Stream would be a type of stream where different streams are merged together. The general idea is illustrated in the following diagram:\r\n\r\n![simplified process][simplified_stream_process]\r\n\r\nThe idea is that you have a set of main readable streams, and a set of secondary readable streams. The secondary streams have to be merged at a specific index of one of the main stream without having buffers pile up in memory.\r\n\r\n## Problem / Why is it needed?\r\nThere are no libraries that provide this functionality and it is a versatile building block, especially for the less experienced programmers. A 'simple' solution for this problem is quite complex. Which can be demonstrated with [my solution (in typescript)](https://gist.github.com/softwareperson/8eab1f94a519338eea812f21fab6a041) for this problem. Which I wrote to answer my own [stackoverflow question](https://stackoverflow.com/questions/56769854/memory-efficient-growing-nodejs-duplex-transform-stream). It is a [little hacky](https://gist.github.com/softwareperson/8eab1f94a519338eea812f21fab6a041#file-mergestream-ts-L115-L122). It would be nice that by implementing this natively, could remove the hacky-ness.\r\n\r\n## Interface\r\nThe draft interface uses a generator function that relies on the `yield` keyword introduced in ECMAScript 2015. The generator function should return an index that indicates where it should be merged, and the `Readable` stream that needs to be merged with the main stream(s).\r\n\r\n```\r\ninterface {index:number, stream: Readable};\r\n```\r\n\r\n The user implementation would look something like this:\r\n```\r\n* _streamGenerator() {\r\n    // create a hundred streams\r\n    for (let index = 0; index < 100; index++) {\r\n        const stream = new Readable();\r\n        stream.push(index);\r\n        stream.push(null);\r\n        yield {index, stream};\r\n    }\r\n}\r\n```\r\n\r\nNext to this interface there I have drafted two constant, `START` and `END` with which the user can mark the start index and the end index of the stream. `START` will have the value `0`, and `END` will have the value `-1`.\r\n\r\n| Name   | Value | Description                         |\r\n| :----- | :---: | :---------------------------------- |\r\n| START  |  0    | Marks the start index of the stream |\r\n| END    | -1    | Marks the end index of the stream   |\r\n\r\nThe start index can be used to prepend values to the main, which might not be that valuable since it works the same as using index 0, but it is a bit more readable. The end index is more valuable since it can be used to append to streams of unknown lengths.\r\n\r\n**Usage:**\r\n\r\n```\r\nconst mergingStream = new Merge({\r\n    * nextStream(): IterableIterator<MergingStream> {\r\n        for (let i = 0; i < 10; i++) {\r\n            const stream = new Readable();\r\n            stream.push(i.toString());\r\n            stream.push(null);\r\n            yield {index: i * 2, stream};\r\n        }\r\n\r\n        const appendedStream = new Readable();\r\n        appendedStream.push('. End Stream');\r\n        appendedStream.push(null);\r\n        yield {index: Merge.END, stream: appendedStream};\r\n        const resetIndex = new Readable();\r\n        resetIndex.push('of this ');\r\n        resetIndex.push(null);\r\n        yield {index: 6, stream: resetIndex};\r\n\r\n    },\r\n});\r\nconst template = new Readable();\r\ntemplate.push(', , , , , , , , , ');\r\ntemplate.push(null);\r\ntemplate.pipe(mergingStream).pipe(getSink());\r\n```\r\n\r\nThis will result in the following\r\n```\r\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9. End of this Stream\r\n```\r\n\r\n\r\n## Use cases / How can it be used?\r\n\r\n### Templates and Caching\r\nThe first use case, and probably the most common one, would be for templates. These templates would have to generate a list of indices where to insert its values.  Caching is a pretty similar story. Your cache can consist out of templates that require some data to be filled. With the introduction of this stream the implementation could look something like this:\r\n\r\n```\r\n    const valueStreams = getValueStreams();\r\n\r\n    const indices = [\r\n        // Merge.START is the same value as index 0 \r\n        Stream.Merge.START,\r\n        100,\r\n\r\n        // Double indices will result in different streams to be appended\r\n        // right after one another\r\n        200, 200\r\n\r\n        // Merge.END will append _nextStream as the new main Stream\r\n        // once the main Stream has ended\r\n        Stream.Merge.END,\r\n\r\n        // index is reset after Merge.END, so you can insert into\r\n        // any position of the new stream again\r\n        Stream.Merge.START, 50\r\n    ];\r\n\r\n    const mergingStream = new Stream.Merge(\r\n        // implementation decides how a stream is returned\r\n        * nextStream(): {\r\n            let i = 0;\r\n            // can be read from a list like this\r\n            for (const stream of valueStreams) {\r\n                yield {index: indices[i++], stream};\r\n            }\r\n            // Or preferably be initialized in this method\r\n            // such that they only allocate memory when they are being used\r\n            // Stream.Merge could pre load the next stream\r\n            yield {index: indices[i++], stream: initializeSomeStreamHere()};\r\n        },\r\n    );\r\n\r\n    getSomeTemplateStream().pipe(mergeStream).pipe(sink);\r\n```\r\n\r\n\r\n### Mutations\r\nAnother possible use case for this type of stream is with data that requires many mutations. \r\n\r\nThat implementation could look something like this.\r\n\r\n```\r\n    const multiplexingStream = getSomeMultiplexingStream();\r\n    const sinkList = getSinkList();\r\n    for (let i = 0; i < 100; i++) {\r\n        const mergingStream = new Stream.Merge(\r\n            * nextStream(): {\r\n                const stream = new ReadStream();\r\n                stream.push(i.toString());\r\n                stream.push(null);\r\n                yield {index: 100, stream};\r\n            }\r\n        )\r\n        multiplexingStream.pipe(mergingStream).pipe(sinkList[i]);\r\n    }\r\n\r\n```\r\n\r\n\r\n### Other use cases\r\n\r\nThere are probably a few more, but these are the biggest once I could come up\r\n\r\n## In Conclusion\r\nthe *Merge Stream* is a very versatile building block that would add value for use cases such as templates, caching and mutating data streams without using a lot of extra memory. I have already written a simple solution. My solution will still need a bit of improvement and optimization and it also doesn't work in object mode (yet). The interface I came up with is a draft. Any other suggestions would be appreciated. I wouldn't mind help (or do it all) turning this draft into a full fletched nodejs feature. \r\n\r\n\r\n<!--Diagram URL-->\r\n[simplified_stream_process]: https://i.imgur.com/JRMVzmv.png\r\n",
        "labels": "feature request",
        "id": 43160
    },
    {
        "title": "fs: add WriteStream.prototype.fsync",
        "body": "Right now it's pretty complicated to intermix `fs.fsync()` calls with `ws.write()` calls, to the point that you lose most of the benefits of using `fs.WriteStream`. Example:\r\n```js\r\nconst fs = require('fs');\r\nconst ws = fs.createWriteStream('test.txt');\r\nws.write('important data', () => {\r\n  fs.fsync(ws.fd, () => {\r\n    // only now is it safe again to call ws.write()\r\n    ws.write('more important data', () => {\r\n      fs.fsync(ws.fd, () => { /* etc. */ });\r\n    });\r\n  });\r\n});\r\n```\r\nIt would be exceedingly helpful if `fs.WriteStream` grew a `.fsync()` method that preserves order with respect to writes so that the following example works like I would expect it to:\r\n```js\r\nconst ws = require('fs').createWriteStream('test.txt');\r\nws.write('important data');\r\nws.fsync();\r\nws.write('more important data');\r\nws.fsync();\r\n```\r\n\r\n<hr>\r\n\r\nIt's not quite impossible to accomplish the above today but it's not very ergonomic. Here is an async/await example:\r\n```js\r\nconst util = require('util');\r\nconst fs = require('fs');\r\nconst ws = fs.createWriteStream('test.txt');\r\nws.once('open', (fd) => go(fd));\r\nasync function go(fd) {\r\n  const write = util.promisify(ws.write.bind(ws));\r\n  const fsync = util.promisify(fs.fsync.bind(null, fd));\r\n  await write('important data');\r\n  await fsync();\r\n  await write('more important data');\r\n  await fsync();\r\n}\r\n```\r\nI don't know, the fact that you need to know about the `'open'` event doesn't give me warm fuzzies. Proper synchronization is important enough that I feel it merits a place in core.",
        "labels": "feature request",
        "id": 43161
    },
    {
        "title": "repl: substring based search history ",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\nMost repl's I've used before allow you to quickly get a previous command back by using the Ctrl+r key to search the command history. It makes life so much easier when you're testing stuff out. Any chance this could be implemented for the nodejs repl?\r\n\r\n",
        "labels": "feature request",
        "id": 43162
    },
    {
        "title": "Diagnostics report: inspect the error object ",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nNow we [inspect the error object on fatal errors](https://github.com/nodejs/node/pull/27243), which is awesome. I started to play with node-report recently and this feature was not incorporated there yet. I think this would make a lot of sense since it would make the report more useful for users. \r\n\r\n**Describe the solution you'd like**\r\nTake the program below as an example:\r\n\r\n```js\r\n// crash.js\r\nfunction crash() { \r\n  let e = new Error('boom'); \r\n  e.val = 1; \r\n  throw e;\r\n} \r\n\r\ncrash();\r\n```\r\n\r\nToday it will output the following stack trace (see how it also prints the custom attribute we added):\r\n\r\n```\r\n$ ./node ./crash.js\r\n/home/mmarchini/workspace/nodejs/node/crash.js:5\r\n  throw e;\r\n  ^\r\n\r\nError: boom\r\n    at crash (/home/mmarchini/workspace/nodejs/node/crash.js:3:11)\r\n    at Object.<anonymous> (/home/mmarchini/workspace/nodejs/node/crash.js:8:1)\r\n    at Module._compile (internal/modules/cjs/loader.js:779:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:790:10)\r\n    at Module.load (internal/modules/cjs/loader.js:642:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:555:12)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:842:10)\r\n    at internal/main/run_main_module.js:17:11 {\r\n  val: 1\r\n}\r\n```\r\n\r\nThe report for this error looks like this today:\r\n\r\n```js\r\n  \"javascriptStack\": {\r\n    \"message\": \"[eval]:1\",\r\n    \"stack\": [\r\n      \"at crash (/home/mmarchini/workspace/nodejs/node/crash.js:3:11)\",\r\n      \"at Object.<anonymous> (/home/mmarchini/workspace/nodejs/node/crash.js:8:1)\",\r\n      \"at Module._compile (internal/modules/cjs/loader.js:779:30)\",\r\n      \"at Object.Module._extensions..js (internal/modules/cjs/loader.js:790:10)\",\r\n      \"at Module.load (internal/modules/cjs/loader.js:642:32)\",\r\n      \"at Function.Module._load (internal/modules/cjs/loader.js:555:12)\",\r\n      \"at Function.Module.runMain (internal/modules/cjs/loader.js:842:10)\"\r\n    ]\r\n  },\r\n```\r\n\r\nIt would be amazing if we had the properties as well, as shown below:\r\n\r\n```js\r\n  \"javascriptStack\": {\r\n    \"message\": \"[eval]:1\",\r\n    \"stack\": [\r\n      \"at crash (/home/mmarchini/workspace/nodejs/node/crash.js:3:11)\",\r\n      \"at Object.<anonymous> (/home/mmarchini/workspace/nodejs/node/crash.js:8:1)\",\r\n      \"at Module._compile (internal/modules/cjs/loader.js:779:30)\",\r\n      \"at Object.Module._extensions..js (internal/modules/cjs/loader.js:790:10)\",\r\n      \"at Module.load (internal/modules/cjs/loader.js:642:32)\",\r\n      \"at Function.Module._load (internal/modules/cjs/loader.js:555:12)\",\r\n      \"at Function.Module.runMain (internal/modules/cjs/loader.js:842:10)\"\r\n    ],\r\n    \"errorProperties\": {\r\n      \"val\": 1\r\n    }\r\n  },\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nThe only alternative as powerful as this would be core dumps, but the entry barrier for core dumps is way higher than node-report.\r\n",
        "labels": "feature request",
        "id": 43163
    },
    {
        "title": "Worker Thread: how to get per-worker cpu & memory util rate?",
        "body": "Dear Node community, I'm working on a Node.js project which utilizes worker thread feature. I'd like to get CPU & memory util rate for each spawned worker thread. I did a few search but with very few information on this topic. Thanks for your help.",
        "labels": "feature request",
        "id": 43164
    },
    {
        "title": "v8 Coverage for integrators",
        "body": "This is derived from the conversations had here: https://github.com/bcoe/c8/issues/116\r\n**Is your feature request related to a problem? Please describe.**\r\nThe problem is with intergrating V8 coverage into downstream systems such as test runners or processes which run nodejs programs.\r\n\r\n**Describe the solution you'd like**\r\nThe most ideal solution would be something like \r\n```\r\n// where it comes from isn't too important\r\nconst coverage = require('some-nodejs-module-maybe?');\r\n\r\nconst collection = coverage.collectCoverage({reporters: ['text-summary', 'lcov']});\r\njasmine.execute();\r\nconst reports = await collection.completeCoverage();\r\n\r\nconst textSummaryReport = reports.get(''text-summary');\r\nconsole.log(textSummaryReport);\r\n\r\ncons lcovReport = reports.get('lcov');\r\nfs.writeFileSync('to/some/location', lcovReport);\r\n// or maybe merge/process it in some other way\r\n```\r\n\r\nHowever it's my understanding that this approach wouldn't work very well since internally the `collectCoverage` would have to activate covergae via the inspector api which isn't the best.\r\nhttps://github.com/bcoe/c8/issues/116#issuecomment-502826818\r\n\r\nWith that in mind another approach is using the `NODE_V8_COVERAGE=/some/dir` env var.\r\nHowever an issue came accross with this one where we need to somehow signal Nodejs to write out the coverage file since we need to process it in in the same process.\r\nhttps://github.com/bcoe/c8/issues/116#issuecomment-503039423\r\n\r\n\r\n**Describe alternatives you've considered**\r\nThe two points above\r\n",
        "labels": "feature request",
        "id": 43165
    },
    {
        "title": "Make it possible to give externals names/util.inspect.custom",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nIn hyperdivision/hid we use externals as handles for device opaque descriptors, however during debugging it's hard to know what exactly you are working with. I want to preserve the opaqueness of the handles, but it would be nice if I could give these externals a name.\r\n\r\n**Describe the solution you'd like**\r\n\r\nCurrently externals end up here in `util.inspect`: https://github.com/nodejs/node/blob/2b8b23067d4211014dd192e6ef774178725c9209/lib/internal/util/inspect.js#L748\r\n\r\nI don't know if this should be another API in N-API, the possibility of setting `util.inspect.custom` or similar.\r\n\r\n**Describe alternatives you've considered**\r\n\r\n`object_wrap` is another alternative, but comes with much more features and boilerplate than I need. I just want to be able to give human readable names to opaque references for debugging.\r\n",
        "labels": "feature request",
        "id": 43166
    },
    {
        "title": "Fix node.js terminal input functionality",
        "body": "Node.js is a multipurpose programming language used everywhere and for everything.\r\n\r\nBut I always felt there was something broken about its terminal input functionality.\r\n\r\nthe easiest way to program is in a imperative manner (A.K.A without any callback hell or async/await).\r\n\r\nit's very easy to print a value to the terminal, you just have to call console.log.\r\n```\r\nconsole.log(\"very easy to use and to remember it\");\r\n```\r\nbut why can't it be the same way for the input functionality?\r\nWhy Do I have to google every single time for a way to get a  input value from the terminal?\r\nWhy do I have to import a module like `readline-sync` for a simple functionality that most programming languages have easily implemented. \r\nWhy can't it be something like pythons's raw_input/input function?\r\n\r\neven in the browser, we have something like this:\r\n```\r\nvar result = prompt(\"Input something: \");\r\n```\r\nWhy can't we have the same thing for the terminal?\r\nIt's easy to remember and I don't have import any external library.\r\n\r\nI'm sorry if this was already discussed. But I was just trying to code something right now, and I just realise node.js's terminal input functionality is too hard to remember and it seems everyone is ok with that.\r\n\r\nBut I'm lazy. Programming languages should improve programmers' lives and not make their lives even harder.",
        "labels": "feature request",
        "id": 43167
    },
    {
        "title": "N-API should allow setting the 'length' property of functions",
        "body": "Currently, `napi_create_function()` and `napi_define_class()` only accept name, native callback, and an opaque data pointer. https://github.com/nodejs/node/blob/c1f0cbe961658b02ae51fe35bfe2d323d49ece34/src/js_native_api.h#L87-L92 https://github.com/nodejs/node/blob/c1f0cbe961658b02ae51fe35bfe2d323d49ece34/src/js_native_api.h#L269-L277\r\nIn particular, it does not accept a parameter for the `length` property for JavaScript functions.\r\n\r\n```js\r\n((a, b, ...c) => {}).length\r\n// 2\r\n```\r\n\r\nWhile it's possible to redefine the `length` property after the function/class has been created, doing so could be slow and error-prone. It would be nice if N-API could directly support this use case.",
        "labels": "feature request",
        "id": 43168
    },
    {
        "title": "N-API: Expose v8::Object::GetIdentityHash",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nA solution suggested for #28164 was to keep a big table of JS objects and their types, and use that to verify the type of a wrapper object before `napi_unwrap`ping it. Currently, the only way to do this is to `napi_strict_equals` against every single object reference in the table, which is very slow if there are a lot of objects to keep track of.\r\n\r\n**Describe the solution you'd like**\r\nPlease expose `v8::Object::GetIdentityHash` through N-API. This will make it possible to maintain a hash table of JS object references.\r\n\r\n**Describe alternatives you've considered**\r\nSee #28164.",
        "labels": "feature request",
        "id": 43169
    },
    {
        "title": "N-API: Type safety for napi_get_value_external/napi_unwrap",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n`napi_get_value_external` is currently type-unsafe. It yields 32 or 64 arbitrary bits, with no guarantee as to whether they mean what the caller thinks they mean, nor which native module created the external. Even assuming that it's a pointer is unsafe and may result in segfault.\r\n\r\n**Describe the solution you'd like**\r\nPlease add a way to attach type information to values created by `napi_create_external`, and a way to check that type information when calling `napi_get_value_external`. The â€œtype informationâ€ should be some sort of unique identifier generated by Node.js with an opaque C type, so that no two native modules can ever accidentally use the same type identifier for different types of external values.\r\n\r\nSuggested API:\r\n\r\n```c\r\n// An opaque identifier.\r\ntypedef struct napi_external_type__* napi_external_type;\r\n\r\n// Creates a new napi_external_type.\r\n// Each call to this function yields a different napi_external_type.\r\nnapi_status napi_create_external_type(\r\n    napi_env env,\r\n    napi_external_type* type\r\n);\r\n\r\n// Like napi_create_external, but takes a napi_external_type parameter.\r\n// Attaches it to the created napi_value.\r\nnapi_status napi_create_typed_external(\r\n    napi_env env,\r\n    void* data,\r\n    napi_finalize finalize_cb,\r\n    void* finalize_hint,\r\n    napi_external_type type,\r\n    napi_value* result\r\n);\r\n\r\n// Like napi_get_value_external, but takes a napi_external_type parameter.\r\n// Throws TypeError if the given napi_value has a different (or no) napi_external_type.\r\nnapi_status napi_get_value_typed_external(\r\n    napi_env env,\r\n    napi_value value,\r\n    napi_external_type type,\r\n    void** result\r\n);\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nCurrently, I'm just assuming that `napi_get_value_external` gives me a pointer to something that's at least `sizeof(void *)` bytes long, and put a magic number at the beginning of the external data structure to identify its type. To make the magic number distinctive, it is a pointer to some data inside my module:\r\n\r\n```c\r\nstatic const void *MAGIC = &MAGIC;\r\n\r\ntypedef struct {\r\n    void *magic; // check if magic == MAGIC before use\r\n    â€¦\r\n} my_data;\r\n\r\nâ€¦\r\n\r\nmy_data *d;\r\nnapi_get_value_external(â€¦, â€¦, &d);\r\nif (d->magic != MAGIC) {\r\n    // bail\r\n}\r\n```\r\n\r\nAs I've said above, this will result in undefined behavior (probably segfault) if some other native module calls `napi_create_external` with a value that isn't a valid pointer, and that external value somehow gets fed to my native module. Nor is it actually guaranteed that my magic number won't happen to be at the beginning of some other module's unrelated data structure, though it is highly unlikely.",
        "labels": "feature request",
        "id": 43170
    },
    {
        "title": "intl: configure default locale",
        "body": "Right now Node.js (by omission) leaves it up to ICU to figure out the locale and configure itself accordingly.\r\n\r\nThat's problematic for a number of reasons, see e.g. https://github.com/nodejs/node/issues/27856#issuecomment-499449890 - tl;dr environment variables affect the output of `Date#toString()`. Googling for variations of 'nodejs lc_all' suggests the issue pops up more often.\r\n\r\nSince one of Node.js's goals is to provide a consistent experience across platforms and environments, I think it would be good to explicitly configure the locale at startup instead of leaving it to happenstance.\r\n\r\nThere are two ways to accomplish that and they're not mutually exclusive:\r\n\r\n1. `setenv(\"LC_ALL\", \"...\"); setenv(\"LC_MESSAGES\", \"...\"); // etc.`\r\n2. `icu::Locale::setDefault(...)`\r\n\r\nI'm adding the semver-major label because there is some risk of breaking existing applications. (Libraries not so much since the average library already runs in a  variety of environments.)\r\n\r\nIt would be good to have some discussion on the merits of both (and alternative?) approaches.",
        "labels": "feature request",
        "id": 43171
    },
    {
        "title": "Expose and write headers on 1xx intermediate status codes",
        "body": "Background: I'm currently working on a document for standardizing how servers may communicate intermediate status of a long-running operation over HTTP (operations running minutes to days). Part of this involves use of 1xx status codes, available in HTTP/1.1 and HTTP/2.\r\n\r\nHTTP specifies that a request may have multiple 1xx responses before a final 2xx-5xx response. These responses, like any other, may have headers:`101 Switching Protocols`, `102 Processing`, and `103 Early Hints` are all known to use headers to convey additional information about the intermediate status. (For example, 101 uses [Upgrade](https://httpwg.org/specs/rfc7230.html#header.upgrade), 102 uses [Status-URI](https://tools.ietf.org/html/rfc2518#section-10.1), and 103 uses [Link](https://httpwg.org/specs/rfc8297.html)).\r\n\r\nThere is currently seemingly no way to write or read these headers. Given the definition of 1xx (which is mandatory in HTTP/1.1 and HTTP/2), I would expect to be able to call `ServerResponse#writeHead` multiple times with a 1xx status code, however, this does not flush the headers to the response, and appears to cause an error to be thrown once the final headers are written! Node.js added `ServerResponse#writeProcessing` in v10.0.0, however, this is specific to a single status code, does not support headers, and is not forward compatible with future status codes.\r\n\r\nI would also expect the `ClientRequest#on(\"information\")` event to include a headers object, so I can read this data.\r\n\r\nThe only known workarounds are to use `ServerResponse#_writeRaw` which is not a public API; and the only available option for clients is to parse responses manually.\r\n\r\n---\r\n\r\nHere is a script demonstrating the expected behavior:\r\n\r\n```javascript\r\n\r\nconst http = require('http');\r\nconst server = http.createServer(handleRequest);\r\nserver.listen(0);\r\nconsole.error('Listening on port '+server.address().port);\r\n\r\nfunction handleRequest(req, res){\r\n    var tasks = [\r\n        'Herding cats',\r\n        'Digging holes',\r\n        'Filling in holes',\r\n        'Making tea',\r\n    ];\r\n    function writeProgress(i){\r\n        console.error('writeProgress('+i+')');\r\n        if(false){\r\n            res.writeHead(102, 'Processing', {\r\n                'Progress': `${i}/${tasks.length} (${tasks[i]})`,\r\n            });\r\n        }else{\r\n            res._writeRaw('HTTP/1.1 102 Processing\\r\\n');\r\n            res._writeRaw('Progress: '+i+'/'+tasks.length+' ('+tasks[i]+')\\r\\n');\r\n            res._writeRaw('\\r\\n');\r\n        }\r\n    }\r\n    function next(){\r\n        if(++i===tasks.length){\r\n            res.setHeader('Content-Type', 'text/plain');\r\n            res.end('All done!\\r\\n');\r\n        }else{\r\n            writeProgress(i);\r\n            setTimeout(next, 100);\r\n        }\r\n    }\r\n    var i = 0;\r\n    writeProgress(i);\r\n    setTimeout(next, 100);\r\n}\r\n\r\nvar req = http.request({\r\n    host: server.address().address,\r\n    port: server.address().port,\r\n    path: '/',\r\n});\r\nreq.end();\r\nreq.on('information', function(res){\r\n    console.log(res);\r\n});\r\nreq.on('response', function(res){\r\n    res.pipe(process.stdout);\r\n    res.on('end', console.error);\r\n});\r\n\r\n```\r\n\r\nWhen `_writeRaw` is used, the Node.js client sees only the `statusCode`:\r\n\r\n```\r\n$ node -v\r\nv12.1.0\r\n$ node demo.js \r\nListening on port 49213\r\nwriteProgress(0)\r\n{ statusCode: 102 }\r\nwriteProgress(1)\r\n{ statusCode: 102 }\r\nwriteProgress(2)\r\n{ statusCode: 102 }\r\nwriteProgress(3)\r\n{ statusCode: 102 }\r\nAll done!\r\n```\r\n\r\nWhen `_writeRaw` is used, `curl` is able to parse the response as expected:\r\n\r\n```\r\n$ curl -v http://localhost:49213/\r\n*   Trying ::1...\r\n* TCP_NODELAY set\r\n* Connected to localhost (::1) port 49213 (#0)\r\n> GET / HTTP/1.1\r\n> Host: localhost:49213\r\n> User-Agent: curl/7.54.0\r\n> Accept: */*\r\n> \r\n< HTTP/1.1 102 Processing\r\n< Progress: 0/4 (Herding cats)\r\n< HTTP/1.1 102 Processing\r\n< Progress: 1/4 (Digging holes)\r\n< HTTP/1.1 102 Processing\r\n< Progress: 2/4 (Filling in holes)\r\n< HTTP/1.1 102 Processing\r\n< Progress: 3/4 (Making tea)\r\n< HTTP/1.1 200 OK\r\n< Content-Type: text/plain\r\n< Date: Sun, 26 May 2019 21:02:58 GMT\r\n< Connection: keep-alive\r\n< Content-Length: 11\r\n< \r\nAll done!\r\n* Connection #0 to host localhost left intact\r\n```\r\n\r\nHowever, when `writeHead` is used, the data never makes it out of the socket, and an error is emitted towards the end:\r\n\r\n```\r\n$ node -v\r\nv12.1.0\r\n$ node demo.js \r\nListening on port 49224\r\nwriteProgress(0)\r\nwriteProgress(1)\r\nwriteProgress(2)\r\nwriteProgress(3)\r\n_http_outgoing.js:467\r\n    throw new ERR_HTTP_HEADERS_SENT('set');\r\n    ^\r\n\r\nError [ERR_HTTP_HEADERS_SENT]: Cannot set headers after they are sent to the client\r\n    at ServerResponse.setHeader (_http_outgoing.js:467:11)\r\n    at Timeout.next [as _onTimeout] (.../demo.js:28:17)\r\n    at listOnTimeout (internal/timers.js:531:17)\r\n    at processTimers (internal/timers.js:475:7)\r\n\r\n$ curl -v http://localhost:49226/\r\n*   Trying ::1...\r\n* TCP_NODELAY set\r\n* Connected to localhost (::1) port 49226 (#0)\r\n> GET / HTTP/1.1\r\n> Host: localhost:49226\r\n> User-Agent: curl/7.54.0\r\n> Accept: */*\r\n> \r\n* Empty reply from server\r\n* Connection #0 to host localhost left intact\r\ncurl: (52) Empty reply from server\r\n```\r\n\r\n---\r\n\r\nIn summary:\r\n\r\n* `ClientRequest#on(\"information\")` should expose a res-like object with headers, and\r\n* `ServerResponse#writeHead` should allow multiple calls with a 1xx status code that is immediately flushed to the socket.",
        "labels": "feature request",
        "id": 43172
    },
    {
        "title": "Feature Request: can continuous call readline.question ",
        "body": "Currently, implement a continuous q&a `rl` might look something like this:\r\n\r\n```\r\nrl.question('What do you think of Node.js?  ', (answer1) => {\r\n    rl.question('What do you think of readline? ', (answer2) => {\r\n        // ...\r\n        rl.close();\r\n    });\r\n});\r\n```\r\nFor interactive types of programs, this can be unfriendly to error handling and readability.\r\n\r\nThen I propose one of the following:\r\n\r\n  * readline.question support to registers a set of consecutive events.\r\n  * add promise type question(almost?). \r\n\r\nCompare:\r\n\r\n```\r\nrl\r\n  .question('What do you think of Node.js? ', answer => {\r\n    \r\n})\r\n  .question('What do you think of readline? ', answer => {\r\n\r\n});\r\n```\r\n\r\nand\r\n\r\n```\r\nrl\r\n  .question('What do you think of Node.js? ', answer => {\r\n    \r\n})\r\n  .then(() => {})\r\n  .error(() => {})\r\n```",
        "labels": "feature request",
        "id": 43173
    },
    {
        "title": "[Feature request] Add node-report to cdp and add Visual Panel like React or Vue",
        "body": "I found node-report is very usefully (tbh I am a little surprised that Node.js has this level of clarity, really amazing job ðŸ‘ ), in some cases more usefully than profiler :)\r\nI would like two thing:\r\n* Introduce it to CDP panel\r\nkind of like this (pic from https://github.com/vuejs/vue-devtools), but for `node-report`\r\n<p align=\"center\"><img width=\"720px\" src=\"https://raw.githubusercontent.com/vuejs/vue-devtools/dev/media/screenshot-shadow.png\" alt=\"screenshot\"></p>\r\n\r\n* Add it to CDP protocal\r\nkind of like https://chromedevtools.github.io/devtools-protocol/tot/SystemInfo, but we add it only in Node domain https://chromedevtools.github.io/devtools-protocol/v8.\r\n\r\ncc @nodejs/inspector @nodejs/report @richardlau \r\n(Not sure I ping the group right, I don't know the Node.js group category )",
        "labels": "feature request",
        "id": 43174
    },
    {
        "title": "Expose acorn parser/plugins in API",
        "body": "**acorn** is one of the most used and fastest JavaScript parser, which is used in many popular projects (e.g. rollup). It is also used internally in Node.js. I think the time has come to expose acorn in Node.js API, which would allow using it out of the box without installing another package.",
        "labels": "feature request",
        "id": 43175
    },
    {
        "title": "`recursive` option for `fs.rmdir`",
        "body": "[fs.mkdir](https://nodejs.org/api/fs.html#fs_fs_mkdir_path_options_callback) gained a `recursive` option in 10.12 (providing alternative to the [`mkdirp`](https://www.npmjs.com/package/mkdirp) module) and I think the popularity of the [`rimraf`](https://www.npmjs.com/package/rimraf) module speaks for itself that there is very high userland to justify having it on `fs.rmdir` and it's variants too.\r\n\r\nExamples of other languages implementing similar functionality are golang's `os.RemoveAll` or python's `shutil.rmtree`.",
        "labels": "feature request",
        "id": 43176
    },
    {
        "title": "Feat: resolver DNS accept qType ALIAS/ ANAME",
        "body": "Based on [RFC](https://tools.ietf.org/html/draft-ietf-dnsop-aname-01) today this `draft`, I guess interesting to give us support in a resolver recursive to query types `ALIAS/ ANAME`.\r\nI did see how lib DNS works, below show reference of the files to possible changes.\r\n\r\n- variable: `ns_t_cname`\r\n    - deps/cares/include/nameser.h\r\n    - src/cares_wrap.cc\r\n\r\n- variable: `T_CNAME`\r\n    - deps/cares/include/nameser.h\r\n    - deps/cares/src/ares_parse_a_reply.c\r\n    - deps/cares/src/ares_parse_aaaa_reply.c\r\n    - deps/cares/src/ares_parse_ptr_reply.c\r\n\r\nAlso, we can need a change in this file `https://github.com/nodejs/node/blob/master/lib/dns.js` \r\n\r\n\r\nsee ya",
        "labels": "feature request",
        "id": 43177
    },
    {
        "title": "Better logging",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nReading logs and stack traces can be difficult.\r\n\r\n**Describe the solution you'd like**\r\nMore readable logs.\r\n\r\n**Describe alternatives you've considered**\r\n[log-process-errors](https://npmjs.com/log-process-errors)",
        "labels": "feature request",
        "id": 43178
    },
    {
        "title": "Servername is not set on TLS sockets if there is a TLS client error",
        "body": "* **Version**: v10.15.3\r\n* **Platform**: Linux\r\n* **Subsystem**: TLS\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nI am writing an HTTPS server and I want to try & detect when clients connect but reject my certificate. For irrelevant reasons this happens often.\r\n\r\nIf this happens, it typically triggers a `tlsClientError` event. When that happens, even though the servername has been received and SNICallback has been called successfully, the `servername` field is still not set on the TLS socket provided with the event. For successful connections however (i.e. `secureConnection`), it is always available.\r\n\r\nThis is because it's only set on the socket in `_finishInit`, which is only gets called after a successful handshake has been completed:\r\n\r\nhttps://github.com/nodejs/node/blob/495822f544a34feadc8d8c19e674f0b00eefefd6/lib/_tls_wrap.js#L735-L747\r\n\r\nIt'd be very useful if this field was set earlier, as soon as the server name has been received, to provide extra context to TLS errors like these.",
        "labels": "feature request",
        "id": 43179
    },
    {
        "title": "Expose a way to specify TLS version by node command line",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nYes, we want to be TLS1.2 compliant. Checking the whole repository to make the whole code TLS1.2 complaint. We liked the existing idea of specifying cipher suit at \"node --tls-cipher-list=\"ECDHE-RSA-AES128-SHA\" server.js\". We need similar command to specify TLS version. \r\n\r\n**Describe the solution you'd like**\r\nTo specify the TLS version at node commandline. Similar to \"node --tls-cipher-list=\"ECDHE-RSA-AES128-SHA\" server.js\"\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n",
        "labels": "feature request",
        "id": 43180
    },
    {
        "title": "Add `timeout` and `killSignal` options to `child_process` `spawn()` and `fork()`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThe `timeout` and `killSignal` options are available in `execFile[Sync]()`, `exec[Sync]()`, `spawnSync()` but not in `spawn()` nor `fork()`. \r\n\r\nThose methods could be useful for `spawn()` and `fork()` too. For example, projects like [`execa`](https://github.com/sindresorhus/execa) (by @sindresorhus) use userland code to bring those options to `spawn()`. \r\n\r\n**Describe the solution you'd like**\r\nAdd those options to `spawn()` and `fork()`.",
        "labels": "feature request",
        "id": 43181
    },
    {
        "title": "async_hooks: context loss when awaiting a thenable",
        "body": "It seems `async_hooks` is losing context, in certain cases, when awaiting a thenable. This appears to occur in all major versions of Node.js with `async_hooks` available. See the code example and output for reference.\r\n\r\nWithin the `then` function on the thenable object, the trigger id is 0. Note that this _does not_ happen when awaiting a thenable as the first await within an async function.\r\n\r\ncc @nodejs/diagnostics \r\n\r\n<details>\r\n<summary>Code example</summary>\r\n\r\n```js\r\nconst async_hooks = require('async_hooks')\r\n\r\nconst asyncHook = async_hooks.createHook({\r\n  init (asyncId, type, triggerAsyncId) {\r\n    log({\r\n      event: 'init',\r\n      asyncId,\r\n      type,\r\n      triggerAsyncId\r\n    })\r\n  },\r\n\r\n  before (asyncId) {\r\n    log({\r\n      event: 'before',\r\n      asyncId\r\n    })\r\n  },\r\n\r\n  after (asyncId) {\r\n    log({\r\n      event: 'after',\r\n      asyncId\r\n    })\r\n  }\r\n})\r\nasyncHook.enable()\r\n\r\nfunction log (data) {\r\n  process._rawDebug(JSON.stringify(data))\r\n}\r\n\r\nfunction tick () {\r\n  return new Promise(setImmediate)\r\n}\r\n\r\nasync function main () {\r\n  await tick()\r\n  await {\r\n    then (fn) {\r\n      log({\r\n        executionAsyncId: async_hooks.executionAsyncId(),\r\n        triggerAsyncId: async_hooks.triggerAsyncId(),\r\n        message: 'these ids should not be zero'\r\n      })\r\n      setImmediate(fn)\r\n    }\r\n  }\r\n}\r\n\r\nmain()\r\n```\r\n\r\n</details>\r\n\r\n<details>\r\n<summary>Output</summary>\r\n\r\n    {\"event\":\"init\",\"asyncId\":2,\"type\":\"PROMISE\",\"triggerAsyncId\":1}\r\n    {\"event\":\"init\",\"asyncId\":3,\"type\":\"PROMISE\",\"triggerAsyncId\":1}\r\n    {\"event\":\"init\",\"asyncId\":4,\"type\":\"Immediate\",\"triggerAsyncId\":1}\r\n    {\"event\":\"init\",\"asyncId\":5,\"type\":\"PROMISE\",\"triggerAsyncId\":3}\r\n    {\"event\":\"before\",\"asyncId\":4}\r\n    {\"event\":\"after\",\"asyncId\":4}\r\n    {\"event\":\"before\",\"asyncId\":5}\r\n    {\"event\":\"init\",\"asyncId\":6,\"type\":\"PROMISE\",\"triggerAsyncId\":2}\r\n    {\"event\":\"init\",\"asyncId\":7,\"type\":\"PROMISE\",\"triggerAsyncId\":6}\r\n    {\"event\":\"after\",\"asyncId\":5}\r\n    {\"executionAsyncId\":0,\"triggerAsyncId\":0,\"message\":\"these ids should not be zero\"}\r\n    {\"event\":\"init\",\"asyncId\":8,\"type\":\"Immediate\",\"triggerAsyncId\":0}\r\n    {\"event\":\"before\",\"asyncId\":8}\r\n    {\"event\":\"after\",\"asyncId\":8}\r\n    {\"event\":\"before\",\"asyncId\":7}\r\n    {\"event\":\"after\",\"asyncId\":7}\r\n\r\n</details>",
        "labels": "feature request",
        "id": 43182
    },
    {
        "title": "Create heapdump on out of memory",
        "body": "**Introduction**\r\nThis issue is a followup of https://github.com/nodejs/node/issues/23328. The outcome of that issue was the introduction of the `v8.writeHeapSnapshot()` API.\r\n\r\nNext step would be to introduce a way of handling an out of memory situation in JS context. \r\nWhen running nodejs processes in a low memory environment, every out of memory that occurs is interesting. To figure out why a process went out of memory, a heapdump can help a lot. \r\n\r\n**Desired solution**\r\nThere are several possible solutions which would suffice:\r\n- introduce an event like `process.on('fatal_error')`, which kicks in for an OoM event. (see https://github.com/nodejs/diagnostics/issues/239#issuecomment-427600405). The question is if it's feasible to execute JS code after the 'fatal_error' occurred?  \r\n- add a CLI flag which enables automatic heapdumps on OoM. This might be more feasible, as it doesn't need to be a JS API and thus can be fixed in native code instead of JS. Downside is that it's not flexible.\r\n- ...\r\n\r\n**Alternatives**\r\nAt the moment, we use our own [module](https://github.com/blueconic/node-oom-heapdump). This uses native code to hook into the `SetOOMErrorHandler` handler of V8.\r\nThis works although it's not very elegant. \r\n",
        "labels": "feature request",
        "id": 43183
    },
    {
        "title": "Better assertion message for C++ binding argument checks",
        "body": "Refs: https://github.com/nodejs/node/issues/20325\r\n\r\nAt the moment we simply use something like\r\n\r\n```\r\nCHECK(args[1]->IsString());\r\n```\r\n\r\nfor guarding against incorrect usage of the C++ bindings, which produces a message that looks like this:\r\n\r\n```\r\n../src/node_contextify.cc:631:static void node::contextify::ContextifyScript::New(const FunctionCallbackInfo<v8::Value> &): Assertion `args[1]->IsString()' failed.\r\n```\r\n\r\nThis is not exactly useful for users who don't know much about our internals. A better message would be something like this (ideally we could phrase it better but that would mean more C++ logic):\r\n\r\n```\r\n2nd argument passed to `process.binding('contextify').ContextifyScript` is not a String.\r\n\r\n(DEP0111): process.binding() is deprecated.\r\nYou are likely using code that accesses Node.js internals incorrectly.\r\n\r\n<JS stack>\r\n\r\n<C++ stack>\r\n```\r\n\r\nWhich could be generated with a macro like this (or we could pass the `2nd` bit if we don't want to write a formatter in C++):\r\n\r\n```\r\nCHECK_BINDING_ARG(args, 1, String, contextify, ContextifyScript);\r\n```\r\n\r\nWe could also use `UNLIKELY()` when implementing the macro for compiler hints.\r\n",
        "labels": "feature request",
        "id": 43184
    },
    {
        "title": "Please support loading node_modules from an archive",
        "body": "`node_modules` is the folder where Node typically picks up libraries for a runtime/application. Often, the number of files being distributed with a stock Node.js distribution is insane and very slow to load with random I/O on some flash/external memories. Assuming that one has a decent amount of RAM, it must be able to partially extract an archive to RAM and load the relevant JS files on demand. I would like this support for the stock distribution as well.\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI have troubles loading some node projects from a slower SD card on R Pi; Buying a faster disk with a better queue is not an option, because I can buy one for myself, not for the many users out there.\r\n\r\n**Describe the solution you'd like**\r\nPlease allow node to alternatively use a node_modules.zip, as a start?.\r\n\r\n**Describe alternatives you've considered**\r\n- Delete many .JS files in node_modules/lib\r\n- Write a bin2cpp based v8 eval (increases RAM usage if many modules unused)\r\n- Accept fate",
        "labels": "feature request",
        "id": 43185
    },
    {
        "title": "`childProcess.killed` should be `true` after `process.kill(childProcess.pid)` is called",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n`childProcess.killed` is inconsistent depending on how the child process was killed:\r\n\r\n```js\r\nconst { spawn } = require('child_process')\r\nconst childProcess = spawn('sleep', [5e6])\r\nchildProcess.kill()\r\nconsole.log(childProcess.killed) // true\r\n```\r\n\r\n```js\r\nconst { spawn } = require('child_process')\r\nconst childProcess = spawn('sleep', [5e6])\r\nprocess.kill(childProcess.pid)\r\nconsole.log(childProcess.killed) // false\r\n```\r\n\r\n**Describe the solution you'd like**\r\n`killed` should be `true` when the process is killed through an external process (`process.kill()` or `kill` in the terminal).\r\n\r\n**Versions**\r\n\r\nNode `12.1.0`, Ubuntu `19.04`.",
        "labels": "feature request",
        "id": 43186
    },
    {
        "title": "modify the runtime stack size.",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI hope I can modify the runtime stack size.\r\n\r\n**Describe the solution you'd like**\r\nno,sorry.\r\n\r\n**Describe alternatives you've considered**\r\nno,sorry.\r\n\r\nbecause --stack-size does not work now,I hope I can modify the runtime stack size.\r\n",
        "labels": "feature request",
        "id": 43187
    },
    {
        "title": "Make it possible to forcibly RST a net.Socket",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI'd like to forcibly reset a socket. Primarily for testing - I'm seeing unexpected RST packets in production, which is crashing my node HTTP proxy (my bug, that's fine), and I'd like to be able to write automated tests to ensure I've fixed correctly.\r\n\r\nAs far as I can tell it's only possible to cleanly close sockets with FIN, you can never intentionally RST.\r\n\r\n**Describe the solution you'd like**\r\n\r\nSomething like `socket.reset()` would be great for my specific case, or alternatively low-level controls (e.g. the ability to set socket options as in the Python code below) would be equally useful.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nFor now, I've implemented this in Python instead. This Python 2.7.1 code is working for me:\r\n\r\n```python\r\nimport socket\r\nimport time\r\nimport struct\r\n\r\nTCP_IP = '127.0.0.1'\r\nTCP_PORT = 8000\r\n\r\n# Connect to the server\r\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)\r\ns.connect((TCP_IP, TCP_PORT))\r\n\r\n# Start an HTTP request\r\ns.send(\"CONNECT example.com:80 HTTP/1.1\\r\\n\\\r\nHost: example.com\\r\\n\\\r\n\\r\\n\\\r\nGET / HTTP/1.1\\r\\n\\\r\nHost: example.com\\r\\n\\\r\n\")\r\ntime.sleep(0.1)\r\n\r\n# RST the socket without reading the response\r\ns.setsockopt(socket.SOL_SOCKET, socket.SO_LINGER, struct.pack('ii', 1, 0))\r\ns.close()\r\n```\r\n\r\nObviously I'd much prefer to test my Node server with JavaScript though, instead of having to bring in another language.",
        "labels": "feature request",
        "id": 43188
    },
    {
        "title": "Odd behaviour: `createRequireFromPath('.')`",
        "body": "* **Version**: v12.0.0\r\n* **Platform**: macOS 10.14.4\r\n* **Subsystem**: module\r\n\r\nCalling `createRequireFromPath('.')` does not honour `process.cwd()` when called a second time after an effective call to `process.chdir(â€¦)`.\r\n\r\nBest explained by this: https://github.com/SMotaal/esm/blob/master/tests/create-require.mjs#L8\r\n\r\n<details>\r\n\r\n\r\n```js\r\nimport {createRequireFromPath} from 'module';\r\nimport {fileURLToPath} from 'url';\r\n\r\nconst specifier = './package.json';\r\nconst [scope, ...paths] = ['../../', '../', './'].map(path => fileURLToPath(new URL(path, import.meta.url)));\r\nconst sanitize = path => path.replace(scope, 'â€¹scopeâ€º/');\r\n\r\nfor (const path of process.argv.includes('-t2') ? paths.reverse() : paths) {\r\n  process.chdir(path);\r\n  console.group('\\nprocess.chdir(%o)', sanitize(process.cwd()));\r\n  console.log();\r\n  try {\r\n    const require = createRequireFromPath('.');\r\n    console.log(\r\n      `createRequireFromPath(%o)\\n  .resolve(%o)\\n    => %o`,\r\n      '.',\r\n      specifier,\r\n      sanitize(require.resolve(specifier)),\r\n    );\r\n  } catch (exception) {\r\n    console.warn(\r\n      `createRequireFromPath(%o)\\n  .resolve(%o)\\n    => %o`,\r\n      '.',\r\n      specifier,\r\n      `${exception}`.split('\\n', 1)[0],\r\n    );\r\n  }\r\n  console.log();\r\n  console.groupEnd();\r\n}\r\n\r\n/*******************************************************************************\r\n * $ node --experimental-modules esm/tests/create-require.mjs\r\n *\r\n *   process.chdir('â€¹scopeâ€º/esm/')\r\n *\r\n *     createRequireFromPath('.')\r\n *       .resolve('./package.json')\r\n *         => 'â€¹scopeâ€º/esm/package.json'\r\n *\r\n *   process.chdir('â€¹scopeâ€º/esm/tests/')\r\n *\r\n *     createRequireFromPath('.')\r\n *       .resolve('./package.json')\r\n *         => 'â€¹scopeâ€º/esm/package.json'\r\n *\r\n ******************************************************************************\r\n * $ node --experimental-modules esm/tests/create-require.mjs -t2\r\n *\r\n *   process.chdir('â€¹scopeâ€º/esm/tests/')\r\n *\r\n *     createRequireFromPath('.')\r\n *       .resolve('./package.json')\r\n *         => 'â€¹scopeâ€º/esm/tests/package.json'\r\n *\r\n *   process.chdir('â€¹scopeâ€º/esm/')\r\n *\r\n *     createRequireFromPath('.')\r\n *       .resolve('./package.json')\r\n *         => 'â€¹scopeâ€º/esm/tests/package.json'\r\n *\r\n ******************************************************************************/\r\n```\r\n\r\n</details>",
        "labels": "feature request",
        "id": 43189
    },
    {
        "title": "A flag for disabling specific warnings",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nAfter recent update I've started getting \"ExperimentalWarning: queueMicrotask() is experimental.\" because of some of my dependencies (I don't even know which one and I don't have a clear way how to find it out).\r\nThis specific warning is useless to me since I can't/don't want to remove my dependencies. There are lots of discussion if this \"queueMicrotask()\" should/should not/will be at some time made not experimental.\r\nI'm perfectly fine that it's experimental or not. I want just to acknowledge this one specific warning and don't look at it anymore.\r\nI use \"--trace-warnings\" when testing so this and I need that flag, but, because of it \"ExperimentalWarning: queueMicrotask()\" is also followed by it's stack and thats really annoying.\r\n\r\n**Describe the solution you'd like**\r\nI'd like to have a command-line flag or a config file for node.js which allows disabling any warning by exact match or a regexp any would fit.\r\n\r\n**Describe alternatives you've considered**\r\n- I can interact with libraries support and they would probably argue that at some point of time this \"ExperimentalWarning: queueMicrotask()\" would not be experimental.\r\n\r\nHowever, even after I wait for it, the progress would never stop. There will always be something new, experimental. And if you have \"node_modules\" with 100+ dependencies you'll likely catch this.\r\nFor now I see no way to disable \"just this specific warning\".\r\n",
        "labels": "feature request",
        "id": 43190
    },
    {
        "title": "REPL: add wildcard to autocompletion",
        "body": "In most terminals it's possible to use an asterix (`*`) to indicate a wildcard search (as filter).\r\n\r\nIt would be great to add something like this to our REPL as well, e.g., using the current autocompletion with `util.types.is*F` results in the globals that start with an `F`. Instead, it would be great to print all `is` functions that start with `is` and that have an `F` somewhere in their name.\r\n\r\nUsing the asterix at the end should print everything as if it's not there (it currently prints nothing).",
        "labels": "feature request",
        "id": 43191
    },
    {
        "title": "Proposal: PR links in documentation history",
        "body": "Currently the docs have a one-line `Added in` section or a collapsible `History` section to communicate a per-feature changelog of sorts. My suggestion is to augment that data with the addition of PR links so a user can view the code history of that feature if they feel they need a deeper understanding of the interface than the docs alone can provide.\r\n\r\nThis could also be a good source of tasks for future Code & Learn events too, going back through the history and filling in the links for past changes. ðŸ¤” ",
        "labels": "feature request",
        "id": 43192
    },
    {
        "title": "Cross-platform path.compare()",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI recently came across an issue where comparing two paths (as strings) contained incorrect logic due to differences between case-sensitivity on Linux vs Windows. I assumed there would be a `path.compare(a,b)` API which would automatically take this into account, but there doesn't seem to be anything, so the solution needed to be manually coded.\r\n\r\nIf you perform a case-sensitive comparison of paths (`path1 === path2`), the logic is incorrect for Windows platforms, but a case-insensitive comparison will be wrong on Mac/Linux.\r\n\r\n**Describe the solution you'd like**\r\n`path.compare(a, b)` where `a` and `b` are strings. The logic would be to perform a simple string comparison, choosing case-sensitivity based on the OS.\r\n\r\n```\r\npath.compare = function (a, b) {\r\n   if (a === b) return 0;\r\n   if (!a) return -1;\r\n   if (!b) return +1;\r\n   const sensitivity = process.platform === 'win32' ? 'base' : 'variant';\r\n   return a.localeCompare(b, 'en', {sensitivity});\r\n}\r\n\r\npath.compare('c:\\\\windows', 'C:\\\\Windows');  // 0 on win32 platforms\r\npath.compare('/Library/node', '/Library/node');  // 0 on all platforms\r\npath.compare('/Library/node', '/Library/node/abc');  // -1 on all platforms\r\npath.compare('/Library/node/abc', '/Library/node');  // +1 on all platforms\r\npath.compare('/Library/node/Abc', '/Library/node/abc');  // 0 on win32, +1 on other platforms\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nThe logic is simple, so perhaps it's not worth adding to the `path` module, but I feel it would be a useful addition and follows a similar API for `Buffer` for example.\r\n",
        "labels": "feature request",
        "id": 43193
    },
    {
        "title": "Resumable hash operations",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nAt present, calculating the hash of a large file needs to be done in one go, in a single process.\r\n\r\nIt would be useful to be able to stop and later resume, perhaps in another process or on another machine entirely.\r\n\r\nThis is particularly useful where the files are large (10GB+).\r\n\r\nUse cases:\r\n\r\n1. Process crashes halfway through hashing a large file. It would be useful to be able to resume from where it left off rather than start again from scratch.\r\n2. Computer 1 has the first half of a file, computer 2 has 2nd half. It would be expensive to transfer the file contents from one computer to the other, so want to hash first half of file on Computer 1 and finish it on Computer 2.\r\n3. Computer 1 is hashing large file. Part way through, Computer 1's resources are required for a higher-priority task. It would be useful to stop the hashing on Computer 1 and allow Computer 2 which is idle to finish it off.\r\n4. Hashing large files on short-lived processes e.g. AWS Lambda, where one invocation cannot complete the entire file.\r\n\r\nAs background, my personal use case is dealing with 100GB+ video files which need to be hashed with SHA1 and MD5. The files are stored in chunks which are distributed across many machines. Many of the machines are geographically distant from each other and connected to each other by slow networks. So transferring the full file to a single machine is slow and expensive.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI imagine an API something like this:\r\n\r\n```js\r\n// Start hash\r\nconst crypto = require('crypto');\r\nconst hash = crypto.createHash('sha1');\r\n\r\nhash.update('data 1');\r\nhash.update('data 2');\r\n\r\n// Get state of hash so far\r\nconst state = hash.getState();\r\nconst json = JSON.stringify(state);\r\n\r\n// Later on, perhaps on another machine entirely...\r\n\r\n// Reinstate hash's state\r\nconst state = JSON.parse(json);\r\nconst hash = crypto.createHash('sha1');\r\nhash.setState(state);\r\n\r\n// Continue hashing\r\nhash.update('data 3');\r\nhash.update('data 4');\r\n\r\n// Get digest\r\nconsole.log(hash.digest('hex'));\r\n```\r\n\r\nI envisage it also working with the streaming interface.\r\n\r\nThe `state` object returned by `.getState()` and passed to `.setState()` would differ depending on the hash algorithm.\r\n\r\nOpenSSL appears to have interfaces to access the internal state of a hash (see `EVP_MD_CTX_copy_ex()` [here](https://www.openssl.org/docs/manmaster/man3/EVP_DigestInit.html)).\r\n\r\nThis also appears to be possible in Python: https://github.com/kislyuk/rehash\r\n\r\n**Describe alternatives you've considered**\r\n\r\nFor some use cases, an alternative would be to hash the file in chunks and store an array of chunk hashes. The integrity of the file can then be determined later by comparing each chunk's hash to what's in the store.\r\n\r\nHowever, in my case, the source of the file provides a hash of the entire file. To ensure the file has been transferred to me without corruption, I need to calculate the hash of the entire file.",
        "labels": "feature request",
        "id": 43194
    },
    {
        "title": "Building Node.js on Visual Studio 2019",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nVisual Studio 2019 just came out and I tried to build node.js with it. I had a look at the supported toolchains and found that the only toolchain supported for Windows is `Visual Studio 2017` - https://github.com/nodejs/node/blob/master/BUILDING.md#windows\r\n\r\nAre there any plans to support building Node.js on Visual Studio 2019?\r\n\r\n**Describe the solution you'd like**\r\nNode.js should build successfully on Visual Studio 2019.\r\n\r\n**Describe alternatives you've considered**\r\nN/A\r\n",
        "labels": "feature request",
        "id": 43195
    },
    {
        "title": "async iterators/generators in stream.pipeline()",
        "body": "Apologies for all the code here.\r\n\r\nWe can consume a `Readable` stream using an async iterator:\r\n\r\n```js\r\n// source: http://2ality.com/2018/04/async-iter-nodejs.html\r\nasync function printAsyncIterable(iterable) {\r\n  for await (const chunk of iterable) {\r\n    console.log('>>> '+chunk);\r\n  }\r\n}\r\n\r\nprintAsyncIterable(fs.createReadStream('my-file.txt', 'utf8'));\r\n```\r\n\r\nAnd we can use async generators similarly to how one would use a `Transform` stream: \r\n\r\n```js\r\n/**\r\n * Parameter: async iterable of chunks (strings)\r\n * Result: async iterable of lines (incl. newlines)\r\n */\r\nasync function* chunksToLines(chunksAsync) {\r\n  let previous = '';\r\n  for await (const chunk of chunksAsync) {\r\n    previous += chunk;\r\n    let eolIndex;\r\n    while ((eolIndex = previous.indexOf('\\n')) >= 0) {\r\n      // line includes the EOL\r\n      const line = previous.slice(0, eolIndex+1);\r\n      yield line;\r\n      previous = previous.slice(eolIndex+1);\r\n    }\r\n  }\r\n  if (previous.length > 0) {\r\n    yield previous;\r\n  }\r\n}\r\n\r\n/**\r\n * Parameter: async iterable of lines\r\n * Result: async iterable of numbered lines\r\n */\r\nasync function* numberLines(linesAsync) {\r\n  let counter = 1;\r\n  for await (const line of linesAsync) {\r\n    yield counter + ': ' + line;\r\n    counter++;\r\n  }\r\n}\r\n```\r\n\r\nThen, we can \"pipe\" these together like so:\r\n\r\n```js\r\nasync function main() {\r\n  printAsyncIterable(\r\n    numberLines(\r\n      chunksToLines(\r\n        fs.createReadStream('my-file.txt', 'utf8')\r\n      )\r\n    )\r\n  );\r\n}\r\nmain();\r\n```\r\n\r\nThat's neat, but also kind of hideous.  What if we could leverage `stream.pipeline()` to do something like this?\r\n\r\n```js\r\nasync function main() {\r\n  stream.pipeline(\r\n    fs.createReadStream('my-file.txt', 'utf8'),\r\n    chunksToLines,\r\n    numberLines,\r\n    printAsyncIterable\r\n  );\r\n}\r\nmain();\r\n```\r\n\r\nI'm unfamiliar with the guts of `stream.pipeline()`--and completely new to async iterators and generators--so don't know how feasible something like this is.\r\n\r\nFWIW, the \"hideous nested function calls\" can be naively replaced by use of the godlike `Array.prototype.reduce()`:\r\n\r\n```js\r\nconst pipeline = async (...args) => args.reduce((acc, arg) => arg(acc));\r\n\r\nasync function main() {\r\n  pipeline(\r\n    fs.createReadStream('my-file.txt', 'utf8'),\r\n    chunksToLines,\r\n    numberLines,\r\n    printAsyncIterable\r\n  );\r\n}\r\nmain();\r\n```\r\n\r\nReference: https://twitter.com/b0neskull/status/1115325542566227968",
        "labels": "feature request",
        "id": 43196
    },
    {
        "title": "Use the `/q` flag with `cmd.exe` in `child_process.spawn()`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n`child_process.spawn()` with `shell: true` on Windows [calls `cmd.exe /d /s /c`](https://github.com/nodejs/node/blob/master/lib/child_process.js#L486).\r\n\r\nThis makes `childProcess.stdout` [include the prompt and command](https://github.com/sindresorhus/execa/issues/116) with Batch files. \r\n\r\n**Describe the solution you'd like**\r\nAdd the [`/q` flag](https://ss64.com/nt/cmd.html).\r\n\r\n**Alternatives**\r\nAdding `@echo off` to Batch files.\r\n",
        "labels": "feature request",
        "id": 43197
    },
    {
        "title": "Add capacity to specify separator for util.format(), instead of space ' '.",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nMany logger use util.format as the underlying implementation. e.g winston.logger.\r\nSo\r\n`logger.warn(1, 2, 3);`\r\ngot result:  `1 2 3`\r\nThis is ok when log is simple, but for real world, space separated log is not easy to analysis.\r\nI have to write like\r\n`logger.warn(v0 + '|' + v1 + '|' + v2);`\r\nor\r\n`logger.warn(``${v0}|${v1}|${v2}``);`  (how can i put single ` in github's code...)\r\n\r\n**Describe the solution you'd like**\r\nConsider add an env variable like process.env.NODE_FORMAT_SEPARATOR\r\n\r\ncode node/lib/internal/util/inspect.js   line: 1541\r\n\r\n```\r\n  while (a < args.length) {\r\n    const value = args[a];\r\n    str += join;\r\n    str += typeof value !== 'string' ? inspect(value, inspectOptions) : value;\r\n    join = ' ';\r\n    a++;\r\n  }\r\n```\r\n\r\ncan be\r\n```\r\n  const sepor = process.env.NODE_FORMAT_SEPARATOR || ' ';\r\n  while (a < args.length) {\r\n    const value = args[a];\r\n    str += join;\r\n    str += typeof value !== 'string' ? inspect(value, inspectOptions) : value;\r\n    join = sepor;\r\n    a++;\r\n  }\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nor just add a function to util to specify separator.\r\n",
        "labels": "feature request",
        "id": 43198
    },
    {
        "title": "Can we report the node versions, in addition to the ABI version, on ABI mismatch?",
        "body": "I recently answered a question about this:\r\n\r\n```\r\ninternal/modules/cjs/loader.js:718\r\n  return process.dlopen(module, path.toNamespacedPath(filename));\r\n                 ^\r\n\r\nError: The module '/lib/node_modules/fs-ext/build/Release/fs-ext.node'\r\nwas compiled against a different Node.js version using\r\nNODE_MODULE_VERSION 57. This version of Node.js requires\r\nNODE_MODULE_VERSION 64. Please try re-compiling or re-installing\r\nthe module (for instance, using `npm rebuild` or `npm install`).\r\n```\r\nThis is a pretty good error message, and it does say what people should do to fix the problem, but most people have no idea what module versions are, that they can be different for different release lines, or how to find out what release line a module version was associated with. This can confuse them. The person who asked me about the above thought the npm package they were using somehow just didn't support node 10.x.\r\n\r\nIt would take a (small) amount of extra tracking on our part, but I think it would be helpful if that message was enhanced to list the node.js major's that a module version could correspond to. It might help cut down the number of questions just a little bit more.\r\n\r\n\r\n<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n",
        "labels": "feature request",
        "id": 43199
    },
    {
        "title": "Feature: Immutable Buffer `buffer.readonly()`",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI have an object with a buffer attached and I need to be able to pass around that Buffer but ensure that it wonâ€™t mutate.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA method on Buffer instances to put it into a â€œread only modeâ€ would be ideal. Iâ€™d prefer it not be in the constructor so that I donâ€™t have to perform a memcopy in order to get it.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThere isnâ€™t much you can do except force a full copy every time you pass it around, which is pretty bad. Object.freeze() wonâ€™t work because all the mutations happen through methods that are effectively invisible to Object.freeze().\r\n\r\nHowever, Object.freeze() has some negative performance implications while implementing this in the Buffer object itself would not have the same problems. This would be a nice features of Node.js Core.",
        "labels": "feature request",
        "id": 43200
    },
    {
        "title": "Documented way to add certificates to existing SecureContext",
        "body": "In some cases, I've found that I've wanted to add a single CA to the list of trusted CAs that Node.js uses by default. There seems to be no documented way to do this. As it stands, officially, if you want to use non standard CAs, you can, but must also specify all CAs that might have otherwise been loaded automatically.\r\n\r\nFrom the `createSecureContext` documentation:\r\n> `ca <string> | <string[]> | <Buffer> | <Buffer[]>` Optionally override the trusted CA certificates. Default is to trust the well-known CAs curated by Mozilla. **Mozilla's CAs are completely replaced when CAs are explicitly specified using this option.** [...]\r\n\r\nIn trying to accomplish this, I've come across a seemingly stable but undocumented API https://github.com/nodejs/node/issues/20432#issuecomment-441514919\r\n\r\n> ```js\r\n> const tls = require('tls');\r\n> // Create context with default CAs from Mozilla\r\n> const secureContext = tls.createSecureContext();\r\n> // Add a CA certificate from Let's Encrypt\r\n> // https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem.txt\r\n> secureContext.context.addCACert(`-----BEGIN CERTIFICATE-----\r\n> MIIEkjCCA3qgAwIBAgIQCgFBQgAAAVOFc2oLheynCDANBgkqhkiG9w0BAQsFADA/\r\n> MSQwIgYDVQQKExtEaWdpdGFsIFNpZ25hdHVyZSBUcnVzdCBDby4xFzAVBgNVBAMT\r\n> DkRTVCBSb290IENBIFgzMB4XDTE2MDMxNzE2NDA0NloXDTIxMDMxNzE2NDA0Nlow\r\n> SjELMAkGA1UEBhMCVVMxFjAUBgNVBAoTDUxldCdzIEVuY3J5cHQxIzAhBgNVBAMT\r\n> GkxldCdzIEVuY3J5cHQgQXV0aG9yaXR5IFgzMIIBIjANBgkqhkiG9w0BAQEFAAOC\r\n> AQ8AMIIBCgKCAQEAnNMM8FrlLke3cl03g7NoYzDq1zUmGSXhvb418XCSL7e4S0EF\r\n> q6meNQhY7LEqxGiHC6PjdeTm86dicbp5gWAf15Gan/PQeGdxyGkOlZHP/uaZ6WA8\r\n> SMx+yk13EiSdRxta67nsHjcAHJyse6cF6s5K671B5TaYucv9bTyWaN8jKkKQDIZ0\r\n> Z8h/pZq4UmEUEz9l6YKHy9v6Dlb2honzhT+Xhq+w3Brvaw2VFn3EK6BlspkENnWA\r\n> a6xK8xuQSXgvopZPKiAlKQTGdMDQMc2PMTiVFrqoM7hD8bEfwzB/onkxEz0tNvjj\r\n> /PIzark5McWvxI0NHWQWM6r6hCm21AvA2H3DkwIDAQABo4IBfTCCAXkwEgYDVR0T\r\n> AQH/BAgwBgEB/wIBADAOBgNVHQ8BAf8EBAMCAYYwfwYIKwYBBQUHAQEEczBxMDIG\r\n> CCsGAQUFBzABhiZodHRwOi8vaXNyZy50cnVzdGlkLm9jc3AuaWRlbnRydXN0LmNv\r\n> bTA7BggrBgEFBQcwAoYvaHR0cDovL2FwcHMuaWRlbnRydXN0LmNvbS9yb290cy9k\r\n> c3Ryb290Y2F4My5wN2MwHwYDVR0jBBgwFoAUxKexpHsscfrb4UuQdf/EFWCFiRAw\r\n> VAYDVR0gBE0wSzAIBgZngQwBAgEwPwYLKwYBBAGC3xMBAQEwMDAuBggrBgEFBQcC\r\n> ARYiaHR0cDovL2Nwcy5yb290LXgxLmxldHNlbmNyeXB0Lm9yZzA8BgNVHR8ENTAz\r\n> MDGgL6AthitodHRwOi8vY3JsLmlkZW50cnVzdC5jb20vRFNUUk9PVENBWDNDUkwu\r\n> Y3JsMB0GA1UdDgQWBBSoSmpjBH3duubRObemRWXv86jsoTANBgkqhkiG9w0BAQsF\r\n> AAOCAQEA3TPXEfNjWDjdGBX7CVW+dla5cEilaUcne8IkCJLxWh9KEik3JHRRHGJo\r\n> uM2VcGfl96S8TihRzZvoroed6ti6WqEBmtzw3Wodatg+VyOeph4EYpr/1wXKtx8/\r\n> wApIvJSwtmVi4MFU5aMqrSDE6ea73Mj2tcMyo5jMd6jmeWUHK8so/joWUoHOUgwu\r\n> X4Po1QYz+3dszkDqMp4fklxBwXRsW10KXzPMTZ+sOPAveyxindmjkW8lGy+QsRlG\r\n> PfZ+G6Z6h7mjem0Y+iWlkYcV4PIWL1iwBi8saCbGS5jN2p8M+X+Q7UNKEkROb3N6\r\n> KOqkqm57TH2H3eDJAkSnh6/DNFu0Qg==\r\n> -----END CERTIFICATE-----`);\r\n> // Use it\r\n> const sock = tls.connect(443, 'host', {secureContext});\r\n> ```\r\n\r\nIt looks to be a real API for a number of reasons:\r\n - No underscores (`_`)\r\n - It is named in a [change log](https://github.com/nodejs/node/blob/3516052bee118dce767dd330fa857f6615c5b28a/doc/changelogs/CHANGELOG_V7.md)\r\n - Tests [use](https://github.com/nodejs/node/pull/10389/files#diff-8959a6c6e723d70e9903a7d3549f02b1R48) [this](https://github.com/nodejs/node/blob/8b4af64f50c5e41ce0155716f294c24ccdecad03/test/parallel/test-tls-addca.js#L15) [function](https://github.com/nodejs/node/blob/8b4af64f50c5e41ce0155716f294c24ccdecad03/test/internet/test-tls-add-ca-cert.js#L47-L49).\r\n - Internal code [uses this API](https://github.com/nodejs/node/blob/f512f5ea138fe86e47c0179d5733044daf6f4fe6/lib/_tls_common.js#L100-L114)\r\n\r\nWould it make sense to document this feature?\r\n\r\n### Alternatives\r\n\r\nIf the default list of CAs were accessible in node, we could do this ourselves without adding extra APIs. I have not actually looked at if this is possible or unintentionally exposed by the SecureContext API.\r\n\r\n### Related Issues\r\nhttps://github.com/nodejs/node/issues/4464\r\nhttps://github.com/nodejs/node/issues/20432\r\nhttps://github.com/nodejs/node/pull/26908#issuecomment-479147423",
        "labels": "feature request",
        "id": 43201
    },
    {
        "title": "Call `require` from N-API?",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nYes, I'm working on converting a Native Addon from v8 & NAN to N-API & node-addon-api. Currently, my Native Addon's C++ code calls `require` by looking it up on the `v8::Local<v8::Object> module` passed to the `NODE_MODULE`-style init function. When moving to N-API, I don't see an option for accessing to `require`. `NODE_API_MODULE`-style init functions only have access to `Napi::Env env` and `Napi::Object exports`.\r\n\r\n**Describe the solution you'd like**\r\n\r\nCan you please clarify whether\r\n\r\n- [ ] I've missed something, and this is currently supported by N-API\r\n- [ ] This is not currently supported from N-API, but could be added in the future\r\n- [x] This is intentionally not supported by N-API\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI've considered\r\n\r\n- ~~Exporting a function to JavaScript from my Native Addon that accepts `require` as a parameter. This might let me delay initializing the part of Native Addon that calls `require`.~~\r\n- Exporting a function to JavaScript from my Native Addon that accepts the thing I'm trying to `require`, rather than the `require` function itself. **Update:** I implemented this.\r\n\r\nBoth changes require that I delay the execution of some code in my Native Addon.\r\n\r\nThank you!",
        "labels": "feature request",
        "id": 43202
    },
    {
        "title": "Userland access to `internalBinding` (at one's own risk)",
        "body": "At [Intrinsic](https://intrinsic.com), we make use of `process.binding('natives')` in order to re-evaluate Node.js core modules inside our isolation environment. In order for these modules to work, we need to have the binding layer accessible. This is similar to how the [`natives`](https://npm.im/natives) module works.\r\n\r\nThe introduction of `internalBinding` was of no issue on its own, since we could just use `process.binding` to replicate its behaviour. However, there are now modules such as `string_decoder` that now having binding parts that are inacessible to userland. We can't simply require that users run with `--expose-internals` as our customers aren't always in control of CLI arguments. Also, our product is delivered as a Node.js module, rather than a separate binary, and we'd like to keep it that way.\r\n\r\n> Note: The `natives` module is subject to the same issue. [Here is a quick example using RunKit.](https://runkit.com/bengl/5ca2ba2a6896c70012ae475c)\r\n\r\nWe do have some workarounds involving re-implementing the exposed APIs, but we find this to be prone to errors and subject to extra maintenance for new versions of Node.js.\r\n\r\nWhat we'd like to do is introduce a way of accessing `internalBinding`-provided code from userland. I know this seems counterintuitive, given the purpose of `internalBinding`, so it would make the most sense for it to be provided in C++ only, requiring some native code to actually get access to it. The difficulty in accessing it is an acknowledgement that we're not expecting the same level of support that the normal user-facing API has. (We would expect basically no support for the actual internal bindings, but we wouldn't expect this access to disappear.) We're certainly open to other suggestions, but we'd like a solution that's maintainable and sustainable.\r\n\r\nWhat do folks think?",
        "labels": "feature request",
        "id": 43203
    },
    {
        "title": "Add maxStringLength option for util.inspect",
        "body": "**Problem**\r\nWhen using `util.inspect()`, it would be nice to have the ability to truncate string values over a certain length wherever they exist in the object under inspection. This would allow us to avoid logging out entire strings in situations where they can be potentially huge and they add too much space in the logs.\r\n\r\n**Proposed solution**\r\nAdd a `maxStringLength` option to util.inspect, similar to `maxArrayLength` option that currently exists.\r\n",
        "labels": "feature request",
        "id": 43204
    },
    {
        "title": "\"[Object: null prototype]\" spam from util.inspect",
        "body": "Commit 90014b6c3c98 changed `util.inspect` as a fix for #22141. While it may be important to emphasize null-prototype objects for that very particular use-case, for general debugging it is just annoying spam that can make dumps of complex objects substantially less readable. This should not be the default behaviour, but an option specifically enabled by `assert.deepStrictEqual`'s use of inspect.",
        "labels": "feature request",
        "id": 43205
    },
    {
        "title": "Add TextEncoder.prototype.encodeInto",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\n`TextEncoder.prototype.encodeInto` is a new method available in latest Chrome and Firefox that allows efficient encoding of strings into a given buffer, avoiding intermediate allocation and copying.\r\n\r\nIts primary usecase is a more efficient way to pass strings to WASM (one of the most expensive things one has to do when communicating with JavaScript) and it's already leveraged by Rust wasm-bindgen where available. wasm-bindgen has support for a Node.js target, so it would be great to speed things up here too.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdding native `encodeInto` method to the `TextEncoder` class already available in `util` module.\r\n\r\nPlease describe the desired behavior.\r\n\r\nMDN: https://developer.mozilla.org/en-US/docs/Web/API/TextEncoder/encodeInto\r\n\r\n**Describe alternatives you've considered**\r\n\r\nSending PR to wasm-bindgen to wrap memory into a Node-specific `Buffer` and use `Buffer.prototype.write` instead.\r\n\r\nIt has very similar semantics, and produces similar speed-ups (up to 35% on some of my string-interaction-heavy WASM libraries), but I wanted to see if it's possible to solve this on the Node.js side first so that the same method could be used for  all platforms.\r\n\r\ncc @jasnell as the author of the original implementation of WHATWG Encoding API in Node.js (https://github.com/nodejs/node/pull/13644)",
        "labels": "feature request",
        "id": 43206
    },
    {
        "title": "dns: provide additional info for ENOTFOUND errors",
        "body": "Refs: #5436 - and plenty of other issues.\r\n\r\nThat issue attracts comments from befuddled users to this day so I think it highlights a real issue, namely that the ENOTFOUND error code on its own is not very helpful.\r\n\r\nHistory/background/context:\r\n\r\n1. It's an artificial error that was introduced for $reasons in Node.js v0.2.0.<sup>1</sup>\r\n\r\n2. It's been around long enough that simply removing it won't fly.\r\n\r\n3. It's returned when getaddrinfo() fails with EAI_NODATA or EAI_NONAME.\r\n\r\n3. It nearly always indicates some transient or environmental error condition: out of file descriptors, no network connectivity, upstream DNS server timing out, etc.\r\n\r\nIt would be nice to provide a better error message, perhaps through an additional status property if necessary for backwards compatibility.\r\n\r\nThe problem: there might not be sufficient metadata to provide a better message.\r\n\r\nFor example, glibc returns EAI_NONAME when there is no IPv6 connectivity and the host only has an IPv6 address. There is no way to dinstinguish that particular condition from a real NXDOMAIN error apart from opting out from glibc's default behavior (see https://github.com/libuv/libuv/issues/2225 - probably has wider-ranging consequences.)\r\n \r\n<sup>1</sup> For the curious: it maps directly to `ARES_ENOTFOUND`, the c-ares error code. That's from before Node.js supported getaddrinfo().",
        "labels": "feature request",
        "id": 43207
    },
    {
        "title": "Add LTS changelog",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI, as developer, want to upgrade Node.js in my project or library from older LTS version to newer one.\r\n\r\n**Describe the solution you'd like**\r\nI would like to read single documentation page, listing all revelant changes made between old LTS and new LTS.\r\n\r\nEg. if I want to upgrade from Node 8 to Node 10 I have to read whole changelog for V9 and V10, including hundreds of `docs` and `test` fixes.\r\n\r\nTherefore, I would like to see page \"upgrading from Node 8 to Node 10\", with list of \"notable\" changes made in Node 9 and pre-LTS Node 10 (and filtered commit list).",
        "labels": "feature request",
        "id": 43208
    },
    {
        "title": "util.callbackify return value problematic characteristics",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `12.0.0-pre` (`d6f6d7f8541327b72667d38777c47` from master) and `10.15.1`\r\n* **Platform**: `Linux myhostname 4.4.0-143-generic #169-Ubuntu SMP Thu Feb 7 07:56:38 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: util\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhen calling `util.callbackify` on an async function. The returned function has a wrong `length` value. It also has the wrong prototype:\r\n\r\n```javascript\r\n> asyncFn = async (a, b) => Promise.resolve(a+b)\r\n[AsyncFunction: asyncFn]\r\n> cbFunction = util.callbackify(asyncFn)\r\n[AsyncFunction: asyncFn]   // questionable, it's actually not an AsyncFunction anymore\r\n> cbFunction.length\r\n2 // plain wrong, should be three, since there's an parameter added\r\n> Object.getPrototypeOf(cbFunction).constructor.name\r\n'AsyncFunction' // it's not.\r\n```\r\n\r\n## `length` property:\r\n\r\nSome libraries actually act differently based on the `length` of a function (express, for example: if a handler has a length of four, it's an error handler).\r\nSince the returned function has one argument added, it should also add one to the length of the new function. I'm aware that there are several constructs\r\nwhere the length parameter is wrong (`function`s that are accessing the `arguments`, functions defined with `...` in the parameter list, etc), but this\r\nbreaks almost all cases and there seems to be no nice workaround to me.\r\n\r\nThe library I'm dealing with has hooks and it gets determined if they are *asyncronous* or *syncronous* based on their `length` (like legacy mocha used to do).\r\n\r\n## `prototype`:\r\n\r\nI understand where this is coming from. There are libraries (like `knex`) that use the builder pattern and have a `then` \r\nmethod in their protoype chain for convenience. \r\n(please ignore that knex also provides a callback interface, as this is to make an argument for the current behaviour):\r\n\r\n```javascript\r\nconst query = knex('table').select('*')\r\n    .where({column: 4}) // has a then method\r\nconst execute = callbackify(query).bind(query); // this works because the query's prototype is set.\r\nexecute(cb);\r\n```\r\n\r\nIn this case, it might be fine as long as the `query`'s prototype has `Function` in his prototype chain. If not, it is highly confusing to have a function that does not have a normal function's methods.\r\n\r\n\r\nI've looked at the original PR that brought and [found a comment](https://github.com/nodejs/node/pull/12442#discussion_r111688746) that stated it would make not that much difference (note that this is the `promisify` introducing PR, but the `callbackify` one states that it is based upon it).\r\n\r\nA definitley not `async` Function gets the `AsyncFunction.prototype`. \r\nAfaik this is just confusing when debugging for now. It does not seem to have any methods on it (until someone sets a `map` method on it).",
        "labels": "feature request",
        "id": 43209
    },
    {
        "title": "worker.onmessage is not called",
        "body": "```js\r\n// main.mjs\r\nimport {Worker} from 'worker_threads';\r\n\r\nconst worker = new Worker(\"./worker.mjs\");\r\nworker.onmessage = ev => console.log(\"onmessage\", ev);\r\nworker.on(\"message\", ev => console.log(\"EventEmitter\", ev));\r\nworker.postMessage(\"from main to worker\")\r\n```\r\n\r\n```js\r\n// worker.mjs\r\nimport {parentPort} from 'worker_threads';\r\n\r\nparentPort.onmessage = ev => console.log(ev);\r\nparentPort.postMessage(\"from worker to main\");\r\n```\r\n\r\nIf you run the `main.mjs` file above, youâ€™ll see only the EventEmitter handler is called, but not the one registered via `onmessage`.\r\n\r\nI think for consistence (as well as the fake MessageEvent handling introduced in #26082), it is desirable to add support for `onmessage` on `Worker`.\r\n\r\ncc @addaleax ",
        "labels": "feature request",
        "id": 43210
    },
    {
        "title": "Exposing KeyObject fields vs. native JWK support",
        "body": "Now that node has a decent API to deal with cryptographic keys, users have requested features to access parts of keys, e.g. the modulus of an RSA key or the curve name of an EC key. @sam-github and I came up with the idea to add a `.fields` property to `KeyObject` which exposes those parts. Other users have encouraged this approach.\r\n\r\nI am currently working on a PR for that and the basics are working nicely:\r\n\r\n```js\r\n> const keyPairRSA = crypto.generateKeyPairSync('rsa', { modulusLength: 1024 })\r\nundefined\r\n> keyPairRSA.publicKey.fields.modulus\r\n137021253720226911691183972137240610622846133147052915629542163534532873356019104530365068889937816017524544544464479119278509383548598349559040164794055344541073852040420760130374918407240711285194600169474281779365813970973286457910750280768421849742536481361766898914122508451829863613535241209789652127067n\r\n> const keyPairEC = crypto.generateKeyPairSync('ec', { namedCurve: 'P-256' })\r\nundefined\r\n> keyPairEC.publicKey.fields.namedCurve\r\n'prime256v1'\r\n```\r\n\r\nOne of the reasons users have requested this feature is to be able to implement JWK on top of the native crypto module without having to tap into OpenSSL. However, this would still only make that work in one direction (`KeyObject` â†’ JWK), to create a `KeyObject` from JWK, a different API would be necessary to construct keys from their fields.\r\n\r\nAnother solution would be to natively support JWK. I am not an expert when it comes to JWK, but it shouldn't be difficult to implement as long as we don't need to include algorithm information in the key as WebCrypto does. This approach would extend `create***Key` and `KeyObject.export` with support for JWK.\r\n\r\nIf JWK support is not the only reason to access parts of the key, it might still make sense to implement `.fields` since JWK was designed for storing keys, not for interacting with its components. For example, `.fields` could make use of ES BigInts whereas JWK encodes everything as strings.\r\n\r\nSo as I see it, there are four options: Implement both, implement one and not the other, or implement none of it. What do you think?\r\n\r\ncc @nodejs/crypto @panva @mscdex",
        "labels": "feature request",
        "id": 43211
    },
    {
        "title": "Cluster worker on exit not forking the same worker.id",
        "body": "Version: 10.14.0\r\nPlatform: Windows 10 Pro 64\r\nSubsystem: cluster\r\n\r\nWhen using cluster mode and a Worker dies (Exit event), cluster module forks new workers based on an incremental ID. \r\nI would like to be able to fork the new Worker using the same ID of the worker that has died. Because all the examples and logics regarding cluster module relies on the worker.id, so I have other copies of the workers list, and if the ID of a worker changes, I need to update all the related lists/controls/logics...\r\nI know I could just create my own property called worker.name, but we should be able to control the worker ID.\r\n\r\nPer documentation, we have these options:\r\n![image](https://user-images.githubusercontent.com/16235598/54761521-01165680-4bd1-11e9-804f-d87469aef188.png)\r\nSame options used by cluster module to fork new processes using child_process.fork()\r\n\r\n![image](https://user-images.githubusercontent.com/16235598/54771054-42176680-4be3-11e9-8646-a272a4b38b72.png)\r\nThis will fork a new worker with a new id, the id is incremented based on the last worker id.\r\n\r\nI was trying to set the `uid` property before forking the new worker, but I get this error:\r\n`spawn ENOTSUP`\r\n\r\nWe could just add a parameter to fork func to accept an id, then internally it can checks if that id is already in use or not... Also, what is the uid/gid, and how is it handled?\r\n```\r\n    export interface ForkOptions {\r\n        cwd?: string;\r\n        env?: any;\r\n        execPath?: string;\r\n        execArgv?: string[];\r\n        silent?: boolean;\r\n        stdio?: any[];\r\n        detached?: boolean;\r\n        uid?: number;\r\n        gid?: number;\r\n        windowsVerbatimArguments?: boolean;\r\n    }\r\n```\r\n\r\nAnother issue is about the cluster interface, there is a TODO about the schedulingPolicy property:\r\n`// TODO: cluster.schedulingPolicy`\r\n\r\nPlease let me know if you understood the issue, and if you need more info.\r\n\r\nThanks!\r\n",
        "labels": "feature request",
        "id": 43212
    },
    {
        "title": "Downgrade HTTP/2 to HTTP1 over HTTP(non-TLS)",
        "body": "Hi, developers. Thank you very much for your wonderful project! I've been using Node.js a lot.\r\n\r\nI have a question about HTTP/2 support. Does `http2.createServer()` allow downgrade HTTP/2 to HTTP/1 when clients access by HTTP/1 with non-TLS? (`{allowHTTP1: true}` is specified)\r\n\r\nHere is a simple script to test my question above.\r\n\r\n* Server: HTTP/2 (`http2.createServer({allowHTTP1: true})`)\r\n* Client1: HTTP/2 GET\r\n* Client2: HTTP/1 GET\r\n\r\n```js\r\n// [This is a portable .js file containing server and client.]\r\n\r\nconst http2 = require(\"http2\");\r\nconst http = require(\"http\");\r\n\r\nconst port = 3000;\r\nconst options = {\r\n  // HTTP/2 will be downgraded to HTTP/1.x \r\n  allowHTTP1: true,\r\n};\r\nconst server = http2.createServer(options);\r\n\r\nserver.on('stream', (stream, headers) => {\r\n  stream.respond({\r\n    'content-type': 'text/plain',\r\n    ':status': 200\r\n  });\r\n  stream.end('hello, world from server!');\r\n});\r\n\r\nserver.listen(port, ()=>{\r\n  // server is ready\r\n  console.log(`Server listening on ${port}!`);\r\n\r\n  // Choose true/false!\r\n  const useHTTP2 = true;\r\n\r\n  if (useHTTP2) {\r\n    // HTTP/2 GET\r\n    http2.connect(`http://localhost:${port}`)\r\n      .request({\":path\": \"/\"})\r\n      // Print body\r\n      .pipe(process.stdout)\r\n  } else {\r\n    // HTTP/1 GET\r\n    http.get(`http://localhost:${port}`, (res)=>{\r\n      // Print body\r\n      res.pipe(process.stdout);\r\n    });\r\n  }\r\n});\r\n```\r\n\r\n### HTTP/2 client is OK\r\n\r\nWhen `const useHTTP2 = true` in the code above, the output is as follows without error.\r\n\r\n```\r\nServer listening on 3000!\r\nhello, world from server!\r\n```\r\n\r\n### HTTP/1 client has error\r\n\r\nWhen `const useHTTP2 = false`, the output has error as follows.\r\n\r\n```\r\nServer listening on 3000!\r\nevents.js:167\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: Parse Error\r\n    at Socket.socketOnData (_http_client.js:442:20)\r\n    at Socket.emit (events.js:182:13)\r\n    at addChunk (_stream_readable.js:283:12)\r\n    at readableAddChunk (_stream_readable.js:264:11)\r\n    at Socket.Readable.push (_stream_readable.js:219:10)\r\n    at TCP.onStreamRead (internal/stream_base_commons.js:94:17)\r\nEmitted 'error' event at:\r\n    at Socket.socketOnData (_http_client.js:448:9)\r\n    at Socket.emit (events.js:182:13)\r\n    [... lines matching original stack trace ...]\r\n    at TCP.onStreamRead (internal/stream_base_commons.js:94:17)\r\n```\r\n\r\nCould you tell me whether HTTP/1 client is allowed?\r\n\r\n### node version\r\n\r\nHere is my node version.\r\n\r\n```bash\r\n$ node -v\r\nv10.15.0\r\n```\r\n",
        "labels": "feature request",
        "id": 43213
    },
    {
        "title": "module.js --> load files from alternative fs implementations",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nId like to perform a `require` to load a module, but from an alternative `fs` implementation (representing a virtual file system).\r\n\r\nI'm using `memfs` and `unionfs` to create a virtual file system.\r\n\r\n**Describe the solution you'd like**\r\nI'd like some way of performing a require() and specifying for that require that an alternative `fs` is to be used rather than node's default `fs` module.\r\n\r\n**Describe alternatives you've considered**\r\nusing `mock-fs` allows me to override `fs` globally for a time, and then restore it after - however I'd have to first sync all my files into `mock-fs` and this is a lot of overhead.\r\n",
        "labels": "feature request",
        "id": 43214
    },
    {
        "title": "crypto hash, hmac and cipher ops could be 2x-3x faster for \"one-shot\" small buffers",
        "body": "[@ronomon/crypto-async](https://github.com/ronomon/crypto-async) recently added support for **synchronous** hash, hmac and cipher methods.\r\n\r\nIn the process, we noticed that Node's crypto equivalents are significantly slower than expected, partly because of calling back and forth into C++ multiple times, i.e. for initialization, updating and finalizing.\r\n\r\nThese calls add up to considerable overhead, on the order of a few hundred ns per call, which is especially noticeable for small buffers less than 1KB.\r\n\r\nFor use-cases which only need to hash a single small buffer, i.e. in \"one shot\", it should be possible to **[improve performance by 2x or even by as much as 3x](https://github.com/ronomon/crypto-async#performance)**, by making a single call into C++ (and by removing other overhead, more on this below).\r\n\r\nOf course, not everyone calls `update()` only once, or hashes or encrypts only small buffers, but I think this is probably representative of a large proportion of use-cases, especially for hashing:\r\n\r\n```\r\ncrypto.createHash('sha256').update(buffer).digest()\r\n```\r\n\r\nIf we could make this use-case 2x to 3x faster (as in less latency) that should be worth doing.\r\n\r\nHow could this be done?\r\n\r\nI think there are at least two approaches:\r\n\r\n1. Firstly, while the current interface must support the existing streams interface, Node could possibly do something transparently under the hood, at least for hashes, by batching calls to C++ for initialize, update and finalize. For example, for a hash, there's no need for Node to do anything when the hash is instantiated (except for error handling, checking for algorithm support etc), and no need to do anything for updates. Node could effectively wait until `update()` is called a second time before calling into C++, or until `digest()` is called. More generally, buffers could be batched until a high-watermark is reached, to amortize calls into C++. For ciphers, of course, this won't be possible, because the user expects `update()` to return something (and we need to support AEAD ciphers which are more complex in terms of interface). This approach won't entirely close the gap with @ronomon/crypto-async, because of the overhead of streams for small buffers.\r\n\r\n2. Secondly, it might be simpler and more optimal to introduce lightweight one-shot methods, to avoid the expense of streams for small buffers, which is significantly costly for small buffers, in addition to the multiple round-trips into C++. For example: `hash(algorithm, buffer, [offset, size], [callback])`. Introducing one-shot methods would also be a natural opportunity to add async multi-core support for large buffers (> 64KB), which would give a huge concurrent throughput boost for large buffers, and eliminate blocking in the event loop.\r\n\r\nThese are just some ideas, in case anyone is interested to run with this.",
        "labels": "feature request",
        "id": 43215
    },
    {
        "title": "Should we add a glossary like chrome ?",
        "body": "Like https://chromium.googlesource.com/chromiumos/docs/+/master/glossary.md.\r\n\r\ne.g I have no clue `WPT` mean for now.\r\nI know `RSLGTM` very recently.\r\nI know `godbolt` from @refack (very amazing tool for cpp).",
        "labels": "feature request",
        "id": 43216
    },
    {
        "title": "crypto: X25519 and X448 and ECDH",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nImplementing [CFRG](https://tools.ietf.org/html/rfc8037) curves ECDH-ES\r\n\r\nResources:\r\n- https://tools.ietf.org/html/rfc7748 - Elliptic Curves for Security\r\n- https://tools.ietf.org/html/rfc8037 - CFRG Elliptic Curve Diffie-Hellman (ECDH) and Signatures in JSON Object Signing and Encryption (JOSE)\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe following WIP on Node already paves the way for EdDSA signatures\r\n\r\n- #26319\r\n- #26774\r\n- #26611\r\n\r\nðŸ‘‡ \r\nTo complete the implementation i'd like X25519 and X448 curves/functions to be usable with `crypto.createECDH(curveName)` to get JOSE ECDH-ES with these OKP keys working.\r\n\r\nI understand from this thread (#18770), particularly this [comment](https://github.com/nodejs/node/issues/18770#issuecomment-434872330) and the conversation below that it may end up being a separate API and that's fine.\r\n\r\n~It seems the curves are already somewhat in because the returned error differs when providing nonsense vs. valid crv/function name.~",
        "labels": "feature request",
        "id": 43217
    },
    {
        "title": "Improve \"Cannot find module\" error",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nWhile trying to debug an issue, I found the error message from node to be slightly misleading and/or not as useful as it could have been.\r\n\r\nHere is a toy example of the issue:\r\n\r\nWe have a package called \"foo\". It consists of a package.json and dist/entry.js:\r\n\r\npackage.json:\r\n```\r\n/tmp/node_demo â€º cat node_modules/foo/package.json \r\n{\r\n  \"name\": \"foo\",\r\n  \"version\": \"0.1.1\",\r\n  \"main\": \"dist/entry.js\"\r\n}\r\n```\r\n\r\ndist/entry.js\r\n```\r\n/tmp/node_demo â€º cat node_modules/foo/dist/entry.js \r\nconsole.log(\"Loaded foo module\")\r\n```\r\n\r\nWe can import this package, everything is good:\r\n```\r\n/tmp/node_demo â€º node\r\n> require(\"foo\")\r\nLoaded foo module\r\n{}\r\n```\r\n\r\nThe improvement comes when we delete the entrypoint for our foo module. In my real-world case, this was done by an overzealous package-trimming routing in a CI pipeline, but I guess there are probably other ways it can occur. It's clearly the user's 'fault', but the error message isn't super obvious:\r\n\r\n```\r\n/tmp/node_demo â€º rm node_modules/foo/dist/entry.js \r\n```\r\n\r\n```\r\n/tmp/node_demo â€º node\r\n> require(\"foo\")\r\nError: Cannot find module 'foo'\r\n    at Function.Module._resolveFilename (module.js:547:15)\r\n    at Function.Module._load (module.js:474:25)\r\n    at Module.require (module.js:596:17)\r\n    at require (internal/module.js:11:18)\r\n> /tmp/node_demo â€º \r\n```\r\n\r\nThe issue here is that the error message `Error: Cannot find module 'foo'` isn't super helpful, because you have a look in `node_modules`, and you see a directory `foo/`, and you see that directory contains `package.json`. Maybe you also see it contains a `src/` dir, a `tests/` dir, and all sorts of other stuff. In my case, this led me to believe the error was that the node interpreter was somehow configured not to look in the local node_modules directory, and led to a fair bit of wild-goose chasing.\r\n\r\n**Describe the solution you'd like**\r\n\r\nIt would be better if the error message directly referred to the missing [main/entry-point]file. E.g. if the error was something like:\r\n\r\n```\r\nError: Cannot find load main file \"dist/entry.js\" when loading module 'foo'\r\n    at Function....\r\n    ...\r\n```\r\n\r\nit would be immediately obvious why node can't load the module.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThe obvious alternative is to do nothing, which would maintain the current error messaging and  behaviour.",
        "labels": "feature request",
        "id": 43218
    },
    {
        "title": "Support for base64url format",
        "body": "`new Buffer(str, \"base64\")` officially accepts both [RFC 3548](https://tools.ietf.org/html/rfc3548) (`+`,`/`) encoding as well as [RFC 4648](https://tools.ietf.org/html/rfc4648#page-7) (`-`,`_`) encoding (see #5239 and #5243).\r\n\r\nTo base64 encode a buffer using [RFC 3548](https://tools.ietf.org/html/rfc3548) we can actually do `buffer.toString(\"base64\")`.\r\n\r\nWould it be possible to also natively support [RFC 4648](https://tools.ietf.org/html/rfc4648#page-7) format using `buffer.toString(\"base64url\")` ?\r\n\r\nIf yes, should we strip trailing `=` characters as they are unnecessary and potentially harmful used in an URL? \r\n\r\n",
        "labels": "feature request",
        "id": 43219
    },
    {
        "title": "worker threads importScirpts and self support / 1:1 browser Worker functionality",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nGiven it is possible to have \"Dedicated Workers\" in the browser now, and that the Worker model is mirroring much of the Worker object from the browser, the lack of an importScripts means making a worker that works in either context requires rolling one's own importScripts function.\r\n\r\n\r\n**Describe the solution you'd like**\r\nWithin a worker self should be the global context and imported stuff should be added to global context.\r\n\r\nAn importScripts function that is available *within* the loaded worker so that a worker script can load additional resources.\r\n\r\nIt should eval the scripts in self/global context. Ideally, vm and fs would be require-able in the worker context, if possible, the worker should \r\n\r\n\r\n\r\n**Describe alternatives you've considered**\r\nI've been playing with a routine for having a worker client and stub worker that allows for messages with a status that can be handled by the client to route things as appropriate and allowing communication to the worker as promises as well as just handling registered \"notices\" on the client. Because I was loading a stub I had a message that handled a request to load user specified scripts. \r\nhttps://github.com/JamesJansson/importScripts/blob/master/importscripts.js\r\n\r\nI was playing with stuff on npm, in particular solid-worker which was close to what I needed but the script when loaded didn't really have access to anything. It was attempting to run in a forked process. And while it worked well enough for simple functionality, I couldn't require fs or vm to support the importScripts and self wasn't defined.\r\n\r\nAdmittedly, I have not attempted the Worker Threads mainly because the stability warning made me wary. I am giving up on trying to make what I'm doing now work on both node and the browser until things are stable, but it would be nice if the stable version can behave like the browser.\r\n\r\nTypically when looking up info online for node you get that you can use, for instance, browserfied content in node as long as it doesn't refer to the window object. Since Workers are window-less contexts they should be a most natural candidate for portabile bundles; hence the request that self be supported. I'd like to be able to browserify/webpack/etc a general worker stub that works in both node and the browser that add on functionality can be added to via importScripts.\r\n\r\nI did see in the documentation that you have the ability to parse external scripts to use when instantiating the Worker, but that's not quite the same thing; perhaps the importScripts function can do that internally?\r\n\r\nhttps://developer.mozilla.org/en-US/docs/Web/API/WorkerGlobalScope/importScripts\r\nhttps://github.com/JamesJansson/importScripts/blob/master/importscripts.js\r\n\r\n",
        "labels": "feature request",
        "id": 43220
    },
    {
        "title": "tls: additional root cert-specific verification",
        "body": "https://hg.mozilla.org/projects/nss/annotate/1feb89a254de/lib/certdb/genname.c#l1558\r\n\r\nUpstream NSS performs additional verification beyond just checking whether the certificate chains back to a trusted root certificate.\r\n\r\nExample: it checks that the CN of certificates attested by ANSSI ends in .fr, .gp, etc.\r\n\r\nConsiderations:\r\n\r\n1. To me this seems desirable. Additional security at low cost.\r\n\r\n2. Node.js seems like the right place to implement it rather than in upstream OpenSSL. OpenSSL bills itself more as a crypto toolkit than a framework.",
        "labels": "feature request",
        "id": 43221
    },
    {
        "title": "--require is missing a reference",
        "body": "* **Version**: v11.5.0\r\n* **Platform**: Darwin aprilis.local 18.2.0 Darwin Kernel Version 18.2.0: Thu Dec 20 20:46:53 PST 2018; root:xnu-4903.241.1~1/RELEASE_X86_64 x86_64\r\n\r\n<!-- Please provide more details below this comment. -->\r\nThe CLI provides a --require option documented in the man page as such:\r\n\r\n>      -r, --require module\r\n>             Preload the specified module at startup.  Follows `require()`'s module resolu-\r\n>            tion rules.  module may be either a path to a file, or a Node.js module name.\r\n\r\nwhich is wonderful because I can run very small programs like this:\r\n\r\n```\r\nnode -r myModule -p 'myModule.tst()'\r\n```\r\nexcept, of course, that the man page does not document how to refer to the module I've required.  I thus cannot use it\r\n\r\nCan we please add to the docs how to refer to modules required in this fashion within the code?",
        "labels": "feature request",
        "id": 43222
    },
    {
        "title": "Secure input for requesting passwords from user input.",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'd like to do all I can to keep user passwords out of memory as soon as possible after being collected.\r\nIdeally, I could use a Buffer and zero-out the memory after I use it... assuming that I never turn it into a string and only read it from the Buffer.  I'm not 100% sure that even that mitigation will prevent the memory from being copied around by the VM... but I guess that's part of this feature request.\r\n\r\n**Describe the solution you'd like**\r\nThe readline module allows you to read an input stream, but the events return strings instead of buffers...  It would be nice if there were a method that could take a buffer for holding passwords from user input.\r\n",
        "labels": "feature request",
        "id": 43223
    },
    {
        "title": "Advance Readable[Symbol.asyncIterator] out of experimental",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI'm loving the use of asyncIteration provided by https://github.com/nodejs/node/pull/17755 . It just works for me! \r\n\r\nUnfortunately I can't work with this feature with my team, because when I use this feature, Node outputs:\r\n\r\n```\r\nExperimentalWarning: Readable[Symbol.asyncIterator] is an experimental feature. This feature could change at any time\r\n```\r\n\r\nGetting ReadableStreams from experimental to something more stable would greatly advance #15709!\r\n\r\n**Describe the solution you'd like**\r\n\r\nAdvancing `Readable#[Symbol.asyncIterator]` out of experimental would help me be able to deploy & use this awesome feature.\r\n\r\nI'm also not sure what the criteria are for advancing this awesome feature into an unstable or stable state, where it no longer logs out on use. I've found a variety of tickets such as #23042 and  #23785 that have landed improvements, which is great, but I'm not sure what we're looking for to advance this great feature's stability. My end user perspective is that the API is correct, and has been validated, across the past 6 months, and I'm hoping this ticket might serve to clarify what else we need or want to advance this feature. \r\n\r\n**Describe alternatives you've considered**\r\n\r\nNo alternatives! Only forward! ;) Sorry, just having fun.\r\n\r\nFrom a process perspective, we might possibly close this issue & continue working on this topic in #17755 , perhaps? It would be convenient for me to have an issue to track & follow for stabilization, so I know when this feature advances. But I'm not sure how experimental features are normally advanced through node. I'd love to know more about how Node handles advancing experimental features.\r\n\r\nThanks all.",
        "labels": "feature request",
        "id": 43224
    },
    {
        "title": "fs.createReadStream and fs.createWriteStream missing *Sync variants.",
        "body": "```\r\n# node -v\r\nv10.15.0.\r\n# uname -a\r\nLinux zen 4.20.13-200.fc29.x86_64 #1 SMP Wed Feb 27 19:42:55 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\nWorkaround:\r\n\r\n```\r\nfunction createWriteStreamSync(file, options) {\r\n  if (!options)\r\n    options = {};\r\n  if (!options.flags)\r\n    options.flags = 'w';\r\n  if (!options.fd)\r\n    options.fd = fs.openSync(file, options.flags);\r\n  return fs.createWriteStream(null, options);\r\n}\r\n\r\nfunction createReadStreamSync(file, options) {\r\n  if (!options)\r\n    options = {};\r\n  if (!options.flags)\r\n    options.flags = 'r';\r\n  if (!options.fd)\r\n    options.fd = fs.openSync(file, options.flags);\r\n  return fs.createReadStream(null, options);\r\n}\r\n```\r\n",
        "labels": "feature request",
        "id": 43225
    },
    {
        "title": "Need support for console.success",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nJust like console.error, we need a hero console.success.\r\n\r\n**Describe the solution you'd like**\r\nWhen console.success is used, I would like to see it in green color. \r\n\r\n\r\n**Describe alternatives you've considered**\r\nCurrent workaround I have is to do console.log(\"Success: Order post is successful\"). \r\n\r\nThis will improve the mood way better than console.error. ",
        "labels": "feature request",
        "id": 43226
    },
    {
        "title": "Providing extra math modules like numpy  etc. as built-ins ? ",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPlease describe the problem you are trying to solve.\r\nPython is becoming more and more popular in data science and deep learning because it is convenient for these realms.  I suppose if we can provide some relevant tool modules about math calculations.  These functions are common enough to become builtin modules instead of just providing by third-party modules.  \r\n\r\n**Describe the solution you'd like**\r\nPlease describe the desired behavior.\r\nImplement functions like `itertools.product` from python. Implement common data science functions like numpy provides.  And one day maybe 1 or 2 years later, when people talking about deep learning or data science , Node.js  firstly comes to their brains instead of just python.  Node.js may be popular for more situations than before and now.  That's what I have imagined, maybe it's naive enough but I want to hear from all of your options about this.  Consider it ? And thank you.\r\n\r\n**Describe alternatives you've considered**\r\nPlease describe alternative solutions or features you have considered.\r\n",
        "labels": "feature request",
        "id": 43227
    },
    {
        "title": "n-api: napi_get_value_int64() needs a strict version",
        "body": "I am working on several n-api modules.\r\n\r\nWe need to enforce that integer arguments are really integers.\r\n\r\nThis is critical for avoiding buffer overflow and dangerous behavior.\r\n\r\nUnfortunately, at present, `napi_get_value_int64()` and friends are lax.\r\n\r\nFor example, from the documentation:\r\n\r\n```\r\nNon-finite number values (NaN, +Infinity, or -Infinity) set the result to zero.\r\n```\r\n\r\nI can understand this from a performance perspective, and have been involved in these performance discussions before, but there should also be a way to test for non-integers (including floats), e.g.  `napi_get_value_int64_strict()`.\r\n\r\nI don't know if this already exists?",
        "labels": "feature request",
        "id": 43228
    },
    {
        "title": "stream.pipeline destroys writable stream when error is occurred",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**:\r\nv11.10.0\r\n\r\n* **Platform**:\r\nMac OS Darwin 16.7.0\r\n\r\n* **Subsystem**:\r\nstream, http\r\n\r\nstream.pipeline is helpful to handle error and interoperable to Promise.\r\nHowever, I found a behavior that is not suitable my usecase.\r\n\r\nI am creating a web server with stream.pipeline. \r\nIf my readable stream emits an error like \"file not found\", I would like to send `error` response to my clients.\r\n\r\ncode example is as follows.\r\n\r\n```javascript\r\nconst fs = require('fs')\r\nconst http = require('http')\r\nconst { pipeline } = require('stream')\r\n\r\nconst server = http.createServer((req, res) => {\r\n  const r = fs.createReadStream('./foo2.txt')\r\n  pipeline(r, res, (err) => {\r\n    if (err) {\r\n      console.log(err) // No such file\r\n      return res.end(\"error!!!\"); // write error response but this message is not shown.\r\n    }\r\n  })\r\n})\r\n\r\nserver.listen(9000)\r\n```\r\n\r\nI have investigated nodejs core, stream.pipeline destroys writable stream when error is occurred.\r\nhttps://github.com/nodejs/node/blob/master/lib/internal/streams/pipeline.js#L42\r\n\r\nso the above code cannot send error response. \r\n\r\n## Question\r\n\r\nIs this an expected behaviour? \r\nIn my understandings, writable stream should be closed anyway, but in this case, we would like to close writable stream manually.\r\n\r\nIn this situation, we need to create custom writable stream?\r\n\r\nI could send a PR to pass an option like `{ destroyOnError: false }` to avoid destory automatically.\r\n",
        "labels": "feature request",
        "id": 43229
    },
    {
        "title": "cli:  --experimental-modules",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n**Alias or Autodetect**\r\n\r\nWhy not exsist alias for `--experimental-modules`?\r\nI if I have to run the project, I tap write each time the same command.\r\n\r\nI think `-em` as an alias would not be bad.\r\n\r\nAs an alternative, detect the file to run with extension `.mjs` and execute directly without command line Option.\r\n",
        "labels": "feature request",
        "id": 43230
    },
    {
        "title": "Enable signing operations via OS native cryptographic stores",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI'm trying to sign application packages as part of my Gulp workflow while keeping the private key stored as securely as possible.\r\n\r\n**Describe the solution you'd like**\r\nI would like to be able to generate/store cryptographic key pairs using a secure cryptographic storage facility such as the Keychain on macOS, the Certificate Store on Windows or GNOME keyring on Linux.\r\n\r\nUsing an OS-Level storage mechanism would allow for storing the keys/key-pairs in a single location while retaining access to them in multiple development environments.\r\n\r\n**Describe alternatives you've considered**\r\n* Store keys in my home directory using password-based encryption\r\n* Sign code outside of the Node.js environment\r\n* Create native add-ons which interact with the OS-level facilities for use with a custom module\r\n* Create a custom module which \"shells out\" to OS-provided binaries to perform the signing operations\r\n\r\n**Other Notes**\r\nThis functionality was discussed in #15113. I'm raising this request in hopes that it may be more easily tracked outside of an already-closed issue.",
        "labels": "feature request",
        "id": 43231
    },
    {
        "title": "Sourceless vm.Script compilation/load",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nNot exactly a problem, but a capability that I'd like to have in Node.js out of the box (Otherwise we need to recompile it).\r\n\r\n**Describe the solution you'd like**\r\nCurrently [`pkg`](https://github.com/zeit/pkg) is adding a flag `\"sourceless\"` that allows compiling a `vm.Script` without requiring keeping the sources around. When you load the compiled script, it works and has no JS sources attached.\r\nIt does so with this patch:\r\n[https://github.com/zeit/pkg-fetch/blob/master/patches/node.v10.4.1.cpp.patch](https://github.com/zeit/pkg-fetch/blob/master/patches/node.v10.4.1.cpp.patch)\r\n\r\nThere's much more going on in the patch, like adding pkg's bootstrap code, or using its wrapped fs/child_process functions, which is not the issue here and is not of interest for this feature request.\r\n\r\nA cleaner patch file, exported to a gist by me can be found here: [v10.x](https://gist.github.com/danielgindi/933b6ef0feab40888465205de37e09da) [v11.x](https://gist.github.com/danielgindi/3e6a8b830d649a6f84a10a8b6f2ec153)\r\n\r\n**Describe alternatives you've considered**\r\nI've tried passing dummy scripts to `new vm.Script` when loading the cached data, but the `cachedData` is rejected.\r\nIt also has the culprit of CPU compatibility, as by default node only loads the `cachedData` if the CPU features matches *exactly*, for performance reasons. Whereas `pkg` allows loading as long as the current CPU has *at least* the features of the CPU it compiled on. So it has binary compatibility, but may not use new CPU features.\r\n\r\nI'm aware of the fact that loading sourceless compiled scripts will have some kind of a performance hit, but it's acceptable in cases where you want to have complete obfuscation, or if you want to avoid the load/parse/compile time of a huge JS script, or any other case where you might want/need to transport binaries instead of sources.\r\n\r\n",
        "labels": "feature request",
        "id": 43232
    },
    {
        "title": "Fully deprecate require('constants')",
        "body": "* **Version**: 10.15.1\r\n* **Platform**: Windows 10 64-bit\r\n* **Subsystem**: constants\r\n\r\nUsing lerna, I defined a local package named `constants`. I then tried to consume it in another lerna package via the statement `const constants = require('constants');` Unfortunately, this pulls in the node.js internal constants module instead of my own package. This API is marked as a documentation-only deprecation, DEP0008. However, since it's a documentation-only deprecation, the node.js runtime is still reserving this module name for its own use. It would be great if this package were fully deprecated and the module name became available for consumers.",
        "labels": "feature request",
        "id": 43233
    },
    {
        "title": "Support ARM64 Windows desktop",
        "body": "**Is your suggestion related to a problem?**\r\nAt present the Electron project does not support the new Windows 10 on ARM (ARM64 Win32) platform. One of its dependencies is Node.js, which also does not support it. This means that on these devices Electron apps run emulated which, with the complexity of Electron, means a suboptimal user experience.\r\n\r\n**Describe the solution you'd like**\r\nI would like Node.js to support Windows 10 on ARM. Ideally this would include any tweaks needed to make Electron embedding easier, and I would be pleased as punch to see Node.js host ARM64 Windows EXEs on its main page.\r\n\r\n**Describe alternatives you've considered**\r\nAs mentioned earlier, Windows 10 on ARM includes an IA32 emulation layer that runs Node.js. This works well for many applications, but my prototype ARM64 build of Node.js runs much faster in significantly less memory.",
        "labels": "feature request",
        "id": 43234
    },
    {
        "title": "feature: crypto.pbkdf2(Sync) support for SecretKeyObject",
        "body": "With the recently introduced KeyObject API it's already possible to pass an instance created via `crypto.createSecretKey` to crypto's `createHmac` and the like. `crypto.pbkdf2` and `crypto.pbkdf2Sync` are lacking this support.\r\n\r\n**Describe the solution you'd like**\r\n`crypto.pbkdf2` and `crypto.pbkdf2Sync` accept `SecretKeyObject` as the password argument",
        "labels": "feature request",
        "id": 43235
    },
    {
        "title": "res.setHeader and res.writeHead should return this",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWhen working with vanilla node HTTP servers, I frequently make the mistake that `res.setHeader` and (more often) `res.writeHead` return `this`, allowing a `.end` to be appended. For example:\r\n\r\n```javascript\r\nres.writeHead(201, headers).end(body);\r\n```\r\n\r\nThis is an error, since `writeHead` returns `undefined`.\r\n\r\n**Describe the solution you'd like**\r\nI'd like to have `res.setHeader` and `res.writeHead` return `this` to allow chaining. The same behaviour should be added to the HTTP/2 compatibility module too. I'm happy to put together a pull request if you are open to the change.\r\n\r\n**Describe alternatives you've considered**\r\nI sometimes define a helper function to do this, but it's clunky.\r\n",
        "labels": "feature request",
        "id": 43236
    },
    {
        "title": "Reuse of createHash initializations",
        "body": "[Reuse](https://en.wikipedia.org/wiki/Reusability) is a fundamental issue...\r\n\r\n```js\r\nconst crypto = require('crypto')\r\nconst H = crypto.createHash('md5')  // NEED REUSE THIS INITIALIZATION\r\nconsole.log( H.update('some data to hash').digest('hex') ) // first ok...\r\nconsole.log( H.update('some2').digest('hex') )  // ugly \"Error: Digest already called\"!\r\n```\r\n-----\r\n\r\nThe problem that I am trying to solve: to reuse initialization.\r\n\r\nThe desired behavior: no error.\r\n\r\n... No alternative solutions, but please, show me if there are some elegant one.\r\n",
        "labels": "feature request",
        "id": 43237
    },
    {
        "title": "Retrieve built-in root certificates within node application",
        "body": "Is there any way to retrieve the built-in root certificates, that are shiped with node (https://github.com/nodejs/node/blob/master/src/node_root_certs.h) from a node application?\r\n\r\nVia https.globalAgent.options.ca it is possible to define custom certificates, but the already existing ones are not listed here.",
        "labels": "feature request",
        "id": 43238
    },
    {
        "title": "Support return value on EventEmitter.once",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nI'm trying to code a Promise method which will be called after `once` and `on` have been called.\r\n\r\nand It will resolve the params that are returned from `once` and `on` functions.\r\n \r\nI use it on server, the project code like this\r\n\r\n```js\r\nmodule.exports.emitThen = async function emitThen (event, ...args) {\r\n  return Promise.all(\r\n    this.rawListeners(event).map(\r\n      listener => Promise.resolve()\r\n        .then(() => {\r\n            return listener.apply(this, args)\r\n          }\r\n        )\r\n    )\r\n  )\r\n}\r\n```\r\n\r\n```js\r\nconst res = await obj.emitThen(eventName, data).then(res=> { \r\n  // do something\r\n})\r\n```\r\n\r\nbut `once` just returns a `null` because it only just be called and return nothing.\r\n\r\nhttps://github.com/nodejs/node/blob/5e1d4462d232400b4e75247540aae863cb6877cf/lib/events.js#L281-L287\r\n\r\n**Describe the solution you'd like**\r\n\r\n```js\r\nfunction onceWrapper(...args) {\r\n  if (!this.fired) {\r\n    this.target.removeListener(this.type, this.wrapFn);\r\n    this.fired = true;\r\n    return Reflect.apply(this.listener, this.target, args);\r\n  }\r\n}\r\n```\r\n\r\nAll in all, **I think it should do the same behavior whatever `on` or `once`**",
        "labels": "feature request",
        "id": 43239
    },
    {
        "title": "get event loop tick id somehow",
        "body": "I filed this in help but didn't get anything so wanted to put it here in case I forget\r\n\r\nhttps://github.com/nodejs/help/issues/1740\r\n\r\nI haven't seen this feature around. With  each tick of the event loop at about 10ms, I assume incrementing a counter might get kinda funky.\r\n\r\nI looked it up, in 1 year, there is about `3*10^10` milliseconds, so that's `3*10^9` centiseconds.\r\nThat's right you just learned centiseconds! lulz\r\n\r\nSo incrementing a counter is probably pretty safe since most servers aren't up for that long but who knows?\r\n",
        "labels": "feature request",
        "id": 43240
    },
    {
        "title": "Buffer objects should implement valueOf so they can be <=> compared directly",
        "body": "* **Version**: Reproduced on v10.14.1, v11.8.0\r\n* **Platform**: MacOS 10.14.2 (Darwin 18.2.0 Darwin Kernel Version 18.2.0: Mon Nov 12 20:24:46 PST 2018; root:xnu-4903.231.4~2/RELEASE_X86_64 x86_64)\r\n* **Subsystem**: buffer\r\n\r\nBuffers can usually, but not always, be compared using `<`, `<=`, `>`, `>=` operators. This should either always fail, or it should always do a lexographical sort (the same thing as `Buffer.compare()`). Currently it seems to work sometimes but not other times - I have no idea why.\r\n\r\n```\r\n$ node\r\n> b = Buffer.from([1,2,3])\r\n<Buffer 01 02 03>\r\n> c = Buffer.from([3,2,3])\r\n<Buffer 03 02 03>\r\n> b < c\r\ntrue # Correct\r\n> b > c\r\nfalse # correct\r\n\r\n> v1 = Buffer.from('00 00 00 0b 71 cb 7b 2f 00 00'.split(' ').join(''), 'hex')\r\n<Buffer 00 00 00 0b 71 cb 7b 2f 00 00>\r\n> v2 = Buffer.from('00 00 00 0b 71 cb a0 a6 00 00'.split(' ').join(''), 'hex')\r\n<Buffer 00 00 00 0b 71 cb a0 a6 00 00>\r\n> Buffer.compare(v1, v2)\r\n-1 # Correct - v2 is greater than v1\r\n> v1 > v2\r\ntrue # Wrong!\r\n> v2 > v1\r\nfalse # Wrong!\r\n> new Uint8Array(v1) > new Uint8Array(v2)\r\nfalse # Correct\r\n```",
        "labels": "feature request",
        "id": 43241
    },
    {
        "title": "Suggestion: Centralized package repository that support multiple versions of a package",
        "body": "## Problem\r\n\r\nProjects that use Node.js likely also use npm packages, and thus contain a `node_modules` folder. Having multiple projects like this leads to having multiple `node_modules` folder which likely contain duplicated packages. This not only wastes disk space, it also wastes bandwidth and time to install these packages.\r\n\r\n(Other platforms (such as Haskell, Rust, Java) avoid this by having a centralized package repository, I was quite surprised at Node's design decision)\r\n\r\n## Description\r\n\r\n* When user executes `require(\"pkg-name\")`, if `\"pkg-name\"` is not found in `module.paths`, Node.js should proceed to search in a fixed location (let's call it `$PREFIX/.node_package_store` until we find a better name) for a `\"pkg-name\"` that matches criteria specified in a manifest file within the project (preferably but not necessary `package.json`).\r\n* `$PREFIX/.node_package_store` is **not** a `node_modules` and `$NODE_PATH` (i.e. `module.paths`) does not affect it.\r\n* `$PREFIX/.node_package_store` should support ~~multiple runtime versions (es5, es6, nodejs versions, bundlers, etc.),~~ multiple package versions and multiple registries.\r\n\r\n### Example structure of a `.node_package_store`\r\n\r\nWhen use npm to install React from registry.npmjs.org\r\n\r\n```\r\n$PREFIX/.node_package_store\r\nâ””â”€â”€ npm6@registry.npmjs.org\r\n    â””â”€â”€ react\r\n        â””â”€â”€ 16.0.0\r\n            â”œâ”€â”€ content\r\n            â””â”€â”€ metadata\r\n```\r\n\r\n## Alternatives I've considered\r\n\r\n* `/node_modules`, `$HOME/node_modules` and the likes: Does not support multiple versions, as a result, different projects still require different/separated `node_modules`.\r\n* I can create a loader myself, but package managers (npm, yarn) don't support it, so it is useless.\r\n* I can use pnpm â€” a package manager that uses hardlinks and symlinks to solve this problem, but it also makes things more complicated.\r\n",
        "labels": "feature request",
        "id": 43242
    },
    {
        "title": "Pass a Promise to the `lookup` option in `socket.connect(...)`",
        "body": "The `socket.connect(...)` accepts the `lookup` option only as a callback-style function. \r\n\r\nNowadays all modern APIs use promises. IMO it should accept promises too. What do you think about it?\r\n\r\nI see there is an experimental Promise API for the `dns` module. Will the old `dns` module be replaced by promises?",
        "labels": "feature request",
        "id": 43243
    },
    {
        "title": "When http header size limit is reached, instead of a generic 400 response, return 431 Request Header Fields Too Large",
        "body": "We overlooked a Node security [release](https://nodejs.org/en/blog/vulnerability/november-2018-security-releases/#denial-of-service-with-large-http-headers-cve-2018-12121) in November 2018 that downsized the max http header size limit to 8192 bytes.\r\n\r\nAfter a Node bump we occasionally saw 400s in production due to large cookies but the response contained no body or interesting headers, all we got is a generic 400 http error code. Is there a good reason for this?\r\n\r\nWe solved the problem eventually but it would of been nice if the HTTP response body gave text explanation of the error. For example `Max HTTP header size of ${maxHttpHeaderSize} reached`. \r\n\r\nThanks.",
        "labels": "feature request",
        "id": 43244
    },
    {
        "title": "UWP/Microsoft Store package",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nNo.\r\n\r\n**Describe the solution you'd like**\r\nBring Node.JS to the Microsoft Store as a UWP package.\r\nWith new Store policies, Node.JS should have little to no limitations if brought to the Microsoft Store. Bringing the Node.JS runtime environment to the Store will allow Windows 10 S and S-Mode users to take advantage of the program and ensure reliability and updates on Windows 10 machines.\r\n",
        "labels": "feature request",
        "id": 43245
    },
    {
        "title": "Missing process functions under workers should throw explicit error",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nJest calls [`mkdirp`](https://npmjs.com/package/mkdirp) during its unit tests. Jest has also recently added support for `worker_threads`. However, when I wanted to try it out, hundreds of tests failed with `TypeError: process.umask is not a function`\r\n\r\nIt turn out `mkdirp` uses `process.umask()` if no `mode` is provided: https://github.com/substack/node-mkdirp/blob/f2003bbcffa80f8c9744579fabab1212fc84545a/index.js#L64\r\n\r\nI've since found that this function missing in `worker_threads` is well documented: https://nodejs.org/api/worker_threads.html#worker_threads_class_worker\r\n\r\n>`process.chdir()` and `process` methods that set group or user ids are not available.\r\n\r\n**Describe the solution you'd like**\r\nIf node could throw \"`process.umask` is not available in worker threads\" or similar it would have made my debugging way easier, rather than the function just be missing.\r\n\r\nI'm not sure how that would play with `typeof process.umask === 'function'` checks people might have?\r\n\r\n**Describe alternatives you've considered**\r\nMy solution was to pass `777` as mode explicitly to `mkdirp`, but a clearer error would have made the debugging way easier.\r\n\r\nMy use case might be a bit special since Jest reconstructs a fake `process` object for every single test (by inspecting the real one), so my rabbit hole before checking worker docs were probably deeper than most people in the same situation. I was also testing node 12 (where threads are unflagged), so I wasn't even aware I was running in threads at first.",
        "labels": "feature request",
        "id": 43246
    },
    {
        "title": "crypto - expose partial state of hash functions",
        "body": "I need to save status of the hashing (in case it is interrupted).\r\n\r\nvar hash = crypto.createHash('sha1');\r\n...\r\nhash.update(buffer);\r\n...\r\n**Now I need to save the hash object.**\r\n...\r\n**Later, I want to load the hash object and continue hashing.**",
        "labels": "feature request",
        "id": 43247
    },
    {
        "title": "NAPI: call stack manipulation from native world + more specific throw",
        "body": "With NAPI, stack traces should show more, than just the entrypoint into native world. It would be awesome, if we could put frames onto call stack with NAPI, to somehow exhibit native side, especially when we throw and need to find where it happened.\r\n\r\nExample:\r\nWhen I use `node-addon-api` ObjectWrap and throw an error with \"a bad message\" from ctor, because some args are missing, then what I get is not very helpful:\r\n\r\n```\r\nthis._myobj = new MyClass();\r\n              ^\r\n\r\nError: a bad message\r\n     at new MyClass (.../src/MyClass.js:6:19)\r\n```\r\n\r\nBetter would be sth. like\r\n```\r\nNAPI_THROW(Env(), \"a bad message\")\r\n^\r\n\r\nError: a bad message\r\n     at NAPI_THROW (.../src/MyClass.cc:21:7)\r\n     at MyClass::MyClass(const Napi::Callback& info) (.../src/MyClass.cc:17:3)\r\n     at new MyClass (.../src/MyClass.js:6:19)\r\n```\r\n\r\nI don't think, only the message should be the critical part of an error, but also the call stack to find it. I thought of sth. like this:\r\n\r\n*issue actually addresses 2 features requests*\r\n\r\n#### 1. stack manipulation\r\n- `napi_push_callstack`, `napi_pop_callstack` and analogous a RAII object of `Napi::CallStack`\r\n- `Napi::CallStack` can be a noop for NDEBUG\r\n\r\n#### 2. better throw\r\n- a more specific throw like `napi_throw_error_from(..., __FILE__, __LINE__)`\r\n- providing some macros that will help\r\n\r\nWhat do you think?",
        "labels": "feature request",
        "id": 43248
    },
    {
        "title": "Add `input` option to async child_process methods",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen spawning a child process, it's common to want to send some data to the process' stdin. Usually, a string or buffer. This can be done by writing to the stdin stream:\r\n\r\n```js\r\nconst {execFile} = require('child_process');\r\n\r\nconst child = execFile('node', (error, stdout, stderr) => {\r\n\tif (error) {\r\n\t\tthrow error;\r\n\t}\r\n\tconsole.log(stdout);\r\n});\r\n\r\nchild.stdin.write('foo');\r\nchild.stdin.end();\r\n```\r\n\r\nHowever, that's a bit verbose and not that obvious. It's also easy to forget to call `.end()`, see https://github.com/nodejs/node/issues/2339.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI propose the async `child_process` methods get an `input` option for convenience. Just like the [synchronous methods already have](https://nodejs.org/api/child_process.html#child_process_child_process_execfilesync_file_args_options).\r\n\r\n```js\r\nconst {execFile} = require('child_process');\r\n\r\nexecFile('node', {input: 'foo'}, (error, stdout, stderr) => {\r\n\tif (error) {\r\n\t\tthrow error;\r\n\t}\r\n\tconsole.log(stdout);\r\n});\r\n```\r\n\r\nThis will also improve the stdin situation when a `child_process` method is promisified, as it then returns a `Promise<Object>` with `stdout` and `stdin` instead of the `ChildProcess` object.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nI could create a `child_process` wrapper that does this, however, I have already done that: https://github.com/sindresorhus/execa#input But I would like to upstream some of the most useful ideas from that package.\r\n\r\n---\r\n\r\n// @floatdrop @Qix-",
        "labels": "feature request",
        "id": 43249
    },
    {
        "title": "--inspect race condition",
        "body": "* **Version**: v8.14.0\r\n* **Platform**: Linux outpost 3.13.0-100-generic #147-Ubuntu SMP Tue Oct 18 16:48:51 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\nn\r\n* **Subsystem**: Inspector\r\n\r\nThe activation of the `--inspect` cmd option is subject to race condition. To reproduce:\r\n1) Create a file, called `debugger.js` with the content:\r\n```js\r\ndebugger\r\n\r\nsetTimeout(() => { debugger }, 10)\r\n\r\nsetTimeout(() => { debugger }, 50)\r\n\r\nsetTimeout(() => { debugger }, 100)\r\n\r\nsetTimeout(() => { debugger }, 200)\r\n\r\nsetTimeout(() => { debugger }, 300)\r\n```\r\n2) Launch it first with:\r\n`node --inspect-brk debugger.js`\r\nto open the Inspector window in the Chrome dev tools\r\n\r\n3) Then launch it several times with:\r\n`node --inspect debugger.js`\r\n\r\n4) Observe most of the times ALL breakpoints are ignored, sometimes ALL are activated, sometimes only the one with 300ms delay.\r\n\r\n5) Expected behavior - all breakpoints are expected to always be honored, including the very 1st one.",
        "labels": "feature request",
        "id": 43250
    },
    {
        "title": "Startup time optimization - specifying location of node_modules",
        "body": "I am guessing that node.js startup could be optimized if we specify the (only) location of node_modules. I believe that the fs gets peppered with stat requests on startup, but if we had something like this:\r\n\r\n```bash\r\n$ node --nm=\"./node_modules\" dist/main.js\r\n```\r\n\r\nthen when non-relative require statements were evaluated, they could jump to the location specified by `--nm`, this might save hundreds of stat calls on startup?\r\n\r\nI would venture to guess that 95% of npm projects only have one relevant node_modules dir, so walking up the filesystem for nested files could be optimized.\r\n\r\nI would guess that there may already be some optimization for this in place, where directories are marked as not having a node_modules dir within them on first pass, but maybe there's more optimization to be had?",
        "labels": "feature request",
        "id": 43251
    },
    {
        "title": "Request for warning documentation",
        "body": "I would like to request documentation for NodeJS warnings. I've searched for a list of them just like the one available for Errors but to no avail. If the docs do exist please point me into the right direction.",
        "labels": "feature request",
        "id": 43252
    },
    {
        "title": "Provide a way of getting a file's real path",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nRight now, given a user-provided file path, there's no (efficient) way of getting that file's real path on disk. On Linux *et al* these are always the same thing (modulo `.` and `..` path components which can be resolved without OS intervention), but Windows and some OS X systems have case-insensitive filesystems where a file named `FILE.TXT` can be referred to by the path `file.txt`. Worse yet, some servers appear to only serve the files in question if the case matches exactly, even when the underlying filesystem is case sensitive (see https://github.com/sass/dart-sass/issues/540).\r\n\r\n**Describe the solution you'd like**\r\n\r\nI'd like a function, something like `fs.realCasePath()`, that takes a path and returns the canonical path on disk using [`FindFirstFileA`](https://docs.microsoft.com/en-us/windows/desktop/api/fileapi/nf-fileapi-findfirstfilea) on Windows and [`fcntl` with `F_GETPATH`](http://www.manpagez.com/man/2/fcntl/) on Unixes.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nRight now this can be worked around using `fs.readdir()` and manually filtering the files, but this is much more expensive than a single O(1) syscall.\r\n\r\n`fs.realpath.native()` *almost* does the right thing, but it also resolves symbolic links which is not desirable here.",
        "labels": "feature request",
        "id": 43253
    },
    {
        "title": "cli: make ^C print a JS stack trace",
        "body": "It would be exceedingly nice for debugging non-responsive scripts if terminating the process with ^C / SIGINT prints a JS stack trace leading up to the currently executing code.\r\n\r\nThe use case is scripts stuck in (for example) infinite loops. Right now you don't really get an indication when that's happening except CPU usage in top.\r\n\r\nIt might be hard to pull off because signal handlers but maybe someone has a clever idea. My attempt at being clever:\r\n\r\n1. Route signals to a watchdog thread instead of the main thread\r\n2. Call `isolate->RequestInterrupt()` when a signal is received.\r\n3. Collect the stack trace in the interrupt handler.\r\n4. Either re-raise the signal on the main thread to terminate as usual, or raise a termination exception to kill the script.",
        "labels": "feature request",
        "id": 43254
    },
    {
        "title": "Feature request: a way to keep .js extensions with ES module files",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nI'd like to keep using `.js` extensions with ES modules.\r\n\r\n**Describe the solution you'd like**\r\n\r\nBesides giving us the option to convert them to `.mjs`, can you also perhaps give us an option to place them in a special folder, perhaps one called `mjs` (or something) where the files in that folders are all treated as ES modules but can have `.js` extensions?\r\n\r\n",
        "labels": "feature request",
        "id": 43255
    },
    {
        "title": "Feature Request: Package Permissions",
        "body": "## Problem: Malicious packages\r\n\r\nWith the recent news of the `event-stream/flatmap-stream` attack ([summary](https://schneid.io/blog/event-stream-vulnerability-explained/?no-cache=1)), it seems like now would be a good time to discuss defending against these kind of attacks.\r\n\r\nPresently available defences:\r\n1. use a lockfile\r\n2. fully audit the published code of entire dependency tree\r\n\r\nWhile a lockfile is generally good practice, it would require auditing to be effective. There lies the issue, auditing is not feasible. Dependency graphs are too large in most modern projects to effectively audit manually.\r\n\r\n## Suggestion\r\n\r\nOne defence is to introduce permissions for node core modules such as `fs`, `http`, `process`, and others.\r\nA `package.json` would need to specify which core modules it uses, ex:\r\n```\r\n{\r\n  \"name\": \"package-name\",\r\n  \"version\": \"1.0.0\",\r\n  \"description\": \"\",\r\n  \"main\": \"index.js\",\r\n  \"permissions\": [\r\n    \"fs\"\r\n  ]\r\n}\r\n```\r\nRestrict import/require such that requiring `http` in this package would throw an error, but `fs` would be permitted.\r\n\r\nEach package would be provided a uniquely restricted import/require.\r\n\r\nFor backwards compatibility packages without a permissions, would be considered to have all permissions. This could be deprecated in favour of always requiring a permissions field.\r\n\r\nAdditionally tooling could be developed for package managers such as yarn and npm. Users could be alerted when permissions have changed anywhere in their dependency graph. Upon install of a dependency the user could be prompted with accepting the permissions for all packages added to the dependency graph.\r\n\r\nThis is not intended to eliminate the need for auditing, but could reduce the amount of packages needing audits to a reasonable level.\r\n\r\n## Outstanding Issues\r\n\r\n- What to do with C++ addons? Being able to identify them as such may be enough, during install the user could be warned that module has full access to their system (equivalent to all permissions).\r\n- Permissions of main package during development, build scripts, ect.\r\n\r\n## Other Defences\r\n\r\n- Content security policy / sandboxing (restrict access to white-listed directories, and domains)\r\n",
        "labels": "feature request",
        "id": 43256
    },
    {
        "title": "node option to run without console on Windows",
        "body": "Is it possible to add option to node v10 and later to run it without Windows console (as a result without extra conhost.exe process and with process.stdout.isTTY == false)?",
        "labels": "feature request",
        "id": 43257
    },
    {
        "title": "Expose a way to restrict openssl signature algorithms",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWe are attempting to restrict client signature algorithms in node.js tls client. Since tls.createSecureContext does not expose an option to specify neither signature algorithms nor client signature algorithms, we've attempted to do so via a custom openssl configuration file (see example below), but unfortunately it does not work. Upon some investigation it looks like node is not calling SSL_CTX_config after [creating the context](https://github.com/nodejs/node/blob/74fb02f689e5e5f911c3a85faf3cdddcd316e076/src/node_crypto.cc#L638). \r\n\r\n```\r\nopenssl_conf = default_conf\r\n\r\n[default_conf]\r\n\r\nssl_conf = ssl_sect\r\n\r\n[ssl_sect]\r\n\r\nsystem_default = ssl_default_sect\r\n\r\n[ssl_default_sect]\r\n\r\nClientSignatureAlgorithms = ECDSA+SHA256\r\nSignatureAlgorithms = ECDSA+SHA256\r\n```\r\n\r\n**Describe the solution you'd like**\r\nWe would prefer for the above to work as described - all configuration from a configuration file supplied to node via --openssl-config option (or env variable) should be applicable.\r\nAdditionally, these options should be exposed in tls.createSecureContext\r\n\r\n**Describe alternatives you've considered**\r\nThe only alternative solution as of now is to use custom built openssl\r\n",
        "labels": "feature request",
        "id": 43258
    },
    {
        "title": "Could there be an equivalent of `createRequireFromPath` for imports?",
        "body": "Currently, there's a clear story for creating a `require` from a dummy module: [`module.createRequireFromPath(filename)`](https://nodejs.org/api/modules.html#modules_module_createrequirefrompath_filename). It'd be amazingly useful to have an equivalent `module.createImportFromPath(filename)` that did the same, but instead returned a function mirroring dynamic import. Of course, this would only be exposed with `--experimental-modules`, but I kind of need the functionality today if I don't want to basically duplicate Node's own internal mechanism for resolving imports.",
        "labels": "feature request",
        "id": 43259
    },
    {
        "title": "behaviour of Buffer.from(string[, encoding]) is not specified for invalid input",
        "body": "for example\r\n```\r\nâžœ  node\r\n> Buffer.from(\"LOL\", \"hex\")\r\n<Buffer >\r\n> Buffer.from(\"LOL#$%^&*(\", \"hex\")\r\n<Buffer >\r\n> Buffer.byteLength(\"LOL#$%^&*(\", \"hex\")\r\n5\r\n> Buffer.byteLength(\"0x8\", \"hex\")\r\n1\r\n> Buffer.from(\"0x8\", \"hex\")\r\n<Buffer >\r\n> Buffer.from(\"qqq0x8123132\", \"hex\")\r\n<Buffer >\r\n> Buffer.from(\"110x8123132\", \"hex\")\r\n<Buffer 11>\r\n> Buffer.from(\"1_-10x8123132\", \"hex\")\r\n<Buffer >\r\n```\r\n\r\nIn general Buffer.from returns trash if input string is is not valid, and it could be a source if error/bugs.  in node v7 this it was throwing `TypeError: Invalid hex string` but now it isn't.\r\n\r\n* **Version**:\r\nv8.12.0\r\n* **Platform**:\r\nDarwin Iraklis-MacBook-Pro-2.local 18.0.0 Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64\r\n\r\n\r\nRelated to #8569 but it's not a feature request it's a bug report as I consider this to be a bug and instead of adding safeFrom this default one should be safe and if people need there should be `unsafeFrom`.\r\n",
        "labels": "feature request",
        "id": 43260
    },
    {
        "title": "Support pausing the debugger on script load",
        "body": "There is a Node debugging scenario that doesn't work very well in vscode (or chrome devtools), but does in debugging Chrome, and I want to start a discussion about how we can improve this. \r\n\r\nTypically when debugging a Node project with sourcemaps, the scripts are transpiled to disk, vscode's launch config points at these files with the \"outFiles\" parameter, then vscode preloads the sourcemaps so it can set breakpoints in the correct locations before the scripts are actually loaded.\r\n\r\nBut there is a scenario where scripts are transpiled on demand, so vscode can't preload their sourcemaps, and can't set breakpoints at the right spots in those scripts until some time after they are loaded. This means that the breakpoints may not be hit, due to the race between running the code and setting the breakpoint at the same time. The best way for vscode to deal with this would be to have node pause execution each time a script is loaded, giving it a chance to load its sourcemaps and set the breakpoint before running the code in the script.\r\n\r\nThe Chrome devtools protocol for Chrome actually gives us a way to pause execution each time a script is loaded, via https://chromedevtools.github.io/devtools-protocol/1-3/DOMDebugger#method-setEventListenerBreakpoint. But this is in the DOMDebugger domain which doesn't exist in Node. \r\n\r\nSo what do you think it would take to get an api like this for node as well? Can nodejs implement a subset of the DOMDebugger domain, does a new domain need to be defined? Or maybe someone has an idea for another solution entirely.",
        "labels": "feature request",
        "id": 43261
    },
    {
        "title": "request for 'id' api to resolve uid to username",
        "body": "Hello, I've written an extension of `fs.stat` ([extrastat](https://github.com/mixint/extrastat)) that gives me MIME types and a human readable 'permissions mode' for a project that presents the file system via web interface, and while stat gives me uid and gid of the file owners, I'm wishing there was a function that could resolve those numbers to username and groupname.\r\n\r\nThe ideal solution would be a call to the `id` utility and returning an object containing all its info. Such that,\r\n```\r\nuid=501(coltenjackson) gid=20(staff) groups=20(staff),12(everyone),80(admin)\r\n```\r\nbecomes...\r\n```json\r\n{\r\n    \"uid\": {\r\n        \"501\": \"coltenjackson\"\r\n    },\r\n    \"gid\": {\r\n    \t\"20\": \"staff\"\r\n    },\r\n    \"groups\": {\r\n    \t\"20\":\"staff\",\r\n    \t\"12\": \"everyone\",\r\n    \t\"80\": \"admin\"\r\n    }\r\n}\r\n```\r\nYou could pass a number or username as first argument \r\nWithout something available in Node, I'll be using child_process.exec and performing regex on the stdout.\r\n\r\nThanks for your consideration",
        "labels": "feature request",
        "id": 43262
    },
    {
        "title": "Feature request: Support create public key from components method?",
        "body": "I cannot use `ursa` anymore at node v10. So I'm trying to move to native crypto. \r\nBut the problem is, native crypto seems not support create public key from components. \r\n\r\nSo, why don't you support create public key from components method?\r\n\r\n----\r\n- [ursa can create public key](https://www.npmjs.com/package/ursa#ursacreatepublickeyfromcomponentsmodulus-exponent) like this,\r\n\r\n```node\r\nconst ursa = require('ursa');\r\n\r\n// modulus should be a base64/base64Url string\r\nconst modulus = new Buffer(modulusStr, 'base64');\r\n// exponent should be base64/base64url\r\nconst exponent = new Buffer('AQAB', 'base64');\r\n\r\nconst pubKey = ursa.createPublicKeyFromComponents(modulus, exponent);\r\nconsole.info(pubKey.toPublicPem('utf8')); \r\n// ------BEGIN PUBLIC KEY------\r\n// ...\r\n```\r\n\r\n- [node-rsa](https://www.npmjs.com/package/node-rsa) way\r\n```node\r\nconst nodeRSA = require('node-rsa');\r\nconst key = new nodeRSA();\r\n\r\nconst modulus = new Buffer(modulusStr, 'base64');\r\nconst exponent = new Buffer('AQAB', 'base64');\r\n\r\nconst pubKey = key.importKey({ n: modulus, e: exponent }, 'components-public');\r\nconsole.info(pubKey.exportKey('pkcs8-public-pem'));\r\n// ------BEGIN PUBLIC KEY------\r\n// ...\r\n```",
        "labels": "feature request",
        "id": 43263
    },
    {
        "title": "import.meta.dirname",
        "body": "Hi! From the specs for import.meta I can see that it specifies that host supplied data can be provided. `__dirname` has served us well. `import.meta.url` is very clunky to use. Will you provide an `import.meta.dirname`?",
        "labels": "feature request",
        "id": 43264
    },
    {
        "title": "Ability to constrain the total heap used by v8 and Node.js (--max-heap-size)",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nRunning NodeJS applications in a memory-constraining environment like Kubernetes is today problematic, because there is no way to tell NodeJS (and the v8 GC) how much *total* memory it has to work with. `--max-old-space-size` is a good start, but due to the way `Buffer` uses memory allocated outside of v8's heap (called \"external memory\"), this is not enough.\r\n\r\nThe problem in essence is this: when running under a memory constraint (i.e. docker/k8s limiting the process' memory), one can specify `--max-old-space-size` that is below the memory constraint, have memory that is below that usage, and yet the process still gets OOMKilled, because most of that memory lives in `Buffer`-s, and thus in the external heap, which v8 does not know about and thus does not feel like it needs to trigger a GC.\r\n\r\nI created a Github repo that reproduces this problem: https://github.com/giltayar/node-memory-constraining-problem. Follow the README to reproduce the problem and to see a more in depth examination of this problem.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI would like a `--max-heap-size` parameter to NodeJS that constrains v8's heaps *and* the external heap to not pass a specified limit.\r\n\r\nThis solution was proposed by @psmarshall and @bmeurer from the v8 team after discussing the problem with them.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nA `--max-external-heap-size` parameter that constrains the external memory size used by `Buffer` and others.\r\n",
        "labels": "feature request",
        "id": 43265
    },
    {
        "title": "About native support for typescript!!",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nNo.\r\n\r\n**Describe the solution you'd like**\r\nAre you planing to support typescript natively? something like ```node main.ts```\r\nI know that it's possible to execute basic ```.ts``` files with node but ```es6``` and ```es7``` features not supported, I also know that it's not related to ```node```engine itself it's related to ```v8``` engine but it can be done with ```node``` and it's going to be great feature of course.\r\n\r\n**Describe alternatives you've considered**\r\n1- embed the compiling stage in memory at the runtime something like the ```JIT```s.\r\n2- add ```es6``` and ```es7``` features support as ```v8``` engine extensions - *No compiling at all*.\r\n",
        "labels": "feature request",
        "id": 43266
    },
    {
        "title": "Ability to check TLS contexts, servernames, altnames",
        "body": "We have `server.addContext(hostname, context)`, but we don't have a `server.getContext(hostname)`.\r\n\r\nWhy?\r\n------\r\n\r\nNow, that might seem rather silly, but let me explain why it would be important to have this:\r\n\r\nThere's a type of spoofing known as _Domain Fronting_ where the attacker creates a TLS session with one SNI, but once connected they send a different HTTP Host header (more info on a bug I created including this at https://github.com/nodejs/node/issues/22389).\r\n\r\nThere's an RFC that specifically prohibits this behavior, which many cloud platforms follow, but node does not currently follow.\r\n\r\nHowever, there's a catch. Another RFC in relation to HTTP/2 contradicts the former and suggests reusing the same TLS connection for a different servername when the certificate in the session includes the new servername (more info at https://www.ietf.org/mail-archive/web/httpbisa/current/msg28781.html).\r\n\r\nCurrent versions of Firefox actually follow the second spec presently.\r\n\r\nI want to block domain fronting, but not to the exclusion of allowing Firefox to reuse tls sessions.\r\n\r\nCurrently I'm checking that the `Host` header matches the `tlsSocket.servername` (when it exists), but in order to support Firefox I need to know the `altnames` (SAN) as well, but I haven't been able to figure out a way to get that information from the socket.\r\n\r\nI'm looking for another workaround, but this seems like something that node could reasonably expose in a future version to make such checks easier.",
        "labels": "feature request",
        "id": 43267
    },
    {
        "title": "AEAD_CHACHA20_POLY1305 support",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nNot really a  problem, I'm trying to write some networking stuff which using AEAD_CHACHA20_POLY1305([rfc7539](https://tools.ietf.org/html/rfc7539)).\r\nAs far as I know, OpenSSL should support that since 1.1 .\r\n\r\nActually I have written some code to support it, and a PR will be sent.\r\n\r\n**Describe the solution you'd like**\r\n\r\nUsing `chacha20-poly1305` In AEAD mode (node only support GCM, CCM and OCB now.)\r\n\r\n**Describe alternatives you've considered**\r\n\r\nAll workaround are good to me( maybe some npm packages, but since openssl has ability to do this, supported by node is the best solution).\r\n",
        "labels": "feature request",
        "id": 43268
    },
    {
        "title": "Add eventfd support to new net.Socket({ fd : eventfd})",
        "body": "It will be nice to receive asynchronous notifications from a C native addon thread using an eventfd. Currently you can do the following:\r\n\r\n```js\r\nconst eventfd = nativeAddon.getEventfd()  // call eventfd() inside the addon and return it\r\nconst num = Buffer.alloc(8)\r\nfs.read(eventfd, num, 0, 8, null, () => { ..... } )\r\n```\r\n\r\nThis works ok, but `fs.read` will block a thread from the uv worker thread pool until a notification is sent from the addon. That's a waste and can block other tasks.\r\n\r\nA possible solution is to add support for doing something like:\r\n\r\n```js\r\nconst eventfd = nativeAddon.getEventfd() \r\nconst s = new net.Socket({ fd : eventfd, writeable : false, readable : true })\r\ns.on('data', () => {..... })\r\n```\r\n\r\nBy implementing a `eventfd_wrap.cc` analogous to `pipe_wrap.cc`.\r\n\r\nNote, I know about `uv_async_send(...)` et al, but I think this mechanism is simpler for some of my use cases.\r\n\r\n",
        "labels": "feature request",
        "id": 43269
    },
    {
        "title": "Discussion: How should the Node executable + Node shared library be distributed?",
        "body": "One thing that came up in [this issue](https://github.com/nodejs/node/issues/23265) was, if the default Node distributions were to ship with a shared build, how should it be structured?\r\n\r\nBasically boils down to:\r\n\r\n * Should the `node` executable just be a small binary that links against `libnode` OR\r\n * Should the distribution ship with a statically linked `node` executable with no shared dependencies, and a separate `libnode` that users can link against?\r\n\r\nDiscussion was pretty contentious and I think it is worth its own issue!",
        "labels": "feature request",
        "id": 43270
    },
    {
        "title": "native ability to strip comments in JSON",
        "body": "This might get vetoed, but I have a case where I can't really easily load node_modules, but I have JSON files to load, and those .json files have comments in them.\r\n\r\nSo I am looking for a way to load those files and strip the comments:\r\n\r\n```js\r\nconst foo = require('./foo.json', {stripComments: true});\r\n```\r\n\r\nI don't think most people want to put this in core, but I am not sure what to do in my case since I can't easily load node_modules deps.\r\n\r\nOn this same subject, I have an idea, I know about Ryan Dahl's cute mistake of not requireing a full path, aka, require('./foo') could be require('./foo.js') or just a file called foo.\r\n\r\nOne solution could be \r\n\r\n```js\r\nconst foo = require('./foo.json', {full: true});\r\n```\r\n\r\nwhich means the above would only look for `foo.json`, and would not look for `foo.json.js`\r\n\r\nwith import syntax, that might mean:\r\n\r\n```js\r\nimport * as foo from './foo.json' {full:true}\r\n```\r\nlol not sure if that works\r\n",
        "labels": "feature request",
        "id": 43271
    },
    {
        "title": "docs: When using the \"Edit on GitHub\" button references to the guides are not obvious",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: current\r\n* **Platform**: web\r\n* **Subsystem**: doc\r\n\r\n<!-- Please provide more details below this comment. -->\r\n> Perhaps the only thing I could note (if it's of any use in improving the docs' \"Edit on GitHub\" process) is that I don't believe I was alerted, when submitting the PR, to the fact that a style guide existed for the docs, against which I could check any amendments I was suggesting.\r\n\r\nWhen clicking the ![image](https://user-images.githubusercontent.com/96947/47798074-021c1980-dcfe-11e8-8698-3a2d93098172.png) button, the user is directed to the edit view in GitHub. There is no reference to the [Docs Style Guide](https://github.com/nodejs/node/blob/master/doc/STYLE_GUIDE.md), and when submitting the PR the referance to the [Contributing Guide](https://github.com/nodejs/node/blob/master/CONTRIBUTING.md) is easy to miss.\r\n\r\nIdeas for improvement will be most appreciated.\r\n\r\nRefs: https://github.com/nodejs/node/pull/23970#issuecomment-434528701\r\nRefs: https://github.com/nodejs/node/pull/21703\r\n\r\n/CC @nodejs/documentation @nodejs/website ",
        "labels": "feature request",
        "id": 43272
    },
    {
        "title": "vm.compileFunction should return an object",
        "body": "At https://github.com/nodejs/node/pull/23837#discussion_r228006947, @jdalton proposed that instead of returning a function with certain special properties, `vm.compileFunction` should instead return an object with the said properties and the function stored as the `value` property on the object.\r\n\r\nThis approach was infact discussed during the design phase of `compileFunction`, and I agree that either approach has it's own merits, but I decided to go with the status quo because it was consistent with similar functions in the vm module and consistency is really important IMO.\r\n\r\nI'm opening this issue as suggested by @jdalton to open a discussion regarding what the best way to return information from these functions will be, moving forward.\r\n\r\nI have three options in mind:\r\n1. Continue with the status quo (consistent).\r\n2. Make `vm.compileFunction` return an Object (inconsistent).\r\n3. Make all similar functions return Objects (consistent).\r\n\r\nFeel free to back one of the above or suggest something else entirely. The updates (if any) will have to be semver-major, but thankfully vm is probably one of the least used modules externally (vs internally).",
        "labels": "feature request",
        "id": 43273
    },
    {
        "title": "Free memory displayed instead of Available memory (not reality)",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v` \r\n\r\n**_v10.1.0_**\r\n\r\n\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\n**_linux centos 64bits_**\r\n\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\nI think there is no need to provide something because it will be clear in your module you retrieve the free memory os.freemem(), but the problem in linux /UNIX there is free memory and available memory , free memory don't take buffer/cache size memory and it is important because the real memory is not the free but the available\r\n\r\nlinux when see there is free memory (available) it will take it to not use disk (it increase performance) but when some application need memory, the buffer will be released and then i we see only 20 Mo free but 2g available memory in 2g will be used when needed\r\n\r\nexample\r\n\r\nwhen buffer use some memory\r\n\r\n![image](https://user-images.githubusercontent.com/3234598/47549714-36a66480-d8fd-11e8-92ec-43e2fc92549e.png)\r\n\r\n\r\nwhen buffer release memory(application need it, or you launch release command)\r\n\r\n![image](https://user-images.githubusercontent.com/3234598/47549784-67869980-d8fd-11e8-8027-abef0af204a1.png)\r\n\r\n\r\nmaybe you can add available memory to be retrieved because this lib is used in pm2-gui for example and monitor show 90 % used memory but it is not the truth, (calcul total-free) but reality either you retrieve the used memory directly... either you retrieved available and not free memory ? or all values it will be better ? \r\n\r\nwhant do you think ? \r\n\r\ngreat librabry !",
        "labels": "feature request",
        "id": 43274
    },
    {
        "title": "why binding.WriteBuffers is not available from api ?",
        "body": "fs.write() uses process.binding('fs').writeBuffer call but fs.WriteStream can use process.binding('fs').writeBuffers which is more efficient in case when there are multiple chunks for writing. Is there a reason why passing multiple chunks with usage of writeBuffers this is not available for users from fs api ?",
        "labels": "feature request",
        "id": 43275
    },
    {
        "title": "Hashbang not resolving `--loader` relative to entry",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 11.0\r\n* **Platform**: macOS 10.14 (18A389)\r\n* **Subsystem**: bootstrap, `--experimental-modules` (only)\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhen using shebangs to specify `--loader` specifically for `--experimental-modules` a file could want to use a relative path to it's own loader file.\r\n\r\nIn this specific case, the module file is it's own loader, as if things are not already complicated enough.\r\n\r\n```js\r\n#!/usr/bin/env node --experimental-modules --loader ./index.mjs\r\n\r\nexport function resolve(... args) {\r\n  // â€¦\r\n  if (resolved.url === import.meta.url) resolve.url += '#initialize';\r\n  return resolved;\r\n}\r\n\r\nfunction bootstrap() {\r\n  // â€¦ \r\n}\r\n\r\nimport.meta.url.endsWith('#initialize') && bootstrap();\r\n```\r\n\r\nThe issue is not related to modules down the road, it is strictly related to the current way relative `--loader` paths are resolved.\r\n\r\nExecuting this file from other paths other than it's own directory looks for `./index.mjs` in the cwd and not the file's own directory.\r\n\r\nI believe that Loader being a variable aspect of a shebang is at least problematic, more so risky, and simply not practical (I could be wrong).\r\n\r\nCan we fix (or justify) this bug (or feature) please?",
        "labels": "feature request",
        "id": 43276
    },
    {
        "title": "Create a flag to know when stream has reached it's last chunk from within _transform.",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v9.3.0\r\n* **Platform**: Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: Stream.Transform\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nI'm using a transform stream in the following way.\r\n\r\n```js\r\n        var transformStream = new Stream.Transform({ writableObjectMode: true, readableObjectMode: true})\r\n        transformStream._transform = function (chunk, encoding, done) {\r\n            \r\n            recordCount++\r\n\r\n            if (transform) chunk = transform(chunk)\r\n\r\n            let jsonChunk = JSON.stringify([chunk])\r\n\r\n            switch (true) {\r\n                case this._writableState.ended:\r\n                    jsonChunk = jsonChunk.slice(1, jsonChunk.length); break\r\n                case recordCount === 1: \r\n                    jsonChunk = jsonChunk.slice(0, jsonChunk.length - 1) + ','; break\r\n                default:\r\n                    jsonChunk = jsonChunk.slice(1, jsonChunk.length - 1) + ','; break\r\n            }\r\n            this.push(jsonChunk)\r\n            done();\r\n        };\r\n```\r\n\r\n\r\nI've tried this with 1 record to see if there are any properties that change when the stream has reached it's last record. I can't find any that change. I'm using this stream to stringify json and then pipe it into gzip so that I can persist the compressed responses. I really need help to know when the stream has reached it's last record. Any help would be greatly appreciated.\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43277
    },
    {
        "title": "add duration argument to timeout.refresh()",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI have seen a new feature on timeout in node  v10.2.\r\nNow we can refresh a timer. This will restart/refresh the timer.\r\nBut always with the initial timeout value.\r\n\r\n**Describe the solution you'd like**\r\nI would like to know if it would be possible to add an argument to refresh method\r\nto change the new delay.\r\nAnd if not given, just use the previous value as for now.\r\n\r\n**Describe alternatives you've considered**\r\nno idea\r\n",
        "labels": "feature request",
        "id": 43278
    },
    {
        "title": "util inspect formatter implementer",
        "body": "I am looking to solve this problem without using a regex:\r\nhttps://stackoverflow.com/questions/52786707/util-inspect-make-string-red-if-number-is-0\r\n\r\nbasically, I am looking for something like:\r\n\r\n```js\r\nutil.inspect(v, {\r\n  formatters: {\r\n     number(n){\r\n       return n === 0 ? 'red' : 'yellow'\r\n    }\r\n  }\r\n})\r\n```\r\n\r\nso formmaters would be a hash of functions, where the key was the type of the input, and the user could return some way to tell util how to format the type.\r\n\r\nBasically, I want 0s to be red, but non-zeros to be yellow for a certain use case, etc.\r\n\r\nSo generically, it might look like:\r\n\r\n```js\r\nutil.inspect(v, {\r\n  formatters: {\r\n     number(n){\r\n       return n === 0 ? 'red' : 'yellow'\r\n    },\r\n     string(s){\r\n      // ....\r\n    },\r\n     boolean(b){\r\n      // ....\r\n    }\r\n  }\r\n});\r\n\r\n// etc\r\n\r\n```",
        "labels": "feature request",
        "id": 43279
    },
    {
        "title": "path: add Buffer support in path methods",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nPR #5616 gave us support for Buffer paths in all fs methods, primarily to allow interacting with files of unknown or invalid file encoding. One frustration has been that the path methods, which are often used in conjunction with fs methods, only accept strings. This makes it difficult to perform many higher-level fs operations in a Buffer-based (and therefore encoding agnostic) way, such as recursive move / copy / remove.\r\n\r\n**Describe the solution you'd like**\r\nIdeally, I would think that the path methods could be updated to also accept Buffer inputs, similarly to the fs methods, and to give Buffer output when requested. Looking at the current `path.js` code, this seems possible but by no means trivial. The current methods primarily iterate through the input strings character-by-character, looking for special values, so I think a similar method could be used for Buffers, or possibly in a string / Buffer agnostic way.\r\n\r\n**Describe alternatives you've considered**\r\nMaking these path methods Buffer-based could be well suited for a user-land module, especially since they are primarily utility methods and there's no interaction with the lower-level system.\r\n",
        "labels": "feature request",
        "id": 43280
    },
    {
        "title": "cluster: implement API for pluggable distribute() for round-robin scheduler #6001",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nClustering combined with something like express is often used as load distribution, making the next available worker process handle a request. What if certain requests are targetted for specific workers?\r\n\r\nThe idea is the master is the controller. Each worker is a long-running process with a variation of a specific job. A REST API might allow control or monitoring of the variables surrounding that job. So any API calls specific to a worker, can just be handled by the worker directly rather than by the API server querying that worker and relaying the message back.\r\n\r\n```\r\n// route these to subprocess x\r\nGET /instances/x/logs\r\nPOST /instances/x/settings\r\n\r\n// route these to subprocess y\r\nGET /instances/y/logs\r\nPOST /instances/y/settings\r\n\r\n// route these to subprocess z\r\nGET /instances/z/logs\r\nPOST /instances/z/settings\r\n\r\n// make a new worker process, returns worker ID as reference\r\nPOST /instances/\r\n```\r\n\r\n**Describe the solution you'd like**\r\nI'm interested in the discussions I found in this old thread:\r\nhttps://github.com/nodejs/node-v0.x-archive/issues/6001\r\n\r\nI'd like to write conditions that decide which worker handles the incoming request. Has this been exposed in any way? I saw a number of discussions but they all seem to have stalled, this may be another one.\r\n\r\n**Describe alternatives you've considered**\r\nTo do so now, you would need to build/implement a message broker to receiving an incoming request for a worker, and pass that on to a worker that has its own API running on its own port.",
        "labels": "feature request",
        "id": 43281
    },
    {
        "title": "os.networkInterfaces() does not expose interface's broadcast address",
        "body": "* **Version**: v11.0.0-pre\r\n* **Platform**: Linux (Ubuntu 16.04.4-LTS)\r\n* **Subsystem**: os\r\n\r\nThe overwhelming majority of network interfaces are Ethernet or Wifi (on servers, almost always Ethernet) which both support broadcasting.  The broadcast address is typically the host address bit-wise ANDed with the net mask, and then bit-wise ORed with the bit-wise complement of the net mask.\r\n\r\nBut not always.  Some arcane network configurations still use zero as the host id to signify the broadcast address (i.e. just the host address bit-wise ANDed with the net mask).\r\n\r\nThat is, for an address such as `192.168.1.12/24` (i.e. net mask of `255.255.255.0`), the broadcast address would typically be `192.168.1.255`.\r\n\r\nThat said, the correct behavior is _always_ to take the broadcast address directly from the interface's configuration state, rather than guessing at it.\r\n\r\nA mechanism to do exactly that is needed.\r\n",
        "labels": "feature request",
        "id": 43282
    },
    {
        "title": "Allow registering multiple uncaught exception capture callbacks",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nWhile experimenting with building [a user-land alternative to the core `domain` module](https://github.com/misterdjules/domaine), I realized that the fact that one can only set one uncaught exception callback makes it more difficult than it could be.\r\n\r\nBasically, the problem is that it is not possible to have two different implementations of a \"domain-like\" module loaded at the same time in a given process. For instance, it is currently not possible to load the user-land `domaine` module along with the core `domain` module.\r\n\r\nThis makes it difficult for applications to start adopting user-land alternatives to `domain`: in the current state, they (and all their dependencies) either need to adopt one single user-land alternative, or stick with the `core` domain module.\r\n\r\nA good example is when I ported restify to use this new `domaine` module instead of the core `domain` module. I had to port `node-tap` (which is used to run restify's tests) to use that new `domaine` module as well.\r\n\r\nAnother example is the fact that one cannot use a user-land domain-like module from within the core repl because it requires `domain`.\r\n\r\nThis is something that I [started discussing with @addaleax](https://github.com/nodejs/node/pull/17159#issuecomment-427208024) but that I thought would benefit from being presented to a broader set of people to gather initial feedback, comments and suggestions.\r\n\r\n**Describe the solution you'd like**\r\n\r\nThe fundamental change would be to allow multiple uncaught exception callbacks to be registered.\r\nI haven't thought too much about the design or the implementation details of a specific solution. I'd first like to gather feedback on whether people would be open to allowing multiple callbacks to be registered.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nThe only alternative to having this feature available that I can see for now is to require applications to migrate their code _and_ all their dependencies to any user-land domain module that they choose to use.\r\n\r\nLooking forward to reading your thoughts!\r\n\r\n/cc @addaleax @vdeturckheim @nodejs/domains ",
        "labels": "feature request",
        "id": 43283
    },
    {
        "title": "HTTP request to HTTPS server causes ERR_EMPTY_RESPONSE instead of error 400 Bad Request",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: Probably any version\r\n* **Platform**: Both Unix/Windows\r\n* **Subsystem**: HTTPS\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nNodejs HTTPS server requested using HTTP causes ERR_EMPTY_RESPONSE instead of some regular error.  Run nodejs with this code:\r\n\r\n```\r\nvar fs = require('fs');\r\nvar https = require('https');\r\nvar options = {\r\n    key : fs.readFileSync(\"my.key\"),\r\n    cert : fs.readFileSync(\"my.crt\")\r\n};\r\nvar app = function (req, res) {\r\n  console.log(\"request\", req.url);\r\n  res.write(\"Hello\");\r\n  res.end();\r\n};\r\nvar server = https.createServer(options, app).listen(8081);\r\n```\r\n\r\nand access server at http://localhost:8081/ - you will get **ERR_EMPTY_RESPONSE** in chrome or **curl: (52) Empty reply from server** using CURL.\r\n\r\nIs it possible to return **HTTP 400 Bad Request** with some error message? You can get inspired by Apache or Nginx...\r\n\r\nE.g. error from Apache:\r\n\r\n> **400 Bad Request**\r\n> Your browser sent a request that this server could not understand.\r\nReason: You're speaking plain HTTP to an SSL-enabled server port.\r\n Instead use the HTTPS scheme to access this URL, please.\r\n\r\nE.g. error from Nginx:\r\n> **400 Bad Request**\r\n> The plain HTTP request was sent to HTTPS port\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43284
    },
    {
        "title": "Send Mouse and Keyboard events?",
        "body": "Hello Everyone,\r\nPlease add support for sending mouse and keyboard events similar to other programming languages instead of relying on other languages such as Python or C++ to accomplish this task.\r\n\r\nIn addition, you can also add features such as Screenshots, loading system libraries (dlls/libs)?, etc.\r\n\r\nThank You,",
        "labels": "feature request",
        "id": 43285
    },
    {
        "title": "Support for read only access to current stack.",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nGet access to current stack instead of throwing an error and parsing the error stack line by line everytime. Similar to `traceback` module in python.\r\n\r\n**Describe the solution you'd like**\r\n```\r\nlet stack = require('stack')\r\n\r\nstack[0].getFunctionName()\r\nstack[0].getLineNumber()\r\nstack[0].getFilePath()\r\n``` \r\nInstead of throwing  an error and catching an error and parsing the error, Is it possible to have a global call stack that can be referenced any time to fetch details of the call stack such as the above code\r\n\r\n**Describe alternatives you've considered**\r\nMultiple npm module which all end up with throwing an error and catching the error and parsing each line of the callstack. This is an important feature for logging as logging line number with function name and file path is important.\r\n",
        "labels": "feature request",
        "id": 43286
    },
    {
        "title": "Can we restart the work on overridable globalAgent?",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThere has been quite a few discussions here (#15620, #8381, #1490) on whether nodejs core should support environment variable for http proxy, and so far the consensus has been that proxy support in core is a slippery slope. Which I agree.\r\n\r\nBut we do need a fix for this headache: **when a userland module use a http library, they often don't expose `agent` option**, thus blocking users from using available userland proxy module like [node-proxy-agent](https://github.com/TooTallNate/node-proxy-agent).\r\n\r\n**Describe the solution you'd like**\r\n\r\nI personally believe making `http(s).globalAgent` overridable is the best way forward:\r\n\r\n1. userland module can provide whatever proxy support they want, be it http/https/socks/pac.\r\n2. user can override `http(s).globalAgent` and be confident that ALL http library will respect it.\r\n3. it has been worked on before (#11249, #9057), we should follow it through.\r\n4. after working on [node-fetch](https://github.com/bitinn/node-fetch) for 3 years I realize it's simply too much to ask userland module to expose `agent` or support environment variable: it's often too niche a requirement (eg. why should an oauth lib expose `agent`?), and many [strongly believe it to be nodejs core problem](https://github.com/sindresorhus/got/issues/79).\r\n\r\n**In short: overridable globalAgent has the lowest impact of all solutions, allow for highest flexibility when it comes to different proxy types, and has userland code ready to take advantage of it.**\r\n\r\n**Describe alternatives you've considered**\r\n\r\nSee linked discussions.\r\n",
        "labels": "feature request",
        "id": 43287
    },
    {
        "title": "N-API: An api for embedding Node in applications",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nRight now there isn't a documented/stable way to use Node as a shared library inside of an application. Were one to be made using N-API, this would open up using Chakra in addition to V8 in an application.\r\n\r\n\r\n**Describe the solution you'd like**\r\nI would like for there to be stable APIs in `node_api.h` for creating/managing a Node environment.\r\n\r\nA function that does this could hypothetically look like:\r\n\r\n```cpp\r\nNAPI_EXTERN napi_status napi_create_env(int* argc, const char** argv, napi_env* env);\r\n// Start the node event loop\r\nNAPI_EXTERN napi_status napi_run_env(napi_env env);\r\n// Cleanup (e.g. FreeIsolateData, FreeEnvironment and whatever else needs to be ran on teardown)\r\nNAPI_EXTERN napi_status napi_free_env(napi_env env);\r\n```\r\n\r\nThe embedder could get this environment's libuv loop using `napi_get_uv_event_loop`. But I would also like to have open the possibility of providing my own libuv loop that I have control over to help integrate with other event loops (e.g. Qt's event loop). This could look like:\r\n\r\n```cpp\r\nNAPI_EXTERN napi_status napi_create_env_from_loop(int* argc, const char** argv,\r\n  napi_env* env, struct uv_loop_s* loop);\r\n```\r\n\r\nKeeping the event loop going (using `uv_run` on the env's loop) would then be the embedder's responsibility.\r\n\r\nAlso, right now methods like `node::CreateEnvironment` seem to always jump into a REPL, unless you provide a string to evaluate or a file to run. Tweaks to help make this nicer to use for embedding will have to be made.\r\n\r\nThese APIs are just hypothetical, and will probably change when an actual attempt to implement them is made.\r\n\r\nI am up to trying to implement this, but I would like to see what kind of discussion happens first and what other ideas people have before I start.\r\n\r\n**Implementation Progress**\r\n - [ ] Create a clean non-NAPI way to use Node embedded\r\n - [ ] Create NAPI functions for creating and managing environments\r\n - [x] Create a NAPI function for evaluating a string (exists in NAPI v1: `napi_run_script`)\r\n - [ ] Create a NAPI function for running a script from file\r\n - [ ] Investigate if this can play nicely with `worker_threads`.\r\n\r\n**Describe alternatives you've considered**\r\nI've tried using the unstable APIs, and they aren't fun to keep up with ðŸ˜… \r\n\r\nFor discussions on how the shared library can be distributed, see this issue: https://github.com/nodejs/node/issues/24028",
        "labels": "feature request",
        "id": 43288
    },
    {
        "title": "INT/KILL should be recognized alongside SIGINT/SIGKILL",
        "body": "I have effectively this code:\r\n\r\n```js\r\nconst cp = require('child_process');\r\nconst k = cp.spawn('bash');\r\nk.kill('INT');\r\nk.kill('KILL');\r\n```\r\n\r\nI get:\r\n\r\n```\r\nTypeError [ERR_UNKNOWN_SIGNAL]: Unknown signal: INT\r\n    at convertToValidSignal (internal/util.js:229:9)\r\n    at ChildProcess.kill (internal/child_process.js:414:5)\r\n    at ReadStream.process.stdin.setEncoding.resume.on.d (/Users/oleg/codes/oresoftware/services-manager/dist/super-cli.js:37:7)\r\n    at ReadStream.emit (events.js:182:13)\r\n    at addChunk (_stream_readable.js:283:12)\r\n    at readableAddChunk (_stream_readable.js:260:13)\r\n    at ReadStream.Readable.push (_stream_readable.js:219:10)\r\n    at TTY.onStreamRead [as onread] (internal/stream_base_commons.js:94:17)\r\n```\r\n\r\njust a case of INT not being recognized, but SIGINT being recognized. Pretty certain INT should be fine? Same with KILL vs SIGKILL?\r\n  ",
        "labels": "feature request",
        "id": 43289
    },
    {
        "title": "Feature request: Crypto APIs should optionally return bigints",
        "body": "Now that bigint support is part of V8, the crypto APIs should be updated to optionally return bigints instead of buffers.\r\n\r\nI've done a bit of testing with N-API and get significantly increased performance, something like 3-4x depending on the algorithm involved, even though I'm using OpenSSL just as Node is to do the hashing: https://github.com/no2chem/bigint-hash\r\n\r\nIt also seems that providing a one-shot hashing implementation (which just hashes a buffer instead of allocating a Hash object) would improve hashing performance as well. \r\n\r\nI'm happy to take a look at submitting a PR for this if this is something that makes sense for node.\r\n",
        "labels": "feature request",
        "id": 43290
    },
    {
        "title": "QUIC support",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThe web is gaining a new connection-less, enduring long term way of communicating, [quic](https://datatracker.ietf.org/wg/quic/documents/) & it would be great to be able to use this new communication technology in node.\r\n\r\n**Describe the solution you'd like**\r\nIt would be excellent to see a quic module supported in Node.\r\n\r\n**Describe alternatives you've considered**\r\nWe could do this in userland, but like http and http2, I believe it is fundamental & integral enough to the web & Node's purposes that Node should officially support an implementation.",
        "labels": "feature request",
        "id": 43291
    },
    {
        "title": "docs: per class pages",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nIt would help to read the docs if there were per-class pages.\r\n\r\nAlso, imo the Node API docs lack following things:\r\n\r\n* Generally, emphasis on readability and clearness\r\n* Side-bar list view of class inheritance tree \r\n* Side-bar list view of properties/methods/events in a module or class\r\n* Emphasized list of possible values of string-enums\r\n* Per-class/object page with properties and methods\r\n* Sometimes return type is just \"Object\" without it being clear how that object looks like\r\n\r\nIt's really hard to get an overview, very time-expensive to read. It is also from a layout/design point of view kind of not the most enjoyable thing I've seen. \r\n\r\nI think you just have to compare with a few other very big API docs to see how it's not really matching the standards. Which is in a way surprising and remarkable, when thinking how big Nodejs is by now. \r\n\r\nAn example of a fairly good and large documentation is MDN: https://developer.mozilla.org/en-US/docs/Web/API/WebSocket\r\n\r\nI think it is crucial to have a good documentation, especially for a public platform.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAll of the points above addressed.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nRe-generate an unofficial API doc based on the Node.js source-code? There are enough good generators out-there. What is crucial is to have types properly annotated and documented inside the code.\r\n",
        "labels": "feature request",
        "id": 43292
    },
    {
        "title": "Readline: emit data events along with current line events",
        "body": "It'd be great if `readline` could emit `'data'` events for each line, so that `for await` could be used:\r\n\r\n```js\r\nconst readline = require('readline');\r\nconst stream = require('stream');\r\n\r\nconst input = new stream.Readable();\r\ninput.push(`{\"some\": \"json\",\"another\":\"json\"}\\n`);\r\ninput.push(`{\"some\": \"json2\",\"another\":\"json2\"}\\n`);\r\ninput.push(null);\r\n\r\n// What I wish I would do:\r\n(async () => {\r\n  const rl = readline.createInterface({input});\r\n  const rows = [];\r\n  for await (const row of rl) rows.push(row);\r\n  console.log(rows)\r\n})();\r\n\r\n// workaround:\r\nconst betterReadLine = ({input}) => {\r\n  const output = new stream.PassThrough({objectMode: true});\r\n  const rl = readline.createInterface({input});\r\n  rl.on('line', line => {\r\n    output.write(JSON.parse(line));\r\n  });\r\n  rl.on('close', () => {\r\n    output.push(null);\r\n  });\r\n  return output;\r\n};\r\n\r\n(async () => {\r\n  const rl = betterReadLine({input});\r\n  const rows = [];\r\n  for await (const row of rl) rows.push(row);\r\n  console.log(rows)\r\n})();\r\n```\r\n",
        "labels": "feature request",
        "id": 43293
    },
    {
        "title": "UDP/Datagram more low level options",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI originally posted the problem I ran into here:\r\nhttps://github.com/nodejs/node/issues/19954\r\nHowever, to keep a long story short, when sockets are created by default in nodeJS they have the \"IP_MULTICAST_ALL\" set to on \"the socket will receive messages from all the groups that have been joined globally on the whole system.\" - http://man7.org/linux/man-pages/man7/ip.7.html\r\nGroups this case being multicast groups, and unfortunately for us it is undesired behaviour,\r\n**Edit:** (Few hours later, I found out my multicast broadcast was disabled, and I was sending directly to the ip, which is not multicast, but the point still stands, why no level options?)\r\n\r\n\r\n\r\n**Describe the solution you'd like**\r\nThus we would like a means to change the ipv4 protocol options (http://man7.org/linux/man-pages/man7/ip.7.html) and the options listed in setsockopt for c (http://pubs.opengroup.org/onlinepubs/009695399/functions/setsockopt.html)\r\nfrom dgram/nodejs, at the moment these options are not exposed at all.\r\n\r\n**In addition** is there are reason these options have not been exposes initially? For us, without the IP_MULTICAST_ALL option exposed, multicast does not behave as intende\r\n\r\n**Describe alternatives you've considered**\r\nSome of the alternatives have been discussed in this issue: https://github.com/nodejs/node/issues/19954\r\nFor the moment we are gonna avoid nodejs and create the socket in python as the options are\r\nexposed there https://docs.python.org/3/library/socket.html#socket-objects\r\n",
        "labels": "feature request",
        "id": 43294
    },
    {
        "title": "Threadpool monitoring / metrics",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nMy (hypothetical) application uses the threadpool. Is the work performed in the threadpool the bottleneck for my application performance? This is hard to know at the moment.\r\n\r\n**Describe the solution you'd like**\r\n\r\nI would like API(s) to monitor the state of the threadpool.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nSince the threadpool is currently embedded in libuv without monitoring hooks (but see [libuv #1528](https://github.com/libuv/libuv/pull/1528)), monitoring is not easy to do.\r\n\r\nI think a monitoring API would be a logical thing to include within or following #22631.\r\n\r\nI would like community input on what the *API* should look like and what *metrics* people would find valuable.",
        "labels": "feature request",
        "id": 43295
    },
    {
        "title": "Add class inheritance/implements info to NodeJS JSON docs",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'm creating a tool that generates a definition files from [NodeJS JSON docs\r\n](https://nodejs.org/docs/latest-v10.x/api/all.json). Node documented great, but I want to know if a class (for example [`Buffer`](https://nodejs.org/docs/latest-v10.x/api/buffer.json)) inherits from or implements other class.\r\n `Buffer` class implements `UInt8Array` and it even mentions in the docs: \r\n```\r\nWith TypedArray now available, the Buffer class implements the Uint8Array API in a manner that is more optimized and suitable for Node.js.\r\n```\r\nBut not in the [JSON docs](https://nodejs.org/docs/latest-v10.x/api/buffer.json).\r\n\r\n**Describe the solution you'd like**\r\nAdd an appropriate property to the JSON:\r\n```json\r\n{\r\n\t\"textRaw\": \"Class: Buffer\",\r\n\t\"type\": \"class\",\r\n\t...\r\n\t\"implements\":[\"UInt8Array\"],\r\n}\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nNo alternative, this is the only and the ideal idea in the NodeJS history or coding in general :D ðŸ’ƒ ",
        "labels": "feature request",
        "id": 43296
    },
    {
        "title": "Tracing agent should maybe support shutdown-on-signal",
        "body": "https://github.com/nodejs/node/pull/22734 removed this feature because the implementation was inherently broken/flaky and not easily fixable.\r\n\r\nA new implementation of it would likely require some significant structural changes to the tracing implementation.\r\n\r\n/cc @nodejs/diagnostics ",
        "labels": "feature request",
        "id": 43297
    },
    {
        "title": "Uninstall instructions",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThe nodejs.org website does not have a how to uninstall page, or it is very hard to find (since there is no search in the website or the api docs).\r\n\r\n**Describe the solution you'd like**\r\nA \"How to uninstall\" guide should be accessible in the main documentation and/or in the downloads section. An uninstall script would be much more desirable.\r\n\r\n**Describe alternatives you've considered**\r\nI've searched all around in the website on how to uninstall, to no avail. I've even searched \"site:nodejs.org uninstall\", and that didn't turn up anything either. I've searched the issues here, also to no avail (which is normal, as this repo is for nodejs, not for the nodejs website (which does not exist or is not public in repo form).",
        "labels": "feature request",
        "id": 43298
    },
    {
        "title": "querystring.stringify() could accept a Map without breaking existing support for objects",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nUsing querystring.stringify() to convert object literals to query strings is very handy. The ability to convert Maps to query strings would be similarly handy.\r\n\r\n**Describe the solution you'd like**\r\nIt seems like it would be relatively low-cost to add something along the lines of the below within [this block](https://github.com/nodejs/node/blob/8b4af64f50c5e41ce0155716f294c24ccdecad03/lib/querystring.js#L218) ...\r\n\r\n```\r\nvar x = obj instanceof Map ? [...obj.entries()].reduce((o, [k, v]) => (o[k] = v, o), {}) : obj;\r\n```\r\n... where `x` is replaced by a better name, and where lines 219 and 225 would need to be updated to reference `x` instead of `obj`.\r\n\r\n**Describe alternatives you've considered**\r\nConverting Maps to object literals prior to passing to `querystring.stringify()` works, but it'd be nice to have `querystring.stringify()` do that for me, by whatever means you determine to be optimal.\r\n",
        "labels": "feature request",
        "id": 43299
    },
    {
        "title": "Web Locks API",
        "body": "Chrome 70 ships with [Web Locks](https://developer.mozilla.org/en-US/docs/Web/API/Web_Locks_API):\r\n\r\n> The Web Locks API allows scripts running in one tab or worker to asynchronously acquire a lock, hold it while work is performed, then release it. While held, no other script executing in the same origin can acquire the same lock, which allows a web app running in multiple tabs or workers to coordinate work and the use of resources.\r\n\r\n\r\n```js\r\nnavigator.locks.request('my_resource', async lock => {\r\n   // The lock has been acquired.\r\n   await do_something();\r\n   await do_something_else();\r\n   // Now the lock will be released.\r\n});\r\n```\r\n\r\nWould it make sense for Node to ship such an API for workers (or even child processes)?\r\n\r\ncc @nodejs/workers @nodejs/open-standards \r\n",
        "labels": "feature request",
        "id": 43300
    },
    {
        "title": "Include iowait and steal in os.cpus()",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWe are experiencing some VM issues with certain cloud vendors, which can be detected by monitoring the [CPU \"steal\" time](http://blog.scoutapp.com/articles/2013/07/25/understanding-cpu-steal-time-when-should-you-be-worried).\r\nWe would like to extend our current application monitoring to include this metric, to create more visibility into the problem in the future. Unfortunately, Node does not expose this information in the current `os.cpus()` implementation.\r\n\r\n**Describe the solution you'd like**\r\nIdeally, `os.cpus()` would expose more categories of CPU time, like `steal` and `iowait`.\r\n\r\n**Describe alternatives you've considered**\r\nAs a fallback solution we can collect this information by running some of the system utilities (`vmstat`, `iostat` etc). This would however mean spawning a separate process just to collect one metric.\r\n",
        "labels": "feature request",
        "id": 43301
    },
    {
        "title": "An optional parameter that lets us delete folders that aren't empty directly",
        "body": "Until now in Node 8.x, we CANNOT directly delete a folder with the sub folders with files. I'm not sure whether we can offer such a function because this is a common behaviour to delete a folder that is NOT empty (Considering the performance, we can write our core codes at C++ layer, and call it through js aspect).\r\n\r\nFor we've got `rmdirSync` or `rmdir`, maybe we can add an optional parameter to choose whether we allow to remove sub files/folders for the parent folder itself or not (In order to be compatible with it, the default value should be `false`, this means when you remove a folder that isn't empty, error will be thrown out like what can see now), something like this followingï¼š\r\n\r\n```javascript\r\nimport { rmdirSync } from \"fs\";\r\nrmdirSync('d:/tryme',true); // The second parameter will let you allow to delete a folder that isn't empty, the default value is false.\r\n```\r\n\r\nPSï¼šI know that some 3-rd parties have implemented this, but it would be better inject it into the nodejs's fs module, which is very useful and pratical.",
        "labels": "feature request",
        "id": 43302
    },
    {
        "title": "Make http.OutgoingMessage._writeRaw public",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\n\r\nI am trying to return HTTP informational statuses to the client. In particular 100, 102, 103 but I would also like to open the door to being able to support future informational status codes.\r\n\r\nBoth 100 and 102 have a dedicated method:\r\n\r\n* `HttpServerResponse.sendContinue` for 100 and\r\n* `HttpServerResponse.sendProcessing` for 102.\r\n\r\nIt would be possible to add another function like it (sendEarlyHints), but it seems a little silly given that these informational statuses more or less follow the same structure.  \r\n\r\nThe http2 library solves this with the `additionalHeaders` function. To illustrate, this is how I send *any* informational status using http2:\r\n\r\n```javascript\r\nconst otherHeaders = { };\r\nconst status = 103;\r\n\r\nstream.additionalHeaders({\r\n   ':status': status,\r\n  ...otherHeaders\r\n});\r\n```\r\n\r\nThis is how I do it for the HTTP1 api:\r\n\r\n```javascript\r\nconst otherHeaders = { };\r\nconst status = 103;\r\nconst rawHeaders = [];\r\n  for (const headerName of Object.keys(outHeaders)) {\r\n    const headerValue = outHeaders[headerName];\r\n    if (Array.isArray(headerValue)) {\r\n      for (const headerVal of headerValue) {\r\n        rawHeaders.push(`${headerName}: ${headerVal}\\r\\n`);\r\n      }\r\n    } else {\r\n      rawHeaders.push(`${headerName}: ${headerValue}\\r\\n`);\r\n    }\r\n}\r\n\r\nconst writeRaw = promisify(res._writeRaw.bind(this.inner));\r\nconst message = `HTTP/1.1 ${status} ${http.STATUS_CODES[status]}\\r\\n${rawHeaders.join('')}\\r\\n`;\r\nawait writeRaw(message, 'ascii');\r\n```\r\n\r\nThe problem here is that I'm using `res._writeRaw`, an undocumented 'private' feature. I would like to not have to rely on this, but as far as I can tell, it's the only 'sane' way.\r\n\r\n**Describe the solution you'd like**\r\n\r\nMake `_writeRaw` a documented, supported feature OR supply a reasonable API for returning any 1xx status header. \r\n\r\n**Describe alternatives you've considered**\r\n\r\nAs far as I know there's no real alternative.",
        "labels": "feature request",
        "id": 43303
    },
    {
        "title": "src: add node::url::URL::href() method",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nI need to get href based on instance of URL object in native code.\r\n\r\n**Describe the solution you'd like**\r\nI can use href() method that is added in addition to existing getters.\r\n",
        "labels": "feature request",
        "id": 43304
    },
    {
        "title": "Align paths in traces",
        "body": "When an exception is thrown or when using `console.trace()`, files paths are not aligned making it difficult to follow them at naked eye and specially to identify when it's one of your files, one internal module of if it's a file located inside `node_modules` folder:\r\n\r\n```js\r\nUnhandledPromiseRejectionWarning: SyntaxError: Identifier 'body' has already been declared\r\n     at Test.Runnable (/opt/app/node_modules/mocha/lib/runnable.js:36:25)\r\n     at new Test (/opt/app/node_modules/mocha/lib/test.js:24:12)\r\n     at context.it.context.specify (/opt/app/node_modules/mocha/lib/interfaces/bdd.js:85:18)\r\n     at Function.context.it.only (/opt/app/node_modules/mocha/lib/interfaces/bdd.js:96:46)\r\n     at Object.<anonymous> (/opt/app/src/modules/templates/template.spec.js:21:4)\r\n     at Module._compile (internal/modules/cjs/loader.js:689:30)\r\n     at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\r\n     at Module.load (internal/modules/cjs/loader.js:599:32)\r\n     at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\r\n     at Function.Module._load (internal/modules/cjs/loader.js:530:3)\r\n     at Module.require (internal/modules/cjs/loader.js:637:17)\r\n     at require (internal/modules/cjs/helpers.js:20:18)\r\n     at /opt/app/node_modules/mocha/lib/mocha.js:250:27\r\n     at Array.forEach (<anonymous>)\r\n     at Mocha.loadFiles (/opt/app/node_modules/mocha/lib/mocha.js:247:14)\r\n     at Mocha.run (/opt/app/node_modules/mocha/lib/mocha.js:576:10)\r\n```\r\n\r\nNot sure if this is done at `v8` level, but my proposal is to add spaces between the function name and the file paths so this last ones gets aligned between themselves to the longest one. In the previous trace, it would get like:\r\n\r\n```js\r\nUnhandledPromiseRejectionWarning: SyntaxError: Identifier 'body' has already been declared\r\n     at Test.Runnable                 (/opt/app/node_modules/mocha/lib/runnable.js:36:25)\r\n     at new Test                      (/opt/app/node_modules/mocha/lib/test.js:24:12)\r\n     at context.it.context.specify    (/opt/app/node_modules/mocha/lib/interfaces/bdd.js:85:18)\r\n     at Function.context.it.only      (/opt/app/node_modules/mocha/lib/interfaces/bdd.js:96:46)\r\n     at Object.<anonymous>            (/opt/app/src/modules/templates/template.spec.js:21:4)\r\n     at Module._compile               (internal/modules/cjs/loader.js:689:30)\r\n     at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\r\n     at Module.load                   (internal/modules/cjs/loader.js:599:32)\r\n     at tryModuleLoad                 (internal/modules/cjs/loader.js:538:12)\r\n     at Function.Module._load         (internal/modules/cjs/loader.js:530:3)\r\n     at Module.require                (internal/modules/cjs/loader.js:637:17)\r\n     at require                       (internal/modules/cjs/helpers.js:20:18)\r\n     at                                /opt/app/node_modules/mocha/lib/mocha.js:250:27\r\n     at Array.forEach                 (<anonymous>)\r\n     at Mocha.loadFiles               (/opt/app/node_modules/mocha/lib/mocha.js:247:14)\r\n     at Mocha.run                     (/opt/app/node_modules/mocha/lib/mocha.js:576:10)\r\n```\r\n\r\nThere would be problems if some code is parsing the trace output taking in consideration to be just only a space between the function name and the file path instead of several spaces, so this change would need to be in a major version, but anyway exception traces are not standard and such libs are very few and mostly for debuging purposses so their impact will be low, and is a small change that they would be easily added.",
        "labels": "feature request",
        "id": 43305
    },
    {
        "title": "Feature request: util: isDeprecated()",
        "body": "Prior discussion: #22524\r\n\r\nIt would be useful to have a public API for reliably detecting deprecated methods and properties upfront.\r\n\r\nAs I mentioned in the referenced issue, end users can currently check `func.name === 'deprecated'` or for properties, check for a getter and/or setter that has `getset.name === 'deprecated'`, however this isn't necessarily something that is guaranteed to always work. I propose we have some API(s) for doing a more reliable check within core (possibly utilizing internal symbols on the deprecated function wrapper?).\r\n\r\nPerhaps the API would be something like `util.isDeprecated(objOrFunc[, propertyName])` so you could do:\r\n\r\n```js\r\nutil.isDeprecated(os.tmpDir);\r\n// or alternatively\r\nutil.isDeprecated(os, 'tmpDir');\r\n// or for non-function properties\r\nutil.isDeprecated(crypto, 'DEFAULT_ENCODING');\r\n```\r\n\r\nThis won't work for all possible deprecation scenarios though (e.g. deprecated function parameters, options, etc.), but at least it'd be something useful for many other cases.",
        "labels": "feature request",
        "id": 43306
    },
    {
        "title": "Discussion: File URLs in Node.js",
        "body": "I wanted to open up a discussion on this topic, as previous work around this has perhaps lacked wider context (https://github.com/nodejs/node/pull/20950)\r\n\r\nBasically when we provide file:/// URLs to users (through `import.meta.url`, the Loader API for modules which relies heavily on file URLs, or any other means), we are expecting users to understand a lot of intricacies of how file URLs work in Node, which it already seems 90% of people will miss.\r\n\r\nFor example, see - https://github.com/wasm-tool/node-loader/commit/e4f6b7d32355a464055e064b6b2bb33bde2b3c96.\r\n\r\nThere are two major problems most people will walk into blindly when converting from file URLs to paths in Node.js:\r\n\r\n1. _`fs.readFile(url.pathname)` works in unix systems, but will break on Windows. This means Windows support will naturally hit a wide and reliably propagating point of friction as these workflows integrate into the npm ecosystem. This issue will keep coming up across many projects as they work with file URLs._\r\n\r\n2. _Non-latin characters need to be percent decoded. `import './ä½ å¥½.mjs'` will be resolved into `file:///.../%E4%BD%A0%E5%A5%BD.mjs`, so that in order to support loading the native characters from the file system, a percent decode operation needs to be performed on the path, with some special cases (eg not percent decoding path separators)._\r\n\r\n(1) is the immediate issue that will show as one of the standard Windows compatibility issues (alongside `path.replace(/\\\\/g, '/')`), and (2) seems like a deeper less seen Anglocentric preference that will continue to propagate here as well.\r\n\r\nSince I've personally not been able to make any progress on this problem through https://github.com/nodejs/node/pull/20950 I'd be interested to hear what we might be able to do about this.\r\n\r\nWhat I would like to suggest here is two new native functions:\r\n\r\n```js\r\nfileUrlToPath(string | URL) -> Node.path path\r\npathToFileUrl(path) -> URL\r\n```\r\n\r\nLet me know if that sounds like a good idea here, and I can see if we can get something into `path` or `url`... (suggestions on which is best are welcome too).",
        "labels": "feature request",
        "id": 43307
    },
    {
        "title": "Change JSON.stringify behaviour on certain builtin objects",
        "body": "This is not a first time when it happens in my work.\r\n\r\nWe accidentaly called `JSON.stringify` on `Error` instance with certain non-standard properties. These objects contained `_response` field, instance of `http.ServerResponse`. Stringifyng such objects results in giant JSON that can't be used in future (or at least, I can't think of common use case for stringifying `http.ServerResponse`).\r\n\r\nTherefore, I would suggest \"blocking\" stringifying instances of following classes:\r\n* `WritableStream`\r\n* `net.Server`\r\n* `ReadableStream`\r\n\r\nThis blocking can be implemented as throwing in `.toJSON` method, making `.toJSON` return subset of object or making it return string `\"[Object net.Server]\"` instead of exposing whole internals of an object. \r\n",
        "labels": "feature request",
        "id": 43308
    },
    {
        "title": "Linux/Unix: Resolve ~",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nnodejs does not resolve the ~ to the users home directory in linux/unix environments.\r\nso the following code fails:\r\n```\r\nconst fs = require(`fs`);\r\nconsole.log(fs.readdirSync(`~`));\r\n```\r\nwith:\r\n```\r\nError: ENOENT: no such file or directory, scandir '~'\r\n    at Object.fs.readdirSync (fs.js:895:3)\r\n```\r\n\r\n**Describe the solution you'd like**\r\n\r\nResolve ~ to the path of the users home directory.\r\n",
        "labels": "feature request",
        "id": 43309
    },
    {
        "title": "[Feature request] Resolve module dependency given the directory configuration in the package.json",
        "body": "**The problem**:\r\n\r\nI have 2 projects in my application structure, I have a core library (`@components`) that is made in typescript and then compiled to plain-javascript in the build directory that exports an object `CustomTable` in the file `build/CustomTable.js`\r\nIn my another project that depends of the package `@components`, included using npm link, I had to specify the folder build when iâ€™m trying to import the component `CustomTable` as following:\r\n\r\n`import CustomTable from '@myOrganization/components/build/CustomTable';`\r\n\r\n**The possible solution**:\r\n\r\nProvide an option in the package.json that defines in what directory the module should be resolved, something like:\r\n\r\n```json\r\n{\r\n    \"name\": \"@myOrganization/components\",\r\n    \"version\": \"0.0.1\",\r\n    \"resolveModuleFrom\": \"./build\",\r\n    \"depedencies\": {}\r\n}\r\n```\r\n\r\nThen when I can use:\r\n\r\n`import CustomTable from '@myOrganization/components/CustomTable';`\r\n\r\nAnd the file `CustomTable.js` should be resolved in the `build` folder.\r\n\r\nI also posted the feature request in the NPM community: \r\nhttps://npm.community/t/provide-an-option-to-define-in-what-directory-the-module-will-be-resolved/1540\r\n",
        "labels": "feature request",
        "id": 43310
    },
    {
        "title": "[Feature request] - [Child_process] child.stdin.on('input') event",
        "body": "So what i want, is that when spawning child, there would be event\r\n\r\n`child.stdin.on('input')`\r\n\r\nWhat it would do is when input appears in console, it would fire the event.\r\n\r\nExample:\r\n\r\n```js\r\nvar rl = require('readline')\r\nvar prompt = rl.createInterface(process.stdin, process.stdout)\r\nprompt.question('Input: ', (input) => {\r\n console.log(input)\r\n process.exit()\r\n})\r\n```\r\nand when you do `node thatFile.js` in spawn, it would fire child's `input` event in main process when it would reach `prompt.question`.",
        "labels": "feature request",
        "id": 43311
    },
    {
        "title": "feel like base32 encoding/decoding is missing",
        "body": "Would like for this to be possible:\r\n\r\n```js\r\nstr = buf.toString('base32')\r\nbuf = Buffer.from(str, 'base32')\r\n```\r\n\r\nI know there are npm packages for it but it feels like some easy fix for for the encoder/decoder to just restrict the table to a smaller alphabet",
        "labels": "feature request",
        "id": 43312
    },
    {
        "title": "Include links to source code in documentation",
        "body": "**Describe the solution you'd like**\r\nFor someone who's learning about the internals of node, it's useful to know exactly where in the codebase certain functions are implemented. I think it would be nice if the node docs linked say a function (like `setTimeout`) to the line in source code (on Github perhaps) where that function is implemented.\r\n\r\n### How it works in rust docs\r\n\r\nRust doc does this and I think it's a really nice feature that helps those wishing to dig deeper but isn't so intrusive to confuse or overwhelm newcomers.\r\n\r\n![screen shot 2018-08-19 at 09 40 32](https://user-images.githubusercontent.com/916064/44304890-08078d00-a394-11e8-96b5-fa3363a8b6d0.png)\r\n\r\n### How it might work for node docs\r\n\r\n![screen shot 2018-08-19 at 09 48 38](https://user-images.githubusercontent.com/916064/44304929-33d74280-a395-11e8-9935-d1107f291a54.png)",
        "labels": "feature request",
        "id": 43313
    },
    {
        "title": "SQL Injection and Timing Attacks using TLS SNI and HTTP Host Header",
        "body": "* **Version**: all\r\n* **Platform**: all\r\n* **Subsystem**: http, tls, maybe http2\r\n\r\nThe Specs\r\n========\r\n\r\n* TLS SNI Extension\r\n  * https://tools.ietf.org/html/rfc3546 (deprecated)\r\n  * https://tools.ietf.org/html/rfc6066#page-6\r\n* HTTP/1.1 Host\r\n  * https://tools.ietf.org/html/rfc2616#page-128\r\n* Internet Host Names\r\n  * https://tools.ietf.org/html/rfc952\r\n  * https://tools.ietf.org/html/rfc1123\r\n  * https://tools.ietf.org/html/rfc5890\r\n\r\n### Summary\r\n\r\nEssentially these say that the SNI field and the Host field are defined as strings limited to the following characters: `a-z0-9.-_`, which the addition of `:` to specify a port in some cases. Obviously there are some other restrictions such as the use of `_` and a leading character in front of an \"A\" label, no numbers in TLDs, restriction on strength length per label between `.`s, etc.\r\n\r\nAttacks\r\n======\r\n\r\nThere are at least two classes of attack that are very easy to do, but shouldn't be possible by parsers follow the spec.\r\n\r\n### SNI - SQL Injection, Timing Attack\r\n\r\n`https.SNICallback` will happily passes invalid SNI bytes, such as \r\n\r\nSQL\r\n\r\n```\r\nRobert'); DROP TABLE Student;\r\n```\r\n\r\nSo if I could guess that a client was doing some sort of virtual hosting and vulnerable to sql injection, I could easily (albeit blindly) send SQL commands:\r\n\r\n```\r\nopenssl s_client -connect test.ppl.family:443 -servername \"Robert'); DROP TABLE Students;\" -showcerts\r\n```\r\n\r\nPaths\r\n\r\n```\r\n../probing/a/path/or/file\r\n```\r\n\r\nIf I know that the server is using fs calls to find certificates to load based on the SNI then I can repeatedly send paths over and over and distinguish slight but consistent variances in the the time it takes to get an error in order to know whether or not certain target files exist on the file system, which may lead to further exploit opportunities.\r\n\r\n```\r\nopenssl s_client -connect test.ppl.family:443 -servername \"../probing/a/path/or/file\" -showcerts\r\n```\r\n\r\n### Host Header - SQL Injection, Timing Attack\r\n\r\nThe host header is susceptible to the same attacks in nearly the same way, excepting that it is **more potentially dangerous** since the attacker can get back some sort of plain-text data with either a leading error message or the actual target data in many of the affected cases:\r\n\r\n```\r\ncurl https://test.ppl.family  -H \"Host: Robert'); DROP TABLE Students;\"\r\n```\r\n\r\n```\r\ncurl https://test.ppl.family  -H \"Host: ../probing/a/path/or/file\"\r\n```\r\n\r\nAgain, I don't know what use malformed headers would be to a legitimate client or server and, whatever they may be, they're off-spec.\r\n\r\n### Domain Fronting\r\n\r\nA different, but related vulnerability is that the tls servername and Host header can be different, this is known as [domain fronting](https://en.wikipedia.org/wiki/Domain_fronting).\r\n\r\nFor example, In a shared hosting environments the SNI may come in as `foo.com` and the host header could be set to `bar.net`. ~~I don't think this introduces any new attack and the risk is relatively low from what I know~~ (WRONG, see below), but it is subversive behavior.\r\n\r\n**Update**: After reading https://portswigger.net/blog/practical-web-cache-poisoning I could definitely see how domain fronting could be used in DoS and DDOS attacks - like causing a reverse proxy to download lots of extremely large files or proxy internal private resources.\r\n\r\nNon-Attack Use Case: Knocking\r\n======\r\n\r\nThe current behavior does enable \"knocking\" - sending arbitrary as a side channel for an application-specific protocol. A traditional example of knocking is sending a ping or \"magic packet\" to a certain port on a server which then causes a firewall rule to be enabled or disabled.\r\n\r\nPersonally, I think that's a pretty cool like the idea of being able to pass arbitrary bytes in order to perform SNI knocking or Host knocking.\r\n\r\nHowever, this is not supported by the spec and is a very very edge case that would be better hid behind a configuration option - or even require the user to drop down to TCP to do.\r\n\r\nI just mention this as a way of acknowledging an off-spec, but valid-ish use case.\r\n\r\nVideo Demonstration\r\n===\r\n\r\nhttps://youtu.be/aZgVqPzoZTY?list=PLZaEVINf2Bq_lrS-OOzTUJB4q3HxarlXk\r\n\r\nNote: I created the video as a tutorial for [Greenlock.js](https://git.coolaj86.com/coolaj86/greenlock-express.js) explaining some of the security features and afterwards I realized that this is probably the sort of thing that belongs in core rather than sparsely implemented here and there among frameworks.\r\n\r\nWhy Not Let \"The Community\" Deal With It?\r\n=====\r\n\r\nNode isn't just for the technical elite anymore. I would imagine that its community has more script kiddies from boot camps than seasoned programmers or security professionals. Even the major frameworks - like express - are not mitigating these attacks (I'm using express in the video demo).\r\n\r\nSince these are issues that deal directly with the specs for the related standards, they affect all frameworks and libraries alike. I believe it should be the responsibility of node, which is parsing the data in the first place, to put at least a small measure of protection in place by better adhering to the existing standards.\r\n\r\nProposed Solution\r\n=====\r\n\r\nI propose that as node is parsing SNI and Host Headers that it reject, with the most appropriate error code, any requests that come in which arbitrary bytes that cannot be parsed according to the specification.\r\n\r\nAs a stop-gap solution I'd recommend simply matching case-insensitively on the set of the 39 allowed characters `a-z0-9.-_`.\r\n\r\nI also suggest that there be a flag in the TLS,HTTP, HTTP2, and HTTPS modules when creating a server that allows these arbitrary bytes be passed rather than returning an error just in case someone is doing something off-spec, such as SNI or Host knocking.",
        "labels": "feature request",
        "id": 43314
    },
    {
        "title": "Async Hooks do not recognize execution contexts created when processing thenables",
        "body": "`Promise.all` to observe input promises, invokes `promise.then` in next event loop, at least it's what stack traces show in both Node.js and Google Chrome.\r\n\r\nStill Async Hooks see it as same execution context, it can be seen by running following code:\r\n\r\n```javascript\r\nconst async_hooks = require('async_hooks');\r\n\r\nasync_hooks.createHook({ init() {} }).enable();\r\n\r\nPromise.all([\r\n  {\r\n    then() {\r\n      console.log(async_hooks.executionAsyncId(), async_hooks.triggerAsyncId(), 'thenable.then invoked by Promise.all');\r\n      console.trace('thenable.then invoked by Promise.all');\r\n    },\r\n  },\r\n]);\r\n\r\nconsole.log(async_hooks.executionAsyncId(), async_hooks.triggerAsyncId(), 'Main');\r\nconsole.trace('Main');\r\n```\r\n\r\nThe outcome is:\r\n\r\n```\r\n1 0 'Main'\r\nTrace: Main\r\n    at Object.<anonymous> (/Users/medikoo/Projects/maas/maas-backend/test.js:15:9)\r\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\r\n    at Module.load (internal/modules/cjs/loader.js:599:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\r\n    at startup (internal/bootstrap/node.js:266:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:596:3)\r\n1 0 'promise.then invoked by Promise.all'\r\nTrace: promise.then invoked by Promise.all\r\n    at Object.then (/Users/medikoo/Projects/maas/maas-backend/test.js:9:15)\r\n    at process._tickCallback (internal/process/next_tick.js:68:7)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:745:11)\r\n    at startup (internal/bootstrap/node.js:266:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:596:3)\r\n```\r\n\r\nI've stumbled on that when trying to configure long stack trace solution for Node.js, and was dealing with custom promise implementations.\r\n\r\nI believe that's not expected.\r\n\r\n* **Version**: v10.9.0 (observable also on v8)\r\n* **Platform**: macOs 10.13.6 (17G65)\r\n",
        "labels": "feature request",
        "id": 43315
    },
    {
        "title": "RFC: make node on Windows install, or prompt users to get, windows-build-tools",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nUsers (even experience node users like me, I'm ashamed to admit) install node for Windows on new boxes, and everything is fine installing modules for a little while until one day they need a native modules, and something seems broken. They spend a little while searching and find out they need to `yarn add global windows-build-tools` or `npm -g install windows-build-tools`\r\n\r\nEssentially, `windows-build-tools` could be considered a dependency for node on Windows in the same way `gcc-c++` is on Linux. As a result, it should be handled better. \r\n\r\n**Describe the solution you'd like**\r\n\r\nMy gut feeling is for build tools to be installed by the node installer. Things should 'just work'.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nHow frequently are native modules needed? I'll let the community decide, but\r\n\r\n - If native modules are frequently needed, I'd like `windows-build-tools` to be there out of the box, in the same way that `gcc-c++` is on Linux. \r\n\r\n - If there are some situations where local modules aren't needed, so we can't have  `windows-build-tools` as a hard dependency, I'd like node to strongly recommend installing  `windows-build-tools` - perhaps during compilation of native modules, perhaps after install.\r\n\r\nI don't have any hard thoughts one way or the other, just interested in what other Windows node users have experienced here.\r\n\r\n",
        "labels": "feature request",
        "id": 43316
    },
    {
        "title": "openssl_cipher_iv_length",
        "body": "I see some issues about `invalid IV length` or `Invalid key length`.\r\nIn PHP, there is a helper method (`openssl_cipher_iv_length`) that return the correct length for IV. \r\n\r\nNode could have a static method for this, something like: \r\n\r\n- `crypto.cipherivLength(algorithm: string): number`\r\n- `crypto.cipherkeyLength(algorithm: string): number`\r\n\r\n**Simple example:**\r\n```js\r\nconst ivLen = crypto.cipherivLength('des-ede3-ofb') // => 8\r\nconst keyLen = crypto.cipherkeyLength('des-ede3-ofb') // => 24\r\n```\r\n\r\n**Complex example:**\r\n```js\r\n'use strict'\r\n\r\nconst assert = require('assert').strict\r\nconst crypto = require('crypto')\r\n\r\nconst SALT = 'foobar'\r\n\r\nfunction genKey(alg) {\r\n\tconst keyLen = 24 // => crypto.cipherkeyLength(alg)\r\n\tconst hash = crypto.createHash('sha256').update(SALT).digest()\r\n\treturn hash.slice(0, keyLen)\r\n}\r\n\r\nfunction encrypt(value, alg = 'des-ede3-ofb') {\r\n\tconst ivLen = 8 // => crypto.cipherivLength(alg)\r\n\tconst iv = crypto.randomBytes(ivLen)\r\n\tconst key = genKey(alg)\r\n\tconst cipher = crypto.createCipheriv(alg, key, iv, {authTagLength: ivLen})\r\n\tconst encryptedUpdate = cipher.update(value)\r\n\tconst encryptedFinal = cipher.final()\r\n\tconst encrypted = Buffer.concat([encryptedUpdate, encryptedFinal], encryptedUpdate.byteLength + encryptedFinal.byteLength)\r\n\treturn [encrypted, iv]\r\n}\r\n\r\nfunction decrypt([encrypted, iv], alg = 'des-ede3-ofb') {\r\n\tconst ivLen = iv.byteLength\r\n\tconst key = genKey(alg)\r\n\tconst cipher = crypto.createDecipheriv(alg, key, iv, {authTagLength: ivLen})\r\n\tconst decryptedUpdate = cipher.update(encrypted)\r\n\tconst decryptedFinal = cipher.final()\r\n\treturn Buffer.concat([decryptedUpdate, decryptedFinal], decryptedUpdate.byteLength + decryptedFinal.byteLength)\r\n}\r\n\r\n// Testing\r\nconst input = 'test'\r\nconst output = decrypt(encrypt(input)).toString('utf8')\r\nassert.strictEqual(input, output) // => OK\r\n```",
        "labels": "feature request",
        "id": 43317
    },
    {
        "title": "[Feature request] [Windows] Unable to run Node.js in safe mode",
        "body": "* **Version**: any\r\n* **Platform**: windows x64\r\n* **Subsystem**: runtime\r\n\r\nMade a script for cleaning up disk and unlocking locked files. The script is written in JavaScript and intended to be run using Node.js in Windows safe mode.\r\n\r\nWhen run the script in windows normal mode, it works. However, when run the script in windows safe mode, get the error:\r\n\r\n```\r\nsocket: (10050) A socket operation encountered a dead network\r\n```\r\n\r\nAfter googling found out that windows safe mode disables network drivers and Node.js won't start if network drivers are disabled.\r\n\r\nIs there a reason to terminate Node.js if there are no network drivers enabled? The script is supposed to use only `fs` and `path` module in order to `unlink` some files and `rmdir` directories. Network is really irrelevant and terminating the Node.js process because of missing drivers doesn't really make sense to me.\r\n\r\nBut, this is total guess, I'm not sure if missing drivers cause it or whatever, that's what I found on google and stack overflow.\r\n\r\n---\r\n\r\nTo make it clear: the feature request is to allow Node.js to run in windows safe mode, without requiring any irrelevant configuration to be present (like network drivers, if that is the cause). Would like to hear your opinion.",
        "labels": "feature request",
        "id": 43318
    },
    {
        "title": "`fs` request: allow bigint values in read() and write() calls",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.7.0\r\n* **Platform**: Linux zeen3.localdomain 4.17.7-100.fc27.x86_64 #1 SMP Tue Jul 17 16:29:47 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nCurrently working on an application that is likely to read & write from values greater than the 32-bit (technically 32 bit signed int) limit in `fs.(read|write)` and `fs.promises.(read|write)`. Wanted to request that these functions be able to accept bigint values for reading/writing files >= 4GiB.\r\n\r\n```shell\r\n$ node\r\n> let fh = await fs.promises.open('k.txt', 'r')\r\n(node:6387) ExperimentalWarning: The fs.promises API is experimental\r\nundefined\r\n> await fh.read(Buffer.allocUnsafe(32), 0n, 32n, 32n)\r\nawait fh.read(Buffer.allocUnsafe(32), 0n, 32n, 32n)\r\n^^^^^\r\n\r\nSyntaxError: await is only valid in async function\r\n\r\n> fh.read(Buffer.allocUnsafe(32), 0n, 32n, 32n)\r\nPromise {\r\n  <rejected> TypeError: Cannot mix BigInt and other types, use explicit conversions\r\n    at read (internal/fs/promises.js:205:3)\r\n    at FileHandle.read (internal/fs/promises.js:77:12)\r\n    at repl:1:4\r\n    at Script.runInThisContext (vm.js:91:20)\r\n    at REPLServer.defaultEval (repl.js:321:29)\r\n    at bound (domain.js:396:14)\r\n    at REPLServer.runBound [as eval] (domain.js:409:12)\r\n    at REPLServer.onLine (repl.js:619:10)\r\n    at REPLServer.emit (events.js:187:15)\r\n    at REPLServer.EventEmitter.emit (domain.js:442:20),\r\n  domain:\r\n   Domain {\r\n     domain: null,\r\n     _events:\r\n      { removeListener: [Function: updateExceptionCapture],\r\n        newListener: [Function: updateExceptionCapture],\r\n        error: [Function: debugDomainError] },\r\n     _eventsCount: 3,\r\n     _maxListeners: undefined,\r\n     members: [] } }\r\n> (node:6387) UnhandledPromiseRejectionWarning: TypeError: Cannot mix BigInt and other types, use explicit conversions\r\n    at read (internal/fs/promises.js:205:3)\r\n    at FileHandle.read (internal/fs/promises.js:77:12)\r\n    at repl:1:4\r\n    at Script.runInThisContext (vm.js:91:20)\r\n    at REPLServer.defaultEval (repl.js:321:29)\r\n    at bound (domain.js:396:14)\r\n    at REPLServer.runBound [as eval] (domain.js:409:12)\r\n    at REPLServer.onLine (repl.js:619:10)\r\n    at REPLServer.emit (events.js:187:15)\r\n    at REPLServer.EventEmitter.emit (domain.js:442:20)\r\n(node:6387) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 1)\r\n(node:6387) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n\r\n> $ type node\r\nnode is aliased to `node --experimental-repl-await --icu-data-dir=`echo -ne \"$HOME\"`/node_modules/full-icu'\r\n```\r\n\r\nOther than that; I'd request the allowing of `bigint` values in eg `utimes()`, `lchmod()`, `flags`, `truncate()`, `mode`, `interval` (on `watchFile`), `highWaterMark` (mostly just for consistency) and so on. It'd be a massive patch though; plus would likely make some parts incompatible (eg constants that are not pulling from `fs.constants` or `process.binding('fs').constants`).\r\n\r\nOf course they shouldn't be using them but... people are human.",
        "labels": "feature request",
        "id": 43319
    },
    {
        "title": "Feature request:child_process.exec for powershell",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:v10.7.0\r\n* **Platform**:Windows 10 64bit\r\n* **Subsystem**:child_process\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nOn Windows, `child_process.exec` (or other methods) supports [only cmd.exe as the shell](https://nodejs.org/api/child_process.html#child_process_shell_requirements), so running the following shows error messages.\r\n\r\n```javascript\r\nconst ChildProcess = require(\"child_process\")\r\n\r\n// trying to use powershell core(pwsh).\r\nChildProcess.exec(\"echo foo\", { shell: \"pwsh\" }, (error, stdout, stderr) => {\r\n    if (error) {\r\n        console.error(\"exec error: \", error);\r\n        return;\r\n    }\r\n    console.log(\"stdout: \", stdout);\r\n    console.log(\"stderr: \", stderr);\r\n})\r\n\r\n```\r\n\r\nresult:\r\n```\r\nexec error:  { Error: Command failed: echo foo\r\nThe argument '/d' is not recognized as the name of a script file. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.\r\n\r\n    at ChildProcess.exithandler (child_process.js:291:12)\r\n    at ChildProcess.emit (events.js:182:13)\r\n    at maybeClose (internal/child_process.js:961:16)\r\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:248:5) killed: false, code: 64, signal: null, cmd: 'echo foo' }\r\n```\r\n\r\nHowever, there are alternate shells like powershell, git-bash, etc. So I suggest to fix the behavior.\r\n\r\nI suppose the cause is this code(a part of `child_process.normalizeSpawnArguments`):\r\n\r\nhttps://github.com/nodejs/node/blob/c3f8dd6f98328a9a47814f1856bc0914859c6e19/lib/child_process.js#L469-L479\r\n\r\nOn Windows, it sets `/d /s /c` for args even if `options.shell!==\"cmd.exe\"`. Powershell can receive `-c` option like unix shells, so `/d /s /c` should be used for only cmd.exe.",
        "labels": "feature request",
        "id": 43320
    },
    {
        "title": "Support for Python 3",
        "body": "Add support for building with Python 3.\r\nPython 2 is very old and it will not be supported in 2020 anymore (https://pythonclock.org/ and python/devguide#344).",
        "labels": "feature request",
        "id": 43321
    },
    {
        "title": "readdir should have {type:'file'} option - should allow user to only retrieve files not folders etc",
        "body": "With this SO question in mind:\r\n\r\nhttps://stackoverflow.com/questions/51333163/nodejs-readdir-only-find-files/51333279\r\n\r\nI know that readdir is some c utitlity on Unix. It would be possibly more efficient for users to pre-filter with readdir instead of running lstatSync or statSync on each item from the array.\r\n\r\nIs it possible for the lower level routines to filter things out efficiently before sending back?",
        "labels": "feature request",
        "id": 43322
    },
    {
        "title": "Feature request - add terminal colors to  core",
        "body": "I have some scripts for which installing dependencies / node_modules would be overkill, but I still could use some colors for the terminal. Right now, I think in userland it's standard to install colors/chalk in node_modules but I am wondering if there is a way to do so with just Node.js core?\r\n\r\nSeems like it would be handy for scripts and wouldn't add too much to core? dunno",
        "labels": "feature request",
        "id": 43323
    },
    {
        "title": "Is there a good way to track how recently data was received from the remote end of an http2 session?",
        "body": "I am trying to detect when a connection underlying an http2 session is broken using [this strategy](https://github.com/grpc/proposal/blob/master/A8-client-side-keepalive.md#basic-keepalive). In short, I want to send an http2 ping when I have at least one active stream (which I can track myself) and when I have not received any data from the server. Is there a good way to determine when was the latest time that I received any data from the server?",
        "labels": "feature request",
        "id": 43324
    },
    {
        "title": "Custom module loader for Workers",
        "body": "Node.js users has two problems:\r\n* Simple and powerful sandboxing.\r\n* Using ES modules.\r\n\r\nWorkers can solve both of them in very elegant way with custom resolvers which are the same as experimental es module resolver.\r\n\r\n```javascript\r\nconst worker = new Worker('./worker-path.js', {\r\n    moduleLoader: {resolve, dynamicInstantiate},\r\n});\r\n```\r\n\r\nIt solves sandboxing with full dependency control in custom context. And it simplifies es modules usage with preserving usual code flow in main thread and es flow in worker thread.\r\n\r\n/cc @addaleax @TimothyGu @Qard @aqrln @oe @benjamingr @nodejs/workers",
        "labels": "feature request",
        "id": 43325
    },
    {
        "title": "Ability to replace current Node process with another",
        "body": "**Edit:** If someone can come up with a better shim for `execve` for Windows, that'd be *far* better. The form below is *very* expensive and *very* horrible.\r\n\r\n**Edit 2:** Linked relevant [SO question](https://stackoverflow.com/questions/51185115/what-is-the-ideal-way-to-emulate-process-replacement-on-windows).\r\n\r\n**Edit 3:** Clarify FS changes\r\n\r\n**Edit 4:** Here's the text from that SO question as of July 6, 2018 (so you don't have to search for it), where I asked about how to do the Windows part.\r\n\r\n<details>\r\n<summary>Click to show (warning: lots of text)</summary>\r\n\r\nSo, in a [feature request I filed against Node.js](https://github.com/nodejs/node/issues/21664), I was looking for a way to replace the current Node process with another. In Linux and friends (really, any POSIX-compliant system), this is easy: use [`execve`](http://man7.org/linux/man-pages/man2/execve.2.html) and friends and call it a day. But obviously, that won't work on Windows, since it only has `CreateProcess` (which `execve` and friends delegate to, [complete with async behavior](https://stackoverflow.com/questions/49736973/blocking-version-of-execvp-windows)). And it's not like [people](https://stackoverflow.com/questions/35111313/windows-exec-equivalent) [haven't](https://stackoverflow.com/questions/6743567/replace-current-process-with-invocation-of-subprocess) [wanted](https://stackoverflow.com/questions/7198666/strategies-for-replacing-program-executable-in-windows) [to](https://stackoverflow.com/questions/198122/how-can-i-replace-the-current-java-process-like-a-unix-style-exec) [do](https://stackoverflow.com/questions/5450147/how-to-replace-the-current-java-process-in-windows-using-jna-jni) [similar](https://stackoverflow.com/questions/45607959/restart-windows-process-inplace-preserving-process-id-and-handles), leading to [numerous duplicate questions on this site](https://www.google.com/search?q=windows+replace+current+process+site:stackoverflow.com). (This isn't a duplicate because it's explicitly seeking a workaround given certain constraints, not just asking for direct replacement.)\r\n\r\nProcess replacement has several facets that have to addressed:\r\n\r\n1. All console I/O streams have to be forwarded to the new process.\r\n1. All signals need transparently forwarded to the new process.\r\n1. The data from the old process have to be destroyed, with as many resources reclaimed as possible.\r\n1. All pre-existing threads and child processes should be destroyed.\r\n1. All pre-existing handles should be destroyed apart from open file descriptors and named pipes/etc.\r\n1. Optimally, the old process's memory should be kept to a minimum after the process is created.\r\n1. For my particular use case, retaining the process ID is not important.\r\n\r\nAnd for my particular case, there are a few constraints:\r\n\r\n1. I can control the initial process's startup as well as the location of my \"process replacement\" function.\r\n1. I could load arbitrary native code via add-ons at potentially any stack offset.\r\n    - Implication: I can't even dream of tracking `malloc` calls, handles, thread manipulation, or process manipulation to track and free them all, since DLL rewriting isn't exactly practical.\r\n1. I have no control over *when* my \"process replacement\" is called. It could be called through an add-on, which could've been called through either interpreted code via FFI or even another add-on recursively. It could even be called during add-on initialization.\r\n    - Implication: I would have no ability to know what's in the stack, even if I perfectly instrumented my side. And rewriting all their `call`s and `push`es is far from practical, and would just be all-around slow for obvious reasons.\r\n\r\nSo, here's the gist of what I was thinking: use something similar to a pseudo-trampoline.\r\n\r\n1. Statically allocate the following:\r\n    1. A single pointer for the stack pointer.\r\n    1. `MAX_PATH + 1` chars for the application path + `'\\0'`.\r\n    1. `MAX_PATH + 1` chars for the current working directory path + `'\\0'`.\r\n    1. 32768 chars for the arguments + `'\\0'`.\r\n    1. 32768 chars for the environment + `'\\0'`.\r\n1. On entry, set the global stack pointer reference to the stack pointer.\r\n1. On \"replacement\":\r\n    1. Do relevant process cleanup and lock/release everything you can.\r\n    1. Set the stack pointer to the stored original global one.\r\n    1. Terminate each child thread.\r\n    1. Kill each child process.\r\n    1. Free [each open handle](https://stackoverflow.com/questions/733384/how-to-enumerate-process-handles).\r\n    1. If possible (i.e. not in a UWP program), [For each heap](https://docs.microsoft.com/en-us/windows/desktop/api/heapapi/nf-heapapi-getprocessheaps), [destroy it](https://docs.microsoft.com/en-us/windows/desktop/api/HeapApi/nf-heapapi-heapdestroy) if it's not the [default heap](https://docs.microsoft.com/en-us/windows/desktop/api/HeapApi/nf-heapapi-getprocessheap) or the temporary heap (if it exists).\r\n    1. If possible, close [each open handle](https://stackoverflow.com/questions/733384/how-to-enumerate-process-handles).\r\n    1. If possible, [walk](https://docs.microsoft.com/en-us/windows/desktop/api/HeapApi/nf-heapapi-heapwalk) the default heap and [free](https://docs.microsoft.com/en-us/windows/desktop/api/HeapApi/nf-heapapi-heapfree) each segment associated with it.\r\n    1. Create a new process with the statically allocated file/arguments/environment/etc. with no new window created.\r\n    1. Proxy all future received signals, exceptions, etc. without modification to this process somehow. [The standard signals are easy](https://docs.microsoft.com/en-us/windows/console/setconsolectrlhandler), but not so much with the exceptions.\r\n    1. Wait for the process to end.\r\n    1. Return with [the process's exit code](https://docs.microsoft.com/en-us/windows/desktop/api/processthreadsapi/nf-processthreadsapi-getexitcodeprocess).\r\n\r\nThe idea here is to use a process-based trampoline and drop the current process size to an absolute minimum while the newly created one is started.\r\n\r\nBut where I'm not very familiar with Windows, I probably made quite a few mistakes here. Also, the above seems *extremely* inefficient and to an extent it just feels horribly wrong for something a kernel could just release a few memory pages, deallocate a bunch of memory handles, and move some memory around for the next process.\r\n\r\nSo, to summarize, what's the ideal way to emulate process replacement on Windows with the fewest limitations?\r\n</details>\r\n\r\n-----\r\n\r\nI would like a means to \"replace\" the current Node process with another, keeping the same process ID. It would be something morally similar to [this function](https://github.com/isiahmeadows/thallium/blob/master/lib/cli/util.js#L92-L111), but it wouldn't return. This would be most useful for conditionally replacing Node flags in a startup script - for example, if someone wants to enable modules and your behavior needs to change non-trivially in the presence of them (like if you need to install a default loader), you'll want to respawn the process with `--experimental-modules --loader <file>` so you can install the loader.\r\n\r\nThis is also for scenarios when you want to run a module as a `main` module. If you want to do logic after the process ends, you should be using `child_process.spawn` regardless - you shouldn't be attempting to \"replace\" it in any capacity.\r\n\r\nHere's what I propose:\r\n\r\n- `child_process.replaceSpawn(command [ , args] [ , options ])`\r\n    - `command` is the path to the new command.\r\n    - `args` is the args to replace the arguments with. This defaults to the empty array.\r\n    - `options` is for the various options for replacing the process. This defaults to an empty object.\r\n        - `options.cwd` is the new cwd to use. (Default: `process.cwd()`)\r\n        - `options.env` is the new environment to use. (Default: `process.env`)\r\n        - `options.argv0` is the binary to spawn as. (Default: `command`)\r\n\r\n- `child_process.replaceFork(mainPath [ , args] [ , options ])` works similarly to above.\r\n    - `mainPath` is the path to the new `require.main`.\r\n    - `options.execPath` is the new binary to spawn as. (Default: `process.execPath`)\r\n    - `options.execArgv` are the new Node flags to spawn with. (Default: `process.execArgv`)\r\n    - `options.argv0` is the binary to spawn as. (Default: `process.argv0`)\r\n    - The command is the original binary itself.\r\n\r\n- Add a `napi_terminating` member for `napi_status` to represent `try_catch.HasTerminated()` and the result of each call after replacement termination.\r\n\r\n- Add a `napi_set_terminate_hook(napi_env env, void (*fun)(void*), void* data)` function to register a callback called on termination, to make it easier to clean up resources.\r\n\r\nInternally, there are two cases you need to cover, and the simulated part for Windows is where it gets really hairy due to all the edge cases. Here's pseudocode for the basic algorithm (I'm not really familiar with Node internals, so take this as a rough guideline):\r\n\r\n1. Stop the main event loop.\r\n1. Go through the standard shutdown routine.\r\n1. Destroy any open libuv handles and cancel any remaining event loop tasks.\r\n1. If we're on a platform that supports process replacement (like Linux or Mac):\r\n    1. Invoke `execve` or equivalent with the new process path, arguments, and environment.\r\n1. Else, if we're on Windows (the only supported OS that doesn't), we have to simulate it entirely:\r\n    1. Terminate execution via `v8::V8::TerminateExecution()`. All N-API callbacks should return `napi_terminated` during this step.\r\n    1. For each loaded native module:\r\n        1. If the native module has a terminate hook, call it.\r\n        1. Unload the native module's DLL.\r\n    1. Close the event loop.\r\n    1. Dispose the isolate.\r\n    1. Do the rest according to whatever happens to [this SO question](https://stackoverflow.com/questions/51185115/what-is-the-ideal-way-to-emulate-process-replacement-on-windows).\r\n    1. Else, on other OSs without a process replacement function, it'd look similar to Windows.\r\n\r\nIn addition, file system requests will have to generally create each file descriptor with `O_CLOEXEC`.\r\n\r\nAs for precedent where this could be used immediately:\r\n\r\n- [Liftoff](https://www.npmjs.com/package/liftoff) works very similarly, just with a little extra opinionated sugar, and that's used natively in Gulp. This kind of thing would speed that up quite a bit.\r\n- I do [very similar](https://github.com/isiahmeadows/thallium/blob/master/cli.js#L126-L150) to transparently pass through unknown Node flags.\r\n- Babel [attempts to use `kexec`](https://github.com/babel/babel/blob/master/packages/babel-node/src/babel-node.js#L87-L88) where available, which [is a POSIX-only module that replaces the process literally](https://www.npmjs.com/package/kexec). Absent that, it falls back to [its own implementation](https://github.com/babel/babel/blob/master/packages/babel-node/src/babel-node.js#L90-L109) that works like the other two examples.",
        "labels": "feature request",
        "id": 43326
    },
    {
        "title": "Feature request: Buffer.readUint(BE|LE) with BigInt support",
        "body": "`buf.readUIntLE(offset, byteLength)` with byteLength > 6 to return `BigInt`\r\n",
        "labels": "feature request",
        "id": 43327
    },
    {
        "title": "Programmatically print an object to the inspector console",
        "body": "* **Version**: master (and all releases that had the new inspector)\r\n* **Platform**: all \r\n* **Subsystem**: inspector, console\r\n\r\nRecently I've seen a couple of requests to logging libraries to route logs to the inspector console. As far as I know, this is currently not possible using the current API.\r\n\r\nDo you think it's worth adding an API to programmatically print object to the console? What would be needed to add it?",
        "labels": "feature request",
        "id": 43328
    },
    {
        "title": "Feature request: accept function or block in `worker_threads` as starting point of execution",
        "body": "This is a crude proposal of a direction I think we can take `worker_threads` forward in, and I thought I should post it to get community feedback. \r\n\r\nI do understand that we are trying to align `worker_threads` with WebWorkers, but considering the fact that server requirements are different from client, and to take advantage of the fact that workers have their own event loop, I think we should support doing the following:\r\n\r\n``` js\r\nlet aVeryLargeArray = [1, 2, 3, 4, 5 .... 100000000];\r\nconst workerThreads = require('worker_threads');\r\nconst messageChannel = workerThreads.start((channel, input) => {\r\n    const resultArray = input.map((item) => item * 2);\r\n    channel.port1.postMessage({ resultArray });\r\n}. aVeryLargeArray); // just like setTimeout with the channel reference as an input to the function\r\nmessageChannel.port1.on(\"message\", ({resultArray}) => {\r\n    console.log(\"The result array obtained is \": resultArray);\r\n    channel.port1.close();\r\n});\r\nmessageChannel.port1.start();\r\n```\r\n\r\nThe main benefit of this which I see that it would make it easier to manipulate very large data sets on the server, synchronously if needed, without starving the event loop of the main thread(kind of using the workers like how `fs` uses the UV Thread Pool)\r\n\r\n/cc @addaleax @nodejs/workers \r\n\r\nEDIT:\r\n\r\nAnother option we could use would be [blocks](https://github.com/domenic/proposal-blocks)",
        "labels": "feature request",
        "id": 43329
    },
    {
        "title": "Feature request: support a list of custom \"is host object\" symbols for serialization",
        "body": "I have a case where I have an arbitrary data type that's *not* an array buffer view and that's *not* a C++ object (specifically, things defined in JS with a few particular symbols I know in advance), and I need to serialize them as if they were \"host\" objects. This value is *not* always top-level and I have no control over what the data is, so doing a simple typed traversal (which would be fast) is not an option. For my particular use case, all I need is a series of property existence checks against a fixed per-serializer list of symbols, so it doesn't have to be much.\r\n\r\nMy only alternative ATM is basically roll this all myself, which will be *sloooooooow*, since I'll be fighting with ICs and improper polymorphic caching.\r\n\r\n(I know this isn't available in V8's serialization API either, so this is in part a feature request for them, too.)",
        "labels": "feature request",
        "id": 43330
    },
    {
        "title": "Multi-hosts urls",
        "body": "`url.parse` and `URL` (it just throws) don't handle urls with multiple hosts\r\n```js\r\nvar u = url.parse('mongodb://server1.db.foo.net:27017,server2.db.foo.net:27017,server3.db.foo.net:27017/data?authMechanism=MONGO-X509&replicaSet=rs0&ssl=true&sslValidate=true', true)\r\n/*\r\nUrl {\r\n  protocol: 'https:',\r\n  slashes: true,\r\n  auth: 'foo',\r\n  host: 'server1.foo.net:7998',\r\n  port: '7998',\r\n  hostname: 'server1.foo.net',\r\n  hash: null,\r\n  search:\r\n   '?authMechanism=X509&replicaSet=rs0&ssl=true&sslValidate=true',\r\n  query:\r\n   { authMechanism: 'X509',\r\n     replicaSet: 'rs0',\r\n     ssl: 'true',\r\n     sslValidate: 'true' },\r\n  pathname: '/:7998,server2.foo.net:7998,server3.foo.net/data',\r\n  path:\r\n   '/:7998,server2.foo.net:7998,server3.foo.net/data?authMechanism=X509&replicaSet=rs0&ssl=true&sslValidate=true',\r\n// ...\r\n*/\r\n```\r\n\r\npython can handle them: https://github.com/whatwg/url/issues/398#issuecomment-401348316\r\n\r\nSo I wonder if it couldn't be something we can change in node?",
        "labels": "feature request",
        "id": 43331
    },
    {
        "title": "Please support web standard crypto.subtle",
        "body": "Node.js developed it's own crypto API before the WebCrypto API.\r\n\r\nSince then, browsers and the web have standardized implementations around the [WebCrypto API standard](https://www.w3.org/TR/WebCryptoAPI).\r\n\r\nThis bug is about Node.js missing support for the WebCrypto standard API and reopens #2833 (from 2015).\r\n\r\nAsking 3rd party libraries to implement the WebCrypto standard is not responsible from a security standpoint for a variety of reasons from implementation expertise to malware.  It is not responsible to put this onto API end users (developers).\r\n\r\nAdditionally, a variety of implementation differences ([like this one](https://stackoverflow.com/a/39651457/1483977)) make compatible implementations buggy and error-prone.\r\n\r\nBack in 2015, there were arguments for not supporting the WebCrypto standard in Node 0.12.\r\n\r\nToday, committing to not supporting the WebCrypto standard is committing to a lack of responsibility for Nodejs as a secure and standards based platform on the web.\r\n\r\n",
        "labels": "feature request",
        "id": 43332
    },
    {
        "title": "Support ES modules in workers",
        "body": "This is how it should be done [according to the HTML spec](https://html.spec.whatwg.org/multipage/workers.html#dedicated-workers-and-the-worker-interface):\r\n\r\n```js\r\nconst worker = new Worker('worker.mjs', { type: 'module' });\r\n```\r\n",
        "labels": "feature request",
        "id": 43333
    },
    {
        "title": "Promisify server.listen",
        "body": "### Problem:\r\n```js\r\nconst server = app.listen();\r\nconsole.log(`Server listening on: ${server.address().port}`)\r\n```\r\ncan fail, as the server is created asynchronously and using the callback is not always practical/flexible\r\n\r\n### Proposal\r\neither `server.listenPromise(port)`, or even better, have `server.listen(port)` return a Promise if no callback is provided\r\n\r\n### Example\r\n```js\r\n\r\n// .... \r\n\r\nconst start = async () => {\r\n    await config.load();\r\n    await DB.connect(dbOptions);\r\n    router(app);\r\n    app.use((err, req, res, next) => { // error handler\r\n        // ...\r\n    });\r\n\r\n    const server = http.createServer(app);\r\n    // proposal:\r\n    return server.listen(process.env.PORT || 3000); // if .listen would be a promise resolving to server\r\n    // or await server.listen(...); return server; else\r\n\r\n    // currently I have to do:\r\n    // return new Promise((res, rej) => server.listen(process.env.PORT || 3000, err => err ? rej(err) : res()));\r\n\r\n    // or using express's app.listen, which wraps createServer and listen:\r\n    // return new Promise((res, rej) => app.listen(process.env.PORT || 3000, function (err) {\r\n    //      if (err) return rej(err);\r\n    //      res(this) // this is node's http Server\r\n    // }));\r\n\r\n    // using util.promisify doesn't look much better:\r\n    // return promisify(server.listen).bind(server)(process.env.PORT || 3000);\r\n    // or\r\n    // return promisify(cb => server.listen(process.env.PORT || 3000, cb))();\r\n};\r\n```\r\n\r\nthen using it somewhere else:\r\n```js\r\nstart()\r\n        .then(server => console.log(`Server listening on: ${server.address().port}`))\r\n        .catch(err => {\r\n           // ...\r\n        });\r\n```\r\n\r\nEdit: I'll try to submit this request to express, and have a similar promise method near https://github.com/expressjs/express/blob/master/lib/application.js#L616-L619\r\n\r\nEdit2: the discussion in expressjs/express#3675 has interesting details",
        "labels": "feature request",
        "id": 43334
    },
    {
        "title": "Replace the use of marked with remark for doc/json generation",
        "body": "Summary: over time the node.js build process has outgrown marked and it's regular expression based processing model.  See:\r\n\r\nhttps://github.com/nodejs/node/pull/21081#issuecomment-399155282\r\nhttps://github.com/nodejs/node/pull/21081#issuecomment-399197585\r\nhttps://github.com/nodejs/node/pull/21081#issuecomment-399510285\r\n\r\nIt is time to replace it with something that involves a proper [syntax tree](https://github.com/syntax-tree/unist) which can be programmatically manipulated and from which artifacts like JSON can be confidently generated.",
        "labels": "feature request",
        "id": 43335
    },
    {
        "title": "feature request: add elliptic for crypot module",
        "body": "ECDH class in crypto module can calculate public key from the private key using elliptic curve but has not some useful methods like Elliptic.Add() and Elliptic.Double().\r\n\r\nI am not good at crypto,I think the methods that are same with [Golang/Elliptic package](https://golang.org/pkg/crypto/elliptic/#CurveParams.Add)\r\n\r\nHope to add these functions.\r\n\r\n\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43336
    },
    {
        "title": "Http2SecureServer Is Not Exported",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.5.0\r\n* **Platform**: MacOS 10.13.2\r\n* **Subsystem**: None\r\n\r\nWhile writing tests for a project I found myself wanting to assert that the return value from a function was an instance of `Http2SecureServer`. However, upon trying to find the export for `Http2SecureServer`, I wound up at https://github.com/nodejs/node/blob/master/lib/internal/http2/core.js and found that the class isn't actually listed in the exports. So there's no discernible way to run an `instanceof` against my return variable, as I can't reference the class.\r\n\r\nIt's an unfortunate limitation; while testing that an object is an instance of `tls.Server` is fine and good, I would much rather add an extra layer of assertiveness and make sure that my return value was in fact an instance of `Http2SecureServer`, as the mechanisms in my use case can also return `https.Server`, which also inherits from `tls.Server`.\r\n\r\nOn the surface this seems like a glaring omission. But there's probably a reason for that. What's the scoop?\r\n\r\n_Update: It would seem the same is true for `Http2Server` as well._",
        "labels": "feature request",
        "id": 43337
    },
    {
        "title": "Validating environment variables",
        "body": "Right now we have no validation of our environment variables even though a couple of these only accept a limited set of values.\r\n\r\nI propose that we add a validation hook and when a environment variable is set a JS function is triggered to verify the value. I would also like to expose the hook to users so they are able to validate the environment variables used in e.g. different modes (running the code in production might accept less values than when run in other modes). Trying to add a hook twice should result in an error.\r\n\r\nIf this is something that others like as an idea, I would go ahead and open a PR to implement this.\r\n\r\nI suggest a similar API to:\r\n\r\n```js\r\nprocess.addEnvVariableValidation('name', (entry) => {\r\n  if (entry === 'foobar') {\r\n    // do stuff\r\n  } else if (entry === 'baz') {\r\n    // do something else\r\n  } else {\r\n    throw new Error('Not accepted environment variable entry')\r\n  }\r\n})\r\n```",
        "labels": "feature request",
        "id": 43338
    },
    {
        "title": "Feature request: allow awaiting event, reject on `\"error\"`",
        "body": "**Edit:** Added `errorEvent` option to configure error events\r\n\r\n99% of my event adaptation of promises end up looking something close to this:\r\n\r\n```js\r\nfunction open(file) {\r\n    return new Promise((resolve, reject) => {\r\n        const stream = fs.createWriteStream(file)\r\n\r\n        function ready() {\r\n            stream.removeListener(\"ready\", ready)\r\n            stream.removeListener(\"error\", fail)\r\n            resolve(stream)\r\n        }\r\n\r\n        function fail(e) {\r\n            reject(e)\r\n            stream.removeListener(\"ready\", ready)\r\n            stream.removeListener(\"error\", fail)\r\n        }\r\n\r\n        stream.on(\"ready\", ready)\r\n        stream.on(\"error\", fail)\r\n    })\r\n}\r\n```\r\n\r\nThis is most frequently with streams, but it also occasionally shows up with other things, including with non-core libraries. What I'd prefer to write is something closer to this:\r\n\r\n```js\r\nasync function open(file) {\r\n    const stream = fs.createWriteStream(file)\r\n    await stream.awaitEvent(\"ready\")\r\n    return stream\r\n}\r\n```\r\n\r\nMy proposed API is this:\r\n\r\n- `ee.awaitEvent(\"name\", {includeAll = false, errorEvent = \"event\"} = {})`: Return a promise fulfilled with an array of arguments once `\"name\"` is emitted, rejected if it's beat by an `\"error\"` event. An extra options object is permitted, and it accepts two options: `includeAll`, which resolves with an array of arguments intead, and `errorEvent`, which allows configuring what event is considered the \"error\" event.\r\n\r\nThe naÃ¯ve implementation is pretty simple, and looks very similar to above.\r\n\r\n```js\r\nEventEmitter.prototype.awaitEvent = function awaitEvent(event, {includeAll, errorEvent = \"event\"} = {}) {\r\n    return new Promise((resolve, reject) => {\r\n        const success = (...args) => {\r\n            this.removeListener(event, success)\r\n            this.removeListener(errorEvent, fail)\r\n            if (includeAll) resolve(...args)\r\n            else resolve(args[0])\r\n        }\r\n\r\n        const fail = e => {\r\n            reject(e)\r\n            this.removeListener(event, success)\r\n            this.removeListener(errorEvent, fail)\r\n        }\r\n\r\n        this.on(event, success)\r\n        this.on(errorEvent, fail)\r\n    })\r\n}\r\n```",
        "labels": "feature request",
        "id": 43339
    },
    {
        "title": "TLS 1.3 Support",
        "body": "As TLS 1.3 has been approved by IETF and browsers will start to adopt it soon, it's nice to have it in node.js too.",
        "labels": "feature request",
        "id": 43340
    },
    {
        "title": "Request: stat.typeof() from the stat object on the fs.stat callback",
        "body": "This is a feature request and not a defect report.\r\n\r\nRequesting stat.typeof() method to report the file system artifact type.  Currently these methods are present in the *fs* library:\r\n\r\n* stats.isBlockDevice()\r\n* stats.isCharacterDevice()\r\n* stats.isDirectory()\r\n* stats.isFIFO()\r\n* stats.isFile()\r\n* stats.isSocket()\r\n* stats.isSymbolicLink()\r\n\r\nEach of those methods returns a boolean.  It would be more convenient if there were a single method that returns a choice of string values:\r\n\r\n* blockDevice\r\n* characterDevice\r\n* directory\r\n* FIFO\r\n* file\r\n* socket\r\n* symbolicLink\r\n* error\r\n\r\nhttps://nodejs.org/dist/latest-v10.x/docs/api/fs.html",
        "labels": "feature request",
        "id": 43341
    },
    {
        "title": "Unexpected behavior of Buffer.from( num.toString(16), \"hex\" )",
        "body": "**Info:**\r\nVersion: v8.10.0\r\nPlatform: Windows 10, 64-bit\r\nSubsystem: buffer module: Buffer.from\r\n\r\n**Code:**\r\n```javascript\r\nlet hex_string = ('abc').toString(16);\r\nlet b = Buffer.from( hex_string, 'hex' );\r\n```\r\n**Problem:**\r\n`b == <Buffer ab>` and I expect that `b == <Buffer 0a bc>`\r\n\r\n**Details and explanation:**\r\nWhen calling `Buffer.from( ... , 'hex')` with hex string that have odd number of characters (in case when no leading zero provided) I expect Buffer.from to add leading zero in case of hex encoding, so `\"1\"` will be recognized as `\"01\"`.\r\n\r\n**Use case example:**\r\n```javascript\r\nBuffer.from( someNumber.toString(16), 'hex' ); \r\n```\r\nI expect that in above example I do not have to append on my own leading \"0\" in case when toString(16) returns odd number of characters.\r\n\r\nOther solution I see (instead of fixing `Buffer.from`) is to update `toString(16)`, but in my opinion fix should implemented inside `Buffer.from`.",
        "labels": "feature request",
        "id": 43342
    },
    {
        "title": "Support WebAssembly.instantiateStreaming",
        "body": "I think it's better support `WebAssembly.instantiateStreaming`.\r\nIt makes more easy to use WebAssembly and we can get more compatibility for Web.\r\n\r\nIt already implemented in Google Chrome, Firefox and some browsers.\r\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WebAssembly/instantiateStreaming\r\n\r\n`instantiateStreaming` already exists in `deps/v8/src/wasm/wasm-js.cc` but cannot cover this branch.\r\n\r\nhttps://github.com/nodejs/node/blob/de732725d8ae232d7b6d56927ea8bef471d5bf1d/deps/v8/src/wasm/wasm-js.cc#L1177-L1182\r\n\r\nTo cover this branch, we must call `SetWasmCompileStreamingCallback`.\r\n\r\nhttps://github.com/nodejs/node/blob/de732725d8ae232d7b6d56927ea8bef471d5bf1d/deps/v8/include/v8.h#L7805\r\nhttps://github.com/nodejs/node/blob/de732725d8ae232d7b6d56927ea8bef471d5bf1d/deps/v8/src/api.cc#L8876-L8877\r\n\r\nIn chromium, implemented here:\r\nhttps://github.com/chromium/chromium/blob/51459d663d841c6430747aec97be9f7e7a7ca41f/third_party/blink/renderer/bindings/core/v8/v8_wasm_response_extensions.cc#L194-L222\r\nAnd use it here:\r\nhttps://github.com/chromium/chromium/blob/51459d663d841c6430747aec97be9f7e7a7ca41f/third_party/blink/renderer/bindings/core/v8/v8_wasm_response_extensions.cc#L228\r\n\r\nWhy we must inject the actual implementation,\r\nIt's said that this is for layering reasons.\r\nhttps://github.com/WebAssembly/design/issues/1085\r\n\r\n## Discussion\r\n1. How about it?\r\n1. How to make `instantiateStreaming` compatible with [design](https://github.com/WebAssembly/design/blob/master/Web.md#webassemblyinstantiatestreaming).\r\n    - ex. `instantiateStreaming(fs.promises.readFile('./some.wasm'), importObject)`\r\n      - It's not compatible with design.\r\n      - readFile returns `Buffer`, not `ArrayBuffer`.\r\n",
        "labels": "feature request",
        "id": 43343
    },
    {
        "title": "Allow linux users to turn off delayed ACK for TCP",
        "body": "This is for all Node.js versions\r\n\r\nre: https://jvns.ca/blog/2015/11/21/why-you-should-understand-a-little-about-tcp/\r\n\r\nAFAIK, delayed ACK is the default on all Linux flavors. It would be interesting to have a way to turn off that flag, via a Node.js call.\r\n\r\nI am not sure if there is a way to persistently set the flag, or if you need to set it for each TCP request. If the latter, perhaps it's prohibitively expensive. So perhaps it's only worth setting the flag on systems where the flag can be set persistently.",
        "labels": "feature request",
        "id": 43344
    },
    {
        "title": "Canâ€™t import fs Promises API with ECMAScript Modules",
        "body": "* **Version**: v10.2.1\r\n* **Platform**: Windows 10 64-bit\r\n* **Subsystem**: fs\r\n\r\nPer [the docs](https://nodejs.org/api/fs.html#fs_fs_promises_api), â€œThe API is accessible via `require('fs').promises`.â€\r\n\r\nWhen using ECMAScript Modules it canâ€™t be accessed like that. One may expect to be able to load it with `import {promises as fs} from 'fs'`, but this gives an error.\r\n```\r\nimport {promises as fs} from 'fs'\r\n        ^^^^^^^^\r\nSyntaxError: The requested module 'fs' does not provide an export named 'promises'\r\n    at ModuleJob._instantiate (internal/modules/esm/module_job.js:89:21)\r\n```\r\n\r\nSo right now accessing the fs Promises API directly when using ECMAScript Modules requires two lines, like so:\r\n```js\r\nimport {default as fsWithCallbacks} from 'fs'\r\nconst fs = fsWithCallbacks.promises\r\n```",
        "labels": "feature request",
        "id": 43345
    },
    {
        "title": "Error handling in EventEmitter",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**: events.js\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nInstead of using `Domain`, we could implement `catch` method similar to `Promise`.\r\nHere is an example: \r\n```js\r\nconst EventEmitter = require('events');\r\n\r\nfunction safeEmit(...args){\r\n\ttry {\r\n\t\tEventEmitter.prototype.emit.apply(this, args);\r\n\t} catch (e) {\r\n\t\tthis.emit(\"error\", e);\r\n\t}\r\n}\r\n\r\nEventEmitter.prototype.catch = function(handler) {\r\n\tthis.on(\"error\", handler);\r\n\tthis.emit = safeEmit;\r\n\treturn this;\r\n}\r\n\r\nconst emitter = new EventEmitter();\r\n\r\nemitter.on(\"open\", (filename) => {\r\n\tconsole.log(\"Opening %s...\", filename);\r\n\tthrow new Error(\"File Not Found!\");\r\n\t})\r\n.catch((e) => {console.error(e.message)});\r\n\r\nemitter.emit(\"open\", \"abc.txt\");\r\n/*\r\nOpening abc.txt...\r\nFile Not Found!\r\n*/\r\n```\r\n",
        "labels": "feature request",
        "id": 43346
    },
    {
        "title": "Implement \"eager evaluation\" in the REPL",
        "body": "Hi, V8 [has a basic way to detect side-effects](https://github.com/v8/v8/blob/e48d9788a4ef21d3bfffbc691bb02c794445c089/src/debug/debug-evaluate.cc#L603) and they [use it for eager evaluation in the devtools](https://developers.google.com/web/updates/2018/05/devtools#eagerevaluation). \r\n\r\nIt would be cool to allow for similar behaviour in our REPL. For clarity, here is the image of Chrome 68's behaviour:\r\n\r\n![image](https://user-images.githubusercontent.com/1315533/40576831-7c6b1d64-6105-11e8-9347-f43bf493d8c1.png)\r\n\r\n<sub>(Image copyright (CC BY 3.0) Google Developer blog [\"What's New In DevTools (Chrome 68)\"](https://developers.google.com/web/updates/2018/05/devtools#eagerevaluation) by Kayce Basques @kaycebasques )</sub>\r\n\r\n@nodejs/repl ",
        "labels": "feature request",
        "id": 43347
    },
    {
        "title": "Add debugger alias for exec(expr)",
        "body": "node v9.8.0\r\nIn the debugger you can quickly inspect the value of a variable at run-time using `exec`. Given\r\n```js\r\n// test.js\r\nvar a = 1\r\n```\r\n```sh\r\n$ node inspect test.js\r\n< Debugger listening on ws://127.0.0.1:9229/4565e728-272a-497d-a3f8-73b03362df0f\r\n< For help see https://nodejs.org/en/docs/inspector\r\n< Debugger attached.\r\nBreak on start in test.js:1\r\n> 1 (function (exports, require, module, __filename, __dirname) { var a = 1\r\n  2\r\n  3 });\r\ndebug> n\r\nbreak in test.js:1\r\n> 1 (function (exports, require, module, __filename, __dirname) { var a = 1\r\n  2\r\n  3 });\r\ndebug> n\r\nbreak in test.js:3\r\n  1 (function (exports, require, module, __filename, __dirname) { var a = 1\r\n  2\r\n> 3 });\r\ndebug> exec('a')\r\n1\r\ndebug> .exit\r\n```\r\nTo more quickly debug an application it would be nice to alias exec to `e` or `p` so one can do\r\n```\r\ndebug> p('a')\r\n1\r\n```\r\nEven better if the expression could be passed without parens and quotes\r\n```\r\ndebug> p a\r\n1\r\n```\r\nThis is in the same spirit as when pressing `Enter` the debugger will repeat the previous command.",
        "labels": "feature request",
        "id": 43348
    },
    {
        "title": "Strict mode for require() function",
        "body": "Since npm create flat module directory, it makes importing a package that isn't declared in `package.json` possible. It would be nice if Node.js can check whether imported package are in `package.json` and warn users about it. This feature should be hidden behind a flag, e.g. `--strict-import`.",
        "labels": "feature request",
        "id": 43349
    },
    {
        "title": "Unable to share ticketKeys in secureContext",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **8.10.0**:\r\n* **Linux 4.13.0-37-generic #42~16.04.1-Ubuntu SMP Wed Mar 7 16:03:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux**:\r\n* **TLS**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI am trying to share the TLS `ticketKeys` among several servers running in cluster in order to enable the reuse of sessions regardless of the particular server receiving the request. Sharing `ticketKeys` among servers is quite straightforward when you create the servers using [`tls.createServer()`](https://nodejs.org/api/tls.html#tls_tls_createserver_options_secureconnectionlistener), but in my case, I need to create the servers using [`net.createServer()`](https://nodejs.org/api/net.html#net_net_createserver_options_connectionlistener) and then wrap the incoming plain sockets with [`new TLSSocket()`](https://nodejs.org/api/tls.html#tls_new_tls_tlssocket_socket_options).\r\n\r\nThe `options` parameter in `new TLSSocket()` allows you to enter a `secureContext`, but unfortunately there is no (published) way to share `ticketKeys` through `secureContext`s. I've peeked into the code, and discovered that there is an undocumented way to do it through `secureContext.context.setTicketKeys()`. I've even tested it and assessed that it works. But I don't dare to use it since it is not documented and could disappear with no previous notice. Could you please add a `ticketKeys` option to [`tls.createSecureContext()`](https://nodejs.org/api/tls.html#tls_tls_createsecurecontext_options) to enable the reuse of TLS sessions in cluster mode?",
        "labels": "feature request",
        "id": 43350
    },
    {
        "title": "Support util.inspect.custom as a public symbol",
        "body": "* **Version**: v10.1.0\r\n* **Platform**: Linux (Arch)\r\n* **Subsystem**: util\r\n\r\nPlease consider supporting `util.inspect.custom` as a public/global symbol either by:\r\n\r\n1) changing `util.inspect.custom` from a private symbol (e.g. `Symbol('util.inspect.custom')`) to a public symbol (e.g. `Symbol.for('util.inspect.custom')`)\r\n\r\nor:\r\n\r\n2) accepting a public symbol as an alternative to the private symbol, just as `\"inspect\"` is currently accepted as a (deprecated) fallback for the symbol\r\n\r\n[Changing it from a string to a symbol](https://github.com/nodejs/node/issues/15549) was a great idea :tada: and it's a perfect use case for a symbol, but, as mentioned [here](https://github.com/nodejs/node/issues/15549#issuecomment-386501861), making it private makes it painful to write code that both a) provides an `inspect` hook if it's loaded in node and b) works seamlessly in the browser if it's not.\r\n\r\n\r\nA workaround has been implemented as an NPM module, [inspect-custom-symbol](https://github.com/mafintosh/inspect-custom-symbol) (cc @mafintosh), which uses the `browser` field in its `package.json` to provide a substitute symbol without pulling in the `util` library in bundlers such as Browserify and Webpack. It's much better than trying to work around this with a tower of late-bound `typeof util.inspect.custom` checks, but it doesn't fix the underlying issue and it's not ideal:\r\n\r\n* it doesn't work in all situations/environments\r\n* it requires an extra dependency\r\n* most people with this dilemma won't be aware of it",
        "labels": "feature request",
        "id": 43351
    },
    {
        "title": "FR: CodeBlocks in REPL.",
        "body": "```\r\n$ node --version\r\nv10.0.0\r\n\r\n$ uname\r\nDarwin LM-BNG-22004407 16.7.0 Darwin Kernel Version 16.7.0\r\n```\r\n\r\nSo, today:\r\n\r\n```\r\n$ node\r\n\r\n> obj = {\r\n... \r\n... \r\n... }\r\n\r\n# If we hit the up arrow key, we see\r\n> }\r\n\r\n> obj = {\r\n```\r\n\r\nRather, if we could display the entire code block, when we do an up arrow, like:\r\n\r\n\r\n```\r\n$ node\r\n\r\n> obj = {\r\n... \r\n... \r\n... }\r\n\r\n# If we hit the up arrow key, we must see\r\n\r\n> obj = {}\r\n```\r\n\r\nThis should make life on the REPL much easier.\r\n\r\nVery similar to how devtool console treats code blocks.\r\n",
        "labels": "feature request",
        "id": 43352
    },
    {
        "title": "RFC process.on(\"shutdown\") proposal",
        "body": "See this popular question on so https://stackoverflow.com/q/14031763/3748498\r\n\r\nBy now there is no clean API to do cleanup when node.js exits, in order to catch all situation you need to do following:\r\n```js\r\nfor (const event of [\"exit\", \"SIGINT\", \"SIGUSR1\", \"SIGUSR2\", \"uncaughtException\", \"SIGTERM\"]) {\r\n  process.on(event, cleanUp)\r\n}\r\n```\r\nThis issue is a place for discussion how to fix it.\r\n\r\nMy proposal is `process.on(\"shutdown\", cleanUp)`.",
        "labels": "feature request",
        "id": 43353
    },
    {
        "title": "http: Using URL with http.request (feature suggestion)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.1.0\r\n* **Platform**: all\r\n* **Subsystem**: http\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nUsing `URL` objects is clearly the way to go when it comes to dealing with URLs, and `http.request()` can take a `URL` object as input. This is great. But if I want to also send custom headers, I'm stuck. I would like to suggest an option for the options object called `url` that can be set to URL object and maybe even a string. I don't really want to make an already complex API more complex, but I'm not sure how else we can make it easier to use URL objects with HTTP requests.\r\n\r\nFeedback, suggestions, thoughts from @nodejs/collaborators very welcome.",
        "labels": "feature request",
        "id": 43354
    },
    {
        "title": "fs.read/write timeouts",
        "body": "Node 8.11.1\r\nDebian Stretch\r\nFilesystem Subsystem\r\n\r\nIt would be great to allow for timing out file descriptor read and write operations.  See for example https://stackoverflow.com/questions/20808126/how-to-timeout-an-fs-read-in-node-js .  Sometimes `fs.read()` takes a really long time, and there seems to be no good way to handle this.\r\n\r\nI imagine it could be done with the smallest interface change by setting a system-wide timeout parameter.\r\n",
        "labels": "feature request",
        "id": 43355
    },
    {
        "title": "readable.readv(size) to reduce memory copies",
        "body": "* **Version**: v10.0.0\r\n* **Platform**: Darwin\r\n* **Subsystem**: stream\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis is a feature request:\r\n\r\nCurrently, a readable stream in paused mode (non-flowing) allows only `read([size])` to consume data from the internal buffer list:\r\n\r\n1. `read()` (without size) returns a buffer in any size, therefore always copyless, but using it for decoding specific data structures is hard and will require coalescing buffers and concatenating or unshift back remains when received too much.\r\n\r\n2. `read(size)` will return null if not enough bytes, otherwise it will extract the requested size from the internal buffer list. This extraction (`fromList(n, state)` at https://github.com/nodejs/node/blob/v10.0.0/lib/_stream_readable.js#L1047) will use memory copy `Buffer.concat()` when the size involves multiple buffers.\r\n\r\nThe problem is that the behavior from read(size) is not allowing a consistent performance since in some cases we will incure buffer allocation + copy, and in others we just use slicing.\r\n\r\nThese are two ways to get a more consistent performance of readable streams:\r\n\r\n1. `readv(size)` - same as `read(size)` but returns an array of buffers so avoids concat altogether.\r\n\r\n2. `read(buffer)` will return null if not enough bytes are available, otherwise it will read directly into the provided buffer and return it. This avoids allocating new buffers, but will always copy from the internal buffer list to the preallocated buffer. This is useful when decoding small fixed size structures such as packet headers in which the copy is less noticeable, but the number of allocations is affecting GC.\r\n\r\nClearly `readv()` is more robust than `read(buffer)` and might suffice, but the latter is a simple way to avoid unwanted allocations or use buffer pools.\r\n\r\nWould be great to get your thoughts if this is worth making a PR.\r\nThanks!",
        "labels": "feature request",
        "id": 43356
    },
    {
        "title": "FR: `.save` to save the evaled results.",
        "body": "```\r\n$ node --version\r\nv10.0.0\r\n\r\n$ uname\r\nDarwin LM-BNG-22004407 16.7.0 Darwin Kernel Version 16.7.0\r\n```\r\n\r\n```js\r\n> new Date\r\n2018-05-05T06:24:11.745Z\r\n> .save foo\r\nSession saved to:foo\r\n```\r\n\r\n```\r\n$ cat foo\r\nnew Date\r\n```\r\nInstead if we have a `.saveAll` or something similar that would save the evaled values as well, would it be useful?\r\n\r\n```js\r\n> new Date\r\n2018-05-05T06:24:11.745Z\r\n> .saveAll foo\r\nSession saved to:foo\r\n```\r\n\r\n```\r\n$ cat foo\r\nnew Date\r\n2018-05-05T06:24:11.745Z\r\n```\r\n\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43357
    },
    {
        "title": "Expose and hook into REPL eval",
        "body": "While building the REPL for https://github.com/TypeStrong/ts-node, I'd love to be able to push people toward using `node -r ts-node/register` for any advanced node.js usage and the one remaining feature to support the REPL. Would it make sense to expose the \"default\" REPL eval for override and `createInternalRepl` in some way so projects like the babel CLI and `ts-node` can hook into and replace the default eval and/or replicate `createInternalRepl`?",
        "labels": "feature request",
        "id": 43358
    },
    {
        "title": "require.resolve API change",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nv8.8.0 - v8.9.0 compatibility\r\n* **Platform**:\r\nall\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIn 8.9, a second `options` argument was added to `require.resolve`, which can change the search path. In pre-8.9, such an argument is silently ignored. That seems like a bad API policy, as people who read current docs will expect the function to use the provided search path, and people who run this on older Node VMs will end up loading the wrong files.\r\n\r\nI'd suggest (a) adding a warning that the argument is ignored in earlier versions, and (b) providing a newly named function (like `require.resolveFrom`) that accepts the paths and and doesn't exist in versions that don't support it.\r\n\r\nRequire search paths are too critical to have same-named functions with such different semantics.\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43359
    },
    {
        "title": "ESM modules and json importing [feature request]",
        "body": "Will it be possible in the future to import .json files as we used to required .json files?\r\n\r\n```\r\nimport pkg from './package'\r\nimport { name, version } from './package'\r\n```\r\n\r\n",
        "labels": "feature request",
        "id": 43360
    },
    {
        "title": "Add lint rule to enforce snake_case in file names",
        "body": "I am currently backporting a lot of things and while doing so there were quite a few files that got renamed from camelCase to snake_case. \r\n\r\nIt would be great to prevent any further additions of such file names to prevent the churn produced by that.\r\n\r\nBy briefly searching for something like that, I stumbled upon https://www.npmjs.com/package/eslint-plugin-filenames.\r\n\r\nI hope other @nodejs/collaborators are fine with this.",
        "labels": "feature request",
        "id": 43361
    },
    {
        "title": "NODE_EXTRA_CA_CERTS cannot be set in code or relative",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nv9.11.1\r\n* **Platform**:\r\nDarwin sheerun.dev 17.4.0 Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST 2017; root:xnu-4570.41.2~1/RELEASE_X86_64 x86_64 i386 MacBookPro12,1 Darwin\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen I start my server with\r\n\r\n```\r\nNODE_EXTRA_CA_CERTS=/Users/sheerun/Source/Ada/search/.certs/ca.crt bin/start\r\n```\r\n\r\nand in code make request to http server that serves with given certificate, all is good\r\n\r\nBut when I set it at the beginning of `bin/start` as so:\r\n\r\n```\r\nprocess.env.NODE_EXTRA_CA_CERTS = \"/Users/sheerun/Source/Ada/search/.certs/ca.crt\"\r\n```\r\n\r\nthen node complains that there's \"self signed certificate in certificate chain\".\r\n\r\nParticularly NODE_EXTRA_CA_CERTS doesn't work when I use `dotenv` package and set NODE_EXTRA_CA_CERTS in `.env` file.\r\n\r\nAlso, it seems NODE_EXTRA_CA_CERTS doesn't allow relative path, just absolute.\r\n\r\nI think both of these issues should be addressed or at least documented with reasons why.",
        "labels": "feature request",
        "id": 43362
    },
    {
        "title": "feature request: add  elliptic curve math for crypto module",
        "body": "* **Version**: node 10.0.0\r\n* **Platform**: Linux\r\n* **Subsystem**: ubuntu 1804\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nNow in Node.js has ECDH class which can calculate public key from the private key using elliptic curve but has nothing about  elliptic curve math methods like `addition()` operation.\r\n\r\nAre there any possibilities to add these functions?",
        "labels": "feature request",
        "id": 43363
    },
    {
        "title": "Making `util.TextDecoder` and `util.TextEncoder` available on the global object",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.0.0\r\n* **Platform**: Microsoft Windows [Version 10.0.16299.371]\r\n* **Subsystem**: util\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nJust wondering since the WHATWG `URL` API was made available on the global object in Node v10.0.0: Should the WHATWG `TextEncoder` and `TextDecoder` APIs (that are currectly available via `require('util')`) be made available on the global object, too, or are there any reasons for not doing so?\r\n\r\nPS: If this should be done, I'd love to start working on a PR for it.",
        "labels": "feature request",
        "id": 43364
    },
    {
        "title": "Install helpr github app on the repository",
        "body": "So I was browsing through issues in the repository as I wanted to contribute to the node ecosystem. One of the problems I faced was clicking on an issue, reading about it and then discovering there is an already open PR for the same issue. IMO it would be helpful if issues are automatically labelled with labels like `pr-available` when a PR references them like `Fixes #2`. \r\nI have built a GitHub app for exactly this. You can check it out at [helPR](https://github.com/rsarky/helpr)",
        "labels": "feature request",
        "id": 43365
    },
    {
        "title": "[Feature request] Enable templated require",
        "body": "* **Version**: v9.11.1\r\n* **Platform**: windows, linux, mac, wt\r\n* **Subsystem**: require\r\n\r\nHi. I really like node.js and the concept behind it, but one thing that I find very disturbing is that `require` function doesn't allow templated arguments.\r\n\r\nFor example, how about\r\n\r\n```js\r\nconst util = require`util`;\r\n```\r\n\r\ninstead of\r\n\r\n```js\r\nconst util = require('util');\r\n```\r\n\r\nAll native functions* allow templated call. Of course, it is not a syntax error to templately call even `require`, but unfortunately `require` doesn't recognize the string properly. It throws assertion error (path must be a string).\r\n\r\nTemplated call not only to save 2 extra characters of typing effort, but it also makes the code more readable and it would make `require` consistent with other native functions which allow such call. Also, since the only argument of `require` is a string, therefore it is the one reason more to implement such call.\r\n\r\nOf course, it is very easy to make a polyfill for it in JavaScript, but why not implement it natively, since I don't see a hindrance for it.\r\n\r\nAny opinions? Thanks.\r\n\r\n---\r\n\r\n<sub>*every function where it makes sense (for example if it accepts only one argument which can only be a string or a number)</sub>",
        "labels": "feature request",
        "id": 43366
    },
    {
        "title": "Can buffer.byteOffset be modified?",
        "body": "Many Node.js methods accept only a buffer, i.e. they don't accept a bufferOffset argument into a buffer.\r\n\r\nIf one has a buffer with thousands of elements inside, for which a method needs to be called for each, then one can use buffer.slice().\r\n\r\nExcept that buffer.slice() allocates a new JS object every slice.\r\n\r\nIs it possible to make buffer.byteOffset adjustable?",
        "labels": "feature request",
        "id": 43367
    },
    {
        "title": "Implement WebCrypto interface",
        "body": "Yes, I did a search for `WebCrypto` and found a lot of closed issues. \r\n\r\nYes, I saw comments like\r\n```\r\nI do not see a reason why to implement it - user could get the same using existing crypto interface\r\n```\r\nI have more than 20 years of experience in software development, many working implemented products, expert in all crypto-related stuff but even for me making such `same using existing crypto interface` is **VERY** untrivial.\r\n\r\nYes, I also saw comments like this\r\n```\r\nUser could generate RSA (EC) keys via spawn openssl <blah-blah>\r\n```\r\nWhy you need the `crypto` module itself? Why not just saying `spawn openssl` instead?\r\n\r\nBut why not just unify API between browsers and Node? WebCrypto even in a standard stage now. \r\nIt is hard to implement and would get much time? [Here is](https://github.com/PeculiarVentures/node-webcrypto-ossl) **EXISTING** code already implemented WebCrypto API in Node environment as a native plugin. It is tested, verified and confirmed to be aligned with WebCrypto API implementations in browser. All you need is to adopt **EXISTING** code as native Node module.\r\n\r\nAs you could see it is not a common issue - I have a real feeling that it is a time to discuss WebCrypto in Node again. I did not participate in prev discussions and would like to start a new one.\r\n",
        "labels": "feature request",
        "id": 43368
    },
    {
        "title": "Require from root",
        "body": "Especially with really large projects it is sometimes quite useful to what to require a local module based on its path from the root of the project. This can help with readability and requiring since you don't have to remember where you when you want to load a module.\r\n\r\n**For require:** \r\n```js\r\nconst user = require.root('models/user');\r\n```\r\n\r\n**For import:** \r\n```js\r\nconst user = import.root 'models/user';\r\n```\r\n\r\nAs for the definition of what root is I think that the directory in the parent path (including the current directory) that has a package.json is considered root. ",
        "labels": "feature request",
        "id": 43369
    },
    {
        "title": "Set --inspect-port to unix socket",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v8.9.4\r\n* **Platform**: 3.10.0-693.17.1.el7.x86_64\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI would like to use `--inspect-port` with a unix socket.\r\n\r\nThis is useful because I plan to send `kill -s SIGUSR1` then not need to worry about which port it takes as well as be be able to enforce security.  As far as I know, the only way to change where the debugger binds to for a `SIGUSR1` is to use `--inspect-port`.\r\n\r\nCurrently when I try I see: `node --inspect-port=/path/to/unix.socket` erroring with:\r\n```\r\nUnable to resolve\" /path/to/unix.socket\": unknown node or service\r\n```\r\n\r\nIs there some other way to accomplish this? If not, please consider this a proposal for a feature.\r\n\r\nThanks!",
        "labels": "feature request",
        "id": 43370
    },
    {
        "title": "[feature] Promise returning process.nextTick",
        "body": "Just a quick idea I had after talking to @sindresorhus.\r\n\r\nWhen `process.nextTick()` is called without a function, return a Promise:\r\n\r\n```js\r\nasync function fn() {\r\n  await process.nextTick();\r\n}\r\n```\r\n\r\nin effect:\r\n\r\n```js\r\nfunction nextTick(fn) {\r\n  if (typeof fn === 'function') {\r\n    process.nextTick(fn);\r\n  } else {\r\n    return new Promise(res => process.nextTick(res));\r\n  }\r\n}\r\n```\r\n\r\nAs more of Node (possibly) moves to Promises/async-await for APIs (#15413) this makes sense I think",
        "labels": "feature request",
        "id": 43371
    },
    {
        "title": "[feature] `require` module options object",
        "body": "Hey guys\r\n\r\nI have a non-breaking feature request to provide a second parameter for `require` to provide an options object, for disabling default caching and any possible future customization. The only caveat is that I am not sure what will happen to `require` with the current ESM modules _controversial_ implementation.\r\n\r\n```\r\nconst pkg = require('./package.json', {\r\n  cache: false,\r\n});\r\n```\r\n\r\nIn the current scope of things, we have this implementation for reading a `JSON` file:\r\n```\r\nconst pkgFilepath = path.join(ROOT, 'package.json');\r\nconst pkg = JSON.parse(fs.readFileSync(pkgFilepath, 'utf8'));\r\n```\r\n\r\nor for reading a js file\r\n\r\n```\r\nconst filePath = resolve(anySupportedExtFile);\r\ndelete require.cache[path.resolve(filePath)];\r\nconst file = require(filePath);\r\n```\r\n\r\n\r\nThe requested feature is easily polyfilled and non-breaking. I am willing to write its code if we get some consensus.\r\n\r\nCheers!",
        "labels": "feature request",
        "id": 43372
    },
    {
        "title": "ES6 ${} causing an Uncaught TypeError: Cannot convert object to primitive value ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.4.0\r\n* **Platform**: macOs 10.13.1\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI was running a simple nodejs server, using nodejs url module to parse request.url.\r\nAfter sending request to this server, the interpreter threw error in the place where a parsed query object embraced by ES6 ${} is supposed to be logged.\r\n\r\n```\r\nconst http = require('http')\r\nconst url = require('url')\r\n// let port = process.argv[2]\r\n\r\nlet port = 9000\r\nconst server = http.createServer()\r\nserver.listen(port)\r\n\r\nserver.on('request', (request, response) => {\r\n\r\n    let requestUrl = require('url').parse(request.url, true)\r\n\r\n    let path = requestUrl.path\r\n    let query = requestUrl.query\r\n\r\n    // console.log(`path: ${path}`)\r\n    // console.log('requestUrl: ',requestUrl)\r\n\r\n    console.log(`querytype: ${typeof query}`)\r\n    console.log(`query: ${JSON.stringify(query)}`)\r\n    // this will throw error: console.log(`query: ${query}`)\r\n    // this won't throw error : console.log(query)\r\n\r\n\r\n    response.statusCode = 200\r\n    response.end('')\r\n})\r\n```",
        "labels": "feature request",
        "id": 43373
    },
    {
        "title": "Implement window.fetch into core",
        "body": "**Edit:** please note that this issue is pretty old and a lot of the information in the first few comments isn't up to date - for current status please see https://github.com/nodejs/node/issues/19393#issuecomment-776529831 .\r\n\r\n--------\r\n\r\nhttps://github.com/bitinn/node-fetch\r\n\r\nIt would make sense if window.fetch was implemented into core. it seems to be a stable enough API that would make a good candidate for inclusion. Not sure what the process is from here but thought I'd raise an issue :)",
        "labels": "feature request",
        "id": 43374
    },
    {
        "title": "Call linker when dynamically importing inside a vm.Module",
        "body": "#### Dynamically importing from a Module\r\nCurrently `vm.Module` can construct and evaluate modules just fine, but there's no way for one of those modules to dynamically import another file e.g.:\r\n\r\n```js\r\nconst mod = new vm.Module(`\r\n    import(\"./otherModule.mjs\");\r\n`);\r\nawait mod.link((specifier, module) => {\r\n    console.log(\"Expected this be called on dynamic import!\")\r\n});\r\n\r\nmod.instantiate();\r\n\r\nconst { result } = await mod.evaluate();\r\n// Error: Cannot find module ./otherModule.mjs\r\nawait result;\r\n```\r\n\r\nNow for dynamic import reusing the linker function should be sufficient as the algorithm for resolving a dynamic module should be the same as for a static module.\r\n\r\nHence we can do `import(\"some-specifier\")` with this simple process:\r\n\r\n1. Repeat the linker algorithm starting by letting `importedModule` be `linkerFunction(\"some-specifier\", importingModule)`.\r\n2. Perform `importedModule.instantiate()`.\r\n3. Perform `importedModule.evaluate()`\r\n4. Resolve the promise for `import(\"some-specifier\")` with `importedModule.namespace`.\r\n5. NOTE: If any of the above steps fail then reject the Promise for `import(\"some-specifier\")`\r\n\r\n---\r\n\r\n#### Dynamically importing from a Script\r\n\r\nBecause the script goal also supports dynamic import we need a way to be able to create a `vm.Script` with a dynamic import hook, I'm not really sure where this should go, perhaps a `linker` option to `script.runInContext(...)` (and variants).\r\n\r\nFor this to be easily compatible with `vm.Module` then `vm.Script` should also support the `url` option in lieu of `filename` so that the linker can just inspect the `.url` property to perform linking.\r\n\r\ne.g.:\r\n\r\n```js\r\nconst script = new vm.Script(`\r\n    import(\"./someModule.mjs\");\r\n`, {\r\n    url: \"file:///my-directory/my-cool-script.js\",\r\n});\r\n\r\nscript.runInContext(context, {\r\n    linker(specifier, scriptOrModule) {\r\n        const resolvedUrl = new URL(specifier, scriptOrModule.url);\r\n        // fetch and instantiate module\r\n        return importedModule;\r\n    },\r\n});\r\n\r\n```",
        "labels": "feature request",
        "id": 43375
    },
    {
        "title": "NODE_PATH in package.json",
        "body": "I wish there was a way to add a folder or folders to the Node module path via package.json, instead of just thru the NODE_PATH env var.\r\n\r\nCurrently, a user can add a folder to the module path by running a script like this:\r\n\r\n`NODE_PATH=my_modules node index.js`\r\n\r\nThis allows the user to load modules from `my_modules` without specifying the path, making the script cleaner and more portable.\r\n\r\nI wish there was way to do this inside package.json, perhaps with a \"path\" array?\r\n\r\n```\r\n\"path\": [\r\n  \"my_modules\"\r\n]\r\n```\r\n\r\nBy specifying the path inside the package.json instead of the CLI command, it would apply to any script within the package. Subsequently, NODE_PATH usage could be removed from NPM script commands.\r\n\r\nThanks for considering this!\r\n",
        "labels": "feature request",
        "id": 43376
    },
    {
        "title": "Adding Websocket support to core",
        "body": "The original thread where adding this was discussed #1010 was closed with a decision by the iojs TC  to rather implement [lower level buffer methods](https://github.com/nodejs/node/pull/1202), but that was abandoned.\r\n\r\n[There is an open EPS](https://github.com/nodejs/node-eps/pull/6) to add the feature, but we have since abandoned the process.\r\n\r\nSome of the people who originally were -1 changed their opinions in #1010 more recently. In fact, we already ship a partial implementation of ws in the inspector.\r\n\r\nI think it might be worth us revisiting adding WS to core.\r\n\r\n/cc @eugeneo @rauchg ",
        "labels": "feature request",
        "id": 43377
    },
    {
        "title": "Standardize `ready` event for built-in streams",
        "body": "Currently, various internal streams have different events that indicate that the underlying resource has successfully been established:\r\n\r\n- `fs` streams use the [`open`](https://nodejs.org/api/fs.html#fs_event_open) event once the file descriptor is available\r\n- `net.Socket`s use the [`connect`](https://nodejs.org/api/net.html#net_event_connect) event once the socket has been established\r\n- `Http2Stream`s use the [`ready`](https://nodejs.org/api/http2.html#http2_creation) event once the underlying http/2 session is established\r\n\r\nI would like to suggest standardizing on emitting `ready` for all of these streams, i.e. emitting `ready` for `fs` streams and network sockets in addition to the event names they currently use.\r\n\r\nIf there are no objections, I think this makes for a good first contribution.",
        "labels": "feature request",
        "id": 43378
    },
    {
        "title": "Building with full-icu by default",
        "body": "Currently, users cannot rely on full i18n support to be present cross-platform and even cross-distribution mainly because different package maintainers use different configurations for ICU and if Node.js was built with `system-icu` one still has to have `libicu` installed. Browsers on the other hand generally do support full i18n out of the box.\r\n\r\nThere is the option to use the [`full-icu`](https://github.com/unicode-org/full-icu-npm) package but it  is somewhat awkward to use as it requires a environment variable or commandline switch to work.\r\n\r\nBuilding with `full-icu` is currently a ~40% increase binary size (on macOS, it goes from 35M to 49M). Is this an acceptable tradeoff? I'm thinking that if we build with it, ICU data should be moved in-tree so the build does not rely on external downloads.\r\n\r\ncc: @nodejs/intl ",
        "labels": "feature request",
        "id": 43379
    },
    {
        "title": "feature request - listen for foreign/alien/non-child process change/exit",
        "body": "This is a feature request. I had a use case where I needed to listen for a parent process to exit, instead of a child process to exit. I wanted a solution that didn't use polling. Using `tail` or `ps` or `lsof` required polling, etc.  Given a PID, or some other piece of information, we should be able to use a non-polling solution to listen for changes to a non-child process event, especially 'exit'.\r\n\r\nSpecifically, my use case is I want to create a one-line mutex, where I pass the parent PID to the child process. Once the parent process exits (most likely user sent the shell a SIGINT), the child deletes the lock. This obviates the need to explicitly release the lock in the parent process, which is much more user friendly - they just need one line of code to acquire the lock, and the lock automatically is released. I got this to work, but it was trickier than I thought it would ever be, due to the difficulty of IPC with non-child processes, not only in Node, but with *nix itself.\r\n\r\nhttps://github.com/ORESoftware/quicklock/blob/master/nodejs.md\r\n\r\nI ended up doing it in pure bash later on, after I figured out how to do with with Node.\r\nHere are the C files that I needed to get this to work with no polling (at least as far as I know it does not use polling):\r\n\r\nhttps://github.com/ORESoftware/quicklock/tree/master/src\r\n\r\non Darwin, it uses kqueue, so that it is evented.\r\non Linux, it uses `ptrace()` to \"seize\" the process and make it a \"child process\", and then uses `waitid()`.\r\n\r\nand those executable files are simply used like so:\r\nhttps://github.com/ORESoftware/quicklock/blob/master/lib/unlock.ts#L54\r\n\r\nso what I am looking for is an API like this in Node:\r\n\r\n```js\r\nprocess.onForeignExit(<pid>, function(err, code){\r\n\r\n});\r\n```\r\n\r\nan error might occur for a number of reasons, foremost of which is if the given pid is not alive at all. We might also wish to use other information besides pid, although I assume that's the most accurate thing to use.\r\n\r\nI don't know about most languages, but C# has this functionality:\r\nhttps://msdn.microsoft.com/en-us/library/fb4aw7b8(v=vs.110).aspx\r\n",
        "labels": "feature request",
        "id": 43380
    },
    {
        "title": "Expose internal statValues in a consumer friendly way.",
        "body": "The `fs.stat` and `fs.statSync` methods have access to an internal `statValues` typed array which holds things like raw `mtimeMs` values. It would be nice to avoid creating an entire stats object for one-off things like `mtimeMs` and friends.\r\n\r\nSince Node is already tracking these values in a way that makes it easy to pluck them individually what do you all think about splitting each value out into their own method which then accesses the internal `statValues` array instead of creating a catch-all for all-values as the stat methods do today?\r\n\r\nRelated: This would also nicely side step [the perf issue](https://github.com/nodejs/node/pull/12818) associated with `stat` too.",
        "labels": "feature request",
        "id": 43381
    },
    {
        "title": "[Tracking] loop/threadpool stats from libuv",
        "body": "If/Once https://github.com/libuv/libuv/pull/1764 lands and we get libuv 2.0 into core, we'll have the ability to collect more accurate timing and count stats from the event loop and thread pool. Will be able to emit these via trace events and performance API fairly easily and without the overhead that using separate uv_check_t, uv_prepare_t, and uv_idle_t handles introduces.\r\n\r\n",
        "labels": "feature request",
        "id": 43382
    },
    {
        "title": "exposing SSL_get_finished and SSL_get_peer_finished ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Subsystem**: `tls` (`tls.TLSSocket`)\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis is a feature request to expose OpenSSL routines `SSL_get_finished` and `SSL_get_peer_finished` as `tls.TLSSocket.getFinished()` and `tls.TLSSocket.getPeerFinished()`, respectively. They are required to implement the current version of `rippled` peer protocol; see ripple/rippled#2413 for details.",
        "labels": "feature request",
        "id": 43383
    },
    {
        "title": "Import [folder_name].js by default",
        "body": "Version: v8.1.4\r\nPlatform: Windows 10 64-Bit\r\n\r\nIf I have the following file structure:\r\n\r\n/book/book.js\r\n\r\nIt would be nice if I could import it via:\r\n\r\nimport book from '/book/'\r\n\r\nrather than:\r\n\r\nimport book from '/book/book'\r\n\r\nI believe current behavior is to import index.js by default when a folder is provided, however if a file exists with the same name as the folder, perhaps that could take priority over index.js. I believe this would save a lot of code in many applications.",
        "labels": "feature request",
        "id": 43384
    },
    {
        "title": "`os` needs fix to detect CPUs or fall back to 1",
        "body": "[NPM fails](https://github.com/npm/npm/issues/19265#issuecomment-348054385) when `os.cpus()` returns undefined. Maybe `os.cpus()` should output something better with sane fallback default values?\r\n\r\nJust an idea. Not sure if it's preferable to expect other programs to check for undefined.",
        "labels": "feature request",
        "id": 43385
    },
    {
        "title": "Support typing \"exit\" or \"quit\" means exit from REPL.",
        "body": "And why nodejs doesn't know that?",
        "labels": "feature request",
        "id": 43386
    },
    {
        "title": "`ecdh.setPublicKey` is actually useful and should be undeprecated",
        "body": "So `ecdh.setPublicKey` has been deprecated since v5.2.0, but there is a certain use case where it is very useful: when you need to uncompress a compressed public key.\r\n\r\nHere's how I would uncompress such a public key:\r\n\r\n```javascript\r\nconst crypto = require('crypto');\r\n\r\nlet ecdh = crypto.createECDH('secp256k1');\r\necdh.generateKeys();\r\n\r\nlet private_key_compressed = ecdh.getPrivateKey(null, 'compressed');\r\nlet public_key_compressed = ecdh.getPublicKey(null, 'compressed');\r\n\r\n// Public key is a buffer of 33 bytes\r\nconsole.log('Compressed public key:', public_key_compressed.length, public_key_compressed);\r\n\r\n// Create a new ecdh object\r\necdh = crypto.createECDH('secp256k1')\r\n\r\n// Use the compressed public key to set the public key\r\necdh.setPublicKey(public_key_compressed);\r\n\r\n// Get the uncompressed get\r\nlet public_key_uncompressed = ecdh.getPublicKey();\r\n\r\n// The returned key is a buffer of 66 bytes long\r\nconsole.log('Uncomrpessed public key:', public_key_uncompressed.length, public_key_uncompressed);\r\n```\r\n\r\nIf `ecdh.setPublicKey` where to disappear I would require another library just for this simple task.",
        "labels": "feature request",
        "id": 43387
    },
    {
        "title": "Feature Idea: Brotli support in core",
        "body": "Taking a quick peek at [\"can i use\"](https://caniuse.com/#feat=brotli) shows that brotli is now supported on Edge, Firefox, Chrome, Safari, and iOS Safari.\r\n\r\nThe [iltorb](https://www.npmjs.com/package/iltorb) package has 912k downloads a month.\r\nThe [brotli npm package](https://www.npmjs.com/package/brotli) has 250k download a month\r\n\r\nIf people are open to this I would be willing to collaborate on a patch to add this functionality.",
        "labels": "feature request",
        "id": 43388
    },
    {
        "title": "Node support of OpenSSL using CAPI engine for Windows distribution",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:  8.9.4\r\n* **Platform**:  Windows 64 bit\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nRunning node js in production environment especially running on Windows computers needs the ability to utilize the Windows certificate store to obtain the PKI trust store as part of TLS communication.\r\n\r\nThe CAPI library is already supported by OpenSSL as a configuration when building the library.\r\n\r\nCan this be configured already and supported in node, if not it would be a good idea to add it for Windows distribution.\r\n\r\nCompanies don't want their private keys exported and available on the OS like is required today with https.request using TLS\r\n",
        "labels": "feature request",
        "id": 43389
    },
    {
        "title": "crypto.alloc() for encryption key memory management",
        "body": "@indutny and everyone working on the `crypto` module:\r\n\r\nAt present, using a `Buffer` for a crypto key exposes the key to core dumps, swapping,  and forking. The user also has to remember to erase the key once done. Granted, core dumps and swapping can be disabled system wide, but some libraries such as `libsodium` take care of this automatically, without the user having to know the fine details.\r\n\r\nWould you be open to a `crypto.alloc()` method to allocate buffers for use as crypto keys and help with [crypto memory management](https://download.libsodium.org/doc/helpers/memory_management.html), this would:\r\n\r\n1. Set the platform equivalents of `MADV_DONTFORK `, `MADV_DONTDUMP`, and `mlock` as far as possible.\r\n\r\n2. Automatically zero buffers at GC time before freeing, along the lines of https://github.com/jedisct1/libsodium/blob/be58b2e6664389d9c7993b55291402934b43b3ca/src/libsodium/sodium/utils.c#L78:L101\r\n\r\n3. Hopefully do guarded heap allocations, but 1 and 2 would be enough for a start.",
        "labels": "feature request",
        "id": 43390
    },
    {
        "title": "Allow max heap size to be configured globally",
        "body": "* **Version**: 8.9.1\r\n* **Platform**: Windows\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nAt the moment certain node processes, e.g. Webpack when building large projects, consistently lead to the out-of-memory error `FATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory`. While it is possible to increase the heap size by calling e.g. `node --max-old-space-size=4096 ./node_modules/.bin/webpack` this is not ideal, especially when executing scripts via NPM defined on the `package.json`'s `scripts` field. \r\n\r\nhttps://github.com/npm/npm/issues/12238 gives an idea of how cumbersome it is to have to preface every script name with `node --max-old-space-size=4096 ./node_modules/.bin/`. Meanwhile other solutions such as https://github.com/endel/increase-memory-limit are ugly hacks at best.\r\n\r\nThis all could be avoided if Node offered a way to globally configure the max heap size, for instance via an environmental variable or a config file. When using Node for frontend tooling there isn't the luxury of just one or two scripts needing to be launched once and then let run forever. There are tons of different scripts used for all kinds of purposes that developers execute in the course of their daily work, and it would be great if there was a simple way to set the max heap size to be higher for all of them.",
        "labels": "feature request",
        "id": 43391
    },
    {
        "title": "\"console.read/readline\" wanted",
        "body": "Just a simple method but very useful for console app's IO.\r\nUntil now we don't have console.read/readline yet but console.log instead.",
        "labels": "feature request",
        "id": 43392
    },
    {
        "title": "Consider freezing Object.prototype for security reasons",
        "body": "* **Version**: any\r\n* **Platform**: any\r\n* **Subsystem**: \r\n\r\n## THE PROPOSAL:\r\n\r\n1. Add Node.js CLI option to control freezing of `Object.prototype` on startup\r\n2. As possible, emit a deprecation warning whenever `Object.prototype` is modified.\r\n3. Over time (e.g. Node.js v11+), enable freezing of  `Object.prototype` by default.\r\n\r\n## JUSTIFICATION:\r\n\r\nThe issue formalizes proposal/discussion started here: https://www.reddit.com/r/node/comments/7y341t/quick_cve20183721_proto_from_jsonparse_mitigation/\r\n\r\n* It's a known poor practice to modify `Object.prototype` in production code.\r\n* There are known vulnerabilities related to overriding of `__proto__` properties under some conditions.\r\n    - There are also plenty of closed Node.js issues one or another way related to the problem.\r\n* Packages which override `toString()`, `valueOf()` or  other standard names require just minor modifications.\r\n    - e.g. use of`Object.defineProperty()`, assigning a new object to class `.prototype` with the key already defined or other variation.\r\n* There are known popular libraries like `should.js` which will break:\r\n  - users can fallback to old behavior through the command line option described above\r\n  - users can migrate to expect/assert or other assertion interface\r\n* As Node.js has already seen Promise-related enforcements, why not to do that for `Object.prototype` as well?\r\n",
        "labels": "feature request",
        "id": 43393
    },
    {
        "title": "Diagnostics: Caching module version",
        "body": "At the recent Diagnostics Summit in Ottawa, several of the APM developers who attended expressed a desire to have Node.js be able to cache and provide the module *version* from it's associated package.json. This could be grabbed at the same time that we grab the `main` but it would likely have a performance impact on loading. Opening this as a tracking issue in case anyone wants to take on the task.",
        "labels": "feature request",
        "id": 43394
    },
    {
        "title": "Add async emit methods to EventEmitter",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nv8.9.4\r\n\r\n* **Platform**:\r\nDarwin pumba-5.local 17.4.0 Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST 2017; root:xnu-4570.41.2~1/RELEASE_X86_64 x86_64\r\n\r\n* **Subsystem**:\r\nevents\r\n\r\nhttps://nodejs.org/api/events.html#events_asynchronous_vs_synchronous instructs users to cause asynchronous event execution in the event handlers by using `setImmediate` or `process.nextTick`, which means that, when using `EventEmitter#emit`, asynchronous event handling is left to clients, and the `EventEmitter` has no control over whether an event is handled asynchronously or synchronously.  In cases where the `EventEmitter` is sensitive to performance, the `EventEmitter` itself can dictate the event emission is asynchronous via code similar to the following:\r\n```\r\nclass MyClass extends EventEmitter {\r\n  // ...\r\n  doSomething() {\r\n    process.nextTick(() => this.emit.bind(this).call('myEvent', {foo:'bar'}))\r\n    // ...\r\n  }\r\n}\r\n```\r\nThe `emit` line above could be replaced by something convenient like\r\n```\r\nthis.emitNextTick('myEvent', {foo:'bar'})\r\n// or\r\nthis.emitImmediate('myEvent', {foo:'bar'})\r\n```\r\nor, even more conveniently,\r\n```\r\nthis.emitAsync('myEvent', {foo:'bar'})\r\n```\r\nwhich uses either `setImmediate` or `process.nextTick` according to the current environment.\r\n",
        "labels": "feature request",
        "id": 43395
    },
    {
        "title": "O_SYNC with O_APPEND flag in fs.open?",
        "body": "fs.open can receive \"rs+\" flag and sets O_SYNC flag for cases when I need to know in callback that data has written to the hard drive (and not waiting in kernel cache) but is there a reason why there is no \"as\" or \"as+\" flag which sets the same O_SYNC flag but just for appending file (O_APPEND) ?\r\n",
        "labels": "feature request",
        "id": 43396
    },
    {
        "title": "Need backward compatibility to use http1 on Http2Server",
        "body": "* **Version**: 9.5.0 (Current)\r\n* **Platform**: Any\r\n* **Subsystem**: http2\r\n\r\n**Details:** \r\n* I was experimenting with http2 on fastify NodeJS Server by following [this doc](https://github.com/fastify/fastify/blob/master/docs/HTTP2.md)\r\n* Once http2 is out of experimental phase in Node v10, I'm planning to use its plain text version for communication between microservices.\r\n* For backward compatibility, I noticed that http2 allows http1 connection for `Http2SecureServer ` https://github.com/nodejs/node/blob/6d84ecefcd7da51ee5f9613f745ba5d0a9818726/lib/internal/http2/core.js#L2456-L2457\r\n* However, I couldn't find an option to pass `allowHTTP1` in options for `Http2Server`\r\nhttps://github.com/nodejs/node/blob/6d84ecefcd7da51ee5f9613f745ba5d0a9818726/lib/internal/http2/core.js#L2529\r\n\r\nSince microservices are updated independently of each other, we need a way to provide backward compatibility for http2 plain text server. Is there a plan to provide such option for Http2Server?",
        "labels": "feature request",
        "id": 43397
    },
    {
        "title": "Request: In the http2 session API, add an event that fires when a PING request frame is received",
        "body": "On the server in particular, I would like to be able to see incoming pings, and possibly take action based on their frequency. A per-session event seems like a good way to do that.",
        "labels": "feature request",
        "id": 43398
    },
    {
        "title": "Surface Open CL Bindings, CUDA Bindings, or v8 GL to Node. GPU Accellerated Node.",
        "body": "I had slacked on submitting this request a few weeks ago. But I'd love to see bindings for GPU-accelerated be surfaced to NodeJS. Right now the story for GPU processing is pretty non-existent and I'd love to find a way to bring the power of SIMT, CUDA Thread processing and other GPU specific optimizations to NodeJS. Things like hashing, graph traversals, and complex searches all would benefit from this if leveraged with these said bindings. \r\n\r\n@jasnell asked I bring this up in an issue again so we could see if partners could come together to help collaborate on a set of bindings.",
        "labels": "feature request",
        "id": 43399
    },
    {
        "title": "RFC: Per Package Loader Hooks",
        "body": "# Per-package loader hooks\r\n\r\nThis proposal seeks strong support for per-package loader hooks.\r\nThis is a definition of how to achieve them.\r\n\r\n## Problem\r\n\r\nIndividual application and packages have loading considerations that vary. The ability to globally mutate the Node module system is problematic and causes packages to alter each other's behavior implicitly.\r\n\r\nCommonJS had various abilities to mutate the CJS loader with `NODE_PATH`, `require.extentsion`, etc. These have all been deprecated. \r\n\r\nVarious workarounds to these use cases [do exist](https://github.com/nodejs/node-eps/blob/master/002-es-modules.md#4321-how-to-support-non-local-dependencies) but do not apply to all code using these patterns.\r\n\r\n## Example Use Cases\r\n\r\n* [Setting how Bare import specifiers work](https://github.com/search?l=JavaScript&q=module._initPaths&type=Code&utf8=)\r\n* [Dynamically creating new modules whenever a package is imported](https://www.npmjs.com/package/meow)\r\n* Transpilation\r\n\r\n## Proposal\r\n\r\n### Scope of hooks\r\n\r\nHooks must be confined to a well defined subsection of the URL space (`fs`) used by `import`.\r\n\r\nThis proposal will define the boundaries of subsections to be:\r\n\r\n* A directory containing package.json will have a termination when crossing the directory.\r\n\r\nGiven the `fs` of:\r\n\r\n```\r\n/path-searching-hook\r\n/foo\r\n  /package.json\r\n  /bar/example.mjs\r\n/a\r\n  /package.json\r\n  /a.mjs\r\n```\r\n\r\n```js\r\n// /foo/bar/example.mjs\r\nimport '../' // does not cross boundary by resolving to `/foo`\r\nimport '../..' // does cross boundary by resolving outside of `/foo` to `/`\r\n```\r\n\r\n```js\r\n// /a/a.mjs\r\nimport '../foo' // does cross boundary by resolving out of `/a`\r\nimport '../foo' // does cross boundary by resolving to `/foo`\r\n```\r\n\r\n### Consumer and Author negotiation\r\n\r\n* It must be possible as a consumer to affect the path resolved within another package's scope.\r\n* It must be possible as a author to affect the path resolved within the author's package scope.\r\n\r\nIn order to avoid recursive boundary crossing in one step, all paths will be resolved in two phases. This is similar to \r\n\r\n1. External resolution that is resolved by consumers from a different package scope.\r\n2. Self resolution that is resolved by the package scope containing the resolved path.\r\n\r\n```js\r\n// /a/a.mjs\r\nimport('/foo');\r\n\r\n// 1. fires /a 's package scope loader hooks, seeing `/a/a.mjs` as source and `/foo` as specifier\r\n// lets assume it resolves to /foo\r\n// 2. fires /foos 's package scope loader hooks, seeing `/foo` as source and `./` as specifier\r\n```\r\n\r\n### Declaration of hooks\r\n\r\nPer package loader hooks can be declared in a `package.json` file as a specifier to find using the globally defined resolution algorithm.\r\nGlobal hooks may affect this resolution, but package hooks may not.\r\nThis allows code coverage, instrumentation, etc. to access package hooks.\r\n\r\n```js\r\n{\r\n  \"name\": \"foo\",\r\n  \"loader\": \"../path-searching-loader\"\r\n}\r\n```\r\n\r\nThis also allows the hooks to exist outside of package boundaries. This file when loaded as a loader will be in a separate Module Map space from userland and only has the globally defined resolution algorithm.\r\n\r\n### Types of hooks\r\n\r\n* only a resolve hook. use `vm.Module` to obtain a new URL if you need to create Module records dynamically.\r\n\r\n## On the nature of static resolution\r\n\r\nESM is able to link statically and there should be a path to allow static / ahead of time usage of per package hooks ideally.\r\n\r\nBy only having a single `resolve` hook, paths can be rewritten and observed to do in-source replacement.\r\n\r\nThis is problematic however, since `vm.Module` lives in memory.\r\nUsage of such APIs on platforms without writable `fs` like Heroku should have a path forward for these hooks.\r\n\r\nI recommend a combination of V8's SnapshotCreator when possible, and a flag to allow rewriting `vm.Module` reservations to a location on disk.\r\n\r\n### Problem, multiple boundary crossing\r\n\r\n```\r\n/root\r\n  /package.json\r\n  /entry\r\n    /package.json\r\n  /dep\r\n    /package.json\r\n```\r\n\r\nIf `entry` were to `import('../dep')`. It would be handled in the typical `entry` hooks then `dep` hooks manner. This does not give `root` a chance to intercept the imports.\r\n\r\nThis is seen as a suitable limitation since `root` is presumed to have ownership of `entry` and `dep`'s source code by them existing within its directory. Edit the `entry` and `dep` packages as needed in order to achieve hooking that goes through `root`'s use cases.\r\n\r\n### Composition\r\n\r\nHooks should have a means by which to achieve composition. This is needed for cases of multiple transformations. A package might seek to call a `super` of sorts to get the result of a parent loader, and it may seek to do the exact opposite as a guard to ensure expected behavior.\r\n\r\nLoaders therefore need to have a concept of a parent loader hooks to defer to, or to ignore.\r\n\r\nChanging hook allocation to be done using `new` and providing the parent as a paremeter is sufficient for this:\r\n\r\n```js\r\n#! node --loader\r\nmodule.exports = class LogImports {\r\n  constructor(parent) {\r\n    this.parent = parent;\r\n  }\r\n  async resolve(specifier, referrer) {\r\n    debugger;\r\n    const ret = await this.parent.resolve(specifier, referrer);\r\n    console.log(url, 'became', ret);\r\n    return ret;\r\n  }\r\n}\r\n```\r\n\r\n#### Example use cases for composition\r\n\r\n* Code Coverage\r\n* Instrumentation such as APM\r\n* Mocks/Spies in testing frameworks\r\n* Logging/Debugging\r\n* Compilation\r\n* Linting\r\n* Isolation (such as with code signing)\r\n\r\n#### Isolation\r\n\r\nHooks that are composed still are isolated by per-package boundaries. Nested packages will not fire the `parent` loader hooks unless they cross into a package boundary with those hooks.\r\n\r\nPassing arbitrary data between instances can be problematic for both isolation and threading. Therefore the only data passed between instances of loaders will be transferables (including [structured clone algorithm](https://nodejs.org/dist/latest-v8.x/docs/api/v8.html#v8_serialization_api)) or primitives.\r\n\r\nThe `parent` passed to the constructor of a loader will be a limited facade that only shows white listed properties and calls the relevant method on the true parent instance. It will ensure errors are thrown if given improper arguments length and/or non-transferable data.\r\n\r\n### Per-package composition\r\n\r\nCan be achieved by manually constructing the chain inside their per-package hook code.\r\n\r\n### Global composition\r\n\r\nCan be achieved by providing multiple `--loader` flags. This allows for better debugging when development loaders need to be added. The full design of this is left to another RFC.\r\n\r\n```js\r\nnpm start\r\n# => node hasErrors.mjs\r\n# aborts\r\nexport NODE_OPTIONS='--loader DebugImports'\r\nnpm start\r\n# will log imports if HasErrors defers to the parent loader\r\n```\r\n\r\n#### Ignoring parents\r\n\r\nIn certain scenarios a package may need to ignore the parent loader. In those situations the hooks will be unable to defer to the default global behavior of the process, which may provide debugging behavior such as logging/code coverage/linting/etc.\r\n\r\nFor now escape hatches are punted on this design space to userland, but it is recommended that when using `NODE_ENV=development` or `NODE_ENV=test` all loaders defer to the parent loader.\r\n\r\n#### Code signing invariant implications\r\n\r\nMutating the code loaded in a code [signed bundle](https://github.com/WICG/webpackage) is problematic. Integrity checks of unexpectedly mutated imports should fail. This area needs more research. Use of any sort of in-source translation should be avoided.\r\n\r\n### Future research\r\n\r\nGiven the problems of ignoring scripts and code signing being unable to easily defer to parent loaders more design needs to be done around development workflows. Inspector tooling is the recommended approach. This may mean adding special hooks to inject loader hooks during development via a flag such as `--inspector-loader-hooks=LogImport` that may fire *before* per package hooks but ensures the inspector is running. Such hooks would not be suitable for production environments.\r\n\r\nThis design also does not instrument CJS as loaders currently are not able to instrument CJS. It is not a design goal of this specification to add CJS support to ESM loaders; however, any design for CJS loaders that is presented should and will be considered for compatibility reasons.",
        "labels": "feature request",
        "id": 43400
    },
    {
        "title": "Any way to decode a buffer containing hex into another buffer?",
        "body": "Does Node provide any way to decode a buffer containing hex into another buffer without creating an interim string?\r\n\r\nI would like to accept an encryption key from the user via a TTY prompt, inputted as hex and received as a buffer, and then decode the hex in this buffer to another buffer containing the raw key.\r\n\r\nAll the work must be done using buffers and not strings since the secret must be erased immediately after working with it. Using an interim string would prevent the secret from being erased from the string's underlying memory. V8 garbage collection might be slow to erase the string and the program is long-running.\r\n\r\nAs a side note, it seems Node's hex and base64 routines assume a change of data type is necessary in the input and output of de/encoding routines. e.g. If the input is a string, then the output must be a buffer, and if the input is a buffer, then the output must be a string. i.e. The data type must change from string>buffer or from buffer>string during the de/encoding. The de/encoding work is conflated with converting a buffer to a string data type and vice versa.\r\n\r\nYet in C, these de/encoding routines are not conflated with a change in data type, i.e. you can decode a buffer containing hex data to a buffer containing binary data, without being forced to change the buffer to another type along the way.\r\n\r\nBuffer.transcode looks promising but I'm not sure it supports hex?",
        "labels": "feature request",
        "id": 43401
    },
    {
        "title": "No line number to show you where you forgot to handle errors for promises",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:  v9.3.0\r\n* **Platform**: Windows 10.0.16299 Build 16299 64-bit\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nSomething really annoying about working with promises is that I never know where I forgot to handle errors. Would it be possible to extend the debug stack to show me the line where I forgot the .catch()?",
        "labels": "feature request",
        "id": 43402
    },
    {
        "title": "Feature request: add `preserveSymlinks` option to `require.resolve()`",
        "body": "According to [the docs](https://nodejs.org/api/modules.html#modules_require_resolve_request_options), the only option currently on `require.resolve(path[, options])` is `paths`. I have a project that I'm trying to eliminate a dependency on [browserify/resolve](https://github.com/browserify/resolve#resolvesyncid-opts), and the only thing holding me back is that my library needs to know the resolved path of a given string while preserving symlinks, regardless of whatever the end-user has set their global Node environment to.\r\n\r\nI propose a second option be added to this method named `preserveSymlinks` which behaves the same way as the [--preserve-symlinks](https://nodejs.org/api/cli.html#cli_preserve_symlinks) CLI flag and ENV var, but is local only to the call on `require.resolve()`. \r\n\r\nI attempted to work around this by changing the `NODE_PRESERVE_SYMLINKS` env var at runtime, but it had no effect.\r\n\r\nIf this seems like an agreeable enhancement to `require.resolve`, I'd happily take a stab at a PR",
        "labels": "feature request",
        "id": 43403
    },
    {
        "title": "Debugging: no simple way to get a list of pending async computations",
        "body": "* **Version**: v8.9.3 / any\r\n* **Platform**: Windows 8.1 x64 / any\r\n* **Subsystem**: debugger API\r\n\r\nConsider the case when some library created a long `setTimeout` or any `setInterval` and didn't cancel it when finished some main action. There should be a tab in Inspector (and corresponding debugger API) to show the list of pending asynchronous computations, so that it's clear why Node.js process is unable to shut down.",
        "labels": "feature request",
        "id": 43404
    },
    {
        "title": "No DNS Search Domain support in C-Ares calls",
        "body": "* **Version**: node:9.2.0-slim (Docker image)\r\n* **Platform**: Linux 8f48fe466727 4.9.49-moby 1 SMP Fri Dec 8 13:40:02 UTC 2017 x86_64 GNU/Linux\r\n* **Subsystem**: dns\r\n\r\nIt would seem that currently, Node.js calls through the C-Ares DNS resolver (`resolve4()` and `resolve6()`) don't support search domains.\r\n\r\nIs this a bug? If not, are there current or planned configuration options to specify them?\r\nShould this issue be cross-posted to the C-Ares repository?\r\n\r\nTo make reproduction of this issue easier, I created a Docker-based repository that you can find here:\r\n\r\nhttps://github.com/Mickael-van-der-Beek/node-dns-test\r\n\r\nPS: Be careful to not use Alpine Linux as Docker based image due to `muslc` being used and not `glibc`. I will create a ticket about this in their repository later.\r\n\r\nEDIT: Might be related to this issue that was supposedly fixed in the past: https://github.com/nodejs/node/issues/9799",
        "labels": "feature request",
        "id": 43405
    },
    {
        "title": "CONTRIBUTING.md improvements",
        "body": "* **Version**: n/a\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nA problem with our `CONTRIBUTING.md` is that it is very long and is often needlessly wordy.\r\n\r\nMost people who are reading the doc are probably clicking through to it from the interface where they are opening a pull request or an issue.\r\n\r\nIn other words, they are just about to do something. That is a terrible time to put a super long document in front of them. Ideally, it would be a short document with just what people need.\r\n\r\nUnfortunately, that can be in tension with other purposes/uses of `CONTRIBUTING.md` such as to advertise our values and be welcoming. So, removing content might hit objections.\r\n\r\nI had intended to go through and make it more concise in a piecemeal fashion without eliminating content. See https://github.com/nodejs/node/commit/90abfd672fca7df6ead766d919935d8e4a678091 for example. But then&hellip; \r\n\r\nI went to open a pull request in ESLint and came across [this magnificent example of a `CONTRIBUTING.md`](https://github.com/eslint/eslint/blob/eb4b1e03f82e3e76db65de07b07d2f94d0a8b25e/CONTRIBUTING.md).\r\n\r\nNice and short, but links out to the things you need to know. If you're opening a bug report it doesn't put hundreds of words about change requests in front of you. That sort of thing. \r\n\r\nSo, if someone wants to try to re-organize our `CONTRIBUTING.md` to be more like that one, I'd be ðŸ‘. Necessary caveat: There are 106 other Collaborators on Node.js and they are likely to have opinions too and their opinions may contradict mine or each other's. Doc changes are hard enough as is, but do be prepared for the too-many-cooks problem. Don't get discouraged!\r\n",
        "labels": "feature request",
        "id": 43406
    },
    {
        "title": "Feature request: Autocomplete filenames for `fs` functions in repl",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.2.1\r\n* **Platform**: macOS Sierra\r\n* **Subsystem**: repl\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIf I type the following code into the repl, and then press `tab`, a list of autocomplete suggestions appears for the `require`-able files in the current directory:\r\n\r\n```\r\nrequire('./\r\n```\r\n\r\nIt would be nice if a similar thing would happen when calling methods like `fs.readFileSync`. Specifically, after typing the following code, I would want the REPL to autocomplete with all existing files in the current directory:\r\n\r\n```\r\nfs.readFileSync('./\r\n```\r\n\r\nThis would be useful when using the REPL to process/view a file.",
        "labels": "feature request",
        "id": 43407
    },
    {
        "title": "feture request: \"fs.readdir\" support json option",
        "body": "**description**\r\n\r\nsometimes we may need to do some batch operation on a folder of json files, so it would be much more convenient to add an json option for `fs.readdir`, just like:\r\n\r\n```javascript\r\nfs.readdir(path, { encoding: 'json' })\r\n// or\r\nfs.readdir(path, { encoding: 'application/json' })\r\n// or\r\nfs.readdir(path, { type: 'application/json' })\r\n```\r\n\r\nat present we can just get buffer objects, when the json object is nested, it bring much problems when parsing and translating the buffer.",
        "labels": "feature request",
        "id": 43408
    },
    {
        "title": "enhancement: provide list of allowed flags of current executable",
        "body": "It'd be useful for [Mocha](/mochajs/mocha) and other certain CLI applications to have a list of supported flags of the current process available.\r\n\r\nMany users which to execute a CLI app like `mocha` with Node.js flags, e.g. `--experimental-modules`. Mocha spawns a `node` process with any requested flags in place, and Mocha loads/runs JavaScript files from within this child process (there may be better ways to do this, but that's not what this issue is about; please put your ideas in [Mocha's issue tracker](/mochajs/mocha/issues) :wink:).\r\n\r\nThis puts a maintenance burden on Mocha to explicitly add support for new Node.js flags (I can provide a list of PRs over the years, but this is basically a 1:1 relationship between new Node.js flags and pull requests).  \r\n\r\nThese flags appear in `mocha --help`. Mocha is unable to *remove* any flags unless it maintained a lookup of Node.js-version-to-allowed-flags itself  (FWIW, I'm unsure if Node.js has ever actually removed a flag).\r\n\r\n(Mocha *could* simply support something like `--node-flags='--harmony --trace-warnings'` option, but this a little too user-hostile for my taste, and doesn't solve the problem of listing the flags.)\r\n\r\nFlags listed under `--v8-options` are *not* shown in `mocha --help`, because Mocha can blindly pass through any flag matching `^--v8-.*`.  In the context of this issue, I'm *not* proposing v8-specific flags are listed.\r\n\r\n* * *\r\n\r\nThese two issues (adding new flags, removing old ones) could be mitigated (going forward) if Node.js provided information on allowed flags in its current executable via an Array in `process`.  For example:\r\n\r\n```js\r\n> process.allowedFlags\r\n[\r\n  {\r\n    name: 'v', \r\n    alias: 'version', \r\n    description: 'print Node.js version'\r\n  },\r\n  {\r\n    name: 'napi-modules', \r\n    description: 'load N-API modules (no-op - option kept for compatibility)'\r\n  },\r\n  {\r\n    name: 'trace-warnings', \r\n    description: 'show stack traces on process warnings'\r\n  }\r\n  // etc etc\r\n]\r\n```\r\n\r\nMocha and other CLI apps like it could consume this information and use it to allow/disallow flags as well as print the information in a \"help\" page.\r\n\r\nReasonable?",
        "labels": "feature request",
        "id": 43409
    },
    {
        "title": "ipv6only listen option",
        "body": "Currently, listening on the `::` address will attempt to bind on IPv4 and IPv6, whatever is available. This works most of the time but a issue arises on Linux with the `ipv6.disable=1` kernel option set (which can be default on certain NAS devices). With it, listening on `::` results in a `EAFNOSUPPORT` error. To work around and still get a IPv4 socket, one would have to apply one of these workarounds:\r\n\r\n1) Listen on `::`, catch the `EAFNOSUPPORT` error and listen again on `0.0.0.0` on error.\r\n2) Listen on `::` and `0.0.0.0` and ignore both the `EAFNOSUPPORT` (can happen on `::`) and `EADDRINUSE` (happens on the latter call when dual-stack actually works) errors.\r\n\r\nTo resolve above ugly error handling, I suggest exposing the existing `UV_{TCP,UDP}_IPV6ONLY` flags on [`server#listen`](https://nodejs.org/api/net.html#net_server_listen_options_callback) and [`socket#bind`](https://nodejs.org/docs/latest/api/dgram.html#dgram_socket_bind_options_callback) via a new boolean option `ipv6only`. With the option set, one can listen on `::` and `0.0.0.0` without any unexpected errors happening.\r\n\r\nRelated: nginx also features the [`ipv6only` option](https://nginx.org/en/docs/http/ngx_http_core_module.html#listen), which has been enabled by default since v1.3.4.",
        "labels": "feature request",
        "id": 43410
    },
    {
        "title": "Support url *strings* in fs APIs",
        "body": "* **Version**: 7.6.0+\r\n* **Platform**: all\r\n* **Subsystem**: fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nRight now the FS APIs do support URLs - but only if they are passed as URL objects. This seems to go against the use of URLs in DOM APIs where methods tend to accept strings. E.g. `fetch` only \"accepts\" URL objects because they happen to stringify to their `.href` property.\r\n\r\nWould it be acceptable to extend the current support for file URLs to \"any string starting with `file://` will be treated like a URL object\"? This would remove the need for people to manually create import and then instantiate a URL object if they already have a valid file URL (e.g. via `import.meta.url`).",
        "labels": "feature request",
        "id": 43411
    },
    {
        "title": "allow wildcard match in util.debuglog()",
        "body": "* **Version**: all\r\n* **Platform**:  all\r\n* **Subsystem**: util\r\n\r\nRefs: https://github.com/nodejs/node/issues/13728\r\n\r\nCurrently, `util.debuglog()` doesn't support wildcard. It will be more dev friendly if it could.\r\nConsider the structure below, \r\n```\r\nâ”œâ”€â”€ classifiers\r\n|   â”œâ”€â”€ logical-regression.js\r\n|   â””â”€â”€ linear-regression.js\r\n|   â””â”€â”€ decision-tree.js\r\n|   â””â”€â”€ ..lots of files...\r\nâ”œ-index.js\r\n```\r\nwe might have different files in the same module, and we really don't want to output those logs at the same time. \r\n\r\nSo a possible solution could be, we define a prefix/postfix to the same module, e.g. `util.debuglog('classifiers-logical-regressions')`, `util.debuglog('classifiers-linear-regression')`\r\n\r\nThen we could define the NODE_DEBUG below to output `*-regressions` only logs, would be `logical-regression` and `linear-regression` in this case.\r\n\r\n```\r\n> SET NODE_DEBUG=classifiers-*-regression\r\n> node index.js\r\n```\r\n\r\nPlease feel free to add more comments. ",
        "labels": "feature request",
        "id": 43412
    },
    {
        "title": "I think child_process.fork() should officially support { detached: true }",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.2.1\r\n* **Platform**: Linux ip-172-31-29-251 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: child_process\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`child_process.spawn()` supports an option [`detached`](https://nodejs.org/api/child_process.html#child_process_options_detached) which \"makes it possible for the child process to continue running after the parent exits.\" `child_process.fork()` does not officially support `detached` as one of its options (by \"officially support\", I mean that it is not documented as a valid option); but I think it should be officially supported.\r\n\r\nMy reasons:\r\n\r\n1. It works today. (details below)\r\n2. It's useful. (details below)\r\n3. I can't think of any reason that it shouldn't be supported.\r\n\r\nIf you agree, then no code changes would be required, but the documentation for `child_process.fork()` would need to list `detached` as a valid option. (Also, TypeScript's `@types/node` would need to be updated, but that would probably be a separate GitHub issue somewhere else.)\r\n\r\n**1. It works today:** First of all, if you look at the [current source](https://github.com/nodejs/node/blob/b1e6c0d44c075d8d3fee6c60fc92b90876700a30/lib/child_process.js#L54) for `child_process.fork()`, it's clear (and not surprising) that `fork()` is just a simple wrapper around `spawn()`. It passes most options through unchanged.\r\n\r\nTo prove that `detached` works with `fork()`: save this as demo.js:\r\n\r\n```js\r\n// launch with \"node demo.js\" or \"node demo.js detached\"\r\n\r\nconst child_process = require('child_process')\r\n\r\nif (process.argv.indexOf('--daemon') === -1) {\r\n    let options = {};\r\n    if (process.argv.indexOf('detached') >= 0) {\r\n        options.detached = true;\r\n    }\r\n\r\n    const child = child_process.fork(__filename, ['--daemon'], options);\r\n    console.log('hello from parent; press ^C to terminate parent')\r\n    process.stdin.read()\r\n} else {\r\n    console.log(`hello from child, my pid is ${process.pid}`)\r\n    setInterval(() => {}, 5000)\r\n}\r\n```\r\n\r\nTo see the NON-detached behavior, launch it with `node demo.js`. It will call `fork()`, so there are now two instances running. Then press ^C; if you do `ps aux | grep demo.js` you will see that both instances terminated.\r\n\r\nTo see the detached behavior, repeat the above but with `node demo.js detached`. In this case, after ^C, the child process is still running.\r\n\r\n**2. It's useful:** `child_process.fork()` can be useful for starting daemon processes, and `detached` is certainly useful for daemons.",
        "labels": "feature request",
        "id": 43413
    },
    {
        "title": "crypto createHash `SHA-1` to `SHA1`",
        "body": "* **Version**: v8.9.3\r\n* **Platform**: all\r\n* **Subsystem**: crypto\r\n\r\nThe official rendering of the \"Secure Hash Algorithm 1\" is \"SHA-1\" according to [the RFC](https://tools.ietf.org/html/rfc3174) and [FIPS 180-4](http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf).  Emphasis on the hyphen.\r\n\r\n`crypto.createHash` however expects the name `SHA1` and fails on `SHA-1`:\r\n\r\n```js\r\n> crypto.createHash('SHA1')\r\nHash { ... }\r\n> crypto.createHash('SHA-1')\r\nError: Digest method not supported\r\n    at new Hash (crypto.js:81:18)\r\n    ...\r\n```\r\n\r\nWould it make sense to add an alias in the node crypto library?",
        "labels": "feature request",
        "id": 43414
    },
    {
        "title": "Allow --perf-prof an --perf-basic-prof in NODE_OPTIONS",
        "body": "Profiling Node.js programs which spawn another Node.js processes using Linux prof is unnecessarily hard: new processes use executable from the parent process, so it is not possible to add a shell wrapper around Node to add `--perf-prof` to a subprocess, one has to find all the places where subprocesses are spawned and add the argument there.\r\n\r\n`NODE_OPTIONS` is perfect for this task (just run the top-level process with it and all subtree will emit profiling data), but it does not support `--perf-prof` or `--perf-basic-prof` at the moment.\r\n\r\nPlease add it.\r\n",
        "labels": "feature request",
        "id": 43415
    },
    {
        "title": "Set windowsHide flag when call child_process.fork in cluster.fork",
        "body": "I'm not very sure about this, actually i'm a newbie to node's cluster, but it doesn't make a lot of sense to me to show many console windows when build a cluster.\r\n\r\nFor a real world scenario, I'm using pm2 with the --instances argument. It opens too many black console windows, which really annoying.",
        "labels": "feature request",
        "id": 43416
    },
    {
        "title": "Add trace_events Clock Sync Event for Date.now() and hrtime()",
        "body": "* **Version**: >= 8.x\r\n* **Platform**: all\r\n* **Subsystem**: trace_events\r\n\r\n`trace_events` has an internal clock, this makes it very difficult to correlate the data with other external data. I would suggest that we emit a [Clock Sync Event](https://docs.google.com/document/d/1CvAClvFfyA5R-PhYUmn5OOQtYMH4h6I0nSsKchNAySU/edit#heading=h.rgcugfne66rf) on startup for synchronizing with `Date.now()` and `process.hrtime()`.\r\n\r\n/cc @nodejs/v8 - as we currently lack a `trace_events` specialist.",
        "labels": "feature request",
        "id": 43417
    },
    {
        "title": "proposal: standardize header size prepended before executing scripts in v8",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version* all*:\r\n* **Platform* all*:\r\n* **Subsystem*: coverage,testing*:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n## Problem\r\n\r\nI've been working with folks on the v8 team to try to move towards using v8's built in coverage as a viable way to collect coverage for Node.js scripts outside of the browser.\r\n\r\nWhen a common-js module is executed in v8, the script is wrapped in a closure which introduces 62 additional bytes to the first line of the application. When an ES module is executed I believe it introduces a different byte count (there's actually no wrapper?).\r\n\r\nIt's difficult for tooling that instruments JavaScript source to predict what header might have been inserted on a source file before it was executed in v8; This leads to inaccurate stack traces and coverage reports. \r\n\r\n## Goals\r\n\r\n* Accurate stack-traces and test coverage tracking, regardless of whether a module is common-js or ESM.\r\n* A developer writing tooling should not have to know what path a module took through the loader.\r\n\r\n## Potential Solution\r\n\r\n* standardize on a padding size that will be inserted on the first line of a script executed in v8 (e.g., 128 characters); ESM or common-js should pad to this size with a no-op, e.g., throw a bunch of spaces on the end of the header.\r\n* expose this padding size as a global variable so that developers writing tooling can reference this value, rather than hardcoding a value.\r\n* it would also be good to do something similar for shebang handling.\r\n\r\nCC: @chrisdickinson, @bmeck, @schuay, @ak239\r\n\r\n",
        "labels": "feature request",
        "id": 43418
    },
    {
        "title": "Native support for loading environment variables",
        "body": "Node based apps are working great with environment variables.\r\nIt is simple to modify the dynamic values based on the app purpose.\r\nBut when it comes to development environment I find it is coming short.\r\n\r\nFor example, for `test` and `production` environments,\r\nmy configuration file can be the same,\r\nand read the variables from the automated building tool environment (`gitlab-runner`, `travis` ...).\r\n\r\nBut for the development phase, running on the local machine of the developers,\r\nwe want the developers to easily modify the values (like `port`, `dbUrl` ...).\r\n\r\n`dotenv` is a great try, but you have to install it as a `dependency`,\r\nthough it's actually a `devDependency`.\r\nI don't want to have something like this in my production app:\r\n\r\n```js\r\nif (process.env.NODE_ENV != PRODUCTION)\r\n    dotenv.config();\r\n```\r\n\r\nAnd while you could argue that I can remove the `if` statement,\r\nmy application still depends on the library.\r\n\r\nI think it could be great if the platform (`node`) could have load the environment variables (like [docker](https://docs.docker.com/engine/reference/commandline/run/#set-environment-variables--e-env-env-file) does).\r\n\r\nAnd so my `package.json` would look something like this:\r\n\r\n```json\r\n\"start\": \"node build/index.js\",\r\n\"start:dev\": \"node --env-file=env-vars.json build/index.js\"\r\n```\r\n\r\nDevelopers now can easily commit and modify the `env-vars.json`,\r\nand the environments are still provide great agility.\r\n\r\nWhat do you guys think?",
        "labels": "feature request",
        "id": 43419
    },
    {
        "title": "console: implement console.table and console.dirxml",
        "body": "Hi everyone!\r\n\r\nFollowing #17004 , #17033 and a discussion with @Trott , I'd like to suggest we implement the remainder of the console methods described in the [WHATWG living standard](https://console.spec.whatwg.org/).\r\nMost of them are already implemented, the only ones left are [`console.table()`](https://console.spec.whatwg.org/#table) and [`console.dirxml()`](https://console.spec.whatwg.org/#dirxml).\r\n\r\nUnless everyone thinks it's a waste of time, I'd like to give it a shot. But of course, help will be deeply welcomed.\r\nIn any case, I think I'll start off with `console.dirxml()` if it's ok.\r\n\r\nComments and advices welcomed!",
        "labels": "feature request",
        "id": 43420
    },
    {
        "title": "Proxy Protocol native support",
        "body": "Are there any plans to support Proxy Protocol natively for http/https?  There's some [wrappers](https://github.com/findhit/proxywrap) available, but seems like it would be appropriate to offer this as a native solution.  Common use case is using ELB's with TCP.\r\n",
        "labels": "feature request",
        "id": 43421
    },
    {
        "title": "add `off` as an alias for `removeListener`",
        "body": "Hello!\r\n\r\nI'd like to open an issue to advocate for adding an `off` method to `EventEmitter` as an alias of `removeListener`, to parallel the existing `on` alias for `addListener`. \r\n\r\n_I know that this has been opened a few times in the past (on old node.js and on io.js), but many of the issues were a **long** time ago, the landscape has converged a lot more on the `off` method since then, and I'd like to argue it once more with a well-researched issue. Thank you!_\r\n\r\nThis addition would reduce the existing UX confusion that results from missing the very popular and commonly implemented parallel method to `on`. It would provide a nice UX improvement by giving the listener removal use case its own terse method. And it would help to improve interoperability with other very common event emitter libraries in node.js and in the larger Javascript world.\r\n\r\n## Popular Libraries\r\n\r\nThe `on/off` method combination is very popular, and it's used by some of the most popular libraries:\r\n\r\n- [jQuery](http://api.jquery.com/off/)\r\n- [Zepto.js](http://zeptojs.com/)\r\n- [Backbone.js](http://backbonejs.org/#Events-off)\r\n- [Ember.js](https://www.emberjs.com/api/ember/2.16/classes/Evented)\r\n- [Next.js](https://github.com/zeit/next.js/blob/9320d9f006164f2e997982ce76e80122049ccb3c/lib/EventEmitter.js#L21)\r\n- [Vue.js](https://vuejs.org/v2/api/#vm-off)\r\n- [Atom](https://github.com/atom/event-kit/blob/v2.4.0/src/emitter.coffee#L140)\r\n\r\nIt's even exposed by popular node.js libraries too, like [Socket.io](https://socket.io/) and [Primus](https://github.com/primus/primus) which choose to bundle their own event emitters with the `off` method.\r\n\r\nHaving it in these very popular libraries has contributed over time to people coming to expect `off` as the parallel method to `on`. Not having it in node.js creates confusion (links to this coming up!) and reduces interoperability with other libraries.\r\n\r\n## Existing Emitters\r\n\r\nFurther,  if you look at user-land event emitter libraries in NPM, _every single one_ with over 1 million downloads per month implements the `off` method...\r\n\r\n- [`component-emitter`](https://yarnpkg.com/en/package/component-emitter)\r\n  - 14.5m downloads / month\r\n  - Used by libraries like `superagent`, `socket.io`, `analytics.js`, ...\r\n- [`eventemitter3`](https://yarnpkg.com/en/package/eventemitter3)\r\n  - 8.4m downloads / month\r\n  - Used by libraries like `primus`, `http-proxy`, `quill`, `reflux`, ...\r\n- [`eventemitter2`](https://yarnpkg.com/en/package/eventemitter2)\r\n  - 4.1m downloads / month\r\n  - Used by libraries like `pm2`, `grunt`, ...\r\n- [`tiny-emitter`](https://yarnpkg.com/en/package/tiny-emitter)\r\n  - 1.3m downloads / month\r\n  - Used by libraries like `mathjs`, `clipboard`, `es6-map`, `es6-set`, ...\r\n\r\nEven I was a little surprised that it was _this_ popular. It's so commonplace that not a single emitter library above 1 million downloads a month does not implement `off`. Which results in many, many other popular node.js libraries exposing `off` in their own emitters and inherited classes.\r\n\r\nThat doesn't even include the _many_ other event emitter popular libraries that have implemented `off` as well, like [`wolfy87-eventemitter`](https://yarnpkg.com/en/package/wolfy87-eventemitter), [`event-lite`](https://yarnpkg.com/en/package/event-lite), [`co-events`](https://yarnpkg.com/en/package/co-events), [`event-pubsub`](https://yarnpkg.com/en/package/event-pubsub), [`component-emitter2`](https://yarnpkg.com/en/package/component-emitter2), [`event-emitter-es6`](https://yarnpkg.com/en/package/event-emitter-es6), ...\r\n\r\nOr other libraries like [`p-event`](https://yarnpkg.com/en/package/p-event) that handle the `off` method as a first-class property of emitters for compatibility since so many people use it.\r\n\r\nThere are even libraries like [`nee-off`](https://yarnpkg.com/en/package/nee-off), [`emitter-mixin`](https://github.com/yields/emitter-mixin/blob/master/index.js#L61) or [`events-off`](https://github.com/feisty/events-off) which have been created to add in the `off` method to existing event emitters that haven't implemented it.\r\n\r\n## UX Confusion\r\n\r\nAs you can see from above, the `on/off` pattern is very popular. It's intuitive,  it has parallel structure, and it's very terse, which is nice since it's so often used and mixed in to other APIs.\r\n\r\nBut right now node.js only implements the `on` method of the duo, which leads to confusion from anyone who's used these other popular libraries. Confusion like in [this StackOverflow question](https://stackoverflow.com/questions/45272812/node-js-cluster-worker-turn-off-event).\r\n\r\n> Question: ... How does one turn off the callback to prevent further on message callbacks? There happens to be no `off` method. I have to update the callback with a new one and it appears that all the old callbacks are being triggered as well.\r\n> ```js\r\n> cluster.on('fork', worker => {\r\n>   worker.on('message', msg => {// Do something...})\r\n> })\r\n> ```\r\n> Answer: Why they added `.on()` as an alias, but did not add `.off()` as an alias too, I don't really know (seems logical to me). ...\r\n\r\nThis kind of confusion doesn't only happen in the node.js world. You can see the same confusion in other libraries that implement `on` without the `off` parallel, [like in Angular](https://stackoverflow.com/questions/14898296/how-to-unsubscribe-to-a-broadcast-event-in-angularjs-how-to-remove-function-reg).\r\n\r\nTo people who are trying to avoid the confusion in their own codebase, they actually end up having to stop using the `on` method, because it's so easy to forget that `off` doesn't exist as its parallelâ€”[like these folks did](https://github.com/LLK/scratch-gui/pull/266).\r\n\r\n> Since this is easy to miss, would you mind changing our `.on()`s to `.addListener()` so we aren't tempted to `.off()` elsewhere?\r\n\r\nNot having this parallel even leads to some weird differences between the browser and node environments. For example, Socket.io instances have the `off` method client-side, but don't have it server-side, because the node.js core `EventEmitter` doesn't implement it.\r\n\r\n## Previous Issues\r\n\r\nThis issue has been brought up a [few](https://github.com/nodejs/node-v0.x-archive/pull/3338), [different](https://github.com/nodejs/node/issues/1064) [times](https://github.com/nodejs/node-v0.x-archive/issues/5352) [before](https://github.com/nodejs/node/pull/540).\r\n\r\nBut I think a decent amount has changed since then, specifically the amount of other big libraries that have implemented the same pattern, and the amount of userland support for the `on/off` combination.\r\n\r\nHere  are some of the old arguments against adding `off`...\r\n\r\n### \"Off isn't the parallel\"\r\n\r\nOne of the arguments against using `off` was that the word \"off\" in English is not always parallel to \"on\". (It was once pointed out that \"on\" could have an antonym of \"under\" too.)\r\n\r\nBut I think this is _super_ pedantic, and doesn't actually hold that much water. All of the existing support for `on/off` as a pair, and the StackOverflow questions that prove people immediately jump to \"off\" as the antonym prove this. And at this point the amount of support for the combination is only further reinforcing this assumption, which leads to people getting confused.\r\n\r\n> @domenic: It's a pretty common pattern in other event-related libraries (EventEmitter2 and jQuery/Zepto being the biggest I can think of). Coming from client-side, I tried `off` first, and when it didn't work, had to go consult the docs to find `removeListener`.\r\n\r\nIf you really do want to get into the weeds there, there are arguments in favor of it being parallel like:\r\n\r\n> @ljharb: For example, I might see an event emitter, while not as a light switch, as a switch on a walkie talkie - where when \"on\", i hear things that come in on the channel, but when i want to stop listening, i turn it \"off\". There's many kinds of on/off switches so I'm sure we can anecdotally come up with a bunch that do, and a bunch that don't, make sense as metaphors for event emitters, but I don't see how that's convincing or valuable in either direction.\r\n\r\nBut I think (and @ljharb agreed that) this descends into overly pedantic discussions. Instead, the vast amount of support for `on/off` as a combination should prove already that it makes sense to a _lot_ of people, and is widely liked.\r\n\r\nNot only that, but if you want an equally not that useful argument, if you lookup [\"on\" on thesaurus.com](http://www.thesaurus.com/browse/on) the only antonym that even shows up is \"off\". :smile:\r\n\r\n### \"Aliases are bad\"\r\n\r\nAnother of the arguments against it was that aliases are bad, and that `on` should be removed instead of adding `off`. \r\n\r\nBut this is obviously not a solution. There are so many dependencies on `on` that it's not going to be removed, and it shouldn't be. \r\n\r\nPeople like the terseness of `on` _a lot_, and would appreciate the same terseness in `off`. For proof, just look at [the node.js documentation](https://nodejs.org/dist/latest-v8.x/docs/api/http.html). Even though `on` is technically the alias and not the canonical method name, almost all every single code snippet in the node.js docs uses `on` instead of `addListener`â€”that's because people appreciate the terseness it gives you.\r\n\r\n### \"Removing is rare\"\r\n\r\nAnother argument that was brought up against `off` is that using `removeListener` is rare, so it doesn't merit having an alias.\r\n\r\nI think this isn't valid on two counts. \r\n\r\nFirst, in the case of a use case where two methods have a very clear parallel, I don't think it makes sense to omit one of the methods in the pair just because it is used slightly less. The pair should be treated as a single \"feature\". If the alias for `on` is necessary (which I think it is given its broad usage), then the alias for `off` should be paired with it. That's how well-designed APIs accommodate users with a good UX. Otherwise you set people up for an expectation that isn't met.\r\n\r\n> @ljharb: Currently there's a nice pairing of `addListener/removeListener`. `on` exists as an alias for `addListener` - but there isn't a companion to \"on\" in the API - so it's asymmetric. \"off\" is the word that, objectively based on library usage, pairs best with \"on\". So, I think it makes sense to add `off` as an alias to `removeListener`.\r\n\r\nSecond, although using `off` may be less common for the node.js core APIs, because you're often setting up listeners for the duration of the process, one of the main purposes of `EventEmitter` is to be inherited from by userland libraries. And at that point, I don't think we should assume the same usage patterns as for the core APIs. It's very possible there are libraries like Socket.io, or browser use cases like unmounting components that use `off` much more frequently. It's no longer reasonable to force the same usage pattern on everyone else, especially for something this simple.\r\n\r\n> @Delapouite: Adding this alias would also be handy in Socket.io which inherits from EventEmitter.\r\n\r\n## Previous PR\r\n\r\nThe good news is actually that there is already a pull request for this that we can just re-open if we decide it's something that should be added. (Obviously I think it is :smile:)\r\n\r\nhttps://github.com/nodejs/node/pull/540\r\n\r\nAnd as you can see, it's pretty minimal.\r\n\r\nSo I'd like to propose that the existing PR be reopened and merged, or we can resubmit a new one if it conflicts too much with the current codebase.\r\n\r\nThat's it! Thank you for reading this far. \r\n\r\nI'd love to hear what you think in the comments.\r\n\r\n_If anyone else has more examples to add to any of the lists, please let me know. I'm going to cc a few people who had brought this issue up previously â€” @ljharb @ChALkeR @domenic @yosuke-furukawa_",
        "labels": "feature request",
        "id": 43422
    },
    {
        "title": "RFC: speeding up Node.js startup using V8 snapshot",
        "body": "I recently went through Node.js bootstrapping code, and think that we could make it a lot faster using V8 snapshot. I wrote a [design doc](https://docs.google.com/document/d/1YEIBdH7ocJfm6PWISKw03szNAgnstA2B3e8PZr_-Gp4/edit#) that captures the main points.\r\n\r\nThis is somewhat separate from the discussion on using V8 snapshot to capture arbitrary initialized state, discussed [here](https://github.com/nodejs/node/issues/13877). The main difference is that the set of native modules is known upfront, and there is no ambiguity about the native bindings that need to be known to V8's serializer/deserializer.\r\n\r\nI'm doing this as sort of a side project, so it may take some time for me to make progress. Any help is welcome.",
        "labels": "feature request",
        "id": 43423
    },
    {
        "title": "Add `os.sysarch()` to get the architecture of the operating system",
        "body": "Continued from https://github.com/nodejs/node-v0.x-archive/issues/2862. // @Fishrock123 @isaacs @jasnell @feross\r\n\r\n`os.arch()` returns the architecture of the Node.js process, not the operating system. This was surprising to me and many other Node.js users. I don't really see the usefulness of that, although there might be one. My main need is to know the architecture of the operating system so I can spawn the correct binary.\r\n\r\nThere is a clear need for it:\r\n\r\n- https://github.com/electron/electron/issues/6044\r\n- https://github.com/sindresorhus/clipboardy/issues/30#issuecomment-343292703\r\n- https://stackoverflow.com/questions/7897678/get-processor-architecture-from-node\r\n- https://coderwall.com/p/0eds7q/detecting-64-bit-windows-in-node-js",
        "labels": "feature request",
        "id": 43424
    },
    {
        "title": "fs.createWriteStream: add util.promisify support.",
        "body": "* **Version**: v8.9.0\r\n* **Platform**: Linux lt1.cfware.com 4.13.10-200.fc26.x86_64 #1 SMP Fri Oct 27 15:34:40 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: fs\r\n\r\n```js\r\n#!/usr/bin/env node\r\n'use strict';\r\n\r\nconst util = require('util');\r\nconst fs = require('fs');\r\nconst createWriteStream = util.promisify(fs.createWriteStream);\r\nconst {spawn} = require('child_process');\r\n\r\nasync function main() {\r\n  const log = await createWriteStream('output.log');\r\n  spawn('ls', ['-lh'], { stdio: ['ignore', log, log]});\r\n  return 'Done';\r\n}\r\n\r\nmain().then(console.log).catch(console.error);\r\n```\r\nThis causes 'output.log' to be created but empty, node.js exits silently.\r\n\r\nI've created a \"polyfill\" which seems to work and do what I would expect:\r\n```js\r\nconst fs = require('fs');\r\nconst util = require('util');\r\nfs.createWriteStream[util.promisify.custom] = (path, options) => {\r\n  const stream = fs.createWriteStream(path, options);\r\n  return new Promise((resolve, reject) => {\r\n    stream.on('error', reject);\r\n    stream.on('open', resolve);\r\n  });\r\n};\r\n```\r\n\r\nI'm not yet prepared to submit a pull request for this (it will be my first to node).  I have code in lib/fs.js that I think correctly uses the internal version of the promises, I haven't had a chance to build.  I'm not sure what automatic tests would be needed for this feature, I've only tested this manually.  I'm reading the contributor guide but still wanted to submit the bug report now.\r\n\r\nI also haven't had a chance to check out other fs API's like createReadStream, probably appropriate to have similar promisify support.",
        "labels": "feature request",
        "id": 43425
    },
    {
        "title": "Non-UTF-8 env vars ",
        "body": "* **Version**: v8.8.1\r\n* **Platform**: Linux daurn-z170 4.13.7-1-ARCH #1 SMP PREEMPT Sat Oct 14 20:13:26 CEST 2017 x86_64 GNU/Linux\r\n* **Subsystem**: process\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nNode.js doesn't seem to have a way to read environment variables that aren't valid unicode. For both keys and values. e.g. \r\n\r\n```\r\n$ env -i $'F\\xa5B=BAR' node -e 'console.log(process.env)' \r\n{ 'Fï¿½B': undefined }\r\n$ env -i $'FOO=B\\xa5R' node -e 'console.log(process.env.FOO.codePointAt(1))'\r\n65533\r\n```",
        "labels": "feature request",
        "id": 43426
    },
    {
        "title": "File i/o, case sensitivity and cross-platform behavior",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.0.0\r\n* **Platform**: 64 bit Windows and Linux present 3.13.0-108-generic #155-Ubuntu SMP Wed Jan 11 16:58:52 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nSo, when using fs commands across platforms, I've noticed some interesting behavior with case sensitivity. On OSes where case sensitivity is not a concern like Windows and OSX, node's file i/o calls work the same with not caring about case sensitivity. Whereas on Linux it does.\r\n\r\nFor example,\r\n\r\n\r\n    util.promisify(fs.readdir)('./foo/bar.txt').then( files => console.log(file))\r\n\r\n\r\nand\r\n\r\n    util.promisify(fs.readdir)('./Foo/bar.txt').then( files => console.log(file))\r\n\r\nWill do the same thing on OSX and Windows, however on Ubuntu (which I am using in a production environment), will only see what is actually on the file system. As node aims to be cross-platform it may be beneficial to have the stricter behavior be constant.",
        "labels": "feature request",
        "id": 43427
    },
    {
        "title": "HTTP2: Make stream/header/flags classes accessible.",
        "body": "* **Version**: Node.js v8.9.0\r\n* **Platform**: W10 64\r\n* **Subsystem**: HTTP2\r\n\r\nWith the HTTP1 module, you could add your own prototypes to the request and response classes. Some npm packages utilized this, including my own.\r\n\r\nHowever, it seems I am unable to create new prototypes for the stream/headers/flags classes because they are not exposed. The only classes visible to me are Http2ServerResponse and Http2ServerRequest.",
        "labels": "feature request",
        "id": 43428
    },
    {
        "title": "host vs hostname inconsistency",
        "body": "**Version:** Node 8 and others\r\n\r\n## Problem\r\n\r\nThe semantics of the `host` option for `server.listen()` are incompatible with the conventions of other APIs, both in Node itself and in browsers, etc. This is a footgun that could be fixed by making the options for `.listen()` be consistent with other APIs.\r\n\r\n## Context\r\n\r\nMost systems I interact with distinguish between a `hostname` and a `host`, where the latter includes a port number and the former does not.\r\n\r\nIn general, Node behaves this way, too (see `os.hostname()`, WHATWG URL, and the legacy `url` module APIs). However, the option object passed to `server.listen(option)` is weird. It only understands `host` (not `hostname`), but a port number is disallowed. This is confusing and leads to very surprising results in some cases.\r\n\r\n## Prior art\r\n\r\nIn browsers\r\n```js\r\nlocation.href = 'https://localhost:3000';\r\nconsole.log(location.host !== location.hostname);  // true\r\nconst whatwgParsed = new URL('https://localhost:3000');\r\nconsole.log(whatwgParsed.host !== whatwgParsed.hostname);  // true\r\n```\r\n\r\nIn Node.js\r\n```js\r\nconst url = require('url');\r\nconst target = 'https://localhost:3000';\r\nconst legacyParsed = url.parse(target);\r\nconsole.log(legacyParsed.host !== legacyParsed.hostname);  // true\r\nconst whatwgParsed = new url.URL(target);\r\nconsole.log(whatwgParsed.host !== whatwgParsed.hostname);  // true\r\n```\r\n\r\n## Current behavior\r\n\r\nThe `server.listen()` API understands a `host` option, but it is incompatible with `host` from other APIs, including WHATWG URL and others. This is because `.listen()` refuses perfectly valid hosts such as `localhost:3000`. A reasonable expectation would be to try `hostname` instead, which is the more common name for the current behavior of the `host` option. Unfortunately, that doesn't work either, as `.listen()` does not understand `hostname`, and it will be silently ignored.\r\n\r\n```js\r\n// Reports an error correctly, since the API lacks a default port, but the error message is somewhat vague\r\nserver.listen({ host : 'localhost' }, () => {});\r\nError: Invalid listen argument: { host: 'localhost' }\r\n\r\n// Listens on 0.0.0.0 rather than localhost (works as documented, but very confusing and as a footgun is arguably unsafe)\r\nserver.listen({ hostname : 'localhost', port : 3000}, () => {});\r\n\r\n// Reports an error even though the host is valid (works as documented, but confusing and incompatible with other specs and APIs)\r\nserver.listen({ host : 'localhost:3000' }, () => {});\r\nError: Invalid listen argument: { host: 'localhost:3000' }\r\n\r\n// Succeeds, even though host usually takes precedence over separate hostname and port options and the host lacks a port (works as documented, but a bit strange)\r\nserver.listen({ host : 'localhost', port : 3000 }, () => {});\r\n```\r\n\r\n## Expected behavior\r\n\r\nAPIs that accept a `host` should respect their port number to avoid confusion and inconsistency. Having separate options for `hostname` and `port` is also awesome, but in that case it should be named `hostname` instead of `host`. I would argue that Node should _only_ support `hostname` _instead of_  `host` (leaving parsing `host`s to userland) but that would be a breaking change, so I'm not sure how feasible that is. At the very least, I think a new `hostname` option could be introduced with the correct behavior, and then `host` could be extended to respect port numbers, and the fact that `host` continues to be in the API would purely be for backwards compatibility reasons.\r\n\r\n```js\r\n// Should report an intuitive error. The host is perfectly valid, but the API lacks a default port.\r\nserver.listen({ host : 'localhost' }, () => {});\r\nError: No port specified\r\n\r\n// Should listen on localhost, whereas it currently listens on 0.0.0.0 instead because hostname is not understood.\r\nserver.listen({ hostname : 'localhost', port : 3000}, () => {});\r\n\r\n// If host needs to be supported, then this should listen on localhost and port 3000, whereas it currently throws an error.\r\nserver.listen({ host : 'localhost:3000' }, () => {});\r\n\r\n// Should probably throw an error, whereas it currently does not.\r\nserver.listen({ host : 'localhost', port : 3000 }, () => {});\r\n```",
        "labels": "feature request",
        "id": 43429
    },
    {
        "title": "File System (fs) is lacking bindings for lutimes(3)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: ALL\r\n* **Platform**: Linux, Mac, other UNIX\r\n* **Subsystem**: File System (fs)\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nFile System (fs) is lacking bindings for lutimes(3), and thus it is very difficult to modify the metadata for a symbolic link from within a Node.js application.  This C Library function has been implemented in glibc since version 2.6, which is over 10 years old, and has likely been available on the Mac for even longer, given its origins in BSD UNIX.  The behavior on Windows could simply be to call utimes(2).\r\n\r\nThis omission seems like an oversight given the support for symbolic link-aware functions including: lstat, lchmod, and lchown.  Additionally, its peer function futimes(3) is also already supported.",
        "labels": "feature request",
        "id": 43430
    },
    {
        "title": "Meaningful node inspect context titles",
        "body": "Problem: When inspecting multiple node contexts using the new --inspect flag paired with the dedicated node inspect in chrome dev tools, knowing which process you're currently inspecting can be confusing as they're all called \"Nodejs Main Context\" as per (I think):\r\n\r\nhttps://github.com/nodejs/node/blob/5886e204f04013879c00aca5ab653c16bef5befc/src/inspector_agent.cc#L302\r\n\r\nPotential solutions:\r\n- Taking an optional environment variable like NODE_CONTEXT_TITLE (looks like the env might already be being passed in there, not sure if same env as process.env?)\r\n- Could pass in a flag along the lines of --inspect-context-title",
        "labels": "feature request",
        "id": 43431
    },
    {
        "title": "Proposal: provide a straight-forward approach for collecting coverage via Chrome's Profiler",
        "body": "## The Problem\r\n\r\nI've been having an ongoing discussion with @bmeck and a few folks working on the V8 project (@schuay, @fhinkel) about how to move [istanbul](https://github.com/istanbuljs) towards using v8's built-in coverage.\r\n\r\nThe biggest blocker, [tracked in the v8 issue tracker here](https://bugs.chromium.org/p/v8/issues/detail?id=7003), is that we need a way to start Node with detailed coverage enabled. -- @schuay can speak better to the specifics, but as I understand it code needs to be put through a preprocessing step that introduces counters, currently we're only able to collect function-level coverage.\r\n\r\nThere are a few other blockers that I will also outline in this issue.\r\n\r\n## Collecting Detailed Coverage\r\n\r\n- [x] @schuay proposes introducing a v8 flag that could be passed to Node when starting, and would run inspector with detailed reporting enabled; does this mean that we'd need to stat Node.js with _`--inspector` or could we still enable this post-hoc?_\r\n\r\n## Other Challenges\r\n\r\nThere are a few other technical challenges that will need to be addressed, to make the switch over to v8's test coverage:\r\n\r\n- [x] if an application exits using `process.exit` or by throwing an exception, it's hard to capture this event and output the coverage information (since talking to the inspector's socket is asynchronous); One option might be using `spawnSync` within `process.exit()`, [but this currently has bugs](https://github.com/bcoe/c8/issues/2).\r\n- [x] v8's coverage output is significantly different than Itanbul's [coverage.json format](https://github.com/gotwarlost/istanbul/blob/master/coverage.json.md) we'll need to write something that translates between the formats.\r\n\r\n## Why this is super cool\r\n\r\n* transpilation to add coverage counters is complex and error-prone, it would be neat to have this happen at the v8 level.\r\n* code transpiled for test coverage runs significantly slower than the code prior to transpilation; I'm betting collecting coverage directly from v8 will be fast (although the subprocess shenanigans might add some overhead).\r\n* this would give us a way to collect coverage for `.mjs` module files, which is currently not possible since the new module system does not execute `require.extensions`.\r\n",
        "labels": "feature request",
        "id": 43432
    },
    {
        "title": "Feature request: Make calling \"inspector_socket_server.PrintDebuggerReadyMessage\" configurable",
        "body": "For our Node.js process, \"child_process.fork\" is called often in combination with the \"--inspect=port\" flag, to be able to create heapdumps though the DevTools protocol (https://www.npmjs.com/package/node-oom-heapdump).\r\n\r\nBecause of this, our logs are being polluted with the following messages:\r\n\"Debugger listening on ws://127.0.0.1:5859/52f6454f-afaa-4409-a1d1-7db277e27200\"\r\n\"For help see https://nodejs.org/en/docs/inspector\"\r\nThis is caused by the following code: https://github.com/nodejs/node/blob/6e2c29bcabb0507262167494a1fd9bc583cae690/src/inspector_socket_server.cc#L100\r\n\r\nThis issue asks to be able to disable these debug messages, by specifying a command line flag like \"--no-inspect-messages\".\r\n\r\n",
        "labels": "feature request",
        "id": 43433
    },
    {
        "title": "Add public/private keys generation algorithms (RSA, EC) to crypto module",
        "body": "Crypto module offers digital signing functionality with two algorithms: RSASSA-PKCS1-v1_5 and ECDSA?\r\n\r\nBut for these we must have RSA or EC generated public/private key pairs.\r\n\r\nAs I understand crypto doesn't have functionality to generate the above pairs.\r\n\r\nCan this be added to crypto module?\r\n\r\n* **Version**: 8.8.1\r\n* **Platform**:\r\n* **Subsystem**: crypto\r\n",
        "labels": "feature request",
        "id": 43434
    },
    {
        "title": "Exposing the logic behind `require.resolve()` via a public API",
        "body": "Node.js does not expose any public API for resolving dependencies. As a result, there are many packages in the ecosystem that are trying to reimplement/mimic Node's module resolution algorithm.\r\n\r\n[resolve](https://www.npmjs.com/package/resolve), [resolve-from](https://www.npmjs.com/package/resolve-from), [eslint-plugin-import](https://www.npmjs.com/package/eslint-plugin-import)... just to list some of them.\r\n\r\nThe big problem with these implementations is that *they don't work the way Node's `require.resolve` works*. For instance, both `resolve` and `resolve-from` were preserving symlinks by default. I did PRs to both packages to fix this issue but they are just a drop in the ocean.\r\n\r\nI work on [pnpm](https://github.com/pnpm/pnpm) - a Node package manager that uses a [symlinked node_modules structure](https://github.com/pnpm/pnpm/blob/master/docs/symlinked-node-modules-structure.md). This node_modules structure is Node.js-compatible (when Node is executed w/o the --preserve-symlinks flag) but because of the many incorrect implementations of Node's module resolution algorithm, pnpm is basically unusable with most of the popular [frameworks/toolings](https://github.com/pnpm/pnpm/issues/801).\r\n\r\nExposing Node's resolution algorithm would allow experimenting with different node_modules structures and tools/frameworks would adjust because they would resolve dependencies correctly.",
        "labels": "feature request",
        "id": 43435
    },
    {
        "title": "Feature request: Allow 'cwd' in cluster.settings",
        "body": "* **Subsystem**: cluster\r\n\r\n`cwd` is the only property currently missing from `cluster.settings`, but which is available in `child_process.fork()`.\r\n\r\nIt should however only be added after https://github.com/nodejs/node/issues/16387 is resolved, to avoid encouraging people to rush face first into that bug.\r\n\r\nThe actual implementation would just be `cwd: cluster.settings.cwd,` [added here](https://github.com/nodejs/node/blob/master/lib/internal/cluster/master.js#L129).",
        "labels": "feature request",
        "id": 43436
    },
    {
        "title": " Introduce CanvasRenderingContext2D and WebGLRenderingContext",
        "body": "**Feautre request:** Introduce `CanvasRenderingContext2D` and `WebGLRenderingContext` constructors in Node.js. There are a few modules on npm trying to simulate them, but their performance and number of methods (and also number of issues) simply cannot be compared with, for example, Chrome's implementation.\r\n\r\nNode.js doesn't have to display rendered image, just let users obtain rgb24 byte stream to use for further purposes. I tried to create a good implementation and publish it as npm module, but it was a huge failure.\r\n\r\nWhat do you think about this idea? If you want new developers for this purpose, then I cannot help you. But I'm sure this will be a great step for Node.js.",
        "labels": "feature request",
        "id": 43437
    },
    {
        "title": "[feature request]The require() function should be able to resolve export default from .mjs file.",
        "body": "The `require()` function should be able to resolve `export default` from `.mjs` or `.m.js` file.",
        "labels": "feature request",
        "id": 43438
    },
    {
        "title": "child_process: Add child_processes.isRootProcess flag",
        "body": "* **Version**: Future\r\n* **Platform**: All\r\n* **Subsystem**: child_process\r\n\r\nThis is a new feature request to add a flag (boolean) to child_process, called something along the lines of `child_process.isRootProcess` that would return true if the current process is the \"root\" of the child_process.fork tree or false if the current process was a forked process and has an upstream ipc channel.\r\n\r\nIn essence this is a simple one-liner inside of child_process:\r\n\r\n    child_process.isRootProcess = !!process.channel;\r\n\r\nor something similar.\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43439
    },
    {
        "title": "We \"need\" a way to create an Http2Session from a socket",
        "body": "While building [`fetch-h2`](https://github.com/grantila/fetch-h2) and when discussing with [`node-fetch`](https://github.com/bitinn/node-fetch/issues/342), and while participating in #14671 I realize that we need this in Node.js; a protocol-agnostic `connect()` to a TLS-enabled web server and let the ALPN handshake allow for both `\"h2\"` and `\"http/1.1\"`. Without this, we won't be able to connect to an https-server without knowing in beforehand if that server wants to (or even can!) speak HTTP/1.1 or HTTP/2.\r\n\r\nI'm thinking of something like `tls.handoverConnect()` which doesn't take application-level (http) arguments (path, headers, etc), it just connects and returns (through a callback, likely) the protocol (\"http/1.1\" or \"h2\") and a corresponding *session*.\r\n\r\nA question is what the session data is. In case of HTTP/2, it should be an Http2Session, but for HTTP/1.1 it must be something where the user can perform the request, and it should probably be integrated with Agents. There's unfortunately an inheritance jungle in the design of these old functions, like `https.request()` where ip/tcp/application-level options are merged into one blob, but the *\"https/1.1 session\"* here (let's call it `Http1SessionProxy`) should be something that looks like the `http` module, in how it has a `request()` function, with the tcp/ip-level options removed.\r\n\r\nLet's say this feature belongs in `tls` (which I think it does):\r\n\r\n```js\r\nconst connectOpts = { host: \"my-server.com\", port: 443, /* ... */ };\r\n\r\ntls.handoverConnect( connectOpts, ( err, protocol ) =>\r\n{\r\n    if ( err ) ... ;\r\n\r\n    // session is an Http2Session or Http1SessionProxy\r\n    const { name, session } = protocol;\r\n\r\n    if ( name === 'http/1.1' )\r\n    {\r\n        // session.request acts just like http.request\r\n        const req = session.request(\r\n            { path: '/foo', headers, ... },\r\n            ( res ) => { ... }\r\n        );\r\n    }\r\n    else if ( name === 'h2' )\r\n    {\r\n        // well, the usual http2-stuff\r\n        const stream = session.request( headers, options );\r\n    }\r\n} );\r\n```\r\n\r\nIn this example, perhaps an Agent could be passed in the `connectOpts`, so that if the session turns out to be HTTP/1.1, the connection will be added to this agent (and by default the global Agent is used, just like traditional `http{s}.request()`).\r\n\r\nAny thoughts on this? I guess it's a good time to look into this now, as the `http2` module is being tested in the wild, but before it's *\"stable\"*.",
        "labels": "feature request",
        "id": 43440
    },
    {
        "title": "readline module and streams",
        "body": "Currently, `readline` module interface is rather special. `Interface` class is EventEmitter acting as stream, but not conforming to `Stream` interface. It's possible to redirect output to stream, but it's significantly less convenient than just `.pipe`. \r\n\r\nThen I propose one of the following:\r\n\r\n* add class `readline.Stream` subclassing `Transform`. \r\n  * `readline.Interface` can be backed by this stream, then no code duplication occurs. Though, I'm not sure about viability of this approach, as `Interface` contains lots of code related to TTY handling.\r\n* make `readline.Interface` instances subclasses of `Transform` stream\r\n\r\nCompare:\r\n\r\n```js\r\nfoo = getReadableStream();\r\nbar = transformStream();\r\nfoo\r\n   .pipe(readline.Stream())\r\n   .pipe(bar)\r\n   .pipe(process.stdout)\r\n```\r\n\r\nvs.\r\n\r\n```js\r\nfoo = getReadableStream();\r\nbar = transformStream();\r\nreadline.createInterface({\r\n   input: foo,\r\n   output: bar\r\n}); // We are using factory function for side effects.\r\nbar.pipe(process.stdout);\r\n```\r\n\r\nUser-land packages providing this functionality:\r\n* [byline](https://www.npmjs.com/package/byline) (423k downloads per month)\r\n",
        "labels": "feature request",
        "id": 43441
    },
    {
        "title": "Implement createObjectURL/Blob from File API",
        "body": "Tracking Issue to allow Loaders to create in-memory URLs that can be imported for things like code coverage:\r\n\r\n- [ ] [BlobStore](https://w3c.github.io/FileAPI/#BlobURLStore)\r\n- [x] Blob (#36811)\r\n- [ ] URL.createObjectURL\r\n- [ ] URL.revokeObjectURL\r\n- [ ] Move `--loader` to use MIMEs",
        "labels": "feature request",
        "id": 43442
    },
    {
        "title": "async_hooks: no way to EmitDestroy on garbage collection with the high-level Embedder API",
        "body": "* **Version**: 8.7\r\n* **Platform**:\r\n* **Subsystem**: async_hooks\r\n\r\nLet's say I make a super simple `AsyncResource`, that lets me bind a function to always run in a particular executionId.\r\n```js\r\nclass BoundFunction extends asyncHooks.AsyncResource {\r\n\r\n  constructor(f, bindTimeAsyncId) {\r\n    super('CONTEXT_BIND', bindTimeAsyncId);\r\n    this.f = f;\r\n  }\r\n\r\n  run() {\r\n    this.emitBefore();\r\n    const ret = this.f();\r\n    this.emitAfter();\r\n    return ret;\r\n  }\r\n}\r\n```\r\nI can use it with the following wrapper:\r\n```js\r\nfunction bind(f) {\r\n\r\n  const bindTimeAsyncId = asyncHooks.executionAsyncId();\r\n  const boundF = new BoundHook(f, bindTimeAsyncId);\r\n\r\n  return () => boundF.run();\r\n}\r\n```\r\n\r\nHowever, it seems I have no way to schedule cleanup. Let's say I do\r\n```js\r\nconst f = () => console.log(`hello from ${asyncHooks.executionAsyncId()}`);\r\nconst boundF = bind(f);\r\n```\r\nI want `BoundFunction#emitDestroy()` to run once the GC grabs boundF. The docs seem to say that this is a normal approach to async resources, by\r\n\r\n>Note: **Some resources depend on garbage collection for cleanup**, so if a reference is made to the resource object passed to init it is possible that destroy will never be called, causing a memory leak in the application. If the resource does not depend on garbage collection, then this will not be an issue.\r\n\r\nHowever, as far as I can see the JS Embedder API gives me no way to achieve this behaviour.",
        "labels": "feature request",
        "id": 43443
    },
    {
        "title": "fs - add copyDirectory function",
        "body": "A `copyFolder` alias would be useful to have. Though `directory` was the original term and seems more technical, many coders are familiar with the term `folder` and it's quicker to type, and makes for slightly more compact source code.\r\n\r\nI suppose there are some difficulties with `fs.copyDirectory` as it was not included in 8.5.0 alongside `fs.copyFile`. \r\n\r\nI also suggest the option for keeping the original timestamps, like with the issue https://github.com/nodejs/node/issues/15793, which applies to `fs.copyFile`.\r\n",
        "labels": "feature request",
        "id": 43444
    },
    {
        "title": "fs.copyFile - add option to keep timestamps",
        "body": "fs.copyFile - It would be useful to have options to keep date created and date modified timestamps.\r\n\r\nPossibly this would be beyond trivial to implement, but in my opinion it would be an excellent extension to node's cross-platform system capabilities.\r\n",
        "labels": "feature request",
        "id": 43445
    },
    {
        "title": "Add context argument to emitter",
        "body": "As part of the hapi v17 work, I removed every closure from the hot path. This provided significant performance improvements. All these closures came from handlers passed to node EventEmitters (specifically from `req` and `res` object). In order to do that, I had to hang my own property on the emitter object. For example:\r\n\r\n```js\r\nconst handler = function (err) {\r\n    this._context.log(err);\r\n};\r\n\r\n// Inside some prototype methods:\r\n\r\nreq._context= this;\r\nreq.on('error', handler);\r\n```\r\n\r\nThis works and can be improved by using symbols, but it's still messy. It also means adding multiple context properties per handler because they might need different context data. Instead, I would like to be able to do something as simple as:\r\n\r\n```js\r\nconst handler = function (err, context) {\r\n    context.log(err);\r\n};\r\n\r\n// Inside some prototype methods:\r\n\r\nreq.on('error', handler, this);\r\n```\r\n\r\nThe idea is to pass a third optional argument to `on()` and then append that argument to the end of the emit arguments list. We already store listeners as objects with properties. When this feature is not used, it means two additional `if` statements: once to check if a third argument was provided and another to check if one is present and needs to be appended. If no third argument is provided, these two extra `if` statements should not have any noticeable impact on performance.\r\n\r\nHowever, since 99% of the time, emitter handlers require the creation of a callback closure, this should make applications using it much faster overall. Potentially, this can be used internally by node as well.\r\n\r\nThere is already a pattern for this in `setTimeout()`. Most new JS features with callbacks now accept some kind of extra binding argument. Because we already bind the handler to the emitter, we cannot use this pattern.\r\n\r\nI'm happy to do the work if the idea is acceptable.",
        "labels": "feature request",
        "id": 43446
    },
    {
        "title": "Add default module search paths to package.json",
        "body": "I'm using TypeScript, with my source files in `src/` and outputting to `dist/`.  I have modules in `src/modules/` and some other stuff in `src/scripts/`.  The directory structure is maintained when TypeScript transpiles to JavaScript in `dist/`.  However, the `import...` statements are transpiled to `require()` statements with the (non-relative) paths unchanged.\r\n\r\nIn TypeScript, I can refer to my modules without having to use messy relative paths by setting `baseUrl` in `tsconfig.json`.  If I set it to `./src`, I can then import my modules with something like:\r\n`import * as myModule from \"modules/myModule\";`\r\n\r\nHowever when that is transpiled to the Node.js equivalent:\r\n`const my_module_1 = require(\"modules/myModule\");`\r\n\r\n... Node.js doesn't find the module because the file pulling in the module is in `src/scripts`.  Wouldn't it be nice if you could just add module search paths to the beginning of Node's paths list by just having a `moduleSearchPaths` property in `package.json` (@refack suggested using `.npmrc` instead)?  Then the first place Node would search would be those paths and I could just say:\r\n```\r\n    ...\r\n    \"moduleSearchPaths\": [\r\n        \"./dist\"\r\n    ]\r\n    ...\r\n```\r\n\r\n... making Node first search for `dist/modules/myModule.js` - and it would work.\r\n\r\nBy the way, I know you can set the `NODE_PATH` env variable to do this but I think that's a nasty solution because I always try to avoid using env variables.  They don't translate well between different environments.",
        "labels": "feature request",
        "id": 43447
    },
    {
        "title": "Add a requirebase() function",
        "body": "Many of us dislike pointing to our modules using `require()` because using relative paths is bad for maintenance and having to worry about \"how many directories to go up\" is rather annoying when you have a much simpler way to specify your module's location: specify it relative to the root of the project, ie. the directory containing `package.json`.  For more discussion on this see: https://gist.github.com/branneman/8048520\r\n\r\nI actually created an npm module that does this, `requirebase`, found here: https://www.npmjs.com/package/requirebase\r\n\r\nHowever it would be nice if this functionality were built into node.js itself.  Apart from anything else my module doesn't work with ES6-style imports (and therefore TypeScript imports) so it would be nice to have this functionality built in.  So instead of this:\r\n\r\n`import myModule from \"../../lib/myModule\";`\r\n\r\nyou would have something like this:\r\n\r\n`import myModule from base \"src/lib/myModule\";`\r\n\r\n... where `package.json` is in the parent directory of `src`.",
        "labels": "feature request",
        "id": 43448
    },
    {
        "title": "Tracking bug and discussion for asynchronous iteration in Node.js core",
        "body": "Asynchronous iteration [has landed in V8 6.3 ](https://bugs.chromium.org/p/v8/issues/detail?id=5855#c36), so we can have it in Node.js v9 at the end of the year.\r\n\r\nThere are some plans to implement a stream version based on this feature. Since node-eps [seems to be archived](https://github.com/nodejs/node-eps/issues/65), maybe it is worth to have an issue for this in the core repository.\r\n\r\nRefs:\r\n\r\nhttps://github.com/tc39/proposal-async-iteration\r\nhttps://tc39.github.io/proposal-async-iteration/\r\nhttps://bugs.chromium.org/p/v8/issues/detail?id=5855\r\n\r\nhttps://ponyfoo.com/articles/javascript-asynchronous-iteration-proposal\r\nhttp://2ality.com/2016/10/asynchronous-iteration.html\r\nhttps://jakearchibald.com/2017/async-iterators-and-generators/\r\n\r\nhttps://github.com/nodejs/CTC/issues/53\r\nhttps://github.com/nodejs/readable-stream/issues/254\r\nhttps://github.com/tc39/proposal-async-iteration/issues/74\r\nhttps://github.com/nodejs/promises/issues/31 (and https://github.com/nodejs/promises/issues/31#issuecomment-323317862)\r\n\r\nhttps://github.com/calvinmetcalf/async-iter-stream\r\n",
        "labels": "feature request",
        "id": 43449
    },
    {
        "title": "A proposal to add fs.scandir method to FS module",
        "body": "## Problem\r\n\r\nNow any interaction with files and directories in the File System is as follows:\r\n\r\n```js\r\nconst fs = require('fs');\r\n\r\nconst entries = fs.readdirSync('path_to_directory');\r\nconst stats = entries.map(fs.statSync);  // Unnecessary File System access\r\n\r\nconst dirs = [];\r\nconst files = [];\r\n\r\nentries.forEach((entry, index) => {\r\n    if (stats[index].isDirectory()) {\r\n        dirs.push(entry);\r\n    } else {\r\n        files.push(entry);\r\n    }\r\n});\r\n```\r\n\r\nThe problem here is that we are call File System a **second time** due to the fact that we don't know the directory in front of us, or file (or symlink).\r\n\r\nBut we can reduce **twice** File System calls by creating `fs.scandir` method that can return `d_name` and `d_type`. This information is returned from `uv_dirent_t` (`scandir`) ([libuv](http://docs.libuv.org/en/v1.x/fs.html#c.uv_dirent_t)). For example, this is implemented in the `Luvit` and `pyuv` (also use `libuv`).\r\n\r\n## Motivation\r\n\r\n  * Performance â€“ reduce **twice** File System calls\r\n  * More consistency with other platforms/languages\r\n  * Should be easy to implement [`String` â†’ `Object` â†’ `d_name` + `d_type`](https://github.com/nodejs/node/blob/master/src/node_file.cc#L302-L311)\r\n    * For `fs.readdir`: return converted `Object` to `String`\r\n    * For `fs.scandir`: return As is\r\n  * Early speed up for `node-glob` (also for each package that uses `fs.readdir` for traversing directories) in most cases (need `fs.stat` when `d_type` is a `DT_UNKNOWN` on the old FS)\r\n\r\n## Proposed solution\r\n\r\nAdd a methods `fs.scandir` and `fs.scandirSync` in a standard Fyle System module.\r\n\r\n```js\r\nconst fs = require('fs');\r\n\r\nconst entries = fs.scandirSync('path_to_directory');\r\n\r\nconst dirs = [];\r\nconst files = [];\r\n\r\nentries.forEach((entry) => {\r\n    if (entry.type === fs.constants.S_IFDIR) {\r\n        dirs.push(entry);\r\n    } else {\r\n        files.push(entry);\r\n    }\r\n});\r\n```\r\n\r\nWhere `entries` is an array of objects:\r\n\r\n  * `name` {String} â€“ filename (`d_name` in `libuv`)\r\n  * `type` {Number} â€“ `fs.constants.S_*` (`d_type` in `libuv`)\r\n\r\n## Final words \r\n\r\nNow I solved this problem by creating C++ Addon but... But I don't speak C++ or [speak but very bad](https://github.com/mrmlnc/readdir-benchmark/blob/c%2B%2B/src/addon.cc) ([i try](https://github.com/mrmlnc/node/commit/c7047eb8ea3ed39a4b3184fce3b84a0b40bcc1d9) ðŸ˜… ) and it requires you compile when you install a package that requires additional manipulation to the end user (like https://github.com/nodejs/node-gyp#on-windows).",
        "labels": "feature request",
        "id": 43450
    },
    {
        "title": "events: adding multiple listeners at once",
        "body": "I often find myself in need of registering to multiple events using the same handler. `.on` currently only supports on event per call, so this most concise way to write it is\r\n\r\n````js\r\nconst errorHandler = (err) => {\r\n  // handle error\r\n}\r\n\r\nserver.on('error', errorHandler)\r\nserver.on('clientError', errorHandler)\r\nserver.on('tlsClientError', errorHandler)\r\n````\r\n\r\nIdeally, I think `.on` and possibly `.once` should provide a way to add multiple listeners in one call, like for example using jQuery-style space-separated event names:\r\n\r\n````js\r\nserver.on('error clientError tlsClientError', (err) => {\r\n  // handle error\r\n})\r\n````\r\n\r\nAbove would be a breaking change for event names containing spaces, so an alternative could be to take the event names from an array:\r\n\r\n````js\r\nserver.on(['error', 'clientError', 'tlsClientError'], (err) => {\r\n  // handle error\r\n})\r\n````",
        "labels": "feature request",
        "id": 43451
    },
    {
        "title": "assert.deepEqual assertion error depth limit",
        "body": "I think it would be better if the message of `assert.deepEqual` was not limited to a depth of 3, and could display the first difference between the objects, like some testing libraries do\r\n\r\n```js\r\nconst assert = require('assert');\r\n\r\nassert.deepEqual({\r\n\tfoo: {\r\n\t\tbar: {\r\n\t\t\tqux: {\r\n\t\t\t\tlolcat: {\r\n\t\t\t\t\tbip: {\r\n\t\t\t\t\t\tyup: 56\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n}, {\r\n\tfoo: {\r\n\t\tbar: {\r\n\t\t\tqux: {\r\n\t\t\t\tlolcat: {\r\n\t\t\t\t\tbip: {\r\n\t\t\t\t\t\tyup: 56.3\r\n\t\t\t\t\t}\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t}\r\n})\r\n\r\n// outputs:\r\n// AssertionError [ERR_ASSERTION]: { foo: { bar: { qux: [Object] } } } deepEqual { foo: { bar: { qux: [Object] } } }\r\n```\r\n\r\nA simple implementation example: \r\n\r\n```js\r\nconst deepEq = (o1, o2) => {\r\n\tconst keys1 = Object.keys(o1);\r\n\tconst keys2 = Object.keys(o2);\r\n\tif (keys1.length !== keys2.length) {\r\n\t\tassert.deepEqual(o1, o2);\r\n\t}\r\n\tfor (let i=0; i<keys1.length; i++) {\r\n\t\tconst v1 = o1[keys1[i]], v2 = o2[keys1[i]];\r\n\t\tif (v1 && typeof v1 === 'object') {\r\n\t\t\tdeepEq(v1, v2);\r\n\t\t} else {\r\n\t\t\tassert.equal(v1, v2);\r\n\t\t}\r\n\t}\r\n};\r\n```\r\n\r\nThe current [implementation](https://github.com/nodejs/node/blob/master/lib/assert.js#L103) passes the entire objects in the Error, and .toString is limited in 3 in depth I guess",
        "labels": "feature request",
        "id": 43452
    },
    {
        "title": "Support oneshot signal handlers",
        "body": "* **Version**: v6.11.3\r\n* **Platform**:  Ubuntu 14.04.5 LTS trusty, kernel: 3.13.0-119-generic, machine/CPU/platform: i686 i686 i686\r\n* **Subsystem**: process\r\n\r\nI thought we had this solved already long ago in https://github.com/nodejs/node/pull/13894 but unfortunately it seems someone decided it's less important just because it got old. :-(\r\n\r\nIt's bad UX to have a run-away program keep hanging even though a user tries to interrupt it with Ctrl+C multiple times, so I usually advise people to capture their signal handlers with `process.once()` instead of `process.on()`, but that's of limited use until node fully supports it. I'll post a gist link to  a test case in a minute.\r\nUpdate: https://gist.github.com/mk-pmb/e48ded5215cf2f3fa54c5335aa68edd4",
        "labels": "feature request",
        "id": 43453
    },
    {
        "title": "Deterministically generating a string from object",
        "body": "There are a few different contexts where it can be useful to generate a string representation of an object. The basic idea is that the same in-memory representation of the object should always yield the same string.\r\n\r\n- You may want to use an object as a cache key. \r\n- You may want to generate a MAC for an object, for example for use with JSON Web Tokens.\r\n- You may want to store an object to disk or to the database in a way that it can be re-created in memory later.\r\n\r\nFor each of these use cases, a serialization function should generate the same string, or Buffer, for the same object. Generating different strings could lead you to incorrectly conclude the object changed.\r\n\r\nThe most common serialization technique - used for example by the `node-jsonwebtoken` is to call JSON.stringify. However, JSON.stringify does not guarantee deterministic output. The latest ECMA spec for JSON.stringify says that it should produce the same order as Object.keys, which should produce the same order as for ... in, which uses Object.[[Enumerate]]() to enumerate object keys. [[Enumerate]] is a) deprecated, and b) the specification [contains this note][note]:\r\n\r\n[note]: http://www.ecma-international.org/ecma-262/6.0/#sec-ordinary-object-internal-methods-and-internal-slots-enumerate\r\n\r\n> The mechanics and order of enumerating the properties is not specified but must conform to the rules specified below.\r\n\r\nIt would be nice if there were any function in the standard library that could convert an object to a string in a deterministic way. This could be solved in any of the following ways:\r\n\r\n- Declaring that Node's JSON.stringify will always produce the same string output for the same object input. JSON.stringify is controlled by an ECMA specification, and V8, so I'm not sure that this is feasible.\r\n\r\n- Adding a new API to either `crypto` or `util` that takes an Object as input and generates a string, guaranteeing it will generate the same output across Node versions.\r\n\r\n- Documenting that some existing API, for example, `Buffer.from(object)`, `util.format(fmt, object)` with some format string, will always generate the same string for the same object (and different strings for different objects).\r\n\r\nI guess there is some question of what \"the same\" means - roughly, I would think two objects that are equal as defined by something like Lodash's `isEqual` function should generate the same string, and objects that fail an `isEqual` check should generate different strings.",
        "labels": "feature request",
        "id": 43454
    },
    {
        "title": "http: deal with the lack of http proxy support in node.js core.",
        "body": "This is a follow-up on #8381.\r\n\r\n_Summary:_\r\nNode's http module does not support http proxies by default. This is a unfortunate situation as libraries don't use packages for http that support http proxies and as a result quite a few tools in the Node ecosystem lack the support for http proxies _(i.e. through environment variables)_.\r\n\r\nIt would be helpful if Node.js could support user proxies and if someone could take the time to implement it, I think the following plan could help get us there:\r\n\r\n1. Old versions of Node.js will never gain http proxy support so it would be important to have a recommended way how to add proxy support to user-land libraries to work on the old versions of Node.js. A guide on \"how to support proxies\" _(maybe combined with a package)_ seems like a minimum requirement to fix this issue which will help no matter how this topic progresses. _(Anyone can start with this, no need to wait for approval, help dearly welcome)._\r\n2. Create a PR to the Node.js docs in which it clearly explains that proxies are the responsibility of user-land and reference the recommended implementation/article in `1.` _(Just reflecting the current state of affairs)_\r\n3. Create a new discussion on to how the package used in `1.` could become part of Node.js core in order to reduce the implementation cost for current and new packages.\r\n4. Discuss the possibility of creating a Node flag that enables the behavior of `3.` in case someone is stuck with user-land code that doesn't implement proxies.",
        "labels": "feature request",
        "id": 43455
    },
    {
        "title": "N-API feature request: expose API to resolve promises asynchronously without napi_create_async_work",
        "body": "My use case: I have a socket that I'm polling with libuv `uv_poll_t`. When an event is present I want to resolve a promise.\r\n\r\nCalling `napi_resolve_deferred()` does not work for me because it does not appear to run microtasks.\r\n\r\nLooking at the test added in [this commit](https://github.com/nodejs/node/commit/a4505910d29597ff8fd9f95d4effcbf3196f63ca) I need to use the following code before resolving the promise.\r\n\r\n```\r\nv8::Isolate* isolate = v8::Isolate::GetCurrent();\r\nv8::HandleScope scope(isolate);\r\nnode::CallbackScope callback_scope(isolate, v8::Object::New(isolate), {0, 0});\r\n\r\n// resolve promise here\r\n```\r\n\r\nThis works perfectly; but now I am required to pull in both `v8.h` and `node.h`. It would be nice if there were N-API method to resolve promises with `napi_resolve_deferred()` asynchronously.\r\n\r\nNote that I am not able to use `napi_create_async_work()`/`napi_queue_async_work()` for the async code in this case.",
        "labels": "feature request",
        "id": 43456
    },
    {
        "title": "Add a guide for uncaught exceptions in node?",
        "body": "Hi folks,\r\n\r\nBit new to node. I read that one unhandled exception can kill whole node server, is this true? (I guess yes).\r\nNow, given that I think it is not easy to program in a way you are sure that there are never uncaught exceptions, and you don't want that single uncaught exception to kill server, what are the mechanisms node offers to deal with this situation?\r\nI head about cluster. Also domains - but doc says they are deprecated.\r\nSo do you mind adding a guide (maybe here: https://nodejs.org/en/docs/guides/) on the latest trend on how to deal with uncaught exceptions in a robust manner?\r\n\r\nThis is the kind of doc I am referring to, to create doc similar to this one: https://shapeshed.com/uncaught-exceptions-in-node/\r\n(though that one is from 2012)",
        "labels": "feature request",
        "id": 43457
    },
    {
        "title": "http - `res.closed`",
        "body": "h2 compat has a great prop called `closed` which makes it easy to decide whether it is safe to call `writeHead` or not. I don't think there is anything corresponding in h1. Would be nice to have though?\r\n\r\nYou can use `headersSent`. However, that will not work in the case where the connection was closed before headers were sent. Maybe https://github.com/nodejs/node/pull/15285 would be enough? Not sure?",
        "labels": "feature request",
        "id": 43458
    },
    {
        "title": "The option --pending-deprecation should be added to NODE_OPTIONS whitelist",
        "body": "* **Version**: v8.5.0\r\n* **Platform**: Microsoft Windows [version 10.0.15063] (64-bit)\r\n* **Subsystem**: *unknown*\r\n\r\nI wanted to enable the `--pending-deprecation` option via the `NODE_OPTIONS` env variable but received the following message when I tried to run `node`:\r\n> --pending-deprecation is not allowed in NODE_OPTIONS\r\n\r\nI think it's safe to allow this option to be set in `NODE_OPTIONS`.",
        "labels": "feature request",
        "id": 43459
    },
    {
        "title": "Add `#ifdef O_DSYNC`",
        "body": "`node_constants.cc` exports `O_SYNC` on Linux, but `O_DSYNC` should probably be added.",
        "labels": "feature request",
        "id": 43460
    },
    {
        "title": "http2 - cannot use client certificate and key",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n**Version**: 8.4.0\r\n\r\nCurrently, as a client, you cannot specify a certificate-key pair for authentication. I know that the **http2** module is still experimental, but this seems like a useful feature.\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "feature request",
        "id": 43461
    },
    {
        "title": "N-API request: Ability to report fatal exception resulting from callbacks that are thrown outside the regular JS call stack",
        "body": "I am attempting to (re)write a node module to use N-API, but there is an issue that I cannot see a workaround for.\r\n\r\nI want to use `uv_poll_t`/`uv_poll_init_socket` etc. to set up socket polling to handle socket events in the native addon. In the native callback there is a code path that executes a JS callback. Looks something like this:\r\n\r\n```\r\n// env is stored in data field of the uv_poll_t handle\r\nNapi::HandleScope scope(env);\r\nValue().Get(\"emit\").As<Napi::Function>().Call(Value(), {\r\n    Napi::String::New(env, \"message\"),\r\n    msg.ToBuffer(env),\r\n});\r\n```\r\n\r\nUnfortunately any exception thrown in the JS callback will crash the process. Instead I want to report a *fatal exception* to Node, so that it can be delegated to the `uncaughtException` event of `process`.\r\n\r\nEssentially, I want to use this code, identical to what is used in the async callback:\r\nhttps://github.com/nodejs/node/blob/a10856a7d31f9b641bf330fe9edfa9728f4b1c78/src/node_api.cc#L3296-L3301\r\n\r\nBut there seems to be no way to do this. Even if I include `v8.h` and `node.h` I cannot convert the exception from N-API back to a v8 exception so I can call `node::FatalException`.\r\n\r\nIdeally I'd like either:\r\n\r\n1. Ability to call `node::FatalException()` via a supported addition to N-API (so that I can cause an `uncaughtException` event to be emitted); or\r\n\r\n2. Ability to use `uv_poll_t`/`uv_poll_init_socket` etc via a supported addition to N-API, similar to `napi_create_async_work` etc.\r\n",
        "labels": "feature request",
        "id": 43462
    },
    {
        "title": "http - IncomingMessage headers",
        "body": "In h2 incoming headers are created with `Object.create(null)` which allows for some nice optimization. I wonder if we can back port this to https://nodejs.org/api/http.html#http_message_headers? ",
        "labels": "feature request",
        "id": 43463
    },
    {
        "title": "Native BigNum support",
        "body": "## Feature request\r\n\r\nNative BigNum support (exposing OpenSSL `bn` library).\r\n\r\n## Workarounds\r\n\r\n- [`bn.js`](http://npmjs.com/package/bn.js)\r\n- [`bignum`](https://www.npmjs.com/package/bignum)\r\n- [other JS libraries](https://www.npmjs.com/search?q=bignum)\r\n\r\n## Justification\r\n\r\nPure JS implementations have limited performance. Native `bn` wrappers may have better performance (and maybe more functions).\r\n\r\n## To be discussed\r\n\r\n- New module or addition for currently existing?\r\n- API?\r\n- More?",
        "labels": "feature request",
        "id": 43464
    },
    {
        "title": "Lack of ability to quickly declare generic context for VM",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v8.4.0\r\n* **Platform**: Arch Linux (Updated just before posting)\r\n* **Subsystem**: VM\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis would be quite handy for module systems, like the one i am doing. (Loading submodules for a program, and submodules can require one another)\r\n\r\nEDIT: Forgot to define a 'generic context'\r\nI.E. the context you are given when running a file, i.e. `nodejs app.js`",
        "labels": "feature request",
        "id": 43465
    },
    {
        "title": "UnhandledPromiseRejectionWarning",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.4.0\r\n* **Platform**: Mac OS\r\n* **Subsystem**: \r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nAs a beginner, to write server, I always see this but cannot find where is the uncaught error.\r\n\r\nWill you add the line number [or error stack]to this error?\r\n\r\nThanks.",
        "labels": "feature request",
        "id": 43466
    },
    {
        "title": "Limit zlib concurrency",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: Node >= 4\r\n* **Platform**: Linux \r\n* **Subsystem**: Zlib\r\n\r\nRelated to https://github.com/nodejs/node/issues/8871#issuecomment-250915913 and https://github.com/websockets/ws/issues/1202.\r\n\r\nIn the benchmarks in [ws#1202](https://github.com/websockets/ws/issues/1202) on both Linux and Mac platforms we've been able to reproduce a consistent performance benefit when limiting `zlib.deflate()` concurrency:\r\n\r\n```\r\n$ node memleak.js 5\r\nRunning with concurrency 5\r\nDeflate: 969.515ms\r\nMemory: { rss: 90619904,\r\n  heapTotal: 27262976,\r\n  heapUsed: 14900688,\r\n  external: 13115452 }\r\n  \r\n$ node memleak.js Infinity\r\nRunning with concurrency Infinity\r\nDeflate: 4416.701ms\r\nMemory: { rss: 2881708032,\r\n  heapTotal: 191889408,\r\n  heapUsed: 156487272,\r\n  external: 492249148 }\r\n```\r\n\r\nRunning with reduced concurrency not only takes less time, it allocates far less memory and avoids the fragmentation issue altogether.\r\n\r\nMoving to a new allocator to avoid the fragmentation issue would not only be error-prone, it still would not fix the performance issue.\r\n\r\nIs there any interest in implementing a queueing mechanism for limiting concurrency on calls to `zlib` to take advantage of the above benefits without pushing the burden downstream?\r\n",
        "labels": "feature request",
        "id": 43467
    },
    {
        "title": "http2 - http/1 without compat",
        "body": "I would like to be able to handle both http/1 and http/2 requests without the http/2 compat.\r\n\r\n```\r\nconst server = http2.createServer({ allowHTTP1: true })\r\nserver.on('request', (...args) => {\r\n  // TODO Avoid http2 compat\r\n  if (args[0].httpVersionMajor < 2) {\r\n    http1(...args)\r\n  }\r\n})\r\nserver.on('stream', (...args) => {\r\n  http2(...args)\r\n})\r\n```",
        "labels": "feature request",
        "id": 43468
    },
    {
        "title": "url.parse function can't parse '&amp;' to '&'",
        "body": "`parseQueryString <boolean>` If `true`, the `query` property will always be set to an object returned by the `querystring` module's `parse()` method. But if the `querystring` is `v=query&amp;id=1`, that will be parse to `{ v: 'query', 'amp;id': '1' }`, maybe we need `{ v: 'query', id: '1' }`",
        "labels": "feature request",
        "id": 43469
    },
    {
        "title": "feature-request - include sqlite3 as builtin module for node v9.x",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.x\r\n* **Platform**: all\r\n* **Subsystem**: node builtins\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\ni'm generally happy with nodejs keeping the codebase lean and free of cruft, but sqlite3 is the one exception.  it would allow us to write standalone, PERSISTENT webservers in embedded systems with zero-dependencies.  recent activity indicates code for the sqlite3 npm-package has stabilized:\r\n\r\n- https://github.com/mapbox/node-sqlite3/compare/v3.1.8...v3.1.9 (very little change for almost a year)\r\n- https://github.com/mapbox/node-sqlite3/compare/v3.1.7...v3.1.8\r\n",
        "labels": "feature request",
        "id": 43470
    },
    {
        "title": "Exposing OpenSSL RSA KeyGen",
        "body": "I'm trying to understand if there is a reason why RSA KeyGen was never exposed as an API in the `crypto` module. I'm familiar with the pure js solutions such as [`keypair`](https://www.npmjs.com/package/keypair) but they are really slow compared to using OpenSSL. \r\n\r\nWas there any other thread about this where a decision was made?\r\n",
        "labels": "feature request",
        "id": 43471
    },
    {
        "title": "Reload certificate files of https.createServer() without restarting node server",
        "body": "Hi, letsencrypt certificate files expires each 3 months. Is there any way to refresh certificate files without restarting node server? Because using stale/expired certificate causes error ERR_INSECURE_RESPONSE in browser.\r\n\r\n```\r\nvar fs = require('fs');\r\nvar https = require('https');\r\nvar ws = require('ws').Server;\r\nvar config = require('config.js');\r\nvar certificate = {\r\n    key: fs.readFileSync(config.sslKeyPath),\r\n    cert: fs.readFileSync(config.sslCrtPath),\r\n}\r\nvar httpsServer = https.createServer(certificate).listen(config.port),\r\nvar wssServer = new ws({ server : httpsServer });\r\n\r\n// I would like to reload certificate monthly...\r\n\r\n// solution A): just update certificate.cer since variable certificate is passed to createServer() as reference because it is Object (not primitive value)\r\nsetInterval(function() { certificate.cert = fs.readFileSync(config.sslCrtPath); console.log(\"reload cerfificate A\"); }, 1000 * 60 * 60 * 24 * 30);\r\n// ... no success\r\n\r\n// solution B): update directly httpsServer.cert (yes, this property exists when you console.log(httpsServer))\r\nsetInterval(function() { httpsServer.cert = fs.readFileSync(config.sslCrtPath); console.log(\"reload cerfificate B\"); }, 1000 * 60 * 60 * 24 * 30);\r\n// ... property is updated but no success\r\n```\r\n\r\nNo solution works and node always use stale certificate for new incoming https requests and websocket connections too . It would be great to have a new method in returned Object from https.createServer() to reload certificate files e.g.: \r\n`httpsServer.reloadCertificate({key: fs.readFileSync(config.sslKeyPath), cert: fs.readFileSync(config.sslCrtPath)})`\r\n... now, new incoming https requests or websocket connections should be handled with new certificate files\r\n\r\n",
        "labels": "feature request",
        "id": 43472
    },
    {
        "title": "Support parsing pem key only once for crypto api",
        "body": "Current API parses the PEM files on every crypto operation, fx: \r\n\r\n* https://nodejs.org/api/crypto.html#crypto_class_sign\r\n* https://github.com/nodejs/node/blob/0d22858d67f5f8f7959a55ceca23adafe12827d5/src/node_crypto.cc#L4168\r\n\r\nI would be nice if this could be done once and a ref to the openssl key could be retained:\r\n\r\n``` javascript\r\nconst crypto = require('crypto');\r\n\r\n// Read and parse key once\r\nconst privateKey = crypto.readPrivateKey(getPrivateKeySomehow());\r\n// privateKey would be a ref to the PEM_read_bio_PrivateKey() pointer\r\n\r\nfor(let i = 0; i < 10000; i++) {\r\n  const sign = crypto.createSign('RSA-SHA256');\r\n  sign.write('some data to sign' + i);\r\n  sign.end();\r\n  console.log(sign.sign(privateKey, 'hex'));\r\n}\r\n```",
        "labels": "feature request",
        "id": 43473
    },
    {
        "title": "n-api: Add optional length to functions accepting const char * ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8\r\n* **Platform**: all\r\n* **Subsystem**: n-api\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nMigrating nodejs/abi-stable-node#254 opened by @RReverser to this repo for better visibility:\r\n\r\nAs discussed in the last meeting, zero-terminated `const char*`, while popular in C land, might be problematic for consumers in other languages having different string representation (for example, Rust with non-zero-terminated string slices represented as `data` + `length`).\r\n\r\nSome N-API functions already accept optional `length` that, when set to `-1`, would mean a length calculated from zero-terminated string and explicit byte length otherwise.\r\n\r\nIt's worth to go through a list of functions that accept `const char*` and add `length` parameter where it's missing, especially for functions that don't provide variants with `napi_value` as a string, namely:\r\n\r\n - `napi_create_function`\r\n - `napi_define_class`\r\n - `napi_module_register` -> `napi_module` struct",
        "labels": "feature request",
        "id": 43474
    },
    {
        "title": "Option to pause only until debugger connects",
        "body": "I'm using node --inspect-brk to ensure that my code doesn't run until after the debugger connects to node, so no breakpoints or console logs are missed. However this requires me to press \"resume\" in the debugger every time I restart node. Can we have a different option, perhaps --inspect-wait, that automatically starts execution after the debugger finishes connecting?",
        "labels": "feature request",
        "id": 43475
    },
    {
        "title": "TLS module: Support multiple ecdhCurve's",
        "body": "The tls module respectively `tls.createSecureContext` should support multiple `echdCurve`'s like [nginx does](http://nginx.org/en/docs/http/ngx_http_ssl_module.html#ssl_ecdh_curve).\r\n\r\nExample:\r\n```\r\nconst options = {\r\n   ecdhCurves: 'x25519:secp521r1:secp384r1',\r\n };\r\n```\r\n\r\nThe order should be honored (perhaps configurable like `honorChiperOrder`).",
        "labels": "feature request",
        "id": 43476
    },
    {
        "title": "Idea: Aligned stack traces",
        "body": "Hi!\r\n\r\nThis is the current style of the stack traces. Like this I can't in one glance:\r\n  - See the names of the functions very well, since they are interspersed with paths.\r\n  - See the paths very well, because they all start at a different column.\r\n  - See if the stack hits my own code or only node_modules.\r\n\r\n```\r\nTypeError: strategy.authenticate is not a function\r\n    at attempt (/service/node_modules/passport/lib/middleware/authenticate.js:348:16)\r\n    at authenticate (/service/node_modules/passport/lib/middleware/authenticate.js:349:7)\r\n    at Layer.handle [as handle_request] (/service/node_modules/express/lib/router/layer.js:95:5)\r\n    at trim_prefix (/service/node_modules/express/lib/router/index.js:317:13)\r\n    at /service/node_modules/express/lib/router/index.js:284:7\r\n    at Function.process_params (/service/node_modules/express/lib/router/index.js:335:12)\r\n    at next (/service/node_modules/express/lib/router/index.js:275:10)\r\n    at initialize (/service/node_modules/passport/lib/middleware/initialize.js:53:5)\r\n    at Layer.handle [as handle_request] (/service/node_modules/express/lib/router/layer.js:95:5)\r\n    at trim_prefix (/service/node_modules/express/lib/router/index.js:317:13)\r\n    at /service/node_modules/express/lib/router/index.js:284:7\r\n    at Function.process_params (/service/node_modules/express/lib/router/index.js:335:12)\r\n    at next (/service/node_modules/express/lib/router/index.js:275:10)\r\n    at /service/node_modules/body-parser/lib/read.js:130:5\r\n    at invokeCallback (/service/node_modules/raw-body/index.js:262:16)\r\n    at done (/service/node_modules/raw-body/index.js:251:7)\r\n```\r\n\r\nSo I propose something like:\r\n```\r\nTypeError: strategy.authenticate is not a function\r\n    at attempt                          /service/node_modules/passport/lib/middleware/authenticate.js:348:16\r\n    at authenticate                     /service/node_modules/passport/lib/middleware/authenticate.js:349:7\r\n    at Layer.handle [as handle_request] /service/node_modules/express/lib/router/layer.js:95:5\r\n    at trim_prefix                      /service/node_modules/express/lib/router/index.js:317:13\r\n    at                                  /service/node_modules/express/lib/router/index.js:284:7\r\n    at Function.process_params          /service/node_modules/express/lib/router/index.js:335:12\r\n    at next                             /service/node_modules/express/lib/router/index.js:275:10\r\n    at initialize                       /service/node_modules/passport/lib/middleware/initialize.js:53:5\r\n    at Layer.handle [as handle_request] /service/node_modules/express/lib/router/layer.js:95:5\r\n    at trim_prefix                      /service/node_modules/express/lib/router/index.js:317:13\r\n    at                                  /service/node_modules/express/lib/router/index.js:284:7\r\n    at Function.process_params          /service/node_modules/express/lib/router/index.js:335:12\r\n    at next                             /service/node_modules/express/lib/router/index.js:275:10\r\n    at                                  /service/node_modules/body-parser/lib/read.js:130:5\r\n    at invokeCallback                   /service/node_modules/raw-body/index.js:262:16\r\n    at done                             /service/node_modules/raw-body/index.js:251:7\r\n```",
        "labels": "feature request",
        "id": 43477
    },
    {
        "title": "Undocumented punycode validation exception",
        "body": "* **Version**: v8.4.0\r\n* **Platform**: Linux 4.12.8 i686\r\n* **Subsystem**: http\r\n\r\n```js\r\nconst http = require('http')\r\n\r\nconst badUrl = 'http://xn--a--a'\r\nconst goodUrl = 'http://a--a'\r\n\r\nconst c = http.get(goodUrl, () =>\r\n    console.log('ok')\r\n)\r\n.on('error', () => console.log('error'))\r\n```\r\n\r\nThe code above prints `error` for `goodUrl` and throws a exception for `badUrl`.\r\n\r\nHowever, this throwing is not explained in the documentation of `http.get()` and `http.request()` methods. Nor in Url constructor etc.\r\n\r\nThe problem seems to stem from the fact that `url.parse('http://xn--a--a').hostname.codePointAt(8)` is `65533`, i.e. url.parse tries to decode punycode which doesn't play well with `Host` header validation.\r\n\r\n```\r\n_http_outgoing.js:492\r\n    throw new TypeError('The header content contains invalid characters');\r\n    ^\r\n\r\nTypeError: The header content contains invalid characters\r\n    at validateHeader (_http_outgoing.js:492:11)\r\n    at ClientRequest.setHeader (_http_outgoing.js:496:3)\r\n    at new ClientRequest (_http_client.js:190:12)\r\n    at request (http.js:39:10)\r\n    at Object.get (http.js:43:13)\r\n```\r\n ",
        "labels": "feature request",
        "id": 43478
    },
    {
        "title": "Add more information to os.networkInterfaces() output?",
        "body": "I had a need to get some detail information about the systemâ€™s IPv6 addresses, specifically whether they were temporary. It turned out that this was not extremely hard to add to the built-in `os.networkInterfaces()` function. Because I would rather not have to ship and maintain a patched node, I extracted the relevant code from node and libuv and put it into a module, then made my additions there: [network-interfaces-plus](https://www.npmjs.com/package/network-interfaces-plus).\r\n\r\nWould there be interest in having this functionality added back to the original `os.networkInterfaces()`?\r\n\r\nI donâ€™t mind if the answer is â€œnoâ€ â€“ I have seen similar requests declined in the past on the grounds that having `os.networkInterfaces()` in core is borderline feature-creep already.\r\n\r\nMy changes modify the libuv ABI (added struct fields) and would probably need to be coordinated with libuv/libuv#1371.\r\n\r\n<details><summary>Example output</summary>\r\n\r\nwith node v6.11.2 on macOS 10.12.6\r\n\r\n```\r\n> os.networkInterfaces() // before\r\n{ lo0: \r\n   [ { address: '127.0.0.1',\r\n       netmask: '255.0.0.0',\r\n       family: 'IPv4',\r\n       mac: '00:00:00:00:00:00',\r\n       internal: true },\r\n     { address: '::1',\r\n       netmask: 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff',\r\n       family: 'IPv6',\r\n       mac: '00:00:00:00:00:00',\r\n       scopeid: 0,\r\n       internal: true },\r\n     { address: 'fe80::1',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:00:00:00:00:00',\r\n       scopeid: 1,\r\n       internal: true } ],\r\n  en0: \r\n   [ { address: 'fe80::1ce9:2f8c:6663:ab03',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:25:00:f4:d8:75',\r\n       scopeid: 4,\r\n       internal: false },\r\n     { address: 'fd49:351c:437d:0:4b6:e152:cd43:74af',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:25:00:f4:d8:75',\r\n       scopeid: 0,\r\n       internal: false },\r\n     { address: 'fd49:351c:437d:0:449b:78a2:7370:4d3b',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:25:00:f4:d8:75',\r\n       scopeid: 0,\r\n       internal: false },\r\n     { address: '192.168.1.59',\r\n       netmask: '255.255.128.0',\r\n       family: 'IPv4',\r\n       mac: '00:25:00:f4:d8:75',\r\n       internal: false } ],\r\n  utun0: \r\n   [ { address: 'fe80::a9bf:ce39:e4f:2c53',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:00:00:00:00:00',\r\n       scopeid: 7,\r\n       internal: false } ],\r\n  vnic0: \r\n   [ { address: '10.211.55.2',\r\n       netmask: '255.255.255.0',\r\n       family: 'IPv4',\r\n       mac: '00:1c:42:00:00:08',\r\n       internal: false } ],\r\n  vnic1: \r\n   [ { address: '10.37.129.2',\r\n       netmask: '255.255.255.0',\r\n       family: 'IPv4',\r\n       mac: '00:1c:42:00:00:09',\r\n       internal: false } ] }\r\n> require('network-interfaces-plus').networkInterfaces() // after\r\n{ lo0: \r\n   [ { address: '127.0.0.1',\r\n       netmask: '255.0.0.0',\r\n       family: 'IPv4',\r\n       mac: '00:00:00:00:00:00',\r\n       internal: true,\r\n       cidr: '127.0.0.1/8' },\r\n     { address: '::1',\r\n       netmask: 'ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff',\r\n       family: 'IPv6',\r\n       mac: '00:00:00:00:00:00',\r\n       scopeid: 0,\r\n       internal: true,\r\n       temporary: false,\r\n       valid_lifetime: 4294967295,\r\n       preferred_lifetime: 4294967295,\r\n       cidr: '::1/128' },\r\n     { address: 'fe80::1',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:00:00:00:00:00',\r\n       scopeid: 1,\r\n       internal: true,\r\n       temporary: false,\r\n       valid_lifetime: 4294967295,\r\n       preferred_lifetime: 4294967295,\r\n       cidr: 'fe80::1/64' } ],\r\n  en0: \r\n   [ { address: 'fe80::1ce9:2f8c:6663:ab03',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:25:00:f4:d8:75',\r\n       scopeid: 4,\r\n       internal: false,\r\n       temporary: false,\r\n       valid_lifetime: 4294967295,\r\n       preferred_lifetime: 4294967295,\r\n       cidr: 'fe80::1ce9:2f8c:6663:ab03/64' },\r\n     { address: 'fd49:351c:437d:0:4b6:e152:cd43:74af',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:25:00:f4:d8:75',\r\n       scopeid: 0,\r\n       internal: false,\r\n       temporary: false,\r\n       valid_lifetime: 2591982,\r\n       preferred_lifetime: 604782,\r\n       cidr: 'fd49:351c:437d:0:4b6:e152:cd43:74af/64' },\r\n     { address: 'fd49:351c:437d:0:449b:78a2:7370:4d3b',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:25:00:f4:d8:75',\r\n       scopeid: 0,\r\n       internal: false,\r\n       temporary: true,\r\n       valid_lifetime: 596355,\r\n       preferred_lifetime: 77955,\r\n       cidr: 'fd49:351c:437d:0:449b:78a2:7370:4d3b/64' },\r\n     { address: '192.168.1.59',\r\n       netmask: '255.255.128.0',\r\n       family: 'IPv4',\r\n       mac: '00:25:00:f4:d8:75',\r\n       internal: false,\r\n       cidr: '192.168.1.59/17' } ],\r\n  utun0: \r\n   [ { address: 'fe80::a9bf:ce39:e4f:2c53',\r\n       netmask: 'ffff:ffff:ffff:ffff::',\r\n       family: 'IPv6',\r\n       mac: '00:00:00:00:00:00',\r\n       scopeid: 7,\r\n       internal: false,\r\n       temporary: false,\r\n       valid_lifetime: 4294967295,\r\n       preferred_lifetime: 4294967295,\r\n       cidr: 'fe80::a9bf:ce39:e4f:2c53/64' } ],\r\n  vnic0: \r\n   [ { address: '10.211.55.2',\r\n       netmask: '255.255.255.0',\r\n       family: 'IPv4',\r\n       mac: '00:1c:42:00:00:08',\r\n       internal: false,\r\n       cidr: '10.211.55.2/24' } ],\r\n  vnic1: \r\n   [ { address: '10.37.129.2',\r\n       netmask: '255.255.255.0',\r\n       family: 'IPv4',\r\n       mac: '00:1c:42:00:00:09',\r\n       internal: false,\r\n       cidr: '10.37.129.2/24' } ] }\r\n\r\n```\r\n</details>",
        "labels": "feature request",
        "id": 43479
    },
    {
        "title": "Add `mainDir` to module resolution algorithm",
        "body": "First off, I realize that the Module API is frozen, so I understand if this proposal will be rejected outright. However, I figured I'd give it a shot anyway.\r\n\r\nMany node packages today are written in a source language other than JavaScript, and compiled before publishing. The `main` field in the package.json file allows these compiled packages to specify a different file as the entry point (i.e. `dist/index.js`).\r\n\r\nHowever, the module resolution algorithm allows for loading files within a module via path syntax, i.e. `require('foo/bar/quux')` would load `bar/quux.js` from the `foo` module. Currently, the only way to ensure this kind of path syntax works (without needing to include `dist/` in the path) is to publish _only_ the `dist` folder. This approach requires the author to remember to publish the subdirectory every time, which can be mistake prone.\r\n\r\nI'd like to propose supporting a new field in the `package.json` spec called `mainDir`. If present, the module resolution algorithm would treat that `mainDir` path as the root path for that package, so compiled packages could specify `\"mainDir\": \"dist\"`, and easily support sub-path module loading (i.e. `require('foo/bar/quux')`) without having to remember to publish from the subdirectory every time.\r\n\r\nI think this would be a relatively straightforward change on the implementation side, happy to PR it, but I wanted to test the waters first. The only trouble I can see is if people are already using `mainDir` in package.json files for something else. However, a quick Github search reveals zero public instances of using `mainDir` in a package.json file. This of course doesn't preclude it's use in private repos, but I think it's a strong indicator that we wouldn't be trampling on too much, if any, existing code.",
        "labels": "feature request",
        "id": 43480
    },
    {
        "title": "Allow file descriptor to be passed to UDP socket - just as one can for TCP/Unix sockets",
        "body": "In the net API (https://nodejs.org/api/net.html) Node allows the reception of an existing socket via its file descriptor - in the server.listen(handle[, backlog][, callback]) API. This is, among other things, useful when receiving the listening socket from a supervising daemon.\r\n\r\nUnfortunately no such possibility appears to exist for the dgram API (https://nodejs.org/api/dgram.html).\r\n\r\nThis is a request to add such a feature in the future.\r\nThanks.",
        "labels": "feature request",
        "id": 43481
    },
    {
        "title": "how to get the ppid of a process?",
        "body": "I want to let child process know if it's parent was killed, so I hope the child process can get it's ppid.\r\nIf ppid == 1, then i can know the parent has died. \r\n\r\nBut process module seems not having this prop or method",
        "labels": "feature request",
        "id": 43482
    },
    {
        "title": "fs.readFile / fs.writeFile and JSON parsing",
        "body": "Hi folks.\r\n\r\nThis is a first idea and I'm curious if you would accept a PR.\r\n\r\nSuper often I write this code (config files etc) to parse JSON back and forth when loading it from a file or writing it back to a file:\r\n\r\n```js\r\n  fs.readFile(filename, 'utf8', (err, data) => {\r\n    if (err) return cb(err)\r\n    const content = JSON.parse(data)\r\n  })\r\n```\r\n\r\nOften I also have to check if the JSON is valid:\r\n\r\n```js\r\n  fs.readFile(filename, 'utf8', (err, data) => {\r\n    if (err) return cb(err)\r\n\r\n    let content\r\n    try {\r\n      content = JSON.parse(data)\r\n    } catch (e) {\r\n      const err = new Error(\r\n        `${filename} contains invalid JSON`\r\n      )\r\n      return cb(err)\r\n    }\r\n  })\r\n```\r\n\r\nSo I just thought about something like `request` has for handling json. A `json: true` option, which takes care of parsing. Together with a nice error code, in case the read content is not parseable as JSON.\r\n\r\nExample:\r\n\r\n```js\r\n  fs.readFile(filename, { json: true, encoding: 'utf8' }, (err, data) => {\r\n    console.log(typeof data === 'object') // true\r\n  })\r\n\r\n  fs.writeFile(filename, { foo: \"bar\" }, { json: true, encoding: 'utf8' }, (err, data) => {})\r\n```",
        "labels": "feature request",
        "id": 43483
    },
    {
        "title": "Add fs.copyFile for copying files, using uv_fs_copyfile",
        "body": "A new `uv_fs_copyfile` function [recently landed in libuv](https://github.com/libuv/libuv/pull/1465) in order to allow more efficient copying of files (in the future, it could allow copy-on-write semantics on file systems that support it). A copyFile function that uses this should be added to Node.js. ðŸ˜ƒ \r\n\r\nDepends on upgrade to libuv 1.14.0 (#14866)",
        "labels": "feature request",
        "id": 43484
    },
    {
        "title": "FR: child_process.exec(cmd, { additionalEnv })",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: *\r\n* **Platform**: *\r\n* **Subsystem**: child_process\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n`child_process.exec(cmd, { env: Object.assign({}, process.env, {NEW_VAR:1}) })` is a very common pattern. IMHO adding an `{ additionalEnv }` option that implements this pattern, will make the API more complete, and less error prone.\r\n",
        "labels": "feature request",
        "id": 43485
    },
    {
        "title": "Support for multiple PFX in tls.createSecureContext",
        "body": "## Feature request\r\n\r\nAs per as `tls.createSecureContext` accepts multiple `key`/`cert-chain` options, I think there is a good approach to get also multiple PFX support. E.g. one for RSA and another one for ECDSA.\r\n\r\n## Workarounds\r\n\r\n1. Use `key`/`cert` arrays:\r\n```js\r\nconst config = {\r\n  key: [ keys.dsa.key, keys.rsa.key ],\r\n  cert: [\r\n    Buffer.concat([keys.dsa.cert, ...keys.dsa.chain]),\r\n    Buffer.concat([keys.rsa.cert, ...keys.rsa.chain])\r\n  ],\r\n  ...\r\n}\r\n\r\nconst context = tls.createSecureContext(config)\r\n```\r\n2. Manually call `context.loadPKCS12` for another chain:\r\n```js\r\nconst config = {\r\n  pfx: keys.rsa.pfx,\r\n  ...\r\n}\r\n\r\nconst context = tls.createSecureContext(config)\r\ncontext.context.loadPKCS12(keys.dsa.pfx)\r\n```\r\n\r\n## New API proposal\r\n\r\n```js\r\nconst config = {\r\n  pfx: [keys.rsa.pfx, keys.dsa.pfx],\r\n  ...\r\n}\r\n\r\n// Or for encrypted PFX, like for keys:\r\nconst config = {\r\n  pfx: [\r\n    { buffer: keys.rsa.pfx, passphrase: 'pA$sW0rD' },\r\n    { buffer: keys.dsa.pfx, passphrase: 'h4cKm3iFy0uCaN' }\r\n  ],\r\n  ...\r\n}\r\n\r\nconst context = tls.createSecureContext(config)\r\n```",
        "labels": "feature request",
        "id": 43486
    },
    {
        "title": "Feature Request: mark tests flaky on FIPS",
        "body": "See https://github.com/nodejs/node/commit/8fae1e64ce81166f6f19972e29e4c1b4828b5683#commitcomment-23583689\r\n\r\nCurrently [`tools/test.py` only compares](https://github.com/nodejs/node/blob/master/tools/test.py#L1035) against `env`, which [is defined as](https://github.com/nodejs/node/blob/master/tools/test.py#L1641-L1645)\r\n\r\n```python\r\n        env = {\r\n          'mode': mode,\r\n          'system': utils.GuessOS(),\r\n          'arch': vmArch,\r\n        }\r\n```\r\n\r\nWhere mode [is release/debug](https://github.com/nodejs/node/blob/master/tools/test.py#L1359), system is OS, and arch is ARCH.\r\n\r\nWe'd need to also have an option for FIPS, I guess that should be in `env`. Maybe a `type`? Type could be `default`, `fips`, or `sharedlib` (if we end up building a shared library as well we might want a `sharedlib` type).\r\n\r\ncc/ @Trott @bajtos ",
        "labels": "feature request",
        "id": 43487
    },
    {
        "title": "Extended memory info for linux",
        "body": "Hi! Is there a chance to receive extended mem statistics for linux?\r\n\r\nNode uses http://man7.org/linux/man-pages/man2/sysinfo.2.html anyway in https://github.com/nodejs/node/blob/cc8fc462f1817c6443ddb288440ca349bd644bdd/deps/uv/src/unix/sysinfo-memory.c#L31\r\n\r\nI understand that there are another implementations exist for win, freebsd, etc. But reading of `/proc/meminfo` is overkill.",
        "labels": "feature request",
        "id": 43488
    },
    {
        "title": "Tracking Issue: DNS features requiring c-ares support",
        "body": "There is a growing list of feature requests for the DNS module which require upstream changes for an efficient implementation within node.\r\n\r\n- [ ] https://github.com/nodejs/node/issues/14648: c-ares does not support multiple response messages for a single question, making AXFR queries impossible to implement within node.\r\n- [ ] https://github.com/nodejs/node/issues/14475: c-ares does not support DNSSEC, making it difficult to implement DNSSEC within node.\r\n- [ ] https://github.com/nodejs/help/issues/634: c-ares does not appear to support parsing the additional and authority sections of DNS messages, at least not directly. An upstream API would be helpful at this point, even though it is possible to implement this within node.\r\n- [ ] https://github.com/nodejs/node/issues/19239: c-ares does not support CAA RRs.\r\n- [ ] It is impossible to implement iterative DNS when using the `dns` module.\r\n- [ ] c-ares appears to restrict the number of concurrent queries per resolver by using a single port per channel\r\n- [ ] c-ares does not expose TTL values except for `A` and `AAAA` rrtypes.\r\n- [ ] https://github.com/nodejs/node/issues/27724 support `ANAME` questions.\r\n\r\nFYI @bagder @daviddrysdale\r\n\r\ncc @addaleax @refack @silverwind @alexte",
        "labels": "feature request",
        "id": 43489
    },
    {
        "title": "Ability to introspect the event loop",
        "body": "(Leaving out the issue template as this is a feature request - hopefully this is okay; CONTRIBUTING.md doesn't really specify.)\r\n\r\nI'm the maintainer for [pump.io](https://github.com/pump-io/pump.io), a server written in Node.js. I'm working on a feature to implement zero-downtime restarts which involves gracefully shutting down and then respawning cluster processes. Basically the way this works is that the master process uses `worker.send` to signal the worker to call `server.close()` on the HTTP server(s), and then everything else in the process is shut down after that completes.\r\n\r\nHowever, there's still stuff keeping the process open - AFAICT some listener must still be on the event loop. It would be really awesome if I had a way to say, \"just dump stack traces of _everything_ you're watching for on the event loop\" so I could track down where these listeners are being registered in the first place. (Or maybe I'm going about this all wrong? If so feel free to say so.)",
        "labels": "feature request",
        "id": 43490
    },
    {
        "title": "Feature request: add closeTo (or approximate, delta, tolerance epsilon) for assert",
        "body": "* **Version**: 8.x\r\n* **Subsystem**: assert\r\n\r\n```js\r\nconst assert = require('assert');\r\n\r\nconst actual = { a: { b: 0.33333 }};\r\nconst expected = { a: { b: 1/3 }};\r\nassert.deepEqual(actual, expected);     // will currently throw\r\n\r\n// proposal 1:\r\nconst options = { delta: 1e-2 };\r\nassert.deepEqual(actual, expected, options);     // would pass without error\r\n\r\n// proposal 2:\r\nassert.closeTo(actual, expected, 1e-6);     // would pass without error\r\n```\r\n",
        "labels": "feature request",
        "id": 43491
    },
    {
        "title": "dns: support AXFR queries",
        "body": "Now that we support `ANY` queries (https://github.com/nodejs/node/pull/13137), I think the foundation is laid to support zone transfers and we can likely share most of the code that is used to parse the `ANY` response and parse the `AXFR` response with it.\r\n\r\ncc: @XadillaX",
        "labels": "feature request",
        "id": 43492
    },
    {
        "title": "Add indent option to util.inspect?",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: all\r\n* **Subsystem**: util\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nIt was mentioned in [comment on PR](https://github.com/nodejs/node/pull/14558#issuecomment-319991058), that it might useful to have 'real indenting' for `util.inspect` via a new option passed in. This is to make it function more like JSON.stringify with passing in a space specifier. Is this something that people would like to see? Would it be useful?\r\n\r\nRefs: [#14545](https://github.com/nodejs/node/issues/14545)",
        "labels": "feature request",
        "id": 43493
    },
    {
        "title": "DiffieHellman/ECDH Generates invalid keypairs",
        "body": "* **Version**: 6.11.1\r\n* **Platform**: Windows 10\r\n* **Subsystem**: \r\n\r\nError is thrown:\r\n**error:0D07207B:asn1 encoding routines:ASN1_get_object:header too long**\r\n\r\nUser Experience Log:\r\nA user should not have to manually wrap the generated keys in the proper \"PEM\" format since PEM is very precious about spaces.  Without wanting to be pejorative, that sucks.  The fact that this code example still doesn't work after the fact also sucks.\r\n\r\nSuggestion:\r\nRemove/deprecate this API or fix it or provide clearer examples to perform this common functionality.\r\n\r\nWorkaround:\r\nUtilize `openssl` executable as a child proc to generate keys instead.\r\n\r\n```js\r\n/** \r\n * @fileoverview Everything below this comment is from the documentation example.\r\n */\r\nconst crypto = require('crypto');\r\nconst assert = require('assert');\r\n\r\n// Generate Alice's keys...\r\nconst alice = crypto.createDiffieHellman(2048);\r\nconst aliceKey = alice.generateKeys();\r\n\r\n// Generate Bob's keys...\r\nconst bob = crypto.createDiffieHellman(alice.getPrime(), alice.getGenerator());\r\nconst bobKey = bob.generateKeys();\r\n\r\n// Exchange and generate the secret...\r\nconst aliceSecret = alice.computeSecret(bobKey);\r\nconst bobSecret = bob.computeSecret(aliceKey);\r\n\r\n// OK\r\nassert.strictEqual(aliceSecret.toString('hex'), bobSecret.toString('hex'));\r\n\r\n/**\r\n *  Everything below this comment is in addition to the docs example!!!\r\n * @omg\r\n */\r\n// Attempts improvement...\r\nconst publicKey = '-----BEGIN PUBLIC KEY-----\\n' +\r\n    aliceKey.toString('base64').match(/.{1,64}/g).join('\\n') +\r\n    '\\n-----END PUBLIC KEY-----\\n';\r\nconst privateKey = '-----BEGIN PRIVATE KEY-----\\n' +\r\n    aliceSecret.toString('base64').match(/.{1,64}/g).join('\\n') +\r\n    '\\n-----END PRIVATE KEY-----\\n';\r\nconsole.log(crypto.privateDecrypt(crypto.publicEncrypt(publicKey, new Buffer('racecar')), privateKey)); // throws!\r\n```",
        "labels": "feature request",
        "id": 43494
    },
    {
        "title": "Suggestion: Return type in function declaration & possible option to view types by clicking in doc",
        "body": "While working with Node.js, I found having the return types of a function (If given) in the function declaration instead of somewhere in the paragraph below it (As seen in the example following) might improve the documentation.\r\n\r\n\r\n![Example screenshot](http://i.imgur.com/FDwu1md.png)\r\n\r\nFurther on, it would most likely be useful to be able to click on the types. Both suggestions are popular documentation features, example is the [Rust Documentation](https://doc.rust-lang.org/std/iter/struct.Filter.html) \r\n\r\nHere a screenshot of what I mean\r\n![Example screenshot](http://i.imgur.com/XKKNWsc.png)",
        "labels": "feature request",
        "id": 43495
    },
    {
        "title": "submodule access for non standard folder structures",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v7.10.0\r\n* **Platform**: posix\r\n* **Subsystem**: osx sierra 10.12.6 (16G29)\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nthis is a general feature request. I understand that this may not be how a module is normally structured by most people, but I would think that there are more out and more this could be applied to than assumed at first glance.\r\n\r\nbasically, I would like to be able to do what I have outlined in this stackoverflow question: https://stackoverflow.com/questions/45472096/deep-module-require-of-non-standard-module-structure such that an individual can hold their files inside of a `lib` or better yet, a `lib/node_modules` folder and anyone outside can access said internal modules as they have been described, either willy nilly as they are now, or with aliases. I would think that the most elegant solution to this problem is to simply have `require` take into account the `main` key in the `package.json` such that if the `main` key is pointing to `./lib/node_modules/index.js` then it would use the path, without the basename: `./lib/node_modules/` to resolve any submodules that are required. that way users could not only have submodules, but also private modules that publicly, are not accessable through requires.",
        "labels": "feature request",
        "id": 43496
    },
    {
        "title": "Require from internal folder",
        "body": "This might be a somewhat controversial proposal: allow users to require from `internal` folder, like `require('internal/fs.js')`.\r\n\r\nOne can already use the *hidden* modules in the `/lib` folder, like:\r\n\r\n```js\r\nrequire('_http_agent');\r\nrequire('_http_client');\r\n// etc.\r\n```\r\nHowever, I am not aware of a way to access the modules in [`/lib/internal`](https://github.com/nodejs/node/tree/master/lib/internal) folder. Does anyone know a way to `require` those? Are there any issues with that?\r\n\r\nI know that in this form it would conflict with the [`internal`](https://www.npmjs.com/package/internal) package, so the exact syntax has still to be figured out.\r\n\r\nThis could be provided as \"use at your own risk\".",
        "labels": "feature request",
        "id": 43497
    },
    {
        "title": "Duplex stream support for separate readableHighWaterMark and writableHighWaterMark",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.2.1\r\n* **Platform**: Darwin\r\n* **Subsystem**: stream\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis need comes from the practice to use transform streams to perform pipeline processing with backpressure, in order to process incoming binary data, by splitting it to intermediate chunk objects. In such cases the transform stream will accept buffers as input (`readableObjectMode: true`) and push out objects (`writableObjectMode: true`), or vice versa.\r\n\r\nWhile the objectMode flag supports separation between readable and writable, the highWaterMark option is unified between the stream roles, which doesn't allow to set the internal buffer size units with respect to the stream type. It seems that optional support for `readableHighWaterMark` and `writableHighWaterMark` is a natural complementary option to the separated `readableObjectMode` and `writableObjectMode` options.\r\n\r\nIf PR's are welcome I can code the same handling for in the ctors of `Readable` and `Writable` and add to docs.\r\n\r\nLMK what you think,\r\nThanks!\r\n\r\nReferences:\r\nâ€¢ https://nodejs.org/en/docs/guides/backpressuring-in-streams/\r\nâ€¢ https://github.com/nodejs/node/blob/master/lib/_stream_readable.js#L69",
        "labels": "feature request",
        "id": 43498
    },
    {
        "title": "errors.js module",
        "body": "Node now has `internal/errors.js` module which allows to set static error codes for errors, which is great. Would be good to expose Node's internal error constructors in a new module say `require('errors')`.\r\n\r\n```js\r\nimport {TypeError as NodesTypeError} from 'errors';\r\n```\r\n\r\nMy use case is as follows: I am now rewriting an in-memory file system module [`memfs`](https://github.com/streamich/memfs) that mimics how `fs` module works, I would like to throw **exactly** the same errors as Node does, so that it can be used for testing, so now I have to basically copy-paste the `internal/errors.js` file into my project to be able to create similar errors to what Node does.",
        "labels": "feature request",
        "id": 43499
    },
    {
        "title": "console,util: implement %o as formatting specifier",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: all\r\n* **Subsystem**: console,util\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`console.log()` and `util.format()` support `%d`, `%i`, `%f`, etc. but not `%o` for objects which seems to be supported in major browsers. \r\n\r\nRefs: https://github.com/nodejs/node/issues/10292\r\n\r\n/cc @silverwind \r\n",
        "labels": "feature request",
        "id": 43500
    },
    {
        "title": "Provide server address on Server#listening event.",
        "body": "* **Version**: 8.2\r\n* **Platform**: Darwin\r\n* **Subsystem**: http\r\n\r\nOften I find that I when I am testing I setup my servers to bind to any available port. However after doing so I need to know what port the server is listening on. This can be a bit tricky with arrow functions currently and I believe an elegant solution would be to simply pass the `server.address()` when the `listening` event fires.\r\n\r\nTake for example:\r\n\r\n```js\r\nimport http from 'http'\r\n\r\nhttp\r\n  .createServer(...)\r\n  .listen(() => {\r\n    // No easy way to grab the server instance or the address.\r\n  })\r\n\r\nhttp\r\n  .createServer(...)\r\n  .listen(function () {\r\n    console.log(this.address())\r\n  })\r\n```\r\n\r\nI've ran up against this quite a few times and it's especially bad for frameworks like Koa where you do not even get the server instance until you invoke listen anyways.\r\n\r\nIdeally either the `server` instance or the `server.address()` would be passed on the `listening` event like so:\r\n\r\n```js\r\nhttp\r\n  .createServer(...)\r\n  .listen((address) => {\r\n    // Happiness!\r\n    console.log(address)\r\n  })\r\n```",
        "labels": "feature request",
        "id": 43501
    },
    {
        "title": "stream.unpipe cannot be chained",
        "body": "Version: 8.2.1\r\nPlatform: Windows 10, 64 bit\r\nSubsystem: stream\r\n\r\n    var stream = require('stream'); \r\n    var fs = require('fs');\r\n \r\n    var readable = fs.createReadStream('in.txt');\r\n    var transform = stream.PassThrough();\r\n    var writable = fs.createWriteStream('out.txt');\r\n\r\n    readable.pipe(transform).pipe(writable);\r\n\r\n    setTimeout(function() {\r\n       // this does not work\r\n       readable.unpipe(transform).unpipe(writable);\r\n    }, 100);\r\n\r\n\r\nPipe commands can be chained in streams, so I anticipated that unpipe commands would also work like this. However, `readable.unpipe(transform)` returns the readable stream object, not the transform stream object like I expected. I am not sure if this is a bug or a feature request, because [the documentation](https://nodejs.org/api/stream.html#stream_readable_unpipe_destination) does not specify what unpipe should return.\r\n",
        "labels": "feature request",
        "id": 43502
    },
    {
        "title": "API issue: No way to abort file open",
        "body": "This is an issue I've recently come across in production code. It's not a technical issue, but rather a problem with the File System API itself (As described by the, at the time of this writing, v8.2.1 documentation).\r\n\r\nWhat I was doing was opening a named pipe for writing, while also starting a process that would read from it. However, there was a chance that starting the process would fail, or be aborted, meaning the pipe would never be opened for reading. Named pipes on Linux block opening until it is open for both reading and writing, so the writing would stall.\r\n\r\nTo be clear: Aborting is an acceptable runtime condition, and is easily detected. In this case, the write to the pipe would also be aborted. The problem is, fs.open would never call its callback if the abort happened before the reading side was open, and the request would \"leak\" at the end of the program, causing node.js to fail to exit.\r\n\r\nMy workaround was to detect if the file has not yet opened for writing at the time of the abort, and open a \"dummy reader\" to unblock the open function.\r\n\r\nSo the API issue is: There is no way to tell fs.open to \"stop trying\" once it's been started. This can be an issue with any non-guaranteed resource requests. Named pipes are one example, but network files are also one. There needs to be a way to programmatically say \"on second thought, I don't really need this file\".\r\n\r\nThis problem only exist with fs.open, since fs.write or fs.read can be easily aborted by simply closing the file with fs.close (I've tested it to be \"safe\", although it would be nice if this was an API guarantee).\r\n\r\nMy suggestion would be for fs.open to return some temporary descriptor that could be used to call an fs.abortOpen function, or something similar.",
        "labels": "feature request",
        "id": 43503
    },
    {
        "title": "dns: Add DNSSEC support",
        "body": "* **Version**: 8.2.1\r\n* **Platform**: 64-bit (OSX 10.17, Ubuntu Server 17.04)\r\n* **Subsystem**: dns.js\r\n\r\nWith today's security requirements and Node.js being an important framework, DNSSEC support and validation are becoming very important for all sorts of applications ranging from API clients to IoT devices.\r\n\r\nNode **dns.js** is missing:\r\n\r\n* Basic support to simply allow RRSIG records in the result, instead it returns an `EBADRESP` error while the requested resource is perfectly valid.\r\n* Basic support to request RRSIG records, i.e. a RRSIG `rrtype` for `dns.resolve()` and a new `dns.resolveRrsig()` method.\r\n* DNSSEC verification, to confirm the returned answer is valid. Perhaps with a new method like `dns.setVerify(true)` to not cause interface trouble.\r\n\r\n---\r\n\r\nI don't know much about the technical part of DNSSEC and how to implement it in Node, but I did notice the results are in line with `dig hostname` on the shell. For example,\r\n\r\n```js\r\n// DNSSEC signed, but works fine\r\ndns.resolve ('myhostname.net', 'A', console.log);\r\n[ '37.97.204.102' ]\r\n````\r\n\r\nis similar to:\r\n\r\n```sh\r\n$ dig myhostname.net a\r\n\r\n;; ANSWER SECTION:\r\nmyhostname.net.\t\t1382\tIN\tA\t37.97.204.102\r\n```\r\n\r\nwhile requesting ANY `rrtype` returns an error:\r\n\r\n```js\r\n// DNSSEC signed, does not work\r\ndns.resolve ('myhostname.net', 'ANY', console.log);\r\n\r\n{ Error: queryAny EBADRESP myhostname.net\r\n    at errnoException (dns.js:50:10)\r\n    at QueryReqWrap.onresolve [as oncomplete] (dns.js:236:19)\r\n  code: 'EBADRESP',\r\n  errno: 'EBADRESP',\r\n  syscall: 'queryAny',\r\n  hostname: 'myhostname.net' }\r\n```\r\n\r\ncompared to dig with clearly the DS and RRSIG included:\r\n\r\n```sh\r\n$ dig myhostname.net any\r\n\r\n;; ANSWER SECTION:\r\nmyhostname.net.\t\t83764\tIN\tNS\tns1.transip.net.\r\nmyhostname.net.\t\t964\tIN\tA\t37.97.204.102\r\nmyhostname.net.\t\t83764\tIN\tDS\t1560 7 1 B564B27573CEC3AC428BA606B4656A0CF85F5B2E\r\nmyhostname.net.\t\t964\tIN\tAAAA\t2a01:7c8:aac3:41b::1\r\nmyhostname.net.\t\t83764\tIN\tNS\tns0.transip.nl.\r\nmyhostname.net.\t\t83764\tIN\tNS\tns2.transip.eu.\r\nmyhostname.net.\t\t83764\tIN\tRRSIG\tDS 8 2 86400 20170730051458 20170723040458 57899 net. nDlnsdcnLynmq7U+wKUYRjV8NBiRo/YcnqtBdM4Sgp8lmNwB6EN97Dbn MpIm+lqnj+r6kWHPQ1fpTZBhBR4qrC+V3WIWaImM0fNVOGaLh3DUgcMn mkXpyJCQmVxcT/0g7F3+tuOuY+/loCe8nQD4gWXizBOO294v1bmPktBB xZ0=\r\n```\r\n\r\nI think that the moment DS and RRSIG records are part of the result Node does not recognize it and thus fails to parse the rest.",
        "labels": "feature request",
        "id": 43504
    },
    {
        "title": "n-api: from zzo38 via IRC - Some ideas for N-API",
        "body": "*edited to reflect completed tasks (@gabrielschulhof)*\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.1.3\r\n* **Subsystem**: n-api\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nhttp://zzo38computer.org/textfile/miscellaneous/napi_ext\r\n\r\n# documentation\r\n\r\n\r\n### String lifetimes.\r\n\r\nThe document should specify if N-API copies the string, to make it clear.\r\n(With SQLite, you can specify whether or not the string should be copied\r\nand if not, what to call to free it.)\r\n\r\n### Examples of asynchronous working.\r\n\r\nThere aren't any example, and it does not explain many things such as\r\nmutexes, calling JavaScript codes during the working, example of using\r\nnapi_make_callback(), thread safety, etc.\r\n\r\nSQLite has support for multithreads too (if enabled), although there is\r\nsome confusion in the N-API documentation as to what exactly is allowed\r\nwhen interfacing SQLite (and other stuff) with N-API when using the\r\nasynchronous working.\r\n\r\n\r\n### External values.\r\n\r\nThe documentation should probably mention that an external value appears\r\nas an object (sealed, frozen, with no properties and no prototype) to\r\nJavaScript codes, even though it is a separate type to native codes.\r\n\r\n\r\n### Get property names.\r\n\r\nThe documentation for napi_get_property_names() does not say whether it\r\ngets only enumerable properties or all properties, and does not say if it\r\nincludes symbols or not.\r\n\r\n\r\n### C++ wrapping.\r\n\r\nWhat is the relation to C++ (I thought this is a C API?) and what is the\r\nreason for the restrictions with napi_wrap()? Also, is it necessary to\r\ncall napi_wrap() only during the constructor callback, or is it OK to do\r\nafterward too?\r\n\r\n\r\n### Throwing exceptions.\r\n\r\nThe document says that napi_throw() throws an Error provided. Is it\r\nnecessary for it to be an Error, or can you throw any value? You should be\r\nallowed to throw any value, I should think.\r\n\r\n# Implementation\r\n\r\n### ~~Retrieving new.target.~~\r\n\r\n~~When a function is called as a constructor, new.target should be\r\nretrievable. This may replace is_construct_call since you can do the same\r\nthing with this anyways.~~\r\n*`napi_get_new_target()`*\r\n\r\n\r\n### ~~Executing JavaScript codes.~~\r\n\r\n~~Some things aren't and perhaps shouldn't be defined in N-API, but it can\r\nbe useful to execute external JavaScript codes sometimes (during\r\ninitialization, especially) in order to do such things.~~\r\n*`napi_run_script()`*\r\n\r\n### Further module arguments.\r\n\r\nIt currently (seems to) provide no way to get the \"require\", \"__dirname\",\r\nand \"__filename\" arguments of a Node.js module. If the native code is a\r\nNode.js module there should probably be some way to retrieve such values\r\n(which may be used with the above \"executing JavaScript codes\" during the\r\ninitialization).\r\n\r\n\r\n### Retrieving the finalizer for a value.\r\n\r\nFor objects created using N-API, it would help to have a function to get\r\nthe finalizer callback for the value, for example:\r\n\r\nnapi_get_value_finalizer(napi_env env,napi_value val,napi_finalize*result)\r\n\r\nThis can be used to determine who created an object, by comparing the\r\nfinalizer function pointer (which will be a null pointer if there is no\r\nfinalizer callback defined) with the address of the native code's own\r\nfunctions (there is no point calling the returned finalizer callback).\r\n\r\n\r\n### ~~Reading strings of 8-bit characters.~~\r\n\r\n~~The function napi_get_value_string_latin1() is missing. Not sure what to\r\ndo for strings having character codes that don't fit in 8-bits; it may be\r\ndefined to just use the low 8-bits, or it may be specified as undefined.~~\r\n\r\n\r\n### Support for WeakMap.\r\n\r\nN-API can already create and manipulate a Array, but there is no support\r\nto create and manipulate a WeakMap, which may sometimes be useful for\r\ninternally attaching extra data to arbitrary objects.\r\n\r\n(You might be able to define your own finalizer callbacks also using a\r\nWeakMap anyways, by giving a key for the object to check, and the value\r\nbeing a external value with a finalizer callback defined, so that it will\r\nbe called when the key object is finalized; I don't know whether or not it\r\nwill work, but it seems like it is allowed to work, at least.)\r\n\r\n\r\n### Creating functions and objects.\r\n\r\nWhen using napi_create_object() and napi_create_function(), you cannot\r\nspecify a finalizer callback, which probably should be allowed since it\r\ncan be useful to have.\r\n\r\n~~Also, napi_create_object() should allow you to optionally specify the\r\nprototype to use (which is a napi_value which is either null or a object;\r\nif it is not specified then it can use the default Object.prototype).~~\r\n*`napi_new_instance()`*\r\n\r\n\r\n### Exotic objects.\r\n\r\nA suggestion is a new N-API function to create custom exotic objects (like\r\nProxy in JavaScript, but without the extra checking).\r\n\r\n\r\n### Generator functions.\r\n\r\nA way to create generator functions with N-API functions. (You can already\r\nfake it, but real generator functions may help a bit better, will work if\r\nyou use the actual generator methods rather than others with the same\r\nname, and may be more efficient in some cases maybe.)\r\n\r\nAttaching a finalizer callback to the generator object can also help.\r\n\r\n\r\n### Immediate garbage collection.\r\n\r\nSometimes you may wish to trigger garbage collection sooner in order to\r\nmake finalizer callbacks to be called. This will not necessarily be\r\nguaranteed, although attempting it can nevertheless be useful sometimes.\r\n(This should also be provided in the \"v8\" module so that it can be used\r\nfrom JavaScript codes directly, too.)\r\n\r\n\r\n### Moving values into scopes.\r\n\r\nSometimes you might want to return a value that is not scoped and then to\r\ndelete the reference to it at the same time. In order to do this, it may\r\nbe useful to add the value to the scope so that it can be returned.\r\n\r\nN-API might automatically do this; the documentation isn't quite clear. If\r\nN-API does already do this, it should be explained, and the stuff in this\r\nsection need not be implemented.\r\n\r\nAnother alternative would be to provide another function to return values\r\nfrom a native code rather than returning it directly.\r\n\r\nAnother possibility may be to create an array and add the value into that\r\narray to prevent it from getting lost, and the array is automatically lost\r\nwhen the function returns, but that seems a bit klugy to me.\r\n\r\n",
        "labels": "feature request",
        "id": 43505
    },
    {
        "title": "discuss: move error codes in internal/errors into separate module",
        "body": "The error codes in [internal/errors](https://github.com/nodejs/node/blob/master/lib/internal/errors.js#L110) are some string constants. When throw an error, we directly use these string like:\r\n\r\n```js\r\nthrow new TypeError('ERR_INVALID_CALLBACK');\r\n```\r\nUsing a plain string has many problems: No auto complete, Easy for typo, Difficult to change the error code......\r\n\r\nI think we should migrate these string constants to a new file (e.g. `internal/error_codes.js`):\r\n\r\n```js\r\nexport const ERR_INVALID_CALLBACK = 'ERR_INVALID_CALLBACK';\r\n// more error codes......\r\n```\r\nThen we can use these codes after import them:\r\n\r\n```js\r\nimport * as codes from 'internal/error_codes';\r\n\r\nthrow new TypeError(codes.ERR_INVALID_CALLBACK);\r\n```\r\n",
        "labels": "feature request",
        "id": 43506
    },
    {
        "title": "HTTP module, multiple headers with same name",
        "body": "* **Version**: All versions from what I can tell\r\n* **Platform**: All\r\n* **Subsystem**: http module\r\n\r\nThe problem is pretty straight forward. There is no good way to send out multiple headers with the same name. I literally had to resort to this jank solution:\r\n```js\r\nhttp.ServerResponse.prototype.sendRawHeader = function(name, value){\r\n\tif(!this._headerSent){\r\n\t\tthis.connection.write(['HTTP/1.1', this.statusCode, STATUS_CODES[this.statusCode], '\\r\\n'].join(' '));\r\n\r\n\t}\r\n\tthis.connection.write([ [name, ':'].join(''), [value, '\\r\\n'].join('') ].join(' '));\r\n}\r\n```\r\n\r\nThis is still bad in my personal opinion as I'm having to write headers out before content and the module should be handling the status code for me.  \r\n  \r\nWhile everyone seems to cite that headers should be capable of being handled as comma separated values, this does not work cross-platform in ever situation. The easiest thing to cite would be sending out multiple `Set-Cookie` headers like so:\r\n```\r\nSet-Cookie: uid=n\r\nSet-Cookie: token=XXX-XXXX-XXX-XXXX\r\n```\r\nThere is absolutely no way to do this and this will never work cross-browser or cross-platform\r\n```\r\nSet-Cookie: uid=n, token=XXX-XXXX-XXX-XXXX\r\n```\r\nThere are other situations with custom software that I've dealt with where other headers need to be sent in multiple lines in order for proper evaluation.  \r\n  \r\n**I propose** that a  function be added like http.ServerResponse.addRawHeader(string) and in the response portion of the HTTP module, a variable (array) named `additionalRawHeaders` be used to track these headers. When headers are finally sent, the last part would be to iterate through additionalRawHeaders and just write those out to the socket.  \r\n  \r\nIf no one agrees with this, if I just write it myself, what are the chances a pull request will be accepted for this?",
        "labels": "feature request",
        "id": 43507
    },
    {
        "title": "moduleFoo/moduleFoo.js should work same as moduleFoo/Index.js",
        "body": "In projects with many module folders, it becomes quite tedious to navigate when searching by file.\r\n\r\nE.g Say you wanted to work on the moduleFoo module and searched for a file named 'moduleFoo', you'd see nothing. You have to search for 'index.js', which floods your search with the index.js of every module in the project. You'd then have to pick the actual index.js you want from the hundred or so results.\r\n\r\nHow about we improve the overall development process?\r\nWhat do folks think about making moduleFoo/moduleFoo.js work the same as moduleFoo/Index.js?\r\n\r\nThis could have lower priority to moduleFoo/Index.js and perhaps could even be enabled by a flag.",
        "labels": "feature request",
        "id": 43508
    },
    {
        "title": "DNS server caching breaks changing networks in runtime",
        "body": "* **Version**: 8.1.3\r\n* **Platform**: macOS Sierra\r\n* **Subsystem**: DNS\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI'm experiencing an odd issue when resolving AAAA hostnames using the `dns` module as the network changes \"below\".\r\n\r\nConsider the following program:\r\n\r\n```js\r\nconst dns = require('dns');\r\n\r\nsetInterval(() => {\r\n  dns.resolve('www.google.com', 'AAAA', (err, records) => { console.log(err, records); });\r\n}, 1000);\r\n```\r\nIf I run this program while connected to an IPv6 network, it works. If I run this program while connected to an IPv6 VPN, it also works.\r\n\r\nHowever, if I run this program while connected to an IPv6 network and *while it runs* connect to the IPv6 VPN, I get the following output:\r\n\r\n```\r\n$ node test.js\r\nnull [ '2a00:1450:400e:800::2004' ]\r\n[...a lot of these...]\r\n{ Error: queryAaaa ECONNREFUSED www.google.com\r\n    at errnoException (dns.js:50:10)\r\n    at QueryReqWrap.onresolve [as oncomplete] (dns.js:235:19)\r\n  code: 'ECONNREFUSED',\r\n  errno: 'ECONNREFUSED',\r\n  syscall: 'queryAaaa',\r\n  hostname: 'www.google.com' } undefined\r\n[...a lot of these...]\r\n```\r\n\r\nThis happens because DNS servers are cached. I'm not too familiar with the code, but from briefly skimming through `src/cares_wrap.cc` it seems that `AresEnsureServers()` -- which is called before each query to ensure DNS servers are available -- immediately returns under certain circumstances that are true in the above case and probably many other.\r\n\r\nWhile I don't suggest disabling DNS server caching, it seems that there's no way to get DNS working in the scenario I described. At the very least, maybe there should be a function to force flushing of the DNS server cache? (e.g. `dns.flush()`) Alternatively, am I missing something and there is a way to get this to work?",
        "labels": "feature request",
        "id": 43509
    },
    {
        "title": "can we set autoPadding for key and iv in crypto.createCipheriv(algorithm, key, iv)? ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:6.9.1\r\n* **Platform**:- Linux 4.4.0-82-generic #105-Ubuntu x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIf we create a new instance using crypto.createCipheriv(algorithm, key, iv) it throws an error of invalid key length. Can we set auto padding so that if the key is short than it automatically adds padding to key or do we manually need to append it, the key here can be of dynamic length?",
        "labels": "feature request",
        "id": 43510
    },
    {
        "title": "how to move up/down stack frames in the node debugger?",
        "body": "Hi, \r\n\r\nI am using Node 8.1.3. There is nothing in the docs regarding moving up/down stackframe once a breakpoint is hit. Is this feature supported yet?",
        "labels": "feature request",
        "id": 43511
    },
    {
        "title": "REPL .load multiline arrow function expressions",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v7.10.0\r\n* **Platform**: Linux DC-28 4.4.0-43-Microsoft #1-Microsoft Wed Dec 31 14:42:53 PST 2014 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThere is no documented way of doing a `.load` in `.editor` style, causing multiline expressions (and JavaScript's implicit semicolons within a REPL) to break functions such as this:\r\n\r\n```\r\nconst parseXlsx = (file) =>\r\n    getFile(file)\r\n        .then(data => xlsx.read(data))\r\n```\r\n\r\n(After getFile(file), the single line REPL will assume that the expression is done) \r\n\r\nProposal:\r\nCombine `.editor` and `.load` into `.load-editor` or `.load-multiline` that loads the entire file before executing it. Possible workarounds - requiring the file and using exports, but that's reinventing `.load`. Alternatively, I'll attempt to minify the output, as that should reduce whitespace that has a special meaning in REPL single-line mode.",
        "labels": "feature request",
        "id": 43512
    },
    {
        "title": "CIDR support for os.networkInterfaces",
        "body": "`os.networkInterfaces` currently returns IP addresses and netmasks in the old-fashioned format of separate address and netmask:\r\n\r\n````js\r\n{ address: '127.0.0.1',\r\n  netmask: '255.0.0.0' }\r\n{ address: '2001:db8::',\r\n  netmask: 'ffff:ffff:ffff:ffff::' }\r\n````\r\n\r\nIt's *very* uncommon to specify a IPv6 subnet mask like above. I think it'd generally be easier for users to work with these addresses if they were also available in CIDR form, maybe via a new `cidr` property, e.g. `'127.0.0.1/8'` and `'2001:db8::/64'`.",
        "labels": "feature request",
        "id": 43513
    },
    {
        "title": "proposal: 'slab' event on readable streams",
        "body": "**Version: all**\r\n**Platform: all**\r\n**Subsystem: stream**\r\n\r\n\r\n**Background**\r\n\r\nTwo common form of using streamed data at the top level are: (i) transform the data before consumption, (ii) pipe the stream into a writeable steam (free flow). Transformation can be one of reduction, aggregation, mutation etc.\r\n\r\nAt top level, these operations work on unit chunk of data. Currently `data` events are generated when the internal buffer has got 'some' bytes in it. This 'some' amount may be either insufficient for the transformer, or excess.\r\n\r\nException to this is (i) when the consumer get exact amount of data (ii) unit of data is one byte.\r\n\r\nThis is is because the data channel hold no bearing on the structure of data.\r\n\r\nA workaround is to accumulate the data in an application buffer upon `data` events, and transform when there is a 'unit' amount of data available which the transformer can work with.\r\n\r\nThis implies 2 things: (i) data buffering at the app level (ii) code duplication, if the same buffering logic is required in many places.\r\n\r\n**Proposal:**\r\n\r\n1. Enable a 'slab' event for readable streams that will be emitted when the data in the internal buffer is fully formed according to a certain predicate.\r\n2. Under default configurations, the stream does not exhibit this event.\r\n3. To enable this event, register a predicate and a listener with the stream. The predicate is an application-defined lambda, which is invoked on the internal stream data every time some bytes arrive into it. the lambda should assert whether the data is fully formed and if so, the offset into the internal buffer upto which makes one slab. The listener is then called with the 'slab' portion of the content.\r\n4. If there are more than one slabs, the listener is called as many times. If there is fewer bytes, no event is produced.\r\n5. Pre-define some standard lambdas in the core: line (delimited by \\n) json (delimited by stringified form of an object) etc.\r\n6. If the 'slab' event is registered, mask the 'data' event for the stream. Caller can still use readable.read() in which case the data is drained and the slab'ing is ignored for the chunk.\r\n7. No behavioral difference for the streams created in Object mode.\r\n\r\nWhy this is required in the core as opposed to somewhere else: \r\n1. Slabing capability at the API level reduces code duplication elsewhere in the stack.\r\n2. Stream consumption become more intuitive and convenient.\r\n\r\nAlternatively, an abstraction can be built around ReadableStream (SlabStream) which exhibits this custom behavior, the tradeoff between the two a subject of discussion and ratification.\r\n\r\nUsage pattern #1:\r\n\r\n```javascript\r\nreadable.on('slab', (d) => {\r\n  var len = d.indexOf('\\n')\r\n  if(len !== -1)\r\n    return {enough: true, line: len}\r\n  return {enough: false, len: -1}\r\n}, (slab) => {\r\n  // process a line of data\r\n})\r\n```\r\n\r\nUsage pattern #2:\r\n\r\n```javascript\r\nreadable.on('slab', {slabber: 'json'}, (d) => {\r\n  // process a fully formed JSON data\r\n})\r\n```\r\n\r\nThoughts?\r\n\r\n/cc @nodejs/streams",
        "labels": "feature request",
        "id": 43514
    },
    {
        "title": "child_process: special handling of process.on('message')",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: *\r\n* **Platform**: *\r\n* **Subsystem**: child_process\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n```js\r\nprocess.on('message');\r\n```\r\nhas a special meaning in the context of IPC between parent and child. The problem is a `'message'` event could be triggered other code, or listened to outside of IPC context, so we can not do any special treatment for it.\r\nI suggest adding `'IPCMessage'` that only the IPC channel can trigger, and registering a listener to would fail if an IPC channel was not established.\r\nRef: https://github.com/nodejs/help/issues/693#issuecomment-310525958\r\n[edit]\r\nThe intention is to emit both events: `message` for backwards compatibility, and `IPCMessage` for a validated IPC only events.",
        "labels": "feature request",
        "id": 43515
    },
    {
        "title": "inspector: add ability to use a constant websocket url",
        "body": "Using node `8.x.x` gives the ability use the Chrome DevTools and that's a great help.\r\n\r\nOne thing that make the developer experience a bit less pleasant is the random bit of the web socket url because it forces this workflow:\r\n\r\n1. start app\r\n2. grab debugger url (looks like to: `chrome-devtools://devtools/bundled/inspector.html?experiments=true&v8only=true&ws=127.0.0.1:9229/dc9010dd-f8b8-4ac5-a510-c1a114ec7d29`)\r\n3. copy paste in chrome\r\n4. debug\r\n5. change code\r\n6. goto 1.\r\n\r\nStep 2. and 3. are very tedious, especially when your app spits logs at startup. If the url was always the same, a simple refresh of the debug tab would be enough.\r\n\r\nI understand there might be reasons for the url to be random (security?) but that'd be really nice to have the ability to make it constant.\r\n\r\nI know a workaround would be to use `inspector.url()` to grab the url and open it programatically but Chrome does not allow that. As stated in [this issue](https://github.com/zeit/hyperlinks/issues/18), it seems impossible to open Chrome Devtools in anyway other than copy-pasting the url in the bar.",
        "labels": "feature request",
        "id": 43516
    },
    {
        "title": "Windows installer: Per user install (feature request)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.1.2\r\n* **Platform**: Windows (all versions)\r\n* **Subsystem**: N/A\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nCan you change Node's Windows installer so that Admin privileges are no longer required to install ? Instead, you can make a per user install, or better, offer the choice between a system and user installation. Thanks.",
        "labels": "feature request",
        "id": 43517
    },
    {
        "title": "known limitation: when running with `--inspect=localhost:0` only one port is printed",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9-pre\r\n* **Platform**: *\r\n* **Subsystem**: inspector,cli\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nA know limitation after #13478\r\nIf node is started with a `hostname` and port 0, the process will possibly bind 2 sockets with two different ports, but print only one\r\n```cmd\r\nd:\\code\\node-cur$ node9pre.exe --inspect=localhost:0\r\nDebugger listening on ws://localhost:63448/38595be5-d6d8-4142-bdbb-25133971f734\r\nFor help see https://nodejs.org/en/docs/inspector\r\n>\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/96947/27265510-297c8afa-5465-11e7-855e-f8b91487541e.png)\r\n",
        "labels": "feature request",
        "id": 43518
    },
    {
        "title": "non-blocking `vm`",
        "body": "`vm.runInContext` is currently blocking/synchronous:\r\n```js\r\n'use strict';\r\nconst vm = require('vm');\r\n\r\nconsole.log('Start');\r\n// Here we simulate some heavy calculations\r\nconst script = new vm.Script('for (let i = 0; i < 1000000000; ++i) {}');\r\nconst context = new vm.createContext();\r\n// Running this code blocks the main application thread.\r\n// That is, we will not see the message \"End\" until this code is executed\r\nscript.runInContext(context);\r\nconsole.log('End');\r\n```\r\n\r\nIt'd be much more powerful if it used libuv like `fs` and `http`/`https` functions do.",
        "labels": "feature request",
        "id": 43519
    },
    {
        "title": "Feature request: exposing more ICU functionality or data?",
        "body": "Looking over a pull request like https://github.com/Sebmaster/tr46.js/pull/11, which pulls in lots of Unicode data tables, and comparing it to Node.js's WHATWG URL implementation which apparently is just able to delegate to ICU, I was struck with the question of why more ICU data and functionality isn't exposed directly to JS? That would allow us to implement tr46.js without pulling in such data tables, or possibly just eliminate it entirely.\r\n\r\nI imagine some of this might be work for ECMA-402, although my understanding is they're still figuring out whether they want to take an ICU dependency. But in the meantime Node.js already has all this data in the binary, from what I understand... any thoughts on exposing it to JS?\r\n\r\n/cc @littledan @TimothyGu @jasnell @Sebmaster @srl295",
        "labels": "feature request",
        "id": 43520
    },
    {
        "title": "fileNameWithPrefix and fileNameWithPostfix",
        "body": "In some cases there will be useful to have functions for adding prefix or postfix to file name.\r\nFor example my implementation is this for add postfix.\r\n```js\r\n  const ext = path.extname(fileName)\r\n  const fileNameWithoutExt = path.basename(fileName).replace(ext, '')\r\n  const fileNameWithPostfix = path.join(path.dirname(fileName), fileNameWithoutExt + postfix + ext)\r\n```\r\n",
        "labels": "feature request",
        "id": 43521
    },
    {
        "title": "require does not cache exceptions",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.0.0\r\n* **Platform**: mac\r\n* **Subsystem**: module\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nRef: https://gist.github.com/stelcheck/0d981e2b951b8c95a3487a733fde1925\r\n\r\nIf upon require, a module file throws, it will be re-required again upon subsequent attempts. This means that the content of the file will be re-executed as well, which I believe is not likely to be a desirable behavior (otherwise one would manually clean up the require cache).\r\n\r\nWhat I would suggest is instead to cache the thrown Error and re-throw it upon subsequent require attempts.\r\n",
        "labels": "feature request",
        "id": 43522
    },
    {
        "title": "Add an easy way to start a TLS communication on top of a plain *server side* Socket",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: Any\r\n* **Platform**: Any\r\n* **Subsystem**: tls\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nThe recommended way to upgrade a plain socket to a TLS socket is to wrap\r\nit with `new TLSSocket(...)`.\r\nBut this wrapping doesn't check certificates \r\nand doesn't emit `secureConnect` event.\r\nThere seem to be no public API to do that checking\r\n(at least I couldn't find it).\r\n\r\nMethod `tls.connect` can be used to wrap socket to TLSSockets,\r\nwith certificate checking and with `secureConnect` emision.\r\nBut it can be used only for *client side* sockets (`isServer == false`)\r\nand not for *server side* sockets got at a net.Socket `connection` event.\r\n\r\nReading the source code, I found that checking certificates is done with\r\nsocket._handle.verifyError(), both for TLSSocket produced by tls.Server and\r\ncreated with tls.connect.\r\nThis is not a documented API, and although the verifyError method has been\r\nthere for a long time, I am not sure if I should use it in user space code.\r\n\r\nI think it would be nice to have a way to fully wrap\r\na plain *server side* socket,\r\nwith certificate checking and `secureConnect` emission.\r\nOr a public and documented API to do certificate checking.\r\n\r\nAlso, it would be nice if the documentation clearly explained\r\nwhen certificates are checked and `secureConnect` is emitted.\r\n",
        "labels": "feature request",
        "id": 43523
    },
    {
        "title": "Add context option to utils.promisify() for method binding",
        "body": "* **Version 8**:\r\n* **Platform OSX**:\r\n\r\nThe new `utils.promisify()` will promisify methods, but they lose their `this` context. Many libs require their methods to be bound.\r\n\r\nHere is an example I'm working on with the offical Stripe package. \r\n\r\n```js\r\n  stripe.refunds.create(refundOptions, (err, refund) => {\r\n    if (err) {\r\n      // handle error..\r\n      return;\r\n    }\r\n    console.log(refund);\r\n  });\r\n```\r\n\r\nIf I want to promisify this:\r\n\r\n```js\r\n// currently have to do\r\nconst createRefund = util.promisify(stripe.refunds.create);\r\nconst refund = await createRefund.call(stripe.refunds, refundOptions);\r\n\r\n// or\r\nconst createRefund = util.promisify(stripe.refunds.create).bind(stripe.refunds);\r\nconst refund = await createRefund(refundOptions);\r\n```\r\n\r\nIdeally I would do this:\r\n\r\n```js\r\nconst createRefund = util.promisify(stripe.refunds.create, stripe.refunds);\r\nconst refund = await createRefund(refundOptions);\r\n```\r\n\r\nI've been using the [ES6-promisify](https://www.npmjs.com/package/es6-promisify#promisify-methods) package for a while now, and it has this option. The Bluebird promisify method also has an option for this.\r\n\r\n",
        "labels": "feature request",
        "id": 43524
    },
    {
        "title": "Integrate C++ AsyncHooks Embedder API with native abstraction",
        "body": "* **Version**: v8.x\r\n* **Platform**: all\r\n* **Subsystem**: n-api, nan, async_hooks\r\n\r\nThe [AsyncHooks Embedder API](https://github.com/nodejs/node/pull/13142) has now been merged, we need to integrate this into [N-API](https://nodejs.org/api/n-api.html) and [NAN](https://github.com/nodejs/nan) such that userland add-ons can inform [`async_hooks`](https://github.com/nodejs/node-eps/blob/master/006-asynchooks-api.md) about the context.\r\n\r\nI'm not very familiar with either APIs, but NAN is the API I know the best, so I will explain it from that perspective.\r\n\r\nAsyncHooks allows userland to get notified about all asynchronous event and understand what caused the asynchronous job to be tasked. This requires 4 events to be emitted: \r\n* `init`: emitted with the asynchronous job is created (called a resource). [`EmitAsyncInit`](https://github.com/nodejs/node/blob/master/src/node.h#L543) emits this.\r\n* `before`, `after`: emitted with the asynchronous job calls back, this can happen multiple times. [`MakeCallback`](https://github.com/nodejs/node/blob/master/src/node.h#L562) now emits these when two additional parameters are passed (`async_id` and `trigger_id`).\r\n* `destroy`: emitted when the resource can't call back anymore. [`EmitAsyncDestroy`](https://github.com/nodejs/node/blob/master/src/node.h#L549) emits this.\r\n\r\nthere is also a high-level API, a C++ class called [`AsyncResource`](https://github.com/nodejs/node/blob/master/src/node.h#L589) but I suspect this isn't useful for NAN or N-API.\r\n\r\nIn terms of NAN I think there is almost a 1 to 1 mapping between [`Nan::Callback`](https://github.com/nodejs/nan/blob/master/doc/callback.md#api_nan_callback) and the AsyncHooks API. I believe the following changes should be made:\r\n\r\n* `Callback::Callback` should call [`trigger_id = AsyncHooksGetTriggerId(isolate);`](https://github.com/nodejs/node/blob/master/src/node.h#L534) and [`uid = EmitAsyncInit(isolate, resource, name, trigger_id);`](https://github.com/nodejs/node/blob/master/src/node.h#L543).\r\n* `Callback::Call` should call [`node::MakeCallback(isolate, resource, callback, argc, argv, uid, trigger_id);`](https://github.com/nodejs/node/blob/master/src/node.h#L562)\r\n* `Callback::~Callback` should call [`EmitAsyncDestroy(isolate, uid);`](https://github.com/nodejs/node/blob/master/src/node.h#L549)\r\n\r\nThis is very similar to the [`AsyncResource`](https://github.com/nodejs/node/blob/master/src/node.h#L589) class. It is not clear what the `resource` should be as `Callback::Callback` does not take such a parameter.\r\n\r\nI believe @mhdawson said during a [diagnostics meeting](https://github.com/nodejs/diagnostics/pull/97) that if NAN required changes then likely N-API would need changes too.\r\n\r\n/cc @mhdawson @addaleax @trevnorris @nodejs/diagnostics @nodejs/n-api @nodejs/addon-api @nodejs/nan (@kkoopa) ",
        "labels": "feature request",
        "id": 43525
    },
    {
        "title": "Add option to break on start of specific file",
        "body": "**Use case**: debugging applications run by certain tools (test runners etc.)\r\n**Issue**: `--inspect-brk` starts debugging in tool, not application code; walking over numerorous function calls before applications starts is cumbersome\r\n**Proposed solution**: add flag `--inspect-brk-on` to be used like: \r\n```shell\r\n$ node --inspect-brk-on=./lib/index.js $(which serverless) invoke --function main # break happens on first line of ./lib/index.js\r\n```",
        "labels": "feature request",
        "id": 43526
    },
    {
        "title": "repl: allow `await` in REPL",
        "body": "I've seen this [requested](https://stackoverflow.com/questions/44169542/how-to-resolve-promises-when-using-app-with-repl/) a few times in StackOverflow now: \r\n\r\nPeople have code that is asynchronous and would like to use values from it in the REPL:\r\n\r\n    // how do I access in the REPL? returns promise\r\n    Transaction.where('reference', '1').fetch().then((res) => { return res }); \r\n\r\nA common workaround is to store a global reference in the REPL, which is a little hacky and relies on timing, but can work for simple cases:\r\n\r\n    > Transaction.where('reference', '1').fetch().then((res) => out = res)\r\n    [Object Promise]\r\n    > out\r\n       /* response available here*/\r\n\r\nThis works, but has timing issues and generally isn't great. We could however run the REPL in the context of an async function potentially - which would allow `await`ing values in the REPL:\r\n\r\n    let res = await Transaction.where('reference', '1').fetch(); \r\n\r\nI think it could be an interesting enhancement but would like more feedback on the idea. @nodejs/collaborators ",
        "labels": "feature request",
        "id": 43527
    },
    {
        "title": "timers: expose rearm()",
        "body": "* **Version**: all\r\n* **Platform**: n/a\r\n* **Subsystem**: timers\r\n\r\nIt would be nice if `timers` exported `rearm()` or at least a variant of it suitable for public consumption. One use case for this is to allow for easier and/or more efficient keepalive mechanisms where a timer needs to be reset after a packet is sent/received.\r\n\r\nCurrently the only two solutions to achieve this are to constantly start/clear a normal Timeout or use an Interval timer and have some extra logic in the Interval callback to determine whether you should actually execute the real callback (and even then you can lose accuracy). Being able to just `rearm(timer)` simplifies all of this greatly and has much less overhead than `clearTimeout()` followed by `setTimeout()` for every packet.",
        "labels": "feature request",
        "id": 43528
    },
    {
        "title": "Tracking issue: Worker support",
        "body": "Iâ€™m opening this as a discussion issue, as proposed in https://github.com/nodejs/node/pull/2133#issuecomment-302952025, to see whether and how we can get (Web)Worker support into Node core.\r\n\r\nThis feature would be comparatively large, thereâ€™s quite a bit of pre-existing work that we will want to look at, and I imagine we might want to do an [enhancement proposal (EP)](https://github.com/nodejs/node-eps) first to make sure we donâ€™t engage in too much unnecessary work. I imagine the roadmap is something like this:\r\n\r\n1. Create a new repository in the org to work under, for code, working out the EP text, discussion issues, and so on. This is something I can just do unless anybody objects to that in the near future.\r\n1. Find volunteers who are willing to do parts of the work, maybe even set up somewhat regular meetings.\r\n1. See if there are any immediate objections to a feature of this kind becoming a part of Node core.\r\n1. Figure out what the API should look like; How close to the WebWorker standard could and should we get? How much of Nodeâ€™s standard modules should be available to workers (e.g.: weâ€™d probably want timers but no I/O modules? or maybe we would want those?)? SharedArrayBuffers? Other magic?\r\n1. Take a look at work that has been done elsewhere, e.g. https://github.com/nodejs/node/pull/2133 or @audreytâ€™s https://github.com/audreyt/node-webworker-threads, and see how much can be used, what went well/not so well, etc.; Also, I know @bnoordhuis has looked into this a lot, so it would be really good to hear his thoughts.\r\n1. Write an EP based on discussion around those topics.\r\n1. Get the CTC to approve that EP.\r\n1. Work on the actual code, documentation, tests, etc. in that extra repository.\r\n1. Open a pull request against this repository (nodejs/node) with the new code.\r\n\r\nI can probably lead a bit of the effort, and Iâ€™ve considered doing this work alone, but so far it always ended at â€œthis would be too much work for me to do on my ownâ€; so if you want to help, please do, but expect to spend some time on this. :heart:\r\n\r\n/cc @nodejs/collaborators @petkaantonov @NawarA @pemrouz",
        "labels": "feature request",
        "id": 43529
    },
    {
        "title": "inspector: allow opt-out of console.* hijacking",
        "body": "* **Version**: all\r\n* **Platform**: n/a\r\n* **Subsystem**: inspector\r\n\r\nIt would be nice to be able to opt out of `console.*` \"hijacking\" by the inspector integration for situations where stdout (and/or stderr) is redirected to a file and the process produces a lot of output. Not only is the output duplicated (once in the file and again in the browser), but it can eat up extra memory if you don't need/care to see the console output in the browser.",
        "labels": "feature request",
        "id": 43530
    },
    {
        "title": "Programatically setting the debug flag has no effects",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 7.10.0\r\n* **Platform**: any\r\n* **Subsystem**: cluster\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nGiven the following code:\r\n\r\n```javascript\r\nconst cluster = require('cluster')\r\n\r\nif (cluster.isMaster) {\r\n  cluster.setupMaster({\r\n    execArgv: [\r\n      '--debug=1337'\r\n    ]\r\n  })\r\n\r\n  cluster.fork()\r\n} else {\r\n  setInterval(() => true, 1000)\r\n}\r\n```\r\n\r\nI get the following output on the console at runtime:\r\n\r\n```plaintext\r\nDebugger listening on port 5859\r\n```\r\n\r\nThe reason for this is because the current code assumes that whatever flag present in execArgv will be the same as the one being passed to the master process, and therefore extracts the initial port from `process.debugPort` instead (ref: https://github.com/nodejs/node/blob/master/lib/internal/cluster/master.js#L98-L119). It also assumes that the first port will be used to debug the master, and automatically increment the port for the first worker. Finally, given the submitted code, one would arguably expect no increments to happen at all; in the actual use-case where I wish to make sure of this pattern, I use cluster with one and only one worker at a time, so re-using the same port would be perfectly fine.\r\n\r\nI would be more than happy to contribute a fix, but given the current behaviour and the fact that I don't know how I could actually distinguish programatic setup from the initial extraction of `execArgv` passed to the master process, I am having a bit of a hard time to figure out how to approach this issue. Suggestions more than welcome.\r\n",
        "labels": "feature request",
        "id": 43531
    },
    {
        "title": "Provide a way to create clone/CoW copies",
        "body": "Currently, copying files is implemented by reading the data of the source file and writing it to the new file, see [fs-extra's implementation of copy](https://github.com/jprichardson/node-fs-extra/blob/master/docs/copy.md). The problem is that this approach doesn't allow the OS to optimize file copying (such as by using direct disk-to-disk copy if it's available), nor does it allow the (optional or by default) use of reflink/CoW.\r\n\r\nI'm specifically interested in making CoW (which is already available on some *nix file systems, including btrfs and zfs) available to nodejs.\r\n\r\nIMHO, nodejs should add an fs.copy function (just like what fs-extra already does) which is implemented using the OS native file copying syscall. It should have an optional `option` parameter that allows specifying the copy should use CoW (if available), just like how [`cp --reflink=auto` from coreutils works on Linux](http://man7.org/linux/man-pages/man1/cp.1.html).\r\n\r\nNote that this would be particularly benefit for cases where files are copied often - particularly big files. I'm thinking that this improvement would substantially benefit package managers (npm, yarn, etc).",
        "labels": "feature request",
        "id": 43532
    },
    {
        "title": "http: setting multiple headers could be more efficient",
        "body": "Currently, multiple headers are set using the `setHeader` method both externally, and internally by methods like `writeHead`. This is fine, except its a key lookup to get the `outHeaders` symbol keyed object (which is internal) for every header that's set, which is unnecessary, when you know all the headers to be set.\r\n\r\nA `setHeaders` method that takes an array of headers, and just sets them in one shot could be more efficient - A tiny micro-optimization that's not a priority on any level. \r\n\r\nWhile this is easy to create a PR for, can this be a public method - since there's no harm in doing so, and would be helpful in setting multiple headers efficiently in one-shot without using `writeHead` which also sets the status.",
        "labels": "feature request",
        "id": 43533
    },
    {
        "title": "Add `open` event to `ChildProcess` objects",
        "body": "`ChildProcess` objects has the `close` event to notify when all the child processes `stdio` streams has been closed, but there's no way to know when the child process got successfully started and it's ready, so I propose to add an `open` event when the `stdio` streams got open to be orthogonal to the `close` event, but could be used too to know when the child process started in a similar way to the `connect` event on the `net` and `http` modules.",
        "labels": "feature request",
        "id": 43534
    },
    {
        "title": "New dlopen flags API",
        "body": "Let's discuss how an API for dlopen flags should look like. A proposal has been made on https://github.com/nodejs/node/pull/12794, where it was clear that once we sort out the API, the implementation is fairly straightforward.\r\n\r\nAs @jasnell and @sam-github pointed out it would be ideal to be able to pass these flags to act locally to a specific addon. On the other hand, this might require more work.\r\n\r\nSetting global dlopen flags seems easier, at the cost of being potentially more fragile. Indeed, it would pollute the namespace, breaking if two addons load collisioning symbols. On the other side, this is highly unlikely. In favor of this, note that the global solution is what Python seems to do.\r\n\r\nSo, I propose two APIs:\r\n \r\n(1) Global, using `process` module. Similar to https://github.com/nodejs/node/pull/12794.\r\n\r\n```\r\nprocess.setdlopenFlags(os.constants.dlopen.RTLD_NOW | os.constants.dlopen.RTLD_GLOBAL);\r\nvar foo = require('foo');\r\nprocess.setdlopenFlags(0);\r\n```\r\n\r\n(2) Also global (?), putting the setter in the `require` object:\r\n\r\n```\r\nrequire.setdlopenFlags(os.constants.dlopen.RTLD_NOW | os.constants.dlopen.RTLD_GLOBAL);\r\nvar foo = require('foo');\r\nrequire.setdlopenFlags(0);\r\n```\r\n\r\nIMO, in this last case, the semantics are misleading. When the `require.setdlopenFlags()` call is made, the current module has already been loaded. So the dlopen flags are set for a JS script that is already loaded. The `Module` instance for the addon has to check its parent dlopen flags.\r\n\r\n(3) Local to an addon, passing an object as an extra argument to `require()`.\r\n```\r\nvar os = require('os');\r\nvar foo = require('foo', {dlopenFlags: os.constants.dlopen.RTLD_NOW | os.constants.dlopen.RTLD_GLOBAL})\r\n```\r\n\r\nAs far as I can see, passing an argument to `require` is the only way of keeping the flag local to a module. The addon to-be-loaded must first create a `Module` instance, which is created in the context of the `require` call.",
        "labels": "feature request",
        "id": 43535
    },
    {
        "title": "Feature request: utilize Symbol.toStringTag in util.inspect",
        "body": "Sample usage is HTML tree, where every child node is named according to its type.\r\n```js\r\nclass Node extends Array\r\n{\r\n    constructor(type = 'InputElement', children = [])\r\n    {\r\n        super(...children);\r\n        this.type = type;\r\n    }\r\n    [Symbol.toStringTag]()\r\n    {\r\n        return this.type;\r\n    }\r\n}\r\n```\r\nExample of print to console:\r\n```console\r\nHTMLElement [\r\n    HeadElement [\r\n        ....\r\n    ]\r\n    BodyElement [\r\n        ....\r\n    ]\r\n]\r\n```\r\n\r\n_(edited by @vsemozhetbyt: added backticks for code blocks)_",
        "labels": "feature request",
        "id": 43536
    },
    {
        "title": "Set inspect.defaultOptions using environment variables",
        "body": "* **Version**: v6.9.1\r\n* **Platform**: Linux jesper-UX303LB 4.4.0-72-generic 93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: util\r\n\r\nI really like the addition of [`util.inspect.defaultOptions`](https://github.com/nodejs/node/issues/7566), but what would be even nicer would be some way to specify these using environment variables. That way no code changes would have to be made to specify these and on a local development machine one could set their default preference easily.\r\n\r\nI'm suggesting the following environment variables:\r\n```\r\nNODE_INSPECT_SHOWHIDDEN\r\nNODE_INSPECT_DEPTH\r\nNODE_INSPECT_COLORS\r\nNODE_INSPECT_CUSTOMINSPECT\r\nNODE_INSPECT_SHOWPROXY\r\nNODE_INSPECT_MAXARRAYLENGTH\r\nNODE_INSPECT_BREAKLENGTH\r\n```",
        "labels": "feature request",
        "id": 43537
    },
    {
        "title": "Relative URLs in WHATWG URL API",
        "body": "* **Version**: v9.x+\r\n* **Platform**: all\r\n* **Subsystem**: url\r\n\r\nWe are on the track to slowly deprecate the non-standard `url.parse()` (https://github.com/nodejs/node/issues/12168#issuecomment-291548561) in favor of the new [WHATWG standard-based URL API](https://nodejs.org/api/url.html#url_the_whatwg_url_api). One use case that currently cannot be migrated over from `url.parse()` is the handling of relative URLs.\r\n\r\n## Background\r\n\r\n`url.parse()` accepts incomplete, relative URLs by filling unavailable components of a URL with `null`.\r\n\r\n```js\r\n> url.parse('#hash')\r\nUrl {\r\n  protocol: null,\r\n  slashes: null,\r\n  auth: null,\r\n  host: null,\r\n  port: null,\r\n  hostname: null,\r\n  hash: '#hash',\r\n  search: null,\r\n  query: null,\r\n  pathname: null,\r\n  path: null,\r\n  href: '#hash' }\r\n```\r\n\r\nOn the other hand, the `URL` constructor guarantees that all URL objects are fully complete and valid URLs, which means that it throws an exception in case of relative URLs:\r\n\r\n```\r\n> new URL('#hash')\r\nTypeError [ERR_INVALID_URL]: Invalid URL: #hash\r\n    at Object.onParseError (internal/url.js:92:17)\r\n    at parse (internal/url.js:101:11)\r\n    at new URL (internal/url.js:184:5)\r\n    at repl:1:1\r\n```\r\n\r\nWHATWG URL API does have the algorithms necessary to parse relative URLs, however, and that is activated if a `base` argument is provided:\r\n\r\n```js\r\n> new URL('#hash', 'http://complete-url/')\r\nURL {\r\n  href: 'http://complete-url/#hash',\r\n  origin: 'http://complete-url',\r\n  protocol: 'http:',\r\n  username: '',\r\n  password: '',\r\n  host: 'complete-url',\r\n  hostname: 'complete-url',\r\n  port: '',\r\n  pathname: '/',\r\n  search: '',\r\n  searchParams: URLSearchParams {},\r\n  hash: '#hash' }\r\n```\r\n\r\nIt is not always the case that a base URL is available, though.\r\n\r\n## Possible solutions\r\n\r\n### Do nothing\r\n\r\nWhat this entails is that the currently supported ability to parse relative URLs will die as `url.parse()` becomes deprecated.\r\n\r\n### Do not deprecate `url.parse()`; otherwise do nothing\r\n\r\nThis is the most obvious actual solution, but from tickets like #12168, I don't see this as a good idea.\r\n\r\n### Add a non-standard `TolerantURL` class\r\n\r\nThis could work if we trick the parser into believing we have a legitimate URL, except there are many conditionals in the [URL parser algorithm](https://url.spec.whatwg.org/#concept-basic-url-parser) that provide ad-hoc compatibility fixes with legacy implementations. We would have to make a set of opinionated assumptions about the nature of the URL, such as the URL's scheme.\r\n\r\nIn addition to parsing, the setters will have awkward semantics. Consider the following:\r\n\r\n```js\r\n// Case 1\r\nconst relativeURL = new TolerantURL('#hash');\r\nconsole.log(relativeURL.href);\r\n  // Prints #hash\r\n\r\nrelativeURL.protocol = 'http:';\r\nconsole.log(relativeURL.href);\r\n  // Should this print http:#hash (what url.format() does)?\r\n  // http://#hash?\r\n  // Or make the setter a noop and therefore just #hash?\r\n\r\n// Case 2\r\n// Assuming we have decided to use http scheme semantics\r\n// for TolerantURL if one is not supplied.\r\n// The URL parser does not allow changing special-ness of\r\n// scheme through the protocol setter.\r\nconst relativeURL = new TolerantURL('//username:password@host/');\r\nrelativeURL.protocol = 'abc';\r\nconsole.log(relativeURL.href);\r\n  // Should this print abc://username:password@host/?\r\n  // Or //username:password@host/?\r\n\r\n// Compare:\r\nconst absoluteURL = new URL('http://username:password@host/');\r\nabsoluteURL.protocol = 'abc';\r\nconsole.log(absoluteURL.href);\r\n  // Prints http://username:password@host/\r\n```\r\n\r\n### Something else that's better than what I thought of above...",
        "labels": "feature request",
        "id": 43538
    },
    {
        "title": "Allow to suppress --inspect hint",
        "body": "When started with inspector protocol, node emits messages relevant for debugging in Chrome DevTools:\r\n```\r\nnode --inspect=48235 --debug-brk test.js\r\nDebugger listening on port 48235.\r\nWarning: This is an experimental feature and could change at any time.\r\nTo start debugging, open the following URL in Chrome:\r\n    chrome-devtools://devtools/bundled/inspector.html?experiments=true&v8only=true&ws=127.0.0.1:48235/c80523d4-0bd2-4e43-8af0-8dc75f12eeb3\r\n```\r\n\r\nHowever, these messages are not relevant when debugging using a tool (e.g. IDE) that connects to the debug port immediately.\r\nIt would be nice if it would be possible to suppress the hint. Possible ways:\r\n1. Check some environment variable (not great, but possible)\r\n2. Or print the hint text only if no connections within 1-2 seconds (that should be enough time for a tool to connect).\r\n\r\n\r\n* **Version**: 7.9.0\r\n* **Platform**: Linux segrey-desktop 3.19.0-32-generic 37~14.04.1-Ubuntu SMP Thu Oct 22 09:41:40 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: debugger",
        "labels": "feature request",
        "id": 43539
    },
    {
        "title": "Debugging HTTP & HTTPS Requests and responses",
        "body": "Is there anyway with a Node.js app that I can get it to log all HTTP and HTTPS requests and responses with URL, header and body contents ?\r\n\r\nWhat would be lovely is a GUI version of Node with a debugger window simular to Chromes developer mode that shows all requests and responses, as well as normal console, and maybe allows other debugging functions and information.\r\n",
        "labels": "feature request",
        "id": 43540
    },
    {
        "title": "feature: a way to package a complete Node.js application",
        "body": "OP feels `node` should provide a way to package a complete app\r\nThere should be a way for converting node.js web app's source code with all its dependencies within node_modules folder to compiled/released/published build files like for example :\r\n\r\n- .net has .dll file\r\n- java has .jar file\r\n- elixir has .beam file.\r\n\r\n\r\n",
        "labels": "feature request",
        "id": 43541
    },
    {
        "title": "installer will not overwrite user's .npmrc, even if invalid",
        "body": "### supporting information:\r\n\r\n - installer: nodejs-v7.8.0-x64.msi\r\n - `node -v` prints: 7.8.0\r\n - os: windows 10.0.16170\r\n\r\n### reproduce\r\nthe Node.js binary itself is in the PATH, but the globally installed packages are not.\r\nI reinstalled the latest nodejs( using nodejs-v7.8.0-x64.msi), and expect the installer can fix it. But it did not.\r\n\r\nIf need some more info, please let me know.",
        "labels": "feature request",
        "id": 43542
    },
    {
        "title": "Request for several features in Node core",
        "body": "We have recently implemented a very large project in node.js, and while the memory still fresh I wanted to summarize why node.js was perceived as a nice toy by most of the developers, and not as a mature language suitable for such a projects.\r\n\r\nDon't take me wrong, I'm not here to criticize, or to start another holy war. My goal is to list the things we encountered in a hope that they will be given a priority in the next releases.\r\n\r\nI cannot reveal the details of the projects, but lets say it was your average web application + algorithmic part. Naturally, we didn't have any expectations from node when it came to the algorithmic part, but we hoped the web part will be easy to implement. How naive of us, huh?. :)\r\n\r\nThe major problem with node:\r\n\r\nMost of the NPM modules are heavy, slow, not well thought out, and resemble the classical dependency hell. Therefore you are forced to constantly reinvent the wheel.\r\n\r\nHere is our reinvention list:\r\n\r\n1. CSV parsing\r\n2, XML/HTML parsing\r\n3. IPv4/IPv6 operations\r\n4. parsing of HTTP headers\r\n5. RSA keys\r\n6. SSL certificates (read ASN1)\r\n7. MySQL drivers (yes we tried mariasql)\r\n8. Sendfile\r\n9. SMTP support\r\n10. Asynchronous logs\r\n11. Zip/Unzip\r\n\r\nIts a basic and widely used stuff, and it was extremely discouraging to find out that node does not support natively anything in that list. Basically, we've spent most of our time doing stuff we shouldn't have been doing.\r\n\r\nCheers,\r\n",
        "labels": "feature request",
        "id": 43543
    },
    {
        "title": "Node occasionally gives multiple files/folders the same inode",
        "body": "**Moderator's note (@Fishrock123): Off-topic comments have and will be deleted.**\r\n\r\n----\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v7.2.1\r\n* **Platform**: Windows 10 Pro 64bit, Windows 7 Enterprise 64bit (Both using NTFS)\r\n* **Subsystem**: File System\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nNode sometimes reports different files/folders to have identical ino values.\r\nI can't reproduce this consistently and copying/reproducing a folder structure that contains dupes elsewhere doesn't replicate the issue.\r\n\r\nI did encounter lots of duplicates under `C:\\Users\\%USER%\\AppData` but it may be different for other people\r\n\r\n#### Example\r\nSpecific example I encountered\r\n```\r\n# Structure\r\nâ”‚   ServerStore.jsx\r\nâ”‚\r\nâ”œâ”€â”€â”€constants\r\nâ”‚       Api.jsx\r\nâ”‚\r\nâ””â”€â”€â”€stores\r\n        UserStore.jsx\r\n\r\n> fs.lstatSync(\"stores\").ino\r\n5910974511014218\r\n> fs.lstatSync(\"stores/UserStore.jsx\").ino\r\n24206847997202570\r\n> fs.lstatSync(\"constants\").ino //Duplicate\r\n9851624184963316\r\n> fs.lstatSync(\"constants/Api.jsx\").ino //Duplicate\r\n9851624184963316\r\n> fs.lstatSync(\"ServerStore.jsx\").ino\r\n3659174697792238\r\n```\r\n#### Test Script\r\nHere's a hacky node script to loop through a directory and look for duplicate inodes.\r\nRunning it on most of my other folders didn't yield a result, until I ran it on `C:\\Users\\%USER%\\AppData` where I encounted loads of duplicates\r\n\r\nUsage: `node dupe.js [dir]`\r\n```javascript\r\nvar fs = require('fs');\r\nvar path = require('path');\r\nvar process = require('process');\r\n\r\n// Recursively walks a directory and looks for duplicate inodes\r\n// loop from http://stackoverflow.com/questions/5827612/node-js-fs-readdir-recursive-directory-search\r\n\r\nvar dir = process.argv[2];\r\nif (dir == undefined) {\r\n    dir = '.';\r\n}\r\n\r\nvar walk = function(dir, done) {\r\n\r\n  var results = [];\r\n  fs.readdir(dir, function(err, list) {\r\n\r\n    if (err) return done(err);\r\n\r\n    var pending = list.length;\r\n    if (!pending) return done(null, results);\r\n\r\n    list.forEach(function(file) {\r\n\r\n      file = path.resolve(dir, file);\r\n      fs.stat(file, function(err, stat) {\r\n        if(stat && stat.ino) {\r\n            results.push({\r\n                file: file,\r\n                ino: stat.ino\r\n            });\r\n        }\r\n\r\n        if (stat && stat.isDirectory()) {\r\n          walk(file, function(err, res) {\r\n            if(res) {\r\n               results = results.concat(res);\r\n            }\r\n            if (!--pending) done(null, results);\r\n          });\r\n        } \r\n        else {\r\n          if (!--pending) done(null, results);\r\n        }\r\n      });\r\n    });\r\n  });\r\n};\r\n\r\nwalk(dir, function(err, results) {\r\n    var merge = {};\r\n    results.forEach(function(it) {\r\n        if (!merge[it.ino]) {\r\n            merge[it.ino] = [];\r\n        }\r\n        merge[it.ino].push(it.file);\r\n    });\r\n    var dupes = Object.keys(merge).filter(key => merge[key].length > 1);\r\n\r\n    dupes.forEach(it => console.log(it, merge[it]));\r\n})\r\n```",
        "labels": "feature request",
        "id": 43544
    },
    {
        "title": "Feature Request: CLI to run package.json scripts",
        "body": "Currently many people use `npm run` in order to start up applications. In environments without `npm` this functionality would be very useful I recommend we pull this functionality into core itself. \r\n\r\nThis has a few things to note/bikeshed:\r\n\r\nWrapper process when running a `node` child process:\r\n* extra pid, may cause oddities if trying to get the PID of the application\r\n  * in `*nix` we can `exec()` in C to replace current process even if the child is not `node`\r\n  * in `WIN32` we cannot use the current process if the child is not `node`\r\n* mostly wasted CPU/mem\r\n* wraps stdio\r\n\r\nEnv variables:\r\n* `npm` sets up *many* environment variables.\r\n  * `PATH` is mutated for the process to include a vendored `node-gyp`, I am unclear to what extent we want this.\r\n\r\nArgv:\r\n* some things like `--inspect` are not properly propagated to child processes\r\n\r\nI am not seeking to introduce a standards `node --run-script build` etc. that would run a compile toolchain, not am I seeking to introduce a standard `node --run-script install`. I would like those to completely delegate to the `package.json`.\r\n\r\nThis can somewhat be related to https://github.com/nodejs/node/issues/11903 which would have some entry point with a `package.json` presumably. It also relates to https://github.com/nodejs/node/issues/11997 which has an idea of process argv delegation.",
        "labels": "feature request",
        "id": 43545
    },
    {
        "title": "Add --auto-open flag w/ --inspect",
        "body": "Based on #7992, I'm filing this issue to start a discussion around supporting a flag that would open or refresh an `inspect` session. Because copying/pasting the URL is a suboptimal workflow. I believe there's a chrome extension that will basically do this, but it'd be really nice to have it supported natively.",
        "labels": "feature request",
        "id": 43546
    },
    {
        "title": "Relative require",
        "body": "Any chances of enhancing `require` to support importing modules by specifying path relative to the base directory or current working directory ?\r\n\r\n## Problem\r\nWhen the directory structure of your Node.js **application** (not library!) has some depth, you end up with a lot of annoying relative paths in your require calls like:\r\n```js\r\nvar Article = require('../../../models/article');\r\n```\r\nThose suck for maintenance and they're ugly.\r\n\r\nMore information and various workarounds are discussed here [https://gist.github.com/branneman/8048520](https://gist.github.com/branneman/8048520)\r\n\r\nIf `node` would have a feature to import using relative paths, that would have been great.\r\n\r\nNot sure if there is already a open issue regarding this.",
        "labels": "feature request",
        "id": 43547
    },
    {
        "title": "ObjectWrap: there is no way to make v8 api call on GC",
        "body": "Currently there is no way to make a v8 api call on garbadge collection for C++ wrapped objects.\r\nThere is no other way to respond to garbadge collection in wrapped object other than destructor but\r\nit's considered to be bad idea to make a v8 api call in C++ class destructor.\r\nFor an example such v8 api call can be call to\r\n```cpp\r\nv8::Isolate::AdjustAmountOfExternalAllocatedMemory\r\n```\r\nin order to tell v8 that there was\r\nmemory allocation/deletion out of it's heap which is important information for GC cycles\r\nand memory usage. Adding\r\n```cpp\r\nvirtual void weakCallback(const v8::WeakCallbackInfo<ObjectWrap>& data)\r\n``` \r\nas an empty method in `ObjectWrap` which can be implemented by subclasses can fix this issue.",
        "labels": "feature request",
        "id": 43548
    },
    {
        "title": "Proposal: --config=file command line argument",
        "body": "In a number of conversations (e.g. https://github.com/nodejs/node/pull/11888), the idea of introducing either a `NODEOPT` environment variable that would allow arbitrary command line flags to be set via the environment, or a `.noderc` configuration file that could provide configuration options has been discussed. These choices have their merits and their disadvantages. One of the key disadvantages for me is the potential for the configuration collisions across applications and spooky action coming from environment settings that are unknown to the user. I *much* prefer explicit opt-in solutions.\r\n\r\nOne approach that could work that can potentially fill the gap is allowing configuration settings to be set using a `.noderc` type configuration file that is explicitly passed in via command line argument:\r\n\r\n```console\r\n$ node --config=/some/path/.noderc app.js\r\n```\r\n\r\nIf a user wanted to make use of environment variables in various environments, they could easily do so via variable expansion:\r\n\r\n```console\r\n$ export NODEOPT=/some/path/.noderc_production\r\n$ node --config=${NODEOPT}\r\n```\r\n",
        "labels": "feature request",
        "id": 43549
    },
    {
        "title": "Add $HOME/.config/nodejs with an option for deduping default repl history",
        "body": "I just landed 5bda5faffdeefa448965159e524eacdd14490436 which allows readlines to dedupe their history automatically when an option is set. I originally thought this would also be nice to have in the repl, but @DannyNemer made some good points in https://github.com/nodejs/node/pull/2982#issuecomment-283529159 about why we shouldn't have that on by default.\r\n\r\nI personally think there could be room for an env variable for this, and I'd personally kinda like to have it.",
        "labels": "feature request",
        "id": 43550
    },
    {
        "title": "Feature Request: Distributable Artifacts",
        "body": "This is a proposal for a feature that can create and use single files as a means to distribute packages be added to Node's core. In this document, use cases are presented but no implementation details are given. This is a rather large undertaking and should be delivered in smaller parts than the whole picture given here. EPs which include exact implementation details should be created as this work is agreed upon and split into smaller chunks.\r\n\r\nThis issue has been created as a successor to [the node --install](https://github.com/nodejs/node/issues/11835).\r\n\r\n## Use cases\r\n\r\n### Application users\r\n\r\nPeople wishing to distribute their node.js applications face a tough time currently. There is no standard way in which to distribute these. Docker is increasingly common, but so is telling people to go install dev tools such as `npm` on their machine and run something from the CLI. Compare this to Electron or Java `.jar` files which require double clicking a single file.\r\n\r\nThis case notably has the following features of interest:\r\n  * global installation\r\n  * run file on double click\r\n  * creation of single file binaries\r\n\r\n| feature | requirements |\r\n| ---- | ---- |\r\n| global installation | well known directory configuration |\r\n| global installation | standards for creating scripts invoking node properly on diff OS |\r\n| double click | CLI file extension support |\r\n| double click | installer based OS file extension registration |\r\n| binaries | build support like `_third_party_main` (native addon statics like `process._linkedBinding` or through extraction) |\r\n| binaries | random access in file |\r\n| binaries | trailing headers |\r\n| binaries | API to access assets (a Resource API) |\r\n\r\nThere are concerns here about how `node-gyp` functions not being compatible with statically linking in a dynamic manner for binaries. In existing research like [noda](https://github.com/bmeck/noda-loader) the solution was to extract the `.node` file to disk as a temporary file and then load it. For truly dynamic distributables that cannot be statically linked, this approach is commonplace.\r\n\r\n### Runtime plugins\r\n\r\nThe applications created by node.js have no standard for which to declare how application plugins should be created. Commonly this involves installing `devDependencies`, but for true runtime determined plugins this functionality does not make sense. Examples of runtime plugins are things such as servelets or minecraft like addons that are not depended upon by the applicaiton intended to run the plugin.\r\n\r\nIn well designed cases you can simply drop a `.dll` or `.jar` into a folder or onto a GUI and have an application know what to do. This should be easier and less home grown for the common case when developing on Node.\r\n\r\nThis case notably has the following features of interest:\r\n  * loading user defined plugins\r\n  * uniform format\r\n    * notably Electron could share the same format as Node\r\n\r\n| feature | requirements |\r\n| ---- | ---- |\r\n| plugin loading | require/import support |\r\n| uniform format | choosing a file format with potential for future meta-data |\r\n\r\n### Verification of distributables\r\n\r\nDue to security or connectivity, verification of the integrity of node.js modules is difficult. There is no clear standard for signing of the code, nor is there a distribution format to even create a digest from.\r\n\r\nOffline distribution is also important in places with low fidelity connections or no connections. Rural locations, network limited secure environments, etc. all would benefit from having a standard of both distribution and verification.\r\n\r\nThis case notably has the following features of interest:\r\n  * Creation of policies around trusted signatures\r\n  * Ease of distribution in low connectivity\r\n  \r\n| feature | requirements |\r\n| ---- | ---- |\r\n| verification of signatures | CA/Keystore standard |\r\n| verification of signatures | CLI support |\r\n| creation of signatures | CLI support |\r\n| low connectivity | offline capable CA/Keystore |\r\n\r\n#### Isolation\r\n\r\nIt should not be possible for other modules to modify the manner in which snapshot internals are loaded. This allows a rudimentary guarantee of evaluation order and dependency resolution but does not intend to prevent mutation of global state.\r\n\r\nIt may be prudent to restrict the ability to load certain modules while within a distributable (`fs`, `child_process`), doing so is potentially configured by the CA/Keystore standard.\r\n\r\n#### Mutability\r\n\r\nIn order for verification to occur, the internal state of a distributable must not have changed. If the only time required for verification is at install, extraction to disk is viable as any mutation after install is allowed.\r\n\r\nIf verification needs to be done when the runtime loads a distributable, an immutable state needs to be setup for a distributable.\r\n\r\n### Creation of reproducable dependency graphs\r\n\r\nOne of the largest problems with tooling in node modules is the lack of reproducable builds. Even with so called lock files, lack of an source of authority mechanism and signatures can lead to problems due to using naive things like checksums and name/version pairs. Creating a fully standardized bundle format that includes the entire assets of a module or application would prevent home grown solutions.\r\n\r\nWith a standard format in place it would also be possible to do a full audit of a dependency graph without having custom tools or having to recreate the entire dir structure on disk.\r\n\r\nThis case notably has the following features of interest:\r\n  * Cross environment\r\n  * Support for symlinks\r\n  * Includes the full fs tree\r\n   * Including assets such as HTML,CSS,Images,etc.\r\n\r\n| feature | requirements |\r\n| ---- | ---- |\r\n| cross environment | format should not be plaintext |\r\n| cross environment | CLI should be able to produce and extract distributables w/o OS tools |\r\n| symlinks | format should support |\r\n| full tree | format should be an full snapshot of the fs, not a manifest |\r\n| full tree | API to access assets if distributable is **not** extracted (a Resource API) |\r\n\r\n## Future Potential\r\n\r\nThe following I believe are best left to the future, but should be important for any design decisions.\r\n\r\n### Encryption\r\n\r\nIt should be possible to use encryption to generate a distributable that requires a key to be decrypted.\r\n\r\n### Privacy\r\n\r\nIn combination with the new bytecode system in V8 for example allows declaring the source string such that the JS debugger would not be able to see the source that generated the bytecode a modest level of code privacy can be obtained.\r\n\r\n### De-duplication\r\n\r\nSometimes, there are many duplicate files within a single application due to things like LICENSE files. While extracted to disk a solution is often to use hard links, it should be possible for a distributable to avoid declaring the same file body repeatedly.\r\n\r\n| feature | requirements |\r\n| ---- | ---- |\r\n| de-duplication | format should be extensible to have a hardlink like mechanism |\r\n\r\n### Poly-distributables\r\n\r\nWhen creating distributions, it is sometimes useful to include multiple variations of an application for testing, localization, etc. This may be due to lack of tooling on a target machine, or it may be to ease a specific workflow.\r\n\r\nDistributables could allow some mechanism by which they can include **multiple** variants withing a single distributable for their internals based upon things such as: language, architecture, debugging, etc. This most likely is not intrinsic to the file format, but more likely revolves around inteligent entry points.\r\n\r\n| feature | requirements |\r\n| ---- | ---- |\r\n| poly-dsitributable | format should not prevent userland from making runtime based routing decisions |\r\n\r\n### Shared library\r\n\r\nThis is the most complicated problem to solve. Many times, when creating applications, duplicate dependencies are extracted to disk in multiple places. Some attempts to avoid this such as using symlinks to a global cache exist. In order to alleviate both an audit, updating, and file size complexity this should be looked at. In particular, having a standard signature format is not enough.\r\n\r\nThe layout of a distributable is not something in scope of this proposed feature, that is left to package managers. Existing package managers can have complex relations where nested packages are not easily expressed using just symlinks due to how realpathing works in Node's module system.\r\n\r\nI suspect, the creation of a well defined shared cache based upon signature of a distributable could be shared amongst all the package managers however.\r\n\r\n## UX Bikeshedding\r\n\r\nAll names/UX happily looking for improvement. I will be using `.distributable` for an opaque file extension.\r\n\r\n```sh\r\nnode app.distributable\r\n```\r\n\r\nRuns the entry point to `app.distributable`\r\n\r\n```sh\r\nnode --create-distributable path/to/app/ --crt ...\r\nnode --create-distributable path/to/module/ --crt ...\r\n```\r\n\r\nCreates a distributable, optionally using `--crt` to declare signing information.\r\n\r\n```sh\r\nnode --extract-distributable app.distributable\r\n```\r\n\r\nExtract `app.distributable` to the current directory. This is probably not terribly useful except to try and muck with source.\r\n\r\n```sh\r\nnode --install-distributable app.distributable\r\n```\r\n\r\nSimilar to `npm --global install`, place `app.distributable` in a configured place and setup permisions and command shims.\r\n\r\n```sh\r\nnode --verify-distributable app.distributable\r\n```\r\n\r\nAutomatically run on install or extract, this checks `app.distributable` against Node's verification policy (signature may not be the only criteria).\r\n\r\n```sh\r\ncd git/nodejs/node\r\n./configure --main=app.distributable\r\nmake\r\n```\r\n\r\nCreate a single binary which runs `app.distributable` when started. Does not include debugger or REPL by default.",
        "labels": "feature request",
        "id": 43551
    },
    {
        "title": "Practical Problem: case-mismatch in package/file require statements",
        "body": "I noticed recently that I can write `require('myPackage')` and `require('mypackage')` interchangeably on my OS because the OS is case-insensitive. This is problematic because when I try to use the same project, package on a OS that case-sensitive the imports don't seem to work. This seems to be an issue that could occur with any package and any file. Since its a systemic issue I think it would be good if node.js would try to check if the case of the file/folder actually matches the case entered and show an error message or deprecation warning that can be turned off via a flag.",
        "labels": "feature request",
        "id": 43552
    },
    {
        "title": "Missing stack traces from async functions after the first await",
        "body": "Version: v7.7.3\r\nPlatform: Windows 7x64\r\n\r\nThe purpose of this issue is really a more broad request for better stack traces with async/await but I figured I would start with a very specific case. If we need to broaden the description, I'm good with that. I've seen a number of lengthy discussion on this subject in various places but I don't see any actual issues for it so I thought I'd start one and hopefully it's not just a duplicate of something I missed.\r\n\r\nI'm filing the specific issue here because it seems the async/await functionality just added provides less useful error handling than we could get with generators.\r\n\r\n```\r\nasync function functionOne() {\r\n  await new Promise((resolve) => {\r\n    setTimeout(() => { resolve(); }, 1);\r\n  });\r\n  throw new Error('Something Bad');\r\n}\r\n\r\nasync function functionTwo() {\r\n  await functionOne();\r\n}\r\n\r\nfunctionTwo()\r\n  .catch((error) => {\r\n    console.error(error);\r\n  });\r\n```\r\nOutputs:\r\n```\r\nError: Something Bad\r\n    at functionOne (C:\\Work\\sandbox.js:5:9)\r\n```\r\n\r\nThat stack is missing everything that called `functionOne` (`functionTwo` specifically).\r\n\r\nThe generator equivalent of this:\r\n\r\n```\r\nconst co = require('co');\r\n\r\nfunction* functionOne() {\r\n  yield new Promise((resolve) => {\r\n    setTimeout(() => { resolve(); }, 1);\r\n  });\r\n  throw new Error('Something Bad');\r\n}\r\n\r\nfunction* functionTwo() {\r\n  yield* functionOne();\r\n}\r\n\r\nco(functionTwo())\r\n  .catch((error) => {\r\n    console.log(error);\r\n  });\r\n```\r\nOutputs:\r\n```\r\nError: Something Bad\r\n    at functionOne (C:\\Work\\sandbox.js:7:9)\r\n    at functionOne.next (<anonymous>)\r\n    at functionTwo (C:\\Work\\sandbox.js:11:10)\r\n    at functionTwo.next (<anonymous>)\r\n    at onFulfilled (C:\\Work\\NPS\\nps-dev\\node_modules\\co\\index.js:65:19)\r\n```\r\n\r\nHere you can see both `functionOne` and `functionTwo` in the stack.\r\n\r\nIf the error is thrown before any `await` in the code, then you actually get a complete stack trace even if the function was called in a whole chain of awaits and regardless if those awaits were first or not:\r\n\r\n```\r\nasync function throwFunction() {\r\n  throw new Error('Something bad');\r\n}\r\n\r\nasync function functionOne() {\r\n  return await throwFunction();\r\n}\r\n\r\nasync function functionTwo() {\r\n  return await Promise.resolve();\r\n}\r\n\r\nasync function functionThree() {\r\n  await functionTwo();\r\n  return await functionOne();\r\n}\r\n\r\nfunctionThree()\r\n  .catch((error) => {\r\n    console.log(error);\r\n  });\r\n```\r\nOutputs:\r\n```\r\nError: Something bad\r\n    at throwFunction (C:\\Work\\sandbox.js:2:9)\r\n    at functionOne (C:\\Work\\sandbox.js:6:16)\r\n    at functionThree (C:\\Work\\sandbox.js:15:16)\r\n    at process._tickCallback (internal/process/next_tick.js:109:7)\r\n    at Module.runMain (module.js:607:11)\r\n    at run (bootstrap_node.js:425:7)\r\n    at startup (bootstrap_node.js:146:9)\r\n    at bootstrap_node.js:540:3\r\n```\r\n\r\nThe real driving force behind this was that I finally found the recipe to get complete stack traces, even when dealing with existing code using promises. With a try...catch in the generator, we can use `VError` to weld together the errors thrown by promises with the stack of the code calling the generator. This does not seem to work with async functions.\r\n\r\nHere's a more complete example using generators that I really wish would continue to work with async functions:\r\n\r\n```\r\nconst co = require('co');\r\nconst VError = require('verror');\r\n\r\nfunction calledFromAPromise() {\r\n  throw new Error('Something bad');\r\n}\r\n\r\nfunction doAPromise() {\r\n  return new Promise((resolve) => {\r\n    setTimeout(() => { resolve(); }, 1);\r\n  })\r\n    .then(() => { calledFromAPromise(); });\r\n}\r\n\r\nfunction* queryFunction() {\r\n  return yield* yieldRethrow(doAPromise());\r\n}\r\n\r\nfunction* functionOne() {\r\n  return yield* queryFunction();\r\n}\r\n\r\nfunction* functionTwo() {\r\n  return yield* functionOne();\r\n}\r\n\r\nfunction* yieldRethrow(iterable) {\r\n  try {\r\n    return yield iterable;\r\n  } catch (error) {\r\n    throw new VError(error);\r\n  }\r\n}\r\n\r\nco(functionTwo())\r\n  .catch((error) => {\r\n    console.log(error);\r\n  });\r\n```\r\nOutputs (with some non-relevant stuff removed):\r\n```\r\n{ VError: : Something bad\r\n    at yieldRethrow (C:\\Work\\sandbox.js:31:11)\r\n    at yieldRethrow.throw (<anonymous>)\r\n    at queryFunction (C:\\Work\\sandbox.js:16:17)\r\n    at functionOne (C:\\Work\\sandbox.js:20:17)\r\n    at functionTwo (C:\\Work\\sandbox.js:24:17)\r\n    at onRejected (C:\\Work\\NPS\\nps-dev\\node_modules\\co\\index.js:81:24)\r\n  jse_cause: \r\n   Error: Something bad\r\n       at calledFromAPromise (C:\\Work\\sandbox.js:5:9)\r\n       at Promise.then (C:\\Work\\sandbox.js:12:19),\r\n```\r\nThe async equivalent outputs this:\r\n```\r\n{ VError: : Something bad\r\n    at yieldRethrow (C:\\Work\\sandbox.js:30:11)\r\n  jse_cause: \r\n   Error: Something bad\r\n       at calledFromAPromise (C:\\Work\\sandbox.js:4:9)\r\n       at Promise.then (C:\\Work\\sandbox.js:11:19),\r\n```\r\n\r\nAs you can see, this has the same problem as at the top in that the rethrown error doesn't have a complete stack.",
        "labels": "feature request",
        "id": 43553
    },
    {
        "title": "child_process.exec considering process.env improvement",
        "body": "* **Version**: At least from 4.8.0 up to 6.10.0\r\n* **Platform**: debian 8\r\n* **Subsystem**: lib/child_process.js\r\n\r\n```javascript\r\nvar exec = require('child_process').exec;\r\n\r\nvar options = {\r\n    env : {\r\n        NODE_ENV : 'production'\r\n    }\r\n};\r\nexec(command, options, function(err, stdout, stderr) {\r\n  //do something here  \r\n});\r\n```\r\n\r\nThe above will loose all other process.env variables.\r\nThis might be correct behavior, but on the other hand I personally would have expected that exec does internally something like:\r\n\r\n\r\n```javascript\r\nvar env;\r\nif (options.env){\r\n    env = Object.assign({}, process.env, options.env);\r\n} else {\r\n   env = Object.assign({}, process.env);\r\n}\r\n```\r\n\r\nand then using it further on. This makes every child process having the process.env with possibility to override specific env vars. I am not familiar with use cases or what other developers would expect, but at least the above way drops out that logic from customer apps and could feel comfortable.\r\nSuppressing that with options.env = false could be an idea too.\r\n\r\nSo don't understand this as a reported bug, just an improvement idea you might think about.\r\n\r\nThanks!",
        "labels": "feature request",
        "id": 43554
    },
    {
        "title": "Feature request: Env Var NODE_REQUIRE",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 4.x.x, 6.x.x, 7.x.x\r\n* **Platform**: All\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI am requesting for something that's basically the command line option `-r` but through an environment variable `NODE_REQUIRE`.  The reason is that the `-r` option is not persistent.  If some other app invokes node, then the `-r` is not applied.  The environment variable `NODE_REQUIRE` should always be checked when node starts up.\r\n\r\nWhen the env var exist and `-r` is also specified, I think both should be required.\r\n\r\nThanks.\r\n",
        "labels": "feature request",
        "id": 43555
    },
    {
        "title": "Feature request: node --install",
        "body": "I'm going to try, as best I can, to distill more than a year of conversations about this topic.\r\n\r\nThis is a touchy subject. There have been numerous threads with various people advocating significant changes to npm or to replace it entirely. This is neither of those things.\r\n\r\n* I am not suggesting that Node.js stop shipping with `npm` by default.\r\n* I am not suggesting that the Node.js project write a full replacement of npm.\r\n\r\nWith that out of the way, and the frame of debate set within those boundaries, I think we can have a productive conversation.\r\n\r\nAs it has matured `npm` has become a large and significantly tool for software development. It includes features for *multiple* development workflows and optimizes itself for developer ergonomics. I don't think we could ask for a better tool for **developers**.\r\n\r\nThe problem is, not every Node.js install is used by a developer. Many installs happen in infrastructure. These installs run an application and are never touched by anything but infrastructure automation. Yet, these installs still include npm and, in fact, *require* npm in many cases because it is the best mechanism we have for installing the dependencies the application needs.\r\n\r\n### `node --install`\r\n\r\n* Installs the dependencies defined in a local package.json.\r\n* Follows all the standard logic found today in `npm install`.\r\n* Defaults to a \"production\" mode of package installation (similar to `npm install --production`.\r\n\r\nBecause the use cases for this are much more narrow than `npm` you can see a future in which additional features are added that are in high demand by production users but make the developer ergonomics more difficult (multiple registry endpoints for instance).\r\n\r\nI'd like to use this thread to reach a consensus about the scope of this feature, potential pitfalls, and whether or not this is something we agree should be added. From there I can work on a proper Enhancement Proposal.",
        "labels": "feature request",
        "id": 43556
    },
    {
        "title": "crypto.pbkdf2() supports custom hash algorithm",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: v6.10.0\r\nPlatform: \r\nSubsystem: crypto\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:v6.10.0\r\n* **Platform**:Darwin 16.4.0 Darwin Kernel Version 16.4.0: Thu Dec 22 22:53:21 PST 2016;\r\n* **Subsystem**:crypto\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n`crypto.pbkdf2()` accepts only digest function names, it will be useful if this can also be a real function so that non built-in digest functions can be used, for example **AES-CMAC-PRF-128**.\r\n",
        "labels": "feature request",
        "id": 43557
    },
    {
        "title": "console - writable property",
        "body": "I am writing testing utilities and have trouble on nodejs platform ridding off unwanted output. \r\n\"console\" is writable property in a browser. On nodejs \"console's\" methods could be rewritten iterating them, so making \"console\" non-writable does not give any insurance, but only make solving of my problem and similar more tedious. From my point of view having \"console\" non-writable counter-intuitive neither reasonable. \r\n\r\nI propose to return writability to \"console\". ",
        "labels": "feature request",
        "id": 43558
    },
    {
        "title": "Proposal: add option to automatically add BOM to write methods",
        "body": "Today I found out that you need to manually add a unicode representation of the Byte Order Mark in unicode files/streams.\r\n\r\nThe fact that you have to manually prepend it [leads to confusion](http://stackoverflow.com/a/27975629/1092853) IMHO. I think that it would be better to add a `addBom` (or something like that) as an option to the different write methods, that would remove the manuality of the process.",
        "labels": "feature request",
        "id": 43559
    },
    {
        "title": "Make \"exports\" a const",
        "body": "Maybe something like (totally not sure if this is doable or if it's even a good idea):\r\n\r\n```js\r\nNativeModule.wrapper = [\r\n  '(function (require, module, __filename, __dirname) { const exports = module.exports; ',\r\n  '\\n});'\r\n];\r\n```\r\n\r\nThe reasoning for this is to give users a warning if they try to change the exports variable reference.",
        "labels": "feature request",
        "id": 43560
    },
    {
        "title": "Make warnings more beginner-friendly",
        "body": "This issue came up while discussing #11642 \r\n\r\nThe problem with the warnings emitted by `process.emitWarning` is that they provide little information about the context or how to get more information. Unless the user knows about the cli flags like `--trace-warnings` or the warning API, there is no clue on how to proceed. A simple solution would be to append a short explanation like *Use the --trace-warnings command line flag to get a full stack trace of this warning.* if the flag is not set.",
        "labels": "feature request",
        "id": 43561
    },
    {
        "title": "Check cwd before spawning child process",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v7.6.0\r\n* **Platform**: Darwin Pecorino.local 16.4.0 Darwin Kernel Version 16.4.0: Thu Dec 22 22:53:21 PST 2016; root:xnu-3789.41.3~3/RELEASE_X86_64 x86_64\r\n\r\nWhen a cwd is passed to `child_process.spawn()` that does not exist, node just reports `ENOENT`:\r\n\r\n```javascript\r\nconst spawn = require(\"child_process\").spawn\r\n\r\nspawn(process.execPath, { cwd: \"/does/not/exist\" });\r\n```\r\n\r\n```\r\n> Error: spawn /usr/local/bin/node ENOENT\r\n    at exports._errnoException (util.js:1028:11)\r\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:193:32)\r\n    at onErrorNT (internal/child_process.js:359:16)\r\n    at _combinedTickCallback (internal/process/next_tick.js:74:11)\r\n    at process._tickDomainCallback (internal/process/next_tick.js:122:9)\r\n```\r\n\r\nThis error message is very confusing because it reads like `/usr/local/bin/node` does not exist. It took me several hours to debug this issue, including serious doubts in my sanity ðŸ˜.\r\n\r\nDo you think it is feasible to check the cwd before spawning the process, or is there a use-case/is it possible to spawn a process with a non-existent cwd? If it's not feasible, would it be an option to include the cwd in the error message to give a slight hint in the right direction?",
        "labels": "feature request",
        "id": 43562
    },
    {
        "title": "IncomingMessage.bytesRead",
        "body": "Would be nice to have a `bytesRead` property on `IncomingMessage` the same as with `fs.createReadStream`.  Since the underlying socket has a `bytesRead` property all that would be needed is a getter.",
        "labels": "feature request",
        "id": 43563
    },
    {
        "title": "Expose `ScriptCompiler::CachedDataVersionTag`",
        "body": "I'm using V8's code cache as exposed by `vm` in https://github.com/zertosh/v8-compile-cache, but I'm hitting cache versioning issues. I'd like know with certainty that a particular cache generated by one machine is compatible with another. `ScriptCompiler::CachedDataVersionTag` can let you do that (https://github.com/nodejs/node/blob/ca480719199d2ff38223aff8e301aced25d7e6f1/deps/v8/include/v8.h#L1379-L1397).\r\n\r\nI'd like to submit a PR exposing that data somewhere. Maybe expose it as a function on the `vm` module, or a static function on the `Script` constructor. Any ideas? Preferences?\r\n",
        "labels": "feature request",
        "id": 43564
    },
    {
        "title": "proposal: programmatically expose the V8 inspector URL",
        "body": "* **Version**: 7.6.0 and later\r\n* **Platform**: all\r\n* **Subsystem**: diagnostics\r\n\r\nThis is a feature request to add a method to the `v8` module that exposes the V8 inspector URL if the process has been started with `--inspect`. The motivation for this feature is to conveniently add links or buttons to a website that the developer can click to open the V8 inspector.\r\n\r\nThis is a hypothetical API:\r\n\r\n```txt\r\n$ node --inspect=dev.example.com:1337\r\n> require('v8').getInspectorUri()\r\nchrome-devtools://devtools/bundled/inspector.html?experiments=true&v8only=true&ws=dev.example.com:1337/8fe96e86-fa03-4a24-b21d-2ce3725e479e\r\n\r\n$ node\r\n> require('v8').getInspectorUri()\r\nnull\r\n```\r\n\r\n",
        "labels": "feature request",
        "id": 43565
    },
    {
        "title": "fs.readdir -> fs.readDir (Suggestion)",
        "body": "Hi,\r\n\r\nI would like to suggest changing the name of the **readdir** function in the fs module to **readDir** (capital D). Or at least adding an alias so that it doesn't break all currently deployed code.\r\n\r\nThis is so that all function names follow the same naming \"style\".\r\n\r\nI know this seems like nitpicking and it is definitely a superfluous issue, but wanted to share my pov. It feels like a quirky trait on an otherwise perfect development framework.\r\n\r\nRegardless of that, I am very grateful for node.js and I thank all contributors for their job in this project.",
        "labels": "feature request",
        "id": 43566
    },
    {
        "title": "fs.stat should returns the actual file path",
        "body": "So on Windows/MacOS X we could force case-sensitive or make a redirect, and other advantages.",
        "labels": "feature request",
        "id": 43567
    },
    {
        "title": "Missing async callstacks on setTimeout",
        "body": "When debugging Chrome, you can have code like\r\n\r\n```javascript\r\nsetTimeout(() => {\r\n  console.log('timeout');\r\n})\r\n```\r\n\r\nand if you pause in the timeout handler and enable async callstacks in Chrome DevTools, you'll see the callstack that lead to calling setTimeout:\r\n\r\n![image](https://cloud.githubusercontent.com/assets/323878/22917539/46ff47bc-f23a-11e6-87b2-3699ce4ed738.png)\r\n\r\nBut if I debug the same code in Node using the inspector protocol, I don't see async callstacks in this case. But I do see async callstacks for Promises. So it must have something to do with Node's timer implementation. Is there any way that it could surface async callstacks too?",
        "labels": "feature request",
        "id": 43568
    },
    {
        "title": "no support for \"connected\" UDP sockets",
        "body": "UDP sockets also support `connect` and can then subsequently be used with `send` and `recv` (instead of `sendto` and `recvfrom`).\r\n\r\nIf exchanging lots of messages with one peer, supporting `connect` would be better than the current `dgram.send(buf, offset, length, port, address, [callback])` which AIUI it will attempt a host lookup for `address` on each call.  If talking to multiple peers, this also allows one socket per peer, with no need to figure out which peer sent the response.\r\n\r\nNB:  I originally opened this as [ticket 769](https://github.com/nodejs/node-v0.x-archive/issues/769) for Node 0.x in March 2011.  It seems to have been archived away and never looked at again.",
        "labels": "feature request",
        "id": 43569
    },
    {
        "title": "Dist request: add http://nodejs.org/dist/latest-lts/",
        "body": "It would be really handy if there was a known place to download the latest and greatest LTS version.  It could be a symbolic link just like .../latest, .../latest-argon, .../latest-boron, etc.",
        "labels": "feature request",
        "id": 43570
    },
    {
        "title": "Bringing network debugging to V8 inspector",
        "body": "Just throwing it out there that I find the network inspection tab in [Node inspector](https://github.com/node-inspector/node-inspector) to be quite useful at times, would be neat if this was in node's built in V8 Inspector.",
        "labels": "feature request",
        "id": 43571
    },
    {
        "title": "Allow --inspect flag to be provided after script name",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 7.4\r\n* **Platform**: Sierra OSx\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nCurrently, only this works\r\n```\r\nnode --inspect myscript.js\r\n```\r\n\r\nIt seems dumb that the following shouldn't work\r\n```\r\nnode myscript.js --inspect\r\n```\r\n\r\nThis becomes especially important when doing [complex npm run scripts](https://docs.npmjs.com/cli/run-script) with passed arguments. For instance, if this feature existed, then we could define a regular run-script and a debug run-script in our package.json, like so\r\n\r\n```\r\n\"scripts\": {\r\n  \"regular\": \"node myscript.js\",\r\n  \"debug\": \"npm run regular -- --inspect\"\r\n}\r\n ```\r\n\r\nBut this fails for the reasons described above. \r\n\r\nAlso, it just makes sense that order shouldn't matter with command line flags. ",
        "labels": "feature request",
        "id": 43572
    },
    {
        "title": "RFC cluster: make scheduler pluggable",
        "body": "* **Version**: Future versions\r\n* **Platform**: All\r\n* **Subsystem**: cluster\r\n\r\nI believe a few people have asked for this directly and indirectly in the past. It would be nice to be able to customize the cluster master's scheduling policy. For example, I've seen people request the ability to \"pause\" a worker.\r\n\r\nOne possibility is to define a custom scheduling policy, and let the user pass in a constructor like our existing `SharedHandle` or `RoundRobinHandle`. Users would need to define a constructor function, `add()` method, and `remove()` method. I put together a small proof of concept, including example usage, in https://github.com/cjihrig/node-1/commit/427beec00cea49e7199eac065eb596224ad18677.\r\n\r\nThe downside is that it exposes some internal ugliness like the constructor function taking `key`, `address`, `port`, `addressType`, `fd`, and `flags` arguments. A simpler alternative might be to only require the user to define a scheduling function like `RoundRobinHandle#distribute()` and then use that with the `RoundRobinHandler` unless the `SharedHandle` is used.\r\n\r\nThoughts?\r\n",
        "labels": "feature request",
        "id": 43573
    },
    {
        "title": "querystring should maybe support Buffers",
        "body": "* **Version**: N/A\r\n* **Platform**: N/A\r\n* **Subsystem**: querystring\r\n\r\nThis was reported on IRC by `zzo38` who doesnâ€™t have a github account, so Iâ€™m opening this issue for them.\r\n\r\n> `require(\"querystring\").escape(Buffer.from([0x80,0x81]))` is expecting `%80%81` but results `%EF%BF%BD%EF%BF%BD`\r\n\r\nSo Iâ€™m reading this as requesting support in `querystring.escape` (and maybe `querystring.unescape`) for raw encoding/decoding to `Buffer` instances instead of always interpreting the values as UTF-8 strings.",
        "labels": "feature request",
        "id": 43574
    },
    {
        "title": "Cannot disable warnings when node is launched via a shell script.",
        "body": "As an end-user, I don't want to ever see warnings or deprecations.  However, when node is invoked from a shell script via a shebang, there is no opportunity to pass the `--no-warnings` option to the process.\r\n\r\n```\r\n#!/usr/bin/env node --no-warnings\r\nconsole.log(\"you will never get this far, so it doesn't matter if this compiles\");\r\n```\r\n\r\nIs there an environment variable that can be set to toggle this option?  If not, please add support for something like `NODE_NO_WARNINGS=1`.\r\n",
        "labels": "feature request",
        "id": 43575
    },
    {
        "title": "Proposal for better cluster tuning",
        "body": "Currently with the way Cluster is implemented in Node, the Master creates a connection handler for the child processes to use. This means if we set maxConnections on our child server, it is per child.\r\n\r\nThis is problematic as it means if, say, we have one child per core, and we are using the default Round Robin load balancing in Cluster, we can max out one child while the other child has available connections.\r\n\r\nIt would be ideal if we can handle this level of tuning somehow at the master level. It seems that we could set the maxConnections at the master level by having the master keep track of total connections and close connections in the load balancer function if the number is greater than the configured value.\r\n\r\nChild behavior could remain unchanged, but for optimal tuning a child should ignore its maxConnections value if the master is handling it.\r\n\r\nAs it stands, we have found that from an ops perspective we need to handle connection back pressure at either the nginx/haproxy/ATS/etc layer in front of our node cluster as the default cluster behavior is far from ideal.",
        "labels": "feature request",
        "id": 43576
    },
    {
        "title": "Child Process: fork stdio option doesn't support the String variant that spawn does",
        "body": "Version: v7.4.0\r\nPlatform: Windows 64 bit\r\n\r\nThe following code forks a script but all it's stdio objects are null\r\n\r\nindex.js\r\n```js\r\nvar child = childProcess.fork('./userapp/test.js', [], {\r\n  stdio: 'pipe'\r\n});\r\nconsole.log('stdio', child.stdio);\r\n```\r\n\r\ntest.js\r\n```js\r\nvar count = 0;\r\nsetInterval(function () {\r\n  if (count == 3) process.exit(1);\r\n  console.log('test: ' + count);\r\n  count++;\r\n}, 1000, 0);\r\n```\r\n\r\nconsole output:\r\n```\r\nstdio [ null, null, null, null ]\r\ntest: 0\r\ntest: 1\r\ntest: 2\r\n```\r\n\r\nAlso i've tried to set the childs stdio with `stdio: [stream, stream, stream]` but this didn't work and the child used the parents stream to output",
        "labels": "feature request",
        "id": 43577
    },
    {
        "title": "Request: support out of tree build",
        "body": "Currently, the configure script and Makefile assume they're being executed with the work tree as the current working directory.  This isn't always the case, and supporting out-of-tree building is very useful; it supports automation, and it supports development, in the cases where the make targets change what is/is not installed.\r\n\r\nI updated `configure` to support this, but failed to realize the project is not using Automake, and once I had, didn't attempt to update the `Makefile`.  Certain tools (from the `tools/` directory) are hardcoded in the Makefile rules.",
        "labels": "feature request",
        "id": 43578
    },
    {
        "title": "Add fs.statvfs function to get disk size/free/available space + other info",
        "body": "There is no build in way to get disk space information. There are a few npm modules available:\r\n- https://www.npmjs.com/package/diskusage (has 8 dependencies, including FFI, which is quite ridiculous, proposed reimplementation in C++: https://github.com/jduncanator/node-diskusage/issues/14)\r\n- https://www.npmjs.com/package/diskspace (depends on an EXE file on Windows)\r\n\r\nThis is such a basic API that should be built-in.",
        "labels": "feature request",
        "id": 43579
    },
    {
        "title": "node js api document should link to LTS release from each page",
        "body": "The API documentation for the LTS stuff is a little hidden on the site -- you have to either know the LTS doc URL or always enter it from the front door, whereas nodejs.org/api is quite easy to remember. \r\n\r\nIt would be really nice if the documentation for the \"live\" release had a link on that page to the relevant documentation for the LTS version (if it exists).\r\n\r\nThe postgres documentation is actually an excellent example of this:\r\n![image](https://cloud.githubusercontent.com/assets/193412/21816128/d5dfaedc-d713-11e6-9109-ac19fe766304.png)\r\n\r\nEach page has a link to various other supported (and even non-supported!) versions which makes it very easy to hop to the correct version that you're using.\r\n\r\n",
        "labels": "feature request",
        "id": 43580
    },
    {
        "title": "not support file URLs containing drive specifiers (e.g., \"file:///c:/path\")",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:All\r\n* **Platform**:windows\r\n* **Subsystem**:fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nRemove leading slashes if followed by drive specifier.As a side effect,\"/c:/path\" can be used as an alternative to \"c:/path\".",
        "labels": "feature request",
        "id": 43581
    },
    {
        "title": "build: introduce zopfli compression",
        "body": "* **Version**: any\r\n* **Platform**: any unix os with .gz tarball release\r\n* **Subsystem**: build\r\n\r\nDear all node maintainer, \r\n\r\nNot sure if you heard of **zopfli** or not, I spend a while to test its performance and impact on node release tarball, wanna share the result with you, wonder if you'll like to accept a PR to use it?\r\n\r\nzopfli is a **fully gz compatible compression** algorithm introduced by **Google** in 2013, with additional 5% size saving but may be 80 times slower when compression (but won't be performance issue when decompression), used to compress the static resource like release tarball, since we can compress it once but use it billion times, so that we can save significant bandwidth and disk space. It's already been included in Ubuntu, Debian, Fedora Linux distros, and also FreeBSD, for the detail, there are some references:\r\n\r\n - https://developers.googleblog.com/2013/02/compress-data-more-densely-with-zopfli.html\r\n - http://www.techrepublic.com/blog/the-enterprise-cloud/googles-zopfli-compression-algorithm-extract-higher-performance-from-your-compressed-files/\r\n - https://github.com/google/zopfli\r\n - https://en.wikipedia.org/wiki/Zopfli\r\n\r\nI just take `node-v7.4.0-linux-x64.tar.gz` release tarball as an example, compare  time + size impact on my computer with both origin `gzip -9` and different iterations of zopfli compression\r\n( `gzip -9`, `zopfli --i1`, `zopfli --i9`, `zopfli --i19`, `zopfli --i50`)\r\n\r\n```\r\n$ time gzip -9 node-v7.4.0-linux-x64.tar\r\n\r\nreal    0m6.452s\r\nuser    0m6.442s\r\nsys     0m0.008s\r\n\r\nsize: 15537444\r\n```\r\n\r\n```\r\n$ time zopfli --i1 node-v7.4.0-linux-x64.tar\r\n\r\nreal    1m49.536s\r\nuser    1m49.452s\r\nsys     0m0.052s\r\n\r\nnode-v7.4.0-linux-x64.tar.gz 15537444 -> 14975152 (96.38%), 16 times slower\r\n```\r\n\r\n```\r\n$ time zopfli --i9 node-v7.4.0-linux-x64.tar\r\n\r\nreal    3m44.684s\r\nuser    3m44.546s\r\nsys     0m0.068s\r\n\r\nnode-v7.4.0-linux-x64.tar.gz 15537444 -> 14937034 (96.13%), 34 times slower\r\n```\r\n\r\n```\r\n$ time zopfli --i19 node-v7.4.0-linux-x64.tar\r\n\r\nreal    6m11.833s\r\nuser    6m11.656s\r\nsys     0m0.068s\r\n\r\nnode-v7.4.0-linux-x64.tar.gz 15537444 -> 14935402 (96.13%), 56 times slower\r\n```\r\n\r\n```\r\n$ time zopfli --i50 node-v7.4.0-linux-x64.tar\r\n\r\nreal    13m49.044s\r\nuser    13m48.278s\r\nsys     0m0.064s\r\n\r\nnode-v7.4.0-linux-x64.tar.gz 15537444 -> 14933583 (96.11%), 168 times slower\r\n```\r\n\r\nSo the time will at least increase 16 times, about 1 min 43 secs on my computer (E3-1220 V2 @ 3.10GHz CPU with DDR3 1333 8GB Ram), the size will be reduced to 96.38%, if we give it more time and iterations, the size could be smaller, but the effect won't growth that significantly, that's the tradeoff.\r\n\r\nI'm not sure how many download times per release will have, since we don't release new version everyday (except nightly build, but we can disable zopfli on nightly build, just use origin gzip on it), give each release few more minutes, save about 4% size on the gz release tarball, save both bandwidth and disk space on the nodejs side, user side, may worth it.\r\n\r\nJust FYI, I also tested zopfli compression result with all the gz tarballs but different compress iterations as below:\r\n\r\nzopfli --i1 size changes:\r\n```\r\nnode-v7.4.0-headers.tar.gz          483170 ->   460281 (95.26%)\r\nnode-v7.4.0-darwin-x64.tar.gz     13416624 -> 12893965 (96.10%)\r\nnode-v7.4.0-linux-arm64.tar.gz    14711615 -> 14155294 (96.21%)\r\nnode-v7.4.0-linux-armv6l.tar.gz   14687810 -> 14147345 (96.32%)\r\nnode-v7.4.0-linux-armv7l.tar.gz   14666298 -> 14122855 (96.29%)\r\nnode-v7.4.0-linux-ppc64.tar.gz    15675943 -> 14887267 (94.96%)\r\nnode-v7.4.0-linux-ppc64le.tar.gz  15335840 -> 14750604 (96.18%)\r\nnode-v7.4.0-linux-s390x.tar.gz    15952274 -> 15138093 (94.89%)\r\nnode-v7.4.0-linux-x64.tar.gz      15537444 -> 14975152 (96.38%)\r\nnode-v7.4.0-linux-x86.tar.gz      14999886 -> 14469933 (96.46%)\r\nnode-v7.4.0-sunos-x86.tar.gz      15309353 -> 14751377 (96.35%)\r\nnode-v7.4.0.tar.gz                27904025 -> 26594185 (95.30%)\r\n```\r\n\r\nzopfli --i9 size changes:\r\n```\r\nnode-v7.4.0-headers.tar.gz          483170 ->   458036 (94.79%)\r\nnode-v7.4.0-darwin-x64.tar.gz     13416624 -> 12848587 (95.76%)\r\nnode-v7.4.0-linux-arm64.tar.gz    14711615 -> 14111936 (95.92%)\r\nnode-v7.4.0-linux-armv6l.tar.gz   14687810 -> 14102389 (96.01%)\r\nnode-v7.4.0-linux-armv7l.tar.gz   14666298 -> 14080710 (96.00%)\r\nnode-v7.4.0-linux-ppc64.tar.gz    15675943 -> 14826696 (94.58%)\r\nnode-v7.4.0-linux-ppc64le.tar.gz  15335840 -> 14710986 (95.92%)\r\nnode-v7.4.0-linux-s390x.tar.gz    15952274 -> 15089968 (94.59%)\r\nnode-v7.4.0-linux-x64.tar.gz      15537444 -> 14937034 (96.13%)\r\nnode-v7.4.0-linux-x86.tar.gz      14999886 -> 14435642 (96.23%)\r\nnode-v7.4.0-sunos-x86.tar.gz      15309353 -> 14712741 (96.10%)\r\nnode-v7.4.0.tar.gz                27904025 -> 26472385 (94.86%)\r\n```\r\n\r\nzopfli --i50 size changes:\r\n```\r\nnode-v7.4.0-headers.tar.gz          483170 ->   457820 (94.75%)\r\nnode-v7.4.0-darwin-x64.tar.gz     13416624 -> 12843218 (95.72%)\r\nnode-v7.4.0-linux-armv7l.tar.gz   14666298 -> 14075986 (95.97%)\r\nnode-v7.4.0-linux-armv6l.tar.gz   14687810 -> 14096693 (95.97%)\r\nnode-v7.4.0-linux-x86.tar.gz      14999886 -> 14431547 (96.21%)\r\nnode-v7.4.0-linux-arm64.tar.gz    14711615 -> 14109192 (95.90%)\r\nnode-v7.4.0-linux-x64.tar.gz      15537444 -> 14933583 (96.11%)\r\nnode-v7.4.0-linux-s390x.tar.gz    15952274 -> 15086037 (94.56%)\r\nnode-v7.4.0-linux-ppc64.tar.gz    15675943 -> 14821324 (94.54%)\r\nnode-v7.4.0-linux-ppc64le.tar.gz  15335840 -> 14706944 (95.89%)\r\nnode-v7.4.0-sunos-x86.tar.gz      15309353 -> 14703688 (96.04%)\r\nnode-v7.4.0.tar.gz                27904025 -> 26461851 (94.83%)\r\n```\r\n\r\nWhat do you guys think?\r\n\r\nThanks for your time :) ",
        "labels": "feature request",
        "id": 43582
    },
    {
        "title": "util.inspect for Uint8Array should print hex",
        "body": "Here's an example:\r\n\r\n```js\r\n> var x = new Buffer(3); x[0] = 0; x[1] = 100; x[2] = 200; x\r\n<Buffer 00 64 c8>\r\n> var y = new Uint8Array(3); y[0] = 0; y[1] = 100; y[2] = 200; y\r\nUint8Array [ 0, 100, 200 ]\r\n```\r\n\r\nI would expect the typed array to print hex just like Buffer.  FWIW technically speaking typed arrays aren't actually arrays, so the argument that it should print like Array doesn't necessarily apply:\r\n\r\n```js\r\n> [x,y].map(Array.isArray)\r\n[ false, false ]\r\n```\r\n\r\nArguably util.inspect should print all integer typed arrays `{Ui,I}nt{8,16,32}Array` with hex entries",
        "labels": "feature request",
        "id": 43583
    },
    {
        "title": "Feature request: add support for the Google Closure Compiler",
        "body": "When used with `-O=ADVANCED`, the [Google Closure Compiler](https://github.com/google/closure-compiler) can apply known optimizations to the code to improve performance. It seems that some performance fixes are as simple as inlining a function (eg. #5127), and the Closure Compiler could automate these with a build step.\r\n\r\nThoughts?",
        "labels": "feature request",
        "id": 43584
    },
    {
        "title": "Feature request: System time change notification",
        "body": "Will it be great to have a feature wherein our node apps can detect change in system time? I recently came across a `time_change_notify` system call, but it doesn't seem to be available in all linux kernels.\r\n\r\n[time_change_notify](https://lwn.net/Articles/403004/)\r\n",
        "labels": "feature request",
        "id": 43585
    },
    {
        "title": "Prevent EMFILE",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\nTry to run (with empty file.txt in working dir):\r\n\r\n``` js\r\nfor(let i = 0; i < 10e3; i++) { require('fs').watch('file.txt') }\r\n```\r\n\r\nProduces instantly: Uncaught Error: watch file.txt EMFILE\r\n\r\nIt make sense to dedupe multiple watchers on same file to prevent 'too many files open'?\r\n\r\n* **Version**: v7.2.1\r\n* **Platform**: macOS\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "feature request",
        "id": 43586
    },
    {
        "title": "`http.ClientRequest.setTimeout` does not timeout if dns.lookup exceeds the timeout",
        "body": "* **Version**:v6.9.2\r\n* **Platform**:Linux nodeServer 2.6.32-573.el6.x86_64 #1 SMP Thu Jul 23 15:44:03 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:http\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis issue arises from a separate issue regarding `dns.lookup`  #8436 potentially blocking the libuv threadpool. Right now if you do a `setTimeout` on a `ClientRequest` it does not include the dns resolution in that period. In example if you have a `req.setTimeout(100)` and dns resolution takes 5000, it will not timeout. This is explained in the docs because `req.setTimeout()` is simply a pass-through to `socket.setTimeout()`. \r\n\r\nThat being said, if a user does `http.request().setTimeout(100)` the user-intent in my opinion is that if that request, in it's entirety, is not complete in 100ms, then it should pass a timeout error, irregardless of what part of the dns/tcp/http phase the failure occurs in.\r\n\r\nReplication gist - https://gist.github.com/owenallenaz/b98ce2b9b491243e76dd517e0fdc46ca",
        "labels": "feature request",
        "id": 43587
    },
    {
        "title": "HTTPS Feature request: Hotswap TLS certificates",
        "body": "I'd like to suggest that there be a way to swap out your TLS certificate (and TLS keys would be nice as well) without bringing your server down. This would enable me to properly do fully-automatic certificate renewal with something like Lets' Encrypt. Existing connections could keep using the old cert, but new connections would use the new one. Should be possible, right?",
        "labels": "feature request",
        "id": 43588
    },
    {
        "title": "build, api, docs: android support",
        "body": "This is meant as tracking issue:\r\n\r\nThere have been a number of efforts made and issues opened (https://github.com/nodejs/build/issues/359, https://github.com/nodejs/node/pull/6876, https://github.com/nodejs/node/issues/6521, https://github.com/nodejs/roadmap/issues/9, https://github.com/nodejs/node/pull/6994) to make Android support possible. Also, some efforts of `electron` code maybe be upstreamed, but likely their maintainers have not enough time to work on it, if it would make sense anyhow.\r\n\r\nI am gonna collect issues and infos centrally here, will also work on it a little and hopefully see some some support from Core once this sees some efforts.\r\n\r\nI am starting this after having conversation on Twitter with @dominictarr @Fishrock123 https://twitter.com/dominictarr/status/810886786830467072?cn=cmVwbHk%3D\r\n\r\n**Possible Steps**\r\n- [ ] validate whether building is possible\r\n- [ ] (officially) document how to build\r\n- [ ] officially support build\r\n- [ ] running `main` as API\r\n- [ ] consider EventEmitter API to exchange strings in both directions\r\n- [ ] continue with iOS (technically)\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**: build, api, docs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "feature request",
        "id": 43589
    },
    {
        "title": "RFE: A way to spawn a foreground process",
        "body": "I have a module called `foreground-child` that will spawn a child process with inherited stdio, and proxy signals to it, and exit appropriately when the child exits.\r\n\r\nHowever, since it's not _actually_ possible to do an `execvp` without a `fork` in Node, it's always going to be a little bit of a kludge.  Because it's not actually running in the same process space, sending a `SIGKILL` will always kill the parent without killing the child.  (Unless the parent is the leader of its process group.)\r\n\r\nIt would be great to be able to do something like this:\r\n\r\n```javascript\r\nvar child = spawn(program, args, {\r\n  env: { env: 'pairs' },\r\n  stdio: [ ... ],\r\n  foreground: true\r\n})\r\n\r\n// similar to doing ^Z,bg in a bash shell\r\nchild.background()\r\n\r\n// move a background process into foreground,\r\n// like doing fg in bash shell\r\nchild.foreground()\r\n\r\n// detach the child process\r\n// like doing ^Z,disown in a bash shell\r\nchild.detach()\r\n```\r\n\r\nShould this be opened as a node-eps issue, or is that just for much higher-level stuff?",
        "labels": "feature request",
        "id": 43590
    },
    {
        "title": "console.log and util.format formatting specifiers",
        "body": "The Chromium console supports format specifiers: https://developers.google.com/web/tools/chrome-devtools/console/console-write#string_substitution_and_formatting\r\n\r\nIn particular, both `%i` and `%d` specify an integral argument.  Node.js does not perform the conversion for `%i`:\r\n\r\n```\r\n/* node.js */\r\n> console.log(\"%i\", 1234)\r\n%i 1234\r\n/* google chrome */\r\n> console.log(\"%i\", 1234)\r\n1234\r\n```\r\n\r\nI think the fix is really simple: the relevant code is at https://github.com/nodejs/node/blob/master/lib/util.js#L86-L117 .  Just adding the `i` case should be enough:\r\n\r\n```\r\n      switch (f.charCodeAt(i + 1)) {\r\n        case 105: // 'i' <-- this is the new line, and it should appear just before the `d` case to make the fall through work\r\n        case 100: // 'd'\r\n```\r\n\r\nIf it makes sense I can send a PR",
        "labels": "feature request",
        "id": 43591
    },
    {
        "title": "Add button at reading docs",
        "body": "I'm a newbie at Nodejs and start reading documents.Something I feel to a problem, again and again, go to the sidebar for next page so why we add two buttons next and previous.",
        "labels": "feature request",
        "id": 43592
    },
    {
        "title": "Proposal: add a console.write method",
        "body": "Often, I find myself needing to ```console.log``` a string without a new line and I use ```process.stdout.write``` for that, but it would be cool if we can just use the global console object for that with all the extra features it supports (like printf, multiple args, etc..), and to make it so that when we have a custom console object, we'll get an ```output-without-a-new-line``` method on that as well.\r\n\r\nMaybe ```console.write()```? I think that matches the feature on other platforms.\r\n\r\n_Happy to implement if you think this is a good idea._",
        "labels": "feature request",
        "id": 43593
    },
    {
        "title": "Fixing --preserve-symlinks. Enhancing node to exploit.",
        "body": "A working prototype that enables using symlinks to machine level module stores, so modules no longer need to be physically copied and duplicated wherever they're used on a given machine. This is accomplished by:\r\n\r\n1. Effectively, setting `__dirname` of the \"main\" entry module to the preserved path passed on the command line, or if it's a file-symlink, using its target path. This is intended to start the program off in the right symbolic path space, to address tooling problems resulting from the current behavior, where `__dirname` is always the [fs.realpath()](https://nodejs.org/dist/latest-v7.x/docs/api/fs.html#fs_fs_realpath_path_options_callback).\r\n 2. For all other `require()d` modules, always using the preserved path of its directory location as its `__dirname`, but always using its `realpath` as the module cache key. This resolves the memory bloat and add-on crashing problems while still letting resolution happen within the symbolic path space.\r\n 3. When building the list of search paths to be used for resolution, by interleaving _**adjacent**_ `somemod+node_modules` directory paths after the _**subordinate**_ `somemod/node_modules`, the directory structure dictating dependency version resolution can still be bound and specific to a given top-level `/node_modules`, but can now be completely decoupled from the physical directories of the modules involved.\r\n",
        "labels": "feature request",
        "id": 43594
    },
    {
        "title": "Support for HTTP/WS inspection",
        "body": "Network domain is what Chrome DevTools (and any other interested frontends) use for inspecting the HTTP and WS traffic in the browser. [This](https://developers.google.com/web/tools/chrome-devtools/network-performance/resource-loading) document provides some insight into Chrome DevTools UI and [here](https://chromedevtools.github.io/debugger-protocol-viewer/tot/Network/) is a description of the protocol for obtaining that data.\r\n\r\nWe propose to introduce a Node specific agent that would expose the same (or subset) of this protocol to enable the UI. It does not seem possible to share the implementation between Blink and Node.js.\r\n\r\nThis agent would also introduce an API for the modules to report the events. E.g. WebSocket modules should be able to notify the agent when WS frames are sent or received.",
        "labels": "feature request",
        "id": 43595
    },
    {
        "title": "Feature proposal: buffer.convert(value[, fromEnc], toEnc)",
        "body": "While investigating the `Buffer` usage, I noticed one thing â€” in many (really, many) cases, `Buffer`s are constructed just for the sake of base64-encoding a string.\r\n\r\nbase64-encodinng is used in many places, like auth headers, data uris, messages, etc.\r\n\r\nWith the new API, that would look like `Buffer.from(from).toString(encoding)`.\r\nWith the old API, that would look like `new Buffer(from).toString(encoding)` (note that this lacks checks).\r\n\r\nSo I propose to add a small utility function, e.g.\r\n\r\n```js\r\nBuffer.convert = function(value, targetEncoding, sourceEncoding) {\r\n  if (!Buffer.isEncoding(targetEncoding)) {\r\n    throw new TypeError('\"targetEncoding\" must be a valid string encoding');\r\n  }\r\n  return Buffer.from(value, sourceEncoding).toString(targetEncoding);\r\n}\r\n```\r\n\r\nNote that the impl does not default to `utf-8` and forces an encoding to be specified, this way it would be more clear what the userspace code does.\r\n\r\nSure, that could be done on userside, but this doesn't deserve a separate package, and re-implementing that in all the packages that do conversion also doesn't look very good to me.\r\n\r\nNote that if we have had such method earlier, the usage of `Buffer` without `new` (and other `Buffer`-related issues) would have been measurably lower.\r\n\r\nIf everyone thinks that this is a good idea, I am willing to file a PR for it (impl/docs/tests).",
        "labels": "feature request",
        "id": 43596
    },
    {
        "title": "Allow `start` option to be string in readline",
        "body": "Finding some string and rewriting the string at given `readline` is hard. The main problem is not getting the correct line number, as this is encoded differently. Having a writestream where you could output at given line would simplify the hazzle and make it easier to reason with. \r\n\r\nThis would be something like: \r\n\r\n```js\r\nrl.on('line', line => {\r\n      \r\n      const options = {\r\n              flags: 'r+',\r\n              defaultEncoding: 'utf8',\r\n              start: line,\r\n              mode: 0o666\r\n            };\r\n          rl.close()\r\n        const a = fs.createWriteStream(path, options);      \r\n        a.write('d')\r\n  });\r\n```\r\n",
        "labels": "feature request",
        "id": 43597
    },
    {
        "title": "Eliminate crashes on Windows by making 'fs' always graceful ",
        "body": "Version: v6.9.1\r\nPlatform: 10.0.14393.0 (Windows 64 bit)\r\nSubsystem: fs\r\n\r\nFrequently Windows users will see:\r\n\r\n    Error: EMFILE: too many open files, open 'C:\\Users\\mike\\Documents\\myapp\\node_modules\\babel-polyfill\\node_modules\\core-js\\package.json'\r\n        at Error (native)\r\n\r\nBecause [EMFILE](https://msdn.microsoft.com/en-us/library/5814770t.aspx?f=255&MSPPError=-2147217396) is a hard limit in Windows.\r\n\r\nThe typical solution is to use graceful-fs:\r\n\r\n    // Monkey-patch real fs module, so all I/O uses graceful FS.\r\n    var fs = require('fs')\r\n    var gracefulFs = require('graceful-fs')\r\n    gracefulFs.gracefulify(fs)\r\n\r\nWhich is fine workaround, but it might be better if fs 'just worked' for Windows users, including waiting for file handles when EMFILE is hit. ",
        "labels": "feature request",
        "id": 43598
    },
    {
        "title": "Feature request: API for debugging node child processes",
        "body": "Kind-of-recent changes in the debugging feature make it easy to debug a node process with whatever debugger speaks the protocol. Most notable, perhaps, is Chrome DevTools.\r\n\r\nFurther, a wrapper tool makes it trivial to start a node process with debugging on and launch the debugger on that. An example that I'm using is https://github.com/jaridmargolin/inspect-process.\r\n\r\nFor me, experience is smooth and I'm happy until I reach *the great wall of the child process*. For example, debugging any test that's run with my favorite test runner, https://github.com/avajs/ava, is kind of impossible, because all of the tests run in child processes and there's no feature to allow running tests in the main process.\r\n\r\n[inspect-process is considering monkey-patching methods of `child_process` for this purpose](https://github.com/jaridmargolin/inspect-process/issues/5).\r\n\r\nWhat I request is an API that will solve this.\r\n\r\nHereâ€™s a thought: An addition to the debugging protocol that:\r\n1. Informs the debugger that a new node child process is going to be launched\r\n    1. Allows the debugger to decide whether that process will be debuggable\r\n        1. If true, the debug port will be provided to the debugger and the debugger could launch a new instance of itself on that. ",
        "labels": "feature request",
        "id": 43599
    },
    {
        "title": "Detailed report for async_wrap in `process.memoryUsage()`",
        "body": "I'm curious if we could report total memory used by different kinds of AsyncWrap instances. This should provide some useful insights when fighting memory leaks.\r\n\r\ncc @trevnorris @nodejs/diagnostics ?",
        "labels": "feature request",
        "id": 43600
    },
    {
        "title": "unhandledRejection Stack Traces are unhelpful",
        "body": "Version: v6.9.1\r\nPlatform: Linux\r\n\r\n\r\n> If possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n\r\nIf I could I would, but the whole problem is that I can't figure out where the problematic code is.\r\n\r\nI have an unhandled promise rejection warning, and for obvious reasons I'd like to get rid of it.  However when I try to figure out where it's coming from (by turning on stack traces for unhandled rejections) I get a trace like:\r\n\r\n    (node:31438) UnhandledPromiseRejectionWarning: Unhandled promise rejection (rejection id: 1): TypeError: Cannot read property 'bottom' of undefined\r\n        at emitPendingUnhandledRejections (internal/process/promises.js:57:27)\r\n        at runMicrotasksCallback (internal/process/next_tick.js:61:9)\r\n        at _combinedTickCallback (internal/process/next_tick.js:67:7)\r\n        at process._tickDomainCallback (internal/process/next_tick.js:122:9)\r\n\r\n... which of course is completely unhelpful since it doesn't reference a single line of my code.  But clearly my code caused the rejection, so is there any way that Node could point me to the source of the problem with the stack trace?",
        "labels": "feature request",
        "id": 43601
    },
    {
        "title": "querystring.stringify appends =& to params without value ",
        "body": "* **Version**: v6.9.1\r\n* **Platform**: Darwin 16.0.0 Darwin Kernel Version 16.0.0: Mon Aug 29 17:56:20 PDT 2016; root:xnu-3789.1.32~3/RELEASE_X86_64 x86_64\r\n\r\nAssuming this should return `'foo&bar&baz'`:\r\n\r\n```javascript\r\nconst qs = require('querystring')\r\n\r\nconsole.log(qs.stringify(qs.parse('foo&bar&baz')))\r\n```\r\nacutal output is `foo=&bar=&baz=`\r\n\r\n`qs.parse('foo&bar&baz')` returns `{ foo: '', bar: '', baz: '' }`, \r\n`qs.stringify({ foo: '', bar: '', baz: '' })` returns `foo=&bar=&baz=`\r\n\r\nWould you consider this behavior a bug?\r\n\r\nrelated docs https://nodejs.org/api/querystring.html#querystring_querystring_stringify_obj_sep_eq_options\r\n\r\nthis seems to be the reason that an equal sign is appended to valueless qs params. See following example:\r\n\r\n```javascript\r\nconst url = require('url')\r\nconst qs = require('querystring')\r\n\r\n\r\nconst href = 'http://example.com/?foo&bar#baz'\r\nconst { protocol, host, pathname, query, hash } = url.parse(href)\r\nconsole.log(url.format({ protocol, host, pathname, query: qs.parse(query), hash }))\r\n\r\n// expected http://example.com/?foo&bar#baz\r\n// returned http://example.com/?foo=&bar=#baz\r\n```\r\n\r\nexpect to log http://example.com/?foo&bar#baz\r\nactual output http://example.com/?foo=&bar=#baz\r\n\r\n\r\nSide note qs.stringify doesn't care if the value is '' or null or undefined\r\n`console.log(qs.stringify({ foo: '', bar: null, baz: undefined }))` returns `foo=&bar=&baz=`\r\n\r\nPersonally  it would be really helpful if querystring.parse would return null instead of '' and if querystring.stringify would omit the `=` sign (`eq` option) when a parameter is null\r\n",
        "labels": "feature request",
        "id": 43602
    },
    {
        "title": "Official Debian/Ubuntu packages",
        "body": "Over at https://github.com/nodejs/docker-node/issues/262 I asked why the Docker image installs Node.js from a tarball rather than Debian packages, and the response was:\r\n> the parent Node.js project does not release DEB packages, it only provides tarballs on release. The popular NodeSource DEB repository is not official, so this image should not depend on it.\r\n\r\nPlease consider adding official Debian/Ubuntu packages to your builds. Ubuntu is probably the most popular Linux distribution so having an 'official' upstream .deb package (even if you just use Debian's or NodeSource's current packaging scripts) would be great.\r\n\r\nDebian does have Node.js packages, but I think they only package 4.x, not 6.x or 7.x.",
        "labels": "feature request",
        "id": 43603
    },
    {
        "title": "Research Discussion: \"Smash-ons\" vs add-ons to simplify access to native libraries",
        "body": "Add-ons are a cool way to let node .js code access native code, be-it OS api's or other native libraries. However, deploying add-ons means that either A) the target machine must have a minimal build tool chain (which may not always be the case on a production server), or that B) the add-on must be prebuilt for all possible platforms and then downloaded (yuck). And building add-ons means being adept in C/C++ and quite familiar with V8's api's and internals.\r\n\r\nI know other VM's offer marshalling services, like .NET's P/Invoke, that lets the VM get access to native stuff without first requiring some code getting compiled to native form.\r\n\r\nIt seems to me most add-ons today are just mostly marshallers. Now I'm sure a full-on native marshaller built as an add-on can provide the best marshalling performance, but I know from my own experience in other runtime worlds there's a bunch of use cases, like just wanting to a call a couple OS methods, that could be handled just fine, performance wise, with a built-in marshalling service.\r\n\r\nI also know that in some cases some types are expensive to marshall, and if it's a 'chatty' api, using a built-in marshalling service wouldn't be ideal, performance wise, but would still be adequate and a reasonable trade off to the aforementioned constraints of building native add-ons.\r\n\r\nHas anyone thought of or looked at the possibility of including a marshalling service directly in node? Besides me?\r\n\r\nI've named a node module that calls into a native marshaller a \"smash-on\" because it's funny sounding, but also kinda hints at, that while easier to make, might be a tiny bit less performant in some cases.\r\n\r\nI have ideas on how to add a marshalling service to node, and would enjoy doing so I think. Just trying to collect the thoughts and opinions of others in the know.",
        "labels": "feature request",
        "id": 43604
    },
    {
        "title": "process.arch not matching with systems arch output for ARM",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.9.1\r\n* **Platform**: Linux jessie 3.4.0-g9e59eab #1 SMP PREEMPT Tue Nov 1 00:35:37 UTC 2016 armv7l GNU/Linux\r\n* **Subsystem**: Debian jessie, armv7l\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen calling `process.arch` it returns `'arm'`, which is not the expected output. I'd expect `process.arch` to return the exact same value as `uname` or `arch` on my linux system returns.\r\n\r\nHowever I found out, that `process.config.variables.arm_version` returns the correct ARM version.\r\nBut anyway: when handling with specific ARM versions, it would be helpful, if `process.arch` returned the correct architecture value, as `arch` does.\r\n\r\nConsole output:\r\n\r\n```bash\r\n$ node\r\n> process.arch\r\n'arm'\r\n> process.config.variables.arm_version\r\n'7'\r\n> .exit\r\n$ uname -m\r\narmv7l\r\n$ arch\r\narmv7l\r\n```\r\n\r\nThis problem occured for me first, when trying to build [Atom](https://github.com/atom/atom) with [electron-packager](https://github.com/electron-userland/electron-packager) for my ARMv7 Debian Jessie system.\r\n\r\nRelated issues:\r\n\r\nhttps://github.com/electron-userland/electron-packager/issues/523\r\nhttps://github.com/atom/atom/issues/5584",
        "labels": "feature request",
        "id": 43605
    },
    {
        "title": "Research Discussion: Faster startup with dynamically generated custom v8 snapshots",
        "body": "If you know about v8 snapshots, and node's 'default' snapshot, you might be able to provide insight into this discussion.\r\n\r\nI seem to be using more and more 'commands' that are node based. When I run them, like npm, it's my understanding node has to reload and recompile the entry.js and all its require()d modules every time.\r\n\r\nI'm wondering if just before node exited, if it could take a v8 snap and save it to a file named to correlate to the full path of entry.js. (obviously optimized to only snap when something changed however, so not _every_ time node exited)\r\n\r\nThen, when node was launched again, it could look for a saved snap based on entry.js and just create a new context from that snap, effectively getting to an executing state much faster.\r\n\r\nAt a high level I'm wondering if my understanding is correct, that a v8 snap is a heap dump that can be reloaded into an isolate, and that when a new context is created in the isolate it starts with modules already jitted, having come from the snap. But wouldn't there be some state that was 'left over' from the original snap that could potentially 'infect' the new context in some non deterministic way? Like say a module set a flag within itself, then the snap was taken, then when reloaded the flag would still be set?\r\n\r\nIs there even a possibility, in some way, to save something from run to run, such that entry.js and all require()'d modules don't have to be parsed/jitted every time?",
        "labels": "feature request",
        "id": 43606
    },
    {
        "title": "Debugger doesn't work for processes which fork other processes",
        "body": "I'm running:\r\n\r\n```\r\n$ node --inspect some-node-script.js\r\n```\r\n\r\nWhere `some-node-script.js` uses plain [`child_process.fork`](https://nodejs.org/api/all.html#child_process_child_process_fork_modulepath_args_options) (run with defaults mostly) calls to initialize few other processes internally. Right after that I receive message _Unable to open devtools socket: address already in use_:\r\n\r\n```\r\n$ node -v\r\nv7.0.0\r\n$ node --inspect some-node-script.js\r\nDebugger listening on port 9229.\r\nWarning: This is an experimental feature and could change at any time.\r\nTo start debugging, open the following URL in Chrome:\r\n    chrome-devtools://devtools/remote/serve_file/@60cd6e859b9f557d2312f5bf532f6aec5f284980/inspector.html?experiments=true&v8only=true&ws=localhost:9229/edbce9e9-0a9d-4c24-8f2b-bcaaeb4a5965\r\nUnable to open devtools socket: address already in use\r\n```\r\nAlso forked process crashes so technically application doesn't run (I've skipped that part of a log to avoid not related noise).\r\n\r\nBehavior is same in both latest Node.js v7 and v6 (Tested on OSX, both El Captain and Sierra, with latest Chrome on board)\r\n\r\nAm I doing something wrong, or there's no support currently for multi-process Node.js apps?\r\n\r\nI've found similar [issue](https://github.com/nodejs/node/issues/8495) which states that this probably should just work, but gives no clue why it actually doesn't.\r\n\r\nI'll be happy to provide simple test case if needed\r\n",
        "labels": "feature request",
        "id": 43607
    },
    {
        "title": "Enable --dev-mod-res switch to better support development-time module storage and installs",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: latest\r\n* **Platform**: all\r\n* **Subsystem**: Modules\r\n\r\n### *** CAVEAT ***\r\nThe author of this issue recognizes it involves a subsystem of node that has been locked, and that there is a somewhat heated history around the subsystem. This may create the potential of any nodejs decision makers in immediately dismissing this issue out-of-hand as a non-starter. It is humbly and respectfully requested the issue be given equal consideration as any other issue, and that it be recognized it's intended to solve a real problem (that's fundamentally a result of the amazing success and wide usage of node).\r\n\r\nIt should also be noted that the implementation this issue recommends in no way breaks the current algorithm implemented by the affected subsystem, that when activated is fully interoperable with the current algorithm while conceptually embracing the simplicity of the current algorithm, that it must be explicitly activated, and that it is meant to address problems primarily encountered during development-time activities.\r\n\r\nThe author has implemented the solution this issue suggests in a fork/branch of node in less than 50 lines of code (<35 in javascript, <10 in C++), and should response to this issue be positive, would immediately create a pull request and fully support and implement any issues with the PR.\r\n\r\n### Problem Statement\r\nIt's unlikely anyone would dispute that npm has contributed greatly to the wide adoption and use of node. It seams nodejs itself has recognized npm as the defacto standard node package manager as it's included with node installers. This is important to this issue, as it really addresses how node and npm work together with respect to how modules are stored and referenced as dependencies of other modules.\r\n\r\nIt is typical that developers within the node ecosystem may eventually (often quickly) come to have dozens of node based projects on their development machines, where each project is stored in its own project folder. As a consequence of how npm currently manages installation of modules, this creates two basic problems.\r\n\r\n#### Problem One - Storage Space\r\nBecause npm creates physical copies of modules when a developer requests it to install all descendant dependencies rooted in a given package.json file, (typically the root package.json of a project for some module, be-it a top-level entry-point type module, or shared-library type module), it's often the result that a version of a referenced dependency module, and all its decedent dependencies, are physically residing on the machine multiple times.\r\n\r\nThis, in combination with typical numbers of node based projects on a developers machine, often results in **_gigabytes_** of storage being consumed (for example, the author has 90+ projects, consuming almost 50 GB in just redundant copies of dependency modules). \r\n\r\nWhile it could be argued this isn't that big of a problem considering the continuing decline of the cost of storage, especially around SSDs, it should not be ignored. Besides the consumed space (which back-of-the-napkin math shows is typically _**20-30 times**_ more than what is actually necessary if module versions were only ever physically installed in one place, then referenced when needed), there's also how it impacts basic activities such as deleting projects, optimal use of the underlying OS's file cache, and others.\r\n\r\n#### Problem Two - Install Duration\r\nA significant amount of time is taken by npm to unpack and copy modules when a developer requests an install of a package.json; 'significant' is in comparison to simply referencing an already installed module (back-of-the-napkin math and initial empirical observation shows referencing an existing physical installation can be _**30+ times**_ faster than always copying).\r\n\r\nInstallation time impacts the initial install of a project/package, but there are other instances when full installs occur beyond the initial one. These typically occur for two primary reasons (although there may be others):\r\n\r\n1. During development of a package, one or more of its dependencies needs to be upgraded. Npm does not have the best history of pulling this off with out problems, and at times what's required is the deletion of the entire node_modules folder for the project, and a re-install of the project's module dependency tree.\r\n2. At times a developer must implement a bug or enhancement on an early version of a project, and the early version has a different module@version dependency tree. Like reason 1) above, it's often best to delete the node_modules folder and re-install.\r\n\r\n#### Problem Impact\r\nIf the above issues occurred once or twice every few months, they probably aren't 'problems'. However, relative to a developer's involvement in the node ecosystem, the above issues can occur several times a month or more, and it ends up becoming more a problem akin to 'death by a thousand paper-cuts'.\r\n\r\n#### Root Problem\r\nIt should be obvious to the knowledgeable reader that the obvious solution is to simply symlink modules. The [documentation](https://nodejs.org/dist/latest-v7.x/docs/api/modules.html#modules_addenda_package_manager_tips) for the Modules subsystem implies that in principal, package managers should be able to implement this.\r\n\r\nHowever, in practice with npm, this cannot be achieved, as npm allows the specified version of a module's dependencies to not be unary, but effectively a list of possible versions, where the 'highest' version, as determined by semver semantics, is chosen at install time. This means that two or more projects that depend on the same module@version, may end up installing slightly differing versions of the dependencies the common module@version itself depends on. Because a module's dependencies can be placed in the `node_modules' subdirectory of the module, this means that the module@version can't be physically installed once and still allow npm to offer reasonable guarantees as to the versions of the entire module dependency tree of a given project when symlink'ing all modules; the only way to guarantee is to physically copy the modules. (Note: npm offers bundling and shrink-wrapping to precisely control dependencies at the version level, but this is a tangent to this issue).\r\n\r\nThis is because the only way node currently allows a module's dependencies to be precise is by installing those dependencies in a sub-directory named 'node_modules' underneath the module's directory.\r\n\r\n### Solution\r\nImplement a --dev-mod-res switch (and NODE_DEV_MOD_RES environment variable) in node, which stands for 'development-time-module-resolution', which activates augmenting node's behavior in two ways:\r\n\r\n1. Search for a module's dependencies not just in a subdir of the module named 'node_modules', but then in an adjacent directory to the module named '<module>.node_modules'. For example, in node's example under [Loading from node_modules folder](https://nodejs.org/dist/latest-v7.x/docs/api/modules.html#modules_loading_from_node_modules_folders), the list and order of the directory searches becomes:\r\n- /home/ry/projects/node_modules/bar.js\r\n- /home/ry/projects.node_modules/bar.js\r\n- /home/ry/node_modules/bar.js\r\n- /home/ry.node_modules/bar.js\r\n- /home/node_modules/bar.js\r\n- /home.node_modules/bar.js\r\n- /node_modules/bar.js\r\n2) Preserve symlinks for all module paths, including the entry module (which, in combination with the NODE_DEV_MOD_RES, allows npm to implement it's lifecycle steps that depend on installed modules). \r\n\r\nWith this augmentation, all modules can by physically installed once on a machine, while they and their dependencies can be symlinked, and a module@version that happens to be symlinked in multiple projects can still have its dependencies effectively determined (symlinked) specific to the project it is being used in.\r\n\r\nNote: node's Modules documentation warns that preserving symlinks can cause unexpected behavior, specifically siting that node will fail if two different symlinks refer to the same native node module. This can be easily addressed by using the module's specified path to determine if a module _**should**_ be loaded, but always using the realpath to determine if the module _**has already been**_ loaded. The current fork/branch does not implement this, but the author would do so should this issue garner positive support.\r\n\r\nThe author of this issue, and a node fork/branch of its implementation, has also implemented a preliminary fork/barnch to npm to work in combination with the --dev-mod-res switch. The change is the addition of a new command to npm called 'mount', which is conceptually identical to 'install' except it symlinks modules, and symlinks dependencies into <module>.node_modules folders. The current implementation of 'mount' in npm makes slight adjustments to its 'install' command, and is relatively low impact to npm from an amount-of-code perspective (about a 100 lines sofar). However, it has currently only been implemented enough to prove the concept.\r\n\r\nDepending on the response to this issue, the author would fully implement 'mount' in npm.\r\n\r\nThank you for your valuable time in reading, contemplating, and responding to this issue.",
        "labels": "feature request",
        "id": 43608
    },
    {
        "title": "Second child process doesn't receive data when using the stdout of first child process as stdin of second",
        "body": "* **Version**: v0.12.9 - v7.0.0\r\n* **Platform**: Linux ${edited hostname} 4.4.0-45-generic #66~14.04.1-Ubuntu SMP Wed Oct 19 15:05:38 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nAlso posted here: http://stackoverflow.com/questions/40306385/missing-lines-when-using-the-stdout-of-a-child-process-as-stdin-of-another\r\n\r\nWhen using the stdout of one child process as stdin for another, it seems that sometimes data is not passed to the next child:\r\n```js\r\nvar spawn = require('child_process').spawn;\r\n\r\nvar pipeId = 0;\r\nvar pipeSlots = 6;\r\n\r\nvar launchProcess = function(cmd, args, stdin, stdout){\r\n  return spawn(cmd, args, {\r\n    stdio: [stdin, stdout, 'ignore']\r\n  });\r\n};\r\n\r\nvar launch = function(){\r\n  var task0 = launchProcess('echo', ['how\\nare\\nyou\\ndear\\nstranger'], 'ignore', 'pipe');\r\n  var task1 = launchProcess('tee', ['/tmp/body-pipeline-' + pipeId], task0.stdout, 'ignore');\r\n\r\n  task0.on('error', function(err){\r\n    console.log('Error while processing task0:' + err.stack);\r\n  });\r\n  task1.on('error', function(err){\r\n    console.log('Error while processing task1:' + err.stack);\r\n  });\r\n\r\n  pipeId++;\r\n};\r\n\r\n// Simulating message queue\r\nsetInterval(function(){\r\n  // Simulating how many messages we get from the messaging queue\r\n  var mqMessageCount = Math.floor(Math.random() * (pipeSlots + 1));\r\n\r\n  for(var i = 0; i < mqMessageCount; i++){\r\n    launch();\r\n  }\r\n}, 250); // For this test we assume that pipes finish under 250ms\r\n```\r\n\r\nSome files are empty:\r\n``` bash\r\nls -lhS /tmp/body-pipeline-*\r\n```\r\n\r\nFYI: `task0.stdout.pipe(task1.stdin)` solves the issue but the script uses 50% CPU (compared to 0% when passing stdout of task0 as stdin of task1) for the equivalent of `yes | tee /tmp//tmp/body-pipeline-x`",
        "labels": "feature request",
        "id": 43609
    },
    {
        "title": "old flags for previous node versions should result in no-op, not error, for current version (?)",
        "body": "This regards Node versions 6.7 and 4.5, but could possibly involve more versions.\r\n\r\nIn v4.5, we could allow for deconstructive assignment with the `--harmony_destructuring` flag.\r\n\r\nHowever, in v6.7 if we use that flag, it says:\r\n\r\n`node: bad option: --harmony_destructuring`\r\n\r\nand a quick check => node --v8-options\r\n\r\nshows us that the new relevant flag in version 6.x is called:\r\n\r\n`--harmony_destructuring_assignment`\r\n\r\nSo what that means is that I need some conditionals in my library such that if a user is using a certain version of Node I use the first flag, and if the user is using another version of Node, I use the second flag.\r\n\r\nIs there a way to mitigate this problem?\r\n\r\nI suppose that one solution could be that using `--harmony_destructuring` with Node version 6 should result in a no-op (just a warning or something) since it was a flag that existed in old Node versions.",
        "labels": "feature request",
        "id": 43610
    },
    {
        "title": "Feature request: Cancel all timeouts",
        "body": "Something like [this hack](http://stackoverflow.com/a/8345814/435124) works pretty well for browser envs, but since Timers don't expose IDs in Node, I haven't found a way to cancel all timers in Node.\r\n\r\nMy use case is I'm running a 3rd party script, and for some reason even when that script returned, my process kept running. Using [why-is-node-running](https://github.com/mafintosh/why-is-node-running) I saw that the 3rd party script set a few timeouts, which prevented my script from exiting.\r\n\r\nI'd rather not use process.exit since my script is consumed by other scripts, which manage their own process. It seems like there are a few workarounds:\r\n\r\n1. Wrap setTimeout to register timeouts in a global registry before I invoke the 3rd party script, then call `clearTimeout` on each timeout in that registry\r\n2. Run the 3rd party script in its own child process, which my process can then kill\r\n\r\nNeither of these are pretty. It would be fantastic to have a better way to do this.\r\n\r\nAlso see https://github.com/nodejs/help/issues/174",
        "labels": "feature request",
        "id": 43611
    },
    {
        "title": "child_process: add public API to unref ipc channel",
        "body": "- **Version**: all\n- **Platform**: n/a\n- **Subsystem**: child_process\n\nIt would be nice to have a public API to `unref()` a child process's ipc channel. My use case for this is that I spawn a child process, send some messages back and forth via ipc, then at some point I want to detach the child process. `child.unref()` is not enough because that only unrefs the C++ ProcessWrap handle. Currently I have to resort to also doing `child._channel.unref()`. I am not sure if this should be done automatically inside `child.unref()` or if there should be a separate function or similar.\n",
        "labels": "feature request",
        "id": 43612
    },
    {
        "title": "support for polling linux character device for incoming data",
        "body": "<!--\nThank you for reporting an issue.\n\nThis issue tracker is for bugs and issues found within Node.js core.\nIf you require more general support please file an issue on our help\nrepo. https://github.com/nodejs/help\n\n\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**:\n  v6.9.1\n- **Platform**: \n  Linux T40001 3.13.0-63-generic #103-Ubuntu SMP Fri Aug 14 21:42:59 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**:\n  fs, net\n\n<!-- Enter your issue details below this comment. -->\n\nHi, I'm trying to determine whether it's possible to poll a linux character device using node.js, and where exactly the breakdown occurs between libuv and node. I'm putting together a small experimental qemu agent which currently requires communicating over a virtio-serial provided character device, and as far as I have tried it doesn't seem possible presently to monitor that fd through any means provided to me in node.\n\nAs a first step I just wanted to check if it might be a limitation of epoll, so I took a modified version of [this code](http://man7.org/tlpi/code/online/dist/altio/epoll_input.c.html), compiled it and listened to the device for incoming data, and was able to verify that epoll in fact notified on change.\n\nI've tried the following methods:\n- `fs.watch` - this doesn't throw any errors, but simply never emits a `change` event on incoming data.\n- `net.createConnection` - this throws a `ECONNREFUSED` as expected, since this is not a socket\n- using `tty.ReadStream` - also fails because of course this isn't a TTY\n\nMy only remaining option has been to simply poll every `Nms` using `fs.read` or `fs.readFile` within a class duck typed as a `net.Socket`, which is less than ideal.  I thought I might just get away with the `fs.watch` approach, but from perusing the source code it looks like that is bound to a `uv_fs_event_start` which is probably falling back to inotify in this case. \n\nSo three questions occur to me at this point:\n- am I completely botching this and missing some obvious API\n- would there be interest in supporting such a feature (I'm more than willing to implement this)\n  - if there is, where would such functionality live? `fs`, `net`, `os`, something else?\n\nThanks!\n",
        "labels": "feature request",
        "id": 43613
    },
    {
        "title": "Add version info: CLDR, Unicode, Timezone",
        "body": "It could be handy to have some additional ICU version information available, besides just the `icu` version itself. since the ICU features have more and more applicability to various parts of Node.\n\nThese could go into `process.versions`, or not.\nNote that for the CLDR and TimeZone version, we actually need to read data files to get the answer. So, I'd hesitate to just stuff constants into `process.versions`. Is there a way to lazily-initialize a constant?\n# Unicode Data Version\n\n```\n unicode: '9.0'\n```\n\nThis gives information about which [Unicode Version](http://www.unicode.org/versions/enumeratedversions.html) is included. This would affect which characters are interpreted by regexes, etc.\n\nImplementation: `u_getUnicodeVersion()` (doesn't actually read any data files to get the result)\n# CLDR Version\n\n```\n cldr: \"30.0.2\"\n```\n\nThis is the version of the [CLDR](http://cldr.unicode.org/) data files used for ICU's implementation.\n# Time Zone Data Version\n\n```\n tz: \"2016g\"\n```\n\nThis is the version of the [iana tz](http://www.iana.org/time-zones) database.\n\ncc: @nodejs/intl \n",
        "labels": "feature request",
        "id": 43614
    },
    {
        "title": "Useless Stack Traces",
        "body": "- **Version**:\n  v5.12.0\n- **Platform**:\n  Ubuntu 16.04 64-bit\n- **Subsystem**:\n  HapiJS v15\n\nExpected:  When an exception is thrown the JS engine **always** provides a stack trace that indicates the full call stack that led to the exception.\nActual:  Frequently employ workarounds to discover the line(s) of code that actually caused the error.\n\nDescription:\nNodeJS generates stack traces that do not provide usable information about the call stack that threw the error.  It's trivial to create a situation where a NodeJS stack trace either:\n1. Points at a line of code which is a require (or include?) file that caused the error, forcing the engineer to find another way to locate the bug, i.e. keep track of all code changes, use debugger breakpoints, and/or use console logging.\n2.  Provides information about the current call stack that threw an error, but is apparently unable to trace the back to the call stack that called it.  In other words, the stack trace does not indicate the actual lines of code that led to the error, making it practically useless.\n\nUnfortunately I don't have the actual test fixture written up to isolate this issue, but I encounter it often.  One way to reproduce this problem is to require a file that generates an error in an async call -- this should generate a stacktrace that points to the line in the file that invoked require(); yet mentions nothing about the actual execution stack that threw the error.  I'm not sure (yet) how to generate a stack trace that doesn't point at the original execution stack, but the Hoek library is good at it.  If a randomly selected codebase is non-trivial and generates async errors then it's practically guaranteed that it generates useless stack traces.\n",
        "labels": "feature request",
        "id": 43615
    },
    {
        "title": "[errors] Add built in ErrnoError",
        "body": "- **Version**: 6.8.1\n- **Platform**: Linux nohomey 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**:  util, spawn, dns .... (all modules that throw the so known System Error)\n\n[System Errors](https://github.com/nodejs/node/blob/master/doc/api/errors.md#system-errors) are documented in the API Documentation and they are thrown all over the code, such examples are: [util](https://github.com/nodejs/node/blob/95ba482a8ee663a1333ccc52b372e81d39df7166/lib/util.js#L1021), [spawn](https://github.com/nodejs/node/blob/db1087c9757c31a82c50a1eba368d8cba95b57d0/deps/npm/lib/utils/spawn.js#L33) and [dns](https://github.com/nodejs/node/blob/7bc6aeac86e6ce09efba4b04190b7792fc72fded/lib/dns.js#L17). So I would like to propose to add built in `ErrnoError class` that can be used both by addon developers, node and even some user JavaScript code and to deprecate the current `System Errors` which are just augmented `Errors`.  `ErrnoError` constructor may accept two arguments `errno` of type `int` and `syscall` of type `string` and it should generate proper error message like `system call X failed with Y errno code, {human readable meaning}`.  `ErrnoError` may also be separated in it's own header/source where errno codes are also mapped and as well available to addon writes then exposed to JavaScript, which is currently done in [node_constants](https://github.com/nodejs/node/blob/db1087c9757c31a82c50a1eba368d8cba95b57d0/src/node_constants.cc#L35).\nAnd finally why I want such change to be made: to remove redundancy, as a node addon developer some times I need to define a macro that throws System Errors and there is no built in one so I have to either re-use the implementation from my previous project or created new one that slightly differs from the previous one - there is no standart way how Error instances are augmented, this redundancy can even be found in node's code itself: again in [util](https://github.com/nodejs/node/blob/95ba482a8ee663a1333ccc52b372e81d39df7166/lib/util.js#L1021), [spawn](https://github.com/nodejs/node/blob/db1087c9757c31a82c50a1eba368d8cba95b57d0/deps/npm/lib/utils/spawn.js#L33) and [dns](https://github.com/nodejs/node/blob/7bc6aeac86e6ce09efba4b04190b7792fc72fded/lib/dns.js#L17) but is in JavaScript code not C++ ...\n",
        "labels": "feature request",
        "id": 43616
    },
    {
        "title": "Buffer API Suggestion: WriteBit(value, offset, offsetWithinByte), ReadBit(offset, offsetWithinByte)",
        "body": "`\nWriteBit(value, offset, offsetWithinByte)\n\nReadBit(offset, offsetWithinByte)\n`\n",
        "labels": "feature request",
        "id": 43617
    },
    {
        "title": "feature request - callbacks in exit handlers - to block even if async code is used",
        "body": "I'm on the latest version of Node (6.7)\n\nI have been using Node for awhile and one thing that seems to be a missing feature is shutdown hooks that are \"blocking\", even if they feature async code. To \"block\" in this case would require callbacks. A simple use-case is a child_process that needs to use `process.send()` (with a request/reply) pattern with a parent process. process.send() is async, and so we can't be guaranteed the parent process will receive the message before the parent may exit.\n\nfor example what we have now is this ('beforeExit' might be deprecated or gone by now):\n\n```\nprocess.on('beforeExit', function () {\n\n});\n\nprocess.on('exit', function (code, signal) {\n\n});\n```\n\nwhat I am looking for is this type of functionality:\n\n```\nprocess.on('beforeExit', function (cb) {\n         setTimeout(cb, 3000);\n});\n\nprocess.on('exit', function (err, code, signal) {\n        // if 'beforeExit' handler is in place, then this will only be called when the callback fires\n        // in the beforeExit handler\n});\n\n```\n\ndoes this functionality exist? The temporary solution is to simply put blocking code in these handlers, but that's not always idea. Hope this makes sense :) I believe it's possible to do this just wondering if it is a sensible request.\n\nThe use case is I have programs which need to run shutdown hooks even if there is a fatal exception in the code, these shutdown hooks have asynchronous code by nature (process.send, for one). So it's a feature that I really need.\n",
        "labels": "feature request",
        "id": 43618
    },
    {
        "title": "Official socket transfer support",
        "body": "I'm interested in an official way of transferring a socket from Node.js (net.Socket / tls.TLSSocket) representation to the native representation (file descriptor / SOCKET descriptor + SSL pointer).\n\nThis can be used to transfer a connection from JS land into an addon, and have the addon manage the connection _way_ more efficient.\n",
        "labels": "feature request",
        "id": 43619
    },
    {
        "title": "Is it possible to notify developer if server.maxConnections reached?",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: all\n- **Platform**: all\n- **Subsystem**: net\n\n<!-- Enter your issue details below this comment. -->\n\nIf `maxConnections` reached, the system simply drops new connection:\nhttps://github.com/nodejs/node/blob/c9b59e8387b08dab20936f32d2b290804718f688/lib/net.js#L1432-L1435\nand developer have hard time trying to debug \"Error: read ECONNRESET\" error message. All cases presented [here](http://stackoverflow.com/questions/17245881/node-js-econnreset) are not helped me. Is it possible to add `self.emit('error')` or maybe other error `self.emit('maxConnectionsReached')` into this if, to help developer debug this error?\n",
        "labels": "feature request",
        "id": 43620
    },
    {
        "title": "dns: don't skip getaddrino/getnameinfo when c-ares init fails",
        "body": "#8710 makes `process.binding('cares_wrap')` throw a JS exception instead of aborting when `ares_library_init()` or `ares_init_options()` fail.\n\nMaybe we can do better.  We can still bring up the bindings for getaddrinfo and getnameinfo because those don't depend on c-ares (although if c-ares fails, there is a goodly chance the others won't work either.)\n\nPolicy question: do we think it's better to quit or keep on trucking in a franken-init state?\n",
        "labels": "feature request",
        "id": 43621
    },
    {
        "title": "Solaris SPARC support",
        "body": "- **Version**: v4.6.0\n- **Platform**: SunOS testsystem 5.11 11.3 sun4v sparc sun4v\n- **Subsystem**:\n\nThe issue obviously not a bug, but rather request for new functionality.  So, is it possible to add support for SPARC Solaris platform? It exists for x86 Solaris, but not for SPARC. \n",
        "labels": "feature request",
        "id": 43622
    },
    {
        "title": "readline: emitKeypressEvents does not properly recognize Alt+Arrow",
        "body": "- **Version**: v6.7.0\n- **Platform**: Linux\n- **Subsystem**: Ubuntu\n\nWhen pressing the Alt+Arrow combo keys on a terminal, the keypress event emitted is the same as if only Arrow was pressed (the `name` property is correct, but the `alt` one is `false` instead of `true`).\n\nThe key sequence used for Alt+Arrow is the same as the Arrow one, except that it is prefixed by an additional escape string (`\\x1b\\x1b[C` for Alt+Left, for example, instead of `\\x1b[C`).\n",
        "labels": "feature request",
        "id": 43623
    },
    {
        "title": "Ship manpages for all core modules",
        "body": "It would be super neat if all the Node core modules shipped manpages. E.g. the HTTP module would have a corresponding `node-http(3)` manpage. (Is section 3 the most appropriate? It's for library _calls_, so I'm not sure. Let's bikeshed.) In particular this is useful for working offline - I suspect a lot of distributions of Node don't ship the HTML docs. I know my Homebrew install sure didn't install them.\n\nI'm totally willing to put together a PR adding a build process for these, but I wanted to double-check that such a PR would be accepted.\n",
        "labels": "feature request",
        "id": 43624
    },
    {
        "title": "zlib.inflateRawSync how do I get the number of bytes read?",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.7.0 (applies to previous versions as well)\n- **Platform**:Darwin [hostname] 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 23 18:25:34 PDT 2016; root:xnu-3248.60.10~1/RELEASE_X86_64 x86_64\n- **Subsystem**: zlib\n\n<!-- Enter your issue details below this comment. -->\n\n`zlib.inflateRawSync` returns the decompressed data.  AFAICT it does not indicate how many bytes were read from the input buffer.  Is there a way to find that?\n\nUse case: some ZIP writers use the \"data descriptor\" feature of the pkzip file format.   The CRC-32 checksum of the uncompressed data and the lengths actually appear directly after the deflated data, so you need to know the number of bytes that the deflator read in order to jump ahead to those fields.  FWIW zip libraries leveraging zlib, like [yauzl](https://github.com/thejoshwolfe/yauzl), do not bother with the checksum.\n",
        "labels": "feature request",
        "id": 43625
    },
    {
        "title": "Feature request: REPL show variable contents upon variable creation",
        "body": "It would be really helpful if the node REPL would show the variable contents after creating and assigning to it. Actually this is what it does if you assign to an already created variable.\r\n\r\n```js\r\nlet myVar = 5\r\n// should output 5\r\nmyVar = 10\r\n// already does output 10\r\n```\r\n",
        "labels": "feature request",
        "id": 43626
    },
    {
        "title": "Request for tool to generate constant declarations in C++ and JavaScript from specifications",
        "body": "Can we align constant values between .h and .js module files please. This needs a basic node.js program to parse a spec and generate C++ header files and JavaScript modules.\n",
        "labels": "feature request",
        "id": 43627
    },
    {
        "title": "Request for dnssec DNSSEC interface API",
        "body": "Can someone examine whether it is a good idea whether to implement a set of DNSSEC functions either as part of the dns API or whether to establish a new dnssec API please.\n",
        "labels": "feature request",
        "id": 43628
    },
    {
        "title": "lift uv constants into separate constants implemetation files for uv process and lib/dns.js",
        "body": "can we lift the uv constants into separate constants specification files for the C++ uv process code and lib/dns.js JavaScript API please.\n\nhttps://github.com/nodejs/node/blob/master/lib/dns.js\n\nneed uv.js file creating please to parallel https://github.com/nodejs/node/blob/master/deps/uv/include/uv.h\n",
        "labels": "feature request",
        "id": 43629
    },
    {
        "title": "Provide a way to call the native realpath function",
        "body": "- **Version**: 6.5.0\n- **Platform**: Mac OS X\n- **Subsystem**: fs\n\nWith https://github.com/nodejs/node/pull/7899 landing, node.js is back to its old JS implementation of `fs.realpath`. I agree this move was necessary given the bugs. However, one feature of the native `realpath` function was that it would return the actual casing of a path as it is on disk, which is very useful to know.\n\nGiven a path of `/foo/bar/some.txt` and running `fs.realpathSync(/foo/BAR/some.txt)` would return `/foo/bar/some.txt`. \n\nThe only workaround to get the real casing of a path with node.js currently is to run `fs.readdir` on each segment of a path and building the path based on the results, because this function returns the actual casing as it exists on disk. Of course, such a method is not very optimal because it needs to do more work the longer the path is.\n\nWould it be possible to get API in `fs` to resolve the path with the native `realpath`? \n",
        "labels": "feature request",
        "id": 43630
    },
    {
        "title": "Feature request: benchmark runner progress indicator",
        "body": "- **Version**: n/a\n- **Platform**: n/a\n- **Subsystem**: benchmark\n\nSince the benchmark runner defaults to 30 runs and some benchmarks can take awhile to run, it would be nice to have a progress indicator on stderr when the CSV data is being written to non-TTY (e.g. piped to R) on stdout (similar to how cURL displays download progress).\n\nAlso, changing the benchmark running logic to instead alternate the benchmark parameter combinations between the new and old executables will allow for faster displaying of results. This may require changes to the R script if it buffers its results until data for all benchmark parameter combinations are received.\n",
        "labels": "feature request",
        "id": 43631
    },
    {
        "title": "chmodSync is not recursive",
        "body": "fs.chmodSync() is not recursive please add recursive feature to it.\n\nThere should be some flag option available to make it recursive.\n\nwith fs.chmodSync()  \"**chmod 777 -R some-folder/**\" cannot be achieved\n- **Version**: v4.5.0\n- **Platform**: linux/windows\n- **Subsystem**: NA\n\n<!-- Enter your issue details below this comment. -->\n",
        "labels": "feature request",
        "id": 43632
    },
    {
        "title": "How does require.resolve work?",
        "body": "I'd like to submit a PR that resolves the root project's package name so that you can use absolute require paths. However, I'm finding it very hard to figured out how this bit of code works:\n\nhttps://github.com/nodejs/node/blob/7b73f559029a10474b74a83bfb1117ab512785d4/lib/module.js\n\nSeems like it should be a one-liner somewhere. I just need to add the base project as one of the \"paths\" to search. Any ideas where that might be?\n\nI'm thinking its in here.\n\nhttps://github.com/nodejs/node/blob/7b73f559029a10474b74a83bfb1117ab512785d4/lib/module.js#L304\n\nSomething like `paths.push(path.dirname(parent.id))`.\n",
        "labels": "feature request",
        "id": 43633
    },
    {
        "title": "Expose V8's JavaScript parser API as an part of standard library?",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: v6.5.0\nPlatform: Darwin Jianrus-MacBook.local 15.6.0 Darwin Kernel Version 15.6.0: Mon Aug 29 20:21:34 PDT 2016; root:xnu-3248.60.11~1/RELEASE_X86_64 x86_64\nSubsystem: V8\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**:\n- **Platform**:\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nHello, everyone. Is it an good idea to expose  V8's JavaScript parser API as an part of standard library?\n\nWhy:\n- Parser API is the key component of many advanced libraries: test, code rewrite, analyze...\n- Many modern language like rust, go, python, erlang bring the parser as an part of their standard libarary\n- Existing solution like esprima is ok, but if Node.js exposes parser API from V8 will be much more better\n\nIf it is needed, I can try to do some contributions.\n\nThanks.\n",
        "labels": "feature request",
        "id": 43634
    },
    {
        "title": "Configuration option to permanently turn on --preserve-symlinks",
        "body": "Developing packages with peer dependencies is really really hard, I lose so many hours a day trying to setup my dev environment in just the right way so it works. \n\nI've only once managed to get the `NODE_PATH=./node_modules` workaround working, I'm not sure why it doesn't work for me, perhaps it's to do with how I configure webpack.\n\nThat flag would save me when developing locally except it doesn't seem to work with webpack and browserify, is there anyway we can permanently configure it to on so we don't have to pass it as an argument for every node process? That way webpack and browserify would work with it.\n",
        "labels": "feature request",
        "id": 43635
    },
    {
        "title": "help() or similar for the REPL",
        "body": "Hi, carrying this over from https://github.com/nodejs/node-v0.x-archive/issues/3916 (at least if Iâ€™m understanding it rightâ€¦?).\n\nIt would be pretty cool to have something like Pythonâ€™s `help()` for the REPL, where things like `help(list)` just show you the documentation for the `list` object/type/whatever.\n\nWe could probably include a gzipped copy of Nodeâ€™s own API docs in some format in the executable, that should not be more than a few hundred kB (213 kB for the current gzipped markdown, 544 kB for the current HTML docs).\n\nIâ€™m imagine weâ€™d want to add something like `util.help(obj)` which returns the docs for `obj`, or, if appropriate, `obj.constructor` (or a `Promise` for the docs? that might be a tad more generic).\n\nSome random thoughts:\n- I am not sure in what format the docs would best be displayed. Maybe using the markdown as it is would be a good start, since thatâ€™s essentially made for human readability â€“ some things like our links would be weird, though.\n- I would be in favour of exposing a `help` in the REPL, or maybe even supporting a tiny syntax extension like `? net.Server`.\n- I am not sure if the doctool has a role to play here. We would probably require some way of wiring up the doc sections with the corresponding objects, and they are clearly not in 1:1 relation.\n- We could, like Python does, display the docs for the methods of a given type, too. I.e., `help(net.Server)` would return the docs for everything on `net.Server.prototype`.\n- Again, like Python does (they _did_ a great job thereâ€¦), we could use `$PAGER` (aka `less` in 99Â % of cases) to display the help for things, at least when it would otherwise exceed one screen page.\n- We could make `util.help` extensible by the user like we do with `util.inspect`, by providing something like a `[util.customHelp]` Symbol property that they can attach. That propertyâ€™s value could be a string or a function returning a string with the docs for it.\n- Maybe â€“ this may be a lot harder but it could also be really _really_ awesome â€“ MDN docs for the types native to JS. That would probably require putting them in a separate package of some sort but it would be cool if the REPL had some way of knowing where to look for that.\n\n/cc @princejwesley @nodejs/documentation \n",
        "labels": "feature request",
        "id": 43636
    },
    {
        "title": "Hotpatching modules leaks memory",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 6.5.0\n- **Platform**: FreeBSD 11.0 BETA1 x64\n- **Subsystem**: module, require\n\n<!-- Enter your issue details below this comment. -->\n\nI have a function that uncaches a module and its children:\n\n``` javascript\nfunction uncacheTree(root) {\n    let uncache = [require.resolve(root)];\n    do {\n        let newuncache = [];\n        for (let i = 0; i < uncache.length; ++i) {\n            if (require.cache[uncache[i]]) {\n                newuncache.push.apply(newuncache,\n                    require.cache[uncache[i]].children\n                        .filter(cachedModule => !cachedModule.id.endsWith('.node'))\n                        .map(cachedModule => cachedModule.id)\n                );\n                delete require.cache[uncache[i]];\n            }\n        }\n        uncache = newuncache;\n    } while (uncache.length > 0);\n};\n```\n\nAfter running it, I require the module that it uncaches again. When I found my server running out of memory in a few days consistently, I found that after taking a coredump, all of the exported objects from the modules I hotpatched stayed on the heap according to  mdb_v8. What's causing this to leak like that? Is there any way it can be fixed? I'm not sure if it's something wrong with node itself or just something hiding out in the code holding references to all the zombie exports.\n",
        "labels": "feature request",
        "id": 43637
    },
    {
        "title": "crypto.createHKDF()",
        "body": "@indutny would there be any support for adding `createHKDF()` to the `crypto` module?\n\nThis is useful when doing common crypto work and I have an implementation with test vectors that I can provide.\n",
        "labels": "feature request",
        "id": 43638
    },
    {
        "title": "crypto.scrypt()",
        "body": "@indutny would there be any support for adding `scryptSync()` and `scrypt()` to the `crypto` module?\n\nThere is already support for `PBKDF2` but `scrypt` can offer an order of magnitude or more strength for the same derivation time.\n",
        "labels": "feature request",
        "id": 43639
    },
    {
        "title": "Suggestion: Add lineNumber",
        "body": "Right now, I can't find out how to read a line number of a module, using `readLine`. I thought this was already implemented, but it is not :/ Is there anyway to get this to work / find out a line number of a module?\n",
        "labels": "feature request",
        "id": 43640
    },
    {
        "title": "yield/await support in repl/cli",
        "body": "In the version of node 6.5.0 that I am running, the repl does support quite a few things already - which is awesome. One thing I came to miss when trying things out though is that the [`yield` (as often used before `await`](https://github.com/tj/co#co-v4) and/or the [`await`](https://www.npmjs.com/package/asyncawait) keyword. If `yield` would be available like with `co` or `await` would be available like in the concept then async code would become easy to test in the REPL.\n",
        "labels": "feature request",
        "id": 43641
    },
    {
        "title": "http: support environment-defined proxy",
        "body": "To enable HTTP connectivity behind corporate firewalls, a number of tools and programming languages support HTTP/HTTPS proxies defined through environment variables like\n\n```\nHTTP_PROXY=http://proxy.com\nHTTPS_PROXY=https://proxy.com\nNO_PROXY=\"*.home.com,another.com\"\n```\n\nNote that there seems to be no consensus on the case of these variables and all-lowercase variable names are also very common. My limited research suggest that at least the following languages automatically obtain and use a proxy from the environment:\n- Python\n- Go\n- Ruby\n- R\n\nThe `request` module also [supports](https://github.com/request/request#controlling-proxy-behaviour-using-environment-variables) these variables, but I feel they show be respected by core `http` and `https` for best compatibilty.\n",
        "labels": "feature request",
        "id": 43642
    },
    {
        "title": "Not helpful error message after upgrading Node",
        "body": "I just upgraded Node from 5.11.1 to 6.5.0 (on latest MacOSX) and then started my node project again.\n\nMy project uses nodegit (with c-bindings). When starting the project I get this error message:\n\n```\nError: Module version mismatch. Expected 48, got 47.\n    at Error (native)\n    at Object.Module._extensions..node (module.js:583:18)\n    at Module.load (module.js:473:32)\n    at tryModuleLoad (module.js:432:12)\n    at Function.Module._load (module.js:424:3)\n    at Module.require (module.js:483:17)\n    at require (internal/module.js:20:19)\n    at Object.<anonymous> (/project-x/node_modules/nodegit/dist/nodegit.js:11:12)\n    at Module._compile (module.js:556:32)\n    at Object.Module._extensions..js (module.js:565:10)\n> [1]    79902 segmentation fault  node\n```\n\nObviously this error is caused by upgrading node and can be fixed quite easily by reinstalling the npm packages (post build scripts etc.). But for an inexperienced user this looks like something horrible just happened, particularly the \"segmentation fault\"-bit at the end.\n\nIt would be awesome if the error could be a little bit friendlier (and helpful)\n",
        "labels": "feature request",
        "id": 43643
    },
    {
        "title": "Remove the requirement of function `_read` when creating a readable stream",
        "body": "<!--\r\nThank you for reporting an issue.\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n- **Version**: Stable v6.5.0\r\n- **Platform**: Debian 8\r\n- **Subsystem**: stream.Readable\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nRequiring `_read` on initializing a new readable stream is quite redudant in some cases. For example:\r\n\r\n```js\r\nvar readableStream = new stream.Readable();\r\nreadableStream._read = function () {}; // what is the point of this?\r\nsource.ondatacoming = function(chunk){\r\n  readableStream.push(chunk);\r\n  if(bytesReceived === source.size){\r\n    readableStream.push(null);\r\n  }\r\n};\r\nreadableStream.pipe(writableStream);\r\n```\r\n\r\n_The use case of the above example is to take advantage of the data flow control of method `pipe`._\r\n",
        "labels": "feature request",
        "id": 43644
    },
    {
        "title": "Should Node.js standard library throw custom Error subclasses?",
        "body": "As we know, ECMAScript define only few `Error` subclasses. W3C specifications adds to this list `DOMException` and `URIError`. Right now, Node.js implements seven `Errors`:\n- Error\n- EvalError\n- RangeError\n- ReferenceError\n- SyntaxError\n- TypeError\n- URIError\n\nOn other side we have Java standard library that defines 74 classes extending [java.lang.Exception](https://docs.oracle.com/javase/7/docs/api/java/lang/Exception.html) and numerous other extending these subclasses. Most of them doesn't make sense in Node.js context, as our standard library is much smaller, but I'm convinced that 7 errors defined in ECMAScript are too general to provide meaningful information on types of error that can happen.\n\nTherefore, I propose:\n- make all exceptions coming from syscalls inherit from new class `SystemError` (`class SystemError extends Error`)\n  - create classes like `FileSystemError` and `NetworkError` to inherit from `SystemError`\n- add class `DeprecationError` inheriting from `Errror` for deprecated features\n- discourage creating direct instances of `Error` in standard library\n\nDisadvantages:\n- code directly checking `err.constructor === TypeError` can break\n\nAdvantages:\n- better typing for TypeScript\n  - many IDEs can use TypeScript definition files and use them as ad-hoc documentation, even if you write in JavaScript\n- Bluebird [`.catch(klass, handler)`](http://bluebirdjs.com/docs/api/catch.html) easier to use\n\nLoose ideas:\n- export classes like `DatabaseError` to be subclassed by database modules\n\nI'm working on pull request to replace `new Error` with `new TypeError` or `new RangeError` wherever it makes sense.\n",
        "labels": "feature request",
        "id": 43645
    },
    {
        "title": "sockets: OutOfBand bytes/packets are not supported",
        "body": "Node v6.3.0\nLinux localhost 3.14.0 #1 SMP PREEMPT Thu Aug 25 01:02:56 PDT 2016 x86_64 Intel(R) Core(TM) i7-5500U CPU @ 2.40GHz GenuineIntel GNU/Linux\nnet\n\nWhen a TCP client, that connects to a NodeJS server, sends an `OutOfBand`/`Urgent` byte, the packet is completely dropped.\n\nFull disclosure, I'm migrating an Android (client) /.NET (server) application that uses `OutOfBand`/`Urgent` bytes and have hit a wall. If the client send a packet with `OutOfBand` flag set, there's no way for me to receive it on the server (nodeJS). \n\nI can understand if the default implementation is to drop them, but there should be an option to allow these packets to come in.\n",
        "labels": "feature request",
        "id": 43646
    },
    {
        "title": "Provide access to file system times with nanoseconds resolution",
        "body": "Node.js should provide nanosecond time values in the fs.stat() response structure similar to how process.hrtime() does it.\n\nIf there is a module or trick to provide ns I would be happy to use that\n\nGenerally on Linux, human readable stat provides the nanoseconds, and epoch time provides the UTC second-level value. The combination is complete. Since Node.js uses ECMAScript Date objects, there is only millisecond resolution.\n- ext4 and Android has nanosecond time resolution since long time\n- Most Linux utilities still drop sub-seconds and Linux cannot display birth date easily\n- Some Android won't give you UTC allowing you to create lots of bugs calculating it\n\nHere's Linux human readable\n\n``` bash\nstat 0 --format %z\n2016-06-14 00:50:44.920739523 -0700\n```\n\n> uname --all && node --version\n> Linux c89 4.4.0-34-generic #53-Ubuntu SMP Wed Jul 27 16:06:39 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n> v6.4.0\n\nI have some utilities moving large data around that uses recursive md5 and metadata before-after to verify integrity\n",
        "labels": "feature request",
        "id": 43647
    },
    {
        "title": "repl: Proposal for better repl",
        "body": "This is my idea/wish to address Node.js repl related issues.\n- Automatic multiline command mode has serious issues. \n  - Recoverable error guess is based on error message emitted by v8(vm specific) engine\n    (we may have to fix the code if vm emits different error string in next release)\n  - False positives. We have to `.break`/`^C` the expression to continue.\n  - We can't reliably deduce the end of expression even if we build an incremental JS parser.\n  \n  ``` js\n  let echo = e => e;\n  let x;\n  x = echo(2); // 2\n  x = echo // both echo and echo\\n(2) are completely valid expression \n  (2) // 2\n  ```\n- No welcome message (it helps to see version number)\n#### Proposal\n- Welcome message with version and help guide\n- Differentiate `execute` & `continue` actions\n  - `^M` or enter key to execute the command (current behavior)\n  - `^J` to continue (Hand over the problem to user, let user decides it) building multiline expression.\n###### Welcome message template\n\n``` js\n> node\nWelcome to Node.js <<version>> (<<vm name>> VM, <<vm version>>)\nType ^M or enter to execute, ^J to continue, ^C to exit\nOr try .help for help, more at https://nodejs.org/dist/v<<version>>/docs/api/repl.html\n>\n```\n\ne.g.\n\n``` js\n> node\nWelcome to Node.js 6.4.0 (v8 VM, 5.0.71.60)\nType ^M or enter to execute, ^J to continue, ^C to exit\nOr try .help for help, more at https://nodejs.org/dist/v6.4.0/docs/api/repl.html\n>\n```\n\n@nodejs/collaborators, I am happy to implement this if there is no objection\n\n_Note_ : Current system executes code when `^M`, `^J` or `enter` pressed. `^I` or `tab` for code completion\n",
        "labels": "feature request",
        "id": 43648
    },
    {
        "title": "Feature request: Horizontal peer-to-peer event-loop messaging w/ process.send (workers)",
        "body": "<!--\nFor all versions of node >6.0.0\n<!-- Enter your issue details below this comment. -->\n\nTo make Node.js concurrency model as efficient as possible, we need to be able to use **process.send** to send messages to an independent (not master) Node.js event loop. \n\nSimilar to the Open Web Standard of postMessage, a frame can postMessage to any frame, given proper reference. We need the approach for our \"frames\", which in Node.js, are forked event loops. As a developer, I should be able to have forked Child and Worker event loops **send(message)** to one another, without having middle-manning between whoever created the child. \n\nFor example, if Master event loop has a forked process, then one of the Master's worker event-loops, should be able to directly communicate to the Forked process, without having to first **process.send(message)** to Master.\n\nThe benefit of this is that it allows Node.js logic to more easily process things in parallel, in a truly async model. We all know that nextTick and timers simply push an item down in the queue to be later processed on the same event-loop, which obviously is not truly \"async\" in the generic definition...its more appropriately doThisLater logic, than processThisInTheBackground logic and report to me when done. \n\nThe final benefit I can think of is that it allows to share memory spaces. Java is able to share memory spaces efficiently across thousands of threads, which one reason why Java is highly adopted and efficient at high-concurrency. Meanwhile, we, in the Node.js community, cannot access shared spaces thanks to Fork... and we could if our event loops could communicate horizontally, instead of today, where send(message) only works on the Master that created them.\n\nWe should change the API from this:\nprocess.send(message[, sendHandle[, options]][, callback])\nto:\nprocess.send(message[, fileDescriptor[, sendHandle][, options]][, callback])\n\nwhere fileDescriptor referrers to a Node.js event loop's system identifier.\n\nI know the IPC approach that we have may make this feature request interesting to implement, but I imagine there is way. Improving Node.js's ability to process things in the background would greatly benefit high-concurrency services that process thousands of requests a second, such as my own, and many other high-concurrency services in our community.\n",
        "labels": "feature request",
        "id": 43649
    },
    {
        "title": "repl: editor mode text not saved in `.save` command",
        "body": "- **Version**: `6.4.0`\n- **Platform**: `Linux arch 4.7.0-1-ARCH #1 SMP PREEMPT Mon Aug 8 22:05:58 CEST 2016 x86_64 GNU/Linux`\n- **Subsystem**: `repl`\n\n<!-- Enter your issue details below this comment. -->\n\nThe new editor mode is wonderful, but I'm unable to to save what was done in the editor mode using the `.save` command.\n\n```\n> const foo = 1\nundefined\n> const bar = 'two'\nundefined\n> .editor\n// Entering editor mode (^D to finish, ^C to cancel)\nfunction fooey () {\n  return 'fooey'\n}\nundefined\n> fooey()\n'fooey'\n> .save zzz.js\nSession saved to:zzz.js\n```\n\n`zzz.js`:\n\n``` javascript\nconst foo = 1\nconst bar = 'two'\n\nfooey()\n```\n",
        "labels": "feature request",
        "id": 43650
    },
    {
        "title": "Is there a place to download node.js shared library(libnode.so.{version}) for each platform?",
        "body": "Hi everyone, \n\nI'm using node.js as a shared library, so when i compiling my project i should give the `libnode.so` file. By now i get the `libnode.so` file through compiling the source code with `--shared` manually, and i wonder is there a place i could download the `libnode.so.{version}` file for each platform like downloading the node.js header files through `https://nodejs.org/dist/latest/node-{version}-headers.tar.gz`? Thanks. \n",
        "labels": "feature request",
        "id": 43651
    },
    {
        "title": "I'm only getting one authorizationError in an HTTPS request when there are at least 2 ",
        "body": "- **Version**: 6.2.2\n- **Platform**: OS X El Capitan\n\nI'm running tests on a website that has two issues with it's SSL certificate. 1) The cert is expired, and 2) The domain name is not listed under it's valid alt names. Whenever I do an HTTPS GET request in Node to that website, I'm only getting one authorization error that says the cert is expired. Is there a way to get a list of all the authorization errors? \n",
        "labels": "feature request",
        "id": 43652
    },
    {
        "title": "debugger: bind to random port with --inspect=0",
        "body": "As #5025, but for `--inspect`. https://github.com/nodejs/node/pull/5025#issuecomment-179951848\n",
        "labels": "feature request",
        "id": 43653
    },
    {
        "title": "TCP Fast Open",
        "body": "- Version: 6.3.1\n- Platform: Windows 64 Bit\n- Subsystem: net\n\nHello,\n\nIs it possible to add TCP Fast Open to the TCP Net Module?\n",
        "labels": "feature request",
        "id": 43654
    },
    {
        "title": "VM: Add source mapping support",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: 6.3.1\nPlatform: Darwin Kernel Version 14.5.0\nSubsystem: vm\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.3.1\n- **Platform**: Darwin Kernel Version 14.5.0\n- **Subsystem**: vm\n\n<!-- Enter your issue details below this comment. -->\n\nCurrently the VM module supports an options object, such that you can run\n\n``` js\nconst vm = require('vm');\n\nvm.runInNewContext(code, context, options);\n```\n\nThe `options` object currently supports the `filename`, `lineOffset`, and `columnOffset` properties which can all be used to provide better error messages. But wouldn't it be best to let the use provide a function that could map an error location in running code to a location in a source file? It seems `lineOffset`, and `columnOffset` are very limited in what they can do relative a mapping function.\n\nSuppose `options` could have a property `resolveLocation`, such that `options.resolveLocation` was a function that took an object `{row, column}` as a parameter, and returned a `{row, column, filename}` object representing the location in the original source. This would make `filename`, `lineOffset`, and `columnOffset` all obsolete.\n\nSuch a feature would make transpiled code running in a VM context far easier to debug.\n\nAny thoughts?\n",
        "labels": "feature request",
        "id": 43655
    },
    {
        "title": "Observe data emitted through stdout and stderr",
        "body": "Currently without [hacking of `process.stdout.write`](https://github.com/sindresorhus/hook-std/blob/master/index.js#L10-L20) there's no way to observe what data do process logs to console, and even through hacking [100% coverage seems not possible](https://github.com/sindresorhus/hook-std/issues/9)\n\nIt would be great if such functionality is easily accessible in Node.js without a need for tweaking node internals\n",
        "labels": "feature request",
        "id": 43656
    },
    {
        "title": "Feature request: Generated Documentation for Reference - PDF and CHM formats",
        "body": "Hi,\n\nI like Node. Is it possible for NodeJS projects to provide users with additional download documentation in PDF or CHM format for carrying around in USB. \n\nIt would be convenient to study the docs whilst the internet are not always available somewhere else especially for new learners. They can mark up, comments within the PDF documentation.\n\nKind regards\n\nTN\n",
        "labels": "feature request",
        "id": 43657
    },
    {
        "title": "Feature request: Inform the \"line\" event on a Readline interface of the type of end-of-line input",
        "body": "I was using the `Readline` module to rewrite a file line by line. While doing that I noticed that I had no idea which end-of-line (`\\r`,  `\\n`, `\\r\\n`) caused the line break so I could not reassemble the file exactly as it was.\n\nOf course I could detect the first EOL and then just use that for everything but in most cases I want to leave the line untouched anyway. Wouldn't it be a good idea to pass the found EOL string as a second argument to the callback of a `line` event emitted by a `readline.Interface`?\n",
        "labels": "feature request",
        "id": 43658
    },
    {
        "title": "Feature request: fs.ReadStream#bytesRead",
        "body": "I would like to propose the addition of `fs.ReadStream.prototype.bytesRead` which should represent the number of bytes read from the file.\n\nIt seems like it's \"missing\" since `fs.WriteStream` has `bytesWritten` and `net.Socket` has both `bytesRead` and `bytesWritten`.\n\nImplementation should be very trivial, I would be happy to submit a pull request.\n",
        "labels": "feature request",
        "id": 43659
    },
    {
        "title": "Feature. Set DNS server port for DNS client",
        "body": "the Docs on the DNS client say that the dns.setServers(servers) method will strip out any custom ports provided. \"If a port specified on the address it will be removed.\" \n\nI'm curious if there is a specific reason for not wanting to support it, or is it planned to be supported?\n",
        "labels": "feature request",
        "id": 43660
    },
    {
        "title": "Several feature requests",
        "body": "Here are three minor enhancements that offer amazing abilities to the Node community.\n- `fs.rmdir` forced recursion option.\n  - In POSIX this is accomplished with `rm -rf dir/path`\n  - In Windows since Vista this is accomplished by piping the command through powershell as `powershell.exe -nologo -noprofile -command \"rm dir\\path -r -force\"`\n- `util.hash`.  It should be noted that native hash support in all the operating systems is a bit dated as none of them support SHA2 or SHA3.  You guys could probably do better writing your own hashing utility from scratch\n  - In Darwin (probably BSD as well) this is accomplished with `shasum -a 512 source` where source is a string, file, directory, or blob\n  - In Linux `sha512sum source` where source is a string, file, directory, or blob.  Each algorithm has its own command, so for example sha128sum\n  - In Windows `certUtil -hashfile source SHA512` where source is a file, string, directory, or blob\n- Compression.  I have looked at various compression approaches recently and most of them suck.  Again, I think you guys could probably do much better writing a wrapper around a good algorithm.\n  - Some security vulnerabilities were discovered with libArchive recently, which is the utility behind tar on BSD and Darwin.\n  - When I recently compared compression sizes I used my prettydiff application as a test platform.  7-Zip compressed to 31mb, Windows native ZIP compressed to 33mb, and ZIP on OSX compressed to 38mb, and tar.bz2 on OSX compressed to 37mb.  ZIP is the clear winner both on terms of compression strength and native availability cross-os\n  - In Windows to zip `powershell.exe -nologo -noprofile -command \"& { Add-Type -A 'System.IO.Compression.FileSystem'; [IO.Compression.ZipFile]::CreateFromDirectory('source', 'output'); }\"`\n  - In Windows to unzip `powershell.exe -nologo -noprofile -command \"& { Add-Type -A 'System.IO.Compression.FileSystem'; [IO.Compression.ZipFile]::ExtractToDirectory('output', 'source'); }\"`\n  - In POSIX to zip `zip -r9yq output input`\n  - In POSIX to unzip `unzip -aq input -d output`\n",
        "labels": "feature request",
        "id": 43661
    },
    {
        "title": "Constructor for wrapping literals in vm module context cannot be altered.",
        "body": "- **Version**: 4.4.7\n- **Platform**: Windows 8, 64bit\n- **Subsystem**: vm\n\nHello,\nI tried to play around with the vm core module. I found that there are some issues with the context switch:\nThis returns false:\n`\nvm.runInNewContext(\"a instanceof Array\", {a: []});\n`\n\nThe solution is to pass the Array object in the sandbox, so this returns true:\n`\nvm.runInContext(\"a instanceof Array\", vm.createContext({a:[], Array:Array}))\n`\n\nStill, this returns false:\n`\nvm.runInNewContext(\"var b = [1,2,3]; b instanceof Array\", {Array:Array});\n`\nClearly V8 uses other constructor to wrap the literals.\n\nAnother interesting example of this problem:\n\nvm.runInNewContext('\\\n    String.prototype.contains = function(str) { return this.indexOf(str) >=  0; };\\\n    var literalString = \"Abc\";\\\n    var objectString = new String(\"Abc\");\\\n    literalString.contains // Returns undefined\\\n    objectString.contains // Returns [Funtion]\\\n  ', { String: String });\n\nI am aware that whenever we want to use a property of a literal in javascript, V8 wraps the literal with its base class, which is required behaviour by ECMAScript. More information in this article:\nhttps://javascriptweblog.wordpress.com/2010/09/27/the-secret-life-of-javascript-primitives/\n\nSo should there be a way to provide what is the default constructor for literals too?\n",
        "labels": "feature request",
        "id": 43662
    },
    {
        "title": "TCP_DEFER_ACCEPT option for http server ?",
        "body": "[varnish](https://github.com/varnishcache/varnish-cache/blob/1c662d992d6cc4ed84726d39f6a40cea0fdc924a/lib/libvarnish/vtcp.c#L172), [nginx](http://nginx.org/en/docs/http/ngx_http_core_module.html) and [apache2](https://httpd.apache.org/docs/2.2/mod/core.html) all give the ability to enable that option - which is something that might be interesting when Node.js is facing internet without proxy.\n\nPlease tag this as a simple idea.\n",
        "labels": "feature request",
        "id": 43663
    },
    {
        "title": "Add fsevents to NodeJS",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 6.x\n- **Platform**: Linux\n- **Subsystem**: Ubuntu\n\n<!-- Enter your issue details below this comment. -->\n## Suggestion\n\nAdd a normalized native interface for [fsevents](https://github.com/strongloop/fsevents) and  [chokidar](https://github.com/paulmillr/chokidar)  so that optional dependencies can be avoided on development oriented packages and to improve development package workflow.\n## Details\n\nNon non-IOS platforms, many development packages installed through `npm` result in the warning:\n\n```\nnpm WARN optional Skipping failed optional dependency /chokidar/fsevents:\nnpm WARN notsup Not compatible with your operating system or architecture: fsevents@1.0.14\n\n```\n\nThe instructions for contributing to the popular Angular 2 project states:\n\n> To add a new dependency do the following:\n> 1. if you are on linux or windows, then use MacOS or ask someone with MacOS to perform the installation. This is due to an optional fsevents dependency that is really required on MacOS to get good performance from file watching.\n> \n> â€” [npm-shrinkwrap.readme.md](https://github.com/angular/angular/blob/d272f96e23f379e1b565435b3af010138e710ab9/npm-shrinkwrap.readme.md)\n\nIt seems to be a rather dubious workflow that's made necessary by the lack of an efficient native file watch capability in node. If NodeJs supplied a normalized fast directory watcher directly, there would be no need for these gymnastics.\n## Prior Art\n- [fsevents](https://github.com/strongloop/fsevents): Native access to OS X FSEvents in Node.js\n- [chokidar](https://github.com/paulmillr/chokidar): A neat wrapper around node.js fs.watch / fs.watchFile / fsevents.\n",
        "labels": "feature request",
        "id": 43664
    },
    {
        "title": "Support for null terminated strings with Buffer toString?",
        "body": "When writing strings to a buffer, it's common to end them with a `0` byte, so that when reading it later, you know when the string ends.\n\nI was looking at the [`toString` method](https://nodejs.org/api/buffer.html#buffer_buf_tostring_encoding_start_end) and noticed there's no overload for null terminated strings. I'd like to use `toString` because the string encoding type can be variable. I'd like to avoid slice/intermediate buffer/indexOf because the performance hit defeats the purpose.\n\nTo encode an arbitrary string in to an arbitrary position in a buffer, it looks like you have to prefix it with either a 4 byte length amount or use a variable length encoding. Both involve iterating over the string to find the byte count: an O(n) operation.\n\n[Smart-Buffer](https://www.npmjs.com/package/smart-buffer) has support for reading and writing null terminated strings, but is an inefficient wrapper that iterates the string as well.\n",
        "labels": "feature request",
        "id": 43665
    },
    {
        "title": "Rely on toJSON in querystring.stringify",
        "body": "It'll be nice if `querystring.stringify` would try to resolve object values with `toJSON`\n(of course only primitive values coming from toJSON would have to be accepted as final)\n\n```\n$ node -v\nv4.4.5\n\n$ node\n> querystring.stringify({ date: new Date })\n'date='\n> JSON.stringify({ date: new Date })\n'{\"date\":\"2016-07-21T14:08:04.397Z\"}'\n```\n",
        "labels": "feature request",
        "id": 43666
    },
    {
        "title": "Contextify should use ES6 Proxy to wrap the global object.",
        "body": "@ofrobots @fhinkel @verwaest @isaacs \n\nI'm recently browsing through node_contextify.cc and found this comment describing ContextifyContext::CopyProperties:\n\n``` c\n  // XXX(isaacs): This function only exists because of a shortcoming of\n  // the V8 SetNamedPropertyHandler function.\n  //\n  // It does not provide a way to intercept Object.defineProperty(..)\n  // calls.  As a result, these properties are not copied onto the\n  // contextified sandbox when a new global property is added via either\n  // a function declaration or a Object.defineProperty(global, ...) call.\n  //\n  // Note that any function declarations or Object.defineProperty()\n  // globals that are created asynchronously (in a setTimeout, callback,\n  // etc.) will happen AFTER the call to copy properties, and thus not be\n  // caught.\n  //\n  // The way to properly fix this is to add some sort of a\n  // Object::SetNamedDefinePropertyHandler() function that takes a callback,\n  // which receives the property name and property descriptor as arguments.\n  //\n  // Luckily, such situations are rare, and asynchronously-added globals\n  // weren't supported by Node's VM module until 0.12 anyway.  But, this\n  // should be fixed properly in V8, and this copy function should be\n  // removed once there is a better way.\n```\n\nSo let me see if I understood this correctly:\n- In ContextifyContext::CreateV8Context we set up a hidden prototype with named property interceptors to intercept accesses to the global object (to sync with the contextified object).\n- Named property interceptors do not trigger for Object.defineProperty.\n\nSeems like wrapping the global object in an ES6 Proxy would solve the issue. I wonder whether doing that is straight-forward. We could then also get rid of the named property interceptors and the hidden prototype.\n",
        "labels": "feature request",
        "id": 43667
    },
    {
        "title": "api to get arm architecture of the binary as in the download page...",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**:  v6.3.0\n- **Platform**: linux-arm\\* \n- **Subsystem**: API?\n\n<!-- Enter your issue details below this comment. -->\n\nI couldn't find any api to get the architecture of the binary itself, \n\n`process.arch` just gives `arm` \n`uname -a` would give for the host.. not the binary\n`node --v8-options` gives `target arm v7..` , and a lot of output..\n\nI want it for the the binary as it is on the download page..  `arm64` `armv6l` `armv7l`\n\nI dumped and greped the `process` object and found..  `process.config.variables.arm_version` among others... \nChecking the api doc for `process.config` says it is not read-only and gives some warning about some packages changing it.. \n\nCould and api be added for this, or should we just parse this form `process.config.variables.arm_*` or `--v8-options` or any other suggestions.. \n",
        "labels": "feature request",
        "id": 43668
    },
    {
        "title": "Inconsistent clearTimeout implementation (timer argument is not converted to primitive)",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.3.0\n- **Platform**: OS X 10.11.5\n- **Subsystem**: Darwin image.local 15.5.0 Darwin Kernel Version 15.5.0: Tue Apr 19 18:36:36 PDT 2016; root:xnu-3248.50.21~8/RELEASE_X86_64 x86_64\n\n<!-- Enter your issue details below this comment. -->\n\n`clearTimeout` and `clearInterval` in Node.js [don't seem to trigger any kind of conversion mechanism for the `timer` attribute](https://github.com/nodejs/node/blob/5aac4c42da104c30d8f701f1042d61c2f06b7e6c/lib/timers.js#L364), if the timer passed in is an `Object` (instead of a `Number`). E.g. `valueOf`, `toString` or `Symbol.toPrimitive`.\n\nFirefox, Chrome and Safari all seem to do that (I couldn't test Edge unfortunately).\n\nA simple example for cancelling a timer would be:\n\n```\nvar timer = setTimeout(function cb() {\n    console.log('timed out');\n}, 1000);\nvar o = {\n    valueOf() { return timer; }\n};\nclearTimeout(o);\n```\n\n**Observed Behavior:** Timer does not get cancelled, `cb` gets triggered\n**Desired Behavior:** Timer gets cancelled, `cb` does not get triggered\n\nThe same goes for `toString` and `Symbol.toPrimitive`.\n\nI'm not sure where (or whether) there is an official specification of `clearTimeout` and `clearInterval`, the closest I have found is:\n\nhttps://html.spec.whatwg.org/multipage/webappapis.html#dom-cleartimeout\n\nThe type conversion in the browsers seem to happen with [`ToNumber`](https://tc39.github.io/ecma262/#sec-tonumber).\n\nIt would be nice if the node.js implementation behaved the same as the browser implementations.\n",
        "labels": "feature request",
        "id": 43669
    },
    {
        "title": "Change os.cpus() output to report whether a core is physical or logical",
        "body": "- **Version**:v7.0.0-pre (custom VS2015 build from commit a58b48b)\n- **Platform**:Windows 7 x64\n- **Subsystem**:?\n\nos.cpus() returns an array of the logical CPUs. It would be nice to have a function returning the actual number of physical cores.\n\nImplementation on Win32 (>= Windows XP) could use [GetLogicalProcessorInformation](https://msdn.microsoft.com/en-us/library/ms683194%28VS.85%29.aspx). That name is pretty misleading as it can also return the number of _physical_ cores as seen in the provided example code.\n",
        "labels": "feature request",
        "id": 43670
    },
    {
        "title": "[repl] do not show all matches on first tab",
        "body": "- **Version**: All\n- **Platform**: All\n- **Subsystem**: REPL (shipped)\n\nIt's an annoyance that the REPL prints out all possibilities the first time hitting the tab. It would be much better if it simply autocompleted as much as possible and waited for a subsequent tab before printing out all matches. Here's an example usages:\n\n```\n> Bu<TAB>.al<TAB>U<TAB>S<TAB>\n```\n\nTo produce `Buffer.allocUnsafeSlow`, but in doing so I get a screen filled with matches that I know I don't want.\n\nThrowing this out there in case anyone wants to take care of it before I do (which I don't plan to in the near future).\n",
        "labels": "feature request",
        "id": 43671
    },
    {
        "title": "[stream] Make _readableState and _writableState part of the public API",
        "body": "Following up from https://github.com/nodejs/node/pull/7077#issuecomment-231497169, and other discussion.\n\nOne of the problem that has lead to **breaking** userland stream modules is related to the fact that they rely on functionality available in `_readableState` and `_writableState` that is not documented, **and that is the only possible way** for solving some issues, like knowing if a stream is in `objectMode: true`, clearing up the leftover write callbacks, and many other functionalities.\n\nI propose we document, standardize and test a piece of `_readableState`Â  and `_writableState`.\n\nI think we should have been able to spot https://github.com/mafintosh/duplexify/issues/6 before releasing, sigh. @calvinmetcalf @TheAlphaNerd are we setting `readable-stream` in passthrough mode for citgm run?\n\nI am opening this discussion here rather than in readable-stream because I would like all possible feedback. As @mikeal said, \"So, what are we gonna do about streams?\" https://github.com/nodejs/summit/issues/16#issuecomment-227552773.\n\n@nodejs/streams we might want probably put this at in our next meeting.\n\ncc @ronkorving @mafintosh \n",
        "labels": "feature request",
        "id": 43672
    },
    {
        "title": "Get native handle from net.Socket",
        "body": "It doesn't seem possible to get the native handle (file descriptor / SOCKET / HANDLE) from a net.Socket via addons. The Node SDK does not include the tcp_wrap.h or any of the derived from headers to allow one to get the uv handle and from there use uv_fileno.\n\nProjects like node-ancillary (https://github.com/VanCoding/node-ancillary) actually end up with a private copy of the internal Node.js headers to allow fetching the uv_tcp_t pointer. This is of course not the right way to solve the problem as this solution will break on internal implementation changes.\n\nGetting the native handle of a socket can be used to transfer the connection from Node.js into the addon or into any other server and this is what I currently do on Unix systems. I cannot do this on Windows since I cannot get the SOCKET handle.\n",
        "labels": "feature request",
        "id": 43673
    },
    {
        "title": "v8_inspector: improvements for developers",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 6.3.0\n\n<!-- Enter your issue details below this comment. -->\n1. Ability to reload node.js process from devtools (as is **Ctrl+R** in Google Chrome)\n2. Pass console logging to devtools console too. Not only to stdout.\n3. Appear compiled js without root closure with global variables (now can be simulated with similar hook https://github.com/Jam3/devtool/blob/master/lib/require-hook.js#L21)\n",
        "labels": "feature request",
        "id": 43674
    },
    {
        "title": "v8_inspector: Support the V8 debugger from within VM contexts",
        "body": "This is a feature request to support Node 6.3.0's V8 inspector capability (`node --inspect`) from within the vm module's contexts. For example:\n\n``` js\nvm.runInNewContext(code, sandbox, {\n  inspect: 9999, // same as --inspect=9999\n});\n```\n\nIf it's not possible to make individual contexts inspectable, it'd also meet our needs to make other contexts inspectable if the parent Node process is running with `--inspect`. Currently code that runs in other contexts isn't debuggable (ex: `debugger` statements are ignored).\n",
        "labels": "feature request",
        "id": 43675
    },
    {
        "title": "Feature request: passing headers to response.writeContinue()",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 6.3.0\n- **Platform**: any\n- **Subsystem**: http\n\nIt would be very useful if someone (I'm willing to create a pull request for it) would add the ability to set the headers of the Continue intermediate headers. One reason for it, is to tell the reverse proxy/webserver which URLs do to a HTTP/2 push for:\n\nhttp://blog.kazuhooku.com/2016/06/h2o-http2-server-201-210-beta1-released.html\n",
        "labels": "feature request",
        "id": 43676
    },
    {
        "title": "Feature request: have http.request() accept socket timeout option which is passed to http.Agent and applied BEFORE connecting",
        "body": "- **Version**: v6.2.2\n- **Platform**: Windows 7 64-bit\n- **Subsystem**:\n\nFor plain socket ('net' module) it is possible to set the socket connect timeout by using socket#setTimeout() before calling socket#connect(). On windows, this has effect as long as you keep the timeout below 20 seconds (which is the Windows default TCP connect timeout). E.g. setting 1 second and then connecting to a non-existing IP address will give a timeout after 1 second, but setting 25 seconds will still timeout after 20 seconds.\n\nFor the http module, there is no such option (http.request() does not take a timeout). There are no workarounds: using ClientRequest#setTimeout() or catching the socket in the on('socket') event and using socket#setTimeout both result in the timeout being set after the connect() call, so it does not function as a connect timeout. \n\nSo the request is to adjust http.request() function so that it takes a timeout option which is set on the socket before it connects. This will in turn require passing on the timeout to the http.Agent#createConnection() when requesting a connection.\n",
        "labels": "feature request",
        "id": 43677
    },
    {
        "title": "Changing default options for util.inspect",
        "body": "`console.log` and relatives use `util.inspect` to stringify complex structures, which creates somewhat of a dilemma when you have an application making use of bare `console` functions but you'd like unrestricted nesting (`depth: null`) or more than 100 visible array elements ( `maxArrayLength: null`) by default.\n\nTo change the default, I could see `util.inspect.setup(opts)` being made available. Anyone with me?\n",
        "labels": "feature request",
        "id": 43678
    },
    {
        "title": "wish: add a 'part' event to http.incomingMessage for managing multipart/x-mixed-replace as HTTP client",
        "body": "IP Cameras implementing MJPEG interfaces usually stream the video over HTTP multipart sending a JPEG frame encapsulated in each part. Currently you cannot use `http.incomingMessage` `data` event to manage these connections, because you miss where the part boundaries are. Ideally a `part` event should be added to `http.incomingMessage`, firing when a complete part is available instead of a data chunk. \n\nI think there are probably other use cases for this.\n",
        "labels": "feature request",
        "id": 43679
    },
    {
        "title": "Behavior of path.basename is different from basename command.",
        "body": "- **Version**: v6.2.2\n- **Platform**: darwin\n\nThough this may be a small thing, the following behavior of `path.basename` is different from `basename` command.\n\n``` js\npath.basename('/')\n// => ''\npath.basename('/', '/')\n// => ''\n```\n\nIn contrast, `basename` command behaves as follows:\n\n```\n$ basename /\n/\n$ basename / /\n/\n```\n",
        "labels": "feature request",
        "id": 43680
    },
    {
        "title": "request - fs support for OS X package option on directories",
        "body": "- **Version**:\n- **Platform**:\n- **Subsystem**: fs\n\n<!-- Enter your issue details below this comment. -->\n\nRequest: extend fs to read and write the directory attribute that makes the directory a\npackage [https://en.wikipedia.org/wiki/Package_(OS_X)].\n",
        "labels": "feature request",
        "id": 43681
    },
    {
        "title": "path.dirname used in loop",
        "body": "I recently ran into an issue where there was a routine that creates a directory as well as all missing parent directories. It calls `path.dirname()` to get its parent directory and, if it doesn't exist, recurses into itself. Eventually it gets to some directory that exists and then works its way back, making the new subordinate directories.\n\nIn my case, I was providing a UNC (which is an expected use-case) and didn't have access to the share. So, the existence check was failing and it kept trying to move to the parent directory. Unfortunately, `path.dirname()`'s default functionality is to essentially return \"\\host\\share\" if _given_ \"\\host\\share\" (because this is considered the \"drive\" and the highest-most root element). It won't peel away any further layers. This caused an infinite loop.\n\nCan we modify `path.dirname()` to assert that what gets returned is not equaled to the argument?\n",
        "labels": "feature request",
        "id": 43682
    },
    {
        "title": "path.dirname() doesn't work with Windows' URNs",
        "body": "I tried this on the [Node Console](http://www.node-console.com/script/code) and it turns out that path.dirname() will basically return its argument if given a URN (\"\\a\\b\"). It's causing an infinite loop on my end. Note that the trailing-slash was included as it's being used in my present situation.\n\n``` js\nvar path = require('path');\nconsole.log(path.dirname(\"//a/b/\"))\nconsole.log(path.basename(\"//a/b/\"))\nconsole.log(path.dirname(\"\\\\\\\\a\\\\b\\\\\"))\nconsole.log(path.basename(\"\\\\\\\\a\\\\b\\\\\"))\n```\n\nOutput:\n\n```\n//a\nb/\n.\n\\\\a\\b\\\n```\n",
        "labels": "feature request",
        "id": 43683
    },
    {
        "title": "http fetch api",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**:\n- **Platform**:\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nNow with fetch going mainstream as a browser api. Does it make sense to implement http.fetch method with the same interface to give isomorphic support?\n\nI know there are modules, but doesn't this make sense being bundled as part of http api ?\n",
        "labels": "feature request",
        "id": 43684
    },
    {
        "title": "Dealing with segfaults",
        "body": "<!--\nThank you for reporting an issue. Please fill in the template below. If unsure\nabout something, just do as best as you're able.\n\nVersion: usually output of `node -v`\nPlatform: either `uname -a` output, or if Windows, version and 32 or 64-bit\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: all\n- **Platform**: all\n- **Subsystem**: native\n\n<!-- Enter your issue details below this comment. -->\n\nToday I found out about https://www.npmjs.com/package/segfault-handler and can't see myself ever shipping a Node based project without it. My only question is, why don't we just build this into Node directly?\n",
        "labels": "feature request",
        "id": 43685
    },
    {
        "title": "stream: proposal to improve err msg when `._write is not implemented`",
        "body": "Right now when someone try to use `writable.write` we don't give too much feedback in the error msg. I think we can do better on that area.\n\n**Example:**\n\n``` javascript\nconst ws = require('stream').Writable();\nws.write('example')\n```\n\n**Output:**\n\n![image 2016-06-23 at 10 41 19 pm](https://cloud.githubusercontent.com/assets/6354455/16326332/ab107c86-3993-11e6-80c1-b72b5e4c5b18.png)\n\n**Proposal:**\n\n![image 2016-06-23 at 10 35 38 pm](https://cloud.githubusercontent.com/assets/6354455/16326344/c6c5b900-3993-11e6-94d5-63c1580d75a8.png)\n",
        "labels": "feature request",
        "id": 43686
    },
    {
        "title": "Make uninstaller for Mac",
        "body": "Dozens of popular StackOverflow questions and tutorials all over dating back years with a ton of tedious steps. It'd be nice if I didn't have to follow some rando tutorial telling me to delete random stuff (and most likely leaving bits of Node all over my computer).\n\nUninstallers are pretty standard, no? Is there some technical reason there isn't one?\n",
        "labels": "feature request",
        "id": 43687
    },
    {
        "title": "Feature request: automatic string decoding for writable streams",
        "body": "- **Version**: all\n- **Platform**: n/a\n- **Subsystem**: stream\n\nIt would be nice if `Writable` streams had a configuration option to decode buffers to strings (using a `StringDecoder` instance). This is handy for example when writing a `Transform` stream that takes utf8 input.\n\nCurrently you have to set up your own `StringDecoder` instance and write the data through that first, which is kind of annoying. For non-multibyte encodings this isn't necessary though since you can just `chunk.toString()` inside your `_write()`/`_transform()` handler.\n",
        "labels": "feature request",
        "id": 43688
    },
    {
        "title": "Feature request: Official support for building node as a dynamic library",
        "body": "I love node.js, and I also love C++. When I write code inside of large C++ applications, I often wish I had an easy way to call out to a JS function which had full node capabilities - full module system, npm support, etc. Simply setting up a JS execution context with something like V8 often isn't enough.\n\nThe problem is that node's C++ core's is (understandably) configured to build an executable (see [here](https://github.com/nodejs/node/blob/master/node.gyp#L17)) rather than a dynamic library. Even if one were to change that, the plumbing required to cleanly get the event loop running and arguments passed from C++ to node isn't there.\n\nPopular projects like Electron have need for this functionality, so they [maintain their own separate fork](https://github.com/electron/node) of node which is versioned independently. This is obviously less than perfect - new features in node won't roll out to electron immediately, etc. \n\nIt would be awesome if there were an officially supported and maintained way to build node as a dynamic library, and simple instructions for setting that up.\n\nThanks!\n",
        "labels": "feature request",
        "id": 43689
    },
    {
        "title": "util.inspect multiline output length limit should be configurable",
        "body": "**Version**:  v4.4.5\n**Platform**: Darwin MacBook-Air.local 14.3.0 Darwin Kernel Version 14.3.0: Mon Mar 23 11:59:05 PDT 2015; root:xnu-2782.20.48~5/RELEASE_X86_64 x86_64\n**Subsystem**: util : util.js#L815:\n\nThe limit is 60 . Can this be configurable ?\nOr is there any potentially foolproof way to log any type of variables in a single line for logging purposes.\n\nP.S> would be happy to submit PR in desired format if this is is acknowledged.\n",
        "labels": "feature request",
        "id": 43690
    },
    {
        "title": "Port the CLI debugger to use the v8 inspector protocol",
        "body": "<!--\nThank you for reporting an issue. Please fill in the template below. If unsure\nabout something, just do as best as you're able.\n\nVersion: usually output of `node -v`\nPlatform: either `uname -a` output, or if Windows, version and 32 or 64-bit\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n\nNow that we have the v8_inspector available in Node, it would be good to create port of the CLI debugger that uses the new inspector protocol. This would have a few benefits:\n- It would make it easier to unit test inspector debug functionality for Node. UI based tests are not going to be easy to automate in the Node.js test infrastructure.\n- The CLI debugger could start taking advantage of the newer features available through the v8 inspector protocol.\n- We can stop depending on the deprecated V8 debug apis that the old protocol uses.\n- Over the long term we would like to converge back to a single debug server implementation and protocol. This would be a semver-major, so this shouldn't be done immediately, but maybe v8.x is a good target for this part?\n\nContributions to make this happen would be most welcome.\n\n/cc @pavelfeldman @TheAlphaNerd @nodejs/diagnostics \n",
        "labels": "feature request",
        "id": 43691
    },
    {
        "title": "How to add max timeout on DNS query?",
        "body": "For example, the request a MX query is a very very long response, how to set by example 8 seconds to stop connection and launch the error callback?\n",
        "labels": "feature request",
        "id": 43692
    },
    {
        "title": "Add setUserTimeout function to sockets",
        "body": "Hi,\n\nI'm working on a nodejs server that declares a tcp streaming endpoint. To detect dead peers, I needed to add a function that let dev set TCP_USER_TIMEOUT value that specifies the maximum amount of time in ms that transmitted data may remain unacknowledged before TCP will forcefully close the\ncorresponding connection and return ETIMEDOUT to the application.\n\nFor this, I had to patch both nodejs and libuv source code.\n\nI though you guys could be interested.\n",
        "labels": "feature request",
        "id": 43693
    },
    {
        "title": "URL to v8_inspector in the Windows console is inconvenient to copy",
        "body": "- **Version**: 7.0.0-nightly20160602aac79dfd78\n- **Platform**: Windows 7\n- **Subsystem**: v8_inspector\n\nSelection in the default Windows console works in the block mode with line wrap replaced by line break in the copy.\n\n![1](https://cloud.githubusercontent.com/assets/10393198/15794170/9de7e348-29f1-11e6-9b56-50dd2711ed96.png)\n\nA user can select a long URL with indentation only by selecting all the full lines:\n\n![2](https://cloud.githubusercontent.com/assets/10393198/15794188/beb42fbe-29f1-11e6-9ca5-ff438077b19d.png)\n\nOn inserting in the address bar, the line break is replaced by `%20` and the URL becomes invalid:\n\n![3](https://cloud.githubusercontent.com/assets/10393198/15794314/87a2c0e8-29f2-11e6-9255-4c800c651908.png)\n\nCurrently a user has these workarounds:\n1. Use not default console.\n2. Expand screen buffer width up to URL width.\n3. Redirect output to file and copy from it.\n4. Manually clean each URL.\n\nIs there a way to address this inconvenience? Maybe a flag can be added to open the URL in the Chrome automatically.\n",
        "labels": "feature request",
        "id": 43694
    },
    {
        "title": "--inspect support for source mapped files",
        "body": "<!--\nThank you for reporting an issue. Please fill in the template below. If unsure\nabout something, just do as best as you're able.\n\nVersion: usually output of `node -v`\nPlatform: either `uname -a` output, or if Windows, version and 32 or 64-bit\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 7.0.0-pre\n- **Platform**:\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nMay be a devtools only change. Inspect currently does not support source mapped files.\n\n/cc @pavelfeldman @ofrobots \n",
        "labels": "feature request",
        "id": 43695
    },
    {
        "title": "Discussion: Interest in segfault-handler ",
        "body": "Hey @nodejs/ctc \n@fresheneesz raised an issue on segfault handler asking if we had discussed handing it over to core https://github.com/ddopson/node-segfault-handler/issues/42 as the info you get for native module failures is a little more informative than the default in node.js.\n\nI am not aware if it has been discussed previously but if it's something of interest then it would be great to make it happen\n",
        "labels": "feature request",
        "id": 43696
    },
    {
        "title": "fs.write() and tls.connect() overloading should be separate methods instead",
        "body": "`fs.write()` and `tls.connect()` have two different, incompatible signatures:\n\n``` js\nfs.write(fd, buffer, offset, length[, position], callback)\nfs.write(fd, data[, position[, encoding]], callback)\n```\n\nThis came up while making a library that [wraps the Node API](https://github.com/slikts/promiseproxy) to promisify the callback methods; the masked inner signature is impossible to promisify in a generic way, and this problem also affects [promisify-node](https://github.com/nodegit/promisify-node/issues/22). The inner method should just have its own name; using overloading for it is just unnecessary added complexity.\n",
        "labels": "feature request",
        "id": 43697
    },
    {
        "title": "Can we add an option to squelch underscore assignment warning in the REPL?",
        "body": "- **Version**: 6.2\n- **Platform**: Ubuntu 14.04\n- **Subsystem**: repl\n\nIn #5431, Node maintainers concluded it would be prudent to warn when users assigned to `_` in the REPL. This seems pretty sane. However, I maintain an application that runs user code in the context of a REPL which often contains the use of underscore. This results in `Expression assignment to _ now disabled.` being output on every run and interfering with the display of the REPL. Could we add an option to squelch this warning, either at the `node` CLI level or on the `repl` module?\n",
        "labels": "feature request",
        "id": 43698
    },
    {
        "title": "Is it a bug to return BOM header after calling fs.readFile when the text encoding (like utf8) is specified?",
        "body": "<!--\nThank you for reporting an issue. Please fill in the template below. If unsure\nabout something, just do as best as you're able.\n\nVersion: usually output of `node -v`\nPlatform: either `uname -a` output, or if Windows, version and 32 or 64-bit\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**:: all version so far\n- **Platform**:: all platform\n- **Subsystem**: ...\n\nWhen loading text content from `filepath` that are utf-8 encode and having a BOM header\n\n```\nfs.readFile(filepath, 'utf8', (err, content) => {\n\n});\n```\n\nthe `content` returned still contains the BOM header, in addition to the text content. It causes a lot of wasted efforts to remove such a header in custom codes and is not the kind of behavior in other languages ...\n\nRemoving such a header in node shouldn't affect most of the existing codes that depend on it since such a header is most likely not used by custom codes anyway\n",
        "labels": "feature request",
        "id": 43699
    },
    {
        "title": "maybe require('buffer') could show a message",
        "body": "- **Version**: 6.1.0\n- **Platform**: linux\n- **Subsystem**: fedora\n\nI misread the doc, i did `var Buffer  = require('buffer');` and could not figure out why this was true `Buffer.alloc===undefined`.\n\n**Maybe** node could display a warning message if someone tries to require buffer like i did, or, **maybe** it could throw an error as if it was not an existing package ?\n",
        "labels": "feature request",
        "id": 43700
    },
    {
        "title": "API proposal for fs.flush method",
        "body": "Hi,\n\nit seems this topic wasn't on the bug tracker before. I have a case where an explicit call to fflush() is necessary. Could you please add a function fs.flush() which gives access to the underlaying routine?\n\nThanks!\n",
        "labels": "feature request",
        "id": 43701
    },
    {
        "title": "Request: send PDF files to printer to print them",
        "body": "- **Version**:6.1\n- **Platform**:Windows 7, 64bit\n- **Subsystem**:printing\n\n---\n\nA built-in module that allows node to send PDF files to a printer so that they can be printed in batch. A use case would be a folder that is watched by a node script that prints every file in the folder.\n",
        "labels": "feature request",
        "id": 43702
    },
    {
        "title": "Next/Back buttons move around in Windows installer",
        "body": "- **Version**: v6.1.0\n- **Platform**: Windows\n- **Subsystem**: Installer\n\nThe Next and Back buttons in the Windows installer move as your transitioning between wizard pages.  These buttons should remain in a fixed position so that you dont accidentally click the wrong button while you are moving through the wizard.\n",
        "labels": "feature request",
        "id": 43703
    },
    {
        "title": "HTTP/2 support",
        "body": "Are there any plans to support HTTP/2? The closest thing to a HTTP/2 client/server implementation is right now the [node-http2](https://github.com/molnarg/node-http2) module, but it still has stability issues (at least the client).\n\nAn \"official\" implementation of HTTP/2 is badly needed, guys. Pretty please :)\n",
        "labels": "feature request",
        "id": 43704
    },
    {
        "title": "http.request client caching feature",
        "body": "I did a quick search across issues and I am wondering if HTTP caching support was ever considered to be implemented at the Node level for `http.request`? -- an RFC-compliant cache which honors cache headers similar to how browsers handle requests/XHR etc.\n\nIf not, is anyone aware of a well-implemented low-level lib with a good coverage of HTTP caching headers?\n",
        "labels": "feature request",
        "id": 43705
    },
    {
        "title": "Add built-in support for ElGamal encryption",
        "body": "ElGamal is one of the available partial, but performant [homomorphic encryption mechanisms](https://en.wikipedia.org/wiki/Homomorphic_encryption). I started to write a [separate library](https://github.com/kripod/elgamal.js) for it, but thought that the functionality I wish to provide could be fit into the official [crypto API of Node](https://nodejs.org/api/crypto.html).\n\nMost of the implementation could be inherited from the available Diffie-Hellman methods, especially, key generation.\n",
        "labels": "feature request",
        "id": 43706
    },
    {
        "title": "Base2 Encoding for Buffers",
        "body": "I'm looking to work with arbitrary length binary data in node,`001000100100` <- stuff like this. Buffers seem like the proper place for this but currently the `'binary'` encoding on buffers is for latin-1 strings, not truly binary data. As currently stands I'm looking at using the `'hex'` encoding and manually converting and then adding padding to my data but this is less than ideal.\n\nI propose that a new encoding `'base2'` be added to buffers in order to allow easier manipulation at the bit level. This would be non-breaking and thus could be added to the next release.\n\n I am of the view that in the long run the `'binary'` encoding should be changed to be truly binary and `'latin-1'` added as a separate encoding. Then again there's probably a great historical reason as to why things are the way they are.\n",
        "labels": "feature request",
        "id": 43707
    },
    {
        "title": "Node.js documentation is not print-friendly",
        "body": "Can not print Node.js documentation from: https://nodejs.org/api/all.html .\n\nSome CSS rules are not appropriate for print mode.\nBefore:\n![image](https://cloud.githubusercontent.com/assets/12509753/15258259/3d51cb42-1953-11e6-961d-c4f6374d4b96.png)\n\nFortunately, I found an simple solution(below).\n\nAt the bottom of style.css add this CSS rule:\n\n```\n@media print {\n\n  html  {\n    height : auto;\n  }\n\n #column2.interior {\n   display : none;\n }\n\n #column1.interior {\n   margin-left : auto;\n   overflow-y  :  auto;\n }\n\n}\n```\n\nAfter my CSS codes:\n![image](https://cloud.githubusercontent.com/assets/12509753/15258581/06e54afa-1955-11e6-9bd1-aae721cc28c2.png)\n",
        "labels": "feature request",
        "id": 43708
    },
    {
        "title": "sourcemap support for node debugger",
        "body": "i'd really like to see sourcemap support for the node debugger. \n",
        "labels": "feature request",
        "id": 43709
    },
    {
        "title": "Allow setting maximum age for http Agent's keep-alive ",
        "body": "Hi!\n\nWe're using Node.js in a setting were we do blue-green deployments by changing DNS records. We are running into an issue using the http Agent' keepAlive setting:\n\nWhen we switch over to a new version of a downstream service by changing the DNS record, the http connections of the upstream service continue pointing to the old version, and continue to do that almost indefinitely if there is enough continuous traffic on the service (which most of the time there is).\n\nFor that reason, we cannot use the keepAlive feature at the moment.\n\nIt would be helpful if we would be able to configure a maximum age for sockets, which is checked when the socket is drawn from the free pool, and if the age exceeds the maximum, the socket is closed and a new one is requested.\n\nIs there a work around for this issue? I found that we could emit an 'agentRemove' event on the socket after a period of time, which is supposed to remove the socket from the agent, but I'm not sure if the socket then requires manual closing after that?\n",
        "labels": "feature request",
        "id": 43710
    },
    {
        "title": "Remove version numbers from file names in the latest LTS releases directory",
        "body": "- **Version**: N/A\n- **Platform**: All\n- **Subsystem**: N/A\n\nMove latest LTS to a predictable URL for automatic installation scripts.\n## Â Use case\n\nI have an installation script for which the latest LTS is a prerequisite. If I link to the current latest release, the URL will break in the next upgrade.\n\ne.g.,\n\nThe current OS X LTS release is at https://nodejs.org/dist/latest-argon/node-v4.4.4.pkg â€“ if I hardcode that into my installation script, it will break when 4.4.5 comes out and at https://nodejs.org/dist/latest-argon/node-v4.4.5.pkg\n## Proposed solution\n\nRemove the version number from the file names in the latest-argon folder. As this will break existing links, a better solution would be to have both versioned and non-versioned files (although it will create redundancy in the current version, the next LTS version can use only non-versioned file names).\n\ne.g., To get the latest Argon LTS release, you would use the following URL:\n\nhttps://nodejs.org/dist/latest-argon/node.pkg\n\nCurrently, that would point to 4.4.4. When 4.4.5 comes out, it will point to 4.4.5 without breaking.\n\nThis should be expected behaviour when linking via a \"latest\" URL.\n",
        "labels": "feature request",
        "id": 43711
    },
    {
        "title": "discuss: have glob function is `fs` or `path` API",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**: \n- **Platform**:\n- **Subsystem**: `fs`, ~~`path`~~\n  Should we consider to have a kernel implementation of `glob`? I see some tickets about this module and find it very central to the ecosystem, yet also critical because of its implementation and performance.\n\nA `C` dirent implementation without all of the globbing patterns would be 5 to 15 times as fast. There is precedence in a lot of language to have this. Also it is some 20 lines of `C` code + the boilerplate.\n",
        "labels": "feature request",
        "id": 43712
    },
    {
        "title": "child_process.spawn ignores PATHEXT on Windows",
        "body": "Originally reported as nodejs/node-v0.x-archive#2318.\n\nTLDR: The workaround is to use [cross-spawn](https://www.npmjs.com/package/cross-spawn) (or [cross-spawn-async](https://www.npmjs.com/package/cross-spawn-async)).\n",
        "labels": "feature request",
        "id": 43713
    },
    {
        "title": "RFE: add option sorted to querystring.stringify",
        "body": "Hi,\n\nMany service API requires a signature of querystring (via `MD5` or `SHA`) for authenticity, and that requires a querystring unique (usually alphabetically sorted by `key`) for any **deep-equal** `Object`s. But now querystring is generated by key-added order (like `JSON.stringify`).\n\nMay I ask if it is worth adding a `sorted` option?\n\nActual:\n\n``` js\n> qs.stringify({a:1, c:1, b: 1})\n'a=1&c=1&b=1'\n```\n\nExpected:\n\n``` js\n> qs.stringify({a:1, c:1, b: 1}, null,null, { sorted: true })\n'a=1&b=1&c=1'\n```\n",
        "labels": "feature request",
        "id": 43714
    },
    {
        "title": "Node.js future version",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Vsion 6.0.0**:\n- **Platform All**:\n\n<!-- Enter your issue details below this comment. -->\n\nI am really a big fan of Node.js and working on it since last 4 years.\nbut no idea of it's core design.\n\nThis is not actually an issue but a request to all Node.js core team members.\nPlease make Node.js multi-core system by default without any clustering module.\n\nBecause it sometimes time consuming and code get messy and \nalso real-time library like Socket.io broken on clustering,\n\nThere are some solution on Github but they are too not 100% perfect.\nbecause some of libs have session problem.\n\nSo my humble request to Node.js team that support multi-core environment..\n",
        "labels": "feature request",
        "id": 43715
    },
    {
        "title": "docs do not state at what version an API was introduced (or deprecated)",
        "body": "<!-- Enter your issue details below this comment. -->\n\nnode documentation just documents the current node, but to write portable node.js, its important to know about when APIs were introduced (or changed incompatibly)\n\nI regularly find developers attempting to use features that only exist on the most recent Node.js versions, such as the `v8` module, without realizing it doesn't exist on some LTS versions.\n\nIt would be quite helpful if the API docs were annotated with the version in which an API was introduced.\n\ncc: @chrisdickinson @bhajian\n\n---\n\n(edited by @addaleax)\n\nNow that basic tooling for this feature is available in the doctool, it would be nice to see if we can get some people together for looking up the versions in which features were added/deprecated! If youâ€™d like to volunteer, Iâ€™d suggest you just comment on this issue.\n\nDocumentation files for which this is definitely worthwhile:\n- [x] assert.md â€“ @Trott in f52b2f116bf510e2af8750061ac6f8a0c9caa653 (#6688)\n- [x] buffer.md â€“ @addaleax in 4dcc692cada019cd2661ff807d829493ebf71594 (#6495)\n- [x] child_process.md â€“ @addaleax in 27d2267066add18a1eafa2ac852ffdb4ae3198be (#6927)\n- [x] cli.md â€“ @Trott in 90675818eede96a063489109f86022dd13ad75cb (#6960)\n- [x] cluster.md â€“ @addaleax in c628982a06e479f0d7d943c13131108924873ba4 (#7640)\n- [x] console.md â€“ @edsadr in 51b8a79bd46a28c2f576a579f258c2222e1a951b (#6995) \n- [x] crypto.md â€“ @lpinca in cfe8278328d190279532ab9b7fd13ae1bfd78ee2 (#8281)\n- [x] dgram.md â€“ @lpinca in 379d9162a2d992f7ff8a20d00f088ede1bf2f0fe (#8196)\n- [x] dns.md â€“ @julianduque in 71996506e9a979e73d20bd418a5c7e34a92c3f08 (#7021)\n- [x] events.md â€“ @lpinca in 769f63ccd8437045af5ddf1f418c53d2319597ed (#7822)\n- [x] fs.md â€“ @addaleax in ba10ea8f3af4a1af5c2f7df3e4f5af348f09e97b (#6717)\n- [x] http.md â€“ @addaleax in 72500f942b85e7fe66176b2807663aa225015e39 (#7392)\n- [x] https.md â€“ @addaleax in e8356b25cdf43079e8a6d74e02df67a49f64e471 (#7392)\n- [x] modules.md â€“ @lpinca in df4880de557fabafb625745c6ea75d3b755595d2 (#8250)\n- [x] net.md â€“ @italoacasas in 8bccc9e6c82c558132a28a462e9dd573ae0302c6 (#7038)\n- [x] os.md â€“ @bengl in 5a8c66a252c16b0d181fd7f1b3232941e5644971 (#6609)\n- [x] path.md â€“ @julianduque in bed44c94a0f05748fc5160610db33ed15f1f540c (#6985)\n- [x] process.md â€“ @bengl in ec67abe4a7c074bb66700c4aede56ffd4aaf3363 (#6589)\n- [x] punycode.md â€“ @firedfox in b90c52e38d47952bf6bef59d9a1c116b1972b8d9 (#6805)\n- [x] querystring.md â€“ @bengl in f7730733384cc15e8e5c842e3e1771e6f917c188 (#6593)\n- [x] readline.md â€“ @julianduque in 0ed4d8c535945865d48d50c023aba46f6286f616 (#6996)\n- [x] repl.md â€“ @addaleax in 740d8cf5e0bf85bbc756096ad40b44f19a4a4ddd (#7256)\n- [x] stream.md â€“ @italoacasas in c897d0ba71c0e73fbd37372e3dd4825e93cd251a (#7287)\n- [x] string_decoder.md â€“ @Trott in eb089e7ccd81c0951e4901df20f6dbaa084af143 (#6741)\n- [x] tls.md â€“ @italoacasas in c2e6078ed95cea135da8ebe4ef5a807e0bd0bbe2 (#7018) \n- [x] tty.md â€“ @trott in d3f3e183bfdd27a66ce4791ba0c933ab33a91512 (#6783)\n- [x] url.md â€“ @bengl in 43e4bafcaf1e40d62b4bbcd33ce8de946586e835 (#6593)\n- [x] util.md â€“ @lpinca in d9142b4bd6e48690337ac8f988719e67d7a361ce (#8206)\n- [x] v8.md â€“ @trott in b3bc36209f927bbdcdcada7e2170f91f1c32d1b3 (#6684)\n- [x] vm.md â€“ @addaleax in 16f98e589c69ffe6283aa11493fd417368708557 (#7011)\n- [x] zlib.md â€“ @addaleax in b49df8891682f0d429f7d594b9ab1185715eb4f7 (#6840)\n\nDocs for which this may or may not make sense:\n- [ ] addons.md\n- [ ] debugger.md\n- [ ] domain.md\n- [ ] globals.md\n- [x] timers.md â€“ @addaleax in cd4dbf33481ee1432b0d71a6576492acc12b4298 (#7493)\n",
        "labels": "feature request",
        "id": 43716
    },
    {
        "title": "Return 501 (Not Implemented) for invalid request methods",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **4.4.3**:\n- **osx**:\n\n<!-- Enter your issue details below this comment. -->\n\n[According to RFC](http://tools.ietf.org/html/rfc2616#section-5.1.1):\n\n>   An origin server SHOULD return the status code 405 (Method Not Allowed)\n>   if the method is known by the origin server but not allowed for the\n>   requested resource, and 501 (Not Implemented) if the method is\n>   unrecognized or not implemented by the origin server. \n\nUsing this snippet:\n\n``` javascript\nvar http = require(\"http\");\nvar server = http.createServer(function(request, response) {\n\n  response.write('{\"derp\":1}');\n  response.end();\n});\n\nserver.listen(9494);\nconsole.log(\"Server is listening\");\n\n```\n\nand the curl request: `$ curl -i localhost:9494/ -X derp`\n\nthe response returned is: `curl: (52) Empty reply from server`\n\nthere doesn't seem to be any way of handling this currently. Am I missing something?\n",
        "labels": "feature request",
        "id": 43717
    },
    {
        "title": "Support for source maps",
        "body": "I don't know if this has been asked before (couldn't find anything), but it would be quite nice if, just like Chrome and other programs, Node.js would have built-in support for [source maps](https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/).\n\nCurrently, there is [node-source-map-support](https://github.com/evanw/node-source-map-support), which is quite good, but given the myriad of JavaScript dialects that are in use today and given that source maps are so widespread, I think it would be useful if was default behavior of Node itself.\n\nCan be considered low-priority, of course.\n",
        "labels": "feature request",
        "id": 43718
    },
    {
        "title": "Module.globalPaths under Windows",
        "body": "- **Version**: 4.3â€”6.0\n- **Platform**: Windows 32, 64\n\nLooks like code at https://github.com/nodejs/node/blob/master/lib/module.js#L590:\n\n``` js\nvar paths = [path.resolve(process.execPath, '..', '..', 'lib', 'node')];\n```\n\nis Unix specific and since `nodejs` is installed as `c:\\program files\\nodejs\\node.exe` the base path resolved to `'C:\\\\Program Files\\\\lib\\\\node'`, and it's pointless.\n\nGuess this should be fixed to `path.resolve(process.env.AppData, 'npm', 'node_modules')` for windows, or something similar since right there node_modules are placed by default in win7+.\n",
        "labels": "feature request",
        "id": 43719
    },
    {
        "title": "http's 'upgrade' event should be handled one handler at a time",
        "body": "- **Subsystem**: http (maybe others)\n\nFrom what I understand, there is only one way to handle connection upgrades: with `http.Server`'s 'upgrade' event. However, from working on a WebSocket implementation, I noticed that there's (what I believe is) an architectural flaw with how the connection upgrades are handled:\n\nFrom the documentation:\n\n> Emitted each time a client requests a http upgrade. If this event isn't listened for, then clients requesting an upgrade will have their connections closed.\n\nFor example:\n\n``` js\n// from the 'ws' module\nserver.on('upgrade', (req, socket, upgradeHead) => {\n  if (req.headers.upgrade !== 'websocket') {\n    // close or return?\n  }\n  // handle the websocket connection\n})\n\n\n// from another module that listens to a different type of upgrade\nserver.on('upgrade', (req, socket, upgradeHead) => {\n  if (req.headers.upgrade !=== 'some-other-protocol') {\n    // close or return?\n  }\n  // handle this connection\n})\n\n```\n\nIf the WebSocket isn't supposed to handle the socket, should the handler close the socket, or return in hopes that another upgrade handler handles the connection?\n\n...and I'm not even mentioning non-blocking calls within handlers, which could be done as a part of determining whether the socket connection should be handled by the handler.\n\nIf there is no other handler for the 'upgrade' event, the socket just stays idle until either the server or the client closes the connection, most likely via timeout (which in itself can cause problems if the timeout is specified to \"none\").\n\nWhile I do know that what I am suggesting is more than likely a breaking change, could upgrade handling be converted to (or something along the lines) to what is essentially a middleware setup, a bit like [connect](https://github.com/senchalabs/connect)? This way, the socket would only be handled by one handler at a time (blocking or non-blocking), a specific handler can withhold a socket it's handling from the other handlers (prevents conflicts), and if everything falls through, it can fall through to node.js's 'last' middleware, which closes the connection.\n\nWill something like this be possible?\n\n_edit:_\n\nOn my way back home, I realized that the 'connect' event is pretty much the same, and express mitigates it with connect + various libraries that write themselves around it, but I just felt that it could be more standardized in node so people who write libraries that use the event e.g. socket authors would be more convinced to add the option where the websocket handling is done as a middleware instead of an event handler. Either way, middleware (like Promise core API) would be nice.\n",
        "labels": "feature request",
        "id": 43720
    },
    {
        "title": "discuss: object serializer/deserializer + transferables",
        "body": "I wanted to propose this issue as a top-level home for discussions from multiple issues, amongst https://github.com/nodejs/node/pull/2133, https://github.com/nodejs/node/issues/3145.\n\nBoth issues are too big to have immediate action (judging from what I have read), but they have a serializer/deserializer feature in common, `node`, `c++` and `v8` are not providing out of the box. @bnoordhuis mentioned that it seems to be unrealistic to drag in `Blink` code because of the many dependencies within that repo. I had a look also into their `WebWorker` implementation, which is fairly huge.\n\n> (Ignoring the WebWorker and IPC discussion) the question would be whether we first wanted to provide an efficient serializer/ deserializer + transferables of c++ objects, which might aid a lot of problems at once and also be a nice standalone feature.\n\nReading up on this from various c++ resources this is of course a non-trivial task. Whereas I also don't believe there will ever be a single method for arbitrary object serialization (please prove me wrong), due to the way v8 works. We would need to judge this before hand because that means a lot of serialization strategies would be insufficient for us. \n\nAs a quick guess, that would probably lead us to implement `::serialize()` methods  per Class, no matter if binary or text, which would ensure serilization happens correctly at dev / build time. \n",
        "labels": "feature request",
        "id": 43721
    },
    {
        "title": "Add script files association in Windows installer",
        "body": "Windows has not shebangs, but file associations can do the thing.\n\nPerl and Python installers both have the appropriate option:\n\n![perl](https://cloud.githubusercontent.com/assets/10393198/14630829/d219688c-0618-11e6-9fd2-efecc8c09770.png)\n\n![python](https://cloud.githubusercontent.com/assets/10393198/14630831/d6ebb48c-0618-11e6-957d-99452014f1da.png)\n\nThey add some keys to the Windows registry for this.\n\nAfter that users can write, for example, `script.pl arg` instead of `perl script.pl arg`. In addition, they can just click on the script icon if script arguments are not needed.\n\nUsers of other interpreters get used to it. After they start using Node.js they feel the lack of this feature. There is no easy solution on the user end: the bunch of proper registry keys are not simple or well-known, and association via context menu is not well for argument handling (see my former frustration in this pseudo-issue: https://github.com/nodejs/node/issues/4725 ). However for the developers of the installer to add this feature seems not so difficult. It could be added to any major or minor version without any chance to break something. \n\nMay be it would be a nice present for windows users on the occasion of Node.js v6.0 release?\n",
        "labels": "feature request",
        "id": 43722
    },
    {
        "title": "Improve stack traces for exceptions thrown at a top-level",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**: 5.1.0\n- **Platform**: Centos 6.x\n- **Subsystem**: `require`\n\n<!-- Enter your issue details below this comment. -->\n\nWhen exceptions are thrown at a top level, there's a distinct lack of information as far as how that module was required. If you have a dependency chain where a requires b which requires c, if c throws an exception while building its module, node doesn't tell you about b or a, which can make it difficult to debug things when there are interactions between modules or global variables. \n\nFor example, I'm seeing this exception:\n\n```\nError: Logger not yet initialized! Initialize first!\n    at Error (native)\n    at init (/home/vagrant/backend/git/node_modules/logger.js:116:19)\n    at eval (eval at proto (/home/vagrant/backend/node_modules/proto/proto.js:57:34), <anonymous>:3:39)\n    at Object.<anonymous> (/home/vagrant/backend/git/node_modules/security.js:7:31)\n    at Module._compile (module.js:425:26)\n    at Object.Module._extensions..js (module.js:432:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:313:12)\n    at Module.require (module.js:366:17)\n    at require (module.js:385:17)\n```\n\nThis doesn't tell me what file required `security.js`, which would be incredibly helpful to me right now in debugging this problem with my code. Also, the part of the stack trace containing internal node stuff is very unlikely to be useful to a developer unless what they're developing is `node` itself. I want to suggest that a stacktrace like the following be generated instead:\n\n```\nError: Logger not yet initialized! Initialize first!\n    at Error (native)\n    at init (/home/vagrant/backend/git/node_modules/logger.js:116:19)\n    at eval (eval at proto (/home/vagrant/backend/node_modules/proto/proto.js:57:34), <anonymous>:3:39)\n    at Object.<anonymous> (/home/vagrant/backend/git/node_modules/security.js:7:31)\n    required by (db.js:4:16)\n    required by (utils.js:9:26)\n    required by (server.js:21:20)\n    required by (appServer.js:3:36)\n```\n",
        "labels": "feature request",
        "id": 43723
    },
    {
        "title": "cannot build from source on Arch Linux w/ python v3.5.1",
        "body": "- **Version**:  node v4.4.3 (but have also seem this with v4.4.2, 4.4.1, etc.)\n- **Platform**:  64-bit Pine64 A64+ board with 2 GB of RAM & Arch Linux OS w/ python 3.5.1 (but would be true of _any_ machine running Arch Linux)\n- **Subsystem**:  N/A\n\n<!-- Enter your issue details below this comment. -->\n\nthis is happening in Arch Linux OS, because they only load python 3.5,1 for that OS.\n\nif you download node.js' latest LTS version (v4.4.x) to compile from source and attempt this starting with using the command line `./configure` command, it will fail, as that script uses python, and Arch Linux OS only comes with python v3.5.1 currently. python 3.x now requires certain statements like `print` now require the quoted string statement to now be in parantheses. so a python v2.7.x print statement would be: `print \"this string\"` must now be `print (\"this string\")` in python v3.x or you will get a compile error. there are still several `print` statements without these parantheses in the node.js configure file for compiling from source that will cause it to fail without much real explanation.\n\nthere are possible fixes â€”\n-  **preferred** â€” rewrite the configure and other script files to test first what version of python they are using: if < python 2.7, tell them to update to 2.7 as current stable vers.; if python 2.7, run the current script; if python >= 3.x, point at another script that has proper python 3.x syntax (`print (\"this string...\")`, etc.)\n-  include in instructions for compiling node.js from source and BUILDING.md and REQDME.md that you have to run on python v.2.7, make sure they have python v2.7 installed, and give them the option to change the language heading in the script files from â€”\n\n`#/usr/bin/env python`\n\nto change it to â€”\n\n`#/usr/bin/env python2`\n\n...but really, python 3.x has been out for a while now and it would be a much better UX if the scripts tested and ran on both python v2.7 and python v3.x, and/or did much better error reporting to tell users what version of python to use.\n\nbest,\n\nâ€”  faddah\n      portland, oregon, u.s.a.\n",
        "labels": "feature request",
        "id": 43724
    },
    {
        "title": "Proposed extension to https.request to allow using a custom OpenSSL client certificate engine.",
        "body": "- **Version**: 6.0.0\n- **Platform**: All\n- **Subsystem**: HTTPS\n\n<!-- Enter your issue details below this comment. -->\n\nI am lacking a way to access the SSL_CTX_set_client_cert_engine function in OpenSSL when doing https requests. I think this functionality would be useful to others which is why I am posting here as a feature request?\n\nPerhaps the interface could look something like this:\n\n```\nvar options =\n{\n    host: 'www.host.com',\n    port: 443,\n    method: 'GET',\n    path: '/sensitive/data.action',\n    clientCertEngine: 'credsmgr',       // my custom SSL client certificate engine\n    agent: false,\n    headers: {}\n};\nhttps.request(options, function(c) {/*etc*/});\n\n```\n\nIt shouldn't be a big thing to incorporate - I can provide a patch if needed? Obviously there would need to be some kind of consensus on the extension... is \"clientCertEngine\" the right name for instance?\n\nThanks in advance for the consideration!\n",
        "labels": "feature request",
        "id": 43725
    },
    {
        "title": "A more intuitive fs.mkdtemp()",
        "body": "<!--\r\nThanks for wanting to report an issue you've found in Node.js. Please fill in\r\nthe template below by replacing the html comments with an appropriate answer.\r\nIf unsure about something, just do as best as you're able.\r\n\r\nversion: `5.10.1`\r\nplatform:  `Darwin 15.3.0`\r\nsubsystem:  `fs`\r\n\r\nIt will be much easier for us to fix the issue if a test case that reproduces\r\nthe problem is provided. Ideally this test case should not have any external\r\ndependencies. We understand that it is not always possible to reduce your code\r\nto a small test case, but we would appreciate to have as\r\nmuch data as possible.\r\n\r\nThank you!\r\n-->\r\n- **Version**: `5.10.1`\r\n- **Platform**: `Darwin 15.3.0`\r\n- **Subsystem**:  `fs`\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI am happy that the Node team decided to implement `fs.mkdtemp()` - the security concerns around this behavior make me glad to see it in core.\r\n\r\nHowever, the API feels awkward to me because:\r\n- The randomness it provides is hard coded to 6 characters, which is just enough that it's _probably fine_, but not enough that I don't want to add more.\r\n- Using the `prefix` argument sounds like a good way to add random characters, but doing half the work is strange if you read code that actually does this. Additionally, _if_ I'm going to implement my own name pattern, I don't really want to _also_ have to keep in mind the one Node is using. For example, should I have to re-implement the entire `mkdtemp` just to get valid [UUIDv4](https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_.28random.29) directory names? That is genuinely useful for unit tests and also for being able to easily `mv` the temporary directory to a cache-proof URL on my server without \"renaming\" it ... lest I have to undo the suffix every time or teach my client code about it.\r\n- Using `prefix` as a directory path is messy, What would you expect this code to do?\r\n  \r\n  ``` javascript\r\n  'use strict';\r\n  \r\n  const os = require('os');\r\n  const fs = require('fs');\r\n  \r\n  fs.mkdtemp(os.tmpdir(), (err, dir) => {\r\n      if (err) {\r\n          throw err;\r\n      }\r\n      console.log('Created directory:', dir);\r\n  });\r\n  ```\r\n  \r\n  If `os.tmpdir()` returns `/tmp` for you, that will actually create a directory at the very root of your filesystem, rather than inside of `/tmp`. And it will end up being named something like `tmp-e0ew3m`. To \"fix\" this you have to use `path.join(os.tmpdir(), '/')`.\r\n\r\nI would like to propose making the API more intuitive and useful for its intended purpose: unique, convenient, secure creation of temporary directories.\r\n1. Have an explicit `cwd` argument, which is internally `path.join()`'d with the name. This is so that the name can be computed in isolation. And to prevent accidentally creating directories out in the open, where they won't actually be cleaned up.\r\n2. Replace `prefix` with (or just add) a `name` option, which is used as-is when provided. Possibly increase the default randomness for the case where one is not provided. This makes it easy to opt-out of the pattern that Node happens to use currently, which is not exposed via any kind of constant (and I don't think that would provide much value, anyway).\r\n\r\nI think these changes are best done as a breaking change, mainly to make the API less surprising. But compatibility could probably be maintained by only enabling these semantics on the options object.\r\n",
        "labels": "feature request",
        "id": 43726
    },
    {
        "title": "Proposal for `.pipe()` - forward error emitted from `src` to `dest` in stream",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **v4.4.1**:\n- **Darwin Bens-Mac-mini.local 13.4.0 Darwin Kernel Version 13.4.0: Wed Mar 18 16:20:14 PDT 2015; root:xnu-2422.115.14~1/RELEASE_X86_64 x86_64**:\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nWhile dealing with a weird uncaughtException, emitted by a stream. It inspires me this idea, maybe `.pipe()` can do one more thing to bind an error listener on the `src` and emit ( forward ) the error to `dest` automatically. \n\nThe benefit is: We can easily handle the error on the destination, and no worry that error might be emitted on somewhere we forgot or have no access to it.\n\nIn my case, for testing purpose, I emit error on the query object created by node-mysql, and keep to get `uncaughtException`, I checked all the EventEmitters on the scope, and don't know why it happened. Till the end, I understand, node-mysql `forward` the error from the query object to the stream, and my database api(my another module not written in the current module) pipe that stream to a Transform stream and return that transform stream to me. I forgot the stream is not the stream originally created by node-mysql, and to avoid potential uncaughtException, I decide to add error listener to the original stream.\n\nIt makes the codes ugly, previously. it is\n\n```\nreturn query.stream().pipe(NormalizeData());\n```\n\nand now, it becomes\n\n```\nvar s = query.stream();\nvar n = NormalizeData():\ns.on('error', err=> n.emit('error', err));\nreturn s.pipe(n);\n```\n\nIt's just an idea, please feel free to close it, if it is no sense :)\n",
        "labels": "feature request",
        "id": 43727
    },
    {
        "title": "Consider moving from gyp to gn",
        "body": "Chromium started to move from gyp to gn a while ago. Soon, the v8 build will be fully supported on gn. While there's no immediate plan to remove the gyp files right away, gyp itself will become unsupported the less people use it.\n\nConsider planning for moving to gn: https://chromium.googlesource.com/chromium/src/+/master/tools/gn/README.md\n",
        "labels": "feature request",
        "id": 43728
    },
    {
        "title": "Request: Allow specifying lookup paths for require.resolve",
        "body": "**tl;dr** I'd like to propose an additional API be exposed to Node.js JavaScript that allows developers to perform `require.resolve()`, but with an custom list of lookup paths.\n## Background\n\nIn ESLint, we allow people to extend their configuration files with Node.js packages, so you can do something like this:\n\n``` yml\nextends: airbnb\n```\n\nAnd then ESLint `require`s `eslint-config-airbnb`. That worked fine until people started creating shareable configs, published on npm, that wanted to inherit from other shareable configs (also published on npm). In that case, they'd want the `require` lookup to happen from their config file and not from the ESLint file doing the `require`. \n## Our Solution\n\nWhat we ended up doing to get this to work: https://github.com/eslint/eslint/blob/master/lib/util/module-resolver.js\n\nIn short:\n1. Create the normal array of lookup paths by combining `Module.globalPaths` and `module.paths`\n2. Prepend another path to the front of that array\n3. Use `Module._findPath()` to do the lookup, passing the lookup paths array\n\nThe obvious ugliness here is that we're not just relying on `Module`, but we're relying on `Module._findPath()`, which seems to indicate that this method should not be used (assuming the underscore is intended to mean \"private\".\n## What I'd Like\n\nSome way to get the functionality of `Module._findPath()` that is an official Node.js API that we can rely on without fear of it changing or being removed. Some possible options (definitely not exhaustive):\n1. Allow a second argument to `require.resolve()` that allows you to pass an array of lookup paths.\n2. Bless `Module._findPath()` by creating something like `Module.resolveFromPaths()` that calls `Module._findPath()` under the covers\n\nOf course, these are just a few ideas I had in my head. Anything that accomplishes the same functionality would be awesome.\n## Prior Art\n\nIt seems like there's a larger need for this capability based on modules available on npm:\n1. [resolve](https://npmjs.com/package/resolve) - effectively does the same thing by trying to recreate the Node.js lookup process. We tried using this, but there are enough differences with the real Node.js implementation that we abandoned it. It also hardcodes some information that should be dynamic (like core module names). 7 million downloads in the past month.\n2. [resolve-module](https://www.npmjs.com/package/resolve-module) - a simpler and less popular version of the same thing.\n3. [custom-resolve](https://www.npmjs.com/package/custom-resolve) - a customized version of `resolve`.\n4. [resolve-cwd](https://www.npmjs.com/package/resolve-cwd) - `require.resolve` using CWD as the root. 50,000 downloads in the past month.\n5. [resolve-from](https://www.npmjs.com/package/resolve-from) - `require.resolve` from any arbitrary path. 1.5 million downloads in the past month.\n",
        "labels": "feature request",
        "id": 43729
    },
    {
        "title": "Request UTF-32 Character Encoding",
        "body": "- **Version**: v5.4.0\n- **Platform**: Windows 7 Professional 64 bit\n- **Subsystem**: buffer\n\nCharacter encoding for buffer.\n\nWhy are utf-8 and utf-16 included for Buffer Encoding but UTF-32 is not?  UTF-32 is just as prevalent and even more useful than the first two including more options for characters.\n",
        "labels": "feature request",
        "id": 43730
    },
    {
        "title": "Custom HTTP methods result in empty replies",
        "body": "- **Version**: v5.9.1\n- **Platform**: Windows 10 x86 64bit\n\nI have the following code:\n\n``` javascript\nvar http = require('http');\nvar server = http.createServer(function (req, res) {\n  res.end('ok');\n});\nserver.listen(0, function () {\n  console.log('Server listening on port', this.address().port);\n});\n```\n\nWhen I send a request with GET, POST or any of `http.METHODS` methods, I get the expected **ok** message with status code **200**.\nE.g. _curl -v -X GET &lt;url&gt;_\n\nBut when I send a request with a custom HTTP method (e.g. 'FOO'), I get an empty reply (no status code and no message).\nE.g. _curl -v -X FOO &lt;url&gt;_\n\nWhat I would expect is to get at least `501 Not Implemented`.\n",
        "labels": "feature request",
        "id": 43731
    },
    {
        "title": "Feature request: fs.ReadStream.tell()",
        "body": "When I try to parse a large local utf8-encoded file, it takes about 2 or 3 hours to accomplish the job. So I need to monitor the rate of progress. Because it is a utf8 file, I can't just read it and convert it by chunk.toString(\"utf8\"), it will cause the characters broken. I set .setEncoding('utf8') first. But then I can't use chunk.length to get the right value of the file position.\n\nI have read some comments, but there is no way to meet my request.\n(e.g., https://github.com/nodejs/node-v0.x-archive/issues/1527 http://stackoverflow.com/questions/13932967/how-do-i-do-random-access-reads-from-large-files-using-node-js )\n\nIf we could have an \"ftell\" as c does (see http://www.gnu.org/software/libc/manual/html_node/File-Positioning.html  ), then it would be possible to monitor the progress. So may we add the \"ftell\" function to the file stream?\n- **Version**: 5.9.1\n- **Platform**: Linux\n",
        "labels": "feature request",
        "id": 43732
    },
    {
        "title": "module: import unload module strategy",
        "body": " A module always loaded in cache. If we only use once, I recommend add strategy to unload the module.\n Like the linux kernel do.\n",
        "labels": "feature request",
        "id": 43733
    },
    {
        "title": "Native DNS caching for lookups",
        "body": "Will we ever see caching in the native dns module? We have noticed a decent amount of overhead when making many parallel calls to the same dns and the dns module is doing lookups.\n\nI understand the idea around this module is to be unopinionated but it might be a feature typical users might want to enable w/o using something like bind.\n",
        "labels": "feature request",
        "id": 43734
    },
    {
        "title": "Longer stack trace on unhandled error events",
        "body": "- **Version**: v5.5.0\n- **Platform**: Darwin mbpro 15.0.0 Darwin Kernel Version 15.0.0: Wed Aug 26 16:57:32 PDT 2015; root:xnu-3247.1.106~1/RELEASE_X86_64 x86_64\n- **Subsystem**: events.js\n\nI am getting the following error in my code:\n\n```\nevents.js:154\n      throw er; // Unhandled 'error' event\n      ^\n\nError: ENOENT: no such file or directory, open '/assets/screencast-preview.png'\n    at Error (native)\n```\n\nUnfortunately, the stack trace doesn't tell me where the error was produced in the code. I was wondering if there was any way to get a longer stack trace on this or if it isn't possible due to the way events are implemented in Node.js.\n",
        "labels": "feature request",
        "id": 43735
    },
    {
        "title": "Improve the error messages instead of the generic \"Error: Cannot find module 'xyz'\"",
        "body": "- **Version**: 4.2.6\n- **Platform**: Windows 10 64-bit\n- **Subsystem**: module.js\n\nHi,\n\nI just had a case where node reported one of my local modules (referenced by `\"my-module\": \"file:../my-module\"`) as missing with the default generic node error:\n\n```\nmodule.js:328\n    throw err;\n    ^\n\nError: Cannot find module 'my-module'\n    at Function.Module._resolveFilename (module.js:326:15)\n    at Function.Module._load (module.js:277:25)\n    at Module.require (module.js:354:17)\n    at require (internal/module.js:12:17)\n    at Object.<anonymous> (C:\\code\\my-service\\server\\server.js:3:23)\n    at Module._compile (module.js:410:26)\n    at Object.Module._extensions..js (module.js:417:10)\n    at Module.load (module.js:344:32)\n    at Function.Module._load (module.js:301:12)\n    at Function.Module.runMain (module.js:442:10)\n```\n\nWhen I looked in the node_modules folder the `my-module` subdirectory was there. From that point on I spent about 30 min to an hour to figure out why node didn't recognize the module that was clearly there.\n\nIn the end it turned out that the entry file for the my-module (specified in package.json `\"main\"`) was missing inside the node_modules\\my-module folder. So the actual fix took about 15 seconds but the time it took to figure out what npm / node where trying to tell me about the error was way too long.\n(for sure I will look immediately for the main file next time, but I'm raising this issue to help others not waste time on the same thing)\n\nMy suggestion would be to add additional checks to see if the \"main\" file for a package is really available at the configured path from package.json ([probably here](https://github.com/nodejs/node/blob/master/lib/module.js#L82)).\n\nSo if the file is missing the node should produce a more helpful error in the future.\n\nPlease let me know what you think about this, once I have some feedback I might work on PR for this.\n\nThanks\n",
        "labels": "feature request",
        "id": 43736
    },
    {
        "title": "net.Socket has no setConnectionTimeout(timeout) method",
        "body": "- **Version**: v5.7.1\n- **Platform**: Mac OSX Yosemite 64bit\n- **Subsystem**: net\n\nCurrently we can only set timeout for an established idle socket, I cannot find a way to set connection timeout. This is missing piece, right?\n",
        "labels": "feature request",
        "id": 43737
    },
    {
        "title": "Functional programming",
        "body": " As everyone knows, Node.js is a JavaScript interpreter. I believe we should focus on a functional language such as Lisp because imperative languages (such as JavaScript) _tell_ the computer what to do instead of _asking_, and why should we decide what the computer should do if it thinks there is a better way of expressing itself? Lisp and Haskell work on the principle that the programmer shows what they want to do, and the interpreter/compiler takes the suggestion and interprets it how it best sees fit. There is no sound reason to be sticking to an unclean imperative language and to make slaves out of technology.\n",
        "labels": "feature request",
        "id": 43738
    },
    {
        "title": "REPL started with replServer doesn't persist history",
        "body": "I'm trying to create a REPL via the programmatic library provided by the built-in repl package (https://nodejs.org/api/repl.html).\n\nI'm doing something like this[1]:\n\n``` js\nvar repl = require('repl')\nrepl.start(' > ')\n```\n\nAnd I'm expecting the commands I enter to be preserved if I open the repl once again later. Not finding that this is the case, I have been trying to setting both `NODE_REPL_HISTORY` and `NODE_REPL_HISTORY` by doing something like this `process.env.NODE_REPL_HISTORY = 'somepath'`. I've tried setting `something` to relative path, absolute path, a folder, a file, a non-existing file and a already existing file. But in all cases, the history is not persisted.\n\nI'm not sure if I found a bug or if I'm doing something wrong but would appreciate any I can get.\n- **Version**: v5.8.0 but reproduced the same issue on every version down to v4.0.0, haven't tested lower versions than that...\n- **Platform**: Darwin Mak.localdomain 15.0.0 Darwin Kernel Version 15.0.0: Wed Aug 26 16:57:32 PDT 2015; root:xnu-3247.1.106~1/RELEASE_X86_64 x86_64\n- **Subsystem**: REPL\n\n[1] In reality I'm doing something bigger, https://github.com/victorbjelkholm/trymodule, but figured a small test-case is better for troubleshooting.\n",
        "labels": "feature request",
        "id": 43739
    },
    {
        "title": "Cannot require peer module from npm linked module",
        "body": "Only similar issue I found here is #3402, but frankly I got lost in discussion over there and perhaps this is something different.\n\nI have setup small repository to reproduce this: https://github.com/FredyC/npm-link-peer-require. Information about issue are pretty much in README file. Here I would like to explain use case for this.\n\nWe have a _core_ module which contains various calculations and logic. Then there is a _data_ module which simply exports settings for this _core_ module. We don't want this _core_ module to be coupled together with _data_ as we want to be able to use different versions of the _data_ module based on different scenarios. Essentially \"use whatever is installed there without considering compatibility\".\n\nUsing `npm link` seems like ideal tool for this as we can simply checkout branch within the _data_ module and experiment with different settings without hassle of actually publishing this anywhere or to make weird copies into _node_modules_ directory.\n\nPlatform: Windows 10 Pro x64 Build 10586\nNode: 5.8.0\nNPM: 3.7.3\n",
        "labels": "feature request",
        "id": 43740
    },
    {
        "title": "Feature request: please provide a built-in version manager with Node",
        "body": "Please provide a built-in, platform independent node version manager with the official Node installation packages. Something like `nvm` or [nvm-windows](https://github.com/coreybutler/nvm-windows), but cross-platform with identical CLI UIs.\n",
        "labels": "feature request",
        "id": 43741
    },
    {
        "title": "Need Debug Symbol (PDB) for Windows platform",
        "body": "Hey Guys,\nJust noticed node.pdb was not shipped with the official node release. Can we please bring this back?\n\nThis is extremely helpful for postmortem debugging node application on windows platform. I don't like to build whole node because just want the PDB file.\n\nthanks,\nWei\n",
        "labels": "feature request",
        "id": 43742
    },
    {
        "title": "buffer: proposal for buffer.replace(sub, newSub [, options]))",
        "body": "- **Subsystem**: `buffer`, (`streams`)\n\n/cc @trevnorris \n\nI was wondering whether a `buf.replace()`, that would similarly work like `str.replace()`, was ever considered. As far as I see it would be useful sugar, since it reduces lots of boilerplate around either returning a new buffer or altering the existing one safely. \n\nI came to this, while wanting to (string) replace buffers in streams, where conversion seemed slow.\n\nMaybe I am missing something...\n",
        "labels": "feature request",
        "id": 43743
    },
    {
        "title": "vi style bindings in node interpreter",
        "body": "I have vi style bindings enabled in my `.inputrc`\n\n```\nset editing-mode vi\n```\n\nI have used these successfully in python's intrpreter and ruby's interpreter, but they do not seem to work correctly with node.\n\nIn this case,  none of the key binds work except of `b`, which will move backwards once then glitch out and no longer work.\n\n**_Edit:_** \nWhen I disable vi style bindings in the `.inputrc`, the ruby and python interpreters behave in the same manner as node.\n- **Version**:  v5.7.0\n- **Platform**: Darwin marmot 14.5.0 Darwin Kernel Version 14.5.0: Tue Sep  1 21:23:09 PDT 2015; root:xnu-2782.50.1~1/RELEASE_X86_64 x86_64\n",
        "labels": "feature request",
        "id": 43744
    },
    {
        "title": "feature request: tools: show linting progress / parallelize linting",
        "body": "- **Version**: master\n- **Platform**: n/a\n- **Subsystem**: `tools`\n\nIn light of #5595, it would be nice to have some kind of progress output when linting, similar to what we have when running tests.\n\nAdditionally, it would be nice to have a `-J` option to parallelize linting (like the test runner).\n",
        "labels": "feature request",
        "id": 43745
    },
    {
        "title": "feature request: checkClientIdentity() for tls.createServer() (TLS core module)",
        "body": "What if I own CA certificate and issue certificates for my clients.\nI have a separated server for each client groups and I wish to prevent using certificates issued for one group by another group. I.e. I wish to avoid interchangeability of certificates. ServerA should serve for groupA, but ServerB should reject requests from groupA and viÑe-versa.\nSo I wish to check some certificate data (CN or SerNum) on my servers.\n\nBut it seems like tls.createServer() does not have such an option as checkClientIdentity() callback.\nhttps://nodejs.org/api/tls.html\nInteresting that tls.connect() have checkServerIdentity(). But tls.createServer() does not have checkClientIdentity(). It looks a bit inconsistently.\n\nI could use CRL, but it would be too big in my case.\n\nSo I suggest to add checkClientIdentity() callback support for tls.createServer() options.\n\nInteresting that in documentation for node 0.12.x on the contrary, checkServerIdentity() is supported for tls.createServer(). And there is no checkServerIdentity() suport for tls.connect().\nIt looks too weird, but it is so.\n**Probably it is documentation bug for 0.12.x.**\nhttps://nodejs.org/docs/latest-v0.12.x/api/tls.html#tls_tls_createserver_options_secureconnectionlistener\n\nIf not, is there undocumented checkServerIdentity() for tls.createServer() which is supported for back compatibility and which I could use as checkClientIdentity()?\n",
        "labels": "feature request",
        "id": 43746
    },
    {
        "title": "Feature request: Add path.split() as a counterpart to path.join()",
        "body": "It's weird that `path.join('foo', 'bar')` exists while for the reverse you have to use `'foo/bar'.split(path.sep)`.\n\nCan we implement `path.split('foo/bar')` for consistency? I can PR if agreed.\n\n_NB. there was an issue years ago titled \"[path.split() needed](https://github.com/nodejs/node-v0.x-archive/issues/1224)\" but the discussion morphed into one about getting path.parse() implemented, and path.split() never happened._\n",
        "labels": "feature request",
        "id": 43747
    },
    {
        "title": "`Require` with a relative path should take into account it comes from a symbolic links",
        "body": "Please have a look at this gist for context: https://gist.github.com/julienw/7c31988d43b639dcfde2\n\nBasically we have 2 files in 2 different directories. Yet in one another directory we have 2 links to these 2 files. If file1 has `require('./file2')` it will fail because node's require is looking only in the \"real\" directory where file1 is. I suggest to augment this behavior to look both in this directory and where the symbolic link is located.\n\nI understand it's not very easy to do given the current code as node doesn't keep track that it loaded the file from a symbolic link in the first place. I'd be happy to contribute with some guidance.\n",
        "labels": "feature request",
        "id": 43748
    },
    {
        "title": "Crypto: Certificate class lacks functionality",
        "body": "- **Version**: V5.6.0\n- **Platform**: Windows 8.1 64-bit\n- **Subsystem**: Crypto\n\nThere is (AFAICT) no way to parse certificates and get data from that.  It would be nice to be able to use PKIX components without knowledge of ASN.1.  Something like provided by Java should work for most people.\n",
        "labels": "feature request",
        "id": 43749
    },
    {
        "title": "Crypto: Missing - get PublicKey from PrivateKey",
        "body": "- **Version**: V5.6.0\n- **Platform**: Windows 8.1 64-bit\n- **Subsystem**: Crypto\n\nI'm a new user of \"node.js\" who have mainly used JBoss/Tomcat before.\nIn Java there is a \"Key\" concept that allows you to get meta data from keys regardless how the keys are stored which is very practical and sometimes necessary.\n\nIn node.js the only (documented) way to use private keys is importing them through PEM-files. Here is my problem: I **need** the public key which is a part of all private key containers but I can't get it without decrypting the container which feels very awkward since this is already done somewhere in the Crypto module:\n\nhttps://github.com/cyberphone/node-webpki.org/blob/master/README.md#using-certificates\n\nIt would be awfully nice if there at least was a method for returning the public key without having to decrypt it yourself.\n\n``` Javascript\nCrypto.getPublicKeyFromPrivateKey(private_key[,encoding])\n```\n",
        "labels": "feature request",
        "id": 43750
    },
    {
        "title": "Request for Native Websocket which is supported on HTTP socket",
        "body": "there are 5 websock libraries\n\nhttp://stackoverflow.com/questions/16392260/which-websocket-library-to-use-with-node-js\n\nIf you have event base sockets and handling already, websocket itself isn't a lot to implement\n\nhttps://github.com/d3x0r/SACK/blob/master/src/netlib/html5.websocket/client/html5.websocket.client.c\nhttps://github.com/d3x0r/SACK/blob/master/src/netlib/html5.websocket/server/html5.websocket.c\nhttps://github.com/d3x0r/SACK/blob/master/src/netlib/html5.websocket/html5.websocket.common.c\n(some structures defined in .h files nearby)\n\nMaybe that one can get a websock object from the HTTP?\nOr maybe I'm msising something and the HTTP connection has a mode it goes into to support length-data transmissions bi-directionally?\n\nThat's all websock is once it negotiates is a UTF-8 -esqe encoding of lengths... most implementations didn't go over 16k fragments.\n",
        "labels": "feature request",
        "id": 43751
    },
    {
        "title": "Feature request: better crypto error messages",
        "body": "- **Version**: master\n- **Platform**: N/A\n- **Subsystem**: crypto\n\nI noticed today when working with public keys and verifying signatures that I would get generic error messages when there was a problem reading a public key, for example: `PEM_read_bio_PUBKEY failed`\n\nWhereas if I check the OpenSSL error stack, I find more detailed/useful error strings, for example:\n\n```\nerror:10067066:elliptic curve routines:ec_GFp_simple_oct2point:invalid encoding\nerror:10098010:elliptic curve routines:o2i_ECPublicKey:EC lib\nerror:100D708E:elliptic curve routines:ECKEY_PUB_DECODE:decode error\nerror:0B07707D:x509 certificate routines:X509_PUBKEY_get:public key decode error\nerror:0906700D:PEM routines:PEM_ASN1_read_bio:ASN1 lib\n```\n\n(The first being the most useful probably)\n\nIt would be great to have _at least_ the first error message instead of the more generic one.\n",
        "labels": "feature request",
        "id": 43752
    },
    {
        "title": "child_process spawn arg string handling",
        "body": "Suggestion: support args strings split by space\nExample:\n`node -e \"r=require('child_process').spawnSync('ls', ['-lh /var']); console.log(r.error);\"`\nIn such case `['-lh /var']` will not work and also won't pass any error to `r.error`.\nExpected behavior from `spawnSync` is to split `'-lh /var'` into `['-lh', '/var']` or pass a relevant error.\n- **Version**: v4.2.6\n- **Platform**: Ubuntu 14.04 LTS 64bit\n",
        "labels": "feature request",
        "id": 43753
    },
    {
        "title": "Ability to obtain the default gateway",
        "body": "I think it would be very useful to have a method on `os` which returns\n- the default gateway of the machine, v4 and v6\n- the default gateway's network interface name (if any)\n\nBasically, something like @indutny's [netroute](https://github.com/indutny/node-netroute) but cross-platform. The ability to access this information seems critical for applications that do low-level things on the local network and I think this justifies its existance in core. My personal use case would be to automatically determine the right interface to do packet capture on.\n\nRight now, the only way (without native modules) to obtain the information in a cross-platform way would be parsing the output of various commands, which is of course slow and error-prone.\n\n@bnoordhuis: the request has been brought up in 2012 and you [rejected](https://groups.google.com/forum/#!msg/nodejs-dev/QbcnxS0_yyg/r_yH0D6zgNEJ) it as bloat. Does this still stand?\n\ncc: @sindresorhus (https://github.com/sindresorhus/internal-ip/issues/5)\n",
        "labels": "feature request",
        "id": 43754
    },
    {
        "title": "Add the `mkdtemp` and `mkstemp` methods to `fs`",
        "body": "I would like to propose the addition of `mkdtemp` and `mkstemp` to the `fs` module, to create a temporary directory and file, respectively.\n\nSome manual pages to start with:\n- [linux's mktemp](http://man7.org/linux/man-pages/man1/mktemp.1.html)\n- [libc's mkdtemp](http://man7.org/linux/man-pages/man3/mkdtemp.3.html)\n- [windows' GetTempPath](https://msdn.microsoft.com/en-us/library/windows/desktop/aa364992%28v=vs.85%29.aspx)\n- [python's tempfile](https://docs.python.org/2/library/tempfile.html)\n- [java's createTempFile](https://docs.oracle.com/javase/7/docs/api/java/io/File.html#createTempFile%28java.lang.String,%20java.lang.String%29)\n\nSo, this utility is fairly often needed for various reasons. Not providing it in nodejs itself means that people try to rewrite it, [badly](https://github.com/bruce/node-temp/blob/master/lib/temp.js#L13-L24). (Or may I say, inefficiently.) (I'm obviously not trying to put the blame on someone there, except on node.js for not providing the functions ;-).)\n\nThis is part of the standard library in most other languages. Whether it's C, python, java, and surely others. I believe node.js would benefit its addition as well.\n",
        "labels": "feature request",
        "id": 43755
    },
    {
        "title": "doc,tool: parse standard error types automatically?",
        "body": "Hi guys. I decided to move discussion here from [#5322](https://github.com/nodejs/node/issues/5322#issuecomment-186229820).\n\nCurrently [errors.markdown](https://github.com/nodejs/node/blob/c4b5a451e30b3063a1fbc471052dc9baa8666d6e/doc/api/errors.markdown) has some unresolved links to standard errors description on MDN. Below there is a list of described errors:\n- `EvalError`\n- `RangeError`\n- `ReferenceError`\n- `SyntaxError`\n- `TypeError`\n- `URIError`\n\nAnd also doc tool has [type parser](https://github.com/nodejs/node/blob/c4b5a451e30b3063a1fbc471052dc9baa8666d6e/tools/doc/type-parser.js#L10) with list of global types.\n\nMaybe add these errors to global types list, so it would be possible just use `{SyntaxError}`? Also this would save some bytes.\n",
        "labels": "feature request",
        "id": 43756
    },
    {
        "title": "feature request for assert core module",
        "body": "I have a simple case\r\n\r\n``` js\r\n  .end(function(err, res) {\r\n        assert(err == null,'Error is not null => '+ err.stack);\r\n```\r\n\r\nthe problem is of course, if err is null, the assert message will still get evaluated, so it will throw a new/preemptive error saying \r\n\r\n``` js\r\nUncaught TypeError: Cannot read property 'stack' of null\r\n```\r\n\r\nI know assert is stable and not likely to change, but the feature I am looking for is somthing like this\r\n\r\n``` js\r\nassert(err == null, function(){\r\n  return 'Error is not null => '+ err.stack;\r\n});\r\n```\r\n\r\nthis of course means, that the callback will only be evaluated if the assertion fails\r\n\r\nhope that makes sense, thanks!\r\n",
        "labels": "feature request",
        "id": 43757
    },
    {
        "title": "RFE: node should have a mktemp()",
        "body": "Today it is more and more important being able to create uniqe files and directories, initially only read/writable to the creating user. Node should have such a function and as a node special, supporting something like a \"deleteOnExit\" flag would be very sweet.\n",
        "labels": "feature request",
        "id": 43758
    },
    {
        "title": "Feature request: A way to mock `module`, `require`",
        "body": "There is a commit in `io.js@2.2.0` that modified behaviour of `require`: https://github.com/nodejs/node/pull/1801\n\nI understand that this is a major release but some of very handy modules doesn't work now.\n- https://github.com/tschaub/mock-fs/issues/43\n- https://github.com/bahmutov/really-need/issues/31\n\nFor me it looks like we need some legal way (public API) for mocking module, require, and so on.\n\nI guess I can make a PR if you point me.\n\nRelated https://github.com/nodejs/node/issues/4190\n",
        "labels": "feature request",
        "id": 43759
    },
    {
        "title": "Add an embedding API for Node.js",
        "body": "To enable Node to be embedded into other applications (C++ applications), I would like to propose some new API. In particular, once the Platform, Isolate and Context have been created, a callback would be useful to allow embedders to inject custom code before node begins processing.\n\nI would be happy to put a pull request together with some ideas if this would help.\n\nDoes anyone have thoughts on this, or maybe something already exists.\n\nI've looked at the -r/--require command line flag, but if I understand this correctly this is about processing JS code. I really need access to the underlying V8 (C++) object to register native callbacks, etc...\n",
        "labels": "feature request",
        "id": 43760
    },
    {
        "title": "Warn when wrong version of installed package is required",
        "body": "Say that I have a `package.json` like the following:\n\n``` js\n{\n  \"dependencies\": {\n    \"lodash\": \"^4.3.0\"\n  }\n}\n```\n\nBut in my `node_modules` directory, I have version `3.10.1` of `lodash` installed.\n\nWhen I `require('lodash')` in a program, Node does not warn me that version of the package fails to satisfy my `semver` requirements. This can cause confusing errors, e.g. when one works on a Node.js project and switches to a branch which requires an updated version of a library, but forgets to run `npm install`.\n\nMy suggestion is to modify `require` so that it will verify if the required package is specified as a dependency, and if so, ensure the required package satisfies any semver requirements.\n",
        "labels": "feature request",
        "id": 43761
    },
    {
        "title": "Listen on unix socket in debugger",
        "body": "Is there any limitation to not listen on unix sockets in debugger?\nIf you don't know any limitations then I can try to implement this feature.\n",
        "labels": "feature request",
        "id": 43762
    },
    {
        "title": "Console does not use os.EOL",
        "body": "`console.log` and `console.dir` use hardcoded `\\n` for end-of-line instead of platform specific `EOL` defined in `os` library.\n\n`lib/console.js`:\n\n``` js\nthis._stdout.write(util.format.apply(this, arguments) + '\\n');\n```\n\n`lib/os.js`:\n\n``` js\nexports.EOL = isWindows ? '\\r\\n' : '\\n';\n```\n",
        "labels": "feature request",
        "id": 43763
    },
    {
        "title": "Make native module rerequirable.",
        "body": "I'm a node embedder, using node v4.2.4\n\nIn my situation,\nsometimes, I need to unrequire module.(Which I delete module cache in require.cache).\nsometimes, I need to refresh the global object to clean the symbol.\n\nIn those case,\nthe .node library probably loaded before. after unrequire module or refresh global object, I got error like 'non self-register'.\n\nThe pure JS module and the buildin module are FINE.\n\nSimple test code:\n\n```\nrequire('iconv');\ndelete require.cache[\"C:\\\\Program Files (x86)\\\\nodejs\\\\node_modules\\\\iconv\\\\lib\\\\iconv.js\"];\ndelete require.cache[\"C:\\Program Files (x86)\\nodejs\\node_modules\\iconv\\build\\Release\\\\iconv.node\"];\nrequire('iconv');\n```\n",
        "labels": "feature request",
        "id": 43764
    },
    {
        "title": "Use package.json for module lookup",
        "body": "Hi,\n\nwouldn't it be a good idea to use the package.json in order to resolve a path? If such a file exists, chances are high that a node_modules folder exists and then it can be used.\n\nI'm writing this issue as the package.json can be used for a package lookup of the own package as well. If you work on an example file of a module, you have to specify the module entry file to make it work. It would be cool, if an example (which maybe gets copied over the internet) could have the same require('modulename') as if it would be used outside.\n\nThanks\n",
        "labels": "feature request",
        "id": 43765
    },
    {
        "title": "realpath should expand tilde to homedir",
        "body": "Hi,\n\nI was wondering if I could translate a path beginning with a tilde to the users home path by using `realpath`. The docs say, there is `os.homedir()`, but it would be cool if realpath could do this without having to replace \"~\" with the output of `os.homedir()`. Do you think this would be a good extension? I've seen, PHP has this behavior as well.\n\nThanks\n",
        "labels": "feature request",
        "id": 43766
    },
    {
        "title": "Windows: addons cannot use the bundled OpenSSL",
        "body": "This is basically a copy of nodejs/node-v0.x-archive#4051, since it looks like that repository is obsolete and the problem still exists in the latest version of Node.\n\nIn the Node development package on Windows, the `include` directory has an `openssl` subdirectory with all of the OpenSSL headers, but the `node.lib` libraries do not export those symbols to link against. \n\nThis means that any Node extension that wants to use OpenSSL must instruct its users to follow the instructions at https://github.com/nodejs/node-gyp/wiki/Linking-to-OpenSSL#windows.\n",
        "labels": "feature request",
        "id": 43767
    },
    {
        "title": "Resolve module with symlinks",
        "body": "You can see my original issue at nodejs/node-v0.x-archive/issues/18203\n\nI have been working for a while with link to develop multiple module or simply reuse my local version.\nHowever, every time I link a module using peerDependencies the link just becomes very painful.\n\nFor instance, if I have a structure like\n\n```\npkg1@1.0.0 D:\\temp\\pkg1\nâ”œâ”€â”€ lodash@3.7.0\nâ””â”€â”€ pkg2@1.0.0 -> D:\\temp\\pkg2\n```\n\nAnd for whatever reason `pkg2` tries to require `lodash` then I get the error `Error: Cannot find module 'lodash'`.\nHowever, without the link, it works perfectly.\nAn even greater problem is if I happened to have lodash installed globally it works with the link, but not using the version intended because I could have version 2.8.0 installed globally. \nThis is worst, because you don't get an error, everything runs and at one point it might break and you will have to search everywhere to finally realise you were not using the right version because of your link.\n\nNow I wanted to try to find the source of the problem and maybe fix it.\nI realized that when you require `pkg2` in my example, its path will be `D:\\temp\\pkg2\\index.js` instead of `D:\\temp\\pkg1\\node_modules\\pkg2\\index.js` which result in the resolve paths to be\n\n```\npaths: Array[3]\n0: \"D:\\temp\\pkg2\\node_modules\"\n1: \"D:\\temp\\node_modules\"\n2: \"D:\\node_modules\"\n```\n\nInstead of\n\n```\npaths: Array[4]\n0: \"D:\\temp\\pkg1\\node_modules\\pkg2\\node_modules\"\n1: \"D:\\temp\\pkg1\\node_modules\"\n2: \"D:\\temp\\node_modules\"\n3: \"D:\\node_modules\"\n```\n\nI tried to change the function tryFile in module.js as follow\n\n``` js\n// check if the file exists and is not a directory\nfunction tryFile(requestPath) {\n  var fs = NativeModule.require('fs');\n  var stats = statPath(requestPath);\n  if (stats && !stats.isDirectory()) {\n    return requestPath; // <= Fix: use the symlink directly\n    //return fs.realpathSync(requestPath, Module._realpathCache);\n  }\n  return false;\n}\n```\n\nAnd it works.\n\nI do believe there is a good reason why it resolves the symlink at this point, but I don't know it.\nMaybe a better solution would be to use the parent's modules path as well when resolving modules.\n",
        "labels": "feature request",
        "id": 43768
    },
    {
        "title": "[proposal] Use of a PR approve management system (PullApprove)",
        "body": "I've done my first contribution here (YEYYY :+1:), and I've seen how you handle PRs landing.\n\n@brunocasanova works with us and has shown me [PullApprove](https://pullapprove.com) yesterday as a possible way to enhance our PR approval.\n\nSince it is free for Open-Source projects and **node** has several guys on the TSC, I am proposing the use of it here.\n\nSetup looks simple tough, it works with an `yaml` file placed on the root of the project.\n\nHere are the [docs](http://docs.pullapprove.com/) for further analysis if you're interested.\n\nNote: I am not affiliated with PullApprove at all. Just think it could interesting to you.\n## \n\nGonna ping those who could handle this request for voting.\nping: @bnoordhuis @chrisdickinson @cjihrig @fishrock123 @indutny @jasnell @misterdjules @mscdex @orangemocha @piscisaureus @rvagg @shigeki @trevnorris \n",
        "labels": "feature request",
        "id": 43769
    },
    {
        "title": "Accept a number-like file descriptor on fs module",
        "body": "Hi all,\n\nNew governance, new implementations, but still anoying, and I got only one negative opinion on [my archived issue](https://github.com/nodejs/node-v0.x-archive/issues/7490), without real arguments.\n\nTested on the actual version (5.4.1), although utils is no longer used to test the fd, the problem is the same : we can't make a compatible helper object.\n\nIf everyone shares the indutny opinion, can I have some technical reasons, please?\n\nI 'm still waiting to be able to publish my library, blocked only by that point.\n\nThanks in advance.\n",
        "labels": "feature request",
        "id": 43770
    },
    {
        "title": "Feature Request: get current response headers or unset them alll",
        "body": "https://github.com/koajs/koa/blob/fcacb352208115e60fffe145394f904743dfa8c3/lib/context.js#L121 so we don't have to do hacks like this.\n\nWould like at least one of the following:\n\n``` js\n// get all header keys\nres.getHeaderKeys() // => ['content-type', 'content-length']\n\n// unset all headers\nres.unsetHeaders()\n```\n\nI think (from reading issues a while ago) that all the headers are stored in node as `[ [<key>, <value>] ]` pairs. i don't mind making that public, either.\n",
        "labels": "feature request",
        "id": 43771
    },
    {
        "title": "V8 - Feature Request: Ability to save and load V8 Code Cache",
        "body": "Users want their programs to start faster and save some trunks of time in parsing and compiling. For .NET apps on Windows, Microsoft has provided `ngen.exe` to preheat the JIT engine, and it seemed to work quite well with desktop apps like Paint.NET. However, NodeJS never got such type of functionality, while parsing and compiling JS is actually considered a much heavier job with even more need of caching than dealing with MSIL.\n\nAccording to [Code caching - V8 JavaScript Engine](http://v8project.blogspot.com/2015/07/code-caching.html), V8 has added Code Caching support since 4.2. From [this Chromium Blog post](https://blog.chromium.org/2015/03/new-javascript-techniques-for-rapid.html), Chromium 41 was able to cut down 40% of compile time.\n\nMy initial case is here at https://stackoverflow.com/questions/34883568. It looks silly to call node programs like such, but anyway having more control over what the huge slow process is being applied onto is worth the lossâ€¦\n\nPS. For Chakra (#4765), there seems to be [`JSSerializeScript`](https://msdn.microsoft.com/en-us/library/dn249671%28v=vs.94%29.aspx) and `JsRunSerializedScript`. Just trying to make sure what I am doing is not stopping something else that I am excited about :smile: \n",
        "labels": "feature request",
        "id": 43772
    },
    {
        "title": "Proposal: Add a public API constant to net/http/https Server telling whereas the server is listening or not",
        "body": "It is not the first time that I've faced a situation where I had to check if a server is listening for connections.\n\nI'm familiar with `lib/net`, so unfortunately I had to use `._handle` with a little bit of tweaks.\nIs there any reason why you guys didn't added one?\n\nMy proposal is to place up a method (maybe called `.listening()`) on `net.Server`'s prototype that would return a `bool`.\n",
        "labels": "feature request",
        "id": 43773
    },
    {
        "title": "Lightweight message passing local ipc",
        "body": "Hi,\n\nI need a lightweight local message passing IPC for nodejs. For Unix, this would be [Unix SOCK_SEQPACKET](http://stackoverflow.com/questions/10104082/unix-socket-sock-seqpacket-vs-sock-dgram) local socket. I see Unix Datagram has gone sometime ago, but I now propose support for SOCK_SEQPACKET, what would provide reliable message passing IPC.\n",
        "labels": "feature request",
        "id": 43774
    },
    {
        "title": "Add absolute rule for require module.",
        "body": "Well, consider the follow directory.\n\n``` js\n     - lib\n        + b.js\n     + a.js\n     + package.json\n```\n\nIf b.js need require a.js:\nb.js\n\n``` js\nvar a = require('../a')\n...\n```\n\nWe know Node has support relative path, but if the dir is complex, the relative path will be trouble.\n\n``` js\n   - lib\n        - d1\n           - d2\n            - d3\n             + b.js\n     + a.js\n     + package.json\n```\n\nb.js\n\n``` js\nvar a = require('../../../../a')\n...\n```\n\nSo, Could Node support `absolute path` that use the dir contains package.json and closest to `b.js`  as root ? Like this:\n\nb.js\n\n``` js\nvar a = require('/a')\n...\n```\n",
        "labels": "feature request",
        "id": 43775
    },
    {
        "title": "Installer feature request: Warn on installation of node.js when prerequisites aren't met",
        "body": "I've found myself confused multiple times when I've had npm modules failing to compile properly, only to find hours later that I didn't have a new enough version of gcc installed. It would be great if the process of installing node.js would force you to get your prereqs in line before it let you install. Alternatively, very prominent warnings would be helpful too.\n",
        "labels": "feature request",
        "id": 43776
    },
    {
        "title": "--interactive with --require",
        "body": "Is there any way to make the repl console start with an included script?\nNeither --interactive --eval  nor --require worked here (v5.3.0)\n",
        "labels": "feature request",
        "id": 43777
    },
    {
        "title": "Allow multiple installs of Node on Windows with msi",
        "body": "![image](https://cloud.githubusercontent.com/assets/10532611/12219281/89898dc4-b73d-11e5-9668-1d73aa0cc690.png)\n\nIt should be possible to install different Node versions to different directories with the msi. Actually, many programs like Java JDK, MySQL Server, PostgreSQL or Python version the installs by minor releases by default. It should at least be **_possible**_ (if not the default) to install Node versions like this\n\n```\nC:\\Program Files\\NodeJS\\4.0\nC:\\Program Files\\NodeJS\\5.4\n```\n\n...but the installer either errors or uninstalls the previous version, depending on order of install. People should be allowed to install to whatever location and these separate installs should be uninstallable separately from Control Panel (with their version in the name). The installer should simply have a checkbox (next to \"Add to PATH\") to uninstall the previous version for easy upgrades.\n",
        "labels": "feature request",
        "id": 43778
    },
    {
        "title": "Introducing Promises to node core?",
        "body": "Even though Promises were removed back in the early days, the situation has changed. I propose we re-introduce Promises to Node.js, _(mostly)_ without introducing breaking changes.\n- People [seem to be in favor](https://twitter.com/nzgb/status/685596938822094849) of introducing promises to Node.js\n- Node.js offers [better support for promises](https://iojs.org/api/process.html#process_event_unhandledrejection) than it used to\n- Promises are very popular\n- Promises are now a part of the language\n- Promises play well with generators _(and eventually `async`/`await`)_\n- User-land is filled with things that turn callback-based API into promise-based\n- Newly introduced APIs in browsers consistently offer promise-based continuation -- `fetch`, ServiceWorker, etc.\n#### Encouraging Use of Promises\n\nES6 in and out of itself is encouraging more and more developers to use promises, and if Node.js were to add support for promises that'd send a clear signal to the community that promises have widespread support.\n\n> In a way, **keeping promises out of core is more opinionated than not**.\n\nI understand most noders prefer callbacks, as I used to _(now I don't mind either way)_. However, they're not that terrible to work with if you're familiarized with them. In addition, promises now being part of the language means more libraries leveraging and written around promises. \n#### As a Breaking Change\n\nThis change would break shorthand notation where people write code like this, although in these situations people hardly ever use the return value of `foo`.\n\n``` js\nfunction foo (bar, baz, done) {\n  if (bar) {\n    // instead of \"safer\" fs.readFile(bar, done); return;\n    return fs.readFile(bar, done);\n  }\n  fs.readFile(baz, done);\n}\n```\n\nThat being said it's a very real possibility that introducing a Promise result to callback-based APIs where no responses were assumed could signify a breaking change in cases where poor coding practices are followed.\n\n``` js\nfunction foo (bar, done) {\n  if (!bar) {\n    return new Error('terrible idea');\n  }\n  fs.readFile(bar, done);\n}\n```\n#### Scope\n\nWhile all of the modules below offer callback-based APIs, it wouldn't be that hard to provide promise based APIs for most of these. Particularly because most promise-based methods could be a wrapper around the callback-based API.\n- `readline` methods offering a callback\n- `repl` methods offering a callback\n- `fs` methods offering a callback\n- `util` methods offering a callback\n- `crypto` methods offering a callback\n- `zlip` methods offering a callback\n- `child_process` methods offering a callback\n- `cluster` methods offering a callback\n- `process` methods offering a callback\n- `http` methods offering a callback\n- `https` methods offering a callback\n- `net` methods offering a callback\n- `tls` methods offering a callback\n- `dgram` methods offering a callback\n- `dns` methods offering a callback\n- `stream` methods offering a callback\n\nObviously, the implementation wouldn't have to offer every single callback-based method in a promise-based flavor. For instance, it could start with just `fs` methods.\n",
        "labels": "feature request",
        "id": 43779
    },
    {
        "title": "More customizable module resolution",
        "body": "I am coming from java and maven world and after using npm and node in multi-module project, i think a lot of improvement could be done with module resolution allowing better work with local modules:\nCould node have a parameter (let suppose _--module_resolution_ is this command line option ) to be able to provided a file with mapping between module name and path into the filesystem (like the **NODE_PATH** variable)  ?\n\nThis file could be a map like \n\n``` javascript\n{\n    \"moduleA\" : {\n        \"path\" : \"/path/to/moduleA/version/1.0.0\",\n        \"resolve\" :  {\n            \"moduleA\" : {\n                \"path\" : \"/path/to/moduleB/version/2.0.0\",\n                \"resolve\" : { ... an so on ... }\n            }\n        }\n    },\n    \"moduleB\" : {\n        \"path\" : \"/path/to/moduleB/version/1.0.0\",\n        \"resolve\" : { ... an so on ... }\n    }\n\n}\n\n//This map will look a lot like npm-shrinkwrap.json file but with local path instead of url\n//I will suppose this file is named module-resolution.json\n```\n\nso running \n\n```\nnode /path/to/moduleMain/index.js --module_resolution=/path/to/moduleMain/module-resolution.json\n```\n\nwill have this effect:\n- in the launched module (moduleMain/index.js):\n  - require(\"moduleA\") will resolve to \"/path/to/moduleA/version/1.0.0\"\n  - require(\"moduleB\") will resolve to \"/path/to/moduleB/version/1.0.0\"\n- but in moduleA :\n  - require(\"moduleB\") will resolve to \"/path/to/moduleB/version/2.0.0\"\n\n**Avantages:**\n- allow the same flexibility than nested _node_modules_ folders (multiple version of the same module name, each module being able to import the choosen version)\n- optimize module resolution because there no more need to iterate going up the filesystem tree to find a _node-module_ folder containing the module\n- all modules and version can be installed in one local repository (like npm-cache but with exploded tgz)\n- no need for linking global modules into local _node_module_ folder\n- no need to fetch and install the same dependencies multiple time for multiple modules with the same dependency\n- no more need for linking folders for local dev with multiple modules\n- no need for npm-dedupe\n\nThis file could be generated by modules managers like **npm** or **bower**.\nDifferents modules managers can handle multiple versions differently easily (if a module manager want to only allow one version of a module to be used, it just have to modify this map)\n\nThis file could be agnostic of the resolution of the js file from the module name so externals tools could use this file for _require_ resolution:\nalgorithme like \n`looking for main field in /resolved/path/from/the/map/package.json` for node or webpack\nor \n`looking for typing field in /resolved/path/from/the/map/package.json` for typescript compiler\ncan be let to the executor discretion.\n",
        "labels": "feature request",
        "id": 43780
    },
    {
        "title": "Header parsing bug in http parser",
        "body": "Hello,\nThis server sample illustrates a bug in the http parser:\n\n<pre>var http = require('http');\nvar net = require('net');\n\nvar server = net.createServer((c) => {\n    c.write('HTTP/1.1 200 OK\\r\\n');\n    c.write('Server: bad server\\r\\n');\n    c.write('X-Buggy-Header: a\\nb\\r\\n');\n    c.write('Connection: close\\r\\n');\n    c.write('Content-Length: 4\\r\\n');\n    c.write('\\r\\n');\n    c.write('test');\n    c.end();\n}).listen(9615);\n\nvar options = 'http://localhost:9615/test';\n\nhttp.request(options, (res) => {\n    console.log('never gets here'); })\n.on('error', (err) => {\n    // will read 'Error: Parse Error'\n    console.log(err); })\n.end();</pre>\n\n\nIMO, Despite the invalid header character, an http parser should make a best effort to return output.\n\nBrowsers such as chrome just trim the invalid data and serve the response:\n\n<pre>HTTP/1.0 200 OK\nServer: bad server\nX-Buggy-Header: a\nConnection: close\nContent-Length: 4</pre>\n\n\nBest Regards,\nShachar W.\n",
        "labels": "feature request",
        "id": 43781
    },
    {
        "title": "Feature: allow require('package-name') if there's a package.json with name: \"package-name\" in $CWD",
        "body": "This would make for cleaner example code:\n\n``` js\nvar Editor = require('.')\n```\n\nis less explicit and harder to read than:\n\n``` js\nvar Editor = require('editor-widget')\n```\n",
        "labels": "feature request",
        "id": 43782
    },
    {
        "title": "Proposal: Implement ES6 import syntax to replace require()",
        "body": "Can we have Node use the ES6 import syntax for importing modules?\n",
        "labels": "feature request",
        "id": 43783
    },
    {
        "title": "Add GC Insights",
        "body": "As more and more enterprise customers are using Node.js, the demand for Node.js monitoring increased as well. Node.js already supports a bunch of ways for retrieving interesting information, but GC information is lacking. Many platforms, e.g. the JVM, support means to programmatically retrieve information about GCs. It would be useful if Node.js had these features too.\n\nThe main users for GC insights will probably be monitoring products. The way these products currently access GC information is via native addons that make use of `AddGCEpilogueCallback`. An example open source implementation of this is [node-gcstats](https://www.npmjs.com/package/gc-stats). Strongloop, Ruxit, Instana and others have their own, probably similar implementations.\n\nUsers of such monitoring tools, or more generally users interested in GC activity, need to compile native addons in order to access this information. It is hard to explain why users need to do this (or have a package such as `build-essential` installed). This gets increasingly harder in Java shops which are used to having everything in the platform. Building these addons automatically on install only reduces this problem, but doesn't remove it.\n\nNode.js used to contain post-gc event infrastructure, but it was removed at the end of last year (Dec 2014) by @bnoordhuis with [the following commit](https://github.com/nodejs/node/commit/dab6f681cd8c43351aa56f4deb2e327c8e4c5cfe):\n\n> lib,src: remove post-gc event infrastructure\n> Remove the 'gc' event from the v8 module and remove the supporting\n> infrastructure from src/.  It gets the axe because:\n> 1. There are currently no users.  It was originally conceived as\n>    an upstreamed subset of StrongLoop's strong-agent GC metrics,\n>    but the strong-agent code base has evolved considerably since\n>    that time and has no use anymore for what is in core.\n> 2. The implementation is not quite sound.  It calls into JS land\n>    from inside the GC epilog and that is unsafe.  We could fix\n>    that by delaying the callback until a safe time but because\n>    there are no users anyway, removing it is all around easier.\n> \n> PR-URL: #174\n> Reviewed-By: Trevor Norris trev.norris@gmail.com\n\nI believe that we got users of such functionality (mainly through monitoring products) and that we could fix the implementation (the second argument in the commit comment). For these reasons, I propose to add the removed functionality back to the `v8` module and improve on it, e.g. by [scheduling work](https://github.com/dainis/node-gcstats/blob/74158ed43841ce92c83feaecaa491df7e7532340/src/gcstats.cc#L125) via `uv_queue_work`. I am willing to do this work and open a PR.\n\n_Disclaimer: I am working for [Instana](http://www.instana.com/) and we have a Node.js sensor with GC information._\n",
        "labels": "feature request",
        "id": 43784
    },
    {
        "title": "Proposal: Add indentation to documentation styles",
        "body": "I believe legibility of the documentation could greatly be improved by adding indentation to it, so it will be clearly visible and easy to survey to see which classes are hosting which properties.\n<br/>\nHere's a sketch depicting the suggested grouping/indentation:\n(left panel: current version; right panel: suggestion)\n\n![node indenting](https://cloud.githubusercontent.com/assets/9283914/12056657/0a0fe9b4-af39-11e5-9ec4-e17ea0d0a06c.png)\n\n_As you can see in the left panel, all kinds of information entities are written next to each other without distinction. In the example it's hard to find the corresponding class for the event when you scroll down._\n\n_In the right panel it's easy to relate and distinguish classes and their content from each other. And you can quickly see when the end of an entity description has been reached._\n",
        "labels": "feature request",
        "id": 43785
    },
    {
        "title": "https server should allow changing credentials dynamically",
        "body": "We need to change the certificate info (credentials/secureContext) dynamically while the server is online without having to shut down and start a new server. We have patched node with code that enables this, but it would be nice to have it on upstream as well.\n\nThe API we have is:\n\n---\n### server.setSharedCredentials(secureContext)\n\nUsed to change the server's TLS options such as the server certificate on the fly. `secureContext` must be an instance of `SecureContext` as is created with `tls.createSecureContext()`.\n\n---\n\nAfter the call, if there were active sockets using old context, those sockets will be disconnected next time data is sent over them.\n",
        "labels": "feature request",
        "id": 43786
    },
    {
        "title": "Request: Make configure forwards compatible by putting parenties with prints",
        "body": "Nodejs can not build with python3 currently because print statements use a python 2 idiom.\n\nIt has been pointed out before that node will not build with python3 because of its dependence on gyp which has similar problems but in the mean time we can add a few parenthesis and be more prepared for when compatibility is possible.\n\nSo my request is that we make the code more forwards compatible. \n",
        "labels": "feature request",
        "id": 43787
    },
    {
        "title": "console.error enhancement",
        "body": "I'm not sure exactly how this works and if this is the right place to raise the issue but:\n\nIn the browser (chrome)\n\n``` javascript\nconsole.error(new Error);\n\n// Logs the error and an expandable stack trace.\nError(â€¦)\n    (anonymous function) @ VM297:2\n    InjectedScript._evaluateOn @VM174:878\n    InjectedScript._evaluateAndWrap @ VM174:811\n    InjectedScript.evaluate @ VM174:667\n```\n\nIn node:\n\n``` javascript\nconsole.error(new Error)\n[Error]\n\n// To properly show the stack trace I would have to console.error the stack.\n// In the browser this causes the stack to be visible twice.\nconsole.error((new Error).stack)\n```\n\nIs it possible to make it so that node will automatically add stack traces on console.error?\n",
        "labels": "feature request",
        "id": 43788
    },
    {
        "title": "NodeJS Browser Engine Functionality",
        "body": "It has come to my attention that NodeJS does not provide command line functionality for running pages strictly for GET & POST data from a document. Essentially this would provide an environment for testing communication between the developers client and server from command line. The only way currently to run and execute a clients ability to GET & POST is by spawning the process to a web browser. Debugging requests should be available via command line for robustness and functionality when programming via remote server or the cloud.\n\nExample Usage\nhttp.runFile('./index.html', function (err, req){   // Theoretical\n    if(err)\n          console.log(\"File does not exist\");\n   if (req.method == 'POST') {\n        console.log(\"POST\");\n\n```\n    var url_parts = url.parse(req.url, true);\n    currentQuery = url_parts.query;\n\n    req.on('end', function () {\n        console.log(\"Body: \" + currentQuery['stubScript']);\n    });\n}\n```\n\n}) ;\n\nNOTE : runFile() should do everything that a browser does when source code is sent to it except for the visual information.\n",
        "labels": "feature request",
        "id": 43789
    },
    {
        "title": "rfc: standardize stream.destroy() and pipe",
        "body": "A lot of modules, both internal (fs, net, http) and external (through2 and others) implement `stream.destroy()` and in fact I alway recommend using @mafintosh's [pump](http://npm.im/pump) to pipe streams. That module automatically calls `destroy()` if present, so no file descriptors are leaked in case of an error.\n\nGiven that it is a de-facto standard, we can document it in the stream API, and add a default implementation of it.\n\nMaybe we can even go further and add a pump-equivalent in core, maybe as an option to pipe.\n\ncc @nodejs/streams  \n",
        "labels": "feature request",
        "id": 43790
    },
    {
        "title": "Warn when node-gyp dependencies aren't met.",
        "body": "`node-gyp` is packaged alongside npm and node, but it installs without error or warning when the requirements of node-gyp 3 aren't met. node-gyp v3 requires MS Visual Studio 2013, but when I install node v5.1.0 which uses node-gyp v3.0.3, I see no warnings or errors, but doing things like installing fs-ext fails with lots of compilation errors.\n\nCan the installer check to make sure dependencies are met when node is installed? At very least, a warning would save a lot of people a lot of trouble.\n",
        "labels": "feature request",
        "id": 43791
    },
    {
        "title": "http status code, 451",
        "body": "A new http status code, \"Unavailable For Legal Reasons\".\nThis http code allows us to provide a fair reason when we can't return some data to the client by legal issues. Also, IETF made it standard. https://datatracker.ietf.org/doc/draft-ietf-httpbis-legally-restricted-status/\n",
        "labels": "feature request",
        "id": 43792
    },
    {
        "title": "rfc: Wouldn't UDP be able to benefit from a sendv() function?",
        "body": "Right now if you want to send multiple buffers, you have to concatenate them before calling send(). It seems however that libuv is perfectly fine with receiving a bunch of buffers. I can imagine that in particular use cases, this could speed up message delivery tremendously. Would love to hear thoughts on this.\n",
        "labels": "feature request",
        "id": 43793
    },
    {
        "title": "Proposal: child_process: Send socket but keep it open in parent",
        "body": "The current behavior when sending a `net.Socket` object to a child process using `child_process.ChildProcess.send()` is to close the socket in the parent. This way, only the socket receiver can read and write to it.\n\nProblem: in some use-cases, a user may want to have BOTH parent and child to write to the TCP socket. For instance, I'm developing an app where a process writes data to the socket, whereas another one writes metadata. Sharing the socket in C, not in Node.js (currently).\n\nThe enhancement I propose is to add an optional `keepOpen` parameter to specify whether the parent should keep the socket open or not (it would default to `false` to keep existing behavior).\n\n``` js\nconst child = require('child_process').fork('child.js');\nconst server = require('net').createServer();\n\nserver.listen(1234).on('connection', function (socket) {\n    child.send('socket', socket, { keepOpen: true });\n\n    // Currently this crashes with: \"Error: This socket is closed.\"\n    socket.write('-- hello from parent --');\n});\n```\n\nWhat I'm asking here is whether this is an acceptable enhancement or not. If it is, I'll start working on a clean pull request.\n",
        "labels": "feature request",
        "id": 43794
    },
    {
        "title": "Rename Promise rejection tracking events",
        "body": "The WhatWG HTML standard went with [`unhandledrejection`/`rejectionhandled`](https://html.spec.whatwg.org/multipage/webappapis.html#unhandled-promise-rejections) instead of the camel-cased Node.js events [`unhandledRejection`/`rejectionHandled`](https://nodejs.org/dist/latest-v5.x/docs/api/process.html#process_event_unhandledrejection).\n\nI think Node.js should rename the events while still keeping the old ones as aliases for backwards compatibility.\n\nBeing able to use the same events names everywhere is important for portability.\n\nhttps://twitter.com/malyw/status/674350427845042178\n## \n\n// @domenic \n",
        "labels": "feature request",
        "id": 43795
    },
    {
        "title": "require() from project root",
        "body": "```\nproject/\n  a/b/c/d/e.js\n  h/i/j/k/l.js\n  package.json\n  ...\n```\n\nSuppose in a big project, h/i/j/k/l.js require a/b/c/d/e.js using require(\"a/b/c/d/e\") woule be nice.\nUsing require(\"../../../../a/b/c/d/e\") is too complex and not stable when h/i/j/k/l.js is moving around.\nSo it would be nice if require() has a search path of module's project root.\n",
        "labels": "feature request",
        "id": 43796
    },
    {
        "title": "Rename nextTick",
        "body": "The `nextTick` function doesn't do what the name states, as it is more of like \"current tick\", or \"from C++ into JS land\". How about renaming it to something better? \n",
        "labels": "feature request",
        "id": 43797
    },
    {
        "title": "Add noAssert to Buffer::write",
        "body": "Currently the `new Buffer(string)` constructor calls `utf8Length` and `write`, which can be very slow, because  `Buffer::write` calls [StringBytes::Write](https://github.com/nodejs/node/blob/master/src/string_bytes.cc#L346) and which calls `v8::String::WriteUtf8` with a `buffer` address and its `capacity` same as the `utf8Length` of the string. But `v8::String::WriteUtf8` will be very fast if passed with a `capacity` equals to or larger than three times of the string length (see [here](https://github.com/nodejs/node/blob/770cd229f9638064b6f39b038b2140bbd6a7a543/deps/v8/src/api.cc#L5061)).\n\nSo I think, why don't we manually make sure the capacity of the buffer is large enough, and pass a larger `capacity`  (for example, three times of the string length) to the `WriteUtf8` method, to make it faster?\n",
        "labels": "feature request",
        "id": 43798
    },
    {
        "title": "Compare with REPL, \"node -p\" & \"node -e\" has different default imports packages ",
        "body": "When in REPL, we can use packages such as fs, vm directly by default.\n\nBut in \"node -p\"/\"node -e\", must require these packages manually\n\n```\nnode -p \"fs\"\n```\n\nreturns \"fs is not defined\"\n\nThis makes command line script running such a pain...\n\nTry \"node -p\", then \"not defined\" one found, and then require the missing package manually. Repeat this again and again.\n",
        "labels": "feature request",
        "id": 43799
    },
    {
        "title": "suggestions on standard nodejs library(SNL)",
        "body": "nodejs with npm is very good at library extension.\nand it is very helpful for developers to share and create packages/libraries.\n\nSome of us may have encountered some problems it introduces.\n1. it takes too much time on compiling native extensions\n2. too many optional packages for one purpose without knowing which one is good and which one is not.\n3. some libraries can't be smoothly upgraded to new released nodejs.\n\nso i would like to suggest that we introduce the standard  nodejs library(SNL)  method to reduce the extra installing time and compiling time, and also introduce a test standard for its delivery.\n\nMy simple consideration would be:\n\nSNL can be dynamically adjusted, and can be self-updated\ncan have an editable config.\nprogrammers can edit this map again and again to reduce the installing and compiling time for their specific projects.\n\nso here are some features I would like to suggest:\n1.configuration\n   library.json or new field in package.json\n   a) can be project specific or system wide\n   b) some options can be the same to packages.json\n   c) introduce new fields 'libraries' and 'globalLibraries' \n\n2.global and locally\n  libraries can local or global\n  <code>npm library update</code> to install locally\n <code>npm library update -g</code> to install globally\n\n <code>libraries</code> in config file to introduce local libraries\n <code>globalLibraries</code> in config file to introduce global libraries\n\n3.library fold name: node-libraries, and parallel with node-modules\n\n4.none build-in, though some may shipped officially\n\n5.types of libraries\n\n   a) OFFICIALL\n    maintained by community\n   b) RECOMMENDED\n   well constructed and very popular but not adopted by the community,\n   or hard to determine the feature\n   c) FREE/USER-DEFINED\n   published npm packages but not that popular.\n\n6.Ship with official libraries config but not install it and use <code>npm library init</code> to install official SNL libraries.\n\n7.Versionized, just like packages.json.\n\nthanks.\n",
        "labels": "feature request",
        "id": 43800
    },
    {
        "title": "extended keepalive configuration on socket",
        "body": "Hello,\n\nI think it would be good to be able to configure socket keep alive parameters. Currently keep alive can be enabled - using [socket.setKeepAlive](https://nodejs.org/api/net.html#net_socket_setkeepalive_enable_initialdelay) but the parameters cannot be set.\n\nI understand this is very OS-dependent and I'm not sure it's possible on all supported operating systems - [notes for linux here](http://www.tldp.org/HOWTO/html_single/TCP-Keepalive-HOWTO/).\n\nI would not want to tweak TCP keep alive parameters on system level as it would affect all processes utilising this feature. \nFor example [mongodb driver](https://github.com/mongodb/node-mongodb-native) uses `setKeepAlive` for its connections (if configured so); it would also make sense to be able to configure keep alive parameters - setting `tcp_keepalive_time`, `tcp_keepalive_intvl`, `tcp_keepalive_probes`.\n",
        "labels": "feature request",
        "id": 43801
    },
    {
        "title": "fs: fs.scan (bulk lstat)",
        "body": "For applications that need to scan large filesystem trees (at startup or at occasional intervals), issuing 100,000 or 1,000,000 lstat calls can take anywhere between 100 to 1000 seconds or more.\n\nMuch of this time is spent building the stats object and crossing back and forth between JS and C++.\n\nIt could be much faster to have a new variant of the lstat call, say fs.scan, which can accept an array of up to 1000 paths at a time to lstat, cross into C++, perform the calls, and then pass an array of stats/error results back.\n\nGoing even further, often only a single field (such as mtime or mode) is required, and it would be much cheaper and put less pressure on the GC, if this could be optionally returned (specified via an options argument to the call) instead of instantiating a stats object for each path.\n\nlstat would be the ideal candidate for this kind of bulk call, as opposed to stat, since most scanners use lstat first before resolving symlinks.\n\nIt also need not set a precedent for creating complicated bulk versions of other fs operations, this alone would speed up scanning considerably, and perhaps could be added as a new kind of fs operation specifically intended to help with scanning (e.g. fs.scan), rather than as a bulk version of lstat (e.g. fs.mlstat).\n",
        "labels": "feature request",
        "id": 43802
    },
    {
        "title": "Possibility to specify address family via https.request options",
        "body": "Hi, I'm trying to force Node.js to use ipv6 address while making https.request. I found possibility to provide `family` option with desired type here: https://nodejs.org/api/https.html#https_https_request_options_callback\n\nUnfortunately it does not work :( It uses ipv4 by default.\n\nI tried to look in the code and found out, that https.request doesn't pass any family option to the net module:\nhttps://github.com/nodejs/node/blob/v4.2.2/lib/_tls_wrap.js#L986\nhttps://github.com/nodejs/node/blob/v4.2.2/lib/net.js#L856\nhttps://github.com/nodejs/node/blob/v4.2.2/lib/net.js#L904\n\nSmall code to reproduce: \n\n``` javascript\nvar https = require('https');\nvar url = require('url');\n\nvar urlObj = url.parse('https://google.com/');\nurlObj.family = 6;\n\nhttps.request(urlObj, function (res) {});\n```\n\nrun it using environment variable: `NODE_DEBUG=http,net:connect`\n\nSo, I have a small question: is it a bug? And what's the better way to tell Node.js to resolve hostnames into ipv6 address by default?\n\np.s. I use Node.js v4.2.2\n",
        "labels": "feature request",
        "id": 43803
    },
    {
        "title": "stdout and stderr on Console instances as public API",
        "body": "The `_stdout` and `_stderr` properties on instances of `Console` are underscore-prefixed, indicating that they aren't part of the public API for node. I've run into several cases where I'd like to access these properties, particularly in building and testing CLI tools. Because of their usefulness in that case and probably others, I'd like to open a PR making them full-fledged public API properties, dropping the underscores and documenting the new properties.\n\nI have a few questions before I do:\n1. Since public API would be added to, and not changed, would this count as semver-minor? Or does the removal of the underscore-prefixed properties count as semver-major?\n2. If it would be semver-major, would some kind of aliasing and deprecation notice be preferable?\n\nThere's probably code that exists in the wild that depends on the underscore-prefixed properties, considering their usefulness when dealing with arbitrary `Console` instances other than the global `console`.\n",
        "labels": "feature request",
        "id": 43804
    },
    {
        "title": "Supporting multiple node versions in a single package",
        "body": "Hey,\n\nFirst, not sure if this is the proper place or if this needs to be in multiple places, but...\n\nI just tackled an interesting use case.\n\nClient A is forced to use v0.12.x, Client B is forced to use v4.2.x.\n\nBoth use the same package, but the package is written for ES6 which v0.12.x doesn't really support that well.\n\nI'm wondering what thoughts are about allowing the `main` property in `package.json` to become an object with keys being node semver strings pointing to the file to be loaded that is written for that version.\n\n``` javascript\n{\n    ...\n    \"main\": {\n        \"<=0.12.x\": \"file2.js\",\n        \"4.x\": \"file3.js\",\n        \">=5.x\": \"file.js\"\n    }\n    ...\n}\n```\n\nObviously this introduces quite a bit of complexity to a single package (dependencies for one) and would admittedly be much easier to have two separate packages for each supported version, but this was just a thought.\n\n(I am already using babel and inline version checking to solve this, but I figured it might pop up as features and versions become more prolific)\n",
        "labels": "feature request",
        "id": 43805
    },
    {
        "title": "Decentralized module delivery",
        "body": "I am asking that the TSC begin to explore a future of module delivery for node that is decentralized. Along with this, it should assume control of determining future standards around the use of the package.json. A decentralized approach (as opposed to what today is centralized) for module distribution is safest at scale. The Web itself was designed around this philosophy and it is a useful model for the scale of node.\n\nFurther, the node community and TSC must retain control over the user experience of node. The future of module delivery can and should involve multiple players that deliver according to standards that are developer driven and in consultation with the TSC that can assure this interest.\n\nThe process of moving forward can and should involve the community in determining possible approaches, tests, and be given careful consideration over time since we are now into an LTS approach to releases. This future can evolve with es6 and with the purpose of moving away from the legacy of a single upstream service.\n",
        "labels": "feature request",
        "id": 43806
    },
    {
        "title": "enhance the \"main\" field of the package.json for entry folder",
        "body": "I hope that the \"main\" field can specify a folder as the module entry, so that the root folder can be not polluted by many JavaScript files and folders.\n\nThe file entry should can be distinct from folder entry by a tailing slash.\n\nSay, for the folder structure like below:\n\n```\nfoo\n|----src\n|    |---- a.coffee\n|    |---- b.coffee\n|    \\---- index.coffee\n|\n|----lib\n|    |---- a.js\n|    |---- b.js\n|    \\---- index.js\n|\n|---- .gitignore\n|---- gulpfile.js\n|---- package.json\n|---- license\n\\---- readme.md\n```\n\nAnd with the package.json file as below:\n\n```\n{\n  ...\n  main: \"lib/\"\n  ...\n}\n```\n\nBy this method, we can tell npm to use foo/lib/index.js as the module entry. If there exists only one file in lib/ folder, it will be used, and it should can use other file name.\n\nWe can also use the syntax below to specify a entry file for the \"foo\" module\n\n```\n{\n  ...\n  main: \"lib/ @ path/to/foo-entry.js\"\n  ...\n}\n```\n\nSome spaces before or/and after @ are permitted and can be omitted.\n\nWithout the improvement above, we must write require(\"foo/lib/a\"), require(\"foo/lib/b\"). It's a bit annoying. To avoid this, under the current package.json specification, we must put all the folders and script files under the root folder, like below:\n\n```\n|----src\n|    |---- a.coffee\n|    |---- b.coffee\n|    \\---- index.coffee\n|\n|---- a.js\n|---- b.js\n|---- index.js\n|---- .gitignore\n|---- gulpfile.js\n|---- package.json\n|---- license\n\\---- readme.md\n```\n\nHere two annoying problems exists: \n1. the module's root folder is a mess with mixing the script files and other kind of files. \n2. It's more annoying while we are writing the build script.\n\nE.g. for \"gulp clean\", we need write the code below\n\n```\ndel = require(\"del\");\ngulp.task(\"clean\", function(callback){ \n  del([\"*.js\", \"!gulpfile.js\"], callback); \n})\n```\n\nEspecially while there are a lot of sub folders and scripts in foo/src folder, some code like below need to be written:\n\n```\ndel = require(\"del\");\ngulp.task(\"clean\", function(callback){ \n  del([ \"*/\", \n        \"!doc/\", \n        \"!test/\",\n        // ... other folder should not be deleted \n        \"*.js\", \n        \"!gulpfile.js\",\n        // ... other js files should not be deleted\n      ], callback); \n})\n```\n\nI'm always afraid to delete some other files by mistake while I am doing this.\n\nWith the improvement described as above, we can use `{ ... main: \"lib/\", ...}` in package.json to enable writing require(\"foo/a\"),  require(\"foo/b\") instead, simply. So we can organize the module and api more conveniently, and small sub modules is encouraged.\n\nI think the syntax `{ main: \"entry-folder/\" } or`{ main: \"entry-folder/ @path/to/entry-file.js\" }' will not break the existed package.json. We can talk about this more deeply.\n\nI'm not sure this improvement should be implemented in node.js or in npm. I've also submitted this in the [npm's project](https://github.com/npm/npm/issues/10506).\n\nBelow is the specification for the \"main\" field in the npm's document:\n\n```\nmain\n\nThe main field is a module ID that is the primary entry point to your program. That is, if your package is named foo, and a user installs it, and then does require(\"foo\"), then your main module's exports object will be returned.\n\nThis should be a module ID relative to the root of your package folder.\n\nFor most modules, it makes the most sense to have a main script and often not much else.\n```\n",
        "labels": "feature request",
        "id": 43807
    },
    {
        "title": "Do not send empty TCP packet in _http_outgoing.js",
        "body": "After https://github.com/nodejs/node/commit/99943e189d7abd978cc7798bf768c4487920b365 we send empty TCP packets on `res.end()` in quite many cases. I don't think that it is a serious thing, but it is definitely worth fixing.\n",
        "labels": "feature request",
        "id": 43808
    },
    {
        "title": "require.resolve throws exception",
        "body": "I know it's locked but it's just silly - to just test if module is present we have to try/catch `require.resolve()`\n\nIt's not very common but it does happen and **such hacks are present even in node itself**: https://github.com/nodejs/node/blob/master/lib/repl.js#L38\n\nWould be great if we could either introduce new method or at least add `opts` hash with support for this.\n",
        "labels": "feature request",
        "id": 43809
    },
    {
        "title": "The order of .node_repl_history should be reversed",
        "body": "Currently, .node_repl_history keeps the newest history at the top of the file, and the oldest at the bottom. This is contrary to essentially every other program that uses a similar history file.\n\n.zsh_history, .bash_history, .python_history, .mysql_history, along with many others, all store the oldest at the top and newest commands at the bottom. Presumably, this is done because you can simply append to the file.\n\nOther than node itself, the number of programs that rely on .node_repl_history having the newest at the top is very small, so it's unlikely this change would be problematic.\n",
        "labels": "feature request",
        "id": 43810
    },
    {
        "title": "Node 4.2: Unable to run Node in non-FIPS mode if compiled with FIPS support",
        "body": "As currently implemented, when Node is compiled with FIPS support (`./configure fips`), there is no way to disable engaging FIPS mode during execution. This means that several functions that rely on non-FIPS approved algorithms (e.g. md5 hashing) will fail, as will any code that depends on them (most obviously, `npm`).\n\nWhat seems needed to me is a way to explicitly enable or disable FIPS operation each time node is invoked. The way this is done with the openssl CLI is via the OPENSSL_FIPS environment variable.\n\nIt is straightforward to add a similar capability to Node. A pull request with a suggested implementation is forthcoming.\n",
        "labels": "feature request",
        "id": 43811
    },
    {
        "title": "Add links to previous versions of individual docs",
        "body": "I think it would be extremely useful if each page of the current docs had links to the previous versions of the documentation. I am upgrading from .10 to 4 and have found myself wanting to compare docs between the 2 versions. For example, if I'm looking at the documentation for the cluster module, I would find it helpful to have a link somewhere to jump to a different version of the docs. I think is this is a really important feature since the docs now default to 5.0, while, as far as I know, the vast majority of node users, will be on a previous version. \n",
        "labels": "feature request",
        "id": 43812
    },
    {
        "title": "Node need a new compile tool",
        "body": "when i install something modules with native, i have to install the `vs`, it is too big(GBs). \n\nCan we use the clang compile the native with a new tool like `node-gyp`. beause install it easily.\n",
        "labels": "feature request",
        "id": 43813
    },
    {
        "title": "Use llnode to test post-mortem data",
        "body": "We should consider using https://github.com/indutny/llnode or something else to verify that postmortem data is intact (and still useful) after v8 upgrades.\n\n(Suggested by @ofrobots )\n",
        "labels": "feature request",
        "id": 43814
    },
    {
        "title": "Is it possible to provide binary for FreeBSD",
        "body": "Hi there, I just want to know is it possible to provide the dist binary for FreeBSD just like linux (e.g. https://nodejs.org/dist/v5.0.0/node-v5.0.0-linux-x64.tar.xz), if the work will need contribution, how can I contribute to it? Thanks!\n",
        "labels": "feature request",
        "id": 43815
    },
    {
        "title": "Allow 'data' argument on callback of Transform._flush()",
        "body": "According to the docs, `transform._transform(chunk, encoding, callback)` callback accept optionals error [and data chunk](https://nodejs.org/api/stream.html#stream_transform_transform_chunk_encoding_callback):\n\n> If you supply a second argument to the callback it will be passed to the push method\n\nbut the callback of `transform._flush(callback)` only accept an optional error. According to the code [it would be fairly easy to add](https://github.com/nodejs/node/blob/bb1bd7639554766a88b8f7aef8891bf8249e613e/lib/_stream_transform.js#L118-L120).\n",
        "labels": "feature request",
        "id": 43816
    },
    {
        "title": "fs: rmdir and friends",
        "body": "``` js\nrequire('fs').rmdir(path, fn);\n```\n\nthis operation only works on empty directories\n\nand takes no options\n\n``` js\nfs.rmdir = function(path, callback) {\n  callback = maybeCallback(callback);\n  if (!nullCheck(path, callback)) return;\n  var req = new FSReqWrap();\n  req.oncomplete = callback;\n  binding.rmdir(pathModule._makeLong(path), req);\n};\n\nfs.rmdirSync = function(path) {\n  nullCheck(path);\n  return binding.rmdir(pathModule._makeLong(path));\n};\n```\n\nany practical occasion to remove a directory with contents will not be served by this API effort\n\nso wanting to use it makes the thing error out\n\n``` js\nError: ENOTEMPTY: directory not empty, rmdir 'libsodium-1.0.6'\n    at Error (native)\n    at Object.fs.rmdirSync (fs.js:763:18)\n```\n\nif we're using fs and want to get rid of something we'll need to do untold extraneous recursions on `require('fs').unlink`! But that's not all! Then check to ensure there are no more dirs for unlink!\n\nbeing able to pass flags to the essential and basic command operations from our executable environment is not only unix philosophy, but a simple matter of common use case and common need.\n\nalso why name it `rmdir`?\n\nI would like to see a `require('fs').rm(path, opts, callback)` and this useless operation gotten rid of\n\nUnderstand that I mean no offense here by that, and appreciate seeing the daily brilliance of development around these APIs. There's no reason to avoid development of a competitive alternative to BASH\n",
        "labels": "feature request",
        "id": 43817
    },
    {
        "title": "Enable Vtune profiling support for JavaScript to provide source code level profiling in Nodejs ",
        "body": "When debugging Nodejs application, it's very important and usefull that the developer can get the\nJavaScript Source code line level profiling information.  For example, which sentence of the JavaScript\nsource code is the most hot position, which sentence leads to cache miss etc. All other profiling tools \nsuch as perf on linux system and the build-in profiling tools in V8 can profiling the C++ source code if \nthe symbol information is available. But for the the dynamic JITTed JavaScript code , they can not \nprovided such detailed Source Code Level profiling information. \n\nV8 Javascript engine contains a component which can enable the JavaScript source code\nlevel profiling for the powerful Intel Vtune Amplifier. And this functionality is already enabled by V8\nembedder such as chrome and D8 shell.  The basic idea is registering the code event handler in \nNodejs for V8. Then Vtune profiling tool will be used to do profiling when running NodeJS.\n\nThis functionality will be switched on /off by one runtime flag. And it will be enabled when developer\nprofiling / optimizing the applications.  So it will not lead to any performance impact or correctness issue when running applications under offical senarios. \n",
        "labels": "feature request",
        "id": 43818
    },
    {
        "title": "Built-in clustering mode (automatic / flagged)",
        "body": "why not add built in clustering mode rather than manual . like node auto detect no of cpus and utilize all cpu cores . or better to integrate node-threads-a-gogo  as core for hybrid app \nhttps://github.com/xk/node-threads-a-gogo\n",
        "labels": "feature request",
        "id": 43819
    },
    {
        "title": "util.inspect is not so hot on large typed arrays",
        "body": "Typing...\n\n```\n> x=new Float32Array(100000);\n```\n\n... leads to death and sorrow, as the interpreter decides to `util.inspect(x)`.  \n\nThere are, of course, workarounds, such as\n\n```\n> x=new Float32Array(100000); 0\n```\n\n... but I was wondering if we might be able to do better.  \n\nWhat if we told util.inspect to handle ArrayBuffers and their views a bit differently from other objects?  \n\nNow obviously we don't want to go changing the code for util.inspect any time some new-fangled object that comes on the scene.  However, typed arrays are definitely here to stay and currently growing in popularity.\n\nTwo reasonable courses would be \n\n```\n >  new Float32Array(36)\n [Float32Array: length 36]\n```\n\nor\n\n```\n> new Float32Array(36)\n{ BYTES_PER_ELEMENT: 4,\n  get: [Function: get],\n  set: [Function: set],\n  slice: [Function: slice],\n  subarray: [Function: subarray],\n  buffer: {slice: [Function: slice], byteLength:144}\n  length: 36,\n  byteOffset: 0,\n  byteLength: 4 }\n```\n\nWhat do you think.  Am I crazy?\n",
        "labels": "feature request",
        "id": 43820
    },
    {
        "title": "Why is there no log level for Console?",
        "body": "We have console.info/warn/error, why not have something like process.env.NODE_LOG_LEVEL to control it?\n",
        "labels": "feature request",
        "id": 43821
    },
    {
        "title": "http.get option localAddress not working",
        "body": "Hello! The binding to Local interface option is not working at all.\nThe case: Arch Linux system with two different ethernet interfaces.\neth0: 192.168.0.173/24\neth1: 192.168.0.182/24\nrouting table is\ndefault via 192.168.0.1 dev eth0  metric 280 \ndefault via 192.168.0.1 dev eth1  metric 281 \n\nEvery interface has a listening http server on other end with the address: 192.168.0.1\nSo I'm trying to send a request to each of them with nodejs.\nSample code:\n\n``` javascript\nvar http = require('http');\nvar options = {};\noptions.port = 80;\noptions.host = \"192.168.0.1\";\noptions.path = '/index.html';\noptions.headers = {'Referer': 'http://' + options.host + ':' + options.port + '/index.html'};\n\noptions.localAddress = '192.168.0.182'; //NOT WORKING!! - REQUEST GOING FROM 192.168.0.173!\n\nvar creq = http.get(options);\ncreq.on('response', function (res) {\n    res.on('data', function (chunk) {\n        console.log(chunk);\n    });\n});\n```\n\nI've even tried creating a socket for that request with new net.Socket({ handle: net._createServerHandle( '192.168.0.182')}); and requests kept going from the wrong address.\nThere's workaround with 'curl --interface eth1 ...' that works, but it's not a good solution.\n",
        "labels": "feature request",
        "id": 43822
    },
    {
        "title": "Add Buffer#includes()",
        "body": "For convenience, code clarity, and parity with `TypedArray`. See [`TypedArray#includes()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray/includes).\n\n> The includes() method determines whether a typed array includes a certain element, returning true or false as appropriate.\n",
        "labels": "feature request",
        "id": 43823
    },
    {
        "title": "btoa() and atob()",
        "body": "All major browsers expose the `btoa` and `atob` globals for encoding ASCII strings as base64 and vice versa. It'd be beneficial for the \"isomorphic\" javascript topic if we'd provide these too:\n- https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/btoa\n- https://developer.mozilla.org/en-US/docs/Web/API/WindowBase64/atob\n\nAs for the implementation, we can't `Buffer('string').toString('base64')` because that would encode unicode while `atob` and `btoa` must per spec throw on charcodes > 255. https://github.com/mathiasbynens/base64 looks like a solid implemenation we could pretty much drop in.\n",
        "labels": "feature request",
        "id": 43824
    },
    {
        "title": "detect \"full-icu\" module",
        "body": "Followup to https://github.com/nodejs/node-v0.x-archive/issues/8996\n- The npm module [full-icu](https://www.npmjs.com/package/full-icu) will at `postinstall` time make sure `node_modules/full-icu` contains the appropriate `icudt*.dat` file needed for full ICU support.\n  - it also prints out instructions on how to fire up Node with full ICU.\n- Proposal: somehow detect the special (?) module name `full-icu` in any of the global search paths or local module search paths.  If found && the correct icudt file is present, _automatically set Node's ICU path to point to that `icudt_.dat`  file*\n\nThis will make getting full data as easy as `npm install [-g] full-icu`\n",
        "labels": "feature request",
        "id": 43825
    },
    {
        "title": "util.inherits cannot be used with ES6 classes",
        "body": "I'm experimenting with ES6 classes and noticed I was unable to use `util.inherits` to inherit `EventEmitter` into the prototype of my class. \n\n``` javascript\n'use strict';\nvar util = require('util');\nvar EventEmitter = require('events').EventEmitter;\n\nclass x {\n    constructor() {\n        EventEmitter.call(this);\n    }\n    emitEvent() {\n        this.emit('event emitted!');\n    }\n}\n\nutil.inherits(x, EventEmitter); // Fails\n```\n\nThe error is `TypeError: Cannot assign to read only property 'prototype' of \nclass x {\n    constructor() {\n        EventEmitter.call(this);\n    }\n    emitEvent() {\n        this.emit('event emitted!');\n    }\n}`\n\nI was able to get inheritance to work using `class x extends EventEmitter`, but using `extends` means my class can't be a subclass of anything besides `EventEmitter` unless I make `EventEmitter` the root class.\n\nThoughts on this?\n",
        "labels": "feature request",
        "id": 43826
    },
    {
        "title": "Is `handleEvent` a welcome improvement to EventEmitter?",
        "body": "Hi,\n\nI am considering a PR but want to make sure the change is worthy.\n\nThe current EventEmitter only accepts functions as event handlers. It would be very cool to align this implementation with the standard [EventListener](https://developer.mozilla.org/en-US/docs/Web/API/EventListener) interface, so an Object (with a `handleEvent` function member) can be used as well.\n\nThis approach has these advantages:\n- no need for a `bind` call with listeners using `this`,\n- easy listener removal in case a `bind` was necessary.\n\nThe current `emitXYZ()` implementation is not well suited for listeners of mixed type, performance-wise. We can either add the `typeof` test to each listener, or store handleEvent-based listeners in a separate storage for faster and unified access.\n\nAny ideas, opinions, suggestions? Has this been discussed before?\n",
        "labels": "feature request",
        "id": 43827
    },
    {
        "title": "Node.js Installer to notify new version",
        "body": "Windows:\nJava has windows notification, which will intimate about the new version of java..\nCan we have some thing like this for node. \nNow that we have new version or patch releases are done within every month.. Many of us doesn't look website every day about new version releases.. \nIf there is notification system that alerts about this new versions.This may make most people to upgrade their nodejs versions. \n- Alert everyone if there is security patch releases  where this notifications may be more useful.\n\nLinux/Unix/Mac: I don't have an idea.  If they do have notification system if it has it can alert about the updates.  That would be great.. \n",
        "labels": "feature request",
        "id": 43828
    },
    {
        "title": "Add Promise.ify() method",
        "body": "Most new async features to ES will use promises rather than callbacks, but most existing features in node uses callbacks. This is true both for built in features (like `fs`) and most existing libraries. It is therefore common to convert existing node features from using callbacks to using promises, and there exists several libraries that can do this: [denodeify](https://www.npmjs.com/search?q=denodeify).\n\nThis is a proposal to extend the built in feature `Promise` with a simple static function for converting callback based functions to promise returning functions. It would work like this:\n\n``` js\nconst fs = require('fs');\nconst readFile = Promise.ify(fs.readFile);\n\nreadFile('myFile.txt').then(v => console.log(v);\n```\n\nThis would make it a standard part of the node environment and would make it easier to transition from callback based functions to promise returning functions. \n",
        "labels": "feature request",
        "id": 43829
    },
    {
        "title": "Suggestion: stream.read(buffer, offset, length, callback)",
        "body": "I am not sure if this is possible with the design of libuv and Node, but it would be great to be able to do:\n\n`stream.read(buffer, offset, length, callback)`\n\n`buffer` is the buffer that the data will be written to.\n\n`offset` is the offset in the buffer to start writing at.\n\n`length` is an integer specifying the number of bytes to read.\n\nEspecially for net and tls sockets.\n\nI am not sure if Node itself currently manages and re-uses the underlying buffers for net sockets? But if not, then this would make it possible to do static memory allocation in a server. In the past, streams did not support pull mode at all, now they support pull mode, but the user still has no control over the allocation of the underlying buffers, so this creates more allocations and more work for the GC.\n\nI am working on a client-side program at the moment and am finding that V8's GC is just too lazy. Things work and eventually get collected but memory usage climbs and climbs. I would like to have more control and rather statically allocate buffers and re-use them. This would also have a positive side-effect of controlling queue sizes and workloads in various parts of the program more explicitly.\n",
        "labels": "feature request",
        "id": 43830
    },
    {
        "title": "FR: Rewrite libs in ES201{5/6}",
        "body": "It would nice to have [lib](https://github.com/nodejs/node/tree/master/lib) in `ES201{5/6}` now that we support few features, did not `const` being used widely, we could bring in others as well?\n",
        "labels": "feature request",
        "id": 43831
    },
    {
        "title": "SIGINT hardcoded to Ctrl+C?",
        "body": "I've had to remap my SIGINT to a different key via `stty`:\n\n```\nstty intr \\^K\n```\n\nNow `^K` performs interrupts correctly in all GNU apps I tried. `node`, however, ignores `^K` sequence, it still responds to `^C`, which no longer should send SIGINT.\n",
        "labels": "feature request",
        "id": 43832
    },
    {
        "title": "Expose up-to-date list of builtin modules",
        "body": "npm's [`normalize-package-data`](http://npm.im/normalize-package-data) needs a list of built in node modules in order to warn against potential package name conflicts (see [`fixNameField`](https://github.com/npm/normalize-package-data/blob/f7ea85c65632cfc9f37ba6821813ad6aa88e5a80/lib/fixer.js#L197-L213).\n\nWe used to have the list hardcoded, and then @sindresorhus was kind enough to author an external package that would maintain such a list, [`is-builtin-module`](http://npm.im/is-builtin-module).\n\nIt seems that this list is best maintained by node itself, since there's always a risk of things going out of sync or being just plain _wrong_. Would it be possible to expose this directly through some built-in value in node?\n\nRef: https://github.com/nodejs/node/pull/3299/files#r41686776\n\ncc @Fishrock123 \n",
        "labels": "feature request",
        "id": 43833
    },
    {
        "title": "Node Debugger Should Make IP Address Configurable",
        "body": "Hi, \n\nToday the Node debugger forces all debug processes to run on the loop back IP of 127.0.0.1.\n\nSee: https://github.com/nodejs/node/blob/f55926a1f03a0127b7bf40c39a6dd5bc79f77a65/lib/_debugger.js#L1619\n\nBut there cases where you might want to expose a remote debugger port that's not just on the loopback interface. For example, on 0.0.0.0 instead. Otherwise, as it is implemented today, remote debugging is not possible -- since the use of the loopback forces all client connections to the node process to be local.\n",
        "labels": "feature request",
        "id": 43834
    },
    {
        "title": "Add option to child_process.spawn to send SIGHUP on exit",
        "body": "One problem we run into quite often is that we have one process spawn other, potentially long-running processes, and would want those child processes to be cleaned up when the parent process dies. Right now achieving that in node is fragile at best. There are known workarounds but most are either unreliable (`process#exit` handlers aren't guaranteed to be called) or require control over the spawned process (e.g. to add an IPC channel and listen for it closing).\n\nThe proposal here is to add a new option (e.g. `sendHUP` or `nohup`) to `child_process.spawn` that automatically sends `SIGHUP` to the spawned children when the node process exits. I'm not even sure if it's possible to do this reliably in face of unclean exits of the parent etc. but it would be a neat feature to have.\n\n(Came up in https://github.com/isaacs/node-tap/pull/175)\n",
        "labels": "feature request",
        "id": 43835
    },
    {
        "title": "Make it easier to debug unhandled error events",
        "body": "We all hard-working developer fear this infamous error:\n\n```\nevents.js:141\n      throw er; // Unhandled 'error' event\n            ^\nError: This socket is closed.\n    at Socket._writeGeneric (net.js:638:19)\n    at Socket._write (net.js:692:8)\n    at doWrite (_stream_writable.js:292:12)\n    at writeOrBuffer (_stream_writable.js:278:5)\n    at Socket.Writable.write (_stream_writable.js:207:11)\n    at Socket.write (net.js:616:40)\n    at Socket.ondata (_stream_readable.js:521:20)\n    at emitOne (events.js:82:20)\n    at Socket.emit (events.js:169:7)\n    at readableAddChunk (_stream_readable.js:146:16)\n    at Socket.Readable.push (_stream_readable.js:110:10)\n    at Pipe.onread (net.js:521:20)\n```\n\nThey are a pain to investigate. Can we make it somehow easier to debug those?\n\nFor example unhandled error events coming from sockets could at least include a better error message saying what kind of socket it is. And what listeners are attached to it. That would help enormously.\n",
        "labels": "feature request",
        "id": 43836
    },
    {
        "title": "Add --silent option to configure",
        "body": "Currently compiling Node.js show one line for each file compiled. Add an `--silent` option like other projects have to only show output on warnings and errors.\n",
        "labels": "feature request",
        "id": 43837
    },
    {
        "title": "Dump pending Writable stream writes",
        "body": "I have found myself in a situation where I'd love to have the ability easily cancel all data that has been backpressured in a `Writable` stream through the `write` calls. Is this something that would be considered for integration if I created a PR?\n\nMore back story on my use case: I'm developing the a command line interface for embedded hardware that runs Node.js. I have a `USB.Connection` object that inherits from `stream.Writable` so that I can write to my embedded device through the standard `write` command. When I am deploying code to the device, I pipe several MB into the stream and it can take seconds or minutes to all be processed through `_write` depending on code size. The problem arises when a user sends a SIGINT signal to the deployment process because I need to immediately cancel all pending writes and execute one more `write` to tell the device to cancel the deployment process. This is currently not possible to do.\n\nThoughts?\n",
        "labels": "feature request",
        "id": 43838
    },
    {
        "title": "please provide a way to use system-installed root certificates instead of bundled ones",
        "body": "This is related to https://github.com/nodejs/node/issues/1256.\n\nIn debian and derivatives, and probably other distributions too,\ncertificates are managed and configured system-wide.\nFor example /etc/ssl/certs/ca-certificates.crt which is also user-configurable.\nIt is so expected and useful that it'd be nice to add a configure switch to nodejs\nso that it bundles a custom file, or even better, a runtime switch.\n[Currently i have a patch on nodejs](http://anonscm.debian.org/cgit/collab-maint/nodejs.git/tree/debian/patches/2014_donotinclude_root_certs.patch) partially doing that,\nand i kept it beside me until someone complained it wasn't in the original release.\n",
        "labels": "feature request",
        "id": 43839
    },
    {
        "title": "Adding sticky session policy to cluster",
        "body": "I don't think it would be too hard to implement, and I guess I can do it myself, but I first want to be sure the idea itself is valid because I genuinely wonder why it does not exist ;)\n- Add cluster.SCHED_IP_HASH (as a reference to Nginx's ip_hash instruction)\n- Make the master handle request distributions based on `socket.remoteAddress` (for what it's worth, it will be unsufficient for some egde cases but a good start)\n\nThis would help solve the common need of sticky session at the right place.\n\nAny thoughts on that before I grab my editor?\n",
        "labels": "feature request",
        "id": 43840
    },
    {
        "title": "add support to npm update nodejs",
        "body": "<p>allow syntax like;</p>\n\n\n``` bash\nnpm install --global node\n```\n",
        "labels": "feature request",
        "id": 43841
    },
    {
        "title": "process.versions.icu",
        "body": "This would be useful to test for the presence of ICU and to implement version-specific behaviour. I've been trying to use [`U_ICU_VERSION`](https://ssl.icu-project.org/apiref/icu4c/uvernum_8h.html), but haven't gotten it working yet, if someone wants to take a shot.\n\nRelated: #3007\n",
        "labels": "feature request",
        "id": 43842
    },
    {
        "title": "Crypto library should have a constant-time equality function",
        "body": "[Issue #8560](https://github.com/nodejs/node-v0.x-archive/issues/8560) was archived, but seems no issue was opened for it here.\n\nI note that there is still no constant-time equality method in the converged node.\n",
        "labels": "feature request",
        "id": 43843
    },
    {
        "title": "Automatically add / strip BOM",
        "body": "Node does not add or strip BOM when reading or writing utf16le or utf8 files. User must do it manually in all the text IOs.\n\nIt is especially inconvenient with streams: for example, in reading huge file line by line, user must check the BOM or some variabe (alreadyStripped) for each line.\n\nWould it be handy to entrust these actions to Node?\n",
        "labels": "feature request",
        "id": 43844
    },
    {
        "title": "New Feature: require.resolvePath method.",
        "body": "Given the nature of `npm@3` vs prior which will flatten module structures, one behavior that was possible before is now problematic.  And that is the ability to predict the path of a given child module to `./node_modules/some-child-module/`, as of npm v3, this may well be `../some-child-module/` ...\n\nAs such, I feel it would be beneficial to expose a `require.resolvePath('some-child-module')` method that would return the directory containing the matching module or throw (similar to require itself) if no such module is found.  In this way one can predictably utilize assets from child modules.\n\nI feel that this could either return the absolute path to the module in question, or a path relative to the module/file making the request.  The absolute path in question is probably the easiest to deal with.\n\n---\n\nAs an aside to this, the issue became apparent as I was writing an abstraction module for bootstrap, which would not be predictable because of the path issues at hand.\n",
        "labels": "feature request",
        "id": 43845
    },
    {
        "title": "Need a way to detect end of stream on custom Writable Streams implementing _write",
        "body": "It seems that _write should be called with `null` as the data, when the end of stream is reached.\n\nThe problem I am having is that I need to add additional data to the end of the stream, and the `finish` event should not be emitted until after that is completed. I need a way to control this, so I'm thinking a new `_end` function with a callback, or perhaps a callback on `_write(null)` would do the trick.\n",
        "labels": "feature request",
        "id": 43846
    },
    {
        "title": "Can Node.js be compiled as a DLL rather than a .exe ",
        "body": "Is there an existing .dll file for node that will allow node to be used within the same process space as a C#/.NET application. If not is there anyway to build this .dll easily?\n",
        "labels": "feature request",
        "id": 43847
    },
    {
        "title": "Support multiline input with user `eval` function",
        "body": "Currently, the node repl module has the capability to do multiline input when the error is an `instanceof Recoverable`. Unfortunately, the constructor is not exported from the `repl` module which results in hacky ways to achieve a multi-line REPL experience like node. By exporting the error constructor, consumers could create their own recoverable instances to function identical to before and have multi-line input work naturally.\n\nReferences: https://github.com/nodejs/node/blob/a69ab27ab458385d24676792b75ad1c25b8c30e5/lib/repl.js#L413, https://github.com/nodejs/node-v0.x-archive/issues/8640, https://github.com/babel/babel/issues/1741, https://github.com/blakeembrey/typescript-node/issues/3\n\nEdit: Mostly a question, if it's reasonable to add I can issue a PR for a one-line export change.\n",
        "labels": "feature request",
        "id": 43848
    },
    {
        "title": "debugger: pressing enter doesn't run the latest action",
        "body": "In debugger, after pressing <kbd>n</kbd> and then <kbd>enter</kbd> it goes to the next instruction which is fine. But when pressing  <kbd>enter</kbd> again would be nice to execute the latest action (in this case _next_), like in the older versions. Here is a gif animation using `5.0.0-pre`. But the issue is reproducible in 4.0.0.\n\n![output](https://cloud.githubusercontent.com/assets/2864371/9899919/b07aa3ba-5c65-11e5-9f08-419319cecb20.gif)\n",
        "labels": "feature request",
        "id": 43849
    },
    {
        "title": "Net api servers bind to all configured network interface IPs by default (insecure)",
        "body": "The HTTP server is bound to IPs on all configured interfaces by default. This can lead to unintentional data leaks.\n\nChanging the default binding address to be localhost and ::1 for IPv4 and IPv6, respectively, increases default security which can be overridden by providing a host address in the parameters.\n",
        "labels": "feature request",
        "id": 43850
    },
    {
        "title": "Add dns.resolve that returns all results",
        "body": "Similar to #736, it'd be nice if we had a `dns.resolve` that queries for all results.\n\nWould the Node core maintainers be amenable to a pr that adds this functionality via c-ares, or should such an addition be delayed until after #1013 has been resolved?\n",
        "labels": "feature request",
        "id": 43851
    },
    {
        "title": "provide aÂ way toÂ introduce newÂ encodings for `new Buffer('someString', 'someEncoding')`",
        "body": "In the constructor `new Buffer('someString', 'someEncoding')` Node.js v4.0.0 itself [supports](https://nodejs.org/docs/v4.0.0/api/buffer.html#buffer_buffer) aÂ limited number ofÂ encodings: `'ascii'`, `'utf8'`, `'utf16le'` (aka `'ucs2'`), `'base64'`, `'hex'`, `'binary'`. That's aÂ half ofÂ aÂ dozen. That's notÂ plenty.\n\nAnd that's why aÂ widelyÂ used package [`iconv-lite`](https://www.npmjs.com/package/iconv-lite) (450+ direct dependents, â‰ˆ240+ thousands ofÂ daily downloads) provides aÂ method ([`.extendNodeEncodings()`](https://github.com/ashtuchkin/iconv-lite/tree/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f#extend-nodejs-own-encodings)) that addsÂ aÂ support ofÂ many other known encodings toÂ the `Buffer` API.\n\nHowever, `iconv-lite` doesÂ not seem toÂ work inÂ NodeÂ v4.0.0 wellÂ enough. AnyÂ use of anÂ iconv-lite-provided encoding inÂ anÂ attempt of `new Buffer('someLatinString', 'encodingName')` results inÂ some random output suchÂ as theÂ following:\n\n![(screenshot)](https://cloud.githubusercontent.com/assets/1088720/9831362/56911214-595c-11e5-9f9a-f00bc0c17d21.gif)\n\nIt seems to me that either 0fa6c4a6fc7ed4a2dfe821f1d3a46d5f6ff43e69 wasÂ not enough toÂ fix #1547 orÂ aÂ separate deeper issue exists.\n\nCurrently iconv-lite's [`extend-node.js`](https://github.com/ashtuchkin/iconv-lite/blob/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f/lib/extend-node.js) changes theÂ behaviour of theÂ following methods:\n\n| in `SlowBuffer` | in `Buffer` |\n| :-: | :-: |\n| [`SlowBuffer.prototype.toString`](https://github.com/ashtuchkin/iconv-lite/blob/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f/lib/extend-node.js#L25) | [`Buffer.prototype.toString`](https://github.com/ashtuchkin/iconv-lite/blob/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f/lib/extend-node.js#L100) |\n| [`SlowBuffer.prototype.write`](https://github.com/ashtuchkin/iconv-lite/blob/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f/lib/extend-node.js#L39) | [`Buffer.prototype.write`](https://github.com/ashtuchkin/iconv-lite/blob/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f/lib/extend-node.js#L114) |\n| [`SlowBuffer.byteLength`](https://github.com/ashtuchkin/iconv-lite/blob/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f/lib/extend-node.js#L88) | [`Buffer.byteLength`](https://github.com/ashtuchkin/iconv-lite/blob/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f/lib/extend-node.js#L88) |\n| Â  | [`Buffer.isEncoding`](https://github.com/ashtuchkin/iconv-lite/blob/e285b7c31eb0406cf5a8e3e09bc16fbd2786360f/lib/extend-node.js#L83) |\n\nWhy those changes were enough inÂ Node v0.10 and v0.12 butÂ aren't in NodeÂ v4.0.0?\n\nI may be wrong, butâ€¦Â itÂ seems toÂ me thatÂ inÂ NodeÂ v0.12 theÂ Buffer's constructor [haveÂ used](https://github.com/nodejs/node/blob/archived-io.js-v0.12/lib/buffer.js#L99) `this.write(subject, encoding)` internally butÂ inÂ theÂ current NodeÂ v4.0.0 neither theÂ Buffer's [constructor](https://github.com/nodejs/node/blob/de051757e28e2fd256eb9a64d44bf22a0e0bbf00/lib/buffer.js#L33-L49) norÂ its [`fromString`](https://github.com/nodejs/node/blob/de051757e28e2fd256eb9a64d44bf22a0e0bbf00/lib/buffer.js#L86-L101) helper doÂ that. TheyÂ seem toÂ use [`binding.createFromString(string, encoding)`](https://github.com/nodejs/node/blob/de051757e28e2fd256eb9a64d44bf22a0e0bbf00/lib/buffer.js#L92) (where necessary) or [`allocPool.write(string, poolOffset, encoding)`](https://github.com/nodejs/node/blob/de051757e28e2fd256eb9a64d44bf22a0e0bbf00/lib/buffer.js#L96) and both ofÂ these comeÂ from [`process.binding('buffer')`](https://github.com/nodejs/node/blob/de051757e28e2fd256eb9a64d44bf22a0e0bbf00/lib/buffer.js#L4) andÂ aren't replaced byÂ `iconv-lite`. AndÂ itÂ won't beÂ easy toÂ replaceÂ them fromÂ userland, IÂ suppose.\n\nIs my assumption correct?\n\nWhat should be done in `iconv-lite` (orÂ inÂ Node.js, orÂ inÂ both) forÂ aÂ multitude ofÂ encodings toÂ work inÂ the `new Buffer('someString', 'encodingName')` constructor correctly?\n",
        "labels": "feature request",
        "id": 43852
    },
    {
        "title": "Split changelog",
        "body": "How about spliting changelog.md into separate files by 'major version' principle? Current 6723 lines and halfof megabyte of changelogs are not so good, i think. What do you say?\n",
        "labels": "feature request",
        "id": 43853
    },
    {
        "title": "Can Node.js add API of I18n?",
        "body": "I build native addons of gettext but it read file everytime called. The javascript version isn't well-performed in cache when I want to translate into multiple languages according users' locales. Some language files are so large to cache in memory.\n",
        "labels": "feature request",
        "id": 43854
    },
    {
        "title": "Native XML Parsing in Node.js?",
        "body": "I dunno is it a right place to ask this question.. Can we have native XML parsing like we have for json.. I just googled and found weather v8 has exposed any api's for XML parsing.. Just found this link https://code.google.com/p/v8-juice/wiki/PluginExpatParser\n",
        "labels": "feature request",
        "id": 43855
    },
    {
        "title": "fs.realpath 70x slower than native ",
        "body": "repost of https://github.com/nodejs/node-v0.x-archive/issues/7902 to ensure it is not lost, as per @jasnell suggestion.\n\ncredit goes to @joliss I am merely transplanting the issue.\n\n---\n\nThe [fs.realpath](https://nodejs.org/api/fs.html#fs_fs_realpath_path_cache_callback) function is 70x slower than native C [realpath](http://man7.org/linux/man-pages/man3/realpath.3.html). On my system, fs.realpath takes 32 Âµs, while C realpath takes 0.45 Âµs.\n\nThis is a real problem in the Broccoli build tool, where we need to resolve symlinks in hot code paths. Resolving 1000 symlinked files - not an unusual case - would take 45 ms, slowing down the build considerably. [1]\n\nAs for a solution: I haven't looked at the fs.js source in detail, but it seems we might be able to call the realpath function in the C standard library, where available, instead of using our [own implementation](https://github.com/nodejs/node-v0.x-archive/blob/df205360f5cdf3310a69748e74c636ec011d2e64/lib/fs.js#L1216-L1433).\n\nBenchmark code for Node:\n\n``` js\nvar fs = require('fs')\n\nvar start = Date.now()\nvar n = 10000\nfor (var i = 0; i < n; i++) {\n  if (fs.realpathSync('.') === 'dummy') throw new Error('never happens')\n}\nconsole.log(((Date.now() - start) * 1000 / n) + ' us') // => 32 us on Node 0.11.13\n```\n\nBenchmark code for C:\n\n``` js\n#include <limits.h> /* PATH_MAX */\n#include <stdio.h>\n#include <stdlib.h>\n\n// Adapted from http://stackoverflow.com/a/1563237/525872\n\nint main(void) {\n  char buf[PATH_MAX + 1]; /* not sure about the \"+ 1\" */\n  int i;\n  for (i = 0; i < 1000000; i++) {\n    char *res = realpath(\".\", buf);\n    if (res) {\n      // printf(\"This source is at %s.\\n\", buf);\n    } else {\n      perror(\"realpath\");\n      exit(EXIT_FAILURE);\n    }\n  }\n  return 0;\n}\n```\n\nRun with `gcc -std=gnu99 realpath-benchmark.c -o realpath-benchmark && time ./realpath-benchmark`. This yields 0.45 Âµs per iteration on my Linux system.\n\n[1] We cannot work around this by using naÃ¯ve string concatenation, because [path_resolution(7)](http://man7.org/linux/man-pages/man7/path_resolution.7.html) requires that we resolve symlinks in all path components. Here is a [gist](https://gist.github.com/joliss/3292eda35cd4d564cdd7) to show why this matters.\n",
        "labels": "feature request",
        "id": 43856
    },
    {
        "title": "Enabling POSIX real-time signals",
        "body": "At present, the POSIX real-time signals cannot be trapped in a node application. It would be useful to add this ability so that a signal handler could be attached to, say, `SIGRTx` where `x` is one of the available signals between 0 and `SIGRTMAX - SIGRTMIN` (typically 30 on Linux). Thus, something like:\n\n```\nprocess.on('SIGRT4',function(){...});\n```\n\nor maybe\n\n```\nprocess.on('SIGRTMIN+4',function(){...});\n```\n",
        "labels": "feature request",
        "id": 43857
    },
    {
        "title": "Allow inspecting inherited properties of an object with util.inspect",
        "body": "Example:\n\n``` js\nvar util = require('util')\n\n\nvar obj = {a: 'foo'}\n\nObject.defineProperty(obj, 'b', {\n  value: 'bar',\n  enumerable: false, // hidden\n})\n\n\nvar proto = {c: 'baz'}\n\nObject.defineProperty(proto, 'd', {\n  value: 'qux',\n  enumerable: false, // hidden\n})\n\n\nObject.setPrototypeOf(obj, proto)\n\n\n// currently:\n\nconsole.log(util.inspect(obj, {showHidden: true}))\n// => { a: 'foo', [b]: 'bar' }\n\n\n// proposition:\n\nconsole.log(util.inspect(obj, {showHidden: true, showInherited: true}))\n// => { a: 'foo', [b]: 'bar', c: 'baz', [d]: 'qux' }\n```\n\nI guess, dealing with intricate circular references is going to be a problem. There's already a package for flattening a prototype chain: http://npmjs.com/package/flatten-prototypes but it chokes on complicated cyclic references sometimes, and ignores hidden (non-enumerable) properties.\n\nI've found out that Lodash.js also has `_.toPlainObject` utility which flattens prototype chains and doesn't have problems with recursive references. Although resulting objects still have hidden properties thrown away. Oh well, who needs them anyway :)\n",
        "labels": "feature request",
        "id": 43858
    },
    {
        "title": "Provide C++ ABI version to addons",
        "body": "Some platforms (most notably FreeBSD, MacOSX) use gcc or clang interchangeably. We no longer support compiler identification (https://github.com/nodejs/node/pull/205), but what is needed for addons is know know which C++ library node has been compiled against.\n\nAt node-sass (https://github.com/sass/node-sass/blob/043c56705c663977468551206556d7f3c75ef9c1/src/libsass.gyp#L68) we were using `--stdlib=libc++`  clang option to force the use of Clang's C++ library but that is probably incorrect as this causes issues with `node` engines compiled against GNU `libstc++.so.6`. (Example: https://github.com/strongloop/fsevents/issues/82).\n\nFreeBSD 9 uses oldish GCC (4.2.1 by default) and we need to use some newer add-on compiler to get a decent C++11 support. But we don't know if the user compiles node with `libstdc++.so.6` from gcc 4.8, 4.9 or maybe 5.0, or maybe with clang and links against its `libc++`.\n\nIt would be idea if C++ ABI information made its way into `config.gypi` and into the `process.config` variable.\nWe would love to be able to provide different binary modules for different C++ library configurations (https://github.com/sass/node-sass/issues/733).\n\nSome additional links for reference:\n- [GNU stdlibc++ ABI Policy and Guidelines](https://gcc.gnu.org/onlinedocs/libstdc++/manual/abi.html)\n- [GNU stdlibc++ 5.1 Dual ABI](https://gcc.gnu.org/onlinedocs/libstdc++/manual/using_dual_abi.html)\n- [LLVM \"libc++\" C++ Standard Library](http://libcxx.llvm.org/)\n",
        "labels": "feature request",
        "id": 43859
    },
    {
        "title": "Feature: requestIdleCallback(cb)",
        "body": "This seems interesting and useful, and probably wouldn't be terrifically hard to add to node: https://w3c.github.io/requestidlecallback/\n\nIt just landed in Chrome Canary: https://plus.google.com/+IlyaGrigorik/posts/bPNjgMwcMKs\n\nCould be worth waiting a bit to see how people find it in browsers, or if V8 has any sort of special support for it in upcoming versions.\n",
        "labels": "feature request",
        "id": 43860
    },
    {
        "title": "Feature Request: Event loop introspection",
        "body": "Every once in a while I have a hanging process, and I have no idea why it hangs. It could take me hours to figure it out. It would be great if there were ways to ask the program things like:\n- How many open file descriptors are there? What kinds of things are they: (type [network, file system file, input descriptor], name [\"http connection to &lt;some IP address>\"], etc)?\n- How many waiting timers are there? What callback(s) are associated with them (so you could print out the text of the functions)?\n\nThis would go a very long way in making hanging scripts easier to debug.\n",
        "labels": "feature request",
        "id": 43861
    },
    {
        "title": "crypto: expose OpenSSL's x.509 API",
        "body": "To generate self-signed x.509 certificates and private keys from within an application, modules like [pem](https://github.com/andris9/pem) have to rely on spawning the system's OpenSSL, which is problematic as it can be out of date or worse, not available at all (Windows).\n\nI think it would make sense to expose the following APIs from the bundled OpenSSL through `crypto`:\n- generate a private key\n- generate a self-signed certificate\n- generate dh parameters\n\nAccompaning the above, I could also see the following:\n- read a private key's size\n- read certificate fields\n- read dh parameters's key size\n",
        "labels": "feature request",
        "id": 43862
    },
    {
        "title": "Incorporate suite of hash utilities into node",
        "body": "Following the lead from this closed node.js request [here](https://github.com/joyent/node/issues/7213) and [here](https://github.com/joyent/node/pull/7372), can we please look at the opportunity of adding support for non-crystallographic hash functions into the node core.\n\nThere are many usecases where hash functions (CRC or checksums) can be useful for non-crystallographic purposes and adding this will go a long way to extend the use of node.js as a general purpose desktop and server application development language.\n\nTo shorten the development effort, it may be best to include an existing cross platform, C or C++ based library that has an appropriate license which contains a wide range of hash functions. To this end, I have done some digging and found that one good candidate is the [RHash Project](http://sourceforge.net/projects/rhash). RHash appears to be small, popular, cross platform, and based on the MIT license. All of this may make RHash a good candidate for the backbone of a checksum library for node.\n\nRegarding where to house checksum libraries, It can either be put under _crypto_, although this will likely raise some passionate discussion. Another suggestion is to create a new library called _hash_.\n",
        "labels": "feature request",
        "id": 43863
    },
    {
        "title": "crypto: API changes needed for AES Counter with CBC-MAC (CCM) support",
        "body": "# Overview\n\nI've started work on adding AES CCM support to node. This is part of a larger goal of getting full DTLS support into node. Specifically I need `AES_128_CCM_8` support. Until then, I'm working on a [native module](https://github.com/spark/node-aes-ccm) for the crypto support and helping @Rantanen improve his [DTLS protocol module](https://github.com/Rantanen/node-dtls).\n\nOpenSSL already supports this cipher, so I thought it was a matter of adding the necessary calls. I've since run into a complication with the order of calls required by OpenSSL and how the `CipherBase` class is structured. \n\nI'm looking for some discussion and/or guidance on how to proceed with implementation.\n# CCM Requirements\n\nCCM requires specifying 2 or 3 additional lengths for proper operation.\n- Length of the IV. This is already [available as an argument](https://github.com/nodejs/node/blob/4c06515a2f13c9b0890b374bb3ab3c0740c282e2/src/node_crypto.cc#L2928) and does not present any issues. \n- Length of the authentication tag\n- Length of the plaintext / ciphertext (only required if also specifying AAD)\n## Authentication Tag Length\n\nThe authentication tag length **must** be specified before calling `EVP_CipherInit_ex` with the `key` and `iv` parameters ([source](https://github.com/nodejs/node/blob/4c06515a2f13c9b0890b374bb3ab3c0740c282e2/src/node_crypto.cc#L2950-L2955)). If specified afterwards, OpenSSL returns a buffer full of zeroes.\n## Plaintext / Ciphertext length\n\nThe total plaintext or ciphertext length **must** be specified before setting the AAD ([via `EVP_CipherUpdate` in `cipher.setAAD`](https://github.com/nodejs/node/blob/4c06515a2f13c9b0890b374bb3ab3c0740c282e2/src/node_crypto.cc#L3042-L3054)) and before adding any plaintext ([via `EVP_CipherUpdate` in `cipher.update`](https://github.com/nodejs/node/blob/4c06515a2f13c9b0890b374bb3ab3c0740c282e2/src/node_crypto.cc#L3069-L3093)). If not specified before, `cipher.setAAD` will fail.\n# Proposed API Changes\n\nIn order to provide the 1 or 2 lengths required, some API changes will be needed. This is where some input would be greatly appreciated.\n\nThe requirement for the authentication tag length is needed before the final OpenSSL call of `CipherBase::initiv`. This means `crypto.createCipheriv` and `crypto.createDecipheriv` need additional optional parameters.\n- Add an optional `authTagLength` property to the `options` parameter of `crypto.createCipheriv` and `crypto.createDecipheriv`\n\nThe requirement for the plaintext / ciphertext length depends on using AAD, thus perhaps it makes sense to add an optional parameter to `cipher.setAAD`?\n- Change the signature of `cipher.setAAD` to `cipher.setAAD(buffer, [length])`. The confusing part here is that `length` is **not** the length of the AAD, but the plaintext / ciphertext length.\n\nI'm open to any and all suggestions regarding API signature changes, or even new methods.\n\nWhat does everyone think?\n",
        "labels": "feature request",
        "id": 43864
    },
    {
        "title": "Feature request: fs async methods to return promises if callback is not provided.",
        "body": "Just a possible 'nice to have' feature, to match the current trend of things like the Fetch API etc.\nObviously this would only work in methods where the usual callback is called exactly once. \n",
        "labels": "feature request",
        "id": 43865
    },
    {
        "title": "Optionally log master secrets for TLS connections",
        "body": "Sometimes it's necessary to decrypt your own TLS connections to debug their contents. Wireshark supports this quite nicely with its decryption feature. For non-DH key agreement, you simply provide the private key of the server. However, for DH key agreement, or when you are acting only as a client, that doesn't work. Firefox and Chrome support the environment variable SSLKEYLOGFILE to write the master secrets used to a file, for decryption by Wireshark. It would be great to support this or a similar mechanism for logging master secrets in Node.\n\nKey log format: https://developer.mozilla.org/en-US/docs/Mozilla/Projects/NSS/Key_Log_Format\nHelpful Stack Exchange howto: https://security.stackexchange.com/questions/35639/decrypting-tls-in-wireshark-when-using-dhe-rsa-ciphersuites/42350#42350\nWireshark decryption docs: https://wiki.wireshark.org/SSL\n\n(reposted from https://github.com/nodejs/node-convergence-archive/issues/59).\n",
        "labels": "feature request",
        "id": 43866
    },
    {
        "title": "assert.deepEqual & post-ES5 Data Types e.g. Map, Set, Iterables, etc",
        "body": "Currently `assert.deepEquals` is ignorant of any new native data types introduced in ES6.\n\nFor example, this should probably throw, yet it does not:\n\n``` js\nassert.deepEqual(new Set([1, 2]), new Set([1]))\n```\n\nA good method might be to `deepEqual` against `.keys()` and `.values()`.\n`deepEqual` should also probably work with generic Iterables too.\n",
        "labels": "feature request",
        "id": 43867
    },
    {
        "title": "Path should format when 'base' missing and 'name' and 'ext' exist",
        "body": "This test shows that `name` and `ext` are not taken into account when using `path.format` without a `base`. \n\nThe common usage this is preventing is this:\n\n``` javascript\nvar src = path.parse(srcpath)\nsrc.base = null\nif(src.ext === '') src.ext = '.js'\nsrc = path.format(src)\n```\n\nHowever this doesn't do anything.\n\n``` javascript\nvar path = require('path')\nvar assert = require('assert')\n\n// pulled from https://nodejs.org/api/path.html#path_path_format_pathobject\n/* global describe, it */\n\ndescribe('node path', function () {\n\n  it('should work as documented', function () {\n    assert.equal(path.format({\n      root: '/',\n      dir: '/home/user/dir',\n      base: 'file.txt',\n      ext: '.txt',\n      name: 'file'\n    }), '/home/user/dir/file.txt')\n  })\n\n  it('should not work if missing base', function () {\n    assert.notEqual(path.format({\n      root: '/',\n      dir: '/home/user/dir',\n      ext: '.txt',\n      name: 'file'\n    }), '/home/user/dir/file.txt')\n  })\n\n  it('should show ext and name are irrelevant', function () {\n    assert.equal(path.format({\n      root: '/',\n      dir: '/home/user/dir',\n      ext: '.txt',\n      name: 'file'\n    }), path.format({\n      root: '/',\n      dir: '/home/user/dir'\n    }))\n  })\n\n})\n```\n\nhttps://github.com/nodejs/io.js/blob/master/lib/path.js#L584\n\nI can write a pull request, if anyone else thinks this is a good idea.\n",
        "labels": "feature request",
        "id": 43868
    },
    {
        "title": "fs: expose scatter/gather syscalls writev() and readv()",
        "body": "with the awesome work achieved here by @ronkorving in  https://github.com/libuv/libuv/commit/2bf782777fc5908b7cf13ecb61f117af8c45b9f9 \n\nthe upcoming libuv release will unblock https://github.com/nodejs/io.js/pull/2167\n\nfirst mentioned by @trevnorris in that PR, i think it makes a lot of sense to expose scatter/gather syscalls `writev` and also `readv` from node.js\n",
        "labels": "feature request",
        "id": 43869
    },
    {
        "title": "Detect circular dependencies",
        "body": "As you can see in my SO question here: http://stackoverflow.com/q/31783473/3763850\nThis kind of circular pattern cause a TypeError since the 2nd module has yet to load (or I'm assuming that's the reason for this error), something that makes it hard to write a fluent application with a lot of separations of concerns, or other cases where the circular pattern may be desirable.\n\nIt would be nice if we could raise a flag about it somehow when debugging or in the IDE.\n(I'm developing using IntelliJ IDEA)\n",
        "labels": "feature request",
        "id": 43870
    },
    {
        "title": "Add support for O_NOATIME flag to fs.open",
        "body": "I checked through the source but it doesn't look like O_NOATIME can be passed to fs.open?\n\nfs.fstat on many files with node.js would be much faster if the fd could be opened with O_NOATIME.\n\nFor indexing or backup programs using node, O_NOATIME can significantly reduce the amount of disk activity.\n",
        "labels": "feature request",
        "id": 43871
    },
    {
        "title": "More getHeapStatistics stats",
        "body": "Coming from running JVM services, it'd be great to have a more detailed view into old-space/new-space usage over time, time spent in GC, etc. \n\nI noticed these are being tracked/printed out by v8 when --trace_gc is on (https://github.com/v8/v8-git-mirror/blob/master/src/heap/gc-tracer.cc) but there's no visibility into this from user code. Is there some way to get at this information? \n",
        "labels": "feature request",
        "id": 43872
    },
    {
        "title": "Async methods for JSON.parse and JSON.stringify",
        "body": "Reviving a request made in the old joyent/node repo: https://github.com/joyent/node/issues/7543\n\n> Given that parse/stringify of large JSON objects can tie up the current thread, it would be nice to see async versions of these methods. I know that parseAsync and stringifyAsync are a bit alien in node.js, just the same it is functionality that would be best served against a thread pool in a separate thread internally.\n> \n> Also exposing options for when to use a given level of fallback internally based on the size of the string/object. ex: a 300kb json takes about 12-14ms to parse holding up the main thread. This is an extreme example, but it all adds up.\n",
        "labels": "feature request",
        "id": 43873
    },
    {
        "title": "exit keyword in repl",
        "body": "It would be a really nice feature if the node/iojs repl supported typing in `exit` in addition to ctrl+c to exit out of the repl as a keyword that is effectively `process.exit(0);`\n",
        "labels": "feature request",
        "id": 43874
    },
    {
        "title": "Win: Request to officially build node.dll with releases",
        "body": "There are a lot of discussions around building native addons and the problems with renaming node.exe to iojs.exe, I tried to re-read as many of those as I could before I came here to write this. I am familiar with the `delay_load_hook` flag workaround.\n\nI just want to point out that there are multiple applications now embedding iojs into their applications (e.g. nwjs.exe, electron.exe). Electron actually builds and ships their own `node.dll` for this reason, I believe. Electron users typically rename electron.exe to my-app.exe before shipping their product as well. Additionally, you have to rebuild any 3rd party modules yourself, you can't just use `node-gyp` in a straightforward way as the module developer intended. The end result is that you have to build your module one way to get it to run with iojs via command line or through unit tests and then you have to compile it again, another way, to get it to actually run in Electron and nwjs.\n\nNeedless to say, this is all extremely complicated and a real barrier to getting native modules in electron / nwjs. \n\nIf, however, io.js shipped with node.exe, iojs.exe & node.dll, and all native addons, when built via node-gyp linked specifically to node.dll instead of to an .exe then this would allow any application to embed node without having to worry about the process name. Additionally, it would allow any native addon compiled with node-gyp, without any extra work, to automatically be compatible with any such embedded application. I could then run unit tests against the same binary that I am running in electron, for example. \n\nI know the argument against adding a .dll is that it is aesthetically pleasing to have node bundled all into a single executable and I don't disagree, but the complexity of managing native addons and building them multiple times to run against multiple executables is outweighing that benefit in my mind. Also, we already have node.exe and iojs.exe, so why not have a 3rd as well? On windows people will rarely use node through any means other than the installer anyway, and the fact that there are 1, 3 or 100 files is largely unappreciated.\n",
        "labels": "feature request",
        "id": 43875
    },
    {
        "title": "process.ulimit",
        "body": "It would be great if there was a way for users to change ulimit explicitly from within a io.js/node.js process.\n\nSomething like process.setulimit and process.getulimit.\n\nFor users who don't understand EMFILE, it would make it easier for them to increase the limit especially on OS X without having to use an interim bash script calling ulimit before launching their script.\n\nIt would also avoid having node do something magical like reset the ulimit in the background, and it would expose more of the os capabilities to the user, which is always great.\n",
        "labels": "feature request",
        "id": 43876
    },
    {
        "title": "Improve Path.parse / Path.format combo",
        "body": "We have `Path.format` / `Path.parse` functions.\nThey can be chained which is very convenient.\n\n``` js\nimport Path from \"path\";\n\nlet path = \"/foo/bar/bazz.js\";\nlet pathP = Path.format(Path.parse(path));\n```\n\nCurrently `parse` converts string to an object with such structure\n\n``` js\n{ root: '/',\n  dir: '/Users/ivankleshnin/Projects/demo',\n  base: 'config.yml',\n  ext: '.yml',\n  name: 'config' }\n```\n\nThis object contains denormalized data between `base`, `name` and `ext` key values.\nNow let's try to replace file extension.\n\n``` js\nimport Path from \"path\";\nimport {assoc} from \"ramda\"\n\nlet path = \"/Users/ivankleshnin/Projects/demo/config.js\";\nlet pathP = assoc(\"ext\", \".json\", Path.parse(path));\n/* {...\n  base: 'config.js',  -- these two are \n  ext: '.json',       -- unsynced!\n...} */\nconsole.log(Path.format(pathP)); // extension weren't changed :(\n```\n\nThe simplest task is going to be not so simple?!\nNow if `format` took into consideration `ext` and `name` rather than `base` this could lead to an equal problem with changes to `base` key being ignored. \n\nCan we get rid of this `base` key?  It's always `parsed.name + parsed.ext` formula, not a big deal to make it manually. Example of hidden file parse: `{ base: '.gitignore', ext: '', name: '.gitignore' }` - same rule apply.\n\nWe can probably also implement it in a backward-compatibile way,\nkeeping `base` but using JS getter / setter for it's evaluation.\n",
        "labels": "feature request",
        "id": 43877
    },
    {
        "title": "module: require relative from package root",
        "body": "Hope this hasn't been raised before, i did search..\n\nEveryone has done this:\n\n```\n    var thing = require('../../../../thing');\n```\n\nWhy not add a symbol that resolves to the closest package.json?\n\n```\n    var thing = require('^/thing');\n```\n\nDoesn't have to be a ^.\n",
        "labels": "feature request",
        "id": 43878
    },
    {
        "title": "Handling EMFILE/ENFILE on fs.open",
        "body": "For build tools that interact a lot with the file system (eg, npm, gulp, grunt, glob, and many other of the most popular node libraries, especially used by the overwhelming majority of \"node devs\" who are actually using it for front-end asset tooling), it is very useful to have `fs.open` delay when it hits the process max file limit, rather than fail to open the file.  If every file being opened is guaranteed to be closed eventually, \"just wait until something closes and then try again\" is a pretty good strategy.\n\nThe `graceful-fs` module does exactly this.  It is a copy of the fs module, but with the `open` and `close` methods fancied up so that it handles EMFILE gracefully.\n\nThere are three options to build such a thing.  I've explored all three of them, and they have different tradeoffs.  All three are being repeatedly broken by recent changes in io.js.\n1. Monkey-patch the fs module itself.  This is not good because \"wait on EMFILE\" behavior is not something you want everywhere, so adding it globally is surprising and bad.\n2. Clone the fs module.  The downside here is that it requires evaling \"internal\" code.  Also, it means that the `Stat` objects aren't instanceof `fs.Stat`, and lots of other weird surprising edges.\n3. Write a hand-rolled artisanal copy of the fs module, re-implementing everything in core.  This is tedious and wasteful, and just as prone to eventual breakage.  It means keeping up with every new addition to fs, but it is technically possible.\n\nTo forestall the reader who will inevitably make this claim, I believe that \"well, you shouldn't do that, and if you do, you get what you deserve\" displays a lack of empathy that is incompetence bordering on malice.  If npm and other cli tools stop working, **io.js doesn't work**, and that will limit its uptake in the real world.  We are in this real world where people are doing this, so you can either say \"we don't want users using our software\", or we can come up with a plan to keep enabling this behavior.\n\nAt the very least, we **must** have a smoke test that actually runs graceful-fs's tests, as soon as possible, and reject changes that break it.\n\nSome forward-looking options to take graceful-fs out of the equation and enable more churn in the fs module without breaking everyone:\n1. Add a flag to fs.open, fs.readFile, fs.writeFile, fs.appendFile, fs.readdir, fs.ReadStream, fs.WriteStream (and any others I'm forgetting!) to tell it to catch EMFILE errors, put them in a queue, and re-try the open operation when a fd closes.  In effect, put graceful-fs in core, but make it opt-in per open.\n2. Explicitly bless either the \"monkeypatch\" or the \"clone\" approaches above, and stick to that.\n3. Vendor the `fs` module like we do with streams, so that graceful-fs could require it as a dependency.  Then the divergence between \"use this internal API for speed\" vs \"use the external equivalent\" could be made explicit and handled with magic comments in the build process or something.\n4. Boil the ocean of migrating every module that currently uses graceful-fs to stop trying to do fs operations in parallel and handle EMFILE themselves.  (This is not a realistic suggestion, imo, but included here for completeness.)\n\nI'll be at Node Conf this week, maybe some of us could discuss this further in person.\n",
        "labels": "feature request",
        "id": 43879
    },
    {
        "title": "Feature request: backport node patch for `Array#values`",
        "body": "The `Array#values` function was temporarily removed from v8 because it broke web compatibility.\n\n`node`/`io.js`, however, do not have that concern.\n\nPer https://github.com/joyent/node/issues/25324#issuecomment-104806702, if `io.js` merges in these two commits, `io.js` (and future versions of `node`) will retain `Array.prototype.values` rather than being hindered by web compat concerns.\n\nCan this be brought in to the next non-patch release of `io.js`?\n",
        "labels": "feature request",
        "id": 43880
    },
    {
        "title": "Improve util.deprecate",
        "body": "As discussed in IRC recently with @Fishrock123 it would be nice if the deprecation messages contain a bit more info. Particulary I'd like to see\n- `filename:linenumber` where it happens in userland code. I think this could be parsed off the stack through `new Error().stack` or similar, suggestions welcome.\n- A prefix like `(node)` to identify where the messages come from.\n- An flag like `-print-all-deprecations` to allow more than one print per deprecation to track down all places where it's happening.\n",
        "labels": "feature request",
        "id": 43881
    },
    {
        "title": "http.OutgoingMessage headers API",
        "body": "Atm, `http.OutgoingMessage` has the following headers-related methods:\r\n- `.setHeader(name, value)`,\r\n- `.getHeader(name, value)`,\r\n- `.removeHeader(name)`.\r\n\r\nThere probably should be methods to:\r\n- Check if headers were already sent (like `._headerSent`).\r\n- ~Clear all headers (if they were not already sent).~ â€” Doable with `removeHeader` and `getHeaderNames`/`getHeaders` since #10805.\r\n- ~List all headers that were set, with values.~ â€” Landed in #10805, thanks, @mscdex!\r\n\r\nAll methods that modify headers should error if the headers were already sent.\r\n\r\nReasoning: https://gist.github.com/ChALkeR/26573ff704f987fd5304\r\n",
        "labels": "feature request",
        "id": 43882
    },
    {
        "title": "Plans on incorporating BoringSSL",
        "body": "It won't be near future and I think that you have better things to do (in peculiar with 3.x release and v8 mess) but if #428 is delayed could BoringSSl be an option ?\n\nIn fact it : \n- is can be [build](https://boringssl.googlesource.com/boringssl/+/master/BUILDING) on windows with VC12 \n- it include [chacha20 and poly1305 stream cipher](https://www.zeitgeist.se/2014/08/23/optimize-aes-and-chacha20-usage-with-boringssl/)  that would provide great improvement to mobile (no AES-Ni on arm processor).\n- it seems that google was the origin of the [libressl chacha poly patch](http://bxr.su/OpenBSD/lib/libssl/src/crypto/evp/e_chacha20poly1305.c)\n- they also plan to include more and more libressl fix into boringssl\n\nDon't mind to close this if you find that this is a dumb question.\n\nEDIT : md formatting and more informations.\n",
        "labels": "feature request",
        "id": 43883
    },
    {
        "title": "Return cancel function from process.nextTick",
        "body": "We may want the ability to cancel nextTick()s, similar to clearTimeout, clearImmediate, cancelAnimationFrame, without having to use an extended/wrapped version of nextTick, like [cancellableNextTick](https://npmjs.org/package/cancellable-next-tick)\n\nOr we may not care if this is a user extension and not part of the node core. What is the performance overhead (thinking garbage collection) of using [this wrapped version of nextTick](https://github.com/zenflow/cancellable-next-tick/blob/master/lib/index.js) if nextTicks are created and cancelled rapidly & repeatedly in the timespan 'between nextTicks'?\n\nrelates to joyent/node#25355\n\nps imo nextTick's shouldn't be \"promised\". We should be able to cancel them and we shouldn't be able to cancel any promises.\n",
        "labels": "feature request",
        "id": 43884
    },
    {
        "title": "Accept ArrayBuffer (and typed array/data view?) anywhere Buffer is allowed in the API",
        "body": "That is, update fs, http, streams, etc.\n\nThis is a proposal, but I would think with @trevnorris's work on making Buffer a subclass of Uint8Array, it seems likely to be not too hard...\n\nOn the web the best practice has emerged that when accepting arguments, allow any of ArrayBuffer or typed array or DataView, which is why I think more than just Buffer | ArrayBuffer would make sense.\n\nWhat do people think? @trevnorris, am I understanding correctly that after your work lands this would not be very hard?\n",
        "labels": "feature request",
        "id": 43885
    },
    {
        "title": "EventEmitter API",
        "body": "_Moved from https://github.com/nodejs/io.js/pull/1785#issuecomment-105223952_\n\nSome modules use the internal `_events` object. It's not a good thing, and that probably means that `EventEmitter` is missing some API methods.\n\nAlso `lib/_stream_readable.js` uses the internal `_events` object of `lib/events.js`, which is ok, but not very nice. What makes that a bit worse is that `lib/_stream_readable.js` is also packaged as an external `readable-stream` module.\n\nSamples of `_events` usage:\n- [readable-stream](https://github.com/nodejs/readable-stream)/lib/[_stream_readable.js](https://github.com/nodejs/readable-stream/blob/master/lib/_stream_readable.js#L576):\n  1. `if (!dest._events || !dest._events.error)`\n  2. `else if (isArray(dest._events.error))`\n  3. `dest._events.error.unshift(onerror);`\n  4. `dest._events.error = [onerror, dest._events.error];`\n- [dicer](https://github.com/mscdex/dicer)/lib/[Dicer.js](https://github.com/mscdex/dicer/blob/master/lib/Dicer.js#L91):\n  1. `if (this._events.preamble)`\n  2. `if ((start + i) < end && this._events.trailer)`\n  3. `if (this._events[ev])`\n- [busboy](https://github.com/mscdex/busboy)/lib/types/[multipart.js](https://github.com/mscdex/busboy/blob/master/lib/types/multipart.js#L183):\n  1. `if (!boy._events.file) {`\n- [ultron](https://github.com/unshiftio/ultron)/[index.js](https://github.com/unshiftio/ultron/blob/master/index.js#L79):\n  1. `for (event in this.ee._events) { if (this.ee._events.hasOwnProperty(event)) {`\n\nIt looks to me that there should be methods in `EventEmitter` to:\n- [x] Get a list of all events from an `EventEmmiter` that currently have listeners. This is what `ultron` module does, and I do not see an API for that. Getting a list of events could also be usable for debugging.\n  \n  _Implemented by @jasnell in #5617, will be available in 6.0._\n- [x] _(optional)_ Check if there are any listeners for a specific event. Like `EventEmitter.listenerCount` but using a prototype, like `EventEmitter.prototype.listeners` but returning just the count. This is what seems to be most commonly used.\n  \n  It has a valid API `EventEmitter.listenerCount`, but why isn't it inside the prototype? That makes it a bit harder to find and that could be the reason behind modules using `this._events.whatever` to count (or check the presense of) the event listeners. \n  \n  That's since 75305f3babd9e927e92b0d9b70d8bb026492ebd0. @trevnorris \n  \n  _Solved by #2349_.\n- [x] _(optional)_ To prepend an event. Does the documentation specify the order in which the events are executed, btw?\n  \n  This is what the internal `lib/_stream_readable.js` and the `readable-stream` module do.\n  \n  _Implemented by @jasnell in #6032._\n",
        "labels": "feature request",
        "id": 43886
    },
    {
        "title": "qs: support hierarchical QUERY?",
        "body": "Even though the [RFC3986](https://tools.ietf.org/html/rfc3986#section-3.4) told us the QUERY should be non-hierarchical, but some libraries supported the following QUERY schema:\n\n```\nfoo[x]=foo.x&bar[y]=bar.y\n```\n\nSuch that how about supporting from the core module?\n",
        "labels": "feature request",
        "id": 43887
    },
    {
        "title": "url: resolve() have same API as path.resolve()",
        "body": "I took it for granted that the `.resolve()` methods behaved consistently. Got surprised by the fact that `url.resolve()` only accepts two arguments.\n\n``` js\npath.resolve([from ...], to)\nurl.resolve(from, to)\n```\n\nCould we allow variable number of arguments when resolving URLs as with paths?\n",
        "labels": "feature request",
        "id": 43888
    },
    {
        "title": "Expose the ChildProcess constructor",
        "body": "So I don't have to do stuff like this: https://github.com/isaacs/spawn-wrap/blob/master/index.js#L33-L38\n",
        "labels": "feature request",
        "id": 43889
    },
    {
        "title": "Support mknod",
        "body": "I am working on implementing a union file system on top of fuse and I noticed that `fs` does not have a [mknod](http://man7.org/linux/man-pages/man2/mknod.2.html) binding.\n\nIs there any reason why this couldn't be supported by `fs`? All the other low level primitives needed to cover all the fuse operations are there actually (:+1: on that).\n\nFor now my workaround was to fix this in userland, https://github.com/mafintosh/mknod\n",
        "labels": "feature request",
        "id": 43890
    },
    {
        "title": "Implement console.group",
        "body": "It might be totally impractical to do this properly, so I'll understand if it's immediately closed as wontfix, but a) it'd be really useful, and b) @domenic [sent me here](https://twitter.com/domenic/status/599631379576561664)!\n\nBasically, it'd be really great if there was something vaguely equivalent to `console.group`, as it's incredibly useful for debugging in the browser. I whipped up [node-console-group](https://github.com/rich-harris/node-console-group) which is a very naive implementation (can't handle wrapped lines, etc) but good enough for my current needs - does this seem like something that would be worth fleshing out and adding to io.js?\n",
        "labels": "feature request",
        "id": 43891
    },
    {
        "title": "Provide a `--warn-on-late-sync` flag for tracing synchronous calls",
        "body": "### What\n\nio.js should provide a `--warn-on-late-sync` that would detect whenever a `*Sync` method has been called after the first full round of the event loop and _emit a warning to stderr_.\n\n``` js\nsetTimeout(function(){\n     fs.readFileSync(\"/foo/bar\");\n})\n```\n\n```\n$ io.js file.js --warn-on-late-sync\n\nWarning fs.readFileSync (file.js 3:7) called after a full turn of the event loop has completed. This may cause performance bottlenecks in your code (option --warn-on-late-sync). Please see http://iojs.org/... for more details.\n```\n### Comments about semantics\n- Warnings are only emitted after a full turn of the event loop has happened.\n- Warnings are not emitted in case the process is terminating (that is, in `process.on(\"exit\"` code)\n- Warnings are emitted to the `stderr` stream, preferably with a stack trace \n  ### Why\n\nThis flag would be very useful at finding out performance bottlenecks of hidden `*Sync` calls and alerting users as well as hopefully explaining what they can do about it (switch to non-*Sync) methods. \n### Breaking changes\n\nThis issue contradicts https://github.com/iojs/io.js/issues/1665 by making it opt-in and not opt out, the benefit is that it enables a lot of what that issue enables without breaking any existing code or forcing users to do anything about it. \n### Future PoV\n\nIt can also be a start for a future `--pedantic` flag that warns against the most common performance pitfalls node servers have that can't be alerted from the userland.\n\n(I opened this issue per @Fishrock123 's request of opening a separate issue)\n\nI'm open to naming suggestions of course, I'd like this to be brought up in the TC to see if the committee doesn't find any implementation limitations or compelling reasons not to do this before any work is initiated. This is of course in addition to any comments being welcome on this issue\n",
        "labels": "feature request",
        "id": 43892
    },
    {
        "title": "Missing a way to get local IP address for received UDP message",
        "body": "This is a duplicate of https://github.com/joyent/node/issues/8788\n\nBasically: I have a udp server listening on a port on multiple interfaces - when I get a message on this port, I would like to be able to detect what interface the message was received from.\n",
        "labels": "feature request",
        "id": 43893
    },
    {
        "title": "gripe: deprecating fs.exists/existsSync",
        "body": "After noticing in the node docs that **fs.exists** and **fs.existsSync** were going to be deprecated, I took at look at the iojs docs to see that it had in fact been.\n\nThis is _really annoying_ and seems like it's based out of the assumption that every developer ever is only checking the existence of a file prior to reading/writing in some async context. While I understand the sentiment behind wanting to avoid 'unnecessary abstractions' or race conditions, _this_ is unnecessary.\n\nWhereas I was previously able to handle the checking of a file's existence with a single boolean variable, I'm now given no other option but to either try/catch or make my code async and listen for error events. \n\nThis feels like prescriptivism, as I can't think of a single reason why a stern warning of the potential implications and/or examples of caveats to its use wouldn't have sufficed. \n\nCan anyone help me understand why this was necessary (beyond pushing the all-async-all-the-time paradigm (that doesn't always necessarily apply (particularly in the case of synchronous CLI tooling)))?\n\n**Or perhaps can I just submit a PR that _un-deprecates_ this perfectly good functionality?**\n\nEDIT: _I am happy to provide any additional documentation that is deemed necessary._\n",
        "labels": "feature request",
        "id": 43894
    },
    {
        "title": "TypedArray.slice is missing",
        "body": "This one came in from twitter:\n\nhttps://twitter.com/antumbral/status/593841427420839937\n\n`ArrayBuffer.slice` is there but:\n\n```\n> var ab = new Uint8Array(32)\nundefined\n> ab.slice\nundefined\n```\n",
        "labels": "feature request",
        "id": 43895
    },
    {
        "title": "feature request: built-in support for serialport",
        "body": "",
        "labels": "feature request",
        "id": 43896
    },
    {
        "title": "Reuse TLS sessions in HTTPS client",
        "body": "The HTTPS client created via `require('https').request()` should reuse TLS sessions by default.\n\nSample code:\n\n``` js\nvar sessions = [];\n\nget(function() {\n  get(function() {\n    require('assert').equal(sessions[0].toString('hex'), sessions[1].toString('hex'));\n    console.log('PASS');\n  });\n});\n\nfunction get(cb) {\n  return new Promise(function(resolve, reject) {\n    require('https').request(\n      { host: 'github.com', headers: { connection: 'close' } },\n      function(res) {\n        sessions.push(res.connection.getSession());\n        res.resume();\n        res.on('end', cb);\n      })\n      .end();\n    })\n}\n```\n\n/cc @indutny \n",
        "labels": "feature request",
        "id": 43897
    },
    {
        "title": "Global proxy support",
        "body": "Is it possible? Depends on whether we support both `http` and `socks` proxy, this can be tricky, because you need to proxy DNS queries as well.\n\nThere are times we want io.js `http` and `https` to work with a proxy, globally, be it http or socks. With current design, the best solution one can come up with is to patch `http` and `https` which often results in compatibility problems (because you need to overwrite default `http.request` and Agent).\n\nWithout a global proxy setting, one cannot easily instruct the whole io.js app to use such a proxy. A notable example is oauth modules, which usually depends on some request modules, and they often use it in a fashion that do not allow proxy settings.\n\nI used these 2 repos to workaround the lack of proxy support, but I feel they are not very sustainable given how fast io.js are improving.\n\nhttps://github.com/goinstant/global-tunnel\nhttps://github.com/yahoo/dnscache\n\nLet me know what you think, it can help a certain group of developers a lot (say ppl in tightly controlled corp network, and ppl in china).\n",
        "labels": "feature request",
        "id": 43898
    },
    {
        "title": "tls: api to change tls ticket keys",
        "body": "As discussed briefly in https://github.com/iojs/io.js/issues/1462. Here's the relevant section from [rfc5077](https://www.ietf.org/rfc/rfc5077.txt):\n\n```\n   o  The keys should be changed regularly.\n\n   o  The keys should be changed if the ticket format or cryptographic\n      protection algorithms change.\n```\n\nFor the first point, we need an api (a function?) to change the ticket keys. For the second part, I'm not sure, can these conditions happen?\n",
        "labels": "feature request",
        "id": 43899
    },
    {
        "title": "Range Locked File Access",
        "body": "It would be really nice if one could do range-based file locking with shared read-write access.\n- `filename` - path to the file\n- `offset` - position to start at in the file (bytes)\n- `length` - number of bytes to read\n- `buf` - buffer result\n- `done` - callback for read/write, first param is error, second is buffer, no params releases lock\n\n```\nfs.safeRead(filename, offset, length, function(err, buf){\n  //...\n});\n\nfs.safeWrite(filename, offset, buf, function(err){ \n  //... \n});\n\nfs.safeReadWrite(filename, offset, length, function(err, buf, done) {\n  //read and/or modify the buffer\n  //...\n    //to abort save, without error, call done without second param\n    done();\n  //...\n  //save response - pass new/modified buffer to write out\n  done(null,buf); //will write the updated record\n});\n```\n\nI know this probably needs to go into `libuv` but it is definitely doable on most platforms (windows, linux, osx, freebsd)...\n\nHere's an example of cross-platform file range locking - http://cvs.synchro.net/cgi-bin/viewcvs.cgi/src/xpdev/filewrap.c?view=markup\n",
        "labels": "feature request",
        "id": 43900
    },
    {
        "title": "Allow to add build-in modules on compile time",
        "body": "(Originally published at https://github.com/joyent/node/issues/14354)\n\nNode.js convert build-in modules (child_process, path...) to C++ sources and add them to the Node.js binary on build time. Add a compile option to add some custom packages the same way so they are available with require() without needing to install them manually.\n\n(If you are curious, I want to add [kexec](https://www.npmjs.com/package/kexec) so it can be used on [NodeOS](https://github.com/NodeOS/NodeOS) on our own Javascript-based [`/usr/bin/env`](https://github.com/NodeOS/NodeOS/blob/master/node_modules/nodeos-initramfs/env.js) instead of `child_process` :-) )\n",
        "labels": "feature request",
        "id": 43901
    },
    {
        "title": "Compressed packages",
        "body": "(Originally posted at [Node.js](https://github.com/joyent/node/issues/14169))\n\nAllow to require() compressed packages as dependencies inside Ç¹ode_modules folder, the same way Python does. The idea is to use less disk space and make transfer of projects faster, since it will only move one file instead of a set of them. Also it would allow to checksum them, obviously in this case the comprossed package would not have inside its dependencies except if sringwash or bundleDependencies are being used, but the Node.js packages resolution algorythm (search for a node_modules in the current folder and all its parents until /) would be capable to solve this.\n\nTo do so, the only change would be that when a compressed (.zip?) file is found inside the node_modules folder, expand it dynamically and process the package.json file the same way it would do with folders.\n",
        "labels": "feature request",
        "id": 43902
    },
    {
        "title": "iojs -i does nothing when -e is used",
        "body": "The following command should evaluate that expression and then enter into the REPL, but it does not\n\n```\n$ iojs -ie 'console.log (\"hi\")' \n```\n",
        "labels": "feature request",
        "id": 43903
    },
    {
        "title": "feature request: a way to inspect what's in the event loop",
        "body": "I recently struggled with debugging a test suite that wouldn't exit. The (tape) tests all finished, but the final result wasn't printed out and the process just hung. \n\nWe eventually tracked the problem down to a few long-running `setTimeout`s that, while fine in app code, needed to be cleared in the tests so that the process could exit. \n\nThis debugging process would have been a lot easier if there was a way to see what V8 had in the event loop, by call stack. Perhaps an API like:\n\n``` js\n\nsetTimeout(() => {console.log('hi')}, 2000)\nsetTimeout(() => {console.log('hi')}, 1000)\n\nprocess.getEventLoop( (stacks) =>\n  stacks.forEach(console.log.bind(console))\n  // ['setTimeout file.js:2']\n  // ['setTimeout file.js:1']\n```\n\n`stacks` is an array of arrays sorted by their order in the event loop and containing the call stack for each item. \n\n Does this already exist? Is it possible?\n",
        "labels": "feature request",
        "id": 43904
    },
    {
        "title": "crypto: sign/verify support for RSASSA-PSS",
        "body": "It would be good if the crypto.createSign / crypto.createVerify implementations supported different openssl padding schemes instead of the default PKCS1.5.  Specifically, I'm interested in PSS and PSS with MGF1.\n\nRSA_padding_add_PKCS1_PSS\nRSA_padding_add_PKCS1_PSS_mgf1\n\nI found the following forum post that may help in the development effort.\n\nhttp://openssl.6102.n7.nabble.com/RSA-sign-and-verify-td44219.html\n\nI'm a bit out of my depth with C++, however I'm willing to help implement if someone could point me in the right direction with crypto.cc.\n\nThanks\n",
        "labels": "feature request",
        "id": 43905
    },
    {
        "title": "Are custom http verbs supported by io.js yet?",
        "body": "According to this issue: https://github.com/joyent/node/issues/3192\n\nBecause I'm having this: http://stackoverflow.com/questions/28899036/node-js-cannot-do-profind-with-request-module\n\nIn a nushell I cannot do a PROPFIND request in node/io.js.\n",
        "labels": "feature request",
        "id": 43906
    },
    {
        "title": "http_outgoing.js: Callbacks never called?",
        "body": "I am currently in the process of debugging a file descriptor leak in my code which only happens in very rare edge cases. \n\nI have identified some potential problems in `http_outgoing.js` that could be the cause of it, but\nwas not able to confirm these with my limited knowledge of the stream internals.\n\nIn the order of most to least important:\n### First case\n\nWhen the underlying stream was already closed, but a `write` call was made, the callback should be called with an error indicating that the stream is already closed.\nCurrently the callback is silently forgotten.\n\nhttps://github.com/iojs/io.js/blob/4874182065655dcf8a39bfa3e4c9b47bfb9e0f75/lib/_http_outgoing.js#L165\n### Second Case\n\nWhen a stream is closed, all callbacks remaining in `this.outputCallbacks` should be\ncalled. I wasn't able to locate any place where this would happen.\n\nhttps://github.com/iojs/io.js/blob/4874182065655dcf8a39bfa3e4c9b47bfb9e0f75/lib/_http_outgoing.js#L49\n### Third case\n\n(Likely not the cause)\n\nIf the response shouldn't have a body, please at least schedule my callback for the next tick instead\nof just returning:\n\nhttps://github.com/iojs/io.js/blob/4874182065655dcf8a39bfa3e4c9b47bfb9e0f75/lib/_http_outgoing.js#L428\nhttps://github.com/iojs/io.js/blob/4874182065655dcf8a39bfa3e4c9b47bfb9e0f75/lib/_http_outgoing.js#L438\n",
        "labels": "feature request",
        "id": 43907
    },
    {
        "title": "Add child_process.spawnShell",
        "body": "In the child_process module currently there is two flavors of exec function: exec and execFile, which is good, but for spawn, there is only one version, would've been great to have something like child_process.spawnShell. Currently I use this code to emulate it:\n\n``` javascript\nchild_process.spawn('cmd', ['/s', '/c', command], {windowsVerbatimArguments:true})\n```\n\nbut it is platform specific and requires the use of undocumented flag windowsVerbatimArguments\n",
        "labels": "feature request",
        "id": 43908
    },
    {
        "title": "socket name of unix domain sockets",
        "body": "It is currently impossible to get the path of a connected unix domain socket. socket.address() returns an empty object if it's not connected over AFINET.\n\nI've looked at lib/net.js, src/tcp_wrap.cc, src/pipe_wrap.cc and libuv and it looks like libuv has support for returning the name of the socket and it is only pipe_wrap.cc that misses something like GetPeerName (I'm not a C coder so I might be wrong on this).\n\n(also filed at https://github.com/joyent/node/issues/9120 a while ago)\n",
        "labels": "feature request",
        "id": 43909
    },
    {
        "title": "Proposal: Non-streaming encryption api ",
        "body": "The steaming format is a poor fit for authenticated ciphers so one idea would be to make a new non streaming api for encryption (maybe just authenticated encryption?) to avoid situations where we are decrypting data we have not authenticated. \n\nThis would also allow us to impliment ccw mode which I seem to recall having issues related to needing to know the message length ahead of time. \n\nI can try throwing together a pull if people like this idea. \n",
        "labels": "feature request",
        "id": 43910
    },
    {
        "title": "windows: install header files required for compiled addons",
        "body": "The windows installer should install header files. If we do this node-gyp wouldn't have to download a tarball to get the headers.\nI would suggest to install them into `program files\\iojs\\include`.\n",
        "labels": "feature request",
        "id": 43911
    },
    {
        "title": "Translate installers for OS X and Windows",
        "body": "It would be nice if we could translate the installer packages as well. Can someone please give me a hand with altering the build process to allow translations for both platforms?\n",
        "labels": "feature request",
        "id": 43912
    },
    {
        "title": "HTTP and HTTPS attempt only single IP, causing intermittent failures",
        "body": "Steps to reproduce:\n\nFind a host that answers a given port only on some of the returned IP addresses for its name. For instance, www.itunes.com has this problem. Then run this code:\n\n```\nrequire('https').get('https://www.itunes.com', function(res) {\n  console.log('statusCode:', res.statusCode);\n}).on('error', function(err) {\n  console.log('Error:', err);\n});\n```\n\nSince www.itunes.com resolves to three different IP addresses (see `dig www.itunes.com`) in random order, io.js will connect to a random host each time, sometimes failing and sometimes succeeding.\n\nArguably, this is broken behavior on the part of the host. However, it's reasonably common on the web. Firefox and Chrome each attempt parallel connections to all IP addresses provided in the DNS response, using the first connection to succeed. Curl attempts each IP address in sequence until it gets a successful connection or runs out of IP addresses: https://github.com/bagder/curl/blob/master/lib/connect.c#L1156\n\nIt looks like the io.js http and https libraries, through `Agent`, call into Socket.connect, which uses `dns.lookup` (returns just one IP address) instead of `dns.resolve`: https://github.com/iojs/io.js/blob/v1.x/lib/net.js#L900.\n\nIs it practical to change the Socket.connect behavior to use `dns.resolve` and try multiple IP addresses? I'm guessing that would be a fairly API-incompatible change. Another possibility: Agent could implement failure handling code that specifically catched connection refused and timeout errors, calls `dns.resolve` itself, and calls Socket.connect again with IP address arguments. This would be less performant but also a smaller API change.\n\nFor the real-world motivating example, I ran into this when writing automated tests for HTTPS Everywhere's rulesets: https://github.com/jsha/https-everywhere/blob/rules-tester/rewriter/tester.js. As-is, I get a number of false positives from hosts that appear to fail but actual work fine in a browser.\n",
        "labels": "feature request",
        "id": 43913
    },
    {
        "title": "make crypto functions execute in the threadpool asynchronously",
        "body": "i would expect:\n- the async implementation to be accessed through the streaming API\n- the sync implementation to be accessed through the legacy `.update()` and `.digest()` methods\n- semver major as people expect the stream to be return the result synchronously (have seen it in many modules where they don't listen to the `readable` event)\n\nbtw i have no idea how much performance benefit this would provide, if any. i just like the idea of having everything executing in the threadpool...\n\nhttps://github.com/joyent/node/issues/4298\n",
        "labels": "feature request",
        "id": 43914
    },
    {
        "title": "async-wrap: no way to catch errors without changing the throw origin",
        "body": "Consider some long stack trace module. It can use `async_wrap` to manage the the callSite objects correctly and use the v8 `Error` hooks to modify the `.stack` property. However because v8 sets the `.stack` property in a lazy way, it is necessary to do a `try {} finally {}` around the callback.\n\nSee https://github.com/AndreasMadsen/trace/blob/master/trace.js#L53 for an example with the `tracing` module.\n\nAn okay solution solution is to use the `uncaughtException` event like this:\n\n``` js\nvar asyncWrap = process.binding('async_wrap');\n\n// Enable asyncWrap and call init hook function on async initialization\nvar asyncHooksObject = {};\nvar kCallInitHook = 0;\nasyncWrap.setupHooks(\n  asyncHooksObject,\n  asyncFunctionInitialized,\n  asyncCallbackBefore,\n  asyncCallbackAfter);\nasyncHooksObject[kCallInitHook] = 1;\n\nfunction asyncFunctionInitialized() {}\n\nfunction asyncCallbackBefore() {\n  process.once('uncaughtException', asyncCallbackError);\n}\n\nfunction asyncCallbackError(error) {\n  // Set stack by v8 magic\n  error.stack;\n\n  // changes throw origin, should not be necessary\n  throw error;\n}\n\nfunction asyncCallbackAfter() {\n  process.removeListener('uncaughtException', asyncCallbackError);\n}\n\nsetTimeout(function () {\n  badluck();\n}, 10);\n```\n\nHowever this changes the throw origin:\n\n```\n/Users/Andreas/Sites/node_modules/trace/test.js:26\n  throw error;\n        ^\nReferenceError: badluck is not defined\n    at null._onTimeout (/Users/Andreas/Sites/node_modules/trace/test.js:34:3)\n    at Timer.listOnTimeout (timers.js:90:15)\n```\n\nIf `uncaughtException` isn't used then this is the error:\n\n```\n/Users/Andreas/Sites/node_modules/trace/test.js:34\n  badluck();\n  ^\nReferenceError: badluck is not defined\n    at null._onTimeout (/Users/Andreas/Sites/node_modules/trace/test.js:34:3)\n    at Timer.listOnTimeout (timers.js:90:15)\n```\n\nThis is much more informative. It would be really nice if `async_wrap` or some other mechanism allowed something similar to the old `tracing.addAsyncListener({ error: handler })` behaviour. Such that the throw origin can be preserved.\n\n_issue tracking: https://github.com/AndreasMadsen/trace/issues/12_\n_issue tracking: https://github.com/iojs/tracing-wg/issues/7_\n",
        "labels": "feature request",
        "id": 43915
    },
    {
        "title": "Using faster url parser",
        "body": "(Original node issue https://github.com/joyent/node/issues/6788)\n\nI have rewritten the url parser module of node core as it was/is a serious bottleneck in some of the [techempower benchmarks](https://www.techempower.com/benchmarks/)\n\nRunning node's urlparser benchmark using iojs it's still 16x faster when not retrieving properties and 11x faster when retrieving all properties (which are lazy getters in my implementation). In absolute terms the current iojs urlparser throughputs 25k parses per second vs 400k lazy/270k eager parses per second. `format` and `resolve` are also affected in similar magnitudes.\n",
        "labels": "feature request",
        "id": 43916
    },
    {
        "title": "url.relative (to complement path.relative)",
        "body": "The core `url` module currently has `url.resolve()` to compute absolute URLs from relative segments (which is complementary with `path.resolve()`). but it is missing the complementary `.relative()` function to compute relative URLs from two absolute URLs.\n\nMany programs simply use `path.relative()` when dealing with URLs (e.g.: https://github.com/substack/node-browserify/blob/ce3deecf7be27373c0131286bda86533ec83ffd1/index.js#L692 ) but on Windows systems, `path.relative()` uses the `path.sep` character, resulting in relative URLs like `..\\\\..\\\\a\\\\b` instead of `../../a/b`.\n\nThe algorithm for computing relative URLs is (AFAIK) the same, but the separator character should always be a `/` as specified in [RFC 3986](http://www.ietf.org/rfc/rfc3986.txt) Section 3.3.\n\nOpening this for discussion here prior to writing a PR.\n",
        "labels": "feature request",
        "id": 43917
    },
    {
        "title": "streaming / iterative fs.readdir",
        "body": "since we're in ES6 territory now, i'm thinking the sync version should be an iterable\n\n``` js\nvar dirs = fs.readdirIter(__dirname);\nfor (dir of dirs) {\n\n}\n```\n\nand have the async version be an object stream:\n\n``` js\nvar stream = fs.readdirStream(__dirname);\nstream.on('data', dir => )\n```\n\nSee: https://github.com/joyent/node/issues/388\n",
        "labels": "feature request",
        "id": 43918
    },
    {
        "title": "Silent Mode execution",
        "body": "Not an issue, but a feature request.\n\nSince it very usefull to use iojs as script interpreter, the one feature is missing, and I can suggest that many can vote for it - execute script without console window showing.\n\nI'm not really a programmer, and cannot even say is it possible or not to make console application start without creating a window. But if it is possible I think it may be very usefull to have some command line switch, like `--background` or `--hidden` to get this stuff.\n\nAnother approach to this can be via another executable, for example windows has wscript.exe and cscript.exe to execute scripts in different modes.\n\nMaybe this was discussed and rejected a lot of time in Node project, but since IOJS is a different project I just want to try again =) I know there is a lot of stuff to get this done like binaries that executes console apps in hidden mode, but this is such a little and such a usefull feature so having it bundled within iojs executable will be really awesome, since we don't need another tool for that.\n\nFor example:\nI need my JS script to execute some program, wait for it's finish, and do some stuff after that, maybe depend on exit code or something like that, so I can spawn a new process from script and give it a callback. They key here is that I don't want to see any windows, neither spawned process, nor iojs. And I will not see spawned process, but will see iojs window for all the time the spawned process will work. So this is a bit frustrating.\n\nSo my question is:\nIs this feature can be accepted for consideration by new TC or not?\n\nAnd if not, can you please provide some info how I can recompile iojs executable to get it run completely silent?\n",
        "labels": "feature request",
        "id": 43919
    },
    {
        "title": "Proposal: HTTP â€“ Move `bodyHead` to `data` event",
        "body": "So, ages and ages ago, for WebSockets support, the idea of an upgradeHead was added. This is for the data that directly trails the headers in a Upgrade or Connect request. Whilst the spec doesn't really say what this is, I propose making this as the first data event, rather than as a extra argument to the `upgrade` or `connect` events.\n\nThis seems like the better way to do this, although, I know it'd be a huge change in API from what we currently have, which is fairly popularly used at present.\n\nI feel that we should've really implemented it this way round in the first place, but there were a whole bunch of reasons as to why this proved difficult at the time.\n\nThoughts?\n",
        "labels": "feature request",
        "id": 43920
    },
    {
        "title": "Buffer - feature request: Buffer.compare with offsets.",
        "body": "I'm really impressed with the new **iojs** features, an awesome work!\n _[Buffer.compare](https://iojs.org/api/buffer.html#buffer_buf_compare_otherbuffer)_ is a great iojs addition ( _memcmp_ is very fast!), but, unfortunately, the current method [implementation](https://github.com/iojs/io.js/blob/v1.x/src/node_buffer.cc#L572) doesn't offer a way to compare 2 portions of Buffers: you are forced to slice one or both Buffers to compare desired portions of data.\n\nNow, Buffer.compare accepts 2 buffers as arguments, instead, it could accept 4 args (+1 optional), or something like that:\n\n``` javascript\nfunction ( Buffer b1, Number start1, Buffer b2, Number start2 [, Number length ] ) {}\n/*\n * For example, comparing 10 bytes:\n *  - b1 from index 0 to 9 \n *  - b2 from index 16 to 25\n */\nBuffer.compare( b1, 0, b2, 16, 10 )\n// or, to mantain current signature:\nBuffer.compare( b1, b2, 0, 16, 10 )\n```\n\n@trevnorris  It would be great if it was planned to add this functionality, it simplify things a lot!!\n",
        "labels": "feature request",
        "id": 43921
    },
    {
        "title": "Offer libdir and mandir configure options.",
        "body": "I currently have a SlackBuild in pending for io.js, I am very excited to bring this great project to Slackware!\n\nI would like to request this enhancement to packaging io.js, if feasible ... to get around being unable to change the library and man paths, I currently have this in the Slackware build script:\n\n```\n# Fix man page path.\nsed -i 's|share/||' tools/install.py\nsed -i '/var manRoot/ s/\"share\",//' deps/npm/lib/{,un}build.js\n\n# Fix libdir for 64-bit.\nsed -i \"s|lib/|lib${LIBDIRSUFFIX}/|g\" tools/install.py\nsed -i \"s/'lib'/'lib${LIBDIRSUFFIX}'/\" lib/module.js\nsed -i \"s|\\\"lib\\\"|\\\"lib${LIBDIRSUFFIX}\\\"|\" deps/npm/lib/npm.js\n```\n\nIt'd be nice if io.js offered a typical configure flag option like `--libdir` and `--mandir`.\n\nThanks!\n",
        "labels": "feature request",
        "id": 43922
    },
    {
        "title": "`os.networkInterfaces` does not list all interfaces. ",
        "body": "Adoption of joyent/node#9029.\n\n[`os.networkInterfaces()`](https://github.com/iojs/io.js/blob/3e1b1dd4a9/lib/os.js#L15) does not list all interfaces, but only those that have addresses, excluding for example an unplugged `eth0`, which can be surprising.\n\nThis happens because `os.networkInterfaces` is actually implemented in terms of [`GetInterfaceAddresses`](https://github.com/iojs/io.js/blob/3abfb56f9b/src/node_os.cc#L187) which calls into [`uv_interface_addresses`](https://github.com/libuv/libuv/blob/7a19a48df8/src/unix/linux-core.c#L741) (which among other things filters out everything except `AF_INET*`) making `networkInterfaces` a bit of a misnomer for what is basically `networkInterfaceAddresses`.\n\nThough `os` is at stability 4 already, this behavior can be a bit unexpected. Perhaps we could correct it somewhat without breaking the API, or at least document it. I can think of a few ways to work this out:\n- Leave the method as it is, but document the exceptional behavior in the docs, and leave it to a community module to solve this correctly; or\n- Alias it to `os.networkInterfaceAddresses`, thus reflecting `GetInterfaceAddresses` and `uv_interface_addresses`; or\n- Implement `uv_interfaces` and rebase `os.networkInterfaces()` on that and `uv_interface_addresses`, preserving the current behavior, but listing all interfaces when given a flag.\n1. yes\n2. os\n3. v0.10, v0.12, v1.0.0\n",
        "labels": "feature request",
        "id": 43923
    },
    {
        "title": "plans on incorporating LibreSSL",
        "body": "Is there any experience with or are there any plans on replacing OpenSSL with the leaner and meaner [LibreSSL](http://www.libressl.org/) with it's new [libtls](http://www.openbsd.org/cgi-bin/man.cgi/OpenBSD-current/man3/tls_client.3?query=tls_init&sec=3) API now that both io.js and LibreSSL have there first releases out?\n",
        "labels": "feature request",
        "id": 43924
    },
    {
        "title": "Make symlink to /usr/local/bin/node optional on OSX installer",
        "body": "In order to be able to run node and io.js in parallel and easily choose what to run, it would be nice if the OSX installer did not automatically create a symlink in /usr/local/bin/node.\n",
        "labels": "feature request",
        "id": 43925
    },
    {
        "title": "Make fs.watch recursive on Windows",
        "body": "I spotted the recursive watch support for OS X in the io.js changelog.\n\nThere's a pull request for libuv at https://github.com/joyent/libuv/pull/1473 to add recursive watch support for Windows but it has been sitting for a few months.\n\nIs there anyone here who could help to get that through?\n\nIf we had recursive watch support for OS X and Windows, then Linux could be handled using a series of inotify watchers (we can't do this on Windows because it would lock every watch directory or parent thereof), and we could get a decent cross-platform watch implementation working on top of io.js.\n",
        "labels": "feature request",
        "id": 43926
    },
    {
        "title": "Option to not install npm in installer",
        "body": "It'd be nice if the OSX iojs installer gave you an option to not clobber existing npm installation (like `./configure --without-npm`), especially if you already have a newer version of npm installed.\n",
        "labels": "feature request",
        "id": 43927
    },
    {
        "title": "RFC: bundle tick processor with iojs",
        "body": "See bnoordhuis/node-profiler#11 for background.  A recurring issue with CPU profiling with `--prof` is that you either need to build d8 (the V8 shell) or install a tick processor package from npm.\n\nThe problem with building d8 is that it's quite tedious and frequently broken due to the way V8 is bundled.  Installing a tick processor is no picnic either; if it doesn't match the V8 version, it produces bogus output.  That isn't currently solvable from user land because the output from the profiler doesn't contain version information and heuristics aren't reliable enough.  I'm going to prepare a patch that adds version information but that is a tangential issue.  (Update: https://codereview.chromium.org/800293002/)\n\nFor ease of use, I propose bundling the tick processor with iojs, either as a standalone JS script (working name: `ioprof`) or by baking it into the binary.  The former would be easiest short-term, the latter offers an arguably nicer user experience.  I volunteer to do the work.\n\nDesign decisions:\n- Add a `--without-ioprof` to the configure script, similar to the `--without-npm` flag?  Assertion without hard data to back it up: no one uses `--without-npm`; `--without-ioprof` is probably not worth the hassle.\n- What about distro packagers that build against an external V8?  We would normally copy the tick processor files from deps/v8/tools but that won't work when compiling against headers only.  The best I can come up with for now is to disable the profiler script when `--shared-v8` is specified.  Maybe @jbergstroem can chime in here.\n",
        "labels": "feature request",
        "id": 43928
    },
    {
        "title": "feature: support initializing Buffer from an ArrayBuffer",
        "body": "I propose we make the `Buffer` constructor also accept `ArrayBuffer`.\n\nCurrently this is what happens:\n\n``` js\nvar u = new Uint8Array([1, 2, 3, 4]);\nvar ab = u.buffer;\nvar b = new Buffer(ab);\nconsole.log(b); // <Buffer >\n```\n\nThis is what should happen:\n\n``` js\nconsole.log(b); // <Buffer 01 02 03 04>\n```\n\nWhen writing isomorphic code (i.e. code that runs on the server and in the browser), it's often the case that you'll get an `ArrayBuffer` from a DOM API (xhr, websockets, webrtc, etc.) and need to convert it to a `Buffer` to work with modules in the npm ecosystem. Users often expect that `new Buffer(arraybuffer)` will work and [they](https://github.com/feross/buffer/pull/42) [open](https://github.com/feross/buffer/pull/39) [issues](https://github.com/maxogden/level.js/issues/34) when it doesn't.\n\nWe have the [`buffer`](https://github.com/feross/buffer) npm module which gives us the same `Buffer` API in the browser (and is used by [browserify](http://browserify.org)), however it tracks the node.js/io.js buffer exactly, so we can't add support for `new Buffer(arraybuffer)` unless core does too.\n\nI know the `Buffer` constructor already takes a million different argument types, so it couldn't hurt to add one more, right? Curious to see what the community thinks about this. If there's interest, I can send a PR.\n",
        "labels": "feature request",
        "id": 43929
    },
    {
        "title": "Feature Request: Every async function returns Promise",
        "body": "Now in node we have callback or EventEmitter model to deal with async calls by default. But in my opinion it is better if every async function returns a native Promise (from new version of V8). \nIt does not break backward compatibility and supports optional callback if needed.\n\nIf so we just do not need to install additional package for promises like q or bluebird except additional functionality is needed.\n\n---\n\n**_EDIT 2014-12-11 by @rvagg**_\n\n_Comment lifted from [here](https://github.com/iojs/io.js/issues/11#issuecomment-66615563) so it's easier to see for newcomers to this conversation._\n\nThis was discussed at the TC meeting yesterday, see #144, the aim was to be able to provide at least some kind of statement as feedback in this issue. I don't think the issue needs to be closed and can continue to collect discussion from those who feel strongly about this topic.\n\nThe feedback from the TC about incorporating a Promises-based API in core goes something like this:\n\n**A Promises API doesnâ€™t make sense for core _right now_ because it's too early in the evolution of V8-based promises and their relationship to other ES\\* features. There is very little interest within the TC in exploring this in core in the short-term.**\n\n**However, the TC is open to change as the feature specifications and implementations in ES6 and ES7 are worked out. The TC is open to experimentation and providing the most optimal API for users, which may potentially include a Promises-based API, particularly if newer features of JavaScript work most optimally in conjunction with Promises. The speed of the language specification process and V8 implementation will mostly dictate the timeline.**\n\n**It should be noted that a callback API is unlikely to ever go away.**\n\n---\n",
        "labels": "feature request",
        "id": 43930
    },
    {
        "title": "doc: nodejs > http > get > Example KO",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 14.16.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Windows 64-bit, but not relevant\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: http\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s): \r\n\r\n- [https://nodejs.org/docs/latest-v14.x/api/http.html#http_http_get_options_callback](https://nodejs.org/docs/latest-v14.x/api/http.html#http_http_get_options_callback)\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nProvided example doesn't work anymore, returns an error \"Request failed. Status code: 301.\"\r\n\r\n![Sans titre](https://user-images.githubusercontent.com/10812138/112452115-90254e80-8d56-11eb-8361-b7b2aafea4dc.png)\r\n\r\nThe provided url leads to http : `http.get('http://nodejs.org/dist/index.json', (res) => {`\r\n\r\nbut **said resource get automatically redirected to it's https twin**.\r\n\r\nIn the example, anything other than 200 is thrown away `if (statusCode !== 200)`\r\n\r\nYou need to set a new resource in http only (no redirection towards https) as the http module can't handle the https protocol ^^.\r\n\r\nCheers\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43931
    },
    {
        "title": "Pooling written instead of Polling",
        "body": "[JavaScript Embedder API](https://nodejs.org/dist/latest-v15.x/docs/api/async_hooks.html#async_hooks_javascript_embedder_api), in first line it is written to be used for  `Connection Pooling`  whereas Embedder API deals with `Connection Polling` not `Pooling`\r\n\r\n",
        "labels": "doc",
        "id": 43932
    },
    {
        "title": "Wrapping existing net.Socket does not work",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 14.16.0\r\n* **Platform**: MacOS \r\n* **Subsystem**: macOS Catalina 10.15.7 \r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```javascript\r\nconst net = require(\"net\")\r\n\r\nconst srv = net.createServer()\r\n\r\nsrv.on(\"connection\", c => {\r\n    const sock = new net.Socket({\r\n        fd: c._handle.fd\r\n    })\r\n})\r\n\r\nsrv.listen(4444)\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nNo required condition (as far as I can tell).\r\n\r\n### What is the expected behavior?\r\n\r\nThat a new `net.Socket` instance is created which behaves exactly like the original instance (`c` in this case).\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nAn error is thrown (EEXISTS):\r\n\r\n```\r\nnet.js:337\r\n        throw errnoException(err, 'open');\r\n        ^\r\n\r\nError: open EEXIST\r\n    at new Socket (net.js:337:15)\r\n    at Server.<anonymous> (test.js:6:15)\r\n    at Server.emit (events.js:315:20)\r\n    at TCP.onconnection (net.js:1560:8) {\r\n  errno: -17,\r\n  code: 'EEXIST',\r\n  syscall: 'open'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "doc",
        "id": 43933
    },
    {
        "title": "doc: DEP0034 no viable replacement for fs.exists",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n[DEP0034](https://nodejs.org/dist/latest-v15.x/docs/api/deprecations.html#DEP0034) states that `fs.stat` and `fs.access` should be used instead of `fs.exists`.\r\n\r\nHowever, while `fs.exists` returns a boolean if the given path exists or not, `fs.stat` and `fs.access` throw an error instead.\r\n\r\nIs there a way to check if a given path exists with Node going forward?",
        "labels": "doc",
        "id": 43934
    },
    {
        "title": "doc: ",
        "body": "# ðŸ“— API Reference D\r\nocs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: âœï¸\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: âœï¸\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: âœï¸\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/âœï¸\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43935
    },
    {
        "title": "doc: linting error on docs/api/http.md",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**:  `master` branch\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**:  Darwin Kernel Version 19.6.0; root:xnu-6153.141.16~1/RELEASE_X86_64 x86_64\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: http\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/http.md\r\n\r\nspecific to running `make test` and `make test-doc`\r\n\r\n## Description\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nRunning the test scripts and linter on master is producing a linter warning that is blocking the test scripts from completing successfully. It points to this line: https://github.com/nodejs/node/commit/53b673e92e851a4adae372fdc4945e174303996b#diff-d692ac4524379ec6a1201165e8ff8d3267c8130e07014e8221ebf7e6f80c6641R3144.\r\n\r\nThe error message received is:\r\n```\r\ndoc/api/http.md\r\n  3119:1-3119:41  warning  Found unused definition  no-unused-definitions  remark-lint\r\n\r\nâš  1 warning\r\nmake: *** [tools/.mdlintstamp] Error 1\r\n```\r\n\r\nI believe it's related to https://github.com/nodejs/node/pull/37265, but I wasn't able to come up with a fix.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43936
    },
    {
        "title": "doc: VM module, how to make VM out of scope and free resources (collected by GC)?",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v14.0.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux localhost 4.14.67 #4 SMP PREEMPT Mon Jan 14 11:28:51 CST 2019 x86_64 Intel(R) Core(TM) i3-7100U CPU @ 2.40GHz GenuineIntel GNU/Linux\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: vm\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/vm.html\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\nI am developing a WASM app that utilizes node's http server and I plan to create a cluster/worker pool that destroys the cluster/worker when WASM memory was grown (is that the correct word?) out of the needed amount. This happen because WASM supports growing memory but not shrinking it, take a look at this [issue](https://github.com/WebAssembly/design/issues/1300). My application already utilizes a memory reset [logic](https://github.com/soIu/rpython/blob/master/javascript/utils/snapshot_memory.js) that works flawlessly, but still the total allocated memory was the last amount of used memory and it jumps especially when there's a huge incoming requests that get in.\r\n\r\nA solution would be deleting all variable reference of the WASM Module instance, Memory instance, and etc and let node's GC collect unused resources but emscripten's emit so many global variable that refers to the instances and I think deleting them is complicated. **So if we execute the emscripten's JS glue code and the WASM on a VM context, can we make it out of scope (make the GC collects it) since there's no way to destroy it as specified on the docs?**\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43937
    },
    {
        "title": "doc: DEP0066 is slightly incorrect",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v15.11.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux nuc 5.4.0-65-generic #73~18.04.1-Ubuntu SMP Tue Jan 19 09:02:24 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: http.ClientRequest\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/deprecations.html#deprecations_dep0066_outgoingmessage_prototype_headers_outgoingmessage_prototype_headernames\r\n\r\n## Description\r\n\r\n[DEP0066](https://nodejs.org/api/deprecations.html#deprecations_dep0066_outgoingmessage_prototype_headers_outgoingmessage_prototype_headernames) implies that using `OutgoingMessage.prototype.getHeaderNames()` is equivalent to the now deprecated `OutgoingMessage.prototype._headerNames` property which is not the case.\r\n\r\n`OutgoingMessage.prototype._headerNames` contains a mapping from lowercase to the exact header names that were sent with the request:\r\n\r\n```\r\n{authorization: \"Authorization\", host: \"Host\"}\r\n```\r\n\r\nWhere `OutgoingMessage.prototype.getHeaderNames()` returns only lowercase names.\r\n\r\nThe now deprecated `_headerNames` property is useful in http debug logging modules that print the exact header names being sent, as some servers are still picky about those. Not having access to the actual header names will make debugging harder, assuming node still sends the headers as they are sent through the `http.request` method.\r\n\r\nBesides the documentation being misleading about this I'd like to know if there is a way to access the headers being sent going forward, since `_headerNames` is now deprecated.",
        "labels": "doc",
        "id": 43938
    },
    {
        "title": "doc: bad `crypto.verify()` dsaEncoding description",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: master\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: n/a\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: doc, crypto\r\n\r\n## Location\r\n\r\n`crypto.verify()`\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/crypto.html\r\n\r\n## Description\r\n\r\nThe description of `dsaEncoding` uses the term \"generated signature\" which is a bit confusing when the function is actually verifying an existing signature and may be a copy-paste error from `crypto.sign()`.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43939
    },
    {
        "title": "Cannot return value from a SourceTextModule to the caller",
        "body": "* **Version**: v15.9.0\r\n* **Platform**: macOS Catalina 10.15.6\r\n* **Subsystem**: VM\r\n\r\n### What steps will reproduce the bug?\r\n\r\nMake file ```retu.js```.\r\n\r\n```\r\nconst vm = require('vm');\r\nconst contextifiedSandbox = vm.createContext({ });\r\n(async () => {\r\n  const bar = new vm.SourceTextModule(`19;`, { context: contextifiedSandbox });\r\n  async function linker(specifier, referencingModule) { }\r\n  await bar.link(linker);\r\n  const  result  = await bar.evaluate();\r\n  console.log(\"Result is: \", result);\r\n})();\r\n```\r\n\r\nRun as ```node --experimental.vm.modules retu.js```\r\n\r\n### What is the expected behavior?\r\n\r\nAccording to the current state of the documentation I expect an output of  ```Result is: 19```\r\n\r\n### What do you see instead?\r\n\r\nOutput of:  ```Result is: undefined```\r\n\r\n\r\n\r\n",
        "labels": "doc",
        "id": 43940
    },
    {
        "title": "Please document FORCE_COLOR/NO_COLOR in `node -h` output",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.20.2, 14.15.5, 15.3.0\r\n* **Platform**: Darwin\r\n* **Subsystem**: tty\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```bash\r\n$ FORCE_COLOR=1 NO_COLOR=1 node -p 1\r\n1\r\n(node:69290) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n\r\n$ node -h | grep COLOR\r\nNODE_DISABLE_COLORS         set to 1 to disable colors in the REPL\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\nExpect `node -h` to mention that node responds in some way to the `NO_COLOR` and `FORCE_COLOR` environment variables.\r\n\r\nDocumentation specifies that `FORCE_COLOR` and `NO_COLOR` can be used to simulate a different color depth terminal, but should identify the logic by which one or the other is preferred, and stipulate that a warning will be generated if both are set.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nNo mention of `FORCE_COLOR` and `NO_COLOR` environment variables.\r\n\r\nOnly limited mention in docs.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nHandling of NO_COLOR and FORCE_COLOR were added in https://github.com/nodejs/node/commit/273398a3d09, however the documentation does not mention that node will warn if both are set, only that they can be used to simulate a different color depth support level.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "doc",
        "id": 43941
    },
    {
        "title": "doc: nodejs > http > get > Example KO",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 14.16.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Windows 64-bit, but not relevant\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: http\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s): \r\n\r\n- [https://nodejs.org/docs/latest-v14.x/api/http.html#http_http_get_options_callback](https://nodejs.org/docs/latest-v14.x/api/http.html#http_http_get_options_callback)\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nProvided example doesn't work anymore, returns an error \"Request failed. Status code: 301.\"\r\n\r\n![Sans titre](https://user-images.githubusercontent.com/10812138/112452115-90254e80-8d56-11eb-8361-b7b2aafea4dc.png)\r\n\r\nThe provided url leads to http : `http.get('http://nodejs.org/dist/index.json', (res) => {`\r\n\r\nbut **said resource get automatically redirected to it's https twin**.\r\n\r\nIn the example, anything other than 200 is thrown away `if (statusCode !== 200)`\r\n\r\nYou need to set a new resource in http only (no redirection towards https) as the http module can't handle the https protocol ^^.\r\n\r\nCheers\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43942
    },
    {
        "title": "Pooling written instead of Polling",
        "body": "[JavaScript Embedder API](https://nodejs.org/dist/latest-v15.x/docs/api/async_hooks.html#async_hooks_javascript_embedder_api), in first line it is written to be used for  `Connection Pooling`  whereas Embedder API deals with `Connection Polling` not `Pooling`\r\n\r\n",
        "labels": "doc",
        "id": 43943
    },
    {
        "title": "Wrapping existing net.Socket does not work",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 14.16.0\r\n* **Platform**: MacOS \r\n* **Subsystem**: macOS Catalina 10.15.7 \r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```javascript\r\nconst net = require(\"net\")\r\n\r\nconst srv = net.createServer()\r\n\r\nsrv.on(\"connection\", c => {\r\n    const sock = new net.Socket({\r\n        fd: c._handle.fd\r\n    })\r\n})\r\n\r\nsrv.listen(4444)\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nNo required condition (as far as I can tell).\r\n\r\n### What is the expected behavior?\r\n\r\nThat a new `net.Socket` instance is created which behaves exactly like the original instance (`c` in this case).\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nAn error is thrown (EEXISTS):\r\n\r\n```\r\nnet.js:337\r\n        throw errnoException(err, 'open');\r\n        ^\r\n\r\nError: open EEXIST\r\n    at new Socket (net.js:337:15)\r\n    at Server.<anonymous> (test.js:6:15)\r\n    at Server.emit (events.js:315:20)\r\n    at TCP.onconnection (net.js:1560:8) {\r\n  errno: -17,\r\n  code: 'EEXIST',\r\n  syscall: 'open'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "doc",
        "id": 43944
    },
    {
        "title": "doc: DEP0034 no viable replacement for fs.exists",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n[DEP0034](https://nodejs.org/dist/latest-v15.x/docs/api/deprecations.html#DEP0034) states that `fs.stat` and `fs.access` should be used instead of `fs.exists`.\r\n\r\nHowever, while `fs.exists` returns a boolean if the given path exists or not, `fs.stat` and `fs.access` throw an error instead.\r\n\r\nIs there a way to check if a given path exists with Node going forward?",
        "labels": "doc",
        "id": 43945
    },
    {
        "title": "doc: ",
        "body": "# ðŸ“— API Reference D\r\nocs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: âœï¸\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: âœï¸\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: âœï¸\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/âœï¸\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43946
    },
    {
        "title": "doc: linting error on docs/api/http.md",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**:  `master` branch\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**:  Darwin Kernel Version 19.6.0; root:xnu-6153.141.16~1/RELEASE_X86_64 x86_64\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: http\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/http.md\r\n\r\nspecific to running `make test` and `make test-doc`\r\n\r\n## Description\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nRunning the test scripts and linter on master is producing a linter warning that is blocking the test scripts from completing successfully. It points to this line: https://github.com/nodejs/node/commit/53b673e92e851a4adae372fdc4945e174303996b#diff-d692ac4524379ec6a1201165e8ff8d3267c8130e07014e8221ebf7e6f80c6641R3144.\r\n\r\nThe error message received is:\r\n```\r\ndoc/api/http.md\r\n  3119:1-3119:41  warning  Found unused definition  no-unused-definitions  remark-lint\r\n\r\nâš  1 warning\r\nmake: *** [tools/.mdlintstamp] Error 1\r\n```\r\n\r\nI believe it's related to https://github.com/nodejs/node/pull/37265, but I wasn't able to come up with a fix.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43947
    },
    {
        "title": "doc: VM module, how to make VM out of scope and free resources (collected by GC)?",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v14.0.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux localhost 4.14.67 #4 SMP PREEMPT Mon Jan 14 11:28:51 CST 2019 x86_64 Intel(R) Core(TM) i3-7100U CPU @ 2.40GHz GenuineIntel GNU/Linux\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: vm\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/vm.html\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\nI am developing a WASM app that utilizes node's http server and I plan to create a cluster/worker pool that destroys the cluster/worker when WASM memory was grown (is that the correct word?) out of the needed amount. This happen because WASM supports growing memory but not shrinking it, take a look at this [issue](https://github.com/WebAssembly/design/issues/1300). My application already utilizes a memory reset [logic](https://github.com/soIu/rpython/blob/master/javascript/utils/snapshot_memory.js) that works flawlessly, but still the total allocated memory was the last amount of used memory and it jumps especially when there's a huge incoming requests that get in.\r\n\r\nA solution would be deleting all variable reference of the WASM Module instance, Memory instance, and etc and let node's GC collect unused resources but emscripten's emit so many global variable that refers to the instances and I think deleting them is complicated. **So if we execute the emscripten's JS glue code and the WASM on a VM context, can we make it out of scope (make the GC collects it) since there's no way to destroy it as specified on the docs?**\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43948
    },
    {
        "title": "doc: DEP0066 is slightly incorrect",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v15.11.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux nuc 5.4.0-65-generic #73~18.04.1-Ubuntu SMP Tue Jan 19 09:02:24 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: http.ClientRequest\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/deprecations.html#deprecations_dep0066_outgoingmessage_prototype_headers_outgoingmessage_prototype_headernames\r\n\r\n## Description\r\n\r\n[DEP0066](https://nodejs.org/api/deprecations.html#deprecations_dep0066_outgoingmessage_prototype_headers_outgoingmessage_prototype_headernames) implies that using `OutgoingMessage.prototype.getHeaderNames()` is equivalent to the now deprecated `OutgoingMessage.prototype._headerNames` property which is not the case.\r\n\r\n`OutgoingMessage.prototype._headerNames` contains a mapping from lowercase to the exact header names that were sent with the request:\r\n\r\n```\r\n{authorization: \"Authorization\", host: \"Host\"}\r\n```\r\n\r\nWhere `OutgoingMessage.prototype.getHeaderNames()` returns only lowercase names.\r\n\r\nThe now deprecated `_headerNames` property is useful in http debug logging modules that print the exact header names being sent, as some servers are still picky about those. Not having access to the actual header names will make debugging harder, assuming node still sends the headers as they are sent through the `http.request` method.\r\n\r\nBesides the documentation being misleading about this I'd like to know if there is a way to access the headers being sent going forward, since `_headerNames` is now deprecated.",
        "labels": "doc",
        "id": 43949
    },
    {
        "title": "doc: bad `crypto.verify()` dsaEncoding description",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: master\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: n/a\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: doc, crypto\r\n\r\n## Location\r\n\r\n`crypto.verify()`\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/crypto.html\r\n\r\n## Description\r\n\r\nThe description of `dsaEncoding` uses the term \"generated signature\" which is a bit confusing when the function is actually verifying an existing signature and may be a copy-paste error from `crypto.sign()`.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43950
    },
    {
        "title": "Cannot return value from a SourceTextModule to the caller",
        "body": "* **Version**: v15.9.0\r\n* **Platform**: macOS Catalina 10.15.6\r\n* **Subsystem**: VM\r\n\r\n### What steps will reproduce the bug?\r\n\r\nMake file ```retu.js```.\r\n\r\n```\r\nconst vm = require('vm');\r\nconst contextifiedSandbox = vm.createContext({ });\r\n(async () => {\r\n  const bar = new vm.SourceTextModule(`19;`, { context: contextifiedSandbox });\r\n  async function linker(specifier, referencingModule) { }\r\n  await bar.link(linker);\r\n  const  result  = await bar.evaluate();\r\n  console.log(\"Result is: \", result);\r\n})();\r\n```\r\n\r\nRun as ```node --experimental.vm.modules retu.js```\r\n\r\n### What is the expected behavior?\r\n\r\nAccording to the current state of the documentation I expect an output of  ```Result is: 19```\r\n\r\n### What do you see instead?\r\n\r\nOutput of:  ```Result is: undefined```\r\n\r\n\r\n\r\n",
        "labels": "doc",
        "id": 43951
    },
    {
        "title": "Please document FORCE_COLOR/NO_COLOR in `node -h` output",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.20.2, 14.15.5, 15.3.0\r\n* **Platform**: Darwin\r\n* **Subsystem**: tty\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```bash\r\n$ FORCE_COLOR=1 NO_COLOR=1 node -p 1\r\n1\r\n(node:69290) Warning: The 'NO_COLOR' env is ignored due to the 'FORCE_COLOR' env being set.\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n\r\n$ node -h | grep COLOR\r\nNODE_DISABLE_COLORS         set to 1 to disable colors in the REPL\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\nExpect `node -h` to mention that node responds in some way to the `NO_COLOR` and `FORCE_COLOR` environment variables.\r\n\r\nDocumentation specifies that `FORCE_COLOR` and `NO_COLOR` can be used to simulate a different color depth terminal, but should identify the logic by which one or the other is preferred, and stipulate that a warning will be generated if both are set.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nNo mention of `FORCE_COLOR` and `NO_COLOR` environment variables.\r\n\r\nOnly limited mention in docs.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nHandling of NO_COLOR and FORCE_COLOR were added in https://github.com/nodejs/node/commit/273398a3d09, however the documentation does not mention that node will warn if both are set, only that they can be used to simulate a different color depth support level.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "doc",
        "id": 43952
    },
    {
        "title": "Uninstallation instructions",
        "body": "Hi,\r\n\r\nI see there is a lot of amazing support for installation, however, I find various articles scattered online across the past few years on uninstallation. Is it possible to update the documentation with clear instructions on how to uninstall node.js from the system? The amount of online articles suggest a lot of people are wanting to uninstall it. This kind of guidance would come in handy for several people. If it is already there somewhere, I would really appreciate it if you could point me to the resource.\r\n\r\nThanks so much for all the work!",
        "labels": "doc",
        "id": 43953
    },
    {
        "title": "doc: ",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: âœï¸\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: âœï¸\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: âœï¸\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/âœï¸\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43954
    },
    {
        "title": "fs file access constants are nearly useless on Windows",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v12.18.3 (and all other version as far as I can tell)\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Windows (32- and 64-bit)\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: fs\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/docs/latest-v12.x/api/fs.html#fs_fs_constants_1\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nFile access constants are basically useless on Windows due to ACL not being checked. ACL being a primary way to regulate file access in Windows, in 99% of cases R_OK and W_OK will behave exactly like F_OK and will **not** provide any additional info, effectively failing in their purpose.\r\n\r\n[This commit](https://github.com/nodejs/node/commit/6c079905a3dc4a6e3317b4fa1ada0ce39c8d0db7) is supposed to address this issue, but the info it adds is very easy to miss and does not highlight the significance of the implications (i.e. fs.access can only be used to check file existence on Windows).\r\n\r\nI propose that a warning should be added to the constants' description, similar to the warning about X_OK being useless on Windows. The exact wording doesn't need to be the same (I presume there still are some cases in which R_OK/W_OK will throw on Windows), but there should be some warning.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43955
    },
    {
        "title": "Table of contents in a <details>",
        "body": "Since table of contents on mobile is really tall in height i propose to put that in a [`<details>`](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/details).\r\n\r\n![Screenshot_20210112-114658](https://user-images.githubusercontent.com/44380480/104304674-f9255600-54cb-11eb-8685-9ad45a4a4284.png)\r\r\n\r\n",
        "labels": "doc",
        "id": 43956
    },
    {
        "title": "doc: description for chunks in _writev in stream_writable",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n- **Version**: v12.18.3\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: `5.9.0-5-amd64 #1 SMP Debian 5.9.15-1 (2020-12-17) x86_64 GNU/Linux`\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: stream\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/docs/latest-v12.x/api/stream.html#stream_writable_writev_chunks_callback\r\n## Description\r\n\r\n\r\ndescrition of params chunks does not correspond to what gives me a console.log\r\n\r\n```\r\n[\r\n  {\r\n    chunk: <Buffer ff ff>,\r\n    encoding: 'buffer',\r\n    callback: [Function: nop],\r\n    next: {\r\n      chunk: <Buffer ff ff>,\r\n      encoding: 'buffer',\r\n      callback: [Function: nop],\r\n      next: [Object]\r\n    }\r\n  },\r\n  {\r\n    chunk: <Buffer ff ff>,\r\n    encoding: 'buffer',\r\n    callback: [Function: nop],\r\n    next: {\r\n      chunk: <Buffer ff ff>,\r\n      encoding: 'buffer',\r\n      callback: [Function: nop],\r\n      next: [Object]\r\n    }\r\n  },\r\n  {\r\n    chunk: <Buffer ff ff>,\r\n    encoding: 'buffer',\r\n    callback: [Function: nop],\r\n    next: {\r\n      chunk: <Buffer ff ff>,\r\n      encoding: 'buffer',\r\n      callback: [Function: nop],\r\n      next: null\r\n    }\r\n  },\r\n  {\r\n    chunk: <Buffer ff ff>,\r\n    encoding: 'buffer',\r\n    callback: [Function: nop],\r\n    next: null\r\n  },\r\n  allBuffers: true\r\n]\r\n\r\n```\r\nI can call callback in chunks object? or call callback in 2nd parameter?\r\nWhat is allBuffers?\r\n\r\nthank you for taking the time to read my request (:\r\n\r\n",
        "labels": "doc",
        "id": 43957
    },
    {
        "title": "doc: ChildProcess links don't go to class documentation",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\nChildProcess links don't go to class documentation\r\n\r\n- **Version**: 12, perhaps others\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/docs/latest-v12.x/api/child_process.html\r\n\r\n## Description\r\n\r\nIt seems unhelpful that the links to `ChildProcess` in the prose go to the module documentation. I'd expect them to link to the \"Class: ChildProcess\" documentation.\r\n\r\nFor example, the documentation for `child_process.fork` includes this:\r\n\r\n```\r\nLike [`child_process.spawn()`][], a [`ChildProcess`][] object is returned. \r\n```\r\n\r\nWhich links to https://nodejs.org/docs/latest-v12.x/api/child_process.html#child_process_child_process -- the top of the module documentation.\r\n\r\nWhereas the link in the method signature documentation (\"Returns: \\<ChildProcess\\>\") goes to the class: https://nodejs.org/docs/latest-v12.x/api/child_process.html#child_process_class_childprocess .\r\n\r\nI'd expect both to go to the class documentation.\r\n\r\nThere are also instances in the documentation where `ChildProcess` is referenced and formatted as code without being linked, FWIW.\r\n",
        "labels": "doc",
        "id": 43958
    },
    {
        "title": "process 'error' event is undocumented",
        "body": "https://github.com/nodejs/node/blob/8b8620d580314050175983402dfddf2674e8e22a/lib/internal/event_target.js#L604 /cc @benjamingr",
        "labels": "doc",
        "id": 43959
    },
    {
        "title": "doc: Buffer UInt -> Uint aliases are not documented",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v12.19.0 and up, v14.9.0 and up, v15 and up\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: All\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: Buffer\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/buffer.html\r\n\r\n## Description\r\n\r\nThe `Buffer.[read/write]UInt` -> `Buffer.[read/write]Uint` aliases added in https://github.com/nodejs/node/pull/34729/ do not appear in the rendered documentation, despite appearing in the YAML sections.\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43960
    },
    {
        "title": "doc: trisna nodejs",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: âœï¸\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: âœï¸\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: âœï¸\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/âœï¸\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43961
    },
    {
        "title": "doc: Clarify what <string> means in path option of fs.readFile, fs.readFileSync etc. ",
        "body": "- **Version**:  14.15.3 x64 \r\n- **Platform**:  Windows 10 64-bit\r\n- **Subsystem**: fs\r\n\r\nAffected URL(s):\r\nhttps://nodejs.org/dist/latest-v14.x/docs/api/fs.html#fs_fs_readfile_path_options\r\nhttps://nodejs.org/dist/latest-v14.x/docs/api/fs.html#fs_fs_readfilesync_path_options\r\n\r\n## Description\r\n\r\nI am not sure if this a documentation issue or a bug. I get a ENOENT error when I use a url string as path for fs.readFile. However, if I convert the url string to a file path, I am able to read the file.  \r\n\r\nIt needs to be clarified if path strings are exclusively file paths and not urls. If it can also be a url string (and I see no reason for not supporting them?) , then this is bug/feature request! \r\n\r\n",
        "labels": "doc",
        "id": 43962
    },
    {
        "title": "doc: Please explain what \"pathObject\" is",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n## Location\r\n\r\nhttps://nodejs.org/api/path.html#path_path_format_pathobject\r\n\r\n- https://nodejs.org/api/âœï¸\r\n\r\n## Description\r\n\r\nI can't see any reference to what \"pathObject\" is (or how to create it).\r\n",
        "labels": "doc",
        "id": 43963
    },
    {
        "title": "docs improvement - \"advanced section\"",
        "body": "At the moment, I am curious how domains are implemented with the newish AsyncHooks / AsyncListener API.\r\nIt might be a tad dangerous to leak details, but could there be an advanced section in the docs that does some case studies and talks about \"under the hood\" stuff and \"implementation details\"?\r\n\r\nRight now, I am just curious how domain is implemented using AsyncHooks / AsyncListener and if it could be documented. TMK the domain implementation changed after AsyncHooks was introduced.\r\n",
        "labels": "doc",
        "id": 43964
    },
    {
        "title": "doc: http.Agent, reuse single socket vs new socket for each request",
        "body": "# ðŸ“— http.Agent, reuse single socket vs new socket for each request\r\n\r\nhttp.Agent documentation says\r\n` [â€¦] It maintains a queue of pending requests for a given host and port, reusing a single socket connection for each until the queue is empty [â€¦]`\r\nWhich is in contrast to the description of the maxSockets option\r\n`[â€¦] Each request will use a new socket until the maximum is reached. []`\r\n\r\nSo will it reuse a single socket connection or use a new socket for each request?",
        "labels": "doc",
        "id": 43965
    },
    {
        "title": "doc: stream.pipeline documentation is misleading WRT 'Iterable' as a valid first argument.",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n- **Version**: v14.7.0\r\n- **Platform**: Windows 10 (64-bit)\r\n- **Subsystem**: `stream`\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/stream.html#stream_stream_pipeline_source_transforms_destination_callback\r\n\r\n## Description\r\n\r\nThe documentation states the following:\r\n\r\n> ![image](https://user-images.githubusercontent.com/3902892/101421955-64b34c80-38aa-11eb-9b09-e3bc5d9db7c2.png)\r\n\r\nThis is misleading, as an `Array` is a valid `Iterable`, yet using an `Array` as the first argument with multiple streams results in an error:\r\n\r\n```js\r\nconst stream = require(\"stream\");\r\n\r\nasync function main() {\r\n    await stream.pipeline(\r\n        /*stream1*/ [1, 2, 3],\r\n        /*stream2*/ new stream.PassThrough({ objectMode: true }),\r\n        /*callback*/ () => { console.log(\"done\"); });\r\n}\r\n\r\nmain().catch(e => console.error(e));\r\n```\r\n\r\nOutput:\r\n\r\n```\r\nTypeError [ERR_INVALID_ARG_TYPE]: The \"source\" argument must be of type function or an instance of Stream, Iterable, or AsyncIterable. Received type number (1)\r\n    at Function.pipeline (internal/streams/pipeline.js:199:15)\r\n    at main (D:\\dev\\scratch\\pipeline\\index.js:4:18)\r\n    at Object.<anonymous> (D:\\dev\\scratch\\pipeline\\index.js:10:1)\r\n    at Module._compile (internal/modules/cjs/loader.js:1256:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1277:10)\r\n    at Module.load (internal/modules/cjs/loader.js:1105:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:967:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:60:12)\r\n    at internal/main/run_main_module.js:17:47 {\r\n  code: 'ERR_INVALID_ARG_TYPE'\r\n}\r\n```\r\n\r\nHowever, if you change `[1, 2, 3]` to `[1, 2, 3].values()` then the call evaluates successfully. It seems like `stream.pipeline` sees the first argument is an `Array` and always picks `stream.pipeline(streams, callback)`, even if there is a `destination` and may be one or more `transforms`.\r\n\r\nThe way the parameters are represented is also confusing. It looks like they are sorted alphabetically rather than based on the \"overload\" being called, so the \"Returns:\" bullet points don't make much sense.\r\n\r\n---\r\n\r\n- [ ] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 43966
    },
    {
        "title": "doc: Expect nodejs doc site to have an api search feature.",
        "body": "",
        "labels": "doc",
        "id": 43967
    },
    {
        "title": "doc: Add issue reference to the PR template",
        "body": "Affected URL(s):\r\n\r\n- https://github.com/nodejs/node/blob/master/doc/guides/contributing/pull-requests.md#step-8-opening-the-pull-request\r\n\r\n## Description\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nâœï¸\r\n\r\nThe PR template should include a ```Reference isssue (Fixes #issue_number)``` so the the PR can be tracked back to the issue easily. For a beginner trying to read PRs to become comfortable with the codebase, it is really helpful if one can directly reach the issue the PR fixes.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43968
    },
    {
        "title": "doc: unclear conditions under which Worker's 'messageerror' is emmited",
        "body": "<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 14.15.1\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux 5.4.0-54-generic #60-Ubuntu SMP Fri Nov 6 10:37:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: worker_threads\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/worker_threads.html#worker_threads_event_messageerror\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nIt is unclear from the documentation how one could cause/simulate `messageerror` to be emitted by the Worker. It would be useful to understand the conditions when it happens and also be able to simulate such situations when testing code. A concrete example when this would be helpful is in [bree codebase](https://github.com/breejs/bree/blob/ef8a363df0bf4652cf027d4ed1d54a9f85f0d465/src/index.js#L655-L663), where test coverage has been skipped because there's no way to simulate this event.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43969
    },
    {
        "title": "doc: history shows wrong version for conditional package export support",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 12.16.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: All\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: loader\r\n\r\n## Location\r\n\r\nModules: Packages\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/packages.html#packages_exports\r\n\r\n## Description\r\n\r\nUnder the \"history\" section, the docs say that conditional export support was added and also unflagged in 12.16, which doesn't seem to be the case. 12.17.0 appears to be the first version that supports conditional exports and I can't get either conditional exports or the `--experimental-conditional-exports` flag to work in 12.16.0.\r\n\r\n![image](https://user-images.githubusercontent.com/2898433/99498789-1d811c80-29cc-11eb-9505-0978cad0b281.png)\r\n\r\n---\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43970
    },
    {
        "title": "How to unref readline?",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\n```js\r\nconst readline = require('readline');\r\n\r\nconst input = readline.createInterface({\r\n\tinput: process.stdin\r\n});\r\n```\r\n\r\nThe code above just hangs.\r\n\r\n**Describe the solution you'd like**\r\n\r\n```diff\r\nconst readline = require('readline');\r\n\r\nconst input = readline.createInterface({\r\n\tinput: process.stdin\r\n});\r\n\r\n+input.unref();\r\n```\r\n\r\n**Describe alternatives you've considered**\r\n\r\nNone yet.\r\n",
        "labels": "doc",
        "id": 43971
    },
    {
        "title": "doc: advices to use full-icu package is outdated",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 13.x.x and above. In fact, since node is delivered with full-icu by default\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: all\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: Duno, i18n maybe ?\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/docs/latest-v13.x/api/intl.html#intl_providing_icu_data_at_runtime\r\n\r\n## Description\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nSince the first version delivered with full-icu by default, Node 13.x.x, the documentation keep advising to use full-icu package if we want to keep up to date with the latest i18n data.\r\n\r\nBut unfortunately, this package only fetch ICU data files for node versions built with small-icu support ...\r\n\r\nSee the corresponding piece of code [here](https://github.com/unicode-org/full-icu-npm/blob/c5492547f1cb25c6835e0a9c1929697ca26efc3f/postinstall.js#L23)\r\n\r\nThus, it is miss leading the reader to be advised to use a tool which is in mutual exclusion with the system that is released by default.\r\n\r\nObviously, not all users of Node 13 and above will go for the default full-icu one, especially if they have memory footprint constraints. \r\n\r\nBut I guess that with the whole [ micro services / containerization / cloud ] hype those days, most peoples don't care much to finely tune there images and go for the official ones on Docker hub ... which themselves comes in a single flavor each, that is, the full one since Node 13 ðŸ­ \r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43972
    },
    {
        "title": "AsyncResource.bind does not forward arguments",
        "body": "Using  **Node 12.19.0**:\r\nWhen binding a function with AsyncResource.bind, the arguments are not forwarded.\r\nI had to write this workaround to make it work:  \r\n```js\r\nfunction bindWorkAround(cb) {\r\n\tAsyncResource.bind(invokeOriginal);\r\n\tlet _arguments;\r\n\treturn onData;\r\n\r\n\tfunction onData() {\r\n\t\t_arguments = arguments;\r\n\t\tinvokeOriginal();\r\n\t}\r\n\r\n\tfunction invokeOriginal() {\r\n\t\tcb.apply(null, _arguments);\r\n\t}\r\n\r\n}\r\n```",
        "labels": "doc",
        "id": 43973
    },
    {
        "title": "REPL: _ and _error variables are not available by default in a repl instance with a modified context",
        "body": "* **Version**: 15.1.0\r\n* **Platform**: 19.6.0 Darwin Kernel Version 19.6.0: Mon Aug 31 22:12:52 PDT 2020; root:xnu-6153.141.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: repl\r\n\r\n### What steps will reproduce the bug?\r\n\r\nStart an application that imports `repl` and modifies the context. For example: [https://github.com/sjsyrek/malcjs](https://github.com/sjsyrek/malcjs)\r\n\r\nUpdate: I applied a workaround to this repo (see below), but if the lines starting at [https://github.com/sjsyrek/malcjs/blob/master/src/index.js#L67](https://github.com/sjsyrek/malcjs/blob/master/src/index.js#L67) are commented out, the issue can still be reproduced.\r\n\r\nBasically,\r\n```js\r\nconst context = {\r\n  // whatever\r\n};\r\n\r\nvm.createContext(context);\r\n\r\nconst replServer = repl.start();\r\n\r\nreplServer.context = context;\r\n```\r\n\r\nTry to use the `_` or `_error` variables for previously evaluated expressions. They do not work as expected.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEvery time.\r\n\r\n### What is the expected behavior?\r\n\r\n[https://nodejs.org/api/repl.html#repl_assignment_of_the_underscore_variable](https://nodejs.org/api/repl.html#repl_assignment_of_the_underscore_variable)\r\n\r\nI expect that when I create my own context for a custom REPL, it won't affect any other initialization steps, including the availability of the (extremely useful) `_` and `_error` variables. I cannot say for sure that anything else is missed in this scenario, but it would be worth investigating (example, entering `util.inspect.replDefaults` in a custom REPL results in an error, whereas the standard REPL returns the inspection defaults).\r\n\r\n### What do you see instead?\r\n\r\nI have observed the strange behavior that when I enter `_` at the repl prompt, it gets duplicated, i.e. `__` is entered instead and I see this error:\r\n```\r\nUncaught ReferenceError: __ is not defined\r\n```\r\n\r\n### Additional information\r\n\r\nIt seems that I was able to resolve this issue by adapting [code](https://github.com/nodejs/node/blob/14699846452e627f97dedb85991eea67d932a79d/lib/repl.js#L1013) directly from the `repl` package and defining these variables myself, e.g.:\r\n```js\r\n\r\nObject.defineProperty(replServer.context, \"_\", {\r\n  configurable: true,\r\n  get: () => replServer.last,\r\n  set: (value) => {\r\n    replServer.last = value;\r\n    if (!replServer.underscoreAssigned) {\r\n      replServer.underscoreAssigned = true;\r\n      replServer.output.write(\"Expression assignment to _ now disabled.\\n\");\r\n    }\r\n  },\r\n});\r\n\r\nObject.defineProperty(replServer.context, \"_error\", {\r\n  configurable: true,\r\n  get: () => replServer.lastError,\r\n  set: (value) => {\r\n    replServer.lastError = value;\r\n    if (!replServer.underscoreErrAssigned) {\r\n      replServer.underscoreErrAssigned = true;\r\n      replServer.output.write(\r\n        \"Expression assignment to _error now disabled.\\n\"\r\n      );\r\n    }\r\n  },\r\n});\r\n```\r\n\r\nBut I assume this is not desirable.",
        "labels": "doc",
        "id": 43974
    },
    {
        "title": "doc:  acknowledge process._getActiveHandles() and process._getActiveRequests()",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: node>=15\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: all platforms\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: process\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/dist/latest-v15.x/docs/api/process.htmll\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nI believe the functions process._getActiveHandles() and process._getActiveRequests() should be documented, and be acknowledged; We should consider adding non-dashed alias as it is used for some time in the ecosystem.\r\nCurrently there are packages which rely at those methods. Even if they will be considered for removal, a regular deprecation process should be considered.\r\nAlternatively, a consensual interface should be considered, if there is a reason for which, the functions aren't documented.\r\nAnyway,  as the functionality is in use and appears time to time in the community, we should embrace these functionalities, as part of the standard documented node features.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ?] I would like to work on this issue and\r\n      submit a pull request.\r\n\r\n\r\n? question mark stands for \"it depends\".",
        "labels": "doc",
        "id": 43975
    },
    {
        "title": "doc: WorkerPool async_hooks example warns about max listeners",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 15.0.1\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: All\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: async_hooks\r\n\r\n## Location\r\n\r\nThe example WorkerPool using async_hooks\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/async_hooks.html#async_hooks_using_asyncresource_for_a_worker_thread_pool\r\n\r\n## Description\r\n\r\nThe code I'm explicitly concerned about is\r\n```\r\n  runTask(task, callback) {\r\n    if (this.freeWorkers.length === 0) {\r\n      // No free threads, wait until a worker thread becomes free.\r\n      this.once(kWorkerFreedEvent, () => this.runTask(task, callback));\r\n      return;\r\n    }\r\n\r\n    // ...\r\n```\r\n\r\nSince this code snippet is presented explicitly as how to do something and is very much code that developers could easily end up copy-pasting into their own codebase, I figured it was worth raising as a potential issue.\r\n\r\nThis code has 2 issues:\r\n* This quickly triggers a `MaxListenersExceededWarning` since it adds a listener for every queued task and that number is unbounded\r\n* This is O(N^2) because when the `kWorkerFreedEvent` fires, it fires _every_ callback (even though N-1 will just be re-queued), and `once` listeners have to do a linear search to remove themselves when they fire\r\n\r\nThoughts?\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43976
    },
    {
        "title": "What are easy thing that new hacker(contributor) can do to contribute to node?",
        "body": "",
        "labels": "doc",
        "id": 43977
    },
    {
        "title": "doc: ",
        "body": "# ðŸ“— API Reference Docs Problem\n\n<!--\n\nThank you for wanting to make nodejs.org better!\n\nThis template is for issues with the Node.js API\nreference documentation.\n\nFor problems with nodejs.org beyond the API\nreference documentation, please open an issue\nusing the issue tracker for our site repository.\n\n  https://github.com/nodejs/nodejs.org\n\nFor more general support, please open an issue\nusing the issue tracker for our help repository.\n\n  https://github.com/nodejs/help\n\n---\n\nFor the issue title, please enter a one-line\nsummary after â€œdoc: â€ (preferably 50 characters\nor less and no more than 72).\n\nThe â€œâœï¸â€ are placeholders signifying requests for\ninput. Replace them with your responses.\n\nIf you are unsure of something, do your best.\n\n-->\n\n<!-- The output of â€œnode --versionâ€. -->\n\n- **Version**: âœï¸\n\n<!-- The output of â€œuname -aâ€ (UNIX) or version\nand 32-bit or 64-bit (Windows). -->\n\n- **Platform**: âœï¸\n\n<!-- The name of affected core module. -->\n\n- **Subsystem**: âœï¸\n\n## Location\n\n_Section of the site where the content exists_\n\nAffected URL(s):\n\n- https://nodejs.org/api/âœï¸\n\n## Description\n\n_Concise explanation of the problem_\n\n<!-- If applicable, include any screenshots that\nmay help solve the problem. -->\n\nâœï¸\n\n---\n\n<!-- Use â€œ[x]â€ to check the box below if you are\ninterested in contributing. -->\n\n- [ ] I would like to work on this issue and\n      submit a pull request.\n",
        "labels": "doc",
        "id": 43978
    },
    {
        "title": "Enable Dark Mode for NodeJS docs",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nPlease enable dark mode for [node docs](https://nodejs.org/api/) like the [nodejs.dev](https://nodejs.dev/learn) website.\r\n\r\n",
        "labels": "doc",
        "id": 43979
    },
    {
        "title": "doc: punycode alternative name collision",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v12.19.0 LTS\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Darwin x86_64\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: punycode\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/punycode.html#punycode_punycode\r\n- https://nodejs.org/dist/latest-v12.x/docs/api/punycode.html#punycode_punycode\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nThe punycode module docs note that it is deprecated and suggest using Punycode.js as an alternative:\r\n\r\n> **The version of the punycode module bundled in Node.js is being deprecated**.\r\n> In a future major version of Node.js this module will be removed. Users\r\n> currently depending on the `punycode` module should switch to using the\r\n> userland-provided [Punycode.js][] module instead.\r\n> \r\n> [â€¦]\r\n> \r\n> The `punycode` module is a third-party dependency used by Node.js and\r\n> made available to developers as a convenience. Fixes or other modifications to\r\n> the module must be directed to the [Punycode.js][] project.\r\n\r\nThe alternative suggested [is published as `punycode` on npm](https://www.npmjs.com/package/punycode) and thus its name is shadowed by the bundled version. A workaround is required to use the third-party module in place of the bundled module (see https://github.com/bestiejs/punycode.js/issues/79 and https://github.com/bestiejs/punycode.js/pull/113).\r\n\r\nThe API docs should either document the workaround required to use the suggested alternative, not suggest an alternative, or suggest an alternative that doesn't require a workaround.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n\r\n[Punycode.js]: https://github.com/bestiejs/punycode.js",
        "labels": "doc",
        "id": 43980
    },
    {
        "title": "doc: performance.measure always requires three arguments",
        "body": "(I was looking doc for an old version)",
        "labels": "doc",
        "id": 43981
    },
    {
        "title": "fs.read documentation does not specify how to detect EOF condition",
        "body": "As far as I can tell, neither `fs.read` nor `FileHandle#read` specify how to detect when the end of a file has been reached, nor can I find this information elsewhere in the `fs` documentation.\r\n\r\nThe `fs.createReadStream` implementation [suggests](https://github.com/nodejs/node/blob/db0e991d528f7fb3ccc90b183b2c2b875bf540ec/lib/internal/fs/streams.js#L194) that the answer to this question is \"when `bytesRead` is 0\", but this should be added to the documentation if that is indeed the correct way to detect this condition.",
        "labels": "doc",
        "id": 43982
    },
    {
        "title": "doc: Options passed needlessly to https request object and agent prop",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v14.12.0\r\n\r\n## Location\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/https.html#https_https_request_options_callback\r\n\r\n## Description\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nIn the following example provided for the https.request method, the request config object is passed both to the top level https request object, and to the agent property of said object. \r\nThis seems to either be a typo, or unclear. I would expect to see the following: \r\n\r\n- \"key\" and \"cert\" should be provided to the agent object only, and should not appear at the top level of the options object.\r\n- The properties that comprise the URL object (\"hostname\",  \"port\", \"path\" and \"method\") should not be provided to the agent object. \r\n\r\nI think this would avoid confusion.\r\n\r\n```\r\nconst options = {\r\n  hostname: 'encrypted.google.com',\r\n  port: 443,\r\n  path: '/',\r\n  method: 'GET',\r\n  key: fs.readFileSync('test/fixtures/keys/agent2-key.pem'),\r\n  cert: fs.readFileSync('test/fixtures/keys/agent2-cert.pem')\r\n};\r\noptions.agent = new https.Agent(options);\r\n\r\nconst req = https.request(options, (res) => {\r\n  // ...\r\n});\r\n```\r\n\r\n\r\n",
        "labels": "doc",
        "id": 43983
    },
    {
        "title": "doc: crypto.sign and crypto.verify string/buffer keys must be pem",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v12.16.2\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Darwin Jacobs-MacBook-Pro.local 18.6.0 Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019; root:xnu-4903.261.4~2/RELEASE_X86_64 x86_64\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: crypto\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/crypto.html#crypto_crypto_sign_algorithm_data_key\r\n- https://nodejs.org/api/crypto.html#crypto_crypto_verify_algorithm_data_key_signature\r\n- possibly (probably?) others\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\nAccording to the documentation for `crypto.sign` and `crypto.verify`, the `key` argument may be a string, buffer, object, or `KeyObject`. It does not mention that if the key is a string or buffer, it must be `pem` format. Passing a key with `der` format will result in an error `error:0909006C:PEM routines:get_name:no start line`\r\n\r\nThe source code is quite clear that keys are assumed to be pem. https://github.com/nodejs/node/blob/d6fe46f749bf39f8cb0a9b29f13f34672122c4eb/lib/internal/crypto/keys.js#L277-L280\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43984
    },
    {
        "title": "Reloading page bypasses TLS client authentication",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.18.3\r\n* **Platform**: Linux 5.8.8-100.fc31.x86_64 #1 SMP Wed Sep 9 20:29:23 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: \r\n\r\n### What steps will reproduce the bug?\r\n- Obtain (or create) a CA certificate, a server certificate, and a server key supplied by said CA.\r\n- Compile (with typescript) and run the following code:\r\n```\r\nimport fs from 'fs';\r\nimport path from 'path';\r\nimport https from 'https';\r\nimport tls from 'tls';\r\nimport express from 'express';\r\n\r\n/* Alias environment variables */\r\nconst port = process.env.PORT || 443;\r\n\r\nconst httpsOptions = {\r\n    key: fs.readFileSync(path.join('certs', 'server.key')),\r\n    cert: fs.readFileSync(path.join('certs', 'server.crt')),\r\n    ca: fs.readFileSync(path.join('certs', 'ca.crt')),\r\n    requestCert: true,\r\n    rejectUnauthorized: false /* This is necessary to accept self-signed certificates, we will perform the authentication ourselves */\r\n};\r\n\r\n/* Create Express app */\r\nconst expressApp = express();\r\nconst expressServer = https.createServer(httpsOptions, expressApp);\r\n\r\nexpressApp.use((req,res,next) => {\r\n    console.log((req.socket as tls.TLSSocket).authorized ? 'true' : 'false');\r\n    if (!(req.socket as tls.TLSSocket).authorized) {\r\n        return res.status(401).send('Unauthorized');\r\n    }\r\n    next();\r\n});\r\n\r\nexpressServer.listen(port, () => {\r\n    console.log(`Server listening on port ${port}`);\r\n});\r\n```\r\n- Open Firefox (version 80) and go to https://localhost. You should have your connection rejected (output is 'false').\r\n- Reload the page. Your connection is now accepted (output is 'true').\r\n- This curiously doesn't happen on Chromium.\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n- Always reproducible. Chromium seems to not trigger the issue.\r\n\r\n### What is the expected behavior?\r\n- Connection should always be rejected\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n- Connection is accepted after page reload\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n- According to documentation at https://nodejs.org/api/tls.html#tls_tlssocket_authorized the `(req.socket as tls.TLSSocket).authorized` flag should always be false if the client certificate doesn't match the server CA. In this case it becomes true after a page reload from Firefox for unknown reasons.\r\n- This issue is described also in a stack overflow entry: https://stackoverflow.com/questions/60367338/result-of-req-socket-authorized-is-not-correct-using-nodejs-https-and-express\r\n- I'm guessing it might be due to some TLS connection reuse logic.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "doc",
        "id": 43985
    },
    {
        "title": "document cross compile arm on linux",
        "body": "I didn't find it in `BUILDING.md`, but it looks like this in our Jenkins CI.\r\n\r\ncc @bnoordhuis @targos @nodejs/platform-arm ",
        "labels": "doc",
        "id": 43986
    },
    {
        "title": "doc,tools: `checkLinks.js` does not cover `api`",
        "body": "This should be tested when building the HTML, but apparently it only tests links internal to `all.html` page:\r\n\r\nhttps://github.com/nodejs/node/blob/9d12c14b19bc30baa4cf556a0b8281e76637f7db/tools/doc/allhtml.js#L85-L88\r\n\r\nUsually that would cover all links internal to the docs, as all links to doc pages are stripped from the filename to keep only the hash part:\r\n\r\nhttps://github.com/nodejs/node/blob/9d12c14b19bc30baa4cf556a0b8281e76637f7db/tools/doc/allhtml.js#L39-L45\r\n\r\nBut in this case, because `modules_module.html` doesn't exist, it's treated as an external page and the broken links slip through the testâ€¦\r\n\r\n> I haven't dug into why but it looks like the api docs are deliberately excluded\r\n\r\nYes indeed. The reason `checkLinks.js` does not cover `api` is because we are using `.html` extension to reference other doc pages, while `checkLinks.js` would expect `.md`. One way of fixing it would be to use `.md` extensions in the Markdown files, and use `checkLinks.js` to test said links â€“ it would also improve the experience of navigating the docs through GitHub web UI. Another way would be to tweak the current test to make sure this doesn't reproduce.\r\n\r\n_Originally posted by @aduh95 in https://github.com/nodejs/node/pull/35182#issuecomment-692037404_",
        "labels": "doc",
        "id": 43987
    },
    {
        "title": "doc: undocumented magic: async iterator over fs.Dir will call dir.close() on iteration end",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: âœï¸v14.10.1\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: âœï¸Linux 4.19.104-microsoft-standard #1 SMP Wed Feb 19 06:37:35 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: âœï¸\r\nfs\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\nhttps://nodejs.org/api/fs.html#fs_class_fs_dir\r\n\r\n## Description\r\n\r\nI'm trying the [fs.Dir](https://nodejs.org/api/fs.html#fs_class_fs_dir) class which was added since node v12.12:\r\n\r\n```js\r\n// hello-world.js\r\nconst fs = require('fs');\r\n\r\n(async function () {\r\n  const dir = await fs.promises.opendir(__dirname);\r\n  for await (const dirent of dir) {\r\n    console.log('name:', dirent.name, 'isDir:', dirent.isDirectory());\r\n  }\r\n  return dir.close();\r\n})();\r\n\r\n```\r\n\r\n```\r\n$ node hello-world.js\r\n```\r\n\r\nIt works as expected, but in the end when calling `dir.close()`, it throws `(node:3218) UnhandledPromiseRejectionWarning: Error [ERR_DIR_CLOSED]: Directory handle was closed\r\nat Dir.close (internal/fs/dir.js:161:13)`. \r\n\r\nAfter asking on stackoverflow, with the help of others, I found that the async iterator will auto close the dir after iteration is over, so I don't need to (and cannot) clean up with `dir.close()` myself. This can be seen in the source code [here](https://github.com/nodejs/node/blob/master/lib/internal/fs/dir.js#L208). \r\n\r\nThis magic is probably good for many developers, but it also throws for those who are careful to code correctly, so I think it should be mentioned in the doc.\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43988
    },
    {
        "title": "Visited doc links styling is visually distracting",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nhttps://github.com/nodejs/node/pull/35034 removed the default styling for links, which is now causing visited links to contrast with all other links and is visually distracting. Perhaps the original issue can be solved some other way?",
        "labels": "doc",
        "id": 43989
    },
    {
        "title": "doc: ClientRequest should extend OutgoingMessage in the docs",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: all\r\n- **Platform**: n/a\r\n- **Subsystem**: http\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/dist/latest-v14.x/docs/api/http.html#http_class_http_clientrequest\r\n\r\n## Description\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\n[`ClientRequest` extends `OutgoingMessage`](https://github.com/nodejs/node/blob/89f2d465cb4ced4fe27725f38ec6143e19136e7b/lib/_http_client.js#L327-L328), but the documentation says it extends `Stream`, which is not entirely incorrect since `OutgoingMessage` extends `Stream`, but users might not be aware that methods from `OutgoingMessage` are available on `ClientRequest` as well.\r\n\r\nDepends on https://github.com/nodejs/node/issues/33847 since OutgoingMessage is not documented at the moment.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43990
    },
    {
        "title": "doc: console.time() Does Not Document PR #29251 Changes",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 14.9.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Windows 10 2004 64-bit\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: Console\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/console.html#console_console_time_label\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nThe current documentation for console.time states \"...when calling console.timeEnd() to stop the timer and output the elapsed time in milliseconds to stdout\". However, since the application of PR #29251 that affects Node.js V13 and higher, this behavior changed to \"display timeEnd with suitable time unit\". For example, if the elapsed time is  3869ms, console.timeEnd() now displays \"3.869s\". For greater values, it will also display hours and minutes per the code in  lib/internal/console/constructor.js. In the examples for console.timeLog() and consooe.timeEnd(), none show anything other than milliseconds as an output.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43991
    },
    {
        "title": "doc: active module page not highlighted in sidebar nav",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: n/a (current master branch)\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: n/a\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: docs\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- http://localhost:8000/api/module.html\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nSee the title of the issue as is self-explanatory.\r\n\r\n### Working\r\n![image](https://user-images.githubusercontent.com/17770407/91643447-4fa06500-ea01-11ea-8470-75bfd58a9b2c.png)\r\n\r\n### Non-working\r\n![image](https://user-images.githubusercontent.com/17770407/91643457-5fb84480-ea01-11ea-853a-1c675b8b953b.png)\r\n\r\nThis was introduced relatively recently and probably has to do w/ the fact that there are `<code>` tags in there.\r\n\r\n/cc @aduh95 as is most likely the most familiar w/ this problem\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43992
    },
    {
        "title": "doc: esm: explain `* as alias` behaviour with cjs modules",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 12.18.3\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Darwin rifler-osx 19.6.0 Darwin Kernel Version 19.6.0: Sun Jul  5 00:43:10 PDT 2020; root:xnu-6153.141.1~9/RELEASE_X86_64 x86_64\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: ECMAScript modules\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/dist/latest-v12.x/docs/api/esm.html\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nfor example, `React@16.13.1` is cjs-only package now\r\n\r\n```js\r\n// index.mjs\r\n\r\nimport React from 'react';\r\nconsole.log(React);\r\n\r\n// {\r\n//     Children: {\r\n//         map: [Function: mapChildren],\r\n//         forEach: [Function: forEachChildren],\r\n//         count: [Function: countChildren],\r\n//         toArray: [Function: toArray],\r\n//         only: [Function: onlyChild]\r\n//     },\r\n//     Component: [Function: Component],\r\n// ........\r\n```\r\n\r\n```js\r\n// index.mjs\r\n\r\nimport * as React from 'react';\r\nconsole.log(React);\r\n\r\n// [Module] {\r\n// default: {\r\n//         Children: {\r\n//             map: [Function: mapChildren],\r\n//             forEach: [Function: forEachChildren],\r\n//             count: [Function: countChildren],\r\n//             toArray: [Function: toArray],\r\n//             only: [Function: onlyChild]\r\n//         },\r\n//         Component: [Function: Component],\r\n// ........\r\n\r\n```\r\n\r\nIn my opinion it is not obvious (and maybe not interoperable with existing code) and it will be nice to document\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43993
    },
    {
        "title": "doc: Buffer.prototype.byteLength is undocumented",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n- **Subsystem**:  buffer\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/buffer.html\r\n\r\n## Description\r\n\r\nBuffer instances have a undocumented `.byteLength` property. We should document it. Docs only exist for the  static method `Buffer.byteLength` but not for `Buffer.prototype.byteLength`.\r\n\r\n````js\r\n> Buffer.from(\"ðŸ“—\").byteLength\r\n4\r\n````\r\n\r\n---\r\n\r\n- [ ] I would like to work on this issue and submit a pull request.",
        "labels": "doc",
        "id": 43994
    },
    {
        "title": "doc: child_process.kill() on windows needs clarification",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v14 and previous ones as well, like v12 LTS\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Windows\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: child_process signals\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/child_process.html\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nThe NodeJS signals documentation (https://nodejs.org/api/process.html#process_signal_events) is pretty clear that on windows child_process.kill(<signal here>) does NOT actually send the signal, but rather just kills the child process abruptly.\r\n\r\nHowever, the child_process.kill() documentation does not make this clarification, and it's opening sentence (\"The subprocess.kill() method sends a signal to the child process. \") leads one to believe that the signal will in fact be sent to the child process on any platform, windows included.\r\n\r\nI'd love to just see a quick blurb/sentence that clarifies the behavior on windows vs other platforms (or perhaps just a link pointing to the signals documentation - https://nodejs.org/api/process.html#process_signal_events).\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43995
    },
    {
        "title": "dns.resolvePtr() seems to always return ENODATA",
        "body": "* **Version**: v12.18.0 / v12.18.3\r\n* **Platform**: Red Hat Enterprise Linux Server release 7.8 / Windows Subsystem for Linux (Ubuntu)\r\n* **Subsystem**: DNS\r\n\r\n### What steps will reproduce the bug?\r\n```\r\nconst execSync = require('child_process').execSync;\r\nconst DnsResolver = require('dns');\r\n\r\nconst dns = new DnsResolver.promises.Resolver();\r\n\r\n// **************************************************************\r\n\r\nasync function test(hostname) {\r\n  let data = '';\r\n\r\n  console.log('--------------------------------------------------');\r\n  console.log('hostname:', hostname);\r\n\r\n  let ipAddress = '';\r\n\r\n  // get ipAddress for the hostname\r\n\r\n  try {\r\n    data = await dns.resolve4(hostname);\r\n    ipAddress = data[0];\r\n    console.log('ipAddress:', ipAddress);\r\n  } catch (error) {\r\n    console.log('ipAddress:', error.message);\r\n  }\r\n\r\n  // resolve PTR record(s)\r\n\r\n  try {\r\n    data = await dns.resolvePtr(hostname);\r\n    console.log(`dns.resolvePtr('${hostname}'):`, data);\r\n  } catch (error) {\r\n    console.log(`dns.resolvePtr('${hostname}'):`, error.message);\r\n  }\r\n\r\n  // execute 'dig' for comparison\r\n\r\n  if (ipAddress) {\r\n    try {\r\n      const cmd = `dig -x ${ipAddress}`\r\n      console.log(cmd);\r\n      const data = execSync(cmd);\r\n      console.log(data.toString());\r\n    } catch (error) {\r\n      console.log(error);\r\n    }\r\n  }\r\n}\r\n\r\n// **************************************************************\r\n\r\n(async function main() {\r\n  await test('support.microsoft.com');\r\n  await test('a23-193-40-147.deploy.static.akamaitechnologies.com');\r\n})();\r\n```\r\n### Actual Output\r\n```\r\n--------------------------------------------------\r\nhostname: support.microsoft.com\r\nipAddress: 23.193.40.147\r\ndns.resolvePtr('support.microsoft.com'): queryPtr ENODATA support.microsoft.com\r\ndig -x 23.193.40.147\r\n\r\n; <<>> DiG 9.16.1-Ubuntu <<>> -x 23.193.40.147\r\n;; global options: +cmd\r\n;; Got answer:\r\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 20389\r\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\r\n\r\n;; OPT PSEUDOSECTION:\r\n; EDNS: version: 0, flags:; udp: 4096\r\n;; QUESTION SECTION:\r\n;147.40.193.23.in-addr.arpa.    IN      PTR\r\n\r\n;; ANSWER SECTION:\r\n147.40.193.23.in-addr.arpa. 27097 IN    PTR     a23-193-40-147.deploy.static.akamaitechnologies.com.\r\n\r\n;; Query time: 20 msec\r\n;; SERVER: 192.168.10.1#53(192.168.10.1)\r\n;; WHEN: Tue Aug 18 13:04:04 EDT 2020\r\n;; MSG SIZE  rcvd: 120\r\n\r\n\r\n--------------------------------------------------\r\nhostname: a23-193-40-147.deploy.static.akamaitechnologies.com\r\nipAddress: 23.193.40.147\r\ndns.resolvePtr('a23-193-40-147.deploy.static.akamaitechnologies.com'): queryPtr ENODATA a23-193-40-147.deploy.static.akamaitechnologies.com\r\ndig -x 23.193.40.147\r\n\r\n; <<>> DiG 9.16.1-Ubuntu <<>> -x 23.193.40.147\r\n;; global options: +cmd\r\n;; Got answer:\r\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 32277\r\n;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1\r\n\r\n;; OPT PSEUDOSECTION:\r\n; EDNS: version: 0, flags:; udp: 4096\r\n;; QUESTION SECTION:\r\n;147.40.193.23.in-addr.arpa.    IN      PTR\r\n\r\n;; ANSWER SECTION:\r\n147.40.193.23.in-addr.arpa. 38791 IN    PTR     a23-193-40-147.deploy.static.akamaitechnologies.com.\r\n\r\n;; Query time: 19 msec\r\n;; SERVER: 192.168.10.1#53(192.168.10.1)\r\n;; WHEN: Tue Aug 18 13:04:05 EDT 2020\r\n;; MSG SIZE  rcvd: 120\r\n```\r\n### Additional Information\r\n\r\nDuring my testing, to my knowledge, I have never received a PTR record while using the DNS module. As seen from the results above, 'dig' does return PTR information. I would assume I would get the IP address when calling resolvePtr(\\<hostname\\>)? Instead, I always seem to get ENODATA. Thanks.\r\n",
        "labels": "doc",
        "id": 43996
    },
    {
        "title": "doc: broken links in doc/guides/commit-queue.md",
        "body": "This fails on my machine:\r\n\r\n```\r\n./configure --ninja\r\nmake test -j12 V=\r\n```\r\n\r\n```\r\nRunning Markdown link checker...\r\nBroken link at /home/mzasso/git/nodejs/node/doc/guides/commit-queue.md:53:5 (/.github/workflows/commit_queue.yml)\r\nBroken link at /home/mzasso/git/nodejs/node/doc/guides/commit-queue.md:76:1 (./tools/actions/commit-queue.sh)\r\nmake[1]: *** [Makefile:604: test-doc] Error 1\r\n```",
        "labels": "doc",
        "id": 43997
    },
    {
        "title": "doc: unable to switch versions due to spacing",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n- **Browser**: Chrome\r\n- **Platform**: Ubuntu 20.04.1 LTS\r\n\r\n## Location\r\n\r\n[latest api documentation](https://nodejs.org/docs/latest-v12.x/api/)\r\n\r\n## Description\r\n\r\nI'm unable to switch versions because of the spacing that exists between the version switcher button and version switcher dropdown:\r\n\r\n![image](https://user-images.githubusercontent.com/20448879/90206560-fb1aaa00-ddb1-11ea-9994-e3b7fc2ea1f7.gif)\r\n\r\n---\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43998
    },
    {
        "title": "doc: ES module wrapper guide",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 14.7.0\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: ESM\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/dist/latest-v12.x/docs/api/esm.html#esm_approach_1_use_an_es_module_wrapper\r\n\r\n## Description\r\nI was wondering if it would be better to write this example as:\r\n```js\r\n{\r\n  \"type\": \"commonjs\",\r\n  \"main\": \"./index.js\",\r\n  \"exports\": {\r\n    \"import\": \"./wrapper.mjs\",\r\n    \"require\": \"./index.js\"\r\n  }\r\n}\r\n```\r\n\r\nsince its current form might be misleading for package maintainers that want to support both ESM and CommonJS contexts. Maybe what happened [here](https://snyk.io/blog/why-did-is-promise-happen-and-what-can-we-learn-from-it/) could be prevented if the documentation was more clear.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "doc",
        "id": 43999
    },
    {
        "title": "Improve documentation on Dual Module Packages",
        "body": "* **Version**: `v14.4.0`\r\n* **Platform**: Windows 10\r\n* **Subsystem**: Windows\r\n\r\n### What steps will reproduce the bug?\r\n```\r\ngit clone git@github.com:MicahZoltu/dual-module-package-repro.git\r\ncd dual-module-package-repro/app-package\r\nnpm install\r\nnode index.mjs\r\n# notice it works\r\nnode index.cjs\r\n# notice it does not work\r\n```\r\nThen remove `\"type\": \"module\"` from `library-package/package.json` and repeat the process:\r\n```\r\nnpm install\r\nnode index.mjs\r\n# notice it doesn't work\r\nnode index.cjs\r\n# notice it does work\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways.\r\n\r\n### What is the expected behavior?\r\nThe ability to ship an NPM package that can be used by either CJS users (any version of NodeJS) or ESM users (running NodeJS 14+)\r\n\r\n### What do you see instead?\r\nI can *either* define `type: module` and it will work as an ESM, or I can not define it or set it to CommonJS and it will work as a CJS module, but I cannot define the package.json such that the package works in both environments.\r\n\r\n### Additional information\r\nThe error indicates that NodeJS *is* correctly following the `exports` path and locating the right module in each situation, however it proceeds to load the module using a loader picked by the presence of the `type` property in `package.json`.  My expectation is that if it loads via the `exports: { import: ... }` entrypoint then that entire call stack from there down should be ESM, and if it loads via `exports: { require: ... }` then the entire call stack from there down should be CJS.\r\n\r\nError when `type: module` is not set:\r\n```\r\ndual-module-package-repro\\library-package\\index-esm.js:1\r\nexport const apple = 'apple'\r\n^^^^^^\r\n\r\nSyntaxError: Unexpected token 'export'\r\n    at wrapSafe (internal/modules/cjs/loader.js:1116:16)\r\n```\r\nError when `type: module` is set:\r\n```\r\ninternal/modules/cjs/loader.js:1216\r\n      throw new ERR_REQUIRE_ESM(filename, parentPath, packageJsonPath);\r\n      ^\r\n\r\nError [ERR_REQUIRE_ESM]: Must use import to load ES Module: ...\\dual-module-package-repro\\library-package\\index-cjs.js\r\nrequire() of ES modules is not supported.\r\nrequire() of ...\\dual-module-package-repro\\library-package\\index-cjs.js from ...\\dual-module-package-repro\\app-package\\index.cjs is an ES module file as it is a .js file whose nearest parent package.json contains \"type\": \"module\" which defines all .js files in that package scope as ES modules.\r\nInstead rename index-cjs.js to end in .cjs, change the requiring code to use import(), or remove \"type\": \"module\" from ...\\dual-module-package-repro\\library-package\\package.json.\r\n\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1216:13)\r\n```\r\n\r\n----\r\n\r\nThe [documentation](https://nodejs.org/api/esm.html#esm_conditional_exports) makes it [sound like](https://nodejs.org/api/esm.html#esm_dual_commonjs_es_module_packages) NodeJS 14 supports packages that can be used as *either* ESM or CJS, but thus far I have not figured out how to actually accomplish this.\r\n\r\nI *believe* this specific problem could be worked around by renaming files to `.cjs` and `.mjs` in the `library-package`.  However, in the real world this solution is far less tenable because I'm compiling from TypeScript which does not do import rewrites during emit (and they maintain a [very strong position](https://github.com/microsoft/TypeScript/issues/16577) that they have no intent to ever change this policy).  This means that I cannot have TypeScript emit files where the import statements have different extensions depending on the module type being targeted.  So in order to have everything be `mjs` in the ESM build output and `cjs` in the CJS build output I would need to run my code through a transformer that rewrites all import statements (both static and dynamic) and also rename all of the files to have extensions by output folder.",
        "labels": "doc",
        "id": 44000
    },
    {
        "title": "FÃ¼gen Sie 'new stream.Duplex (options)' docs 'writable' und 'readable' hinzu",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\nDies sollte hinzugefÃ¼gt werden, da es noch nicht existiert\r\n",
        "labels": "doc",
        "id": 44001
    },
    {
        "title": "doc: improper description of AsyncLocalStorage behavior",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: v12.18.2\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux kjarmicki-dell 4.15.0-109-generic #110-Ubuntu SMP Tue Jun 23 02:39:32 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: async_hooks\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/async_hooks.html#async_hooks_asynclocalstorage_run_store_callback_args\r\n\r\n## Description\r\n\r\nThere's a section in the documentation regarding `AsyncLocalStorage.run` that states:\r\n> This methods runs a function synchronously within a context and return its return value. The store is not accessible outside of the callback function or the asynchronous operations created within the callback.\r\n\r\nAs far as I can tell this is not true, for example:\r\n```js\r\nconst {AsyncLocalStorage} = require('async_hooks');\r\nconst storage = new AsyncLocalStorage();\r\n\r\nstorage.run('anything', () => {\r\n  setTimeout(() => {\r\n    console.log(storage.getStore()); // prints \"anything\"\r\n  }, 10);\r\n});\r\n```\r\nI'd consider `setTimeout` callback to be an asynchronous operation created within the callback and the store is accessible there.\r\n\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request",
        "labels": "doc",
        "id": 44002
    },
    {
        "title": "doc: Worker Threads - Worker: recieveMessageOnPort",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n## Location\r\n\r\nCode example\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/worker_threads.html#worker_threads_worker_receivemessageonport_port\r\n\r\n## Problem description\r\n\r\nI think it should be `port1` instead of `port2` in the docs since that was the port used for message transfer.\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nOriginal:\r\n\r\n```javascript\r\nconst { MessageChannel, receiveMessageOnPort } = require('worker_threads');\r\nconst { port1, port2 } = new MessageChannel();\r\nport1.postMessage({ hello: 'world' });\r\n\r\nconsole.log(receiveMessageOnPort(port2));\r\n// Prints: { message: { hello: 'world' } }\r\nconsole.log(receiveMessageOnPort(port2));\r\n// Prints: undefined\r\n```\r\n\r\nUpdated:\r\n```javascript\r\nconst { MessageChannel, receiveMessageOnPort } = require('worker_threads');\r\nconst { port1, port2 } = new MessageChannel();\r\nport1.postMessage({ hello: 'world' });\r\n\r\nconsole.log(receiveMessageOnPort(port1));\r\n// Prints: { message: { hello: 'world' } }\r\nconsole.log(receiveMessageOnPort(port2));\r\n// Prints: undefined\r\n```\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44003
    },
    {
        "title": "node --prof documentation missing from --help output",
        "body": "* **Version**: v14.5.0\r\n* **Platform**: Linux\r\n\r\nThe `node --prof` option is [documented on the website](https://nodejs.org/api/cli.html#cli_prof), but it's missing from the output of `node --help`.",
        "labels": "doc",
        "id": 44004
    },
    {
        "title": "doc: Does child_process.execFile really resolve to a ChildProcess?",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: v14.5.0\r\n- **Platform**: macOS (Darwin 19.5.0)\r\n- **Subsystem**: child_process\r\n\r\n## Location\r\n\r\n`child_process.execFile`:\r\n\r\n> If this method is invoked as its util.promisify()ed version, it returns a Promise for an Object with stdout and stderr properties. The returned ChildProcess instance is attached to the Promise as a child property. In case of an error (including any error resulting in an exit code other than 0), a rejected promise is returned, with the same error object given in the callback, but with two additional properties stdout and stderr.\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/dist/latest-v12.x/docs/api/child_process.html#child_process_child_process_execfile_file_args_options_callback\r\n- https://nodejs.org/dist/latest-v14.x/docs/api/child_process.html#child_process_child_process_execfile_file_args_options_callback\r\n\r\n## Problem description\r\n\r\nI'm trying to retrieve the status code of a process that was run using `util.promisify(child_process.execFile)`; the documentation suggests that there should be a ChildProcess \"child\" property, but that doesn't seem to exist. The only mention of ChildProcess in the source code is the return value (which gets wiped out after the function is promisified, of course).\r\n\r\nI don't think the documentation is clear enough on what it means here, and maybe a feature or bug request is also necessary.\r\n\r\n\r\n\r\n---\r\n\r\n- [x] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44005
    },
    {
        "title": "doc: npm install in docker fails ",
        "body": "Hi ,\r\n   I have a application which has totally 13 sub node applications and they are interlinked like one linking with other and along with this we have lot of 3rd party libraries. They are all getting installed properly in mac. But when tried to dockerise this and install in the hierarchal way thats installed in local it goes well upto 11th project and in the 11th module which  has only dependency to their sub modules and no 3rd part libs.  is giving with number of such warnings and stopping at the end with max stacktrace error .\r\n\r\nnpm WARN tar ENOENT: no such file or directory, open '/app/app12/node_modules/.staging/es5-ext-cefe45e3/error/#/throw.js'\r\nnpm WARN tar ENOENT: no such file or directory, open '/app/app12/node_modules/.staging/type-217172ab/CHANGELOG.md'\r\n\r\n\r\nFollowing is my dockerFile\r\n\r\n\r\nFROM node:10.16.0-alpine\r\n\r\nRUN apk --no-cache add \\\r\n      bash \\\r\n      g++ \\\r\n      ca-certificates \\\r\n      lz4-dev \\\r\n      musl-dev \\\r\n      cyrus-sasl-dev \\\r\n      openssl-dev \\\r\n      make \\\r\n      python\r\n\r\nRUN apk add --no-cache --virtual .build-deps gcc zlib-dev libc-dev bsd-compat-headers py-setuptools bash\r\n\r\nWORKDIR /app/app13\r\n\r\n\r\nCOPY ./app1 /app/app1\r\nCOPY ./app2 /app/app2\r\nCOPY ./app3 /app/app3\r\nCOPY ./app4 /app/app4\r\nCOPY ./app5 /app/app5\r\nCOPY ./app6 /app/app6\r\nCOPY ./app7 /app/app7\r\nCOPY ./app8 /app/app8\r\nCOPY ./app9 /app/app9\r\nCOPY ./app10 /app/app10\r\nCOPY ./app11 /app/app11\r\nCOPY ./app12 /app/app12\r\nCOPY ./Repository /app/Repository\r\n\r\nCOPY ./app13 /app/app13\r\n\r\nRUN npm install -g npm@6.9.0\r\nRUN npm -version && node --version\r\nENV config ../Repository/dkronline.json\r\nRUN cd ../app1 && npm install --no-package-lock\r\nRUN cd ../app2 && npm install  --no-package-lock\r\nRUN cd ../app3 && npm install --no-package-lock\r\nRUN cd ../app4 && npm install --no-package-lock\r\nRUN cd ../app5 && npm install --no-package-lock\r\nRUN cd ../app6 && npm install --no-package-lock\r\nRUN cd ../app7 && npm install --no-package-lock\r\nRUN cd ../app8 && npm install --no-package-lock\r\nRUN cd ../app9 && npm install --no-package-lock\r\nRUN cd ../app10 && npm install --no-package-lock\r\nRUN cd ../app11 && npm install --no-package-lock\r\nRUN cd ../app12 && npm install  --no-package-lock \r\n\r\nRUN npm install --no-package-lock\r\n\r\nCMD [ \"node\", \"app.js\", \"../Repository/dkronline.json\" ]\r\n\r\nEXPOSE 3000 4321\r\n\r\n\r\nThe other part is if I dont do this npm install here and start the docker and then do it there and it works completely fine. Can I get any help",
        "labels": "doc",
        "id": 44006
    },
    {
        "title": "doc: Add POST and/or PUT reference for HTTPS module",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: âœï¸ 12.16.2\r\n- **Platform**: âœï¸  N/A\r\n- **Subsystem**: âœï¸ N/A\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/https.html#https_https_request_options_callback\r\n\r\n## Problem description\r\n\r\nThe HTTPS module request examples do not include any reference example for POST and PUT requests, only GET.\r\nI'm creating this issue to track a possible future work on improving this doc page to include further examples on HTTPS requests that uses methods other the GET.\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44007
    },
    {
        "title": "doc: for `tls.createServer` options, providing `ctx` to `SNICallback` `cb` call is optionary.",
        "body": "# ðŸ“— API Reference Docs Problem\r\n- **Version**: v15.0.0-pre\r\n- **Platform**: 4.15.0-108-generic #109-Ubuntu SMP Fri Jun 19 11:33:10 UTC 2020 x86_64 GNU/Linux\r\n- **Subsystem**: TLS\r\n\r\n## Location\r\n`tls.createServer` -> `options` -> `SNICallback` description\r\nAffected URL(s):\r\nhttps://nodejs.org/api/tls.html#tls_tls_createserver_options_secureconnectionlistener\r\n\r\n## Problem description\r\nTurns out that `ctx` is not mandatory when calling `cb` passed to `SNICallback`, contrary to what the documentation states. It appears that `cb` falls back to the server's SecureContext if the second parameter (`ctx`) is not provided.\r\n\r\nI assume this is a documentation bug since such behavior makes sense to me.\r\n\r\nBelow is a test that proves my point:\r\n```\r\n'use strict';\r\nconst common = require('../common');\r\nif (!common.hasCrypto)\r\n  common.skip('missing crypto');\r\nconst fixtures = require('../common/fixtures');\r\nconst assert = require('assert');\r\nconst tls = require('tls');\r\nconst { spawn } = require('child_process');\r\n\r\nif (!common.opensslCli)\r\n  common.skip('node compiled without OpenSSL CLI.');\r\n\r\nconst key = fixtures.readKey('rsa_private.pem');\r\nconst cert = fixtures.readKey('rsa_cert.crt');\r\nconst options = {\r\n  key,\r\n  cert,\r\n  ca: [cert],\r\n  requestCert: true,\r\n  rejectUnauthorized: false,\r\n  secureProtocol: 'TLS_method',\r\n  // Ensure that the SNICallback is actually called.\r\n  // Notice that 'cb' is called with only one parameter.\r\n  SNICallback: common.mustCall((servername, cb) => cb(null)),\r\n};\r\n\r\nconst server = tls.createServer(options, function(cleartext) {\r\n  cleartext.on('error', function(er) {\r\n    // We're ok with getting ECONNRESET in this test, but it's\r\n    // timing-dependent, and thus unreliable. Any other errors\r\n    // are just failures, though.\r\n    if (er.code !== 'ECONNRESET')\r\n      throw er;\r\n  });\r\n  cleartext.end('');\r\n});\r\n\r\n// Ensure that a secure connection has been estabilished even though here is\r\n// no secure context passed to SNICallback's `cb` call.\r\nserver.on('secureConnection', common.mustCall());\r\n// Ensure that a client error does not occur even though there is no secure\r\n// context passed to SNICallback's `cb` call.\r\nserver.on('tlsClientError', common.mustNotCall());\r\n\r\nserver.listen(0, function() {\r\n  const args = [\r\n    's_client',\r\n    '-tls1',\r\n    '-connect', `localhost:${this.address().port}`,\r\n    '-servername', 'hurrmm',\r\n    '-key', fixtures.path('keys/rsa_private.pem'),\r\n    '-cert', fixtures.path('keys/rsa_cert.crt'),\r\n  ];\r\n\r\n  function spawnClient() {\r\n    const client = spawn(common.opensslCli, args, {\r\n      stdio: [ 0, 1, 'pipe' ]\r\n    });\r\n    let err = '';\r\n    client.stderr.setEncoding('utf8');\r\n    client.stderr.on('data', function(chunk) {\r\n      err += chunk;\r\n    });\r\n\r\n    client.on('exit', common.mustCall(function(code, signal) {\r\n      if (code !== 0) {\r\n        // If SmartOS and connection refused, then retry. See\r\n        // https://github.com/nodejs/node/issues/2663.\r\n        if (common.isSunOS && err.includes('Connection refused')) {\r\n          requestCount = 0;\r\n          spawnClient();\r\n          return;\r\n        }\r\n        assert.fail(`code: ${code}, signal: ${signal}, output: ${err}`);\r\n      }\r\n      assert.strictEqual(code, 0);\r\n\r\n      server.close();\r\n    }));\r\n  }\r\n\r\n  spawnClient();\r\n});\r\n```\r\n- [x] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44008
    },
    {
        "title": "doc: document the minimum required version for shared libuv",
        "body": "NodeJS requires as shared libuv at least version 1.26.0, but this is not detected by `./configure`: https://github.com/nodejs/node/issues/30120\r\n\r\nDocument at https://nodejs.org/en/docs/meta/topics/dependencies/#libuv the minimum required version.",
        "labels": "doc",
        "id": 44009
    },
    {
        "title": "doc: add links to source code in docs",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: N/A\r\n- **Platform**: N/A\r\n- **Subsystem**: N/A\r\n\r\n## Location\r\n\r\nOn every module docs page\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/*\r\n\r\n## Problem description\r\n\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nIt would be nice to have links to source code below the title of each module. For an example, look at pythons documentation for the heapq module: https://docs.python.org/3/library/heapq.html. So for node Buffer it would look like: \r\n\r\n# Buffer\r\n\r\n<!--introduced_in=v0.1.90-->\r\n\r\n> Stability: 2 - Stable\r\n\r\n**Source Code:** [lib/buffer.js](https://github.com/nodejs/node/blob/master/lib/buffer.js)\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44010
    },
    {
        "title": "n-api,doc: update doc regarding callback HandleScope/CallbackScope use",
        "body": "Explicitly state that HandleScope and CallbackScope declarations are not required inside AsyncWorker, ThreadsafeFunction et. al. callbacks.\r\n\r\nRe: https://github.com/nodejs/node-addon-examples/issues/142",
        "labels": "doc",
        "id": 44011
    },
    {
        "title": "worker: motivating examples?",
        "body": "I'm having a hard time figuring out when I would actually want to use workers over a child process.\r\n\r\nThe docs provide the following motivation:\r\n\r\n> Unlike child_process or cluster, worker_threads can share memory. They do so by transferring ArrayBuffer instances or sharing SharedArrayBuffer instances.\r\n\r\nHowever, I'm having a hard time finding a case where I would actually use this. Usually I would have either strings or objects that I would like to pass onto a worker. Maybe something like https://capnproto.org/ could take advantage of this? But from what I can see such approaches are actually quite slow in javascript.\r\n\r\nAlso, from what I understand actually transferring Buffers to workers have some edge cases and could fallback to become a copy.\r\n\r\nI'm not saying it's a bad feature. I would really love to try it out and use it. I'm just having trouble finding the use case for it.\r\n\r\nMaybe someone could provide some ideas/examples of when this would be useful would be helpful as a point of inspiration?\r\n",
        "labels": "doc",
        "id": 44012
    },
    {
        "title": "document http.OutgoingMessage",
        "body": "AFAIK There's no documentation available for `http.OutgoingMessage`. Any new contributor willing to work on this can refer `http.IncomingMessage` for some inspiration.",
        "labels": "doc",
        "id": 44013
    },
    {
        "title": "doc: tojin12341za",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: âœï¸\r\n- **Platform**: âœï¸\r\n- **Subsystem**: âœï¸\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/âœï¸\r\n\r\n## Problem description\r\n\r\n_Concise explanation of what you found to be problematic_\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44014
    },
    {
        "title": "doc: decodeURIComponent and encodeURIComponent missing",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€: \r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: âœï¸ v10.19.0\r\n- **Platform**: âœï¸ Linux strawberry 5.4.0-sabayon #1 SMP Fri May 8 19:23:19 UTC 2020 x86_64 Intel(R) Core(TM) i5-5300U CPU @ 2.30GHz GenuineIntel GNU/Linux\r\n- **Subsystem**: âœï¸ Sabayon Linux\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/âœï¸\r\n- https://nodejs.org/api/globals.html\r\n\r\n## Problem description\r\n\r\n_Concise explanation of what you found to be problematic_\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nâœï¸ Recently I learned over a Pull Request, that the Node.js documentation lacks mentioning of [`decodeURIComponent()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/decodeURIComponent) and [`encodeURIComponent()`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/encodeURIComponent).\r\n\r\nAccording to browser-compat-data, the support was added in [v0.1.100](https://github.com/mdn/browser-compat-data/blob/263e9a8be5d31b4ca4a65e9ec49b2d3574e1935f/javascript/builtins/globals.json#L183-L185) and [v0.1.100](https://github.com/mdn/browser-compat-data/blob/263e9a8be5d31b4ca4a65e9ec49b2d3574e1935f/javascript/builtins/globals.json#L287-L289).\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and submit a pull request.\r\n\r\nNot sure, what is needed, i.e. what should go into the documentation. I better leave the checkbox blank so long :-)",
        "labels": "doc",
        "id": 44015
    },
    {
        "title": "doc: wrong info for `http` deprecation",
        "body": "* **Version**: v12.x, master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc, http\r\n\r\nDEP0133 which is about the deprecation for `outgoingMessage.connection` has two issues:\r\n\r\n* It's currently labeled as being doc-deprecated in v12.12.0 which is not true, it was done so in v13.0.0.\r\n\r\n* The deprecations documentation for v12.x (since v12.12.0) lists DEP0133, which should either be removed (because it's not deprecated in v12.x) or the correct (future major) version needs to be shown instead",
        "labels": "doc",
        "id": 44016
    },
    {
        "title": "doc: UNABLE_TO_VERIFY_LEAF_SIGNATURE/unable to verify the first certificate error not documented",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: v12.17.0\r\n- **Platform**: macOS 10.14.6 Mojave: Darwin Kernel Version 18.7.0 x86_64\r\n- **Subsystem**: \r\n\r\n## Location\r\n\r\nHTTPS Module\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/https://nodejs.org/api/https.html\r\n\r\n## Problem description\r\n\r\nThe error \"unable to verify the first certificate\" with code `UNABLE_TO_VERIFY_LEAF_SIGNATURE` is not documented making it extremely difficult to fix. \r\n\r\nTurns out this was caused by a site not providing a certificate chain. While the error wasn't node's fault the lack of documentation made it look like a bug in node and made fixing the problem extremely difficult.\r\n\r\nThe true cause was obscured by work configuring certificate stores to explicitly trust the intermediate certificates so web browsers produced no errors. The vast majority of search results suggest disabling security (a terrible idea), the rest point out the `NODE_EXTRA_CA_CERTS` which is helpful, but I was already using it.\r\n\r\n*Note:* While this isn't actually a security vulnerability the fact that most advice is to turn off certificate verification it can lead people to introduce security vulnerabilities on their own.\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\n```\r\nError: unable to verify the first certificate\r\n    at TLSSocket.onConnectSecure (_tls_wrap.js:1496:34)\r\n    at TLSSocket.emit (events.js:315:20)\r\n    at TLSSocket._finishInit (_tls_wrap.js:938:8)\r\n    at TLSWrap.ssl.onhandshakedone (_tls_wrap.js:696:12) {\r\n  code: 'UNABLE_TO_VERIFY_LEAF_SIGNATURE'\r\n}\r\n```\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44017
    },
    {
        "title": "doc: --http-parser description is missing",
        "body": "Affected URL(s):\r\nhttps://nodejs.org/dist/latest-v13.x/docs/api/cli.html\r\nhttps://nodejs.org/dist/latest-v14.x/docs/api/cli.html\r\n\r\nDescription for ```--http-parser``` is missing, but this option still exists in ```Node.js options that are allowed are``` list.\r\n\r\nIs it deprecated, maybe?\r\n\r\nhttps://nodejs.org/dist/latest-v12.x/docs/api/cli.html\r\n\r\nEverything is ok.",
        "labels": "doc",
        "id": 44018
    },
    {
        "title": "doc: ",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: âœï¸\r\n- **Platform**: âœï¸\r\n- **Subsystem**: âœï¸\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/âœï¸\r\n\r\n## Problem description\r\n\r\n_Concise explanation of what you found to be problematic_\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44019
    },
    {
        "title": "EventTarget - supporting \"current event\"",
        "body": "Hey,\r\n\r\nNode is discussing experimentally adding EventTarget for its experimental AbortController implementation. One of the things the DOM specification has is something called [\"current event\"](https://dom.spec.whatwg.org/#window-current-event).\r\n\r\nBasically a global is defined on `window.event`:\r\n\r\n```js\r\nconst et = new EventTarget();\r\net.addEventListener('foo', (e) => console.log(window.event)); // logs the Event instance\r\net.dispatchEvent(new Event('foo'))\r\n```\r\n\r\nThis is part of the DOM API and a divergence from the spec. Since we are _only_ implementing EventTarget and not the whole DOM (or window), I think this is fine to not implement. The DOM specification also notes this is a legacy feature.\r\n\r\nWhen I asked about this Domenic noted that it's fine to not implement as part of EventTarget as it's a part of a different API (like we're not implementing CustomEvent or MouseEvent).\r\n\r\nThe plan is currently:\r\n\r\n - Don't support `window.event` (or `globalThis.event` really) for event targets.\r\n - Don't port the WPTs that rely on `window.event` (if they test something else: port them to use the event argument).\r\n\r\nIt is not _hard_ to support technically (literally just setting a global before and deleting it after), but I would rather not support this feature if we can help it. Both because we can't correctly do so (no window) and because the feature exists mostly for inline event handlers (which we also don't support).\r\n\r\nI wanted to ask for feedback regarding this plan and to see if anyone has any strong feelings one way or another.",
        "labels": "doc",
        "id": 44020
    },
    {
        "title": "Simplify docs on how to pipe from an async Iterator to a Writable",
        "body": "In https://nodejs.org/api/stream.html#stream_piping_to_writable_streams_from_async_iterators we should how to use Events.on and Promise.race() to write to a Writable. However, pipeline already support this and this can be greatly simplified. See https://nodejs.org/api/stream.html#stream_stream_pipeline_source_transforms_destination_callback.",
        "labels": "doc",
        "id": 44021
    },
    {
        "title": "doc: missing single quotes in api/tls.md for v10.x",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v10.x\r\n* **Platform**: n/a\r\n* **Subsystem**: doc, tls\r\n\r\nThe `minVersion` and `maxVersion` descriptions in the `tls` docs are missing single quotes before `TLSv1.2`. The docs for newer branches do not have this issue.",
        "labels": "doc",
        "id": 44022
    },
    {
        "title": "doc: https://nodejs.org/api/esm.html#esm_dual_commonjs_es_module_packages",
        "body": "- I have a monorepo written in Typescript with 3 packages - \r\n```\r\nmonorepo \r\n|_ package1\r\n|_ package2\r\n|_ package3 \r\n```\r\n- package3 is a CRA. And, `package1` uses/imports `package2` and `package3` imports `package2`.\r\n- I build a `lib` and a `lib-esm` for both package1 and package2 and expose them via package.json - \r\n```\r\n  \"main\": \"./lib/index.js\",\r\n  \"module\": \"./lib-esm/index.js\",\r\n  \"types\": \"./lib/index.d.ts\",\r\n```\r\n`lib` - is my typescript package transpiled to cjs \r\n`lib-esm` - is my typescript package transpiled to es6/esnext\r\n\r\n- my `./lib/index.js` looks like this - (simplified) - \r\n```\r\nexport * from file1;\r\nexport * from file2; \r\n```\r\nnow, can I just create a ./wrapper.js - \r\n```\r\nimport * as cjs  from './lib/index.js';\r\nexport const {cjs,};\r\n```\r\nand have my package1 look like this - \r\n```\r\n{\r\n  \"type\": \"module\",\r\n  \"main\": \"./lib/index.js\",\r\n \"types\": \"./lib/index.d.ts\",\r\n  \"exports\": {\r\n    \"import\": \"./wrapper.js\",\r\n    \"require\": \"./lib/index.js\"\r\n  }\r\n}\r\n```\r\n- will it not break and support all the browsers that having 2 copies like - lib and lib-esm were supporting? \r\n- this approach as I see from the docs is new, <1year. is it safe to use this? \r\n- all this wrapper.js has is commonjs inside, so how is it able to help anyone? \r\n- but I had also read that `main` in your package.json is used when someone using your package imports your package via require(), and `module` - when they import it via ES6 import. but, now there will be no `module` in my package.json\r\n- how do i know or make sure that my package's state is isolated? what does that mean? as written in the docs?\r\n\r\n- please direct me to some article, if you think these questions are already answered somewhere else - would be really helpful!",
        "labels": "doc",
        "id": 44023
    },
    {
        "title": "API doc: ",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: âœï¸\r\n- **Platform**: âœï¸\r\n- **Subsystem**: âœï¸\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/âœï¸\r\n\r\n## Problem description\r\n\r\n_Concise explanation of what you found to be problematic_\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nâœï¸\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44024
    },
    {
        "title": "doc: <integer> is misleading",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: master\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/buffer\r\n- https://nodejs.org/api/events\r\n...among others\r\n\r\n## Problem description\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nMany methods are documented to take `<integer>` or `<integer[]>`. Examples:\r\n[Buffer.from(array)](https://nodejs.org/api/buffer.html#buffer_class_method_buffer_from_array)\r\n[emitter.setMaxListeners(n)](https://nodejs.org/api/events.html#events_emitter_setmaxlisteners_n)\r\nIt seems to always mean \"an integer Number\". However, clicking the type link leads to an [MDN section](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type) that starts with \"ECMAScript has two built-in numeric types: Number and BigInt (see below).\". One might erroneously think that BigInt, which is also an \"integer\", works too.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44025
    },
    {
        "title": "AsyncLocalStorage potential issue ?",
        "body": "https://github.com/nodejs/node/blob/9949a2e1e3100c4ff1f228bac57c1af95cdc3e9d/lib/async_hooks.js#L248\r\n\r\nYou are using the `resource` object to store the `store` whereas the doc state :\r\n\r\n> In some cases the resource object is reused for performance reasons, it is thus not safe to use it as a key in a WeakMap or **add properties to it**.\r\n\r\nI just wondering if it is ok.\r\n",
        "labels": "doc",
        "id": 44026
    },
    {
        "title": "doc: some methods inherited from Uint8Array are documented but not all",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: master\r\n- **Subsystem**: buffer\r\n\r\n## Location\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/buffer.html\r\n\r\n## Problem description\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nSome methods inherited from `Uint8Array` are not documented, e.g. `map`, `reduce`, `set`. This makes sense because it's stated that the `Buffer` class is a subclass of the `Uint8Array` class, but some _are_ documented, e.g. `entries`, `keys`, `values`. This might be confusing.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44027
    },
    {
        "title": "n-api: does napi_create_external_buffer copy?",
        "body": "Hunting down a bug related to napi_create_external_buffer, I got a bit confused by reading the docs here:\r\n\r\nhttps://nodejs.org/dist/latest-v14.x/docs/api/n-api.html#n_api_napi_create_external_buffer\r\n\r\n`[in] data: Raw pointer to the underlying buffer to copy from.`\r\n\r\nDoes this mean that the buffer is created with the same pointer or a new pointer that's a memcopy?\r\n\r\nFurther down on the docs for the same method it also says:\r\n\r\n`This API allocates a node::Buffer object and initializes it with data backed by the passed in buffer.`\r\n\r\nWhich I'm also not sure wheather to interpret as a memcopy",
        "labels": "doc",
        "id": 44028
    },
    {
        "title": "awaiting between creating a readline interface, and using async iterator will cause iterator to sometimes skip.",
        "body": "\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:v12.13.0\r\n* **Platform**:Linux myuser 4.15.0-74-generic #84-Ubuntu SMP Thu Dec 19 08:06:28 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\nreadline.createInterface \r\nasyncIterator\r\n\r\n### What steps will reproduce the bug?\r\n\r\nif you perform something like \r\nhttps://github.com/nodejs/node/blob/2a7432dadec08bbe7063d84f1aa4a6396807305c/test/parallel/test-readline-async-iterators.js\r\n\r\n```js\r\nasync function testSimple() {\r\n  for (const fileContent of testContents) {\r\n    fs.writeFileSync(filename, fileContent);\r\n\r\n    const readable = fs.createReadStream(filename);\r\n    const rli = readline.createInterface({\r\n      input: readable,\r\n      crlfDelay: Infinity\r\n    });\r\n\r\n    const iteratedLines = [];\r\n    for await (const k of rli) {\r\n      iteratedLines.push(k);\r\n    }\r\n\r\n    const expectedLines = fileContent.split('\\n');\r\n    if (expectedLines[expectedLines.length - 1] === '') {\r\n      expectedLines.pop();\r\n    }\r\n    assert.deepStrictEqual(iteratedLines, expectedLines);\r\n    assert.strictEqual(iteratedLines.join(''), fileContent.replace(/\\n/gm, ''));\r\n  }\r\n}\r\n```\r\n\r\n\r\nIf you add some kind of await xxx() between creating the interface and iterating, the iterator will miss lines.  In my case I input 100k lines from a file, then output those same lines to a new file.  several thousand lines will go missing. \r\n\r\n### How often does it reproduce? Is there a required condition?\r\n100%\r\nNeed to add some await async between creating the interface and using for await\r\n\r\n### What is the expected behavior?\r\nnot to miss iterations\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\n",
        "labels": "doc",
        "id": 44029
    },
    {
        "title": "doc: child_process.SpawnSync output, stdout, stderr can be null",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: v13.9.0\r\n- **Platform**: Mac OS 10.15.4\r\n- **Subsystem**: child_process\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/child_process.html#child_process_child_process_spawnsync_command_args_options\r\n\r\n## Problem description\r\n\r\n_Concise explanation of what you found to be problematic_\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nIn the \"Returns\" desciption it states that \"stdout\" and \"stderr\" can be `<Buffer>` or `<string>` and that \"output\" is of type `<Array>`.\r\n\r\nHowever, this is not the case when the spawned process terminates with an error.\r\nTo reproduce you can run the following script:\r\n\r\n```js\r\nconst child_process = require(\"child_process\")\r\n\r\n// any command that is not available or fails with an error\r\nconst result = child_process.spawnSync(\"not_found\") \r\n\r\nconsole.log(result)\r\n``` \r\n\r\nwill output:\r\n\r\n```\r\n{\r\n  error: Error: spawnSync not_found ENOENT\r\n      at Object.spawnSync (internal/child_process.js:1045:20)\r\n      ...\r\n    errno: -2,\r\n    code: 'ENOENT',\r\n    syscall: 'spawnSync not_found',\r\n    path: 'not_found',\r\n    spawnargs: []\r\n  },\r\n  status: null,\r\n  signal: null,\r\n  output: null,\r\n  pid: 36085,\r\n  stdout: null,\r\n  stderr: null\r\n}\r\n```\r\n\r\nAs you can see \"stdout\", \"stderr\" and \"output\" are `null`.\r\nI'm not sure if this is a bug in the implementation or if this is the desired behavior. In the latter case it should be stated in the docs that these three fields can also be null and under which conditions this is the case.\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and submit a pull request.\r\n",
        "labels": "doc",
        "id": 44030
    },
    {
        "title": "doc: all <pre> tags are highlighted as JavaScript",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!------------------------------------------------------------------------------\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API reference docs.\r\n\r\nFor more general support, please open an issue in\r\nour help repo at â€œhttps://github.com/nodejs/helpâ€.\r\n\r\nFor the issue title, enter a one-line summary after â€œdoc: â€.\r\nThe â€œâœï¸â€ signifies a request for input. If unsure, do the best you can.\r\n\r\nIf you found a problem with nodejs.org beyond the API reference docs, please\r\nopen an issue in our website repo at â€œhttps://github.com/nodejs/nodejs.orgâ€.\r\n------------------------------------------------------------------------------->\r\n\r\n<!--\r\nVersion: output of â€œnode -vâ€\r\nPlatform: output of â€œuname -aâ€ (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n- **Version**: n/a\r\n- **Platform**: n/a\r\n- **Subsystem**: n/a\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n- https://nodejs.org/api/embedding.html\r\n- Any other document w/ a Markdown code fence\r\n\r\n## Problem description\r\n\r\n_Concise explanation of what you found to be problematic_\r\n\r\n<!-- If applicable, include any screenshots that may help solve the problem. -->\r\n\r\nWhile looking into #32938, I discovered that currently, every single &lt;pre&gt; tag gets highlighted as JavaScript **regardless** of the info string specified (and **even if left unspecified**). The following line executes the code that does this.\r\n\r\nhttps://github.com/nodejs/node/blob/94e5b5c77dade0d8f7358c66144b75c369679cab/doc/template.html#L56\r\n\r\nThis behavior can be observed in the C++ code blocks in the published API reference documents. The following line is the reason for this â€” the language has been hard-coded.\r\n\r\nhttps://github.com/nodejs/node/blob/94e5b5c77dade0d8f7358c66144b75c369679cab/doc/api_assets/sh_main.js#L542\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if interested in contributing. -->\r\n\r\n- [x] I would like to work on this issue and submit a pull request.\r\n\r\n^ I'm currently on summer vacation, so I would have the time to work on this. \r\n\r\n/cc @Trott",
        "labels": "doc",
        "id": 44031
    },
    {
        "title": "--expose-gc is not documented in CLI options",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "doc",
        "id": 44032
    },
    {
        "title": "HTTPS highwatermark not working",
        "body": "* **Version**: Node.js v15.0.0-nightly20200505c17dcb3253\r\n* **Platform**: Windows 10 x64\r\n* **Subsystem**: https\r\n\r\n### What steps will reproduce the bug?\r\n\r\nIn #32781 was fixed that highWatermark was not established in https streams when we passed that option. But after some tests it is still receiving chunks of data of a fixed 16KB size.\r\n\r\nDownloading a file from a LAN Server via HTTP with an increased hightwatermark we can see this progress (chunks of ~65kbs)\r\n\r\n```\r\nHTTP Test\r\n--------------------------------------------------\r\nResponse.readableHighWaterMark: 131072\r\nOutfile WriteStream WritableHighWaterMark: 131072\r\n\r\nProgress: 0%    10.69 kB / 21.85 MB\r\nProgress: 0%    74.69 kB / 21.85 MB\r\nProgress: 0%    138.69 kB / 21.85 MB\r\nProgress: 0%    202.69 kB / 21.85 MB\r\nProgress: 1%    266.69 kB / 21.85 MB\r\nProgress: 1%    330.69 kB / 21.85 MB\r\nProgress: 1%    394.69 kB / 21.85 MB\r\nProgress: 2%    458.69 kB / 21.85 MB\r\nProgress: 2%    522.69 kB / 21.85 MB\r\nProgress: 2%    586.69 kB / 21.85 MB\r\n...\r\n```\r\n\r\nDownloading the same file, from the same LAN Server via HTTPS we are still receiving chunks of 16KB even traces of the response readadableHighWaterMark are established to 128KB, so it seems there is something that is not propagating well.\r\n\r\n```\r\nHTTPS Test\r\n--------------------------------------------------\r\nResponse.readableHighWaterMark: 131072\r\nOutfile WriteStream WritableHighWaterMark: 131072\r\n\r\nProgress: 0%    16.00 kB / 21.85 MB\r\nProgress: 0%    32.00 kB / 21.85 MB\r\nProgress: 0%    48.00 kB / 21.85 MB\r\nProgress: 0%    64.00 kB / 21.85 MB\r\nProgress: 0%    80.00 kB / 21.85 MB\r\nProgress: 0%    96.00 kB / 21.85 MB\r\nProgress: 0%    112.00 kB / 21.85 MB\r\n...\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### Additional information\r\n\r\nAttached goes a js what Im using to do those tests.\r\n\r\n[downloadfile.test.js.txt](https://github.com/nodejs/node/files/4585648/downloadfile.test.js.txt)\r\n",
        "labels": "doc",
        "id": 44033
    },
    {
        "title": "`module.path` exists but is not documented",
        "body": "The [module object](https://nodejs.org/api/modules.html#modules_the_module_object) does not contain the path property. ",
        "labels": "doc",
        "id": 44034
    },
    {
        "title": "EcmaScript documentation: move \"stability tag\" to chapters",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nOn the documentation, the \"experimental\" flag is put on the whole page:\r\nhttps://nodejs.org/api/esm.html\r\n\r\nBut the concept is not \"experimental\" anymore... only some part of it are still \"experimental\".\r\n\r\nFor example, chapters as thoses are probably \"stable\":\r\n- Package Scope and File Extensions\r\n- Main Entry Point Export\r\n- Dual CommonJS/ES Module Packages\r\n- ...\r\n\r\nwhile some other are really \"experimental\" (at my opinion):\r\n- Subpath Exports\r\n- import.meta\r\n- ...\r\n\r\n**Describe the solution you'd like**\r\nDon't you think the \"experimental\" tag should be splitted by chapters, so that we can start using the stable parts while not trusting over unstable parts?\r\n",
        "labels": "doc",
        "id": 44035
    },
    {
        "title": "Requesting documentation of v8.getHeapStatistics() properties",
        "body": "https://github.com/nodejs/node/issues/32206 mentions that none of the properties returned by `v8.getHeapStatistics()` are properly documented. \r\n\r\nI'm currently relying on an answer I found on stackoverflow (https://stackoverflow.com/questions/41541843/nodejs-v8-getheapstatistics-method) but there should be some official documentation about the individual values returned in the documentation.",
        "labels": "doc",
        "id": 44036
    },
    {
        "title": "Inconsistent use of plaintext code fencing in docs",
        "body": "Hey party people!\r\n\r\nI'm working on a project that parses all the markdown files in the [doc](https://github.com/nodejs/node/tree/master/doc) directory of this repo, and I've come across a number of instances of inconsistent naming of the plaintext [info string](https://github.github.com/gfm/#info-string) (i.e. the language) in GitHub Flavored Markdown code fencing:\r\n\r\nlanguage | instances\r\n:------- | :--------\r\n`text`    | 44\r\n`txt`   | 21\r\n`fundamental`   | 1\r\n`markdown`   | 1\r\n`raw`   | 1\r\n\r\nI'm currently using this hack to sanitize all the incoming markdown before converting it to HTML:\r\n\r\n```js\r\nmarkdown = markdown\r\n  .replace(/```txt/gm, '```plaintext')\r\n  .replace(/```text/gm, '```plaintext')\r\n  .replace(/```fundamental/gm, '```plaintext')\r\n  .replace(/```raw/gm, '```plaintext')\r\n  .replace(/```markdown<.*$/gm, '```plaintext')\r\n  .replace(/```plaintext<.*$/gm, '```plaintext')\r\n```\r\n\r\nHere's what the current [documentation style guide](https://github.com/nodejs/node/blob/master/doc/guides/doc-style-guide.md) says about code blocks:\r\n\r\n> * For code blocks:\r\n>   * Use language aware fences. (\"```js\")\r\n>   * Code need not be complete. Treat code blocks as an illustration or aid to\r\n>     your point, not as complete running programs. If a complete running program\r\n>     is necessary, include it as an asset in `assets/code-examples` and link to\r\n>     it.\r\n\r\nThere's no mention of what the canonical language should be for plaintext, but I'd suggest standardizing on one of the following:\r\n\r\n- `text` is the most commonly used plaintext info string in this project\r\n- `plaintext` is what the popular [highlight.js](https://highlightjs.org/usage/) syntax highlighting library expects\r\n\r\nI don't have a strong opinion about what the info string should be as long as it's used consistently across the docs. I'd be happy to open a pull request to clean these up, but wanted to open an issue first for discussion.\r\n\r\nThings that might need to be done to resolve this:\r\n\r\n- [ ] Choose an info string for plain text\r\n- [ ] Update docs to all use the same info string\r\n- [ ] Update the style guide\r\n- [ ] Add a [linting rule](https://github.com/nodejs/remark-preset-lint-node/blob/master/index.js#L21)?\r\n- [ ] What else?\r\n\r\ncc @nodejs/documentation ðŸ‘‹ ",
        "labels": "doc",
        "id": 44037
    },
    {
        "title": "Discussion(doc,tools): Include file source text into Markdown files",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nProblem space: There does not appear to be a way to embed the source text of a local file into the Markdown files of the API docs.\r\n\r\nContext: I'm trying to include a JS code sample in API docs Markdown that would exist in a different file. It would be preferable if it could pass a few validation & lint-style checks prior to being embedded and disseminated. I mentioned the desire for this in [a previous comment](https://github.com/nodejs/node/pull/29819#issuecomment-608288763), which follows.\r\n\r\n> Ideally these samples would live in their own files and be subject to typechecking and linting prior to being embedded into the docs via a templating engine otherwise you inevitably end up providing bad samples to users, which isn't uncommon.\r\n\r\nAfter further thought and [a new PR](https://github.com/nodejs/node/pull/32646), re-implementation of this test fixture (presently inert & obsoleted), re-purposing it, and re-integrating it as a code sample supporting the prose of a new loader example seems most logical. However, as @devsnek pointed out, code samples intended for docs shouldn't exist in `test/` (with `doc/` potentially being more appropriate as an idea fielded on IRC).\r\n\r\n**Describe the solution you'd like**\r\n\r\nAfter a cursory look, @Trott and myself are under the impression that [the documentation generator (`tools/doc/`)](https://github.com/nodejs/node/tree/master/tools/doc) is not presently capable of performing this feature and it was suggested that there may be value in opening an issue for discussion.\r\n\r\nTherefore, (pointed out to me by @Trott) this is solvable in a number of different ways as is apparent in the following StackOverflow question and may benefit from discussion.\r\n\r\nhttps://stackoverflow.com/questions/4779582/markdown-and-including-multiple-files\r\n\r\n---\r\n\r\nAny thoughts/suggestions are welcome and would be highly appreciated! :)\r\n\r\n/cc @rubys and @vsemozhetbyt as have been relevant prior contributors to `tools/doc/`\r\n/cc @wooorm as has been helpful with previous @unifiedjs tooling workflows\r\n/cc @GeoffreyBooth as is likely interested in the discussion and outcome\r\n/cc @nodejs/documentation as would likely be the relevant team",
        "labels": "doc",
        "id": 44038
    },
    {
        "title": "'uncaughtException' event not working with unhandled promises",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 13.3.0\r\n* **Platform**: Win 10 64-bit\r\n* **Subsystem**: Process\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nprocess.on('uncaughtException', (err, origin) =>\r\n{\r\n\tconsole.log('catch: ' + err.message + ' | ' + origin);\r\n\tconsole.log();\r\n});\r\n\r\nexamplePromise();\r\n\r\nfunction examplePromise()\r\n{\r\n\treturn Promise.reject('Test');\r\n}\r\n```\r\n### What is the expected behavior?\r\n\r\nAccording to the [documentation](https://nodejs.org/api/process.html#process_event_uncaughtexception) default node handling should be overwritten by this callback with `unhandledRejection` origin\r\n\r\n### What do you see instead?\r\n\r\n```\r\n(node:14784) UnhandledPromiseRejectionWarning: Test\r\n(node:14784) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 1)\r\n(node:14784) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n```\r\n\r\n### Additional information\r\n\r\nI think that is probably an error that documentation and origin variable suggests that `uncaughtException` can handle promises when we have `unhandledRejection` event. ",
        "labels": "doc",
        "id": 44039
    },
    {
        "title": "Using \"folder\" and \"directory\" interchangeably in documentation",
        "body": "https://nodejs.org/api/fs.html\r\n\r\nI'm reading this and it seems like Node documentation like to mix the terms \"folder\" and \"directory\" interchangeably.\r\n\r\nI'm wondering, why is Node mixing these concepts, _they are not the same thing_.\r\n\r\nhttps://nodejs.org/api/fs.html#fs_fs_mkdtemp_prefix_options_callback\r\n\r\nQuote:\r\n> History\r\n> prefix <string>\r\n> options <string> | <Object>\r\n> \r\n> encoding <string> Default: 'utf8'\r\n> callback <Function>\r\n> \r\n> err <Error>\r\n> folder <string>\r\n> Creates a unique temporary directory.\r\n> \r\n> Generates six random characters to be appended behind a required prefix to create a unique temporary directory. Due to platform inconsistencies, avoid trailing X characters in prefix. Some platforms, notably the BSDs, can return more than six random characters, and replace trailing X characters in prefix with random characters.\r\n> \r\n> The created folder path is passed as a string to the callback's second parameter.\r\n> \r\n> The optional options argument can be a string specifying an encoding, or an object with an encoding property specifying the character encoding to use.\r\n> \r\n> fs.mkdtemp(path.join(os.tmpdir(), 'foo-'), (err, folder) => {\r\n>   if (err) throw err;\r\n>   console.log(folder);\r\n>   // Prints: /tmp/foo-itXde2 or C:\\Users\\...\\AppData\\Local\\Temp\\foo-itXde2\r\n> });\r\n> The fs.mkdtemp() method will append the six randomly selected characters directly to the prefix string. For instance, given a directory /tmp, if the intention is to create a temporary directory within /tmp, the prefix must end with a trailing platform-specific path separator (require('path').sep).\r\n> \r\n> // The parent directory for the new temporary directory\r\n> const tmpDir = os.tmpdir();\r\n> \r\n> // This method is *INCORRECT*:\r\n> fs.mkdtemp(tmpDir, (err, folder) => {\r\n>   if (err) throw err;\r\n>   console.log(folder);\r\n>   // Will print something similar to `/tmpabc123`.\r\n>   // A new temporary directory is created at the file system root\r\n>   // rather than *within* the /tmp directory.\r\n> });\r\n> \r\n> // This method is *CORRECT*:\r\n> const { sep } = require('path');\r\n> fs.mkdtemp(`${tmpDir}${sep}`, (err, folder) => {\r\n>   if (err) throw err;\r\n>   console.log(folder);\r\n>   // Will print something similar to `/tmp/abc123`.\r\n>   // A new temporary directory is created within\r\n>   // the /tmp directory.\r\n> });",
        "labels": "doc",
        "id": 44040
    },
    {
        "title": "max-http-header-size \"added\" docs",
        "body": "The [docs for `--max-http-header-size`](https://nodejs.org/api/cli.html#cli_max_http_header_size_size) history note includes `v11.6.0 | Added in: v11.6.0` but it was also \"added\" (at the same time) in [10.15.0](https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V10.md#2018-12-26-version-10150-dubnium-lts-mylesborins)\r\n\r\nwhat's the best way to reflect this in those docs? two \"added\" entries? a single entry with `v11.6.0 / v10.15.0` or similar? something else?\r\n\r\nhappy to make the change with some guidance on how to best format it",
        "labels": "doc",
        "id": 44041
    },
    {
        "title": "doc: Should `runMain()` and `globalPaths` of module add in doc?",
        "body": "By chance, I find `runMain()` method was used in [babel-node](https://github.com/babel/babel/blob/master/packages/babel-node/src/_babel-node.js#L207) but it can't be found in API.\r\n\r\nI also checked issue and code, but nothing. \r\n\r\n```bash\r\n$ git grep runMain $(git rev-list --all doc/api/modules.md) -- doc/api/modules.md\r\n# nothing\r\n\r\n$ git grep globalPaths $(git rev-list --all doc/api/modules.md) -- doc/api/modules.md\r\n# nothing\r\n\r\n$ git grep builtinModules $(git rev-list --all doc/api/modules.md) -- doc/api/modules.md\r\n534c204e223d85c44cd6b1b642f29143095077f6:doc/api/modules.md:### `module.builtinModules`\r\n534c204e223d85c44cd6b1b642f29143095077f6:doc/api/modules.md:const builtin = require('module').builtinModules;\r\na220202a47ee87d1ef91fa8f65a3e048f298b7c1:doc/api/modules.md:### `module.builtinModules`\r\n```\r\n\r\nHowever [the `builtinModules` property near `globalPaths`](https://github.com/nodejs/node/blob/master/lib/internal/modules/cjs/loader.js#L176-L182) can be found. Should `runMain()` and `globalPaths` of module add to doc? If needed, I would be pleased to write them.\r\n\r\n",
        "labels": "doc",
        "id": 44042
    },
    {
        "title": "child_process.exec/execFile docs have some inconsistencies and inaccuracies",
        "body": "I don't have time to fix this now, but while looking at sec issues related to these APIs, I found some oddities.\r\n\r\nhttps://nodejs.org/api/child_process.html#child_process_child_process_execfile_file_args_options_callback says\r\n\r\n> shell <boolean> | <string> If true, runs command inside of a shell. \r\n\r\nBut execFile() doesn't have a `command` argument... this was pasted from exec(), it seems. Probably what happens is that if there is a shell, then `file` and `args` are all concatenated together, `' '` seperated, and passed to the shell.\r\n\r\nSince the shell option AFAICT ends up following the same path as from exec(), it suggests that the exec docs:\r\n\r\n> shell <string> Shell to execute the command with. See Shell Requirements and Default Windows Shell. Default: '/bin/sh' on Unix, process.env.ComSpec on Windows.\r\n\r\nare incomplete, probably `false` would work just fine as an arg there, making exec() behave exactly like execFile().\r\n\r\nThis seems to be a bit legacy as well:\r\n\r\n> The child_process.execFile() function is similar to child_process.exec() except that it does not spawn a shell by default. Rather, the specified executable file is spawned directly as a new process making it slightly more efficient than child_process.exec().\r\n\r\nNow that both exec and execFile() have a shell, differing only be the default value, its probably more accurate to say the difference is that one takes an array of strings as an argument `execFile(file, argv, ..`  and the other takes a single string `exec(command, ...)`.\r\n\r\nThe text following is now wrong:\r\n\r\n> The same options as child_process.exec() are supported. Since a shell is not spawned, behaviors such as I/O redirection and file globbing are not supported.\r\n\r\nIt can't both *support* the same options, and *not support* some of the options.\r\n\r\nIt should probably say \"If a shell is ...\" (only one word different, but its important).\r\n\r\nexec should probably have docs saying the same thing, shell behaviours are not supported when shell is `false`.\r\n\r\nAnd execFile() should probably include the warnings from exec about how shell special chars vary by platform.\r\n\r\nSome of these issues are shared with the \"sync\" versions of the APIs.\r\n\r\n",
        "labels": "doc",
        "id": 44043
    },
    {
        "title": "events: timing issue awaiting multiple events emitted in same nextTick",
        "body": "Just leaving this here as an issue worth investigating. Not sure there's anything we can do about it other than documenting it...\r\n\r\nMultiple events emitted on the same `process.nextTick()` may be missed when using `await once()`. For example, when running the following, both the `'bar'` and `'foo'` events are emitted but the `async function foo()` never completes because `await once(myEE, 'foo')` occurs *after* the `foo` event is actually emitted.\r\n\r\n```js\r\n'use strict';\r\n\r\nconst { EventEmitter, once } = require('events');\r\n\r\nconst myEE = new EventEmitter();\r\n\r\nasync function foo() {\r\n  await once(myEE, 'bar');\r\n  console.log('bar');\r\n\r\n  await once(myEE, 'foo');\r\n  console.log('foo');\r\n}\r\n\r\nprocess.nextTick(() => {\r\n  myEE.emit('bar');\r\n  myEE.emit('foo');\r\n});\r\n\r\nfoo().then(() => console.log('done'));\r\n\r\nsetTimeout(() => {}, 1000);\r\n```\r\n\r\nThe only way to catch both events is to use `Promise.all()` or `Promise.allSettled()`, or to not use `await` with `once(myEE, 'bar')`\r\n\r\n```js\r\n'use strict';\r\n\r\nconst { EventEmitter, once } = require('events');\r\n\r\nconst myEE = new EventEmitter();\r\n\r\nasync function foo() {\r\n  await once(myEE, 'bar');\r\n  console.log('bar');\r\n\r\n  await once(myEE, 'foo');\r\n  console.log('foo');\r\n}\r\n\r\nasync function foo2() {\r\n  await Promise.all([once(myEE, 'bar'), once(myEE, 'foo')]);\r\n  console.log('foo', 'bar');\r\n}\r\n\r\nprocess.nextTick(() => {\r\n  myEE.emit('bar');\r\n  myEE.emit('foo');\r\n});\r\n\r\nfoo2().then(() => console.log('done'));\r\n\r\nsetTimeout(() => {}, 1000);\r\n```\r\n\r\nWhy does this happen? It is because the process.nextTick is processed before the microtask queue. Both events are emitted synchronously before the microtask queue is processed. The `await once(myEE, 'bar')` does not continue until the microtask queue is executed, after the `'foo'` event is emitted, so `await once(myEE, 'foo')` ends up waiting forever, having missed the actual event.\r\n",
        "labels": "doc",
        "id": 44044
    },
    {
        "title": "http spec says url/query-sting should be unlimited. this can't be set programatically. ",
        "body": "```\r\nvar http = require('http')\r\nhttp.createServer({maxHeaderSize: 16000 }, function () {}).listen(8080)\r\nconsole.warn(http.maxHeaderSize)\r\n```\r\nAbove does not set the maxHeaderSize. Yes you can do it from CLI, but you should be able to set it programatically.\r\nhttps://github.com/nodejs/node/issues/24692\r\nhttps://github.com/expressjs/express/issues/4218",
        "labels": "doc",
        "id": 44045
    },
    {
        "title": "doc: `--max-old-space-size` should be documented",
        "body": "Even though `--max-old-space-size` is a V8 flag, I would expect us to document it, given that itâ€™s probably the most useful V8 flag for Node.js users overall.\r\n\r\nRefs: #32251",
        "labels": "doc",
        "id": 44046
    },
    {
        "title": "Move to Electron's docs-parser tooling for Node.js documentation",
        "body": "Over the past four months, I've gotten more and more involved in Electron as a project. Generally, they are extremely forward on automation and tooling intended to reduce maintainer burden since they are such a small team maintaining such a large project.\r\n\r\nOne of the tools they created, [docs-parser](https://github.com/electron/docs-parser), is especially interesting and I think Node.js could benefit from adopting it as a fundamental piece of our documentation tooling.\r\n\r\n## Why\r\n\r\nI see quite significant benefits to adopting docs-parser:\r\n\r\n- **More consistency in Node.js documentation.** Docs parser _requires_ you to write in according to the [documentation styleguide](https://github.com/electron/electron/blob/master/docs/styleguide.md) that Electron uses. As a reader and consumer I've never had a particularly good experience using our docs, and have . Whether it's the hierarchical improvements or the relative consistency from section to section, docs-parser's enforced writing style helps ensure that our users' experience while consuming documentation is _consistent_.\r\n- **Straightforward detection of missing context.** In the example above, you can see that each of the properties on the object returned by `getHeapStatistics()` have an empty \"description\" property. This emptiness is extremely useful in finding places where additional context can be added. For example, it's trivial to write a tool that checks for empty \"description\" properties. This provides an excellent path forward to enriching our documentation with context that's useful to users who don't have the same understanding that we do.\r\n- **Potential internal tooling to reduce maintainer burden.** Electron doesn't just ship this by itself. They have two other tools, [typescript-definitions](https://github.com/electron/typescript-definitions) and [archaeologist](https://github.com/electron/archaeologist) which - when used together - provide a GitHub check that surfaces a representation of the documentation API as a .d.ts, diffing the current PR's representation with the representation of the documentation in `master`. This provides a way for maintainers to parse out the changes to APIs in code in addition to just personally reading the docs themselves.\r\n\r\n## How does docs-parser differ from what we currently have?\r\n\r\n### Document Structure\r\n\r\ndocs-parser requires a specific document structure that is currently documented in [the Electron Styleguide API Reference section](https://github.com/electron/electron/blob/master/docs/styleguide.md#api-references).\r\n\r\nThis structure has specific expectations about titles, descriptions, modules, methods, events, classes (undocumented here: multi-class mode, which would be needed in Node.js and is currently supported by docs-parser), static properties, instance methods, and instance properties.\r\n\r\nI've worked on converting Node.js's `querystring`, `v8`, and `worker-threads` docs in a personal repo which you can find here in the docs/api directory: [bnb/node-docs-parser](https://github.com/bnb/node-docs-parser). Please take a look if you're interested in what the differences are - the first commit on each file was the state I started with and the final commit in each is the docs-parser version. Additionally, there's a directory with the original versions that you can compare side-by-side if you'd prefer to approach it that way.\r\n\r\nIn doing this I found that - while a few things did need to be shuffled around to correctly parse - the overall updated structure was more clear and approachable with minimal additional effort.\r\n\r\n### Actual Markdown\r\n\r\ndocs-parser requires a comparatively strict structure around markdown _input_, since it directly parses markdown.\r\n\r\nHere's an example from Node.js:\r\n\r\n```md\r\n## `querystring.escape(str)`\r\n<!-- YAML\r\nadded: v0.1.25\r\n-->\r\n\r\n* `str` {string}\r\n\r\nThe `querystring.escape()` method performs URL percent-encoding on the given\r\n`str` in a manner that is optimized for the specific requirements of URL\r\nquery strings.\r\n\r\nThe `querystring.escape()` method is used by `querystring.stringify()` and is\r\ngenerally not expected to be used directly. It is exported primarily to allow\r\napplication code to provide a replacement percent-encoding implementation if\r\nnecessary by assigning `querystring.escape` to an alternative function.\r\n```\r\n\r\nAnd here's the current equivalent in docs-parser:\r\n```\r\n### `querystring.escape(str)`\r\n\r\n- `str` String\r\n\r\nThe `querystring.escape()` method performs URL percent-encoding on the given\r\n`str` in a manner that is optimized for the specific requirements of URL\r\nquery strings.\r\n\r\nThe `querystring.escape()` method is used by `querystring.stringify()` and is\r\ngenerally not expected to be used directly. It is exported primarily to allow\r\napplication code to provide a replacement percent-encoding implementation if\r\nnecessary by assigning `querystring.escape` to an alternative function.\r\n```\r\n\r\nThey seem nearly identical, and indeed they basically are. This is a good example of how minor some of the necessary changes are. Here's another slightly more complicated example:\r\n\r\nNode.js version:\r\n```\r\n### `v8.getHeapStatistics()`\r\n\r\nReturns `Object`\r\n\r\n* `total_heap_size` number\r\n* `total_heap_size_executable` number\r\n* `total_physical_size` number\r\n* `total_available_size` number\r\n* `used_heap_size` number\r\n* `heap_size_limit` number\r\n* `malloced_memory` number\r\n* `peak_malloced_memory` number\r\n* `does_zap_garbage` number\r\n* `number_of_native_contexts` number\r\n* `number_of_detached_contexts` number\r\n\r\n`does_zap_garbage` is a 0/1 boolean, which signifies whether the\r\n`--zap_code_space` option is enabled or not. This makes V8 overwrite heap\r\ngarbage with a bit pattern. The RSS footprint (resident memory set) gets bigger\r\nbecause it continuously touches all heap pages and that makes them less likely\r\nto get swapped out by the operating system.\r\n\r\n`number_of_native_contexts` The value of native_context is the number of the\r\ntop-level contexts currently active. Increase of this number over time indicates\r\na memory leak.\r\n\r\n`number_of_detached_contexts` The value of detached_context is the number\r\nof contexts that were detached and not yet garbage collected. This number\r\nbeing non-zero indicates a potential memory leak.\r\n\r\n<!-- eslint-skip -->\r\n` ` `js\r\n{\r\n  total_heap_size: 7326976,\r\n  total_heap_size_executable: 4194304,\r\n  total_physical_size: 7326976,\r\n  total_available_size: 1152656,\r\n  used_heap_size: 3476208,\r\n  heap_size_limit: 1535115264,\r\n  malloced_memory: 16384,\r\n  peak_malloced_memory: 1127496,\r\n  does_zap_garbage: 0,\r\n  number_of_native_contexts: 1,\r\n  number_of_detached_contexts: 0\r\n}\r\n` ` `\r\n```\r\n\r\ndocs-parser version:\r\n```md\r\n### `v8.getHeapStatistics()`\r\n\r\nReturns `Object`\r\n\r\n* `total_heap_size` number\r\n* `total_heap_size_executable` number\r\n* `total_physical_size` number\r\n* `total_available_size` number\r\n* `used_heap_size` number\r\n* `heap_size_limit` number\r\n* `malloced_memory` number\r\n* `peak_malloced_memory` number\r\n* `does_zap_garbage` number\r\n* `number_of_native_contexts` number\r\n* `number_of_detached_contexts` number\r\n\r\n`does_zap_garbage` is a 0/1 boolean, which signifies whether the\r\n`--zap_code_space` option is enabled or not. This makes V8 overwrite heap\r\ngarbage with a bit pattern. The RSS footprint (resident memory set) gets bigger\r\nbecause it continuously touches all heap pages and that makes them less likely\r\nto get swapped out by the operating system.\r\n\r\n`number_of_native_contexts` The value of native_context is the number of the\r\ntop-level contexts currently active. Increase of this number over time indicates\r\na memory leak.\r\n\r\n`number_of_detached_contexts` The value of detached_context is the number\r\nof contexts that were detached and not yet garbage collected. This number\r\nbeing non-zero indicates a potential memory leak.\r\n\r\n<!-- eslint-skip -->\r\n` ` `js\r\n{\r\n  total_heap_size: 7326976,\r\n  total_heap_size_executable: 4194304,\r\n  total_physical_size: 7326976,\r\n  total_available_size: 1152656,\r\n  used_heap_size: 3476208,\r\n  heap_size_limit: 1535115264,\r\n  malloced_memory: 16384,\r\n  peak_malloced_memory: 1127496,\r\n  does_zap_garbage: 0,\r\n  number_of_native_contexts: 1,\r\n  number_of_detached_contexts: 0\r\n}\r\n` ` `\r\n```\r\n\r\nHowever, docs-parser has an interesting technical benefit. Like our current setup, it outputs JSON. Compare the two following JSON _outputs_:\r\n\r\nNode.js JSON output:\r\n```\r\n{\r\n          \"textRaw\": \"`v8.getHeapStatistics()`\",\r\n          \"type\": \"method\",\r\n          \"name\": \"getHeapStatistics\",\r\n          \"meta\": {\r\n            \"added\": [\r\n              \"v1.0.0\"\r\n            ],\r\n            \"changes\": [\r\n              {\r\n                \"version\": \"v7.2.0\",\r\n                \"pr-url\": \"https://github.com/nodejs/node/pull/8610\",\r\n                \"description\": \"Added `malloced_memory`, `peak_malloced_memory`, and `does_zap_garbage`.\"\r\n              },\r\n              {\r\n                \"version\": \"v7.5.0\",\r\n                \"pr-url\": \"https://github.com/nodejs/node/pull/10186\",\r\n                \"description\": \"Support values exceeding the 32-bit unsigned integer range.\"\r\n              }\r\n            ]\r\n          },\r\n          \"signatures\": [\r\n            {\r\n              \"return\": {\r\n                \"textRaw\": \"Returns: {Object}\",\r\n                \"name\": \"return\",\r\n                \"type\": \"Object\"\r\n              },\r\n              \"params\": []\r\n            }\r\n          ],\r\n          \"desc\": \"<p>Returns an object with the following properties:</p>\\n<ul>\\n<li><code>total_heap_size</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>total_heap_size_executable</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>total_physical_size</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>total_available_size</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>used_heap_size</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>heap_size_limit</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>malloced_memory</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>peak_malloced_memory</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>does_zap_garbage</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>number_of_native_contexts</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n<li><code>number_of_detached_contexts</code> <a href=\\\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures#Number_type\\\" class=\\\"type\\\">&lt;number&gt;</a></li>\\n</ul>\\n<p><code>does_zap_garbage</code> is a 0/1 boolean, which signifies whether the\\n<code>--zap_code_space</code> option is enabled or not. This makes V8 overwrite heap\\ngarbage with a bit pattern. The RSS footprint (resident memory set) gets bigger\\nbecause it continuously touches all heap pages and that makes them less likely\\nto get swapped out by the operating system.</p>\\n<p><code>number_of_native_contexts</code> The value of native_context is the number of the\\ntop-level contexts currently active. Increase of this number over time indicates\\na memory leak.</p>\\n<p><code>number_of_detached_contexts</code> The value of detached_context is the number\\nof contexts that were detached and not yet garbage collected. This number\\nbeing non-zero indicates a potential memory leak.</p>\\n<!-- eslint-skip -->\\n<pre><code class=\\\"language-js\\\">{\\n  total_heap_size: 7326976,\\n  total_heap_size_executable: 4194304,\\n  total_physical_size: 7326976,\\n  total_available_size: 1152656,\\n  used_heap_size: 3476208,\\n  heap_size_limit: 1535115264,\\n  malloced_memory: 16384,\\n  peak_malloced_memory: 1127496,\\n  does_zap_garbage: 0,\\n  number_of_native_contexts: 1,\\n  number_of_detached_contexts: 0\\n}\\n</code></pre>\"\r\n        },\r\n```\r\n\r\ndocs-parser JSON output:\r\n```\r\n      {\r\n        \"name\": \"getHeapStatistics\",\r\n        \"signature\": \"()\",\r\n        \"description\": \"* `total_heap_size` number\\n* `total_heap_size_executable` number\\n* `total_physical_size` number\\n* `total_available_size` number\\n* `used_heap_size` number\\n* `heap_size_limit` number\\n* `malloced_memory` number\\n* `peak_malloced_memory` number\\n* `does_zap_garbage` number\\n* `number_of_native_contexts` number\\n* `number_of_detached_contexts` number\\n\\n`does_zap_garbage` is a 0/1 boolean, which signifies whether the `--zap_code_space` option is enabled or not. This makes V8 overwrite heap garbage with a bit pattern. The RSS footprint (resident memory set) gets bigger because it continuously touches all heap pages and that makes them less likely to get swapped out by the operating system.\\n\\n`number_of_native_contexts` The value of native_context is the number of the top-level contexts currently active. Increase of this number over time indicates a memory leak.\\n\\n`number_of_detached_contexts` The value of detached_context is the number of contexts that were detached and not yet garbage collected. This number being non-zero indicates a potential memory leak.\\n\\n<!-- eslint-skip -->\",\r\n        \"parameters\": [],\r\n        \"returns\": {\r\n          \"collection\": false,\r\n          \"type\": \"Object\",\r\n          \"properties\": [\r\n            {\r\n              \"name\": \"total_heap_size\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"total_heap_size_executable\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"total_physical_size\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"total_available_size\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"used_heap_size\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"heap_size_limit\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"malloced_memory\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"peak_malloced_memory\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"does_zap_garbage\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"number_of_native_contexts\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            },\r\n            {\r\n              \"name\": \"number_of_detached_contexts\",\r\n              \"description\": \"\",\r\n              \"required\": true,\r\n              \"additionalTags\": [],\r\n              \"collection\": false,\r\n              \"type\": \"number\"\r\n            }\r\n          ]\r\n        },\r\n        \"additionalTags\": []\r\n      },\r\n```\r\n\r\nThe latter output has a significantly larger amount of _useful_ context extracted from the same Markdown.\r\n\r\n## Current Challenges and Potential Blockers\r\n\r\nI would like to get a feeling for how folks feel about these potential technical/functional blockers.\r\n\r\n- [ ] Three elements of metadata that Node.js uses are currently missing from docs-parser: changes, introduced in, and stability.\r\n  - Potential solution: I've talked with @MarshallOfSound and it seems that there's potential for adding an extensible metadata section to docs-parser.\r\n- [ ] docs-parser does not currently output individual, per-API JSON files.\r\n  - Potential solution: this could be PR'ed or extracted in an additional step from the all-in-one file.\r\n- [ ] some elements of docs-parser are currently hardcoded to be electron-specific. \r\n  - Potential solution: [electron/docs-parser#21](https://github.com/electron/docs-parser/pull/21), additional configuration by file that @MarshallOfSound said he'd be interested in shipping.\r\n- [ ] Bug in the multi-class mode which results in a parsing error in docs that have mutliple classes ([@electronjs/docs-parser#27](https://github.com/electron/docs-parser/issues/27))\r\n  - Potential solution: slated to be fixed.",
        "labels": "doc",
        "id": 44047
    },
    {
        "title": "Misleading error that module does not provide export",
        "body": "### What steps will reproduce the bug?\r\n\r\n1. `git clone https://github.com/dandv/lib-does-not-provide-export-foo`\r\n2. `cd lib-does-not-provide-export-foo/use-lib`\r\n2. `node use-it.js   # node v13.9.0`\r\n\r\n### What is the expected behavior?\r\nThe script should run and output `foo`.\r\n\r\n### What do you see instead?\r\n\r\n```\r\nimport { foo } from '../lib/index.js';\r\n         ^^^\r\nSyntaxError: The requested module '../lib/index.js' does not provide an export named 'foo'\r\n```\r\n\r\n### Additional information\r\n\r\nWithin the context of a large project, this was a pretty odd mystery, when [`lib/index.js`](https://github.com/dandv/lib-does-not-provide-export-foo/blob/master/lib/index.js) clearly exports `foo`. Feel free to have some fun figuring out it (not hard with the minimal repro repo, but imagine the confused looks in a real-world scenario). Solution below.\r\n\r\n.\r\n.\r\n.\r\n.\r\n.\r\n.\r\n.\r\n.\r\n.\r\n.\r\n\r\n\r\n**Solution**\r\n\r\n[lib/package.json](https://github.com/dandv/lib-does-not-provide-export-foo/blob/master/lib/package.json) lacks `\"type\": \"module\"`.\r\n\r\n**Proposal**\r\n\r\nA clearer error would indicate that the imported file is not a module at all. As it is, the error suggested that other symbols were exported fine, so I kept double checking for typos and what not. This happened during a conversion to TypeScript that involved adding one export. The error made me think the problem was that export; it was not - it was that I forgot to add `\"type\": \"module\"` to `package.json`.\r\n\r\nThe full title of the bug would be \"Misleading error that module does not provide export when \"module\" is not in fact a module\", but that would have been a spoiler.",
        "labels": "doc",
        "id": 44048
    },
    {
        "title": "Document napi_create_bigint_uint64",
        "body": "Per https://github.com/nodejs/node/pull/32058#pullrequestreview-369666520 the documentation is missing.",
        "labels": "doc",
        "id": 44049
    },
    {
        "title": "package.exports: false is not working with module loader",
        "body": "Edits:\r\n\r\nIf you come here via search engine and `@babel/*` complaints  such errors after you upgraded to node.js 12.17.0 or 13.10.0, please update `@babel/helper-compilation-targets` to latest version.\r\n\r\nIf you are not using babel directly, please update your build infra (`react-scripts`, `vue-cli` and others to name) to latest version. If they doesn't work, the last resort is to remove your package lockfiles and re-install.\r\n\r\n--- Original Post ---\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: \r\nPlatform: \r\nSubsystem: ES Modules\r\n-->\r\n\r\n* **Version**: v13.10.1\r\n* **Platform**: Darwin jh.local 19.3.0 Darwin Kernel Version 19.3.0: Thu Jan  9 20:58:23 PST 2020; root:xnu-6153.81.5~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: ES Modules\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n1. Create a package `foo`, with `package.json` as\r\n```json\r\n{\r\n  \"exports\": false\r\n}\r\n```\r\n2. add a test file `test.js`.\r\n```js\r\nrequire(\"foo\")\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nMust reproduce\r\n\r\n### What is the expected behavior?\r\nIt should load successfully according to the [docs](https://nodejs.org/api/esm.html#esm_package_exports)\r\n\r\n> If a package has no exports, setting \"exports\": false can be used instead of \"exports\": {} to indicate the package does not intend for submodules to be exposed.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nIt throws\r\n```\r\nError [ERR_PACKAGE_PATH_NOT_EXPORTED]: No \"exports\" main resolved in /path/to/foo/package.json\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n`exports: {}` also throws.\r\n`exports: null` looks good to me but it is undocumented.\r\n\r\nThe issue is firstly reported in https://github.com/babel/babel/issues/11216, we had changed `exports: false` to `exports: { \".\": \"./lib/index.js\" }` for backward compatibility to Node.js 13.0-13.1. But I don't expect `exports: false` will break on Node.js 13.10\r\n\r\nI am not familiar with ES modules spec. So if this behaviour is intended, please update the docs.",
        "labels": "doc",
        "id": 44050
    },
    {
        "title": "Docs only shows version subset in navigation",
        "body": "* **Browser version**: Chrome Version 80.0.3987.106\r\n* **Operating system**: macOS 10.14\r\n\r\nWhen viewing a given API reference on the website, there's an option to view another version:\r\n\r\n<img width=\"688\" alt=\"Screen Shot 2020-03-03 at 11 13 02 AM\" src=\"https://user-images.githubusercontent.com/2036040/75810734-fac8ae00-5d3f-11ea-9e10-0de3e19b1826.png\">\r\n\r\nIt allows for a user to pick another version to swap to and see relevant docs, but it's constrained by what existed at the time the _currently chosen doc_ was written. This means that e.g when a user picks v11.x, they won't be able to go back to v13.x:\r\n\r\n<img width=\"732\" alt=\"Screen Shot 2020-03-03 at 11 14 25 AM\" src=\"https://user-images.githubusercontent.com/2036040/75810846-32375a80-5d40-11ea-97a0-23c7e06e0b30.png\">\r\n\r\nwithout first going back to v12.x.\r\n\r\nI'd say this is an antipattern, and that we should unilaterally be storing the versions available in the most recently defined major line. If this seems like a good path forward, i'm happy to implement this myself!\r\n",
        "labels": "doc",
        "id": 44051
    },
    {
        "title": "docs: needs clarification: \"terminal raw mode\" (signal handling)",
        "body": "About the `SIGINT` event on `process` it is said in the docs that\r\n\r\n> It is not generated when terminal raw mode is enabled.\r\n\r\nhttps://github.com/nodejs/node/blame/3ec4b21b1c438255df6f1652377011080dc28052/doc/api/process.md#L504\r\n\r\nIn the example program I play around with the SIGINT handler was not firing. I assumed that I was testing with the \"terminal raw mode\", so I was looking into understanding what that is and how to disable it.\r\n\r\nA web search for `nodejs \"terminal raw mode\"` didn't yield anything useful, though. I also explored `node --help` and didn't see anything obvious.\r\n\r\nI think we should clarify in docs what \"terminal raw mode\" is and then cross-link to that place from the SIGINT doc I linked above.\r\n\r\n\r\n",
        "labels": "doc",
        "id": 44052
    },
    {
        "title": "Improve documentation for Performance Hooks entry types",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nPerformance Hooks entry types `gc`, `http` and `http2` are only listed in the docs, there's no explanation about when those are triggered or examples how to use them efficiently. \r\n\r\n**Describe the solution you'd like**\r\nBetter documentation for those entry types.\r\n\r\n**Describe alternatives you've considered**\r\nBlog posts? But these can easily get outdated (for example, `clearGC` mentioned [here](https://medium.com/the-node-js-collection/timing-is-everything-6d43fc9fd416) doesn't seem to be on the API anymore).",
        "labels": "doc",
        "id": 44053
    },
    {
        "title": "[doc] oaepLabel option missing from crypto.publicEncrypt's \"key\" value",
        "body": "While the docs mention the `oaepHash` value for the object of the `key` value for the `crypto.publicEncrypt` function they don't mention the `oaepLabel` value that can also be specified in said object.",
        "labels": "doc",
        "id": 44054
    },
    {
        "title": "crypto.Decipher.update errors when inputEncoding is provided and data is a Buffer",
        "body": "* **Version**: 13.8.0\r\n* **Platform**: any as far as I can tell - discovered on Windows 10 Enterprise 64bit\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n\r\nCreating a piece of content to encrypt with an odd length, encrypting it using cipher then calling decipher.update with a buffer containing the encrypted value and 'hex' as the inputEncoding will reproduce the error.\r\n\r\n```\r\nconst crypto = require('crypto');\r\n\r\nconst key = '76814765872355644465872785667516';\r\nconst iv = '594835440127';\r\nconst content = 'the content to be encrypted seems to need to be an odd length to reproduce the issue correctly.';\r\n\r\nconst cipher = crypto.createCipheriv('aes-256-gcm', key, iv);\r\nlet encrypted = cipher.update(content, 'utf8', 'hex');\r\nencrypted += cipher.final('hex');\r\nconst authTag = cipher.getAuthTag().toString('hex');\r\n\r\nconst encryptedBuffer = Buffer.from(encrypted, 'hex');\r\nconst authTagBuffer = Buffer.from(authTag, 'hex');\r\nconst decipher = crypto.createDecipheriv('aes-256-gcm', key, iv);\r\ndecipher.setAuthTag(authTagBuffer);\r\nlet decrypted = decipher.update(encryptedBuffer, 'hex', 'utf8');\r\ndecrypted += decipher.final('utf8');\r\n\r\nconsole.log(decrypted);\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nShould be consistently reproducible with the above code\r\n\r\n### What is the expected behavior?\r\n\r\nThe docs for Decipher.update state that inputEncoding should be ignored when the data argument is a Buffer:\r\nUpdates the decipher with data. If the inputEncoding argument is given, the data argument is a string using the specified encoding. If the inputEncoding argument is not given, data must be a Buffer. If data is a Buffer then inputEncoding is ignored.\r\n\r\nThe input encoding is instead being validated and failing validation.  If the inputEncoding is provided as null in the example above, decryption happens correctly.\r\n\r\nThe above code snippet should log out 'the content to be encrypted seems to need to be an odd length to reproduce the issue correctly.'\r\n\r\n### What do you see instead?\r\n\r\ninternal/validators.js:153\r\n    throw new ERR_INVALID_ARG_VALUE('encoding', encoding,\r\n    ^\r\n\r\nTypeError [ERR_INVALID_ARG_VALUE]: The argument 'encoding' is invalid for data of length 95. Received 'hex'\r\n    at validateEncoding (internal/validators.js:153:11)\r\n    at Decipheriv.update (internal/crypto/cipher.js:159:3)\r\n    at Object.<anonymous> (C:\\Users\\n0139509\\IdeaProjects\\azure-node-auth\\example.js:19:26)\r\n    at Module._compile (internal/modules/cjs/loader.js:1151:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1171:10)\r\n    at Module.load (internal/modules/cjs/loader.js:1000:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:899:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12)\r\n    at internal/main/run_main_module.js:17:47 {\r\n  code: 'ERR_INVALID_ARG_VALUE'\r\n}\r\n\r\n\r\n### Additional information\r\n\r\nThis works properly in all versions of node I've tried prior to 13 (tried 10 and 12).  It seems to be caused by the addition of the validateEncoding call to the Cipher.prototype.update function in internal/crypto/cipher.js without any check for whether the data provided is a Buffer or not, but I'm not sure if the docs were meant to change, or if the possibility of a Buffer being provided was overlooked when that call was added.",
        "labels": "doc",
        "id": 44055
    },
    {
        "title": "HTTP2 Server Upgrade listener undocumented",
        "body": "- All versions that have HTTP2 and HTTPS* implemented\r\n- Documentation problem\r\n\r\nThe code below shows what is up. I wonder what could be the reason that it works even-tough it is undocumented even in the typescript definitions that come with npm.\r\nI would say this is due to C++ inheritance from HTTPServer to HTTPSServer and HTTP2Server, but no idea, someone could look into it to make sure.\r\n\r\n```\r\nconst server = http2.createServer({\r\n  allowHTTP1: true\r\n});\r\n\r\nserver.on('upgrade', (request, socket, head) => {\r\n  // This does work, but no documentation anywhere (internet, TS definitions, ancestor classes neither)\r\n  // (One could add as ws upgrade handler here)\r\n});\r\n```\r\n\r\n**Edit:** apparently it is undocumented in the node HTTPS Server as well.",
        "labels": "doc",
        "id": 44056
    },
    {
        "title": "async_hooks doc missing AsyncHook class",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: current master branch (v14.0.0-pre)\r\n* **Platform**: n/a\r\n* **Subsystem**: doc, async_hooks\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThe docs talk about `AsyncHook` and specifies it as the return value for methods, but there is no entry for the class.",
        "labels": "doc",
        "id": 44057
    },
    {
        "title": "doc: Improve docs search engine indexing",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n### There's no way to access api from search engine in one click.\r\n\r\nIt's very hard to search node api from search engine. A typical example would be searching `node writefilesync`, the top result points to `https://nodejs.org/api/fs.html` without the heading hash `#fs_fs_writefilesync_file_data_options`. \r\n\r\n![image](https://user-images.githubusercontent.com/1488391/73585987-6aaff400-4475-11ea-86f9-ca07a1a72679.png)\r\n\r\n\r\nIn most cases, it's sth like the following, where there's a `jump to xxx` link to the hashed url `https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API/Using_Fetch#Body`\r\n\r\n<img width=\"794\" alt=\"Screen Shot 2020-01-30 at 2 40 14 PM\" src=\"https://user-images.githubusercontent.com/1488391/73484929-30a8fa00-4370-11ea-9ded-0355951e9e15.png\">\r\n\r\nI'm not sure what's missing here, a quick search seems to suggest search engine need a unique id in headings like `<h4 id=\"xxx\"></h4>` to tell the heading structure.\r\n\r\nSince there's no search bar in the doc, it seems using search engine followed by Ctrl+F is the only way to find an api.\r\n\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44058
    },
    {
        "title": "docs: <code> blocks in headings not rendered correctly",
        "body": "See e.g. https://nodejs.org/api/esm.html#esm_package_json_type_field. The text `\"type\"` should be rendered as a code block, yet instead itâ€™s rendered as normal text with wide margins on either side. In earlier versions I tried using backticks but they werenâ€™t supported in Markdown headings.\r\n\r\ncc @Trott ",
        "labels": "doc",
        "id": 44059
    },
    {
        "title": "Documentation for creating a `Buffer` which shares a `TypedArray`'s memory is misleading",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v12.13.0\r\n* **Platform**: Windows 10 64-bit\r\n* **Subsystem**: docs\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThe documentation for `Buffer` [reads, in part](https://nodejs.org/docs/latest/api/buffer.html#buffer_buffers_and_typedarray) (abbreviated for clarity):\r\n\r\n> It is possible to create a new `Buffer` that shares the same allocated memory as a `TypedArray` instance by using the `TypedArray` object's `.buffer` property.\r\n> \r\n> \r\n> ```js\r\n> const arr = new Uint16Array(2);\r\n> arr[0] = 5000;\r\n> arr[1] = 4000;\r\n> const buf2 = Buffer.from(arr.buffer);\r\n> console.log(buf2);\r\n> // Prints: <Buffer 88 13 a0 0f>\r\n> ```\r\n> \r\n\r\nThis works in this case, but I think it's hazardous advice for arbitrary `TypedArray`s because the backing `ArrayBuffer` could extend beyond the bounds of the `TypedArray` which is providing a view of it. For example:\r\n\r\n```js\r\nconst arrA = Uint8Array.from([0x63, 0x64, 0x65, 0x66]) // 4 elements\r\nconst arrB = new Uint8Array(arrA.buffer, 1, 2) // 2 elements\r\nconsole.log(arrA.buffer === arrB.buffer) // true\r\n\r\nconst buf = Buffer.from(arrB.buffer)\r\nconsole.log(buf)\r\n// expected, based on documented advice: <Buffer 64 65>\r\n// actual: <Buffer 63 64 65 66>\r\n```\r\n\r\nIt might be better to have the docs suggest `Buffer.from(arr.buffer, arr.byteOffset, arr.byteLength)` as the general solution to this problem.",
        "labels": "doc",
        "id": 44060
    },
    {
        "title": "new tls.TLSSocket issue",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10.x+\r\n* **Platform**: All\r\n* **Subsystem**: tls\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhen I try to create a secure connection over an existing stream, implementing something similar to STARTTLS, the suggested way is to use new tls.TLSSocket(<duplex stream>).\r\n\r\nI also want to use mutual certification authentication but the tlsSocket.authorized is never set to true for the Server even when the client certificate is signed correctly by the expected CA. From the _tls_wrap.js code, it seems this flag is only set for the server when the underlying stream is an actual socket.\r\n\r\nOn the client side things are working as expected, as the client side connection is created with tls.connect().\r\n\r\nIt used to be that the deprecated pair returned by tls.createSecurePair() has access to the internal SSL object, which I can use verifyError() to check the validity of the client certificate. But this hidden feature has also been removed in recent versions.\r\n\r\nWhat is the correct approach to mca for \"upgraded\" connection?\r\n",
        "labels": "doc",
        "id": 44061
    },
    {
        "title": "correction on Crypto Sign class example (Using Sign and Verify objects as streams) https://nodejs.org/api/crypto.html#crypto_class_sign",
        "body": "// According to website (https://nodejs.org/api/crypto.html#crypto_class_sign) In following code  //console.log() print false which is a wrong output.  \r\n//but it should print true when sign.write() and verify.write() have same data as input\r\n\r\n--------------------------------------------------------------------------------------------------------\r\n\r\nconst crypto = require('crypto');\r\n\r\nconst { privateKey, publicKey } = crypto.generateKeyPairSync('ec', {\r\n  namedCurve: 'sect239k1'\r\n});\r\n\r\nconst sign = crypto.createSign('SHA256');\r\nsign.write('some data to sign');\r\nsign.end();\r\nconst signature = sign.sign(privateKey, 'hex');\r\n\r\nconst verify = crypto.createVerify('SHA256');\r\nverify.write('some data to sign');\r\nverify.end();\r\nconsole.log(verify.verify(publicKey, signature));\r\n// Prints: true or false\r\n\r\n-------------------------------------------------------------------------------------\r\n\r\n//solution\r\n//please update verify.verify(publicKey,signature) to verify.verify(publicKey,signature,'hex')\r\n//or\r\n//update  sign.sign(privateKey, 'hex') to sign.sign(privateKey)\r\n// then above code print right output on specified inputs.",
        "labels": "doc",
        "id": 44062
    },
    {
        "title": "security implications of legacy url.parse() should be more clearly documented",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: all\r\n* **Platform**: all\r\n* **Subsystem**: url\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nurl.parse() is \"sloppy\" with its parsing, so use of it can result in behaviour unexpected by some users that has security implications.\r\n\r\nIt is marked as deprecated at https://nodejs.org/api/url.html#url_url_parse_urlstring_parsequerystring_slashesdenotehost, but the docs don't specifically call out the security issues, so people won't necessarily know that security is a reason to avoid it.\r\n\r\nIt also doesn't list the specific (known) security issues, so that its not possible for users of the legacy url.parse() API to determine whether their usage is insecure.\r\n\r\nThese should be addressed through documentation. \r\n\r\nRelated\r\n- https://github.com/nodejs/node/issues/23694\r\n- https://hackerone.com/reports/738333\r\n- https://hackerone.com/reports/678487\r\n\r\nVulnerability reports in process of disclosure, so link will be dead for a while longer.",
        "labels": "doc",
        "id": 44063
    },
    {
        "title": "Clarify behaviour when listening for 'error' event using once()",
        "body": "The documentation for once [states](https://nodejs.org/api/events.html#events_events_once_emitter_name):\r\n\r\n> Creates a Promise **that is fulfilled when the EventEmitter emits the given event or that is rejected when the EventEmitter emits 'error'**. The Promise will resolve with an array of all the arguments emitted to the given event.\r\n\r\nIt's not clear from the documentation what happens when once is used to listen for `error` event. In my case this is the desired behaviors but I was surprised when my tests were not failing because an error event was emitted.\r\n\r\nThis:\r\n```js\r\nconst { EventEmitter, once } = require('events');\r\n\r\nconst ee = new EventEmitter();\r\n\r\nonce(ee, 'error').then(([err]) => {\r\n    console.log('resolves', err);\r\n}).catch((err) => {\r\n    console.log('rejects', err);\r\n})\r\n\r\nee.emit('error', new Error('Hi'))\r\n```\r\nPrints:\r\n```\r\nresolves Error: Hi\r\n    at Object.<anonymous> ...\r\n```\r\n\r\nCan you clarify this behaviour in the documentation please?",
        "labels": "doc",
        "id": 44064
    },
    {
        "title": "v8.getHeapSpaceStatistics() link to GetHeapSpaceStatistics() is broken",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\nhttps://nodejs.org/api/v8.html#v8_v8_getheapspacestatistics\r\n* **Version**: current\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\n<!-- Please provide more details below this comment. -->\r\nhttps://nodejs.org/api/v8.html#v8_v8_getheapspacestatistics links to https://v8docs.nodesource.com/node-10.6/d5/dda/classv8_1_1_isolate.html#ac673576f24fdc7a33378f8f57e1d13a4 which is 404.\r\n\r\nIt should be replaced with a more stable link, if one exists, though I can't find one.",
        "labels": "doc",
        "id": 44065
    },
    {
        "title": "Documentation is not clear enough regarding parameters in callback",
        "body": "https://nodejs.org/docs/latest-v12.x/api/net.html#net_server_listen_options_callback\r\n\r\nIt states: `callback <Function> Common parameter of server.listen() functions.`\r\n\r\nThis does not give me any information if there are or if there are no any parameters when the function is called.",
        "labels": "doc",
        "id": 44066
    },
    {
        "title": "How to get the \"Date\" set on a response header for HTTP2?",
        "body": "Ref: https://github.com/nodejs/node/issues/28302",
        "labels": "doc",
        "id": 44067
    },
    {
        "title": "Select another version dropdown bug",
        "body": "* **URL**: https://nodejs.org/api/https.html\r\n* **Browser version**: Chrome 78\r\n* **Operating system**: Windows 10\r\n\r\nThe `View another version` dropdown is a bit broken. When you mouse over it and go down, it closes before you can get your mouse into the version selection box.\r\nSeems to happen 9/10 times for me.",
        "labels": "doc",
        "id": 44068
    },
    {
        "title": "doc: fix recommendation of setImmediate() over process.nextTick()",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nOn this url:\r\n\r\n- https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/\r\n\r\nAt the `process.nextTick()` section, it says:\r\n\r\n> We recommend developers use setImmediate() in all cases because it's easier to reason about (and it leads to code that's compatible with a wider variety of environments, like browser JS.)\r\n\r\nBut this is untrue since `setImmediate()` isn't supported in \"wider variety of environments\". Only supported in Edge & IE, but not Chrome, Firefox, Safari (on both desktop and mobile platforms).\r\n\r\n- https://developer.mozilla.org/en-US/docs/Web/API/Window/setImmediate\r\n- https://caniuse.com/#feat=setimmediate\r\n\r\n**Describe the solution you'd like**\r\n- remove that last phrase \"(and it leads to code that's compatible with a wider variety of environments, like browser JS.)\"?\r\n\r\n**Describe alternatives you've considered**\r\n- I think `setTimeout` and `window.requestAnimationFrame` are the nearest alternatives for `setImmediate` for the browser, but I don't know how to phrase it yet",
        "labels": "doc",
        "id": 44069
    },
    {
        "title": "Documentation writable stream example confusing order",
        "body": "```\r\nwriter.on('finish', () => {\r\n  console.log('All writes are now complete.');\r\n});\r\n```\r\nshould be before \r\n```\r\nwriter.end('This is the end\\n');\r\n```\r\nhttps://nodejs.org/api/stream.html#stream_event_finish",
        "labels": "doc",
        "id": 44070
    },
    {
        "title": "doc: http.ServerResponse close event",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 12.x\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nIn the [version 10 documentation](https://nodejs.org/docs/latest-v10.x/api/http.html#http_event_close_1) it states that the 'close' event is emitted on a response when the connection is terminated before the response has ended.\r\n\r\nIn the [version 12 documentation](https://nodejs.org/docs/latest-v12.x/api/http.html#http_event_close_1) it simply states that the connection was terminated. This does not seem consistent with the behaviour I have seen, where the event is actually emitted at the end of each response, which I have also found described in [a commit](https://github.com/nodejs/node/commit/ffb503be5f07a26d73a2b3b59955636452948ba7) introduced in version 11.\r\n\r\nCan you clarify that the event in version 12 is in fact emitted at the end of each response, in which case I would be happy to submit a PR to update the docs.",
        "labels": "doc",
        "id": 44071
    },
    {
        "title": "doc: add NO_COLOR to disable colors in assert doc",
        "body": "Currently the assert docs point to only `NODE_DISABLE_COLORS` env variable to disable tty colors. `NO_COLOR` does the same thing. \r\n\r\nGoing ahead and creating a small PR to add the variable there.\r\n\r\n<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v12.8.0\r\n* **Platform**: Darwin Kernel Version 18.7.0\r\n* **Subsystem**: doc\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44072
    },
    {
        "title": "doc: document how we use Travis CI",
        "body": "Our Onboarding and Collaborator guide only explain how we use Jenkins.\r\n\r\nIt's hard to tell if Travis CI is testing is redundant to Jenkins or not. I believe Travis CI builds the docs? Is green Travis CI required or optional for landing PRs?\r\n\r\nDoes anybody want to take this on and add one or two sentences to our onboarding docs? Thanks!",
        "labels": "doc",
        "id": 44073
    },
    {
        "title": "undocumented \"lookup\" option in http.request / http.get",
        "body": "Hi there, is the `lookup` option for `http.request` intentionally undocumented? Sindre's `got` uses it but I'd want to know if it's stable or not since it's not documented?\r\n\r\n- https://github.com/nodejs/node/blob/b361f9577fbd72e518438d3fa0b01f7d34d814a5/test/parallel/test-http-client-timeout-option-with-agent.js#L12\r\n- https://github.com/nodejs/node/blob/dcc5e51e1cb4e102effd7fc515681446b07e428e/test/parallel/test-http-client-req-error-dont-double-fire.js#L18\r\n- https://github.com/szmarczak/cacheable-lookup\r\n- https://nodejs.org/api/http.html#http_http_request_options_callback",
        "labels": "doc",
        "id": 44074
    },
    {
        "title": "Undocumented url.parse pathname change",
        "body": "**Code**\r\n\r\n```js\r\nvar url = require(\"url\")\r\nconsole.log(url.parse('ws://localhost').pathname)\r\n```\r\n\r\n**Node version and output**\r\n\r\n12.13.0\r\n\"/\"\r\n10.16.3\r\nnull\r\n\r\nThe change is not visible [in the docs](https://nodejs.org/dist/latest-v13.x/docs/api/url.html#url_url_parse_urlstring_parsequerystring_slashesdenotehost)\r\n\r\nI could submit a PR if you confirm this should be added to the doc",
        "labels": "doc",
        "id": 44075
    },
    {
        "title": "suggested updates to the onboarding doc",
        "body": "This is a TODO list that I took during the onboarding of legendcas. Opening an issue in case I forget about them - but feel free to pick them up if you are interested to help!\r\n\r\n- [ ] Mention this trick `git remote set-url origin --push no_push`\r\n- [ ] Mention nodejs/help (when triaging issues)\r\n- [ ] Itâ€™s not necessary to explain everything in the on boarding document. The person doing the onboarding can ask whether the collaborator already knows about each point and skip if they already do. If they have questions, answer them.\r\n- [ ] Mention the new 7 day rule, or just add a link to the collaborator guide about the rules\r\n- [ ] Mention other commonly used CIs\r\n  - [ ] micro benchmark\r\n  - [ ] v8\r\n  - [ ] custom e.g. internet\r\n  - [ ] stress test\r\n  - [ ] citgm\r\n- [ ] Mention how to get a git ref to use in the Jenkins build parameters\r\n- [ ] The `what belongs in Node.js` seems a bit outdated? In general we just open issues and discuss on a case-by-case basis\r\n- [ ] Mention the travis CI\r\n- [ ] Mention the resume build button and the stop button in Jenkins\r\n- [ ] Mention how to report issues to the build team: with the machine id\r\n- [ ] TODO(joyee): Update node-core-utils recording, and just add a link to the recording to quickly demonstrate how to use it\r\n- [ ] Add the github-bot and node-core-utils repo to the \"other repos\" links, and explain what those are\r\n- [ ] Mention the Collboarator github team discussion page\r\n- [ ] Mention how security bugs are handled (or a link to SECURITY.md)\r\n- [ ] Mention that collaborators can nominate other collaborators (and add a link to GOVERNANCE.md)\r\n",
        "labels": "doc",
        "id": 44076
    },
    {
        "title": "Documentation for http.message.url suggests using deprecated url API",
        "body": "At the following piece of documentation (for v12; the latest one):\r\n\r\n* https://nodejs.org/dist/latest-v12.x/docs/api/http.html#http_message_url\r\n* https://github.com/nodejs/node/blob/master/doc/api/http.md#messageurl\r\n\r\nIt describes:\r\n\r\n> To parse the url into its parts `require('url').parse(request.url)` can be used:\r\n> [â€¦]\r\n> â€¦or `true` can be passed as the second argument to `require('url').parse`:\r\n> [â€¦]\r\n\r\nHowever, this legacy `url` module/API is deprecated since v11.\r\n\r\nThus, the documentation should be updated.\r\n\r\nBonus points for grepping the rest of the documentation to find other outdated examples.",
        "labels": "doc",
        "id": 44077
    },
    {
        "title": "Error.prepareStackTrace not called when --enable-source-maps",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v12.12.0\r\n* **Platform**: Windows 10 64-bit\r\n* **Subsystem**: error\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nIt seems that when `--enable-source-maps` is enabled, the way errors work is altered. For example, a global `Error.prepareStackTrace` function is no longer called as part of the process.\r\n\r\nI know `--enable-source-maps` is experimental based on the docs, but cannot find any specific information on, for example, if this is an expected change to runtime behavior or not.\r\n\r\nJust glancing around at the source code, I believe that `internal/errors.js` is what is calling the `Error.prepareStackTrace` when defined, but the command line flag replaces the stack trace implementation to one that does not call `Error.prepareStackTrace` any longer.",
        "labels": "doc",
        "id": 44078
    },
    {
        "title": "emitClose default wrong in fs.createWriteStream documentation",
        "body": "The documentation for [`fs.createWriteStream`][1] says:\r\n\r\n> emitClose <boolean> Default: false\r\n\r\nBut [the source code][2] defaults to true:\r\n\r\n```javascript\r\n  // Should close be emitted on destroy. Defaults to true.\r\n  this.emitClose = !options || options.emitClose !== false;\r\n```\r\n\r\n[1]: https://nodejs.org/api/fs.html#fs_fs_createwritestream_path_options\r\n[2]: https://github.com/nodejs/node/blob/e71bdadf526477c05d676034cfab0aa42cda257d/lib/_stream_writable.js#L154-L155",
        "labels": "doc",
        "id": 44079
    },
    {
        "title": "CHANGELOG_V12 - wrong flag listed",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**:\r\nIrrelevant.\r\n* **Platform**:\r\nIrrelevant\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\nRelease notes for node v12.12.0 say `--source-map-support`, but trying to use it results in:\r\n`node: bad option: --source-map-support`\r\n\r\nThe actual flag is `--enable-source-maps`.",
        "labels": "doc",
        "id": 44080
    },
    {
        "title": "http docs should refer to stream.Duplex instead of net.Socket",
        "body": "In many places in the documentation (example: [`'socket'` event](https://nodejs.org/api/http.html#http_event_socket)), `socket` is not necessarily a `net.Socket`, but always a `stream.Duplex` (which `net.Socket` inherits from). We should at least mention that if we don't want to replace all references.",
        "labels": "doc",
        "id": 44081
    },
    {
        "title": "test/doctool/test-doctool-html requires internet connection?",
        "body": "I got this today:\r\n\r\n```\r\n/Applications/Xcode.app/Contents/Developer/usr/bin/make -s test-doc\r\nRunning JS linter...\r\nRunning C++ linter...\r\nRunning Markdown linter on misc docs...\r\nRunning Markdown linter on docs...\r\n=== release test-doctool-html ===\r\nPath: doctool/test-doctool-html\r\nFailed to add alternative version links to foo\r\nFailed to add alternative version links to foo\r\nFailed to add alternative version links to foo\r\nFailed to add alternative version links to foo\r\n/Users/joyee/projects/node/test/common/index.js:710\r\nconst crashOnUnhandledRejection = (err) => { throw err; };\r\n                                             ^\r\n\r\nError: connect ETIMEDOUT 151.101.228.133:443\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1128:14) {\r\n  errno: -60,\r\n  code: 'ETIMEDOUT',\r\n  syscall: 'connect',\r\n  address: '151.101.228.133',\r\n  port: 443\r\n}\r\nCommand: out/Release/node /Users/joyee/projects/node/test/doctool/test-doctool-html.js\r\n[01:17|% 100|+   3|-   1]: Done\r\nmake[1]: *** [test-doc] Error 1\r\nmake: *** [test] Error 2\r\n```\r\n\r\nAnd if I turn off Wifi..\r\n\r\n```\r\nNODE_DEBUG=net out/Release/node /Users/joyee/projects/node/test/doctool/test-doctool-html.js\r\nFailed to add alternative version links to foo\r\nFailed to add alternative version links to foo\r\nNET 34507: pipe false null\r\nNET 34507: connect: find host raw.githubusercontent.com\r\nNET 34507: connect: dns options { family: undefined, hints: 1024 }\r\nNET 34507: _read\r\nNET 34507: _read wait for connection\r\nFailed to add alternative version links to foo\r\nFailed to add alternative version links to foo\r\nNET 34507: destroy\r\nNET 34507: close\r\nNET 34507: close handle\r\n/Users/joyee/projects/node/test/common/index.js:710\r\nconst crashOnUnhandledRejection = (err) => { throw err; };\r\n                                             ^\r\n\r\nError: getaddrinfo ENOTFOUND raw.githubusercontent.com\r\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (dns.js:60:26) {\r\n  errno: -3008,\r\n  code: 'ENOTFOUND',\r\n  syscall: 'getaddrinfo',\r\n  hostname: 'raw.githubusercontent.com'\r\n}\r\n```\r\n\r\nHas there been any changes that add this new requirement? It seems weird to require internet connection to run the doc tests.",
        "labels": "doc",
        "id": 44082
    },
    {
        "title": "Buffer.from(string, 'hex') needs a documentation update (was: Buffer.from(x, `hex`).toString(`hex`) does not return x for certain values of x)",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10.16.3\r\n* **Platform**: Darwin Renes-MacBook-Pro.local 18.6.0 Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019; root:xnu-4903.261.4~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**: Buffer\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nRun these in the REPL:\r\n\r\n```\r\n Buffer.from('0', 'hex').toString('hex')               // returns ''\r\n Buffer.from('08', 'hex').toString('hex')              // returns '08'\r\n Buffer.from('088', 'hex').toString('hex')             // returns '08'\r\n Buffer.from('0888', 'hex').toString('hex')            // returns '0888'\r\n Buffer.from('08888', 'hex').toString('hex')           // returns '0888'\r\n Buffer.from('088888', 'hex').toString('hex')          // returns '088888'\r\n```\r\n\r\nI expected `.toString('hex')` to be the inverse operation of `Buffer.from(x, 'hex')`, but it doesn't seem to be the case. Why not?\r\n\r\nI was able to catch this error using `fast-check` and it found a few other strings that behave this way:\r\n\r\n* 8501eb788\r\n* eb788\r\n* 788",
        "labels": "doc",
        "id": 44083
    },
    {
        "title": "Better description of statuscode handling and improve example",
        "body": "Currently https://nodejs.org/api/http.html#http_http_get_url_options_callback mentions only `200` but any `2xx` statuscode is a `success` and not an error.\r\n\r\nThis should be improved.\r\n\r\nIf you have a question, suggestion or issue regarding our website,\r\nplease post it in https://github.com/nodejs/nodejs.org!\r\n\r\nIssues with the Node.js API documentation should be posted here. All other\r\nissues regarding the website will be closed.\r\n",
        "labels": "doc",
        "id": 44084
    },
    {
        "title": "doc: make tables responsive",
        "body": "I'm not sure how to proceed with this since we need a wrapping `div`.\r\n\r\nBasically\r\n\r\n```html\r\n<div class=\"whatever-name-we-decide\">THE MARKDOWN TABLE</div>\r\n```\r\n\r\nand\r\n\r\n```css\r\n.whatever-name-we-decide { overflow: auto; }\r\n```\r\n\r\nWith the above, the tables won't overflow the screen when they don't fit.",
        "labels": "doc",
        "id": 44085
    },
    {
        "title": "Contradiction in Readable docs",
        "body": "> The readable.push() method is intended be called only by Readable implementers, and only from within the readable._read() method.\r\n\r\nThis immediately follows an example showing\r\n\r\n```js\r\nif (!this.push(chunk))\r\n        this._source.readStop();\r\n```\r\n\r\nin the constructor instead.",
        "labels": "doc",
        "id": 44086
    },
    {
        "title": "Samples not language aware",
        "body": "in many cases changing \"Hello, World!\" to \"ÐŸÑ€Ð¸Ð²ÐµÑ‚, Ð¼Ð¸Ñ€!\" lead to encoding hell\r\n\r\ni guess it not good for newcomers :(\r\n\r\nhere http2 sample \r\n\r\n==========================\r\n```\r\nconst http2 = require('http2');\r\nconst fs = require('fs');\r\n\r\nconst server = http2.createSecureServer({\r\n  key: fs.readFileSync('localhost-privkey.pem'),\r\n  cert: fs.readFileSync('localhost-cert.pem')\r\n});\r\nserver.on('error', (err) => console.error(err));\r\n\r\nserver.on('stream', (stream, headers) => {\r\n  // stream is a Duplex\r\n  stream.respond({\r\n    'content-type': 'text/html',\r\n    ':status': 200\r\n  });\r\n  stream.end('<h1>Hello World (ÐŸÑ€Ð¸Ð²ÐµÑ‚, Ð¼Ð¸Ñ€!)</h1>');\r\n});\r\n\r\nserver.listen(8443);\r\n```\r\n\r\n==================\r\n\r\nand how it look in browser -> Hello World (Ð ÑŸÐ¡Ð‚Ð Ñ‘Ð Ð†Ð ÂµÐ¡â€š, Ð Ñ˜Ð Ñ‘Ð¡Ð‚!)\r\n\r\n:(\r\n\r\n",
        "labels": "doc",
        "id": 44087
    },
    {
        "title": "Document that `napi_get_date_value()` ignores leap seconds as per spec",
        "body": "https://github.com/nodejs/node/pull/29401#issuecomment-528020224:\r\n> > I'm actually not sure whether it does or does not account for leap seconds.\r\n> \r\n> From https://tc39.es/ecma262/#sec-time-values-and-time-range:\r\n> \r\n> > Time in ECMAScript does not observe leap seconds; they are ignored.",
        "labels": "doc",
        "id": 44088
    },
    {
        "title": "Emission of secure events changed across versions of node",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8.16.1, v10.16.3, v12.8.1\r\n* **Platform**: Linux tufopad 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: tls\r\n\r\n<!-- Please provide more details below this comment. -->\r\nIt seems to be a bit of discordance in the emission of the `secure` event across versions of node and also if you use the deprecated `createSecurePair` vs `new tls.TLSSocket`.\r\n\r\n# Steps to reproduce\r\nFirst, you'll need to clone [this repo](https://github.com/tufosa/tls-secure-event) containing the sample code.\r\n\r\nThis program starts a `tls.Server`, and then two clients, one using the deprecated `createSecurePair` and the other using `tls.TLSSocket`. It just opens the connections and wait for the different events to trigger. Each event leaves a trace. It reproduces 2 cases per client (4 in total): one just opening the connection (`write: false`) and the other opening the connection and immediately writing an empty string to the socket (`write: true`). Therefore the 4 cases are:\r\n\r\n- SecurePair-write-false\r\n- SecurePair-write-true\r\n- TLSSocket-write-false\r\n- TLSSocket-write-true\r\n\r\nIn order to reproduce the bug, run `node main.js` using different versions of nodejs and observe the differences in behaviour through the traces left by the program. It seems like both the `secure` and `secureConnection` events are emitted with different criteria depending on the version of node used.\r\n\r\nI undestand that `createSecurePair` is deprecated and therefore should not be used, but I believe that the new way of doing things (`tls.TLSSocket`) should have the same behaviour as the old `createSecurePair` in order to make the transition easier. It seems reasonable to wait for the `secure` event before attempting to write anything. This is how the old `createSecurePair` behaved in node v8.16.1, but this behaviour has been changed in node 10 and node 12.\r\n\r\nAlso [the documented `secureConnect`](https://nodejs.org/docs/latest-v8.x/api/tls.html#tls_event_secureconnect) event is never emitted. An undocumented `secure` event is emitted instead. I see that this has been reported before (at least [here](https://github.com/nodejs/node/issues/10555) and [here](https://github.com/nodejs/node/issues/13368)), but the docs haven't been fixed.\r\n\r\n## node v8.16.1\r\n```\r\nCreating SecurePair write false client...\r\n(node:31271) [DEP0064] DeprecationWarning: tls.createSecurePair() is deprecated. Please use tls.TLSSocket instead.\r\nsecureConnection\r\nsecure\r\n\r\nCreating TLSSocket write false client...\r\nERROR:  TLSSocket with write false did NOT receive secure event\r\n\r\nCreating SecurePair write true client...\r\nsecureConnection\r\nsecure\r\n\r\nCreating TLSSocket write true client...\r\nsecureConnection\r\nsecure\r\n\r\nFinished\r\n```\r\nThe only case not emitting any event is TLSSocket-write-false.\r\n\r\n## node v10.16.3\r\n```\r\nCreating SecurePair write false client...\r\n(node:31533) [DEP0064] DeprecationWarning: tls.createSecurePair() is deprecated. Please use tls.TLSSocket instead.\r\nERROR:  SecurePair with write false did NOT receive secure event\r\n\r\nCreating TLSSocket write false client...\r\nERROR:  TLSSocket with write false did NOT receive secure event\r\n\r\nCreating SecurePair write true client...\r\nsecureConnection\r\nsecure\r\n\r\nCreating TLSSocket write true client...\r\nsecureConnection\r\nsecure\r\n\r\nFinished\r\n```\r\nAll write-false cases fail (as in do not emit events) and all write-true cases\r\npass.\r\n\r\n## node v12.8.1\r\n```\r\nCreating SecurePair write false client...\r\n(node:31828) [DEP0064] DeprecationWarning: tls.createSecurePair() is deprecated. Please use tls.TLSSocket instead.\r\nERROR:  SecurePair with write false did NOT receive secure event\r\n\r\nCreating TLSSocket write false client...\r\nERROR:  TLSSocket with write false did NOT receive secure event\r\n\r\nCreating SecurePair write true client...\r\nsecure\r\n\r\nCreating TLSSocket write true client...\r\nsecureConnection\r\nsecure\r\n\r\nFinished\r\n```\r\nAll write-false cases fail and the write-true cases behave slightly different,\r\nas one of them (SecurePair-write-true) never emit the `secureConnection` event.\r\n\r\n",
        "labels": "doc",
        "id": 44089
    },
    {
        "title": "doc: AsyncGenerator + Writable + unhandled exception",
        "body": "Given the examples of using async generators with writable streams https://nodejs.org/dist/latest-v12.x/docs/api/stream.html#stream_piping_to_writable_streams_from_async_iterators.\r\n\r\nThere seems to be an issue in that they can cause an unhandled exception if `'error'` is emitted after `'finish'` (which is currently possible in some cases even with core streams). `once` will release the `'error'` handler on completion (`'finish'`). I would personally discourage using it as in the example, i.e.\r\n\r\nI would replace:\r\n\r\nUNSAFE\r\n```js\r\nconst { once } = require('events');\r\n\r\nconst writable = fs.createWriteStream('./file');\r\n\r\n(async function() {\r\n  const readable = Readable.from(iterator);\r\n  readable.pipe(writable);\r\n  // Ensure completion without errors.\r\n  await once(writable, 'finish');\r\n})();\r\n```\r\n\r\nwith\r\n\r\nSAFE\r\n```js\r\nconst finished = util.promisify(stream.finished);\r\n\r\nconst writable = fs.createWriteStream('./file');\r\n\r\n(async function() {\r\n  const readable = Readable.from(iterator);\r\n  readable.pipe(writable);\r\n  // Ensure completion without errors.\r\n  await finished(writable);\r\n})();\r\n```\r\n\r\nor\r\n\r\n```js\r\nconst pipeline = util.promisify(stream.pipeline);\r\n\r\nconst writable = fs.createWriteStream('./file');\r\n\r\n(async function() {\r\n  const readable = Readable.from(iterator);\r\n  await pipeline(readable, writable);\r\n})();\r\n```\r\n\r\n\r\n\r\nand \r\n\r\nUNSAFE\r\n```js\r\nconst { once } = require('events');\r\n\r\nconst writable = fs.createWriteStream('./file');\r\n\r\n(async function() {\r\n  for await (const chunk of iterator) {\r\n    // Handle backpressure on write().\r\n    if (!writable.write(chunk))\r\n      await once(writable, 'drain');\r\n  }\r\n  writable.end();\r\n  // Ensure completion without errors.\r\n  await once(writable, 'finish');\r\n})();\r\n```\r\n\r\nwith\r\n\r\nSAFE\r\n```js\r\nconst { once } = require('events');\r\nconst finished = util.promisify(stream.finished);\r\n\r\nconst writable = fs.createWriteStream('./file');\r\n\r\n(async function() {\r\n  for await (const chunk of iterator) {\r\n    // Handle backpressure on write().\r\n    if (!writable.write(chunk))\r\n      await once(writable, 'drain');\r\n  }\r\n  writable.end();\r\n  // Ensure completion without errors.\r\n  await finished(writable);\r\n})();\r\n```\r\n\r\n\r\nPossibly with a note on why `once` is not appropriate in this situation.",
        "labels": "doc",
        "id": 44090
    },
    {
        "title": "doc: how to document multiple inheritance",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThis request was raised in PR comment https://github.com/nodejs/node/pull/29290#discussion_r317847743\r\n\r\n**Describe the solution you'd like**\r\nHow to represent multiple inheritance in Node.js documentation\r\n\r\n**Describe alternatives you've considered**\r\n* The documentation only shows single parent class, or no inheritance at all\r\n* Going through the code to find out particular class extends multiple classes",
        "labels": "doc",
        "id": 44091
    },
    {
        "title": "Please document the list of possible errors for tls#TLSSocket#authorizationError",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'm trying to implement the EST enrollment protocol over TLS. In this protocol, I have to continue the TLS connection even on SOME of the possible TLS handshake errors. Unfortunately, the list of possible errors is not documented (the NodeJS Errors documentation page doesn't list them and neither does the TLS documentation page)\r\n\r\n**Describe the solution you'd like**\r\nThe NodeJS TLS documentation page should list all possible values for the authorizationError property\r\n\r\n",
        "labels": "doc",
        "id": 44092
    },
    {
        "title": "fs.read documentation errors",
        "body": "https://nodejs.org/api/fs.html#fs_fs_read_fd_buffer_offset_length_position_callback\r\n\r\nReferences to buffer and offset are indicative of writing, when they should be for reading.\r\n\r\n![fs-read-bug](https://user-images.githubusercontent.com/1139657/63509054-721bac00-c498-11e9-87fb-6ec6dbab010d.png)\r\n\r\n",
        "labels": "doc",
        "id": 44093
    },
    {
        "title": "`socket.setTimeout` destroys connection automatically",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.15.3\r\n* **Platform**: Windows 10 Pro 64-bit\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhen a socket timeouts via `socket.setTimeout()`, it is automatically destroyed, even though the [documentation ](https://nodejs.org/api/net.html#net_socket_settimeout_timeout_callback) states that it should not be.\r\n\r\n> When an idle timeout is triggered the socket will receive a 'timeout' event but the connection will not be severed. The user must manually call socket.end() or socket.destroy() to end the connection.\r\n\r\nCode to reproduce:\r\n```\r\nconst http = require('http');\r\n\r\nconst server = http.createServer(function (req, res) {\r\n});\r\n\r\nserver.on(\"connection\", socket => {\r\n    console.log('on connection');\r\n    socket.setTimeout(2000, () => {\r\n        console.log('on socket timeout', socket.destroyed);\r\n    });\r\n});\r\n\r\nserver.listen(3000);\r\n```",
        "labels": "doc",
        "id": 44094
    },
    {
        "title": "`querystring.stringify` unexpected behavior on `undefined` values",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10\r\n* **Platform**: MacOS\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n`JSON.stringify` omitting undefined values:\r\n```js\r\nJSON.stringify({s: 's', i: 0, n: null, u: undefined});  \r\n// output: {\"s\":\"s\",\"i\":0,\"n\":null}\r\n```\r\n\r\nBut `querystring.stringify` not omitting undefined values:\r\n```js\r\nquerystring.stringify({s: 's', i: 0, n: null, u: undefined});  \r\n// output: s=s&i=0&n=&u=\r\n```\r\n\r\nMoreover, I think that treating `null`s and `undefined`s the same way is less usable for the user (ie. user musts to `delete` properties from the object in order to filter them).",
        "labels": "doc",
        "id": 44095
    },
    {
        "title": "tls.DEFAULT_MIN_VERSION according to docs is v11 feature, but its present in v10.16.0 and is incorrect",
        "body": "* **Version**: 10.16.0\r\n* **Platform**: Ubuntu 14.04\r\n\r\nAccording to the [docs](https://nodejs.org/docs/latest-v12.x/api/tls.html#tls_tls_default_min_version) `tls.DEFAULT_MIN_VERSION` is available starting v11  and default value is `TLSv1.2`\r\n\r\nIssue : \r\n1. `Ubuntu 14.04` with Nodejs `v10.16.0` has `tls.DEFAULT_MIN_VERSION` defined\r\n2. It is returning incorrect value viz `TLSv1` instead of `TLSv1.2`\r\n\r\n",
        "labels": "doc",
        "id": 44096
    },
    {
        "title": "Improve module.createRequire documentation",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThe documentation was unclear for [createRequire](https://nodejs.org/api/modules.html#modules_module_createrequire_filename), I see #27758 & #27762 made a change and adds `import.meta.url`. I think this change adds difficulty (and needs more information) to understand this example.\r\n\r\nAlso, the *filename* argument (path) can be a file, or URL. I don't understand why [`../src/utils/`](https://github.com/nodejs/node/pull/27762/files#diff-80aff3ac9e9dd24f8cafe60d4ff3942a) was changed to `import.meta.url`. It makes no sense to use createRequire with the module URL. And why rewrite \"require\" ?\r\n\r\n**Describe the solution you'd like**\r\n\r\nRewrite the example : \r\n\r\n```js\r\nimport { createRequire } from 'module';\r\nconst requireUtil = createRequire(require.resolve('../src/utils/'));\r\n\r\n// Require `../src/utils/some-tool`\r\nrequireUtil('./some-tool');\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nAnother solution was: Add explain before the example and a link to `https://nodejs.org/api/esm.html#esm_import_meta`\r\n\r\n## Second part :\r\n**Is your feature request related to a problem? Please describe.**\r\nThe documentation was unclear for [createRequire](https://nodejs.org/api/modules.html#modules_module_createrequire_filename). I think the argument name *path* is more suited to *filename* in `module.createRequire(filename)` According to : \"Must be a file URL object, file URL string, or absolute path string.\"\r\n\r\n**Describe the solution you'd like**\r\nChange *filename* to *path*.",
        "labels": "doc",
        "id": 44097
    },
    {
        "title": "TypeError: Readable.from is not a function",
        "body": "Hi Folks,\r\n\r\nI was learning \"Streams\" from Nodejs.org website. I would like to bring to your notice that one of the API i.e., `Readable.from` is throwing an error - \"T**ypeError: Readable.from is not a function**\".\r\n\r\nI am using Node **v11.13.0**\r\n\r\nIn debug mode, I found that there isn't any property accessor named - \"_from_\" on \"_Readable_\" class, it's prototype or on it's super class either(Stream).\r\n\r\nFYI, I didn't make any tweaks to the provided example, and tried to use it as it is(screenshot attached).\r\n\r\nIf I am missing anything, please enlighten me.\r\n\r\nThanks in advance,\r\nDeepak\r\n\r\n![Readable from](https://user-images.githubusercontent.com/13273605/61206594-23525800-a71d-11e9-8ba6-0b3edcf01b26.png)\r\n",
        "labels": "doc",
        "id": 44098
    },
    {
        "title": "[Website Generator] Links must be .html for nodejs.org/api but they're actually .md on github",
        "body": "The [doc/api folder](https://github.com/nodejs/node/tree/master/doc/api) is full of .md files that serve as the documentation for the Node.js JavaScript libraries. These files are also what's used in the [nodejs.org website](https://nodejs.org/api/) for the website's api documentation. \r\n\r\nEvidently, there's [a tool](https://github.com/nodejs/node/tree/master/tools/doc) that converts these .md files into the doc folder into the webpages on nodejs.org. (And I think that tool gets run [as part of the Release process](https://github.com/nodejs/node/blob/master/doc/releases.md#14-check-the-release) for each Node.js version bump. I'm not 100% sure about that, though.)\r\n\r\nThe issue is that URLs in the doc files that link to other doc files must be formatted with a .html extension to work properly for the website. For example, [this PR that tries to change .html extensions to .md](https://github.com/nodejs/node/pull/28575) can't be merged because it would break the nodejs.org api documentation. \r\n\r\nThis is a problem because on github, the links don't work properly because the file names on github have .md extensions, not .html. Which means that links on github in those files don't work because the file being referenced (ex. `doc-name.html`) doesn't exist.\r\n\r\nThe solution would be to update the website api doc generation tool (which I think [is this](https://github.com/nodejs/node/tree/master/tools/doc)) to convert any .md extensions in URLs to .html when going through the doc files, so that we can update URLs in those docs to be .md so that they link correctly to the actual files on github.",
        "labels": "doc",
        "id": 44099
    },
    {
        "title": "add note in BUILDING.md about running `make distclean`",
        "body": "* **Version**: v13.0.0-pre\r\n* **Platform**: (OSX 10.13.4, Xcode 9.4.1, i5), (Debian GNU/Linux 10, GCC 7.3.0, amd64)\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n## Failure Building Master\r\n\r\nI'm receiving the following error when trying to build Node.js on master:\r\n\r\n```bash\r\n/Users/benjamincoe/bcoe/node/out/Release/obj.target/v8_snapshot/geni/embedded.cc:5:10: fatal error: 'src/snapshot/macros.h' file not found\r\n#include \"src/snapshot/macros.h\"\r\n```\r\n\r\nI'm receiving this error both on my Debian work desktop and my ancient Macbook.\r\n\r\nI also noticed that the same issue was reported by @ronag [here](https://github.com/nodejs/node/pull/27984).\r\n\r\n## ./configure --without-snapshot\r\n\r\nI was able to compile if I configured a build without snapshots, but the `./node` bin generated ~segfaults~ fails a check and exits with `1` .\r\n\r\n----\r\n\r\nCC: @nodejs/build",
        "labels": "doc",
        "id": 44100
    },
    {
        "title": "http2/compat: undocumented public property \"complete\"",
        "body": "The `Http2ServerRequest` has an undocumented public property \"complete\".\r\n\r\nI guess it should be either be documented or made private? What is it's purpose? Should we add it to http/1?\r\n\r\n```js \r\n  get complete() {\r\n    return this._readableState.ended ||\r\n           this[kState].closed ||\r\n           this[kStream].destroyed;\r\n  }\r\n```\r\n\r\nI'm not sure where this property is useful over just checking `this[kState].closed`? Seems like some kind of hybrid property of streams being closed and the old http/1 `finished` semantics.\r\n\r\nI guess it is `true` if `end()` has been called OR `'close'` has been emitted?",
        "labels": "doc",
        "id": 44101
    },
    {
        "title": "doc: undocumented properties are mentioned in the stream doc",
        "body": "`writable.writableBuffer` and `readable.readableBuffer` are mentioned https://nodejs.org/api/stream.html#stream_buffering but are undocumented in the appropriate sections.\r\n\r\nNot sure if this need to be addressed. Please close if this is OK.\r\n",
        "labels": "doc",
        "id": 44102
    },
    {
        "title": "doc: crypto.createDiffieHellmanGroup() not documented",
        "body": "See title. Class `DiffieHellmanGroup` isn't documented either.\r\n\r\nUsage:\r\n```js\r\nconst name = 'modp1';\r\nconst dh = crypto.createDiffieHellmanGroup(name);\r\n```\r\nIt takes a well-known modp group as its argument but otherwise works the same as `DiffieHellman`.\r\n\r\n`name` is taken from [RFC 2412](https://tools.ietf.org/html/rfc2412) (modp1 and 2) and [RFC 3526](https://tools.ietf.org/html/rfc3526):\r\n```\r\n$ perl -ne 'print \"$1\\n\" if /\"(modp\\d+)\"/' src/node_crypto_groups.h\r\nmodp1  #  768 bits\r\nmodp2  # 1024 bits\r\nmodp5  # 1536 bits\r\nmodp14 # 2048 bits\r\nmodp15 # etc.\r\nmodp16\r\nmodp17\r\nmodp18\r\n```",
        "labels": "doc",
        "id": 44103
    },
    {
        "title": "writable stream _write and _writev",
        "body": "Version: `v12.4.0` or `v10.15.3`\r\nPlatform: `Linux 4.15.0-51-generic #55~16.04.1-Ubuntu SMP Thu May 16 09:24:37 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`\r\nSubsystem: Stream Duplex, Object mode, piped into itself.\r\n\r\nThe documentation says that when I implement `_writev` method, it will receive chunks of data available in the buffer.\r\n\r\nWhat I actually see is that both `_write` and `_writev` methods are used simultaneously.\r\nIf `_write` is fast enough to process the buffer until it fills up to more than one object, then only `_write` is used. Otherwise, for the first object in the buffer `_write` will be used, and the rest will be sent to `_writev`.\r\n\r\nExample:\r\n```\r\nDEBUG: Calling _write with 1\r\nDEBUG: Calling _writev with 15\r\nDEBUG: Calling _write with 1\r\nDEBUG: Pushing null to readable\r\nDEBUG: Calling _writev with 15\r\nDEBUG: Calling _write with 1\r\nDEBUG: Calling _writev with 2\r\nDEBUG: Writable final\r\nDEBUG: _writev 16, _write 16\r\nDEBUG: Read 243, Written 243\r\n```\r\n\r\nIs this an expected behavior? I was assuming that when `_writev` method is implemented, it will be used exclusively.\r\n\r\nThanks",
        "labels": "doc",
        "id": 44104
    },
    {
        "title": "os.homedir() doesn't respect setuid",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8.10.0\r\n* **Platform**: Linux 4.15.18-15-pve #1 SMP PVE 4.15.18-40 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: os\r\n\r\n<!-- Please provide more details below this comment. -->\r\nExpected os.homedir() to home directory of the *current* user as a string but when the current user changes via process.setuid() this directory still show the original user's home directory",
        "labels": "doc",
        "id": 44105
    },
    {
        "title": "http2.connect's listener Parameter is Not Explained in The Documentation",
        "body": "* **Version**: 12.4.0\r\n* **Platform**: not important\r\n* **Subsystem**: http2\r\n\r\n`http2.connect`'s `listener` parameter is not explained in the documentation: https://nodejs.org/api/http2.html#http2_http2_connect_authority_options_listener\r\n",
        "labels": "doc",
        "id": 44106
    },
    {
        "title": "dns docs are missing that family = 0 for dns.lookup is allowed",
        "body": "<!-- Please remove this line and fill the template -->\r\n\r\n* **Node.js Version**: 12.2\r\n* **OS**: macOs\r\n* **Scope (install, code, runtime, meta, other?)**: runtime\r\n* **Module (and version) (if relevant)**: `dns`, `net`, `tls`\r\n\r\nQuick question: is `dns.lookup(url, 0, callback)` supported as part of Node's API? [The documentation](https://nodejs.org/dist/latest-v10.x/docs/api/dns.html#dns_dns_lookup_hostname_options_callback) says `Must be 4 or 6`, and any positive integer other than 4 or 6 will return a `TypeError [ERR_INVALID_OPT_VALUE]: The value \"2\" is invalid for option \"family\"`. But passing in `0` does not error. Is this expected? If so, is this something stable that developers can rely on?\r\n\r\n```js\r\n// The following are all expected to work\r\ndns.lookup('www.google.com', 4, err => {\r\n  console.log(err); // null\r\n});\r\ndns.lookup('www.google.com', 6, err => {\r\n  console.log(err); // null\r\n});\r\ndns.lookup('www.google.com', err => {\r\n  console.log(err); // null\r\n});\r\n\r\n// The following should error\r\ntry {\r\n  dns.lookup('www.google.com', 1, () => {});\r\n} catch (e) {\r\n  console.log(e); // TypeError [ERR_INVALID_OPT_VALUE]: The value \"1\" is invalid for option \"family\"\r\n}\r\ntry {\r\n  dns.lookup('www.google.com', 2, () => {});\r\n} catch (e) {\r\n  console.log(e); // TypeError [ERR_INVALID_OPT_VALUE]: The value \"2\" is invalid for option \"family\"\r\n}\r\ntry {\r\n  dns.lookup('www.google.com', 3, () => {});\r\n} catch (e) {\r\n  console.log(e); // TypeError [ERR_INVALID_OPT_VALUE]: The value \"3\" is invalid for option \"family\"\r\n}\r\ntry {\r\n  dns.lookup('www.google.com', 5, () => {});\r\n} catch (e) {\r\n  console.log(e); // TypeError [ERR_INVALID_OPT_VALUE]: The value \"5\" is invalid for option \"family\"\r\n}\r\n\r\n// Asking about this one:\r\ndns.lookup('www.google.com', 0, err => {\r\n  console.log(err); // null <-- is this correct?\r\n});\r\n```",
        "labels": "doc",
        "id": 44107
    },
    {
        "title": "esm modules documentation doesn't describe how to implement a module",
        "body": "I read https://nodejs.org/api/esm.html and found that while it had good/exhaustive coverage of `import`, it doesn't describe how to `export` a module. Unless I very much missed it, there is not even a single example of a ESM module.\r\n\r\nI know, `import` and `export` are part of the language base, and node's documentation doesn't cover the Javascript language. In this case, I think its necessary to at least have a single example, such as:\r\n```\r\nexport function whatever() {};\r\nexport function somethingElse() {};\r\nexport default {\r\n  whatever,\r\n   somethingElse,\r\n};\r\n```\r\n\r\nNot having this makes the import docs hard to understand, they talk a lot about \"exports\" and \"default exports\", but without defining them.\r\n\r\nAlso, having read through ~600 lines of documentation on ECMAscript modules and still having to scrape the internet to figure out how to write one is not a great documentation experience :-).\r\n\r\n<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: master/12\r\n* **Platform**: any\r\n* **Subsystem**: doc\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44108
    },
    {
        "title": "fs Promises API still marked as experimental for Node 10",
        "body": "https://nodejs.org/dist/latest-v10.x/docs/api/fs.html still reports fs-promises API to be experimental, even though it was declared stable in https://github.com/nodejs/node/pull/26581\r\nShouldn't same apply to Node 10 as well, or some code still needs to be backported first?",
        "labels": "doc",
        "id": 44109
    },
    {
        "title": "[Documentation Suggestion] How To Contribute To Unit Tests",
        "body": "**Description**\r\nI'm new to the Node project and I want to help contribute, and I've seen suggestions that a great way to contribute is to look at the [code coverage report](https://coverage.nodejs.org/), find something that doesn't have full coverage, and write/add to tests to help the coverage be more complete. \r\n\r\nHowever, the actual steps to do that are a bit vague (the code coverage website is a bit hard to understand), and this process isn't documented in this project. (I actually heard about doing this in [this medium article](https://medium.com/the-node-js-collection/interested-in-contributing-to-node-js-core-read-on-5614f60d074d).)\r\n\r\n**Solution**\r\nCan we add a section in one of the contributing documents (I guess either on the website or maybe a new doc (that gets referenced in [CONTRIBUTING.md](https://github.com/nodejs/node/blob/master/CONTRIBUTING.md)) to list out the steps of how to either use the code coverage tool to find code that's untested, and how to help add tests (or add to current tests) to contribute?\r\n\r\nI'm not sure if we should treat this in two parts (one part being documentation on how to use the code coverage tool, and another on how to use contribute by using it to find untested code), or to make just one document.",
        "labels": "doc",
        "id": 44110
    },
    {
        "title": "Fix documentation for the new `createRequire()`",
        "body": "## First issue: https://nodejs.org/dist/v12.2.0/docs/api/esm.html\r\n\r\nProblem: mentions the deprecated `module.createRequireFromPath()` (and not `module.createRequire()`).\r\n\r\n## Second issue: https://nodejs.org/dist/v12.2.0/docs/api/modules.html#modules_module_createrequire_filename\r\n\r\nThe code example is:\r\n\r\n```js\r\nconst { createRequire } = require('module');\r\nconst requireUtil = createRequire(require.resolve('../src/utils/'));\r\n\r\n// Require `../src/utils/some-tool`\r\nrequireUtil('./some-tool');\r\n```\r\n\r\nI believe this would be a better example (`import` vs. `require`; `import.meta.url` vs. `require.resolve()`):\r\n\r\n```js\r\nimport {createRequire} from 'module';\r\nconst require = createRequire(import.meta.url);\r\n\r\nconst siblingModule = require('./sibling-module.cjs');\r\n```\r\n\r\nAdditionally, one could demonstrate `url.pathToFileURL()` and import a module via an absolute path. I suspect that it may be better not to allow absolute paths as arguments for `createRequire()`.",
        "labels": "doc",
        "id": 44111
    },
    {
        "title": "Fix documentation for `childProcess.kill(signal)`: `signal` can be a number",
        "body": "With [`childProcess.kill(signal)`](https://nodejs.org/api/child_process.html#child_process_subprocess_kill_signal), `signal` is documented as being a `string`. \r\n\r\nHowever in the code, `signal` can be [either a string](https://github.com/nodejs/node/blob/908292cf1f551c614a733d858528ffb13fb3a524/lib/internal/child_process.js#L435) or [a number](https://github.com/nodejs/node/blob/908292cf1f551c614a733d858528ffb13fb3a524/lib/internal/util.js#L220).",
        "labels": "doc",
        "id": 44112
    },
    {
        "title": "API docs: type for TLS Certificate's `subjectaltname` field is wrong.",
        "body": "The API doc says it's an array ([link](https://nodejs.org/api/tls.html#tls_certificate_object)):\r\n> - `subjectaltname` &lt;Array&gt; (Optional) An array of names for the subject, an alternative to the subject names.\r\n\r\nBut there's an example below those docs that shows a string:\r\n\r\n```\r\nsubjectaltname: 'DNS:*.nodejs.org, DNS:nodejs.org',\r\n```\r\n\r\nWhen I use `TlsSocket.getPeerCertificate()` myself, I get a string.",
        "labels": "doc",
        "id": 44113
    },
    {
        "title": "Probably, some mistakes in the Node.js API documentation (\"Modules\" file)",
        "body": "Issues with the Node.js API documentation should be posted here.\r\n\r\nHi,\r\nI translated Modules file recently (v6).\r\nhttps://nodejs.org/docs/latest-v6.x/api/modules.html\r\nIt seems to me that something is a little bit strange with 2 sentences:\r\n\r\n1.\r\n\"Putting together all of the above, here is the high-level algorithm in pseudocode of what require.resolve() does:\"\r\n\r\nWhat was discussed above in the previous sections is mostly how require() works.\r\nAnd in the pseudocode below the above sentence they write \"require(X)...\".\r\n\r\nSo, I guess the correct version should be \r\n\"Putting together all of the above, here is the high-level algorithm in pseudocode of what require() does:\"\r\n\r\n\r\n2.\r\n\"It is convenient to organize programs and libraries into self-contained directories, and then provide a single entry point to that library.\"\r\n\r\nAs far as I understand, libraries and directories are different things.\r\nSo, if they organize programs and libraries into directories, then the entry point should probably be provided to directories.\r\n\r\nSo, I guess the correct version should be\r\n\"It is convenient to organize programs and libraries into self-contained directories, and then provide a single entry point to those directories.\"\r\n\r\n--------\r\nI'm not a professional programmer, so maybe I got something wrong.\r\nPlease, look into this.\r\n",
        "labels": "doc",
        "id": 44114
    },
    {
        "title": "Syntax Highlighting license ",
        "body": "This might not be an issue, but one of our scanning tools picked up on it so thought I'd post it for discussion anyway. \r\n\r\nSyntax Highlighting JS (https://github.com/nodejs/node/blob/master/doc/api_assets/sh_main.js) has a [GPLv3 license](http://shjs.sourceforge.net/doc/gplv3.html). It is only used in the docs, but I don't know if this could have implications if anyone was to redistribute the docs (perhaps unlikely?). \r\n\r\nShould the license potentially be listed/mentioned somewhere else in addition to the file itself?\r\n\r\nI notice that SHJS is also [over in nodejs/nodejs.org](https://github.com/nodejs/nodejs.org/blob/master/static/legacy/sh_main.js). Do we still need it in nodejs/node, could it be pulled in from nodejs.org? (refs: https://github.com/nodejs/nodejs.org/pull/2150#issuecomment-472128420). \r\n\r\nAdmittedly I do not know the history of this file/docs. /cc @nodejs/documentation \r\n  \r\n\r\n\r\n\r\n \r\n",
        "labels": "doc",
        "id": 44115
    },
    {
        "title": "Proposal: PR links in documentation history",
        "body": "Currently the docs have a one-line `Added in` section or a collapsible `History` section to communicate a per-feature changelog of sorts. My suggestion is to augment that data with the addition of PR links so a user can view the code history of that feature if they feel they need a deeper understanding of the interface than the docs alone can provide.\r\n\r\nThis could also be a good source of tasks for future Code & Learn events too, going back through the history and filling in the links for past changes. ðŸ¤” ",
        "labels": "doc",
        "id": 44116
    },
    {
        "title": "path.extname('.a.a')!=''",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.14.0\r\n* **Platform**: Linux pcd 5.0.7-arch1-1-ARCH #1 SMP PREEMPT Mon Apr 8 10:37:08 UTC 2019 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\nAccording to the documentation for `path.extname(path)`:\r\n\r\n> If there is no . in the last portion of the path, or if the first character of the basename of path (see path.basename()) is ., then an empty string is returned.\r\n\r\n`path.basename('.a.a')[0]=='.'` and `path.extname('.a.a')!=''` should not happen at the same time.\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44117
    },
    {
        "title": "doc: several properties undocumented on child process",
        "body": "Tracking back as far as Node 0.12 it seems that the documentation for [`ChildProcess`](https://nodejs.org/api/child_process.html#child_process_class_childprocess) is missing several properties.\r\n\r\n- `exitCode` - if the process exited will contain the exit code, else `null`. Useful in combination with `killed` â†’ `if (proc.exitCode !== null || proc.killed)` to see if the process is still running.\r\n- `signalCode` - not sure what that is good for.\r\n- `spawnfile` & `spawnargs` the initial properties of the spawning. In combination with exec will show what shell is used. Useful for debugging.\r\n\r\n",
        "labels": "doc",
        "id": 44118
    },
    {
        "title": "doc: remove invalid padding from crypto.publicDecrypt",
        "body": "#9609 and #9611 should also apply to publicDecrypt.\r\n\r\nOriginal issues:\r\n#9588 and #1093\r\n\r\n",
        "labels": "doc",
        "id": 44119
    },
    {
        "title": "meaning of the boolean return value of `send()` not documented",
        "body": "https://nodejs.org/api/child_process.html#child_process_subprocess_send_message_sendhandle_options_callback describes the meaning of the boolean return.\r\n\r\nIt should be described in https://nodejs.org/api/cluster.html#cluster_worker_send_message_sendhandle_callback and\r\nhttps://nodejs.org/api/process.html#process_process_send_message_sendhandle_options_callback but is not.\r\n\r\nreported in https://github.com/nodejs/node/issues/26937#issuecomment-478079356\r\n\r\n<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: all\r\n* **Platform**: n/a\r\n* **Subsystem**: process, cluster\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44120
    },
    {
        "title": "http_event_information missing argument response <http.IncomingMessage>",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.12.0 and v10.15.3\r\n* **Platform**: documentation\r\n* **Subsystem**: HTTP event information\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n`http` `event` `information` is missing argument `response <http.IncomingMessage>` in the documentation found at [nodejs documentation http_event_information](https://nodejs.org/dist/latest-v11.x/docs/api/http.html#http_event_information), but the example has an example of a `response` argument",
        "labels": "doc",
        "id": 44121
    },
    {
        "title": "Add LTS changelog",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI, as developer, want to upgrade Node.js in my project or library from older LTS version to newer one.\r\n\r\n**Describe the solution you'd like**\r\nI would like to read single documentation page, listing all revelant changes made between old LTS and new LTS.\r\n\r\nEg. if I want to upgrade from Node 8 to Node 10 I have to read whole changelog for V9 and V10, including hundreds of `docs` and `test` fixes.\r\n\r\nTherefore, I would like to see page \"upgrading from Node 8 to Node 10\", with list of \"notable\" changes made in Node 9 and pre-LTS Node 10 (and filtered commit list).",
        "labels": "doc",
        "id": 44122
    },
    {
        "title": "error docs for SystemErrors seems to partially predate the existence of the class",
        "body": "I believe that when the `SystemError` class was introduced, the docs were not completely reworked to refer to it.\r\n\r\n- https://nodejs.org/api/errors.html#errors_class_assertionerror Check the line *above* this link:\r\n\r\n> System-level errors are generated as augmented Error instances\r\n\r\nClass inheritance is not usually called \"augmentation\", I think this line predates `SystemError`\r\n\r\n- https://nodejs.org/api/errors.html#errors_system_errors\r\n\r\nThe nesting is weird, `SystemError`, https://nodejs.org/api/errors.html#errors_class_systemerror, should be at the same level as the other error classes above, but instead its nested inside this section, and the section says:\r\n\r\n> In Node.js, system errors are Error objects with extra properties.\r\n\r\nThis is strange, all the other error classes are documented with\r\n\r\n> Class: RangeError, A subclass of Error ...\r\n\r\nNot \"RangeError, an Error object with extra properties\"!\r\n\r\nI think the special section https://nodejs.org/api/errors.html#errors_system_errors needs to be removed, any useful information in it moved into the SystemError class docs, https://nodejs.org/api/errors.html#errors_class_systemerror, and the SystemError class docs should be outdented to the same level as all the other classes, and the doc text be brought into line with the other docs.\r\n\r\nA number or sections, such as https://nodejs.org/api/errors.html#errors_errors, discuss \"System errors\", but its not clear whether all \"System errors\" are of class `SystemError`.\r\n\r\nhttps://nodejs.org/api/errors.html#errors_common_system_errors and elsewhere imply that `SystemError` is usually a result of a failed syscall, but this isn't true, at least not anymore, there is a long list of `error.code` values for `class SystemError` that do not originate from a syscall: https://nodejs.org/api/errors.html#errors_node_js_error_codes\r\n\r\nAs I understand it, the situation is that there are a few classes of errors:\r\n\r\n- Javascript, defined by V8/the JS standard\r\n- System, defined by Node.js, with a class of `SystemError`.\r\n\r\n`SystemError` has a `.code` (and other properties), and can be further broken down into two categories:\r\n\r\n1. Those originating from a syscall, where the `.code` is going to mirror the macro name from `man errno`.\r\n2. Those originating from node.js internally, where the `.code` we made up (and document in this page).\r\n\r\nIn short, I think the situation is as I summarize above, but the actual docs still have traces in their structure of the earlier state, and should be edited for clarity and structure.\r\n\r\nI don't have the time ATM to do this, but this would make a good first contribution for someone wanting to get involved in improving our docs.",
        "labels": "doc",
        "id": 44123
    },
    {
        "title": "VM: options.columnOffset has no effect on column number in stack trace output",
        "body": "* **Version**: v10.3.0 and v10.15.2\r\n* **Platform**: Linux ip-172-30-3-105 4.14.42-52.37.amzn1.x86_64\r\n* **Subsystem**: vm\r\n\r\nIn vm.runInNewContext (and maybe other versions of \"run\", too), the `options.columnOffset` has no effect. I've tried a couple of intentionally-caused errors with various `columnOffset` values (ranging from -5 to 5), but the character position reported in the stack trace (via `e.stack`) is always the same. Note that `lineOffset` works as expected.",
        "labels": "doc",
        "id": 44124
    },
    {
        "title": "Should we add a glossary like chrome ?",
        "body": "Like https://chromium.googlesource.com/chromiumos/docs/+/master/glossary.md.\r\n\r\ne.g I have no clue `WPT` mean for now.\r\nI know `RSLGTM` very recently.\r\nI know `godbolt` from @refack (very amazing tool for cpp).",
        "labels": "doc",
        "id": 44125
    },
    {
        "title": "mkdtemp doc issue?",
        "body": "During test-writing / manual fuzzing, I noticed that the doc for mkdtemp added in https://github.com/nodejs/node/pull/6800 states that \"Generates six random characters to be appended behind a required prefix to create a unique temporary directory\". This is true on Linux and Windows, but misses an edge case on BSDs (including Apple). As seen below, it actually \"replaces trailing X's with random characters and then appends six additional random characters to the prefix to create a unique directory name\".\r\n```\r\n// on macOS\r\n> fs.mkdtempSync(path.join(os.tmpdir(), 'foox')) // does as documented\r\n'/tmp/fooxz5Ve7r'\r\n\r\n> fs.mkdtempSync(path.join(os.tmpdir(), 'fooX')) // also replaces the X from the prefix\r\n'/tmp/foo1PqEasA'\r\n         ^-- not an 'X'\r\n```\r\n\r\nI think this is just a doc issue, but opening this as an issue to hear what others think.",
        "labels": "doc",
        "id": 44126
    },
    {
        "title": "Add a guide on \"How do I become a Node.js committer\".",
        "body": "This is a meta issue, but it's something that it is not clear to a newcomer to the project. While the answer is simple \"contribute!\", they might look for some more info.\r\n\r\nThis came from a twitter exchange with @mikeal https://twitter.com/mikeal/status/1099729128813518848, who wrote https://medium.com/the-node-js-collection/healthy-open-source-967fa8be7951 (a long time ago!).",
        "labels": "doc",
        "id": 44127
    },
    {
        "title": "Avoid small initial text for API docs on pages with wide tables",
        "body": "The [Crypto docs](https://nodejs.org/docs/v11.10.0/api/crypto.html) have a wide table down the page somewhere. On smaller viewports, this causes the text to be small, and the initial rendering of the page to be zoomed out to include the excess overflow to the right.\r\n\r\n| iOS Chrome |  iOS Chrome\r\n|--|--\r\n| ![crios-top](https://user-images.githubusercontent.com/156867/52866723-2f6ac700-3137-11e9-9b8c-016ee59d249a.PNG) | ![crios-table](https://user-images.githubusercontent.com/156867/52866722-2f6ac700-3137-11e9-8090-1e1084ac0929.PNG)\r\n\r\n| iOS Firefox Focus\r\n|--\r\n|<img alt=\"fmob-top\" height=\"380\" src=\"https://user-images.githubusercontent.com/156867/52866724-2f6ac700-3137-11e9-8184-35df200e3433.PNG\">\r\n\r\nBelow is a comparison to [FS docs](https://nodejs.org/docs/v11.10.0/api/fs.html), which renders correctly (notice the larger text and edges of the content aligned with the viewport)\r\n\r\n| Chrome DevTools (FS docs)  | Chrome DevTools (Crypto docs)\r\n|--|--\r\n| ![emu-okay](https://user-images.githubusercontent.com/156867/52866548-d26f1100-3136-11e9-9405-5dcad1e7247f.png) | ![emu-problem](https://user-images.githubusercontent.com/156867/52866549-d26f1100-3136-11e9-8479-f20fecfae694.png)\r\n\r\n",
        "labels": "doc",
        "id": 44128
    },
    {
        "title": "docs: document how to land ICU floating patches",
        "body": "per: https://github.com/nodejs/node/pull/26090#pullrequestreview-203857169\r\n\r\ndocument how to land floating patches to ICU.\r\n\r\n// @refack ",
        "labels": "doc",
        "id": 44129
    },
    {
        "title": "doc: Broken (404ing) links in Docs",
        "body": "Thanks to @JustinBeckwith's [linkinator](https://github.com/JustinBeckwith/linkinator) tool, I was able to pretty easily check our docs to see if any of the links were 404ing. Turns out we currently have 2 404s _somewhere_ in the docs. Here are the links that are 404ing:\r\n\r\n- http://man7.org/linux/man-pages/man3/uname.3.html\r\n- http://man7.org/linux/man-pages/man1/curl.1.html\r\n\r\nAt a bare minimum, you could view source on `docs/api/all.html` and search for these links to identify where they are in the docs.\r\n\r\nThe tool currently falsely reports all DevTools protocol links as 404ing when they are not actually 404ing. I'll open up an issue on the linkinator repo for that.",
        "labels": "doc",
        "id": 44130
    },
    {
        "title": "doc(http): res.write(data) followed by res.end() is not actually equivalent to res.end(data)",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.9.0\r\n* **Platform**: `Linux (My hostname) 4.15.0-45-generic #48-Ubuntu SMP Tue Jan 29 16:28:13 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux` (Xubuntu 18.04)\r\n* **Subsystem**: Documentation of HTTP module\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nIn the document for method `end([data][, encoding][, callback])` of class `http.ServerResponse`, there's a following text:\r\n\r\n>If data is specified, it is equivalent to calling `response.write(data, encoding)` followed by `response.end(callback)`.\r\n\r\nHowever, this is not actually true when there's only single `response.write(data)`, demonstrable with the following code:\r\n\r\n```js\r\nconst http = require('http');\r\n\r\nconst HELLO = 'Hello!\\n';\r\n\r\nconst server1 = http.createServer(function (req, res) {\r\n  res.write(HELLO);\r\n  res.end();\r\n});\r\n\r\nconst server2 = http.createServer(function (req, res) {\r\n  res.end(HELLO);\r\n});\r\n\r\nserver1.listen(9001);\r\nserver2.listen(9002);\r\n```\r\n\r\nBy using `curl -v`, this happens:\r\n```\r\n$ curl -v http://localhost:9001/ # response.write(data) follow by response.end()\r\n*   Trying 127.0.0.1...\r\n* TCP_NODELAY set\r\n* Connected to localhost (127.0.0.1) port 9001 (#0)\r\n> GET / HTTP/1.1\r\n> Host: localhost:9001\r\n> User-Agent: curl/7.58.0\r\n> Accept: */*\r\n> \r\n< HTTP/1.1 200 OK\r\n< Date: Fri, 08 Feb 2019 10:26:25 GMT\r\n< Connection: keep-alive\r\n< Transfer-Encoding: chunked\r\n< \r\nHello!\r\n* Connection #0 to host localhost left intact\r\n\r\n$ curl -v http://localhost:9002/ # response.end(data)\r\n*   Trying 127.0.0.1...\r\n* TCP_NODELAY set\r\n* Connected to localhost (127.0.0.1) port 9002 (#0)\r\n> GET / HTTP/1.1\r\n> Host: localhost:9002\r\n> User-Agent: curl/7.58.0\r\n> Accept: */*\r\n> \r\n< HTTP/1.1 200 OK\r\n< Date: Fri, 08 Feb 2019 10:26:31 GMT\r\n< Connection: keep-alive\r\n< Content-Length: 7\r\n< \r\nHello!\r\n* Connection #0 to host localhost left intact\r\n$ \r\n```\r\n\r\nSo, it appears that `response.write(data)` follow by `response.end()` cause Node.js to use chunked encoding, while `response.end(data)` cause Node.js to not using chunked encoding and include `Content-Length` header. This small distinction is important with some client. For example, [Windows 10's MDM enrollment system will not accept chunked response](https://docs.microsoft.com/en-us/windows/client-management/mdm/on-premise-authentication-device-enrollment).",
        "labels": "doc",
        "id": 44131
    },
    {
        "title": "http2 API documentation issues",
        "body": "## Compatibility API example\r\n\r\nHere's the example code from the API docs in the [compatibility API section](https://nodejs.org/api/http2.html#http2_compatibility_api):\r\n\r\n```js\r\nconst http2 = require('http2');\r\nconst server = http2.createServer((req, res) => {\r\n  res.setHeader('Content-Type', 'text/html');\r\n  res.setHeader('X-Foo', 'bar');\r\n  res.writeHead(200, { 'Content-Type': 'text/plain' });\r\n  res.end('ok');\r\n});\r\n```\r\n\r\nThe `Content-Type` header is overwritten here in `writeHead()`, but unless the reader knows that `writeHead()` *merges* its headers with the headers set in `setHeader()`, the reader may think there's something special going on here.\r\n\r\nSuggestion: remove first call to `setHeader()`; ensure example is straightforward\r\n\r\n## No documentation of `HTTP2_HEADER_*` constants\r\n\r\nThere are many references to e.g., `http2.constants.HTTP2_HEADER_STATUS`.  These are not listed in the [constants section](https://nodejs.org/api/http2.html#http2_http2_constants).  Is `HTTP2_HEADER_CONTENT_TYPE` different than `'Content-Type'`?  Can these be used interchangeably?  If I use the compatibility API, should I use these constants?\r\n\r\nSuggestion: document the constants and when to use them.",
        "labels": "doc",
        "id": 44132
    },
    {
        "title": "Double keypress in readline / process.stdin",
        "body": "* **Version**: 11.8.0, 11.9.0\r\n* **Platform**: Windows 10 (x64)\r\n* **Subsystem**: console\r\n\r\nThis code produces repeated output:\r\n```javascript\r\nconst readline = require('readline')\r\nconst process = require('process')\r\n\r\nlet rl = readline.createInterface({terminal: true, input: process.stdin, output: process.stdout})\r\nrl.resume()\r\nrl.input.on('data', (chunk) => {\r\n  console.log(`Received ${chunk.length} bytes of data - content was: ${chunk}`)\r\n})\r\n```\r\n\r\nRun this with Node 11.8.0 or above and press the down arrow; two messages are produced:\r\n```\r\nReceived 3 bytes of data - content was:\r\n\r\nReceived 3 bytes of data - content was:\r\n```\r\n\r\nRevert to Node 11.7.0, a single message is produced.\r\n```\r\nReceived 3 bytes of data - content was:\r\n```\r\n\r\nThis breaks, among many things, scrolling through menus in Inquirer.js: https://github.com/SBoudrias/Inquirer.js/issues/778\r\n\r\nThis appears to be Windows specific (as far as I could tell, I was only able to test on a Linux VM via Docker right now).\r\n\r\nGit bisect tells me this issue first appeared with c0859d71765b2f728256b8ac1cfc948311321b37, which upgraded `libuv` to `1.25.0`.\r\n\r\nI'll keep digging into libuv (I already have an idea of where the problem was introduced in 1.25.0) but since this impacts Node on Windows somehwat significantly I figured it would be useful to have a way to track this!",
        "labels": "doc",
        "id": 44133
    },
    {
        "title": "doc: http.ClientRequest path property description needs clarification",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nThe documentation for `request.path` mentions that the property is read-only, which is misleading.\r\n\r\nFirst, it is technically not set as a real read-only property, so it is mutable. Secondly, `request.path` is read from at a later point in time if `headers` was not passed to the `ClientRequest` constructor.\r\n\r\nHere is a small example that shows this:\r\n\r\n```js\r\nconst http = require('http');\r\n\r\nhttp.createServer(function(req, res) {\r\n  this.close();\r\n  console.log('req.url =', req.url);\r\n  res.end();\r\n}).listen(0, function() {\r\n  const req = http.request(\r\n    { port: this.address().port, method: 'GET' },\r\n    (res) => res.resume()\r\n  );\r\n  console.log('req.path =', req.path);\r\n  req.path = '/foo/bar/baz';\r\n  req.end();\r\n});\r\n\r\n// prints:\r\n// req.path = /\r\n// req.url = /foo/bar/baz\r\n```\r\n\r\nI would suggest removing the 'Read-only' portion from the description *or* making the property truly read-only using the appropriate property descriptor.",
        "labels": "doc",
        "id": 44134
    },
    {
        "title": "doc/api/n-api.md: Update version matrix",
        "body": "We need to update the version matrix given there to reflect the current state of N-API availability.",
        "labels": "doc",
        "id": 44135
    },
    {
        "title": "Version 11.8.0 release notes?",
        "body": "Where are the release notes (https://github.com/nodejs/node/releases) for 11.8.0?",
        "labels": "doc",
        "id": 44136
    },
    {
        "title": "doc: ERR_SYNTHETIC issues on v11.x",
        "body": "On v11.x, the `ERR_SYNTHETIC` header is the wrong size, also causing the list at the top of the errors doc page to be indented incorrectly. This does not impact master.\r\n",
        "labels": "doc",
        "id": 44137
    },
    {
        "title": "os.userInfo throws if no username in docker container",
        "body": "Original issue opened here: https://github.com/sindresorhus/username/issues/21\r\n\r\nIt turns out that running a script with `docker run` with `--user` flag set, then user actually has no `$HOME` or `username`. This in turn causes following error: `uv_os_get_passwd returned ENOENT (no such file or directory)` if `os.userInfo()` is accessed.\r\n\r\nSome people have resorted to try catch blocks: \r\n\r\nhttps://github.com/moleculerjs/moleculer/pull/396/files#diff-38423b3db1f1c2a43666c7ad898ba126R45\r\n\r\nBut is is not documented that `os.userInfo()` ever throws - https://nodejs.org/dist/latest-v10.x/docs/api/os.html#os_os_userinfo_options\r\n<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8, v10\r\n* **Platform**: Linux, Docker container\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44138
    },
    {
        "title": "Unable to disable REPL history on Windows",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10.15.0\r\n* **Platform**: Windows 10 x64 (1809)\r\n* **Subsystem**: REPL (`lib/internal/repl.js`)\r\n\r\n<!-- Please provide more details below this comment. -->\r\nPer the [REPL documentation](https://nodejs.org/docs/latest-v10.x/api/repl.html#repl_environment_variable_options) the history file path can be changed by setting the `NODE_REPL_HISTORY` environment variable to a valid path or disabled by setting it to the empty string.\r\n\r\nOn Windows platforms an empty environment variable is difficult to set. From my own testing:\r\n- A variable cannot be saved with a blank value via the System Properties UI (`sysdm.cpl`).\r\n- Setting the value to `''` or `\"\"` will set it to a literal two single quotes or double quotes when using the System Properties UI.\r\n- Setting the value to `''` will set it to a literal two single quotes when using the `setx` Command Prompt utility.\r\n- The [.NET Environment.SetEnvironmentVariable](https://docs.microsoft.com/en-us/dotnet/api/system.environment.setenvironmentvariable?view=netframework-4.7.2) method notes that an empty variable value will result in the variable being deleted if it exists or a no-op if it doesn't.\r\n\r\nI've found that a blank variable can be set using `setx` with two double quotes: `setx NODE_REPL_HISTORY \"\"`. I haven't tried calling the underlying [Win32 SetEnvironmentVariable](https://docs.microsoft.com/en-us/windows/desktop/api/winbase/nf-winbase-setenvironmentvariable) function directly but given the behaviour of `setx` it presumably would work.\r\n\r\nIt seems clear to me that setting blank environment variables is discouraged and the support for doing so is patchy at best. This being the case, it would be desirable to support an alternate value that's legal on Windows to indicate that the REPL history should not be saved. One possible option would be recognising the value `''` (i.e. two single quotes) which in my view is the most intuitive setting, but there's of course other options.\r\n\r\nThoughts?",
        "labels": "doc",
        "id": 44139
    },
    {
        "title": "docs: Dirent definition doesn't tell me anything useful about Dirent",
        "body": "Link: https://nodejs.org/api/fs.html#fs_class_fs_dirent\r\n\r\nAfter clicking the link to this definition from the `fs` section on `readDir`, it seems circular and not at all helpful. After reading the definition, I still have no idea what a `Dirent` is.",
        "labels": "doc",
        "id": 44140
    },
    {
        "title": "Example for crypto publicKey signing in Browser and privateKey decryption in node",
        "body": "I have been hard pressed to discover an example of how to use a publicKey sent to a Browser to the be able to decrypt in node what was encrypted in the browser with the nodejs crypto generate KeyPair's PublicKey.\r\n\r\nIt has been difficult being 'subtle' in the nuances of which type of encryption to use and the impossibility of seeing what it is as it's encrypted and doesn't seem to carry probable information about how it was done etc.\r\n",
        "labels": "doc",
        "id": 44141
    },
    {
        "title": "doc: backticks being rendered literally in docs",
        "body": "* **Version**: v10.x, master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nAt least in the `crypto` docs, there are backticks being rendered literally instead of highlighting/styling the enclosed text. One example is the header [here](https://nodejs.org/docs/latest/api/crypto.html#crypto_crypto_module_methods_and_properties). I should note that at least in this particular example, the v8.x docs seem to render it properly.\r\n\r\nThere may be other instances of this issue throughout the documentation, I have not checked.\r\n",
        "labels": "doc",
        "id": 44142
    },
    {
        "title": "Create node/doc/guides/writing-docs.md",
        "body": "Currently we don't seem to have a guide for writing docs â€“ or at least not one that I can find.\r\n\r\nIn the [`node/doc/guides`](https://github.com/nodejs/node/tree/master/doc/guides) directory, there seems to be examples for [writing and running benchmarks](https://github.com/nodejs/node/blob/master/doc/guides/writing-and-running-benchmarks.md) and [writing tests](https://github.com/nodejs/node/blob/master/doc/guides/writing-tests.md), but not one for writing docs.\r\n\r\nI'd be happy to help take this on if someone could provide a list of bullets that would need to be addressed as steps to write docs within the file.",
        "labels": "doc",
        "id": 44143
    },
    {
        "title": "Vary: Accept-Encoding missing in zlib examples",
        "body": "Ref: https://github.com/nodejs/node/blob/master/doc/api/zlib.md#compressing-http-requests-and-responses\r\n\r\nIt appears to me that the examples lack setting the `Vary: Accept-Encoding` Response header.\r\n",
        "labels": "doc",
        "id": 44144
    },
    {
        "title": "Document the behavior of random port behavior depending on OS",
        "body": "The node documentation on running `.listen()` without specifying a port reads like\r\n\r\n> the operating system will assign an arbitrary unused port\r\n\r\n_([source](https://github.com/nodejs/node/blame/master/doc/api/net.md#L330))_\r\n\r\nA [stackoverflow](https://stackoverflow.com/a/10266225) question of the same type hints at significant differences between the OS's, but it is likely outdated. It seems like it would be a good idea to clarify if the behavior has been normalized by Node.js or link to documentation on how the different os-api's implement this.",
        "labels": "doc",
        "id": 44145
    },
    {
        "title": "BUILDING.md: how-to-install has become obscured",
        "body": "The procedure to build and **then install** node has become obscured through changes\r\nto BUILDING.md over the last two years.  Much additional information has been added for\r\nrunning tests, coverage, build docs, etc. and now important steps such as\r\n```\r\n$ [sudo] make install\r\n```\r\nare 4 pages down from the starting `$ ./configure` step, and is tacked on the end of \r\n\"Building the documentation\"!  How is someone unfamiliar with the \"usual steps\" \r\nsupposed to find \"how to install node\" ?\r\n\r\nSimplest fix would be to emulate all the new section headings and add an \"Installing\r\nNode\" section header before the four lines beginning \"To test if Node.js was built \r\ncorrectly:\"  I somehow feel the new section should be before subjects docs, coverage,\r\nand maybe before even tests, given how much those have been elaborated on.\r\n\r\n[doc]",
        "labels": "doc",
        "id": 44146
    },
    {
        "title": "fs.watch() file as symbolic link",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8.12.0 and v10.13.0\r\n* **Platform**: 4.19.13-300.fc29.x86_64\r\n* **Subsystem**: \r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nCreate a real file, `testfile` with any content.\r\nCreate a symbolic link to that file \r\n```bash\r\nln -s testfile testlink\r\n```\r\nCreate a node .js file, `test.js`\r\n``` javascript\r\nconst fs = require(\"fs\");\r\nconst file = \"testlink\";\r\nfs.watch(file, (eventType, filename) => {\r\n    console.log(eventType, filename);\r\n});\r\n```\r\nNow when executing `node test.js` changes on the content of `testfile` are correctly logged. \r\nEg, editing `testfile` will result in the correct `change testlink` log.\r\n\r\nBut now if the symbolic link is removed, nothing is triggered. Actually, the file that was originally the source file is still watched, regardless if the symlink exists or not, or eventually points to another file. This seems to be the case with and without the `--preserve-symlinks` option.\r\n\r\nI would expect that the symlink is treated as a real file, especially with `--preserve-symlinks` hence I feel this behavior is unexpected, therefore I report it as a bug.\r\n\r\nIf this behavior is considered to be normal, it could be mentioned in the documentation for `fs.watch()`",
        "labels": "doc",
        "id": 44147
    },
    {
        "title": "doc: `os.networkInterfaces()` example outdated",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nThe [`os.networkInterfaces()`](https://nodejs.org/docs/latest/api/os.html#os_os_networkinterfaces) example is outdated as the IPv6 interfaces do not include the `scopeid` property.",
        "labels": "doc",
        "id": 44148
    },
    {
        "title": "NAPI: some napi_*_threadsafe_function naming/documentation issues",
        "body": "#### 1. `initial_thread_count` parameter of `napi_create_threadsafe_function`\r\nI think the name and documentation of parameter `initial_thread_count` in [napi_create_threadsafe_function](https://nodejs.org/api/n-api.html#n_api_napi_create_threadsafe_function) is very confusing.\r\n\r\nWithout reading node impl, for me it was not possible understand what it does. In context of the methods `napi_acquire/release_threadsafe` I think it should be better called sth. like `initial_acquired`, so it is more clear, that that's the corresponding amount of `napi_acquire_threadsafe_function` calls.\r\n\r\nIf we don't/can't change the name, at least documentation should be adapted as it's misleading:\r\n\r\n```\r\n[in] initial_thread_count: The initial number of threads, including the main thread, which will be making use of this function.\r\n```\r\n\r\nmaybe (simply) better something like this:\r\n```\r\n[in] initial_acquired: The initial number of acquisitions.\r\n```\r\n\r\n#### 2. documention threadsafe chapter\r\nFor me the [header documentation](https://nodejs.org/api/n-api.html#n_api_asynchronous_thread_safe_function_calls) of the threadsafe chapter is too long, while there is less documentation in the functions.\r\n\r\nI'd like to read something like this to understand how it works from top:\r\n\r\n```\r\n...\r\nA threadsafe_function has two different kinds of reference counting that\r\nprevents it from being destroyed:\r\n  1. environment reference via `napi_ref/unref_threadsafe_function` (to\r\n     be only called from node thread)\r\n  2. acquisition via `napi_acquire/release_threadsafe_function` (to be\r\n     called from any thread)\r\n\r\nIt is destroyed, either if:\r\n  1. ref-count via `napi_ref/unref_threadsafe_function` is zero and all\r\n     acquisitions are released\r\n  2. or it's released via `napi_tsfn_abort` mode`\r\n```\r\n\r\nMaybe some more specific documentation in the functions and the parameters plus examples.\r\n\r\nWent through it and found this, which is both wrong I think? not a napi_value and not referenced.\r\n> napi_create_threadsafe_function() creates a persistent reference to a napi_value\r\n\r\nMaybe it should be updated.\r\n\r\nWhat do you think?",
        "labels": "doc",
        "id": 44149
    },
    {
        "title": "Request for warning documentation",
        "body": "I would like to request documentation for NodeJS warnings. I've searched for a list of them just like the one available for Errors but to no avail. If the docs do exist please point me into the right direction.",
        "labels": "doc",
        "id": 44150
    },
    {
        "title": "Need change in the read me file",
        "body": "Could we change the sentence **Node.js is a JavaScript runtime built on Chrome's V8 JavaScript engine.** to **Node.js is a JavaScript run-time that is built on Chrome's V8 JavaScript engine.**?",
        "labels": "doc",
        "id": 44151
    },
    {
        "title": "are the YAML \"added\" annotations ambiguous? and are they rewritten on backport?",
        "body": "* **Version**: all node.js docs\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\ncf. https://github.com/nodejs/node/pull/24847\r\n\r\nThe added annotations are very useful, and at the same time, I think they are slightly ambiguous, or at least their interpretation is subtle! And undocumented: https://nodejs.org/api/documentation.html at least doesn't describe them, but perhaps they are described elsewhere?\r\n\r\nExamples:\r\n\r\n> Added: v7.5.0\r\n\r\nIs the API present in 8.0.0? I think it would have to be, because if it was added in `>8.0.0` and backported then this would look like:\r\n\r\n> Added:\r\n>     - v8.3.0\r\n>     - v7.5.0\r\n\r\nCorrect? But a bit subtle!\r\n\r\nIts not clear to me whether @nodejs/releasers have a process to update the YAML tags when backporting/cherry-picking. Because https://github.com/nodejs/node/pull/24847 I suspect not. It would be kind of onerous, since both the backported branch _and_  the master needs to be updated to reflect the release of the API on the old branch. I don't know how much energy should be spent in keeping the annotations up to date on the release branches, but it would be great if at least the master & current documentation was complete.... meaning it would need updating after every release. :-(\r\n\r\nSummary: I think that ideally:\r\n\r\n1. the \"about this documentation\" docs should describe the meaning of the YAML version annotations.\r\n2. we should have tooling/process to keep those annotations up to date.",
        "labels": "doc",
        "id": 44152
    },
    {
        "title": "Worker should indicate it inherits from EventEmitter",
        "body": "* **Version**: 10.*.*\r\n* **Platform**: Documentation\r\n* **Subsystem**: worker_threads\r\n\r\nThe documentation for Worker class should indicate that it inherits from EventEmitter.  It's apparent that it does so reading the documentation, but it does not specifically say so. Other classes like ChildProcess do indicate this.",
        "labels": "doc",
        "id": 44153
    },
    {
        "title": "doc: backticks rendering as-is in crypto docs",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nCurrently [this header](https://nodejs.org/docs/latest/api/crypto.html#crypto_crypto_module_methods_and_properties) is being rendered like:\r\n\r\n<blockquote>\r\n`crypto` module methods and properties\r\n</blockquote>\r\n\r\ninstead of:\r\n\r\n> `crypto` module methods and properties",
        "labels": "doc",
        "id": 44154
    },
    {
        "title": "Undocumented NODE_TLS_REJECT_UNAUTHORIZED environment variable",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**:\r\nv8 LTS, v10 LTS, v11 Current\r\n* **Platform**:\r\nAll\r\n* **Subsystem**:\r\nDocumentation\r\n\r\nMissing **NODE_TLS_REJECT_UNAUTHORIZED** environment variable description on https://github.com/nodejs/node/blob/master/doc/api/cli.md\r\n",
        "labels": "doc",
        "id": 44155
    },
    {
        "title": "Passing options object to http.createServer stops server responding",
        "body": "* **Version**: node 8.12.0\r\n* **Platform**: macOS Sierra 10.12.6 (16G1510)\r\n* **uname -a**: Darwin [USERNAME] 16.7.0 Darwin Kernel Version 16.7.0: [DATETIME]; root:xnu-3789.73.14~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: http\r\n\r\n**Example:**\r\n```js\r\n\"use strict\";\r\nconst http = require('http');\r\nconst options = {};\r\n\r\nconst server = http.createServer(options, (req, res) => {\r\n    console.log('got here', req, res);\r\n});\r\nserver.listen(4000);\r\n```\r\n```bash\r\n# telnet localhost 4000\r\nGET /\r\n\r\n```\r\nExpected: Console.log of \"got here\"\r\nActual: No output.\r\n\r\nIt also doesn't work is options is set to:\r\n```\r\nconst options = {\r\n  IncomingMessage: http.IncomingMessage,\r\n  ServerResponse: http.ServerResponse\r\n}\r\n```   \r\n\r\n**Is** working as expected in v10.13.0\r\n\r\nUsing `node inspect` the difference in execution between v8 and v10 seems to be this line:\r\n_http_common.js:117\r\n`return parser.onIncoming(parser.incoming, shouldKeepAlive);`\r\n\r\nWhich should be returning a IncomingMessage object, but instead returns nothing. But that's as far as I could get with this.\r\n\r\nCalling without the options object - i.e.:\r\n```node\r\nconst server = http.createServer((req, res) => {})\r\n```\r\nWorks as expected",
        "labels": "doc",
        "id": 44156
    },
    {
        "title": "Doc: Agent ctor options are not fully documented, such as `lookup`",
        "body": "ref:\r\n\r\n- https://github.com/nodejs/node/pull/12839\r\n\r\nissue:\r\n\r\n- Agent ctor does accept options that will be used by [`socket.connect`](https://nodejs.org/api/net.html#net_socket_connect_options_connectlistener).\r\n- But I can't find any reference of this at [`new Agent([options])`](https://nodejs.org/api/http.html#http_new_agent_options).\r\n- To be fair, [`agent.createConnection(options[, callback])`](https://nodejs.org/api/http.html#http_agent_createconnection_options_callback) does mention this but few users realize this allows them to make custom dns lookup via passing a custom Agent instance.",
        "labels": "doc",
        "id": 44157
    },
    {
        "title": "docs: When using the \"Edit on GitHub\" button references to the guides are not obvious",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: current\r\n* **Platform**: web\r\n* **Subsystem**: doc\r\n\r\n<!-- Please provide more details below this comment. -->\r\n> Perhaps the only thing I could note (if it's of any use in improving the docs' \"Edit on GitHub\" process) is that I don't believe I was alerted, when submitting the PR, to the fact that a style guide existed for the docs, against which I could check any amendments I was suggesting.\r\n\r\nWhen clicking the ![image](https://user-images.githubusercontent.com/96947/47798074-021c1980-dcfe-11e8-8698-3a2d93098172.png) button, the user is directed to the edit view in GitHub. There is no reference to the [Docs Style Guide](https://github.com/nodejs/node/blob/master/doc/STYLE_GUIDE.md), and when submitting the PR the referance to the [Contributing Guide](https://github.com/nodejs/node/blob/master/CONTRIBUTING.md) is easy to miss.\r\n\r\nIdeas for improvement will be most appreciated.\r\n\r\nRefs: https://github.com/nodejs/node/pull/23970#issuecomment-434528701\r\nRefs: https://github.com/nodejs/node/pull/21703\r\n\r\n/CC @nodejs/documentation @nodejs/website ",
        "labels": "doc",
        "id": 44158
    },
    {
        "title": "docs: Version switcher is broken / misleading",
        "body": "Currently if you try to switch to other semver major versions of the same docs on the docs site, you get extremely inconsistent results. Questions I had as I was going throught\r\n\r\nAs an example, here are the HTTP/2 docs:\r\n\r\n**v8.x**\r\n![image](https://user-images.githubusercontent.com/502396/47739263-6631d580-dc4b-11e8-98e8-f82ef79306d4.png)\r\n\r\n**v9.x** (where is v8.x?)\r\n![image](https://user-images.githubusercontent.com/502396/47739287-72b62e00-dc4b-11e8-8ffd-51799c717b8c.png)\r\n\r\n**v10.x** (where is v8.x, and why wasn't this doc listed on the **v8.x** or **v9.x** docs pages?)\r\n![image](https://user-images.githubusercontent.com/502396/47739466-cfb1e400-dc4b-11e8-9f2e-bcc088a3292b.png)\r\n\r\n**v11.x** (why wasn't this listed on any of the other pages?)\r\n![image](https://user-images.githubusercontent.com/502396/47739411-b3ae4280-dc4b-11e8-8c52-19d6f754e4ba.png)\r\n\r\nI experienced this in a few other docs pages as well.",
        "labels": "doc",
        "id": 44159
    },
    {
        "title": "doc: is the stability guarantee of err.code documented anywhere?",
        "body": "Surprisingly I cannot find in any significant places in https://github.com/nodejs/node/blob/master/doc/api/errors.md that `err.code` provides a stronger stability guarantee and should be preferred over parsing `err.mesage`.  Am I missing something?\r\n\r\nThis is something that a lot of Node.js collaborators know, I am sure, but if we don't put it in a significant place in the docs (e.g. with examples), the users may not be able to be sure about that.\r\n\r\ncc @jasnell ",
        "labels": "doc",
        "id": 44160
    },
    {
        "title": "UDP/Datagram Sockets documentation",
        "body": "**Module**\r\nUDP/ Datagram Sockets documentation\r\n\r\n**Current Documentation**\r\n\r\nThe description for the `listening` event for `dgram.Socket` states that 'This occurs as soon as UDP sockets are created'. [Reference](https://nodejs.org/api/dgram.html#dgram_event_listening)\r\n\r\n**Expected Documentation**\r\n\r\nTo my understanding this is incorrect as the listening event is fired once the socket is bound to a Port and Address. This is also stated elsewhere in the documentation ([Refer](https://nodejs.org/api/dgram.html#dgram_socket_bind_port_address_callback)) 'Once binding is complete, a 'listening' event is emitted ...'",
        "labels": "doc",
        "id": 44161
    },
    {
        "title": "Is the example wrong ?",
        "body": "About the [cluster Event:'message'](https://github.com/nodejs/node/blob/master/doc/api/cluster.md#event-message),\r\nis this example wrong ? \r\nWhen I run the code in my machine, It shows `numReqs` didn't increase as below:\r\n\r\n![screen shot 2018-10-28 at 8 42 18 am](https://user-images.githubusercontent.com/23313266/47610656-7e5bf600-da8d-11e8-9ad3-b1b1b790b83f.png)\r\n\r\n<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.12.0\r\n* **Platform**: macOS High Sierra 10.13.3\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44162
    },
    {
        "title": "Wrong variable used in documentation",
        "body": "> Sorry if I'm raising this issue on the wrong place.\r\n\r\nIn the documentation, https://nodejs.org/en/docs/guides/dont-block-the-event-loop/ `took = process.hrtime(n);` should be replaced by `took = process.hrtime(before);`\r\n\r\n",
        "labels": "doc",
        "id": 44163
    },
    {
        "title": "Missing semver-major change in v11.0.0 changelog",
        "body": "> Modified close event behaviour landed in version 11.0.0 (it is ok:) but I haven't found it  in semver-major changes in its changelog... If I don't look a bad way it would be fine to add this information... Thanks\r\n\r\n_Originally posted by @mareksrom in https://github.com/nodejs/node/commit/8799f43fb0626d4453f7ff7d9d20d4075adf7784#commitcomment-31025720_\r\n\r\nOriginal PR: https://github.com/nodejs/node/pull/20611",
        "labels": "doc",
        "id": 44164
    },
    {
        "title": "Documentation for Http2ServerRequest properties",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThe [`http2.Http2ServerRequest`](https://nodejs.org/api/http2.html#http2_class_http2_http2serverrequest) has some useful properties that are undocumented. But IMHO, they should be part of the public API.\r\n\r\n**Describe the solution you'd like**\r\nThe following properties could become part of the `http2` module documentation:\r\n`method`, `authority`, `scheme`, `url`\r\n(See [`lib/internal/http2/compat.js`](https://github.com/nodejs/node/blob/e7f710c1d4729890806610e5450d7a0edfb4ac11/lib/internal/http2/compat.js#L346-L368))\r\n\r\n**Describe alternatives you've considered**\r\nThe alternative is to use the headers object:\r\n```js\r\n// alternative to: req.authority\r\nreq.headers[':authority']\r\n```\r\n\r\n**PR?**\r\nIf these properties should be documented and therefore part of the public API, I am happy to create the corresponding documentation in a PR.",
        "labels": "doc",
        "id": 44165
    },
    {
        "title": "Include list of all subsystems/topics in README.md",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nApproaching Node.js as a first time contributor or someone trying to understand the project's processes.\r\n\r\n**Describe the solution you'd like**\r\nList out and define all subsystems/topics in the README.md file. Examples of what I'm referring to: **deps, doc, test, meta, build, util**. These are terms we use heavily in PRs but don't actually say what they are nor is there really any indication that they have meaning outside of their usage.\r\n\r\n**Describe alternatives you've considered**\r\nListing in a different file or location and linking is not as useful, since it will not be nearly as discoverable. Not sure there are additional alternatives. Maybe a probot app that automagically comments on any issue that has a subsystem/topic attached with the definition? A PR to add those definitions to the README.md seems like a significantly lower barrier ðŸ˜„ ",
        "labels": "doc",
        "id": 44166
    },
    {
        "title": "doc: list the stability status of each API in one place?",
        "body": "Right now each API has their own page with their stability index, but AFAIK there is not a central place where you can find the stability status of all the APIs at a glance (correct me if I am wrong). It may be useful to have a list somewhere in https://github.com/nodejs/node/blob/master/doc/api/documentation.md#stability-index",
        "labels": "doc",
        "id": 44167
    },
    {
        "title": "module: createRequireFromPath documentation is incorrect",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.12.0\r\n* **Platform**: MacOS 10.14 (Darwin)\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThe [documentation](https://nodejs.org/docs/latest/api/modules.html#modules_module_createrequirefrompath_filename) for `createRequireFromPath` makes it seem like you can pass a directory to the function, but that will never correctly resolve packages.\r\n\r\nUsing the following directory structure;\r\n\r\n```\r\nsrc/\r\nâ””â”€â”€ utils\r\n    â””â”€â”€ some-tool.js\r\n```\r\n\r\nThe following code will throw a `MODULE_NOT_FOUND` exception (example from the docs):\r\n\r\n```javascript\r\nconst { createRequireFromPath } = require('module');\r\ncreateRequireFromPath('../src/utils')('some-tool');\r\n```\r\n\r\nHowever, if we pass a file path we can resolve it just fine.\r\n\r\n```javascript\r\nconst { createRequireFromPath } = require('module');\r\ncreateRequireFromPath('../src/utils/index.js')('some-tool');\r\n```\r\n\r\nIs there a bug here or is the documentation wrong? I'm willing to make a PR to either fix the issue or update the documentation :)",
        "labels": "doc",
        "id": 44168
    },
    {
        "title": "meta: investigate \"incorporating feedback in your pull request\"",
        "body": "New GitHub feature:\r\n\r\nhttps://help.github.com/articles/incorporating-feedback-in-your-pull-request/#applying-a-suggested-change\r\n\r\nThis can simplify nits addressing. We may need to update our contributing guides (including how-to steps to sync local branches with remote changes if needed).",
        "labels": "doc",
        "id": 44169
    },
    {
        "title": "Warn on potentially insecure inspector options (--inspect=0.0.0.0)",
        "body": "Extracted from #21774.\r\n\r\nInspector by default is bound to 127.0.0.1, but suggestion to launch it with `--inspect=0.0.0.0` is highly copy-pasted without proper understanding what it does.  I've observed that personally in chats, also see [google](https://www.google.ca/search?q=\"--inspect%3D0.0.0.0\").\r\n\r\nBinding inspector to 0.0.0.0 (in fact, to anything but the loopback interface ip) allows RCE, which could be catastrophic in cases where the IP is public. The users should be informed of that.\r\n\r\nA warning printed to the console (with corresponding documentation change) should at least somewhat mitigate this.\r\n\r\nNote: the doc change and the c++ change can come separately.",
        "labels": "doc",
        "id": 44170
    },
    {
        "title": "WebAssembly global is not mentioned in documentation",
        "body": "* **Version**: 10.11.0\r\n* **Platform**: all\r\n* **Subsystem**: docs\r\n\r\nIt looks like the `WebAssembly` global is available but there is no mention in [the docs](\r\nhttps://nodejs.org/docs/latest-v10.x/api/globals.html) of when this was introduced and which features are available.\r\n\r\nExample usage: https://glot.io/snippets/f5j3smuum8\r\n\r\nShould WebAssembly be added to the globals page or maybe even add a separate page?",
        "labels": "doc",
        "id": 44171
    },
    {
        "title": "docs: fs.writeStream.bytesWritten",
        "body": "The docs say:\r\n\r\n[`The number of bytes written so far. Does not include data that is still queued for writing.`](https://nodejs.org/dist/latest-v10.x/docs/api/fs.html#fs_writestream_byteswritten)\r\n\r\nHowever, looking at the code the `bytesWritten` property is incremented **after** `fs.write` completes, i.e. no queue should be involved?\r\n\r\nIt's true that queues on other levels might be involved e.g. `libuv` and the OS. However, given those constraints the `bytesWritten` is never correct unless a `fsync` is involved and which it never is, i.e. there is no difference in the accuracy of `bytesWritten` before and after `finish`, which some users (including myself) would like to assume. ",
        "labels": "doc",
        "id": 44172
    },
    {
        "title": "Discuss renaming doc/guides",
        "body": "In https://github.com/nodejs/node/pull/23287#issuecomment-427625557, @Trott wrote:\r\n> Also: The whole \"things called 'guides' are in two different places and mean subtly different things, and oh yeah the website is generated in this repo over here except for the docs which are generated over here\".... If there's some way that information could have been something could have been surfaced naturally, I'd love to hear what it is. Because that stuff is confusing and probably only a few people know it.\r\n> \r\n> Maybe the `guides` directory in this repo can be renamed to something that makes it clear they are internal to the project and/or moved out of `docs`?\r\n> \r\n> Maybe a bot can comment on any PR that adds a new file to the `docs/guides` letting the user know that these guides are for internal use and if they meant to create something for end users, then they should close this PR and open a new PR over in this other repo?\r\n> \r\n> Other ideas?\r\n\r\n",
        "labels": "doc",
        "id": 44173
    },
    {
        "title": "Buffer.toString('utf8') appears to use wtf-8",
        "body": "The byte sequence `237, 166, 164` is not valid utf8, since it encodes a [surrogate code point](https://en.wikipedia.org/wiki/UTF-8#Invalid_code_points), which is not a valid [unicode scalar value](http://www.unicode.org/glossary/#unicode_scalar_value). So `Buffer.from([237, 166, 164]).toString('utf8')` should error. But instead, it returns a string, effectively implementing [wtf-8](https://simonsapin.github.io/wtf-8/) rather than utf-8.\r\n\r\nOr does `Buffer.toString` simply not provide any validity guarantees at all, returning garbage strings if the buffer contains invalid input? In that case, *please* document this as expected behavior, since it makes the function completely useless for a bunch of use cases.\r\n\r\n`node -v`: `v10.11.0`\r\n`uname -a`: `Linux aljoscha-laptop 4.18.10-arch1-1-ARCH #1 SMP PREEMPT Wed Sep 26 09:48:22 UTC 2018 x86_64 GNU/Linux`\r\n\r\nSee also https://github.com/rust-lang/rust/issues/54845\r\n\r\n*edit*: This also leaks into `JSON.parse`, which can accept garbage strings even though ECMA-404 (the json standard prescribed for JSON.parse as defined in ECMAScript) only allows valid utf8 input.",
        "labels": "doc",
        "id": 44174
    },
    {
        "title": "tools: ICU shrinker needs to adapt to new output path",
        "body": "* **Version**:v11.0.0-pre\r\n* **Platform**:all\r\n* **Subsystem**:tools\r\n\r\nThe location of the ICU small datafile changed from `out/Release/gen/icutmp` to `out/Release/obj/gen/icutmp`\r\n\r\nNot critical (because there's a workaround), but would be nice to fix the default. Supports #23244 \r\n\r\n",
        "labels": "doc",
        "id": 44175
    },
    {
        "title": "doc: document \"flat\" `util.inspect` signature",
        "body": "The code allows calling it as \r\n```js\r\nutil.inspect(object, [showHidden], [depth], [colors])\r\n```\r\nIt wash refactored 6 years ago (Refs: 07774e6) and marked legacy, but it seems it is still often used, and so should be documented.",
        "labels": "doc",
        "id": 44176
    },
    {
        "title": "Incomplete documentation require()",
        "body": "Incomplete documentation at https://nodejs.org/dist/latest-v8.x/docs/api/modules.html#modules_require\r\n_It states no use cases._\r\n\r\n`require()` is widely used for reading `.json` files.\r\nIs it safe to apply `require()` over `.json`? Are there any guarantees that `.json` file is allowed to contain single JSON object only? Are there any guarantees `require()`ing a `.json` file containing valid JS code will never lead to interpreting the code?",
        "labels": "doc",
        "id": 44177
    },
    {
        "title": "docs: per class pages",
        "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nIt would help to read the docs if there were per-class pages.\r\n\r\nAlso, imo the Node API docs lack following things:\r\n\r\n* Generally, emphasis on readability and clearness\r\n* Side-bar list view of class inheritance tree \r\n* Side-bar list view of properties/methods/events in a module or class\r\n* Emphasized list of possible values of string-enums\r\n* Per-class/object page with properties and methods\r\n* Sometimes return type is just \"Object\" without it being clear how that object looks like\r\n\r\nIt's really hard to get an overview, very time-expensive to read. It is also from a layout/design point of view kind of not the most enjoyable thing I've seen. \r\n\r\nI think you just have to compare with a few other very big API docs to see how it's not really matching the standards. Which is in a way surprising and remarkable, when thinking how big Nodejs is by now. \r\n\r\nAn example of a fairly good and large documentation is MDN: https://developer.mozilla.org/en-US/docs/Web/API/WebSocket\r\n\r\nI think it is crucial to have a good documentation, especially for a public platform.\r\n\r\n**Describe the solution you'd like**\r\n\r\nAll of the points above addressed.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nRe-generate an unofficial API doc based on the Node.js source-code? There are enough good generators out-there. What is crucial is to have types properly annotated and documented inside the code.\r\n",
        "labels": "doc",
        "id": 44178
    },
    {
        "title": "doc: document AliasedBuffer in C++ style guide",
        "body": "The actual API is documented in https://github.com/nodejs/node/blob/master/src/aliased_buffer.h but it would be good to have a note in the style guide about trying not to create regular typed arrays in C++ if they are going to be used to pass data out of band.",
        "labels": "doc",
        "id": 44179
    },
    {
        "title": "Add class inheritance/implements info to NodeJS JSON docs",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nI'm creating a tool that generates a definition files from [NodeJS JSON docs\r\n](https://nodejs.org/docs/latest-v10.x/api/all.json). Node documented great, but I want to know if a class (for example [`Buffer`](https://nodejs.org/docs/latest-v10.x/api/buffer.json)) inherits from or implements other class.\r\n `Buffer` class implements `UInt8Array` and it even mentions in the docs: \r\n```\r\nWith TypedArray now available, the Buffer class implements the Uint8Array API in a manner that is more optimized and suitable for Node.js.\r\n```\r\nBut not in the [JSON docs](https://nodejs.org/docs/latest-v10.x/api/buffer.json).\r\n\r\n**Describe the solution you'd like**\r\nAdd an appropriate property to the JSON:\r\n```json\r\n{\r\n\t\"textRaw\": \"Class: Buffer\",\r\n\t\"type\": \"class\",\r\n\t...\r\n\t\"implements\":[\"UInt8Array\"],\r\n}\r\n```\r\n\r\n**Describe alternatives you've considered**\r\nNo alternative, this is the only and the ideal idea in the NodeJS history or coding in general :D ðŸ’ƒ ",
        "labels": "doc",
        "id": 44180
    },
    {
        "title": "doc: should object parameter properties be sorted?",
        "body": "Refs: https://github.com/nodejs/node/pull/22824#discussion_r217258885\r\n\r\nPros:\r\n\r\n1. They will be easier to find in long lists.\r\n\r\nCons:\r\n\r\n1. Huge doc churn, git blame ruin, difficult diffs to review in correction PRs, significant backporting burdens.\r\n2. Hard to maintain in new PRs except it will be automated as doc lint rule.\r\n3. Some properties can be grouped logically, this grouping will be destroyed by ABC-sorting.\r\n\r\nPlease, vote:\r\n\r\n+1 â€” :+1: \r\n-1 â€” :-1: \r\n\r\nApart from the previous voting:\r\n\r\n\"I may be ready to review such PRs (one per doc to reduce the workload)\" â€” :tada: ",
        "labels": "doc",
        "id": 44181
    },
    {
        "title": "doc: process.stdout.fd is mentioned but undocumented",
        "body": "`process.stdout.fd` is mentioned in these 2 sections:\r\n\r\nhttps://nodejs.org/api/async_hooks.html#async_hooks_printing_in_asynchooks_callbacks\r\nhttps://nodejs.org/api/async_hooks.html#async_hooks_asynchronous_context_example\r\n\r\nBut it is not documented in [`process.stdout`](https://nodejs.org/api/process.html#process_process_stdout) or in a section of any mentioned prototype (`net.Socket`, Duplex or Writable stream).\r\n\r\nShould it be documented with `process.stdin.fd` and `process.stderr.fd`?",
        "labels": "doc",
        "id": 44182
    },
    {
        "title": "why isNull deprecated in the doc but not in the source ?",
        "body": "I found that `isNull` has deprecated in the [doc](https://nodejs.org/dist/latest-v10.x/docs/api/util.html#util_util_isnull_object).\r\n\r\n```js\r\nconst util = require(\"util\");\r\nconsole.log(util.isNull(1));\r\n```\r\n\r\nRun code above hasn't deprecated warning.\r\n\r\nI search the [source](https://github.com/nodejs/node/blob/cdb359840c9537e460b1bf0536fc36ec5fe2db2d/lib/util.js#L1465) and these isn't deprecated yet.\r\n\r\nI think that the doc should be update.",
        "labels": "doc",
        "id": 44183
    },
    {
        "title": "doc: crypto sign.sign() signature description missing options",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\n[Relevant link](https://nodejs.org/docs/v10.10.0/api/crypto.html#crypto_sign_sign_privatekey_outputformat)\r\n\r\n`sign.sign()` currently only lists `key` and `passphrase` in the signature description, but the general function description also includes `padding` and `saltLength` as additional options.\r\n",
        "labels": "doc",
        "id": 44184
    },
    {
        "title": "Docs missing for http2Stream.id and the 'ready' event",
        "body": "I wrote a piece of code that made a request to A, and after a moment, made a request to B with the prior stream as a parent.\r\n\r\nThis means I needed to pass the ID of stream A to the `client.request` call for stream B.\r\n\r\n`stream.id` is mentioned in passing, but it isn't specifically documented.\r\n\r\nSame goes for the `ready` event.",
        "labels": "doc",
        "id": 44185
    },
    {
        "title": "Add blurb to N-API documentation indicating that we recommend the use of badges",
        "body": "Re: https://github.com/nodejs/admin/issues/221\r\nRe: https://github.com/nodejs/abi-stable-node/issues/333\r\n\r\n@nodejs/n-api",
        "labels": "doc",
        "id": 44186
    },
    {
        "title": "crypto.privateDecrypt cannot decrypt message",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8.11.3\r\n* **Platform**: Linux x86_64\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\nI'm trying to encrypt/decrypt data using a rsa key but the process fails somehow with this message :\r\n\r\n> Error: error:04099079:rsa routines:RSA_padding_check_PKCS1_OAEP_mgf1:oaep decoding error\r\n\r\nCode : \r\n```javascript\r\nvar  childProcess = require('child_process');\r\nvar  crypto = require('crypto');\r\n\r\nvar pk;\r\nvar mess_chiffre;\r\n\r\nvar sign = function () {\r\n  var buf = new Buffer(\"Coucou c'est relou!!!\");\r\n  var sig = crypto.privateEncrypt(pk,buf);\r\n  mess_chiffre = sig.toString('hex');\r\n  console.log(\"Signed : \", mess_chiffre);\r\n};\r\n\r\n\r\nvar decrypt = function () {\r\n  var buff = new Buffer(mess_chiffre,'hex')\r\n  console.log('Buffer : ',buff)\r\n  console.log('decrypting withh pk: ')\r\n  console.log(pk)\r\n  var mess = crypto.privateDecrypt(pk,buff)\r\n  console.log(mess)\r\n};\r\n\r\n\r\nchildProcess.exec('openssl rsa -in private.key', {},\r\n    function (err, stdout, stderr) {\r\n  if (err) throw err;\r\n  pk = stdout; // Save in memory for later use\r\n  sign();\r\n  decrypt();\r\n});\r\n\r\n```",
        "labels": "doc",
        "id": 44187
    },
    {
        "title": "Uninstall instructions",
        "body": "**Is your feature request related to a problem? Please describe.**\r\nThe nodejs.org website does not have a how to uninstall page, or it is very hard to find (since there is no search in the website or the api docs).\r\n\r\n**Describe the solution you'd like**\r\nA \"How to uninstall\" guide should be accessible in the main documentation and/or in the downloads section. An uninstall script would be much more desirable.\r\n\r\n**Describe alternatives you've considered**\r\nI've searched all around in the website on how to uninstall, to no avail. I've even searched \"site:nodejs.org uninstall\", and that didn't turn up anything either. I've searched the issues here, also to no avail (which is normal, as this repo is for nodejs, not for the nodejs website (which does not exist or is not public in repo form).",
        "labels": "doc",
        "id": 44188
    },
    {
        "title": "docs: missing history entry for 10.10.0 in fs.readDir(Sync)",
        "body": "https://nodejs.org/api/fs.html#fs_fs_readdirsync_path_options\r\n\r\nThe history doesn't contain an entry for the recently added `withFileTypes` option. This is the same for the sync and async API.",
        "labels": "doc",
        "id": 44189
    },
    {
        "title": "Buffer deprecation backward compatibility",
        "body": "This is not a bug but can be a suggestion to be added to https://nodejs.org/en/docs/guides/buffer-constructor-deprecation/\r\n\r\nI am using several versions of nodejs, the default is still in fact for some reasons 0.11.3 (yes, you read well, not 11.3, 0.11.3)\r\n\r\nIn addition I am not willing for now to change ``new Buffer`` for all my projects\r\n\r\nI did not find a solution that could solve my issues in the above link, then I ended up with something like:\r\n\r\n```javascript\r\nvar oBuffer=Buffer;\r\n\r\nif (oBuffer.from) {\r\n\tBuffer=function() {\r\n\t\tif (typeof arguments[0]==='number') {\r\n\t\t\treturn oBuffer.alloc(arguments[0]);\r\n\t\t} else {\r\n\t\t\treturn oBuffer.from.apply(null,arguments);\r\n\t\t};\r\n\t};\r\n\tObject.keys(oBuffer).forEach(function(val) {\r\n\t\tBuffer[val]=oBuffer[val];\r\n\t});\r\n\tObject.setPrototypeOf(Buffer.prototype,oBuffer.prototype);\r\n};\r\n```\r\n\r\nA bit ugly but seems to work well (at least for myself, to be confirmed in general)",
        "labels": "doc",
        "id": 44190
    },
    {
        "title": "url: WHATWG API `.origin` behavior does not match the documentation",
        "body": "* **Version**: `v10.9.0`, `v11.0.0-pre` (master)\r\n* **Platform**: `Linux yoga 4.18.5-arch1-1-ARCH #1 SMP PREEMPT Fri Aug 24 12:48:58 UTC 2018 x86_64 GNU/Linux`\r\n* **Subsystem**: doc, url\r\n\r\nDocumented ([link](https://github.com/nodejs/node/blob/master/doc/api/url.md#whatwg-api)):\r\n```js\r\nconst myURL = new URL('https://%CF%80.com/foo');\r\nconsole.log(myURL.href);\r\n// Prints https://xn--1xa.com/foo\r\nconsole.log(myURL.origin);\r\n// Prints https://Ï€.com\r\n```\r\n\r\nActual behavior:\r\n```console\r\n> const myURL = new URL('https://%CF%80.com/foo');\r\n> console.log(myURL.href);\r\nhttps://xn--1xa.com/foo\r\n> console.log(myURL.origin);\r\nhttps://xn--1xa.com\r\n```\r\n\r\nThe doc implies that `.origin` is not punicode-encoded in this scenario, but it in fact is punicode-encoded.",
        "labels": "doc",
        "id": 44191
    },
    {
        "title": "doc: is Google Analytics tracking actually useful?",
        "body": "It has been 1Â½ years since Google Analytics tracking (for docs) landed in #6601, and perhaps more than a year since it has been actually activated on the website.\r\n\r\nThe rationale for including it back then was that it should give us information on documentation usage and there were claims that such stats would improve our docs, as far as I remember.\r\n\r\nSo, the questions are:\r\n1. What data has been collected?\r\n2. Who has it?\r\n3. How was that data used?\r\n4. Has Google Analytics actually proven to be useful for improving the docs over the year?\r\n\r\nRefs: #6601, #22595.\r\n\r\n/cc @nodejs/documentation @nodejs/website @bnoordhuis @phillipj\r\n",
        "labels": "doc",
        "id": 44192
    },
    {
        "title": "__filename (and thus __dirname) have undefined behaviour for symlinks.",
        "body": "the `__filename` (and so also `__dirname`) values do not report the correct paths for files and dirs that have been symlinked/junctioned, given that their behaviour is currently undefined in the API, thus not officialy _having_ a correct behaviour in these cases.\r\n\r\nReading through https://nodejs.org/docs/latest/api/modules.html#modules_filename the only description is that referencing the value will yield an absolute path, but the conventional absolute path for a symlink or junction is that path, as seen locally. Instead, `__filename`/`__dirname` yield the original resource path, which can be on completely different drives or even network shares. \r\n\r\nGiven that `__filename`'s behaviour is currently undefined for symlinks/junctions, and that the actual behaviour that manifests is contrary to normal, expected behaviour for symlink/junction, what it's currently doing is close enough to a bug to merit fixing.\r\n\r\n- can we change `__filename` to return the proper absolute path, local to the filesystem path that the file was loaded from, and,\r\n- can we update the API documentation to define the behaviour as \"this value is symlink/junction-safe\"\r\n\r\nI know about the https://nodejs.org/api/cli.html#cli_preserve_symlinks flag, but this should not be the exception to the rule: not following a symlink to its original resource unless _explicitly told to_ is the whole reason symlinks and junctions work, where code that checks for locality should not break just because symlinks are suddenly resolved to wildly remote paths (\"am I running in a dir parallel to my owner?\", \"is this resource in a subdir of my dir?\", \"is this web asset being loaded from the dir that my config says is my asset dir?\" etc. etc.)",
        "labels": "doc",
        "id": 44193
    },
    {
        "title": "Include links to source code in documentation",
        "body": "**Describe the solution you'd like**\r\nFor someone who's learning about the internals of node, it's useful to know exactly where in the codebase certain functions are implemented. I think it would be nice if the node docs linked say a function (like `setTimeout`) to the line in source code (on Github perhaps) where that function is implemented.\r\n\r\n### How it works in rust docs\r\n\r\nRust doc does this and I think it's a really nice feature that helps those wishing to dig deeper but isn't so intrusive to confuse or overwhelm newcomers.\r\n\r\n![screen shot 2018-08-19 at 09 40 32](https://user-images.githubusercontent.com/916064/44304890-08078d00-a394-11e8-96b5-fa3363a8b6d0.png)\r\n\r\n### How it might work for node docs\r\n\r\n![screen shot 2018-08-19 at 09 48 38](https://user-images.githubusercontent.com/916064/44304929-33d74280-a395-11e8-9935-d1107f291a54.png)",
        "labels": "doc",
        "id": 44194
    },
    {
        "title": "Document `Buffer.of()`",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 11.0.0-pre (master)\r\n* **Platform**: N/A\r\n* **Subsystem**: buffer doc\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n`Buffer.of()` is not documented in `doc/api/buffer.md` but (probably) should be. (Right?)",
        "labels": "doc",
        "id": 44195
    },
    {
        "title": "readable.pipe returns stream.Readable",
        "body": "[readable.pipe](https://nodejs.org/api/stream.html#stream_readable_pipe_destination_options) is documented to return `stream.Writable`. However, as only `stream.Readable` has a `pipe` method, it only makes sense to return that to set up chains of piped streams. I also verified that a pipe to a `Gunzip` object could be used as a `Readable` stream.\r\n",
        "labels": "doc",
        "id": 44196
    },
    {
        "title": "createPushResponse() callback needs better documentation",
        "body": "* **Version**: 10.8.0\r\n* **Platform**: docs\r\n* **Subsystem**: http2\r\n\r\nhttp2: documentation for `createPushResponse()` in `Http2ServerResponse` should spell out what its callback returns more clearly. My interpretation was that it would return similar to `ServerHttp2Stream.pushResponse()` but it does not. In specific, headers are not passed to the callback of `createPushResponse()`.\r\n\r\nhttps://github.com/nodejs/node/blob/fc846662637af5372d234cdf2f2e0314a73bcd31/lib/internal/http2/compat.js#L670\r\n",
        "labels": "doc",
        "id": 44197
    },
    {
        "title": "Incorrect documentation for `child_process`",
        "body": "* **Version**: all\r\n* **Platform**: all\r\n* **Subsystem**: child_process\r\n\r\nI recently [put in a PR over on DefinitelyTyped](https://github.com/DefinitelyTyped/DefinitelyTyped/pulls/28025) based on the `child_process` docs, and another user [pointed out](https://github.com/DefinitelyTyped/DefinitelyTyped/issues/28069) that the documented options are missing a legal value.  [The stdio section of the child_process docs](https://nodejs.org/api/child_process.html#child_process_options_stdio) lists `\"inherit\"` as a valid (shorthand) string argument, but it does not appear in the numbered list under the array argument description.\r\n\r\nAt first, I thought \"inherit\" and `null`/`undefined` were equivalent, but then I dug around in [the relevant code](https://github.com/nodejs/node/blob/master/lib/internal/child_process.js#L910) and it behaves differently from any other value.  Under the hood, the transformed object (having `type = \"inherit\"`) is passed through to the native implementation as is, and I'm not sure where to find the source for that (in v8, I guess?), so the trail sort of went cold for me.  If anybody can explain what \"inherit\" (in an array value, not as shorthand) actually does, I can put in the PR, or you could just file the PR directly. ",
        "labels": "doc",
        "id": 44198
    },
    {
        "title": "Inconsistent flag & environment variable documentation",
        "body": "Right now we have a inconsistent documentation of multiple of our environment variables and CLI options. These have to be documented at least in three places: `/doc/api/cli.md`, `/src/node.cc` and `/doc/node.1`. Most of the time the variable or flag would also be documented a fourth time in the code that it belongs to.\r\n\r\nI added the `help wanted` label so we can address this.\r\n\r\n1) We need a full list of currently existing flags and variables and if they are fully documented or not.\r\n2) We have to fix all of them.",
        "labels": "doc",
        "id": 44199
    },
    {
        "title": "Underscores in doc headlines are escaped",
        "body": "The headlines containing underscores in the latest documentation have the underscores escaped:\r\n\r\n![image](https://user-images.githubusercontent.com/10602/43952342-f8984738-9c95-11e8-93d1-9480b6698f52.png)\r\n\r\nExample: https://nodejs.org/api/stream.html#stream_transform_flush_callback\r\n\r\nI can try and fix it my self, but I have no idea how the docs are built, so I would need some guidance ðŸ˜¬ ",
        "labels": "doc",
        "id": 44200
    },
    {
        "title": "No documentation for net.Socket \"free\" event.",
        "body": "Apparently sockets in keep-alive emit a \"free\" event when ready to be reused. I could not find documentation of this event at https://nodejs.org/api/net.html#net_class_net_socket\r\n",
        "labels": "doc",
        "id": 44201
    },
    {
        "title": "http.get method() ignores query params when passing an URL as first argument",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v8.10.0\r\n* **Platform**: Linux 4.15.0-29-generic Ubuntu SMP Tue Jul 17 15:39:52 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: http\r\n\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen passing an `URL` with query params as the first argument to `http.get()` method, the query is ignored.\r\n\r\n```js\r\nconst URL = require('url');\r\nconst http = require('http');\r\nconst assert = require('assert');\r\n\r\nfunction parseJsonResp(next) {\r\n   return function(resp) {\r\n     var raw = '';\r\n     resp.on('data', function(chunk) {\r\n       raw += chunk;\r\n     });\r\n     resp.on('end', function() {\r\n       next(null, JSON.parse(raw));\r\n     });\r\n  }\r\n};\r\n\r\nconst url = URL.parse('http://httpbin.org/get');\r\nurl.query = {foo: 'bar'}\r\n\r\nhttp.get(url, parseJsonResp(function(err, obj) {\r\n  assert(obj.args.foo === 'bar'); // It fails here\r\n}));\r\n\r\n```",
        "labels": "doc",
        "id": 44202
    },
    {
        "title": "Documentation for BufferwriteDoubleLE/writeDoubleBE is confusing",
        "body": "The documentation for these methods has the following:\r\n\r\n    buf.writeDoubleBE(0xdeadbeefcafebabe, 0);\r\n\r\nHowever `0xdeadbeefcafebabe` a particularly poor value choice.  To the naive reader, it implies this method is for writing 64-bit integers, and that JS supports 64 bit integers (which it doesn't.  E.g. `(0xdeadbeefcafebabe).toString(16)` yields `deadbeefcafeb800`).\r\n\r\nIt would be clearer if the example used something like `1234.5678` or `Math.PI` or `1.2345e67` .",
        "labels": "doc",
        "id": 44203
    },
    {
        "title": "fork method, args parameter cannot be null",
        "body": "* **Version**: 10.5.0 (but I think this is not related)\r\n* **Platform**: Ubuntu 18.04.1 LTS (but I think this is not related)\r\n* **Subsystem**: child_process\r\n\r\nHi,\r\n\r\nI've just realized that this code can't work because args parameter can't be null. But it's not documented and I think it can be disturbing.\r\n\r\n```\r\nchildProcess.fork(app.js', null, {\r\n    execPath: process.execPath\r\n  })\r\n```\r\n\r\nBut the following will work : \r\n```\r\nchildProcess.fork(app.js', [], {\r\n    execPath: process.execPath\r\n  })\r\n```\r\n\r\nI think this line is related to the issue : \r\nhttps://github.com/nodejs/node/blob/2bea9cefbc10ed1dd497bbae61c07d971da287dd/lib/child_process.js#L71\r\n\r\nI'm not sure if it's the intended behavior, or if it's a lack in the documentation ?",
        "labels": "doc",
        "id": 44204
    },
    {
        "title": "Buffer documentation on pooling might be misleading",
        "body": "Open https://nodejs.org/api/buffer.html or [master/doc/api/buffer.md](https://github.com/nodejs/node/blob/master/doc/api/buffer.md), and search for Â«poolÂ».\r\n\r\n---\r\n\r\n> ### Buffer.from(), Buffer.alloc(), and Buffer.allocUnsafe()\r\n> â€¦\r\n> Buffer instances returned by `Buffer.allocUnsafe()` may be allocated off a shared internal memory **pool** if size is less than or equal to half `Buffer.poolSize`. Instances returned by `Buffer.allocUnsafeSlow()` never use the shared internal memory **pool**.\r\n\r\n> ### Class Method: Buffer.allocUnsafe(size)\r\n> ...\r\n> Note that the Buffer module pre-allocates an internal Buffer instance of size `Buffer.poolSize` that is used as a pool for the fast allocation of new Buffer instances created using `Buffer.allocUnsafe()` and the deprecated `new Buffer(size)` constructor only when size is less than or equal to `Buffer.poolSize >> 1` (floor of `Buffer.poolSize` divided by two).\r\n> Use of this pre-allocated internal memory pool is a key difference between calling `Buffer.alloc(size, fill)` vs. `Buffer.allocUnsafe(size).fill(fill)`. Specifically, `Buffer.alloc(size, fill)` will never use the internal Buffer pool, while `Buffer.allocUnsafe(size).fill(fill)` will use the internal Buffer pool if size is less than or equal to half `Buffer.poolSize`. The difference is subtle but can be important when an application requires the additional performance that `Buffer.allocUnsafe()` provides.\r\n\r\nNext match is in `Buffer.allocUnsafeSlow` docs (skipped here).\r\n\r\n> ### Class Property: Buffer.poolSize\r\n> {integer} Default: 8192\r\n> This is the size (in bytes) of pre-allocated internal Buffer instances used for **pooling**. This value may be modified.\r\n\r\n> ### buf.byteOffset\r\n> {integer} The `byteOffset` on the underlying `ArrayBuffer` object based on which this `Buffer` object is created.\r\n> When setting `byteOffset` in `Buffer.from(ArrayBuffer, byteOffset, length)` or sometimes when allocating a buffer smaller than `Buffer.poolSize` the buffer doesn't start from a zero offset on the underlying ArrayBuffer.\r\n\r\n---\r\n\r\nIn fact, `Buffer.from(arg)` is pooled:\r\n```console\r\n$ node\r\n> Buffer.from('xx').offset\r\n0\r\n> Buffer.from('xx').offset\r\n8\r\n> Buffer.from([1,2,3]).offset\r\n16\r\n> Buffer.from('Hello').buffer.byteLength\r\n8192\r\n```\r\n\r\nThat is not documented in `Buffer.from` docs or anywhere where people would search for it â€” from the docs, it might look like automatic pooling is something that is used only for `Buffer.allocUnsafe`.\r\n\r\nThe only place that mentions that `Buffer.from(arg)` is pooled is Â«or sometimes when allocating a buffer smaller than `Buffer.poolSize`Â» clause in the `buf.byteOffset` documentation. Also, that one isn't even present in v8.x LTS docs.\r\n\r\nPerhaps, `Buffer.from` documentation should explicitly mention that it might return pooled buffers (as `Buffer.allocUnsafe` does).",
        "labels": "doc",
        "id": 44205
    },
    {
        "title": "doc: headerlines not rendered correctly with extra backslash",
        "body": "Looks like something changed in how we render documentation for 8 vs 10. Headers used to need `\\` to escape special characters. Now the backslash is rendered and our docs look weird. \r\n[Here](https://nodejs.org/dist/latest-v10.x/docs/api/deprecations.html#deprecations_dep0002_require_linklist) is an example, source: \r\n\r\n```### DEP0002: require('\\_linklist')```\r\n\r\n\r\nHow it looks in docs for 10 ([here](https://nodejs.org/dist/latest-v10.x/docs/api/deprecations.html#deprecations_dep0002_require_linklist)): \r\n### DEP0002: require('\\\\\\_linklist')\r\n\r\n### &nbsp;\r\n\r\n### &nbsp;\r\n\r\nHow it looks in docs for 8 ([here](https://nodejs.org/dist/latest-v8.x/docs/api/deprecations.html#deprecations_dep0002_require_linklist)):\r\n ### DEP0002: require('_linklist')\r\n \r\nI think we can remove the extra `\\`, `.md` files viewed on GitHub would render correctly. \r\n\r\ncc @nodejs/website ",
        "labels": "doc",
        "id": 44206
    },
    {
        "title": "doc: header escaping regression",
        "body": "Details here: https://github.com/nodejs/node/pull/21936#issuecomment-409649872; pulled out as a separate issue so that we can discuss the changes and reference it in a pull request.",
        "labels": "doc",
        "id": 44207
    },
    {
        "title": "errors: documenting removed error codes",
        "body": "See https://github.com/nodejs/node/pull/21491 for a full list of removed/inconsistent error codes (h/t to @ChALkeR for the investigation). There could be more though\r\n\r\nActions requested\r\n\r\n- [ ] Add a new section in `doc/api/errors.md` documenting the removed error codes\r\n- [ ] Add change logs for those codes (releases in which they initially appeared and got removed). This requires a bit more archeology.\r\n  - To find out when a code got added, look into the git blame of `doc/api/errors.md` (before it got removed) and identify the commit where it was added (GitHub's commit UI will show the tags where the commit appears so it shouldn't be too hard).\r\n  - To find out when a code got added, see https://github.com/nodejs/node/pull/21491\r\n\r\n",
        "labels": "doc",
        "id": 44208
    },
    {
        "title": "Should Socket.readable/writeable be documented?",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.7.0\r\n* **Platform**: all\r\n* **Subsystem**: docs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`net.Socket` has 2 very useful properties: `readable` and `writable`, but they are not documented. Should we make them private, or expose them? I for one am in favor of making them documented public properties, but would like to hear what others think. Thanks.",
        "labels": "doc",
        "id": 44209
    },
    {
        "title": "doc: explaination about flagged feature etiquette needed",
        "body": "There is a lot of misunderstanding in the ecosystem about how harmony* and experimental flags should be used, most alarmingly in the case of libraries that ship support for features that are flagged.\r\n\r\nWe need to document:\r\n- Why flags are how we (and V8*) ship experimental features\r\n- Why you should only use flagged features at an application level\r\n- Why you shouldn't use flagged features in production environments\r\n- Why you shouldn't publish versions of your libraries with support for flagged features\r\n- Given the restrictions above, ways that you *can* help us test flagged features\r\n\r\nThis seems like a lot for one person so I thought I would open an issue about it and get some collaboration going.\r\n\r\n\\*We probably shouldn't document V8's flagging, but it might be necessary to at least mention harmony flags.",
        "labels": "doc",
        "id": 44210
    },
    {
        "title": "Documentation on native addon filenames and `NODE_MODULE`",
        "body": "The documentation says: \r\n\r\n> The module_name must match the filename of the final binary (excluding the .node suffix).\r\n\r\nToday I realized that I don't do this. I was using cmake-js to compile the module. The macro `NODE_MODULE` itself (seemingly) requires a valid C identifier which can't have dashes so I avoided it by using underscores, but our filename did have dashes, meaning the filename and the value given to `NODE_MODULE` didn't match. However, I haven't seen any negative consequences of this. \r\n\r\nWhat is the purpose of this documentation? What problems can arise from not following this?",
        "labels": "doc",
        "id": 44211
    },
    {
        "title": "fs.rename doesn't work as documented",
        "body": "**Version**: 10.7.0\r\n**Platform**: Windows 10 x64\r\n**Subsystem**: fs\r\n\r\nThe documentation for fs.rename is not entirely correct or at least incomplete.\r\nIt is documented to \r\n> Asynchronously rename file at oldPath to the pathname provided as newPath. In the case that newPath already exists, it will be overwritten.\r\n\r\nAt least on Windows it will also work on directories but it will not overwrite a destination directory but instead throw a EPERM error indicating a permission problem.\r\nIf oldPath is a directory and newPath is a file, the file will be replaced, if oldPath is a file and newPath is a directory, the exception is thrown.\r\n\r\nNow I'm going to say it's probably a good thing that it's not replace an entire directory but the EPERM error message is misleading and it would probably be better to be precise in the documentation:\r\n\r\n> Asynchronously rename file or directory at oldPath to the pathname provided as newPath. In the case that newPath is a file and already exists, it will be overwritten, if there is a directory at newPath an error will be raised instead.",
        "labels": "doc",
        "id": 44212
    },
    {
        "title": "test: unclear error with _toc.html",
        "body": "\r\n* **Version**: master\r\n* **Platform**: OS X\r\n* **Subsystem**: doc\r\n\r\nI'm adding a new error code, and I'm getting: \r\n\r\n```\r\n=== release test-make-doc ===\r\nPath: doctool/test-make-doc\r\nassert.js:338\r\n    throw err;\r\n    ^\r\n\r\nAssertionError [ERR_ASSERTION]: _toc.html does not not match TOC\r\n    at Object.<anonymous> (/Users/matteo/Repositories/node/test/doctool/test-make-doc.js:45:10)\r\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\r\n    at Module.load (internal/modules/cjs/loader.js:599:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\r\n    at startup (internal/bootstrap/node.js:266:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:596:3)\r\nCommand: out/Release/node /Users/matteo/Repositories/node/test/doctool/test-make-doc.js\r\n```\r\n\r\nConsidering that `_toc.md` was deleted in https://github.com/nodejs/node/pull/21637, what should I do to fix this?\r\n\r\ncc @rubys",
        "labels": "doc",
        "id": 44213
    },
    {
        "title": "10.7.0 doc mistake: new vm.Module",
        "body": "```\r\n  // Since module has no dependencies, the linker function will never be called.\r\n  await module.link(() => {});\r\n  module.initialize();\r\n  await module.evaluate();\r\n```\r\nthe method `initialize` does not exist. May be `instantiate` is correct.",
        "labels": "doc",
        "id": 44214
    },
    {
        "title": "doc - Document MODULE_NOT_FOUND error code",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: All\r\n* **Platform**: N/A\r\n* **Subsystem**: N/A\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe error code `MODULE_NOT_FOUND` doesn't seem to be documented (see https://nodejs.org/dist/latest-v8.x/docs/api/errors.html#nodejs-error-codes). Having it officially supported/documented will help us safely implement \"tryRequire\" operations for optional files.\r\n\r\n(By the way, I'm not finding where the API documents live. Maybe the docs for how to update docs could be surfaced better so this could have taken the form of a PR.)",
        "labels": "doc",
        "id": 44215
    },
    {
        "title": "Worker Threads docs example not working",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **node v10.6.0**\r\n* **Darwin 17.5.0**\r\n* **Worker threads**\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nHello,\r\n\r\nRunning the example from https://nodejs.org/docs/v10.6.0/api/worker_threads.html#worker_threads_class_worker doesn't work. It fails with:\r\n\r\n```\r\n$ node --experimental-worker oncetest.js\r\n\r\nevents.js:167\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\nTypeError: require(...).once is not a function\r\n    at Object.<anonymous> (/Users/krzysztof.slonka/projects/native-workers-playground/oncetest.js:13:29)\r\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\r\n    at Module.load (internal/modules/cjs/loader.js:599:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\r\n    at MessagePort.port.on (internal/worker.js:425:27)\r\n    at MessagePort.emit (events.js:182:13)\r\n    at MessagePort.onmessage (internal/worker.js:66:8)\r\nEmitted 'error' event at:\r\n    at Worker.[kOnErrorMessage] (internal/worker.js:296:10)\r\n    at Worker.[kOnMessage] (internal/worker.js:306:37)\r\n    at MessagePort.Worker.(anonymous function).on (internal/worker.js:243:57)\r\n    at MessagePort.emit (events.js:182:13)\r\n    at MessagePort.onmessage (internal/worker.js:66:8)\r\n```\r\n\r\nI think it should be: `parentPort.once` right?",
        "labels": "doc",
        "id": 44216
    },
    {
        "title": "Adding Pronouns to the README.md",
        "body": "Hey @nodejs/collaborators \r\n\r\nA while back a bunch of us decided to start including our pronouns in the [README.md](https://github.com/nodejs/node#collaborators). I wanted to take a quick opportunity to remind folks of this and encourage them to PR their pronouns if they are up for it.\r\n\r\nNot only is it a quick and easy PR, but knowing pronouns can improve communication. Even if you are on the fence about it, including your pronoun shows solidarity and support pf other collaborators to whom this is very important to.",
        "labels": "doc",
        "id": 44217
    },
    {
        "title": "Creating a branch of the Docs using RunKit",
        "body": "As a part of the @nodejs/website-redesign work, we've gone through some work to analyze a way to improve some of the interactivity of the documentation on the website once we re-launch with the work the Website Redesign team is working on.\r\n\r\nEarly on, RunKit approached us with an interest to help improve the docs and make them more interactive while degrading gracefully.\r\n\r\nMy personal biggest concern was offline mode and not blocking the Docs for those who have JavaScript disabled â€“ both of which are entirely addressed by the demos that the RunKit team has provided.\r\n\r\nThey've also been going to great lengths to ensure that some of the edge cases we have are addressed entirely within the platform.\r\n\r\n@tolmasky from the RunKit team has requested that we begin to spin up an initial setup of RunKit enabled docs to help load-test the RunKit servers. This is purely to help see if they're going to need to set up a dedicated server for Node.js or if their existing infra will suffice.\r\n\r\nI offered to be a bridge to Core to begin to help process this request â€“ not sure what the barriers on the Docs side will be, but happy to help connect the dots and do what we need to to make this work ðŸ‘ \r\n\r\nAlso wanted to mention that the RunKit team has been incredibly willing to help out and bend over backward to enable the Website Redesign team to succeed in revamping the Node.js website and improving the UX for developers. Huge thank you to them for all the work they're doing ðŸ™Œ",
        "labels": "doc",
        "id": 44218
    },
    {
        "title": "doc: troubleshooting FAQ?",
        "body": "We have some frequently emerged issues mostly concerned Node.js installation. Just two classic examples:\r\n\r\n1. Windows issue with antivirus and \"Performance counters\" / \"Event tracing\" options: https://github.com/nodejs/node/issues/20538\r\n\r\n2. Global `npm` installation issue: https://github.com/nodejs/node/issues/21661\r\n\r\nShould we create some troubleshooting FAQ doc and link to it from the main `nodejs/node` GitHub page and from the nodejs.org site?\r\n",
        "labels": "doc",
        "id": 44219
    },
    {
        "title": "events: Loop forwards to find listener in removeListener function",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n`removeListener()` in `events` module loop backwards to find listener from array. Consider the following code:\r\n```javascript\r\nconst EventEmitter = require('events')\r\n\r\nfunction pong () {\r\n  console.log('pong')\r\n}\r\n\r\nlet a = new EventEmitter()\r\n\r\na.once('ping', pong)\r\na.on('ping', pong)\r\na.removeListener('ping', pong)\r\na.emit('ping')\r\na.emit('ping')\r\n\r\n// output:\r\n// pong\r\n\r\nlet b = new EventEmitter()\r\n\r\nb.on('ping', pong)\r\nb.once('ping', pong)\r\nb.removeListener('ping', pong)\r\nb.emit('ping')\r\nb.emit('ping')\r\n\r\n// output:\r\n// pong\r\n// pong\r\n```\r\nThe output shows that for multiple same listeners, the last added one will be the first to remove (LIFO). I think maybe a \"FIFO\" logic is better for this case. And I find the commit on 5 Mar 2013 which implements \"loop backwards\" logic.\r\nhttps://github.com/nodejs/node/commit/3e64b5677f10abf849c2da762421437b89d1e11e#diff-71dcd327d0ca067b490b22d677f81966\r\nThe commit message shows this logic optimize `removeAllListeners()`.But it did effect this specific case. Maybe `removeAllListeners()` should keep \"LIFO\" logic and the backward loop optimizing, and `removeListener()` could use a forward loop.\r\n",
        "labels": "doc",
        "id": 44220
    },
    {
        "title": "Docs (N-API): napi_create_function docs inconsistent",
        "body": "* **Subsystem**: N-API\r\n\r\nSee the description of parameters:\r\nhttps://github.com/nodejs/node/blob/master/doc/api/n-api.md#napi_create_function\r\nvs.\r\nhttps://github.com/nodejs/node/blob/master/doc/api/n-api.md#napi_create_function-1\r\n\r\nThe first one appears to be correct - it takes 6 parameters, not 5.\r\n\r\nMight be beneficial to link from one part of the docs to the other, so that you don't have to maintain docs for this function in two places?",
        "labels": "doc",
        "id": 44221
    },
    {
        "title": "meta: number of approval ambiguity",
        "body": "It seems we have some ambiguity in docs.\r\n\r\nhttps://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md#code-reviews:\r\n\r\n> All pull requests must be reviewed and accepted by a Collaborator with sufficient expertise who is able to take full responsibility for the change. In the case of pull requests proposed by an existing Collaborator, an additional Collaborator is required for sign-off.\r\n\r\nhttps://github.com/nodejs/node/blob/master/doc/guides/contributing/pull-requests.md#step-10-landing\r\n\r\n> In order to land, a Pull Request needs to be reviewed and approved by at least one Node.js Collaborator and pass a CI (Continuous Integration) test run. \r\n\r\nEvidence of confusing:\r\n\r\nhttps://github.com/nodejs/node/pull/21318#issuecomment-400483863\r\n\r\nSo how many approval do we need for a PR when the author is a Collaborator?",
        "labels": "doc",
        "id": 44222
    },
    {
        "title": "Doc: Running in low memory environments (--max_old_space_size) seems to be undocumented",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThere used to be an entry (the only entry!) in the github wiki FAQ about running in low memory. It looks like the wiki has been deleted without moving its contents to other documentation / website. Consider this issue a request to have this documented. (and a complaint that the issue about deleting the wiki should not have been closed until its contents were properly moved to a maintained location, not an unadvertised archive repo).",
        "labels": "doc",
        "id": 44223
    },
    {
        "title": "test/doctool/test-make-doc.js fails if .DS_Store exists",
        "body": "```\r\n=== release test-make-doc ===\r\nPath: doctool/test-make-doc\r\nassert.js:270\r\n    throw err;\r\n    ^\r\n\r\nAssertionError [ERR_ASSERTION]: .DS_Store does not not match TOC\r\n    at Object.<anonymous> (test/doctool/test-make-doc.js:44:10)\r\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\r\n    at Module.load (internal/modules/cjs/loader.js:599:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\r\n    at startup (internal/bootstrap/node.js:260:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:584:3)\r\nCommand: out/Release/node test/doctool/test-make-doc.js\r\n```",
        "labels": "doc",
        "id": 44224
    },
    {
        "title": "Replace the use of marked with remark for doc/json generation",
        "body": "Summary: over time the node.js build process has outgrown marked and it's regular expression based processing model.  See:\r\n\r\nhttps://github.com/nodejs/node/pull/21081#issuecomment-399155282\r\nhttps://github.com/nodejs/node/pull/21081#issuecomment-399197585\r\nhttps://github.com/nodejs/node/pull/21081#issuecomment-399510285\r\n\r\nIt is time to replace it with something that involves a proper [syntax tree](https://github.com/syntax-tree/unist) which can be programmatically manipulated and from which artifacts like JSON can be confidently generated.",
        "labels": "doc",
        "id": 44225
    },
    {
        "title": "ERR_TLS_RENEGOTIATE, ERR_HTTP2_SETTINGS_CANCEL are not defined",
        "body": "While taking a look at #21435 / #21421, I did a quick and dirty check which errors are being instantiated and `/lib` and checked what happened.\r\n\r\n1.  `ERR_MISSING_DYNAMIC_INTSTANTIATE_HOOK` seems to be used in loader, but never defined.\r\nhttps://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/internal/modules/esm/loader.js#L6-L8 https://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/internal/modules/esm/loader.js#L95-L96 Not defined in [lib/internal/errors.js](https://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/internal/errors.js).\r\n\r\n2. `ERR_TLS_RENEGOTIATE` seems to be used in tls, but never defined.\r\nhttps://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/_tls_wrap.js#L47-L52 https://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/_tls_wrap.js#L572-L574 Not defined in [lib/internal/errors.js](https://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/internal/errors.js).\r\n\r\n3. `ERR_HTTP2_SETTINGS_CANCEL` seems to be used in http2, but never defined.\r\nhttps://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/internal/http2/core.js#L45-L62 https://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/internal/http2/core.js#L615-L616  Not defined in [lib/internal/errors.js](https://github.com/nodejs/node/blob/b56f65e28c02249359f4f8b682522c7d8d7c5eff/lib/internal/errors.js).\r\n\r\nThis probably affects all 10.x versions, but was not backported to earlier branches as is a semver-major.\r\n\r\nBlame points at 1d2fd8b65bacaf4401450edc8ed529106cbcfc67 / #19137.\r\n\r\n/cc @targos \r\n\r\nThis also probably needs a testcase when fixed, I do not have one atm.",
        "labels": "doc",
        "id": 44226
    },
    {
        "title": "Stream writable/readable properties are undocumented as of streams2",
        "body": "* **Version**: 10\r\n* **Platform**: N/A\r\n* **Subsystem**: doc\r\n\r\nstream.Writable#writable is no longer documented, but according to https://stackoverflow.com/a/23094413/1198896 it exists and probably _should_ be documented. Presumably the same is true for stream.Readable#readable?",
        "labels": "doc",
        "id": 44227
    },
    {
        "title": "dns.js not properly iterating through DNS array",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.11.3\r\n* **Platform**: Windows 10 Pro v1709\r\n* **Subsystem**: dns\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI'll preface this by saying that there's a significant chance I'm simply misunderstanding `dns.setServers`, but that being said, I believe I'm experiencing undesired functionality. \r\n\r\nGiven `var dnsServer1` and `var dnsServer2` are two valid IP Address strings of two valid DNS servers, and given that `var host` is a valid string which resolves to an IP on `dnsServer1` but **not** on `dnsServer2`, consider the following code:\r\n```\r\ndns.setServers([dnsServer2, dnsServer1]);\r\ndns.resolve(host, (err, records) => {\r\n    if (err) {\r\n        console.log(err);\r\n    } else {\r\n        console.log(records);\r\n});\r\n```\r\nIf the above is run, an `ENOTFOUND` error will be produced and `records` will be `undefined`. However, if the order of the array passed into `dns.setServers` is reversed, i.e. \r\n\r\n`dns.setServers([dnsServer1, dnsServer2])` \r\n\r\nand the same call to `dns.resolve` is made, no error will be produced and `records` will have resolved to a valid IP. \r\n\r\nIsn't `dns.resolve` supposed to check through each DNS IP set by `dns.setServers` until either one is able to resolve `host` or none of them are able to do so? Here it instead seems the entire resolve operation fails as soon as the first DNS IP fails, and succeeds as soon as the first DNS IP succeeds. \r\n\r\nI've tried to find more thorough documentation but couldn't find anything that said one way or the other. ",
        "labels": "doc",
        "id": 44228
    },
    {
        "title": "doc: missing cli options",
        "body": "[In the last CLI doc](https://nodejs.org/download/nightly/v11.0.0-nightly20180609ef1f130041/docs/api/cli.html), these options are missing:\r\n\r\n`--experimental-worker`\r\n`--loader`\r\n\r\nBut they are present in the source whitelist for `NODE_OPTIONS`:\r\n\r\nhttps://github.com/nodejs/node/blob/2237a8e45d5043e89cc126f7a7546f3a62f30e59/src/node.cc#L3162-L3168\r\n\r\ncc @addaleax @nodejs/modules, as I am not sure how to document them.",
        "labels": "doc",
        "id": 44229
    },
    {
        "title": "doc: explicitly mention that the explanation of an synchronous fs API live in the docs of the async API",
        "body": "* **Version**: master\r\n* **Subsystem**: fs, doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIn a lot of cases, the documentation of a synchronous fs API only links to the aysnc version of that API in order to reduce duplicated texts. \r\n\r\nFor example, `fs.readSync()` only mentions\r\n\r\n```\r\nSynchronous version of fs.read(). Returns the number of bytesRead.\r\n```\r\n\r\nWhich could be confusing to beginners since it does not explicitly mention that if they want to see a detailed explanation of the arguments, they should click the link of `fs.read()`. It would be more friendly if, for example, in the `fs.readSync()` docs we explicitly say:\r\n\r\n```\r\nSynchronous version of fs.read(). Returns the number of bytesRead.\r\n\r\nFor detailed information, see the documentation of fs.read().\r\n```\r\n\r\nAnd do the same for other `fs.*Sync` APIs if applicable.\r\n\r\nRefs: https://github.com/nodejs/node/issues/21193",
        "labels": "doc",
        "id": 44230
    },
    {
        "title": "There may be a syntax error in the nodejs napi doc.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:   nodejs 10.3.0 documents\r\n* **Platform**: \r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nhttps://nodejs.org/dist/latest-v10.x/docs/api/n-api.html#n_api_object_lifetime_management\r\n\r\nThis document may has a syntax error:\r\n\r\nIn many cases, however, it is necessary that the handles remain valid for either a shorter or longer lifespan than that of the native method. The sections which follow describe the N-API functions than can be used to change the handle lifespan from the default.\r\n\r\n...the N-API functions than can be used to change the..., than shoul change to that.",
        "labels": "doc",
        "id": 44231
    },
    {
        "title": "`vm.Script` should support timeouts",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: `10.2.1`\r\n* **Platform**: `Darwin Simens-MacBook-Pro.local 17.4.0 Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST 2017; root:xnu-4570.41.2~1/RELEASE_X86_64 x86_64`\r\n* **Subsystem**: `vm`\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nAccording to the [docs](https://nodejs.org/api/vm.html#vm_new_vm_script_code_options), you should be able to pass `timeout` when doing `new Script`. This seemingly does not work.\r\n\r\nRunning the following snippet will successfully throw an error after one second:\r\n\r\n```js\r\nconst vm = require('vm');\r\n\r\nconst script = new vm.Script('while(true){}');\r\n\r\nscript.runInContext(vm.createContext(), {timeout: 1000});\r\n```\r\n\r\nThe following will _not_:\r\n```js\r\nconst vm = require('vm');\r\n\r\nconst script = new vm.Script('while(true){}', {timeout: 1000});\r\n\r\nscript.runInContext(vm.createContext());\r\n```\r\n\r\nI did some digging (which might not be useful at all), and to my untrained eyes it looks like `new Script` constructor ignores `timeout` argument: https://github.com/nodejs/node/blob/9461f327f50c9885508392938053a62985d13259/lib/vm.js#L45-L52\r\n\r\nReported in https://github.com/jsdom/jsdom/pull/2238, /cc @TimothyGu",
        "labels": "doc",
        "id": 44232
    },
    {
        "title": "v4 still shows as LTS in docs version picker",
        "body": "will have a fix for this shortly\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: n/a\r\n* **Platform**: n/a\r\n* **Subsystem**: n/a\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n![screen shot 2018-05-22 at 6 13 51 pm](https://user-images.githubusercontent.com/6627780/40398274-f651435a-5deb-11e8-9cd2-b8cd9e3f729e.png)\r\n\r\n",
        "labels": "doc",
        "id": 44233
    },
    {
        "title": "Inconsistent documentation: hostname vs host",
        "body": "The Node.js documentation is currently rather freeform when it comes to distinguishing between `hostname` and `host`. There are arguments and properties named `host` that refer to `hostname` and their description makes as much clear. There are also arguments and properties that refer to `host` in both the name and the description, despite actually intending to represent the `hostname`.\r\n\r\nThis can without any doubt create confusion for end users but also for contributors. For a recent example see: https://github.com/nodejs/node/pull/20875 or https://github.com/nodejs/node/pull/20493\r\n\r\nI think it would be nice if we could slowly update the the documentation and code to be more clear about this. While we cannot change property names on options objects, argument names can certainly be changed and documentation can be updated.\r\n\r\nSome example entries:\r\n\r\nhttps://nodejs.org/dist/latest-v10.x/docs/api/tls.html#tls_tls_checkserveridentity_host_cert\r\nhttps://nodejs.org/dist/latest-v10.x/docs/api/tls.html#tls_tls_connect_port_host_options_callback\r\nhttps://nodejs.org/dist/latest-v10.x/docs/api/tls.html#tls_tls_connect_options_callback\r\nhttps://nodejs.org/dist/latest-v10.x/docs/api/net.html#net_server_listen_options_callback\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44234
    },
    {
        "title": "doc: outdated link",
        "body": "https://nodejs.org/api/fs.html#fs_availability section contains [`FSEvents`](https://developer.apple.com/library/mac/documentation/Darwin/Conceptual/FSEvents_ProgGuide/Introduction/Introduction.html#//apple_ref/doc/uid/TP40005289-CH1-SW1) link which is currently redirected to a page that seems unrelated.\r\n\r\n@nodejs/platform-macos, can you check and fix or suggest a new link?",
        "labels": "doc",
        "id": 44235
    },
    {
        "title": "Inconsistent styling of deprecated items",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nThere are some places in the documentation where deprecated items are not especially highlighted/styled as being deprecated, whereas others have both the red 'deprecated' label in the outline at the top of the page and the big red bar in the actual description. This is the case, no matter what level of deprecation is involved (doc-only, runtime, etc.).\r\n\r\nFor example: `crypto.DEFAULT_ENCODING` and `crypto.fips` are both deprecated, but are not highlighted as such, unlike `crypto.createCipher` which *is*.\r\n\r\nThere may be other instances of this throughout all of the documentation, but these are the first ones I noticed.",
        "labels": "doc",
        "id": 44236
    },
    {
        "title": "doc: add doc for tty writes ( readline.js / REPL )",
        "body": "The readline interface is missing the keybindings docs for possible input to tty. Attaching a list of possible bindings to be added to the doc.\r\n\r\n| KeyBindings        | Description       | \r\n| ------------- |:-------------:|\r\n| `ctrl+shift+backspace`   | delete line left |\r\n| `ctrl+shift+delete`   | delete line right |\r\n| `ctrl+c`   | emits SIGINT |\r\n| `ctrl+h`   | delete left |\r\n| `ctrl+d`   | delete right or EOF |\r\n| `ctrl+u` | delete from current to line start |\r\n| `ctrl+k` | delete from current to end of line |\r\n| `ctrl+a` | goto start of line |\r\n| `ctrl+e` | goto to end of line |\r\n| `ctrl+b` | back one character |\r\n| `ctrl+f` | forward one character |\r\n| `ctrl+l` | clear screen |\r\n| `ctrl+n` | next history item |\r\n| `ctrl+p` | prev history item |\r\n| `ctrl+z` | (need clarification) |\r\n| `ctrl+w` or `ctrl+backspace` | delete backwards to a word boundary  |\r\n| `ctrl+delete` | delete forward to a word boundary |\r\n| `ctrl+left` | word left |\r\n| `ctrl+right` | word right |\r\n| `meta+b` | word left |\r\n| `meta+f` | word right |\r\n| `meta+d` or `meta+delete`| delete word right |\r\n| `meta+backspace` | delete word left |\r\n\r\n\r\n",
        "labels": "doc",
        "id": 44237
    },
    {
        "title": "tools: strange workaround in doctools",
        "body": "1. `tools/doc/package.json` requires `\"js-yaml\": \"^3.5.2\"`:\r\n\r\n  https://github.com/nodejs/node/blob/6fd8022641da3e58fa44f339457110b15813c9be/tools/doc/package.json#L13\r\n\r\n2. `tools/doc/node_modules/js-yaml` contains only dummy `index.js` with reexport of `js-yaml` from ESLint dependency (so the version from the above-mentioned requirement cannot be checked anyway?):\r\n\r\n  https://github.com/nodejs/node/blob/6fd8022641da3e58fa44f339457110b15813c9be/tools/doc/node_modules/js-yaml/index.js#L8-L14\r\n\r\n\r\nWhy not delete `js-yaml` from `tools/doc/package.json`, then delete `tools/doc/node_modules/js-yaml` and then require `js-yaml` straight from the ESLint dependency? It is only required here:\r\n\r\nhttps://github.com/nodejs/node/blob/20509ebee681233443ebc7dc1b58c2fab6d2b12f/tools/doc/common.js#L3\r\n",
        "labels": "doc",
        "id": 44238
    },
    {
        "title": "Wrong stability state of N-API in the addons docs",
        "body": "Looks like the stability state of N-API [in the addons docs](https://github.com/nodejs/node/blob/master/doc/api/addons.md) is outdated\r\n\r\n> Stability: 1 - Experimental\r\n\r\nShouldn't it be \r\n\r\n> Stability: 2 - Stable\r\n\r\n?",
        "labels": "doc",
        "id": 44239
    },
    {
        "title": "Docs bug in https://nodejs.org/api/child_process.html ?",
        "body": "I tried this example on MacOS, node.js version 9:\r\n\r\nhttps://nodejs.org/api/child_process.html#child_process_example_sending_a_socket_object\r\n\r\nafter the socket in the child process calls:\r\n ```js\r\nsocket.end(`Request handled with ${process.argv[2]} priority`);\r\n```\r\n\r\nthe browser says it represents an invalid HTTP response.\r\n\r\nPerhaps the example is missing something important?\r\n\r\nI tried the example, in this codebase:\r\nhttps://github.com/ORESoftware/flub/blob/master/test/index.js\r\n\r\nit didn't work for me.\r\n",
        "labels": "doc",
        "id": 44240
    },
    {
        "title": "Stream pipe documentation is confusing",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10\r\n* **Platform**: n/a\r\n* **Subsystem**: stream\r\n\r\nNewbie to using NodeJS + NodeJS streams and I find the documentation very confusing, especially around pipes. I get the idea of piping streams but the documentation on `pipe` says it is on `Readable`, accepts a `Writable`, and returns a `Writable` and then mentions that it is possible to chain calls to `pipe` (e.g. `r.pipe(z).pipe(w);`). However it makes **zero** mention of how this is possible in the document. `pipe` returns a `Writable`, yet according to the document `Writable` has no `pipe` method. So how can they be chained?\r\n\r\nFiddling around in node inspecting things I see that the `stream` package is a class that both `Readable` and `Writable` inherit from. Perhaps having the documentation actually show this hierarchy and have more \"standard\" class documentation would help?\r\n\r\nMaybe this isn't shown because piping a `Writable` stream to another stream makes no sense. What are you piping? You can't read from it. Unless you actually can and the idea of a `Writable` stream is a lie and everything is a `Duplex`? Or does it just pass the data over that writable and on to the next stream? Maybe this just a general design issue with Node streams? Or maybe there's an undocumented requirement that in order to chain `pipe` the argument to `pipe` must be a `Duplex`? (Digging further that appears to be the case - `Writable` has a `pipe` method that throws when called because it is not readable).\r\n\r\nSite note: The example in `pipe` pipes through a `Gzip` object. But the documentation for `Gzip` is non existent and makes no mention that is a stream of any kind except in the small examples at the top of the zlib page. It seems pretty important to me to know that it is not only a stream, but a `Transform` that zips the input stream and outputs the zipped data.\r\n\r\nI'm not looking for help using streams or gzip or anything else. Just noting that as someone totally new the documentation is in need of improvement. Especially for something that is presumably very core to Node as streams. Basically clearer documentation around `pipe` and its requirements (chaining requires streams be `Duplex`s) and what classes are streams - specifically what kind of stream (like `Gzip` is a `Transform`). More generally I'd say the \"classic\" documentation of documenting classes, methods, and hierarchies is more useful than entirely example based documentation.\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44241
    },
    {
        "title": "doc: napi_create_range_error has incorrect prototype",
        "body": "Function napi_create_range_error in documentation has prototype:\r\n```c\r\nNODE_EXTERN napi_status napi_create_range_error(napi_env env,\r\n                                                napi_value code,\r\n                                                const char* msg,\r\n                                                napi_value* result);\r\n```\r\nwhere `msg` has type `const char*`. But according to `node_api.h` the prototype should be:\r\n```c\r\nNAPI_EXTERN napi_status napi_create_range_error(napi_env env,\r\n                                                napi_value code,\r\n                                                napi_value msg,\r\n                                                napi_value* result);\r\n```\r\nwith `msg` having type `napi_value`.",
        "labels": "doc",
        "id": 44242
    },
    {
        "title": "Status of the spawned process is null",
        "body": "* **Version**: <s>v8.5.0</s> v10.0.0\r\n* **Platform**: `Linux tio2 4.15.13-300.fc27.x86_64 #1 SMP Mon Mar 26 19:06:57 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: [child_process](https://nodejs.org/api/child_process.html)\r\n\r\nIn the documentation for `child_process.spawnSync` it says that the `status` property of the returned object is of type `<number>` and it nowhere mentions that it may be `null`. However, the following script prints `null` (expected is 139):\r\n\r\n```js\r\n'use strict';\r\n\r\nvar fs = require('fs');\r\nvar path = require('path');\r\nvar os = require('os');\r\nvar cp = require('child_process');\r\n\r\nvar dir = path.join(os.tmpdir(), `${Date.now()}`);\r\nfs.mkdirSync(dir);\r\n\r\nvar name = 'test.cc';\r\nvar file = path.join(dir, name);\r\nfs.writeFileSync(file, 'int main(){++*(int*)0;}');\r\ncp.spawnSync('gcc', [file], {cwd: dir});\r\n\r\nvar files = fs.readdirSync(dir);\r\nvar output = files.find(file => file !== name);\r\nvar obj = cp.spawnSync(path.join(dir, output));\r\n\r\nconsole.log(obj.status);\r\n```\r\n\r\nOn windows it prints `3221225477` which is expected result on windows.",
        "labels": "doc",
        "id": 44243
    },
    {
        "title": "test: Cannot find module 'unified-args'",
        "body": "After `make test -j4` I get:\r\n\r\n```\r\nRunning Markdown linter on misc docs...\r\nRunning Markdown linter on docs...\r\ninternal/modules/cjs/loader.js:573\r\n    throw err;\r\n    ^\r\n\r\nError: Cannot find module 'unified-args'\r\n    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:571:15)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:497:25)\r\n    at Module.require (internal/modules/cjs/loader.js:626:17)\r\n    at require (internal/modules/cjs/helpers.js:20:18)\r\n    at Object.<anonymous> (/Users/martin/projects/node/tools/remark-cli/cli.js:13:13)\r\n    at Module._compile (internal/modules/cjs/loader.js:678:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:689:10)\r\n    at Module.load (internal/modules/cjs/loader.js:589:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:528:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:520:3)\r\nmake[3]: *** [tools/.miscmdlintstamp] Error 1\r\nmake[3]: *** Waiting for unfinished jobs....\r\ninternal/modules/cjs/loader.js:573\r\n    throw err;\r\n    ^\r\n\r\nError: Cannot find module 'unified-args'\r\n    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:571:15)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:497:25)\r\n    at Module.require (internal/modules/cjs/loader.js:626:17)\r\n    at require (internal/modules/cjs/helpers.js:20:18)\r\n    at Object.<anonymous> (/Users/martin/projects/node/tools/remark-cli/cli.js:13:13)\r\n    at Module._compile (internal/modules/cjs/loader.js:678:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:689:10)\r\n    at Module.load (internal/modules/cjs/loader.js:589:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:528:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:520:3)\r\nmake[3]: *** [tools/.docmdlintstamp] Error 1\r\nmake[2]: *** [lint] Error 2\r\nmake[1]: *** [test-doc] Error 2\r\nmake: *** [test] Error 2\r\n```\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: [current master branch](https://github.com/nodejs/node/tree/2d609c5d53a4394bd2a9c6e15ab074c3cc2039a2)\r\n* **Platform**: macOS High Sierra 10.13.4\r\n* **Subsystem**: test\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44244
    },
    {
        "title": "require.resolve API change",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nv8.8.0 - v8.9.0 compatibility\r\n* **Platform**:\r\nall\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIn 8.9, a second `options` argument was added to `require.resolve`, which can change the search path. In pre-8.9, such an argument is silently ignored. That seems like a bad API policy, as people who read current docs will expect the function to use the provided search path, and people who run this on older Node VMs will end up loading the wrong files.\r\n\r\nI'd suggest (a) adding a warning that the argument is ignored in earlier versions, and (b) providing a newly named function (like `require.resolveFrom`) that accepts the paths and and doesn't exist in versions that don't support it.\r\n\r\nRequire search paths are too critical to have same-named functions with such different semantics.\r\n\r\n\r\n",
        "labels": "doc",
        "id": 44245
    },
    {
        "title": "doc: update 'openssl list-cipher-algorithms' to 'openssl list -cipher-algorithms'.",
        "body": "Refs: #20400.\r\n\r\n- [x] documentation is changed or added\r\n- [x] commit message follows [commit guidelines]\r\n\r\n",
        "labels": "doc",
        "id": 44246
    },
    {
        "title": "ecdh.computeSecret needs to clearly specify that it returns X coefficient",
        "body": "So current version of the ECDH.computeSecret is misleading. It return 32 bytes, which misleads thinking that it's a private coefficient, where it is a X coefficient of the shared secret. This needs to be reflected in the documentation",
        "labels": "doc",
        "id": 44247
    },
    {
        "title": "NODE_EXTRA_CA_CERTS cannot be set in code or relative",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nv9.11.1\r\n* **Platform**:\r\nDarwin sheerun.dev 17.4.0 Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST 2017; root:xnu-4570.41.2~1/RELEASE_X86_64 x86_64 i386 MacBookPro12,1 Darwin\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen I start my server with\r\n\r\n```\r\nNODE_EXTRA_CA_CERTS=/Users/sheerun/Source/Ada/search/.certs/ca.crt bin/start\r\n```\r\n\r\nand in code make request to http server that serves with given certificate, all is good\r\n\r\nBut when I set it at the beginning of `bin/start` as so:\r\n\r\n```\r\nprocess.env.NODE_EXTRA_CA_CERTS = \"/Users/sheerun/Source/Ada/search/.certs/ca.crt\"\r\n```\r\n\r\nthen node complains that there's \"self signed certificate in certificate chain\".\r\n\r\nParticularly NODE_EXTRA_CA_CERTS doesn't work when I use `dotenv` package and set NODE_EXTRA_CA_CERTS in `.env` file.\r\n\r\nAlso, it seems NODE_EXTRA_CA_CERTS doesn't allow relative path, just absolute.\r\n\r\nI think both of these issues should be addressed or at least documented with reasons why.",
        "labels": "doc",
        "id": 44248
    },
    {
        "title": "N-API documentation needs review (misleading / wrong code samples, etc)",
        "body": "I've been reading the [N-API docs](https://nodejs.org/api/n-api.html#) to understand it and it needs some cleanup. I'm not sure if all of these notes are still an issue in [master](https://github.com/nodejs/node/blob/master/doc/api/n-api.md).\r\n\r\nI also somewhere saw a line which was missing its `;`, and now I can't find it.\r\n\r\n#### [N-API](https://nodejs.org/api/n-api.html#n_api_n_api)\r\n\r\n>  These wrappers are not part of N-API, nor will they be maintained as part of Node.js. One such example is: node-api.\r\n\r\n- node-api has been renamed [node-addon-api](https://github.com/nodejs/node-addon-api), and its repo has been renamed.\r\n\r\n#### [napi_status](https://nodejs.org/api/n-api.html#n_api_napi_status)\r\n\r\n- The typedef described in the documentation doesn't match the definition in the [10.0.0 header file](https://github.com/nodejs/node/blob/v10.0.0/src/node_api_types.h#L60-L76).\r\n\r\n#### [napi_create_error](https://nodejs.org/api/n-api.html#n_api_napi_create_error)\r\n\r\n- Weird formatting of text 'be associated with the error':\r\n\r\n<img width=\"820\" alt=\"image\" src=\"https://user-images.githubusercontent.com/47413/39424582-b1fc025e-4cba-11e8-8a51-bb51a892b22a.png\">\r\n\r\n#### [Making handle lifespan shorter ...](https://nodejs.org/api/n-api.html#n_api_making_handle_lifespan_shorter_than_that_of_the_native_method)\r\n\r\n```c\r\n  napi_status status = napi_get_element(e, object, i, &result);\r\n```\r\n\r\n* `e` -> `env`. Likewise in the second example in this block, where the environment is referred to as `env` in calls to some methods but not `napi_get_element`.\r\n\r\n#### [Module registration](https://nodejs.org/api/n-api.html#n_api_module_registration):\r\n\r\n> To add the method hello as a function ...\r\n\r\n```c\r\nnapi_value Init(napi_env env, napi_value exports) {\r\n  napi_status status;\r\n  napi_property_descriptor desc =\r\n    {\"hello\", Method, 0, 0, 0, napi_default, 0};\r\n  if (status != napi_ok) return NULL;\r\n  status = napi_define_properties(env, exports, 1, &desc);\r\n  if (status != napi_ok) return NULL;\r\n  return exports;\r\n}\r\n```\r\n\r\n* `status` is checked before it is assigned\r\n* `napi_property_descriptor` fields are (`utf8name`, `name`, `method`, `getter`, `setter`, `value`, `attr`, `data`). There are 8 of them, not 7. Unless I'm missing something, the code should be `{\"hello\", 0, Method, 0, 0, 0, napi_default, 0}`. But imho it should use `NULL` instead of 0. In modern C I would simply write this as `{.utf8name=\"hello\", .method=Method}`, ~~although I'm not sure if the VC++ compiler can handle struct property initializers yet.~~ The internet says [yes](https://news.ycombinator.com/item?id=8030433)\r\n* To make it more obvious how to extend the example, it might be better to make `desc` an array of `napi_property_descriptor` objects. Although the class example does that... so maybe its not super important.\r\n\r\n> To define a class ...\r\n\r\n```c\r\nnapi_value Init(napi_env env, napi_value exports) {\r\n  napi_status status;\r\n  napi_property_descriptor properties[] = {\r\n    { \"value\", NULL, GetValue, SetValue, 0, napi_default, 0 },\r\n    DECLARE_NAPI_METHOD(\"plusOne\", PlusOne),\r\n    DECLARE_NAPI_METHOD(\"multiply\", Multiply),\r\n  };\r\n  // ...\r\n```\r\n\r\n* Again, the property descriptor is invalid. It should be `{ \"value\", NULL, 0, GetValue, SetValue, 0, napi_default, 0 },`.\r\n* `DECLARE_NAPI_METHOD` is not a real thing - it does not exist anywhere else in the documentation or header files. This example should either define it locally or not use it.\r\n\r\n\r\n#### [napi_property_descriptor](https://nodejs.org/api/n-api.html#n_api_napi_property_descriptor)\r\n\r\n* The order of the documentation for the `data` and `attributes` fields should be swapped\r\n",
        "labels": "doc",
        "id": 44249
    },
    {
        "title": "fs: promises have undocumented write(string,â€¦) method",
        "body": "* **Version**: 10.0.0, master\r\n* **Subsystem**: fs\r\n\r\nNon-promises API has two variants documented: [Buffer](https://github.com/nodejs/node/blob/master/doc/api/fs.md#fswritefd-buffer-offset-length-position-callback), [string](https://github.com/nodejs/node/blob/master/doc/api/fs.md#fswritefd-string-position-encoding-callback).\r\n\r\nPromises API has only Buffer variants documented: [method](https://github.com/nodejs/node/blob/master/doc/api/fs.md#fspromiseswritefilehandle-buffer-offset-length-position), [class method](https://github.com/nodejs/node/blob/master/doc/api/fs.md#filehandlewritebuffer-offset-length-position).\r\n\r\nThis code works, but it's undocumented behavior:\r\n```js\r\nconst fs = require('fs/promises');\r\nconst fd = await fs.open('temp.txt', 'w+');\r\nfd.write('test\\n');\r\n```",
        "labels": "doc",
        "id": 44250
    },
    {
        "title": "Update openssl command to list digest algos in docs",
        "body": "Documentation update in https://nodejs.org/api/crypto.html#crypto_crypto_createhash_algorithm_options\r\n\r\n> The algorithm is dependent on the available algorithms supported by the version of OpenSSL on the platform. Examples are 'sha256', 'sha512', etc. On recent releases of OpenSSL, **openssl list-message-digest-algorithms** will display the available digest algorithms.\r\n\r\nReplace the openssl command\r\n```\r\nopenssl list-message-digest-algorithms\r\n```\r\nwith \r\n```\r\nopenssl list -digest-algorithms\r\n```\r\n\r\nTested with:\r\n```\r\n$ openssl version\r\nOpenSSL 1.1.0h  27 Mar 2018\r\n```\r\n\r\n",
        "labels": "doc",
        "id": 44251
    },
    {
        "title": "Making `util.inspect` recurse indefinitely by passing `Infinity` instead of `null`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.0.0\r\n* **Platform**: Microsoft Windows [Version 10.0.16299.371]\r\n* **Subsystem**: util\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI'm wondering about the `depth` option for [`util.inspect`](https://nodejs.org/api/util.html#util_util_inspect_object_options).\r\n\r\nThe documentation states \"_To make it recurse indefinitely, pass `null`._\"\r\n\r\nI think it would be more intuitive to pass `Infinity` to make it recurse indefinitely.\r\n\r\nWould a change like this be accepted?",
        "labels": "doc",
        "id": 44252
    },
    {
        "title": "doc: `fs.write` accepts strings to write but it's not documented",
        "body": "* **Version**: master\r\n* **Subsystem**: fs, doc\r\n \r\n<!-- Enter your issue details below this comment. -->\r\n\r\n[`fs.write(fd, buffer[, offset[, length[, position]]], callback)`](https://nodejs.org/api/fs.html#fs_fs_write_fd_buffer_offset_length_position_callback) and [`fs.writeSync(fd, buffer[, offset[, length[, position]]])`](https://nodejs.org/api/fs.html#fs_fs_writesync_fd_buffer_offset_length_position) actually take strings as the `buffer` argument, and `fs.write` will pass the original string back to the callback if the write is successful.\r\n\r\nShould it be documented? I suspect there are already quite a few people using it in the user land.\r\n",
        "labels": "doc",
        "id": 44253
    },
    {
        "title": "TLS docs still mention SSLv3",
        "body": "See https://nodejs.org/dist/latest-v10.x/docs/api/tls.html#tls_tls_createsecurecontext_options and also search the page for `sslv3`. They should be removed as Node hasn't supported SSLv3 for a couple of years now.",
        "labels": "doc",
        "id": 44254
    },
    {
        "title": "Documentation for Buffer#includes is not accurate",
        "body": "* **Version**: node 8.10.0\r\n* **Platform**: Linux 4.13.0-38 (x86_64)\r\n* **Subsystem**: Buffer\r\n\r\nFirst argument for `Buffer#includes` is documented as:\r\n\r\n> value `<string> | <Buffer> | <integer>` What to search for.\r\n\r\nThis excludes `UInt8Array` which is often accepted as an argument for `Buffer` methods.\r\n\r\nThe problem with this is that in practice this API accepts `Uint8Array` objects as arguments:\r\n```javascript\r\n> Buffer.from([1, 2, 3]).includes(Uint8Array.from([1, 2]))\r\ntrue\r\n```\r\n\r\nMy suggestion is that the documentation should be updated to reflect this.",
        "labels": "doc",
        "id": 44255
    },
    {
        "title": "Migrate or delete crypto/OpenSSL wiki doc?",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: n/a\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nNot sure if there's consensus on eliminating the wiki or not, but if we do, should https://github.com/nodejs/node/wiki/Crypto-Performance-Notes-for-OpenSSL-1.0.2a-on-iojs-v1.8.0 be migrated somewhere (docs or the website) or is it OK to let it get deleted?\r\n\r\n/cc @shigeki @nodejs/crypto ",
        "labels": "doc",
        "id": 44256
    },
    {
        "title": "doc: all.html is seriously broken link-wise",
        "body": "#### Cause of the state\r\n\r\n`all.html` is assembled from [`all.md`](https://github.com/nodejs/node/blob/master/doc/api/all.md) by preliminary gluing all `.md` sources in one blob as they are. This is made by chain of `tools\\doc\\generate.js` -> `tools\\doc\\preprocess.js` -> `tools\\doc\\html.js`.\r\n\r\nThat means that all the bottom references are merged as they are without collisions resolved.\r\n\r\n#### Types of collisions\r\n\r\nCurrently, we have many homonym bottom references in `.md` files. They can be grouped into 3 types by the severity of collision impact:\r\n\r\n1. Completely identical bottom references with no danger, like:\r\n\r\n```md\r\n[Android building]: https://github.com/nodejs/node/blob/master/building.md#androidandroid-based-devices-eg-firefox-os\r\n[Android building]: https://github.com/nodejs/node/blob/master/building.md#androidandroid-based-devices-eg-firefox-os\r\n\r\n[Common System Errors]: errors.html#errors_common_system_errors\r\n[Common System Errors]: errors.html#errors_common_system_errors\r\n\r\n[debugger]: debugger.html\r\n[debugger]: debugger.html\r\n\r\n[MSDN-Rel-Path]: https://msdn.microsoft.com/en-us/library/windows/desktop/aa365247.aspx#fully_qualified_vs._relative_paths\r\n[MSDN-Rel-Path]: https://msdn.microsoft.com/en-us/library/windows/desktop/aa365247.aspx#fully_qualified_vs._relative_paths\r\n\r\n[Native Abstractions for Node.js]: https://github.com/nodejs/nan\r\n[Native Abstractions for Node.js]: https://github.com/nodejs/nan\r\n\r\n...Many of them...\r\n```\r\n\r\n2. Bottom references with negligible differences (producing the same result by redirecting, referring to the same section inside `all.html` or a separate `[module].html` doc, referring the doc (above doc TOC) or its top heading (below doc TOC)):\r\n\r\n```md\r\n[Chrome Debugging Protocol]: https://chromedevtools.github.io/debugger-protocol-viewer\r\n[Chrome Debugging Protocol]: https://chromedevtools.github.io/debugger-protocol-viewer/\r\n\r\n[`'finish'`]: #stream_event_finish\r\n[`'finish'`]: stream.html#stream_event_finish\r\n\r\n[`'uncaughtException'`]: #process_event_uncaughtexception\r\n[`'uncaughtException'`]: process.html#process_event_uncaughtexception\r\n[`'uncaughtException'`]: process.html#process_event_uncaughtexception\r\n\r\n[`__dirname`]: #modules_dirname\r\n[`__dirname`]: modules.html#modules_dirname\r\n\r\n[`__filename`]: #modules_filename\r\n[`__filename`]: modules.html#modules_filename\r\n\r\n[REPL]: repl.html\r\n[REPL]: repl.html#repl_repl\r\n\r\n[stream]: stream.html\r\n[stream]: stream.html\r\n[stream]: stream.html\r\n[Stream]: stream.html#stream_stream\r\n\r\n[TTY]: tty.html\r\n[TTY]: tty.html#tty_tty\r\n\r\n...Many of them...\r\n```\r\n\r\n3. Bottom references referring to different places, either close enough (doc top vs doc main class) or completely different (not the same docs or different outer pages). This is all of them I can collect for now:\r\n\r\n<details>\r\n<summary>Almost 30 collisions:</summary>\r\n\r\n```md\r\n[Caveats]: #crypto_support_for_weak_or_compromised_algorithms\r\n[Caveats]: #fs_caveats\r\n\r\n[Duplex]: #stream_class_stream_duplex\r\n[Duplex]: stream.html#stream_duplex_and_transform_streams\r\n\r\n[ICU]: http://icu-project.org/\r\n[ICU]: intl.html#intl_internationalization_support\r\n[ICU]: intl.html#intl_options_for_building_node_js\r\n\r\n[Punycode]: https://tools.ietf.org/html/rfc3492\r\n[Punycode]: https://tools.ietf.org/html/rfc5891#section-4.4\r\n\r\n[Readable]: #stream_class_stream_readable\r\n[Readable]: stream.html#stream_readable_streams\r\n[Readable]: stream.html#stream_readable_streams\r\n\r\n[Writable Stream]: stream.html#stream_class_stream_writable\r\n[Writable Stream]: stream.html#stream_class_stream_writable\r\n[Writable Stream]: stream.html#stream_writable_streams\r\n\r\n[Writable]: #stream_class_stream_writable\r\n[Writable]: stream.html#stream_writable_streams\r\n[Writable]: stream.html#stream_writable_streams\r\n\r\n[`'checkContinue'`]: #http2_event_checkcontinue\r\n[`'checkContinue'`]: #http_event_checkcontinue\r\n\r\n[`'close'`]: #dgram_event_close\r\n[`'close'`]: #net_event_close\r\n\r\n[`'data'`]: #net_event_data\r\n[`'data'`]: #stream_event_data\r\n\r\n[`'drain'`]: #net_event_drain\r\n[`'drain'`]: #stream_event_drain\r\n\r\n[`'end'`]: #net_event_end\r\n[`'end'`]: #stream_event_end\r\n\r\n[`'error'`]: #child_process_event_error\r\n[`'error'`]: #net_event_error_1\r\n\r\n[`'exit'`]: #child_process_event_exit\r\n[`'exit'`]: #process_event_exit\r\n[`'exit'`]: process.html#process_event_exit\r\n\r\n[`'message'`]: child_process.html#child_process_event_message\r\n[`'message'`]: process.html#process_event_message\r\n\r\n[`'request'`]: #http2_event_request\r\n[`'request'`]: #http_event_request\r\n\r\n[`Agent`]: #https_class_https_agent\r\n[`Agent`]: #http_class_http_agent\r\n\r\n[`Buffer`]: buffer.html\r\n[`Buffer`]: buffer.html\r\n[`Buffer`]: buffer.html#buffer_buffer\r\n[`Buffer`]: buffer.html#buffer_class_buffer\r\n[`Buffer`]: buffer.html#buffer_class_buffer\r\n\r\n[`ChildProcess`]: #child_process_child_process\r\n[`ChildProcess`]: child_process.html#child_process_class_childprocess\r\n\r\n[`EventEmitter`]: events.html\r\n[`EventEmitter`]: events.html\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n[`EventEmitter`]: events.html#events_class_eventemitter\r\n\r\n[`require()`]: globals.html#globals_require\r\n[`require()`]: modules.html#modules_require\r\n\r\n[`response.end()`]: #http2_response_end_data_encoding_callback\r\n[`response.end()`]: #http_response_end_data_encoding_callback\r\n\r\n[`response.setHeader()`]: #http2_response_setheader_name_value\r\n[`response.setHeader()`]: #http_response_setheader_name_value\r\n\r\n[`response.socket`]: #http2_response_socket\r\n[`response.socket`]: #http_response_socket\r\n\r\n[`response.write()`]: #http2_response_write_chunk_encoding_callback\r\n[`response.write()`]: #http_response_write_chunk_encoding_callback\r\n\r\n[`response.writeContinue()`]: #http2_response_writecontinue\r\n[`response.writeContinue()`]: #http_response_writecontinue\r\n\r\n[`response.writeHead()`]: #http2_response_writehead_statuscode_statusmessage_headers\r\n[`response.writeHead()`]: #http_response_writehead_statuscode_statusmessage_headers\r\n\r\n[`server.close()`]: #net_server_close_callback\r\n[`server.close()`]: net.html#net_event_close\r\n[`server.close()`]: net.html#net_server_close_callback\r\n\r\n[`URL`]: url.html#url_class_url\r\n[`URL`]: url.html#url_class_url\r\n[`URL`]: url.html#url_the_whatwg_url_api\r\n[`URL`]: url.html#url_the_whatwg_url_api\r\n[`URL`]: url.html#url_the_whatwg_url_api\r\n```\r\n</details><br>\r\n\r\n#### What are collision results?\r\n\r\n1. The first type of collision is completely safe.\r\n\r\n2. The second type is safe data-wise but may be confusing or may have performance penalty: `all.html` doc is huge and links referring now internal section, now another document may baffle or cause regular reloading of the big page (even cached, it overload the browser significantly during reparsing). But it seems we cannot do anything simple to resolve this.\r\n\r\n3. The third collision is severe and may cause many misunderstandings. The reference from the last included doc wins and rewrites all previous links. This can be easily checked:\r\n\r\n* `Caveats` link in [`crypto.getDiffieHellman(groupName)`](https://nodejs.org/download/nightly/v10.0.0-nightly201804175eb9f3c91c/docs/api/crypto.html#crypto_crypto_getdiffiehellman_groupname) section inside the `crypto.html` doc refers to the `crypto.html#crypto_support_for_weak_or_compromised_algorithms`.\r\n* `Caveats` link in [`fs.watch(filename[, options][, listener])`](https://nodejs.org/download/nightly/v10.0.0-nightly201804175eb9f3c91c/docs/api/fs.html#fs_fs_watch_filename_options_listener) section inside the `fs.html` doc refers to the `fs.html#fs_caveats`.\r\n* `Caveats` links in both [`crypto.getDiffieHellman(groupName)`](https://nodejs.org/download/nightly/v10.0.0-nightly201804175eb9f3c91c/docs/api/all.html#crypto_crypto_getdiffiehellman_groupname) and [`fs.watch(filename[, options][, listener])`](https://nodejs.org/download/nightly/v10.0.0-nightly201804175eb9f3c91c/docs/api/all.html#fs_fs_watch_filename_options_listener) sections inside the `all.html` doc refer to the same `all.html#fs_caveats` place, which is wrong for the `crypto` module part.\r\n\r\n#### What can we do?\r\n\r\n* Manually diverge at least all the links from the third type. It may produse too verbose and cumbersome link texts and this does not prevent future collisions, but this is a quick workaround.\r\n* Set doc linting rule to prevent inter-docs link collisions.\r\n* Make doctools to pretransform links inside docs before merging. Our internal URL hash system is safe enough for that.\r\n\r\nI can do the first job if this is wanted, but others are currently above my knowledge of doc system tooling.\r\n\r\nMaybe there are some other ways to fix this.",
        "labels": "doc",
        "id": 44257
    },
    {
        "title": "documentation of --napi-modules",
        "body": "Looks like the documentation for `--napi-modules` doesn't match the `node --help` output.\r\n\r\nhttps://github.com/nodejs/node/blob/237aa7e9ae850bbaf39563b368bc617468f2136d/src/node.cc#L3493-L3494\r\n\r\nhttps://github.com/nodejs/node/blob/237aa7e9ae850bbaf39563b368bc617468f2136d/doc/node.1#L119-L121\r\n\r\nhttps://github.com/nodejs/node/blob/237aa7e9ae850bbaf39563b368bc617468f2136d/doc/api/cli.md#L134-L140\r\n\r\nhttps://github.com/nodejs/node/pull/14902 removed the description from `cli.md` but not from `node.1`. https://github.com/nodejs/node/pull/19878 [spotted the discrepancy](https://github.com/nodejs/node/pull/19878#issuecomment-379587988) between the files and added it back. I think I'd favour keeping the option listed in the docs, but with the description changed to match the `--help` output (or similar words) -- It's definitely [no longer experimental](https://github.com/nodejs/node/pull/19262). \r\n\r\ncc @nodejs/n-api ",
        "labels": "doc",
        "id": 44258
    },
    {
        "title": "process.release.headersUrl: distributors might want to provide an absolute file url",
        "body": "In which case it wouldn't be a .tar.gz file, but a directory (for example file:///usr/include/nodejs on debian).\r\nThis would be useful for configurability of node-gyp, as explained in https://github.com/nodejs/node-gyp/issues/1415.\r\n\r\nOn debian we build nodejs against potentially different versions of shared libraries required by nodejs.\r\nTheir respective headers are all available in system-installed places for gyp to discover.\r\nUntil now it didn't change anything, however it becomes problematic when building a module using openssl: node-gyp pulls the \"official\" nodejs 8 headers with openssl 1.0 headers, but the system-installed node has been built against openssl 1.1.\r\n\r\nOf course, the node-gyp debian package is already patched so that it uses the right include directory.\r\nBut that doesn't prevent npm-installed modules from installing their own node-gyp version which will download the \"wrong\" headers.\r\n\r\ncc-ing @nodejs/delivery-channels here again since many distributions are already using openssl 1.1.",
        "labels": "doc",
        "id": 44259
    },
    {
        "title": "doc: add section in fs to document mode argument",
        "body": "* **Version**: master\r\n* **Platform**: N/A\r\n* **Subsystem**: fs\r\n\r\nI noticed this while reviewing #20042\r\nThe description of `mode` argument is repeated in [`fs.access()`](https://nodejs.org/api/fs.html#fs_fs_access_path_mode_callback) and [`fs.accessSync()`](https://nodejs.org/api/fs.html#fs_fs_accesssync_path_mode), and can be moved to a single location.\r\n\r\nWDYT @nodejs/fs? This would be a good first issue for a new contributor.",
        "labels": "doc",
        "id": 44260
    },
    {
        "title": "State explicitly in docs that 'close' does not take any arguments",
        "body": "In the `http2` module, the `Http2Session` class emits an event named `close`, which is documented at https://github.com/nodejs/node/blob/master/doc/api/http2.md#event-close.\r\n\r\nAs evident from the following function from `lib/internal/http2/core.js`, the event does not expect any arguments:\r\n\r\n```js\r\nfunction emitClose(self, error) {\r\n  if (error)\r\n    self.emit('error', error);\r\n  self.emit('close');\r\n}\r\n```\r\n\r\nHowever, the current docs do a poor job of communicating this, therefore creating confusion.\r\n\r\nThus, the fact that the `close` event does not expect arguments should be explicitly mentioned in the docs.\r\n\r\nThe exact source can be found at: https://github.com/nodejs/node/blob/6376d430f442486f98bf145dc62a4e7424f10257/doc/api/http2.md#L126-L131",
        "labels": "doc",
        "id": 44261
    },
    {
        "title": "Node REPL does not honor `uncaughtException` listeners",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: master\r\nPlatform: Linux blocky 4.13.0-38-generic #43~16.04.1-Ubuntu SMP Wed Mar 14 17:48:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: Linux blocky 4.13.0-38-generic #43~16.04.1-Ubuntu SMP Wed Mar 14 17:48:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n**REPL commands**\r\n\r\n``` console\r\n$ node\r\n> process.on('uncaughtException', (err) => console.log('caught' + err));\r\n> throw 'hi';\r\n```\r\n\r\n**OUTPUT :**\r\n``` console\r\nThrown: hi\r\n```\r\n\r\nRunning `process.hasUncaughtExceptionCaptureCallback()` in the REPL console outputs `true`, so it is understandable why the listener isn't called.\r\n\r\nHowever\r\n\r\n``` console\r\n> process.setUncaughtExceptionCaptureCallback(null);\r\n```\r\nthrows the Error:\r\n\r\n```\r\nError [ERR_DOMAIN_CANNOT_SET_UNCAUGHT_EXCEPTION_CAPTURE]: The `domain` module is in use, which is mutually exclusive with calling process.setUncaughtExceptionCaptureCallback()\r\n    at process.setUncaughtExceptionCaptureCallback (domain.js:97:15)\r\n    at repl:1:9\r\n    at Script.runInThisContext (vm.js:91:20)\r\n    at REPLServer.defaultEval (repl.js:311:29)\r\n    at bound (domain.js:396:14)\r\n    at REPLServer.runBound [as eval] (domain.js:409:12)\r\n    at REPLServer.onLine (repl.js:609:10)\r\n    at REPLServer.emit (events.js:187:15)\r\n    at REPLServer.emit (domain.js:442:20)\r\n    at REPLServer.Interface._onLine (readline.js:285:10)\r\n----------------------------------------\r\nError: require(`domain`) at this point\r\n    at domain.js:93:28\r\n    at NativeModule.compile (internal/bootstrap/loaders.js:209:7)\r\n    at NativeModule.require (internal/bootstrap/loaders.js:137:18)\r\n    at repl.js:63:16\r\n    at NativeModule.compile (internal/bootstrap/loaders.js:209:7)\r\n    at NativeModule.require (internal/bootstrap/loaders.js:137:18)\r\n    at internal/repl.js:4:14\r\n    at NativeModule.compile (internal/bootstrap/loaders.js:209:7)\r\n    at Function.NativeModule.require (internal/bootstrap/loaders.js:137:18)\r\n    at startup (internal/bootstrap/node.js:240:40)\r\n```\r\nI could not find any documentation of this behaviour for the Node REPL.\r\n\r\nIs this a bug, or is this a desired behaviour which has to be documented?",
        "labels": "doc",
        "id": 44262
    },
    {
        "title": "doc: style ambiguity",
        "body": "Currently, we have some doc fragments with `<code>` inside `<em>`:\r\n\r\nhttps://github.com/nodejs/node/blame/de0053cc3280bdf72c9010f383290f79120a1e98/doc/api/dns.md#L641\r\n\r\nhttps://github.com/nodejs/node/blame/b3bff41690dbbb937d20b7f2c484b72b1f8e3440/doc/api/process.md#L1496-L1502\r\n\r\nThey make sense for GitHub rendering:\r\n\r\nhttps://github.com/nodejs/node/blob/de0053cc3280bdf72c9010f383290f79120a1e98/doc/api/dns.md#dnsresolve-dnsresolve-and-dnsreverse\r\n\r\nhttps://github.com/nodejs/node/blob/b3bff41690dbbb937d20b7f2c484b72b1f8e3440/doc/api/process.md#processrelease\r\n\r\nbut not for the nodejs.org rendering:\r\n\r\nhttps://nodejs.org/download/nightly/v10.0.0-nightly2018041142d8976dff/docs/api/dns.html#dns_dns_resolve_dns_resolve_and_dns_reverse\r\n\r\nhttps://nodejs.org/download/nightly/v10.0.0-nightly2018041142d8976dff/docs/api/process.html#process_process_release\r\n\r\nbecause we revert the effect in the `doc/api_assets/style.css`:\r\n\r\nhttps://github.com/nodejs/node/blob/b3bff41690dbbb937d20b7f2c484b72b1f8e3440/doc/api_assets/style.css#L64-L66\r\n\r\nSo we have some options:\r\n\r\n1. Leve as is if we are OK with the difference.\r\n2. Move `<code>` out of `<em>` (or delete `<em>` if there is no other text inside it except the `<code>`).\r\n3. Change `doc/api_assets/style.css`.\r\n",
        "labels": "doc",
        "id": 44263
    },
    {
        "title": "add HPE_INVALID_METHOD to documentation",
        "body": "The HTTP error `HPE_INVALID_METHOD` is not documented.\r\n\r\nSuggestion:\r\n\r\n`doc/api/errors.md` (line ~1659)\r\n\r\n```\r\n<a id=\"HPE_INVALID_METHOD\"></a>\r\n### HPE_INVALID_METHOD\r\n\r\nA \"Parse Error\" occurred because the HTTP method is not supported\r\nor the incoming packet encoding is not US-ASCII.\r\n```\r\n(ascii reference noted because base64 encoded packets cannot be parsed)\r\nRef: #19344 \r\n\r\nExample:\r\n`R0VUIC8gSFRUUC8xLjENCkhvc3Q6IGxvY2FsaG9zdDozMDAwDQoNCg==` and `GET / HTTP/1.1\\r\\nHost: localhost:3000\\r\\n\\r\\n` is the same string encoded differently.\r\n\r\nError report:\r\n```\r\nError: Parse Error\r\n    at socketOnData (_http_server.js:455:20)\r\n    at emitOne (events.js:121:20)\r\n    at Socket.emit (events.js:211:7)\r\n    at addChunk (_stream_readable.js:263:12)\r\n    at readableAddChunk (_stream_readable.js:250:11)\r\n    at Socket.Readable.push (_stream_readable.js:208:10)\r\n    at TCP.onread (net.js:607:20)\r\n  bytesParsed: 1,\r\n  code: 'HPE_INVALID_METHOD',\r\n  rawPacket: <Buffer .. >\r\n```\r\n\r\nIf `HPE_INVALID_METHOD` presents itself as similarly to other common HTTP errors, it would make sense to document them as such.\r\n\r\nQuestion: is there a reason why `HPE_*` constants (specifically errors) are not documented?",
        "labels": "doc",
        "id": 44264
    },
    {
        "title": "Example Object Wrapping code never calls destructor",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.11.1\r\n* **Platform**: Windows 10 Enterprise 64-bit\r\n* **Subsystem**: documentation\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n[The documentation](https://nodejs.org/api/addons.html#addons_wrapping_c_objects) for _Wrapping C++ Objects_ has an example that creates a class called `MyObject` which derives from `node::ObjectWrap`.  \r\n\r\nIt would be very helpful if the documentation described the mechanism by which the object will be deleted (how/when) and provided an example of how to get the destructor to actually be invoked in practice, since it will only get deleted when the garbage collector runs.  As I understand it (as I am able to demonstrate by running the example), the destructor will not get called.  The example suggests that one is intended to run the following code, which will not induce a garbage collection:\r\n\r\n```\r\n// test.js\r\nconst addon = require('./build/Release/addon');\r\n\r\nconst obj = new addon.MyObject(10);\r\nconsole.log(obj.plusOne());\r\n// Prints: 11\r\nconsole.log(obj.plusOne());\r\n// Prints: 12\r\nconsole.log(obj.plusOne());\r\n// Prints: 13\r\n```\r\n\r\nIt would be much better if there were an example that shows how to force a garbage collection that causes the wrapped object to get properly destroyed so that developers of addons can ensure that C++ resources are not leaked.\r\n\r\nAs I see it, this is only half an example because it only demonstrates creating objects, not destroying them.  They are not demonstrated to get destroyed using this example code.  I think this is a shortcoming of the documentation.",
        "labels": "doc",
        "id": 44265
    },
    {
        "title": "add search button to docs",
        "body": "I'm very suprised there is not search functionality in the node docs.  This would be a great addition to the docs and make it easier to navigate inside them.\r\n\r\nworkaround: google (not quite as convenient)",
        "labels": "doc",
        "id": 44266
    },
    {
        "title": "doc: add documentation on porting from Buffer(arg) usage",
        "body": "Refs: #19079\r\n\r\nAs previously discussed, it would be great if we could provide that instructions somewhere (docs, news, medium, whatever).\r\n\r\nI made an initial draft in my repo here: [Porting-Buffer.md](https://github.com/ChALkeR/safer-buffer/blob/master/Porting-Buffer.md), and @addaleax contributed significant parts of it.\r\n\r\nWhat would be the next steps to discuss it and fix it so that it could be included somewhere?\r\nI guess that needs to be done in time for 10.0 release.\r\n\r\n_Also: comments/patches to the doc at its current state are welcomed._\r\n\r\n/cc @nodejs/tsc ",
        "labels": "doc",
        "id": 44267
    },
    {
        "title": "doc: sorting in doc/api/cli?",
        "body": "Currently, both command line options and environment variables in the [`cli` doc](https://github.com/nodejs/node/blob/master/doc/api/cli.md) are not sorted alphabetically.\r\n\r\nI am not sure if these lists use some logic or time order that has to be preserved.\r\n\r\nIs it worth to sort them ASCII-wise?",
        "labels": "doc",
        "id": 44268
    },
    {
        "title": "fs,net: missing documentation for new \"ready\" events",
        "body": "PR https://github.com/nodejs/node/pull/19408 added new \"ready\" events to streams in fs and net.\r\n\r\nI think they need to be documented and have a \"changes\" entry. The commit is going to be in the next v9.x release.",
        "labels": "doc",
        "id": 44269
    },
    {
        "title": "crypto,doc: update language around key stretching",
        "body": "`doc/api/crypto.md` currently says this:\r\n\r\n> it is recommended that developers derive a key and IV on their own using `crypto.pbkdf2()`\r\n\r\nThat's only sound when the key+IV are used once.  Using the same key+IV twice is undesirable in general and downright disastrous with counter mode ciphers:\r\n\r\n1. identical plaintexts encrypt to the same ciphertext (usually not what you want)\r\n2. leaks information about the initial plaintext block with CBC and CFB ciphers\r\n3. completely destroys the security of CTR, GCM and OFB ciphers\r\n\r\nIt would be good to add some guidelines on how to safely create and store IVs.  They should be unpredictable but don't need to be kept secret after encrypting.  Are there exceptions to this rule?\r\n\r\nRefs: indexzero/nconf#299",
        "labels": "doc",
        "id": 44270
    },
    {
        "title": "Http2SecureServer.close fails",
        "body": "* **Version**: v9.10.1\r\n* **Platform**: Linux Host-001 4.14.6-300.fc27.x86_64 #1 SMP Thu Dec 14 15:31:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: http2\r\n\r\n**Problem**:\r\nClosing an Http2Server runs only when it has no connection;\r\nOtherwise, no \"close\" or \"error\" event is emitted after close(), and script doesn't exit (server still listening)\r\n\r\n**bug.js**:\r\nconst\r\n    http2 = require( \"http2\" ),\r\n    srv = http2.createServer();\r\nsrv.listen(9000);\r\nconst client = http2.connect(\"http://localhost:9000\");\r\nsetTimeout(() => { srv.close() }, 500);\r\n\r\n$ **export NODE_DEBUG=http2; node ./bug.js**\r\nHTTP2 30406: Http2Session client: created\r\n(node:30406) ExperimentalWarning: The http2 module is an experimental API.\r\nHTTP2 30406: Http2Session server: received a connection\r\nHTTP2 30406: Http2Session server: setting up session handle\r\nHTTP2 30406: Http2Session server: sending settings\r\nHTTP2 30406: Http2Session server: submitting settings\r\nHTTP2 30406: Http2Session server: created\r\nHTTP2 30406: Http2Session client: setting up session handle\r\nHTTP2 30406: Http2Session client: sending settings\r\nHTTP2 30406: Http2Session client: submitting settings\r\nHTTP2 30406: Http2Session client: new settings received\r\nHTTP2 30406: Http2Session server: new settings received\r\nHTTP2 30406: Http2Session server: settings received\r\nHTTP2 30406: Http2Session client: settings received\r\n",
        "labels": "doc",
        "id": 44271
    },
    {
        "title": "test-make-doc now failing locally",
        "body": "\r\n* **Version**: master\r\n* **Platform**: mac\r\n* **Subsystem**: doc, test\r\n\r\nI just pulled and test-make-doc is now failing:\r\n\r\n```Â \r\n$ out/Release/node /Users/matteo/Repositories/node/test/doctool/test-make-doc.js\r\nassert.js:248\r\n    throw err;\r\n    ^\r\n\r\nAssertionError [ERR_ASSERTION]: all.html is empty\r\n    at Object.<anonymous> (/Users/matteo/Repositories/node/test/doctool/test-make-doc.js:47:10)\r\n    at Module._compile (internal/modules/cjs/loader.js:678:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:689:10)\r\n    at Module.load (internal/modules/cjs/loader.js:589:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:528:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:520:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:719:10)\r\n    at startup (internal/bootstrap/node.js:225:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:572:3)\r\n```\r\n\r\nThis as been introduced in https://github.com/nodejs/node/pull/19581. Not sure what I should do to make this pass again on my machine, I already tried `make clean` and `make doc`.",
        "labels": "doc",
        "id": 44272
    },
    {
        "title": "deps: document which ICU version we work with",
        "body": "in https://github.com/nodejs/Intl/issues/35 I wrote:\r\n> I _think_ node will work with a pretty wide range of ICUs at this point. It might be worth actually testing this, and making sure `configure` complains if the ICU is too old.\r\n\r\nProbably ICU4C 58.2 is the minimum for `master` ( ad721429c02a086373d841206927718048d6b521 ish ) at this point. It would be 57 if https://github.com/nodejs/node/issues/19656 were solved.\r\n\r\nNote that the backlevel ICU versions are relevant to packagers trying to use the pre-installed ICU from the system or other packaging. For example, Ubuntu stretch (at least on raspbian) has ICU 57.1 installed.\r\n\r\n### must be 99 ways to overengineer this\r\n- Just document the ICU version\r\n   - in `configure` with the relevant options?\r\n   - in `tools/icu/README.md` (doesn't seem helpful)\r\n   - in `doc/api/intl.md` (best option?)\r\n   - in the wiki?\r\n- *warn* in `configure` if the version is too old\r\n- *error* in `configure` if the version is too old\r\n   - â€¦ with an option to override?\r\n",
        "labels": "doc",
        "id": 44273
    },
    {
        "title": "Listening to SIGUSR1 blocks debugger",
        "body": "* **Version**: v8.9.4\r\n* **Platform**: 3.10.0-693.17.1.el7.x86_64\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI am not sure which is the correct behavior for an intercepted `SIGUSR1`, the documentation or the a test case. Can the code and/or documentation please be fixed?\r\n\r\n[process documentation](https://nodejs.org/api/process.html) says:\r\n> SIGUSR1 is reserved by Node.js to start the debugger. It's possible to install a listener but doing so will not stop the debugger from starting.\r\n\r\nBut a quick test shows that the debugger is not started.\r\n\r\nCode:\r\n```javascript\r\nlet i = 0;\r\nsetInterval(() =>\r\n        console.log(i++),\r\n    1000);\r\n\r\nprocess.on('SIGUSR1', () => console.log('Got SIGUSR1'))\r\n```\r\n\r\nIf you send a `SIGUSR1` only `Got SIGUSR1` is printed. The typical `Debugger listening on ws://127.0.0.1:9229/66fb119d-2443-4bdf-80b1-6386995ba253` is not printed. You can also verify that the debugger didn't start with with `netstat -ap`.\r\n",
        "labels": "doc",
        "id": 44274
    },
    {
        "title": "doc: missing \"changes\" entry for vm code generation options",
        "body": "Feature added in https://github.com/nodejs/node/pull/19016",
        "labels": "doc",
        "id": 44275
    },
    {
        "title": "doc: mark StackOverflow as unofficial",
        "body": "We're listing StackOverflow as a place for support in our [README.md](https://github.com/nodejs/node/pull/18191). Following the discussion in [#18191](https://github.com/nodejs/node/pull/18191), we should make it clear that the StackOverflow entries are not moderated by the Node.js Foundation. ",
        "labels": "doc",
        "id": 44276
    },
    {
        "title": "build: how to build and test docs on Windows",
        "body": "This is a small how-to note on the mentioned topic.\r\n\r\nCurrently, there is no task like [`doc-only`](https://github.com/nodejs/node/blob/90b05382734aca10b51b187eb955a964cbcaed74/Makefile#L615) in the [vcbuild.bat](https://github.com/nodejs/node/blob/master/vcbuild.bat), and the test for doc building result [is skipped on Windows](https://github.com/nodejs/node/blob/90b05382734aca10b51b187eb955a964cbcaed74/test/doctool/test-make-doc.js#L3-L5).\r\n\r\nHowever, sometimes it is needed to quickly test some doc changes for a PR locally on Windows, maybe without building the `node` (~ 1 hour with 100% dual-core CPU on my machine).\r\n\r\nIt turns out to be not so difficult to build and test docs on Windows. However, the process has some quirks.\r\n\r\n1. [Add `make`](https://gist.github.com/evanwill/0207876c3243bbb6863e65ec5dc3f058) to common Git Bash tools for Windows.\r\n\r\n2. Unfortunately, a simple command `NODE=/path/to/node make doc-only` [recommended in BUILDING.md](https://github.com/nodejs/node/blob/master/BUILDING.md#building-the-documentation) works only if `node` is located deeper than the `PWD` path because of [this macro](https://github.com/nodejs/node/blob/90b05382734aca10b51b187eb955a964cbcaed74/Makefile#L645-L655) in the `doc-only` task flow (it seems this caution is valid for Linux too).\r\n\r\n    If the path to `node` has no spaces, we can call with this relative path (supposing the project root is something like `d:\\node-fork\\`):\r\n\r\n    ```console\r\n    $ NODE=../../C/nodejs/node.exe make doc-only\r\n    ```\r\n\r\n    If the path to `node` has spaces (like the default `\"C:\\Program Files\\nodejs\\node.exe\"`), [we have a problem with `make`](https://stackoverflow.com/questions/9838384/can-gnu-make-handle-filenames-with-spaces). However, we can temporarily locate `node` in `PWD`, so this simple hack works:\r\n\r\n    ```console\r\n    $ cp \"`where node`\" node.exe && NODE=node.exe MAKE=make make doc-only && rm node.exe\r\n    ```\r\n\r\n    We should define `MAKE=make` if the path to `make` also has spaces (which is default: `c:\\Program Files\\Git\\mingw64\\bin\\make.exe`).\r\n\r\n4. Finally, we can just comment out [the skipping](https://github.com/nodejs/node/blob/90b05382734aca10b51b187eb955a964cbcaed74/test/doctool/test-make-doc.js#L3-L5) in `test/doctool/test-make-doc.js` and test the result.\r\n",
        "labels": "doc",
        "id": 44277
    },
    {
        "title": "Add information about buffer.byteOffset property to Buffer.from(string) documentation",
        "body": "I'm was trying to make this example work:\r\n```javascript\r\nvar firstBuffer = Buffer.from('hello world');\r\nvar secondBuffer = Buffer.from(firstBuffer.buffer, 0, firstBuffer.length);\r\n\r\nconsole.log (firstBuffer) // <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64>\r\nconsole.log (secondBuffer) // <Buffer da 07 00 00 da 07 00 00 db 07 00>\r\n\r\nassert(firstBuffer.buffer === secondBuffer.buffer, \".buffer property is the same\");\r\nassert (firstBuffer[0] == secondBuffer[0]) // fails\r\n```\r\nit didn't worked and I didn't know why until I found that `offset` property of the `firstBuffer` wasn't `0` as I would assume. I modify it to use correct offset and problem was solved, but I spend more than hour because there wasn't any info in official docs.\r\n\r\nIt would be good  to mention in documentation that result of `Buffer.from(string)` can have `offset` different than `0`\r\n\r\n\r\n* **Version**: 9.8.0\r\n* **Platform**:  4.13.0-36-generic #40-Ubuntu SMP  x86_64\r\n* **Subsystem**: buffer\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44278
    },
    {
        "title": "pipe() doesn't close piped streamA after streamB has been destroyed",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:v9.5.0\r\n* **Platform**:Windows 7 x64\r\n* **Subsystem**:_stream_readable.js\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nAfter two sockets are piped, it seems logical that when one is end, the other will end too (except errors, as documentation clearly says). But that's not always true. \r\nIn my case, I have piped sockets, and in rare cases one socket was left in ESTABLISHED state, while other was closed. So end() (uv_shutdown()) was not called for that abandoned connection, otherwise it should be in some of TCP close states.\r\nI wrote following test to reproduce this behavior, and found another strange thing: in case 2 and case 3  unpipe event is emitted after close, but documentation for close event says that \"no more events will be emitted\". This is not an issue for me, just conflict with documentation.\r\n\r\nThe main issue is the case 1, socketA is destroyed but socketB got no events at all:\r\nsocketA | connect\r\nsocketB | connect\r\nsocketB | pipe\r\nsocketA | pipe\r\nsocketA | close\r\nsocketA | unpipe\r\n\r\nI look into pipe() implementation, and it looks like it ends writable side only when readable end event is emitted, i.e. only two stream end scenarios are considered: error and end. But destroy() introduce another one - just close without end or error events.\r\nOr maybe I miss something in docs about pipe handling and this is normal? It could be fixed like this:\r\n```javascript\r\nreadable.on('unpipe', ()=>{\r\n    writable.end();\r\n});\r\n```\r\nThe code:\r\n```javascript\r\nconst net = require('net');\r\n\r\nfunction logEvent(socket, socketName, event){\r\n    socket.on(event, ()=>{\r\n        console.log(`${socketName} | ${event}`);\r\n    });\r\n}\r\n\r\nfunction setHandlers(socket, socketName){\r\n    logEvent(socket, socketName, 'connect');\r\n    logEvent(socket, socketName, 'finish');\r\n    logEvent(socket, socketName, 'pipe');\r\n    logEvent(socket, socketName, 'unpipe');\r\n    logEvent(socket, socketName, 'end');\r\n    logEvent(socket, socketName, 'close');\r\n    logEvent(socket, socketName, 'error');\r\n}\r\n\r\nfunction connectSocket(socketName, host, port, cb){\r\n    const socket = new net.Socket();\r\n    setHandlers(socket, socketName);\r\n    socket.connect(port, host, ()=>{\r\n        cb(socket);\r\n    });    \r\n}\r\n\r\nfunction setPipeErrorHandler(readable, writable){\r\n    readable.on('error', ()=>{\r\n        writable.destroy();\r\n    });\r\n}\r\n\r\nconnectSocket('socketA', 'google.com', 80, (socketA)=>{\r\n    connectSocket('socketB', 'google.com', 80, (socketB)=>{\r\n        setPipeErrorHandler(socketA, socketB);\r\n        setPipeErrorHandler(socketB, socketA);\r\n\r\n        socketA.on('pipe', ()=>{\r\n            //case 1\r\n            //socketA unpipe emitted after close, socketB was not closed at all :(\r\n            socketA.destroy();\r\n\r\n            //case 2\r\n            //both closed, but socketB unpipe was emitted after close\r\n            //socketA.destroy('error');\r\n\r\n            //case 3\r\n            //everything is OK\r\n            //socketA.end();\r\n        });\r\n\r\n        socketA.pipe(socketB);\r\n        socketB.pipe(socketA);\r\n    });\r\n});\r\n```",
        "labels": "doc",
        "id": 44279
    },
    {
        "title": "[api-doc] what returns when calling stream.read() after stream is closed is not consistent documented",
        "body": "* **Version**: [docs/latest-v8.x](https://nodejs.org/docs/latest-v8.x/api/stream.html#stream_readable_read_size)\r\n\r\n#### [readable.read([size])](https://nodejs.org/docs/latest-v8.x/api/stream.html#stream_readable_read_size)\r\n\r\nThe doc states \r\n> null will be returned unless the stream has ended, in which case all of the data remaining in the internal buffer will be returned.\r\n\r\nThen it also states\r\n> Note: Calling stream.read([size]) after the 'end' event has been emitted will return null. No runtime error will be raised.\r\n\r\nSo, what it returns when calling stream.read() after stream is closed, **null** or **all of the data remaining in the internal buffer**?",
        "labels": "doc",
        "id": 44280
    },
    {
        "title": "fs.access() not reporting error on Windows",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.6.1\r\n* **Platform**: Windows 7 Professional x64\r\n* **Subsystem**:  fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nfs.access() returns no error when given a file/directory with no priveleges.\r\n\r\nCode example:\r\n```javascript\r\n'use strict'\r\n\r\nconst fs = require('fs')\r\n\r\nfs.access('./restricted', fs.constants.R_OK || fs.constants.W_OK, err => {\r\n  if (err) {\r\n    console.log(err)\r\n  } else {\r\n    console.log('no access() error')\r\n  }\r\n})\r\n\r\nfs.stat('./restricted', (err, stat) => {\r\n  if (err) {\r\n    console.log(err)\r\n  } else {\r\n    console.log('no stat() error')\r\n  }\r\n})\r\n```\r\nOutput:\r\n```\r\nno access() error\r\n{ Error: EPERM: operation not permitted\r\n  errno: -4048,\r\n  code: 'EPERM',\r\n  syscall: 'stat',\r\n  path: 'C:\\\\Workspaces\\\\restricted' }\r\n```\r\n\r\n\r\n",
        "labels": "doc",
        "id": 44281
    },
    {
        "title": "Documents about difference of inspect or --inspect and it's arguments",
        "body": "* **Version**: 9.6.1\r\n* **Platform**: Debian 9 and Windows 10\r\n* **Subsystem**: inspector\r\n\r\nExample:\r\n`node inspect my-script` will listen a port and start debugger cli\r\n`node --inspect my-script` will only listen a port\r\n`node inspect --port=1234 my-script` will able to enter debugger cli with custom port **No Document**\r\n> I did not found any document about how to enter debugger cli with custom port\r\n\r\n`node --inspect=1234 my-script` will only listen on custom port\r\n\r\n---\r\nIt's a bit confuse for user, it looks like one command, but in face they have different behavior",
        "labels": "doc",
        "id": 44282
    },
    {
        "title": "Console log WeakSet and WeakMap always empty",
        "body": "* **Version**: 8.9.4\r\n* **Platform**: Windows 10 x64\r\n* **Subsystem**: powershell\r\n\r\nCurrently trying to console.log WeakSet or WeakMap will always display as empty.\r\n```js\r\nvar set = new WeakSet([{yes: true}]);\r\nconsole.log(set); // logs WeakSet{}\r\n\r\nvar map = new WeakMap([[{yes: true}, true]]);\r\nconsole.log(map); // logs WeakMap{}\r\n```\r\nI believe I understand why logging them does not work, but node should display a warning and/or should document this behavior.",
        "labels": "doc",
        "id": 44283
    },
    {
        "title": "Clarify that require.resolve automatically adds global folders to lookup path ",
        "body": "* **Version**: v8.9.4\r\n* **Platform**: Fedora 26\r\n\r\nIt's not clear from the docs that `require.resolve` automatically adds the global folder to the module search path when using the `paths` option. It's clear that each path provided will be used as the starting point of a node_modules hierarchy. However, no where is it stated that the global folders (like `~/.node_modules`) are added implicitly, leading one to assume that these paths are not search when the `paths` option is specified.\r\n\r\nMy proposed change is highlighted in bold.\r\n\r\n> Paths to resolve module location from. If present, these paths are used instead of the default resolution paths, **with the exception of the global folders like `~/.node_modules`, which are always included.** Note that each of these paths is used as a starting point for the module resolution algorithm, meaning that the node_modules hierarchy is checked from this location.\r\n\r\nI'd be happy to submit a patch if this proposed change is acceptable.",
        "labels": "doc",
        "id": 44284
    },
    {
        "title": "Move CPP_STYLE_GUIDE.md to /doc",
        "body": "<!-- Enter your issue details below this comment. -->\r\nI think `CPP_STYLE_GUIDE.md` should be in the same folder as the more general `STYLE_GUIDE.md`, which is located in the `/doc` directory. \r\n\r\nPerhaps they can both be moved into `/doc/guides` directory. ",
        "labels": "doc",
        "id": 44285
    },
    {
        "title": "Improving the documentation for `url.format()`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: All\r\n* **Platform**: All\r\n* **Subsystem**: All\r\n \r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI've noticed that the [documentation for the `url.format()` method](https://nodejs.org/api/url.html#url_url_format_urlobject) has becoming a long-winded story of \"If this condition is met, then this happens, else this other thing happens, unless something something.\"\r\n\r\nI'm all for leaving this detailed explanation of the method's behavior intact, but I think it would also be immensely useful to have some example code to illustrate the common case. Something like this:\r\n\r\n```js\r\nurl.format({\r\n  protocol: 'https',\r\n  hostname: `en.wiktionary.org`,\r\n  pathname: '/w/api.php',\r\n  query: {\r\n    action: 'query',\r\n    format: 'json',\r\n    prop: 'extracts',\r\n    titles: 'orthogonal'\r\n  }\r\n})\r\n```\r\n\r\nI'm happy to open a pull request for this, but wanted to check first to see if a change like this would be welcomed.\r\n",
        "labels": "doc",
        "id": 44286
    },
    {
        "title": "Let's start to write upgrade guides!",
        "body": "I think there is one thing that Node is missing compared to many other projects when a new major version is released: a clear guide for users who want to migrate their code from an earlier version.\r\n\r\nWe have lists of breaking changes [in the wiki](https://github.com/nodejs/node/wiki#apibreaking-changes), mostly maintained by @Fishrock123.\r\nThose are valuable, but I would like to propose something different:\r\n\r\n- Create a new folder in docs (for example `doc/guides/upgrade/`)\r\n- When a new major branch is cut, add a new file in this folder for the next major (for example `upgrade-to-node-10.md`\r\n- Actively update the file during development on the master branch\r\n- Do not just copy/paste commit messages. Write sentences that speak directly to the user reading them\r\n- Illustrate with code and console output examples\r\n- Do not restrict it to semver-major changes. Write about everything that the users might need to know about while upgrading (new core modules/functions, new ES features, doc deprecations, etc.)\r\n- When the release happens, publish the doc to the website and add a link to the download page for some time\r\n\r\n/cc @nodejs/collaborators @nodejs/website @nodejs/tsc @nodejs/community-committee ",
        "labels": "doc",
        "id": 44287
    },
    {
        "title": "Document about CI results expected in the onboarding PR",
        "body": "Refs: https://github.com/nodejs/node/pull/18824#issuecomment-366419923\r\n\r\nI believe the current practice is:\r\n\r\n1. Ask the people getting onboard to launch a full CI (to make sure they can do that), and paste the link in the PR\r\n2. After the linter goes green, stop the CI (since it's just a documentation change we don't really need to get a green full CI, also unfortunately these days the full CI are almost never green..)\r\n3. We don't require onboarding PR to wait for 48/72 hours, so with at least one LGTM and a green linter , the PR is ready to land. How long the PR needs to wait depends on the author. It's OK to wait for < 30mins, IMO.\r\n",
        "labels": "doc",
        "id": 44288
    },
    {
        "title": "The testing guide does not mention where a test should be added",
        "body": "https://github.com/nodejs/node/blob/master/doc/guides/writing-tests.md\r\n\r\n1. It does not mention how to determine which folder a new test should go to: `parallel`, `sequential`, or any other folders under `test`\r\n<del>2. It does not mention how the test should be named (if it's a new test script)</del> It does\r\n3. It does not mention how to find existing test cases and how to decide if a new test case belongs to a new file or an existing file.",
        "labels": "doc",
        "id": 44289
    },
    {
        "title": "Obsolete link and maybe info in crypto.md",
        "body": "See intro notes for `Certificate` class: https://github.com/nodejs/node/blob/master/doc/api/crypto.md#class-certificate\r\n\r\nThe link is 404 now: https://www.w3.org/TR/html5/forms.html#the-keygen-element\r\n\r\nLast working link time: https://web.archive.org/web/20171207004547/https://www.w3.org/TR/html5/forms.html#the-keygen-element\r\n\r\nNo `<keygen>` part in the new spec: https://www.w3.org/TR/html5/sec-forms.html\r\n\r\nThe cause: https://www.w3.org/TR/html52/changes.html#features-removed\r\n\r\nIt seems we should change the link at least and maybe add a note about element removal from the spec.\r\n\r\ncc @nodejs/crypto\r\n",
        "labels": "doc",
        "id": 44290
    },
    {
        "title": "Cannot attach to second node process by using SIGUSR1",
        "body": "* **Version**: 6.12.3 +\r\n* **Platform**: Win 10 x64 / Linux 4.x\r\n* **Subsystem**:\r\n\r\nSuppose I have two or more running node processes which are not in debugging mode and I want to activate the debugger in these processes. By using SIGUSR1 or `process._debugProcess()` the process starts listening on the default port 5858 for the debugging client. All node processes after the first that receive SIGUSR1 will fail to take port 5858 and thus cannot be debugged while already running.\r\n\r\nWorse, if you use `node debug -p $PID_OF_SECOND_PROCESS` the debugger will attach to the first node process that was able to take port 5858 instead of the PID given on the command-line.\r\n\r\nIs there any way to change the default debugging port for an already running node process, so I can attach to that?",
        "labels": "doc",
        "id": 44291
    },
    {
        "title": "unsafe multiple fs.write with position argument?",
        "body": "Official docs saying \"it is unsafe to use fs.write multiple times on the same file without waiting for the callback\" but is it true event when position argument is provided? I found this question on stackoveflow (https://stackoverflow.com/questions/41756977/is-it-safe-to-use-write-multiple-times-on-the-same-file-without-regard-for-con ) , where user with nickname dan-d said that \"The remark about unsafeness does not apply when the position argument is given. fs.write calls pwrite(2) when given the position argument\". So can you guys clarify is it safe or unsafe to call fs.write multiple times without waiting for callback when position argument is provided? If the unsafety really related only to calls without position argument, therefore it should be mentioned in docs.",
        "labels": "doc",
        "id": 44292
    },
    {
        "title": "Can't send signals using signal numbers",
        "body": "* **Version**: v9.5.0\r\n* **Platform**: Linux arch 4.14.15-1-ARCH #1 SMP PREEMPT Tue Jan 23 21:49:25 UTC 2018 x86_64 GNU/Linux\r\n* **Subsystem**: process\r\n\r\nUsing `process.kill` with signal numbers should work according to the documentation, but I get an ERR_UNKNOWN_SIGNAL error when using numbers instead of strings. For example:\r\n\r\n    $ node\r\n    > process.kill(process.pid, \"SIGTERM\")\r\n    Terminated\r\n\r\n    $ node\r\n    > 15 === require(\"constants\").SIGTERM\r\n    true\r\n    > process.kill(process.pid, 15)\r\n    TypeError [ERR_UNKNOWN_SIGNAL]: Unknown signal: 15\r\n        at process.kill (internal/process.js:168:15)",
        "labels": "doc",
        "id": 44293
    },
    {
        "title": "Flaky linux tests",
        "body": "* **Version**: master\r\n* **Platform**: Fedora24, Ubuntu1404, possibly other Linux distros as well\r\n* **Subsystem**: test\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThere seems to be a more recurring issue with running native addons tests on Linux. I have seen many fail lately with the message \"Failed to add alternative version links to index\". I pasted two examples below, but I remember there being more in the past.\r\n\r\n---\r\n\r\nExample from https://ci.nodejs.org/job/node-test-commit-linux/16068/nodes=ubuntu1404-64/console:\r\n<details>\r\n\r\n```bash\r\nBuilding addon /home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/\r\ngyp info it worked if it ends with ok\r\ngyp info using node-gyp@3.6.2\r\ngyp info using node@10.0.0-pre | linux | x64\r\ngyp info chdir /home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/\r\ngyp info spawn /usr/bin/python\r\ngyp info spawn args [ '/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/deps/npm/node_modules/node-gyp/gyp/gyp_main.py',\r\ngyp info spawn args   'binding.gyp',\r\ngyp info spawn args   '-f',\r\ngyp info spawn args   'make',\r\ngyp info spawn args   '-I',\r\ngyp info spawn args   '/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/build/config.gypi',\r\ngyp info spawn args   '-I',\r\ngyp info spawn args   '/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/deps/npm/node_modules/node-gyp/addon.gypi',\r\ngyp info spawn args   '-I',\r\ngyp info spawn args   '/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/common.gypi',\r\ngyp info spawn args   '-Dlibrary=shared_library',\r\ngyp info spawn args   '-Dvisibility=default',\r\ngyp info spawn args   '-Dnode_root_dir=/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64',\r\ngyp info spawn args   '-Dnode_gyp_dir=/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/deps/npm/node_modules/node-gyp',\r\ngyp info spawn args   '-Dnode_lib_file=/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/$(Configuration)/node.lib',\r\ngyp info spawn args   '-Dmodule_root_dir=/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding',\r\ngyp info spawn args   '-Dnode_engine=v8',\r\ngyp info spawn args   '--depth=.',\r\ngyp info spawn args   '--no-parallel',\r\ngyp info spawn args   '--generator-output',\r\ngyp info spawn args   'build',\r\ngyp info spawn args   '-Goutput_dir=.' ]\r\ngyp info spawn make\r\ngyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build', '--jobs', 2 ]\r\nmake[2]: Entering directory `/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/build'\r\n  CXX(target) Release/obj.target/binding/binding.o\r\n  SOLINK_MODULE(target) Release/obj.target/binding.node\r\n  COPY Release/binding.node\r\nmake[2]: Leaving directory `/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/build'\r\ngyp info ok \r\ntouch test/addons/.buildstamp\r\nFailed to add alternative version links to index\r\nAborted (core dumped)\r\nmake[2]: *** [out/doc/api/string_decoder.json] Error 134\r\nmake[2]: *** Waiting for unfinished jobs....\r\nmake[2]: Leaving directory `/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64'\r\nmake[1]: *** [doc-only] Error 2\r\nmake[1]: Leaving directory `/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64'\r\nmake: *** [run-ci] Error 2\r\nBuild step 'Execute shell' marked build as failure\r\nRun condition [Always] enabling perform for step [[]]\r\nRun condition [Always] enabling perform for step [[]]\r\nTAP Reports Processing: START\r\nLooking for TAP results report in workspace using pattern: *.tap\r\nDid not find any matching files. Setting build result to FAILURE.\r\nChecking ^not ok\r\nJenkins Text Finder: File set '*.tap' is empty\r\nNotifying upstream projects of job completion\r\nFinished: FAILURE\r\n```\r\n\r\n</details>\r\n\r\n---\r\n\r\nExample from https://ci.nodejs.org/job/node-test-commit-linux/16068/nodes=ubuntu1404-64/console:\r\n<details>\r\n\r\n```bash\r\nBuilding addon /home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/\r\ngyp info it worked if it ends with ok\r\ngyp info using node-gyp@3.6.2\r\ngyp info using node@10.0.0-pre | linux | x64\r\ngyp info chdir /home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/\r\ngyp info spawn /usr/bin/python\r\ngyp info spawn args [ '/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/deps/npm/node_modules/node-gyp/gyp/gyp_main.py',\r\ngyp info spawn args   'binding.gyp',\r\ngyp info spawn args   '-f',\r\ngyp info spawn args   'make',\r\ngyp info spawn args   '-I',\r\ngyp info spawn args   '/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/build/config.gypi',\r\ngyp info spawn args   '-I',\r\ngyp info spawn args   '/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/deps/npm/node_modules/node-gyp/addon.gypi',\r\ngyp info spawn args   '-I',\r\ngyp info spawn args   '/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/common.gypi',\r\ngyp info spawn args   '-Dlibrary=shared_library',\r\ngyp info spawn args   '-Dvisibility=default',\r\ngyp info spawn args   '-Dnode_root_dir=/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64',\r\ngyp info spawn args   '-Dnode_gyp_dir=/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/deps/npm/node_modules/node-gyp',\r\ngyp info spawn args   '-Dnode_lib_file=/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/$(Configuration)/node.lib',\r\ngyp info spawn args   '-Dmodule_root_dir=/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding',\r\ngyp info spawn args   '-Dnode_engine=v8',\r\ngyp info spawn args   '--depth=.',\r\ngyp info spawn args   '--no-parallel',\r\ngyp info spawn args   '--generator-output',\r\ngyp info spawn args   'build',\r\ngyp info spawn args   '-Goutput_dir=.' ]\r\ngyp info spawn make\r\ngyp info spawn args [ 'BUILDTYPE=Release', '-C', 'build', '--jobs', 2 ]\r\nmake[2]: Entering directory `/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/build'\r\n  CXX(target) Release/obj.target/binding/binding.o\r\n  SOLINK_MODULE(target) Release/obj.target/binding.node\r\n  COPY Release/binding.node\r\nmake[2]: Leaving directory `/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64/test/addons/zlib-binding/build'\r\ngyp info ok \r\ntouch test/addons/.buildstamp\r\nFailed to add alternative version links to index\r\nAborted (core dumped)\r\nmake[2]: *** [out/doc/api/string_decoder.json] Error 134\r\nmake[2]: *** Waiting for unfinished jobs....\r\nmake[2]: Leaving directory `/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64'\r\nmake[1]: *** [doc-only] Error 2\r\nmake[1]: Leaving directory `/home/iojs/build/workspace/node-test-commit-linux/nodes/ubuntu1404-64'\r\nmake: *** [run-ci] Error 2\r\nBuild step 'Execute shell' marked build as failure\r\nRun condition [Always] enabling perform for step [[]]\r\nRun condition [Always] enabling perform for step [[]]\r\nTAP Reports Processing: START\r\nLooking for TAP results report in workspace using pattern: *.tap\r\nDid not find any matching files. Setting build result to FAILURE.\r\nChecking ^not ok\r\nJenkins Text Finder: File set '*.tap' is empty\r\nNotifying upstream projects of job completion\r\nFinished: FAILURE\r\n```\r\n\r\n</details>\r\n\r\n---",
        "labels": "doc",
        "id": 44294
    },
    {
        "title": "`make lint-ci` lints docs, but `make lint` doesn't",
        "body": "After working on the v9.5.0 release proposal, I was concerned to see that the node-test-linter ci job failed. Apparently, we are linting docs in CI, but not locally with `make lint`. \r\n\r\nIMO, if we lint in CI, we should lint locally. Otherwise, people could be confused as to why it passes locally but not when run in CI. Would love to hear the opinions of others",
        "labels": "doc",
        "id": 44295
    },
    {
        "title": "`man node` produces warnings on macOS",
        "body": "On macOS 10.13.3 with node 9.4.0, I get these warnings printed after opening and closing node's manpage via `man node` and <kbd>q</kbd>:\r\n\r\n````\r\n`R' is a string (producing the registered sign), not a macro.\r\n`R' is a string (producing the registered sign), not a macro.\r\n````\r\n\r\nVersions of tools involved in `man` processing:\r\n\r\n````sh\r\n# groff --version\r\nGNU troff (groff) version 1.19.2\r\nGNU grops (groff) version 1.19.2\r\n````",
        "labels": "doc",
        "id": 44296
    },
    {
        "title": "Document NODE_MANY_ACCEPTS environment variable.",
        "body": "While investigating a problem with electron/dat I found the `NODE_MANY_ACCEPTS` environment variable exclusively used in the win32 context.\r\n\r\nhttps://github.com/nodejs/node/blob/02fef8ad5a6c0e5c1ce0d4b46aa3a762935c981c/lib/net.js#L1757-L1760\r\n\r\nHowever I was not able to find any documentation of why this is necessary or what it does in the [environment variable doc](https://github.com/nodejs/node/blob/4503da8a3a3b0b71d950a63de729ce495965f6ea/doc/api/cli.md#environment-variables).",
        "labels": "doc",
        "id": 44297
    },
    {
        "title": "The \"Reviewing Pull Requests\" section in the contributing guide is not written in the contributor's perspective",
        "body": "Just reading through https://github.com/nodejs/node/pull/17285#issuecomment-351527655 and discovered that we don't seem to have a document written in a new contributor's perspective about what a PR needs to proceed or to be blocked. I've split the contributing guide into separate documents and the part about reviews seem to be written in reviewers' perspective which is odd, considering we already have a collaborator guide that covers that: \r\nhttps://github.com/nodejs/node/blob/master/doc/guides/contributing/pull-requests.md#reviewing-pull-requests\r\n\r\nOpening this mostly to remind me to update (completely rewrite?) this part...",
        "labels": "doc",
        "id": 44298
    },
    {
        "title": "API Docs It would be great if we could have a visual difference between the examples that actually work, and the examples that are incomplete or have approximations",
        "body": "API Docs \r\nAll of the examples in the documentation can be run similarly.\r\nNot true.\r\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \r\n- 1 )\r\nSome examples do not work because it is an \"illustration\" , without the right parameters.\r\nCould you please use another layout, for this type of examples that do not work?\r\nSee API -> Console -> Example using the Console class: \r\n\t     \r\n        const out = getStreamSomehow(); // ReferenceError: getStreamSomehow is **not defined**\r\n\t\r\n        const err = getStreamSomehow();  // ReferenceError: getStreamSomehow is **not defined**\r\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \r\n- 2 )\r\nSome examples, are not complete, \r\nSee Console -> Class: Console-> Example using the Console class: -> new Console(stdout[, stderr])\r\n\r\n        const output = fs.createWriteStream('./stdout.log');\r\n        const errorOutput = fs.createWriteStream('./stderr.log');\r\n        const logger = new Console(output, errorOutput);\r\n\r\nThis two lines are missing , at the head of the file, :\r\n               \r\n          const fs = require('fs');\r\n\r\n          const { Console } = require('console');\r\n",
        "labels": "doc",
        "id": 44299
    },
    {
        "title": "fs: is fs.unwatchFile() available on Windows?",
        "body": "* **Version**: v4 â€“ master\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: fs\r\n\r\n1. Create a script:\r\n```js\r\n'use strict';\r\n\r\nconst fs = require('fs');\r\n\r\nfs.watchFile(__filename, { interval: 1000 }, (current, previous) => {\r\n  console.log(current.size, previous.size);\r\n  fs.unwatchFile(__filename, () => { console.log('File unwatched'); });\r\n  console.log('unwatchFile() called');\r\n});\r\n```\r\n\r\n2. Launch it, then change and save several times.\r\n\r\n3. Expected output:\r\n```console\r\n275 274\r\nunwatchFile() called\r\nFile unwatched\r\n[exit]\r\n```\r\n\r\nReal output\r\n```console\r\n275 274\r\nunwatchFile() called\r\n276 275\r\nunwatchFile() called\r\n277 276\r\nunwatchFile() called\r\n[.., no exit]\r\n```\r\n\r\nI cannot find any caveats in `fs` doc about this. Is there any?",
        "labels": "doc",
        "id": 44300
    },
    {
        "title": "require.resolve.paths(${built-in module id}) returns null",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.4.0\r\n* **Platform**: macOS 10.13.2\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen [`require.resolve.paths()`](https://nodejs.org/api/modules.html#modules_require_resolve_paths_request) receives a Node.js built-in module ID, for example `fs` and `http2`, it doesn't return `Array<string>` but `null`.\r\n\r\n```console\r\n$ node -p \"require.resolve.paths('.');\"\r\n[ '/Users/shinnn/test',\r\n  '/Users/shinnn/test/node_modules',\r\n  '/Users/shinnn/node_modules',\r\n  '/Users/node_modules',\r\n  '/node_modules',\r\n  '/Users/shinnn/.node_modules',\r\n  '/Users/shinnn/.node_libraries',\r\n  '/usr/local/Cellar/node/9.4.0/lib/node' ]\r\n\r\n$ node -p \"require.resolve.paths('fs');\"\r\nnull\r\n\r\n$ node -p \"require.resolve.paths('http2');\"\r\nnull\r\n```\r\n\r\nIs this an expected behavior? I'm OK with the current `null` returning behavior but we should inform this special case in the API document. Otherwise, if the original intent of https://github.com/nodejs/node/pull/16397 is always retrieving `Array<string>` as currently documented, we should fix the bug.\r\n\r\n-------\r\n\r\nFor reference, `require.resolve` returns the ID itself when it takes one of the built-in module IDs.\r\n\r\n```console\r\n$  node -p \"require.resolve('fs');\"\r\nfs\r\n```",
        "labels": "doc",
        "id": 44301
    },
    {
        "title": "shell option for execFile and execFileSync in child_process module not documented",
        "body": "* **Version**: 8.9.4\r\n* **Platform**: n/a\r\n* **Subsystem**: child_process\r\n\r\nThe shell option for the execFile and execFileSync functions in the child_process module is not documented. However, it clearly works, as this mocha/chai test proves:\r\n\r\n```js\r\nconst { execFile, execFileSync } = require('child_process')\r\nconst expect = require('chai').expect\r\n\r\nconst EXEC_OPTS = { encoding: 'utf8', shell: process.env.SHELL }\r\n\r\ndescribe('execFile()', () => {\r\n  it('should run command using specified shell', async () => {\r\n    let fn\r\n    try {\r\n      const result = await new Promise((resolve, reject) => {\r\n        execFile('ls', ['*'], EXEC_OPTS, (err, stdout) =>\r\n          err ? reject(err) : resolve(stdout))\r\n      })\r\n      fn = () => result\r\n    } catch (err) {\r\n      fn = () => { throw err }\r\n    }\r\n    expect(fn).to.not.throw()\r\n  })\r\n})\r\n\r\ndescribe('execFileSync()', () => {\r\n  it('should run command using specified shell', () => {\r\n    expect(() => execFileSync('ls', ['*'], EXEC_OPTS)).to.not.throw()\r\n  })\r\n})\r\n```\r\n\r\nI'm happy to add documentation for this option. I just need to know if this behavior is intention or whether it's the result of leaky internals.",
        "labels": "doc",
        "id": 44302
    },
    {
        "title": "Wrong v9.4.0 documentation for `ServerHttp2Stream#pushStream()`",
        "body": "* **Version**: v9.4.0\r\n* **Platform**: Darwin Kernel Version 17.3.0: Thu Nov  9 18:09:22 PST 2017; root:xnu-4570.31.3~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: http2\r\n\r\nhttps://github.com/nodejs/node/pull/17406 changed the callback function of `ServerHttp2Stream#pushStream()` from `(pushedStream, headers) => {}` to `(err, pushedStream, headers) => {}`. But the example code in the documentation still says the former: https://nodejs.org/dist/latest-v9.x/docs/api/http2.html#http2_http2stream_pushstream_headers_options_callback\r\n\r\nIt'd be great if the example code could be updated. Even better would be to document the callback function's signature in more detail. The document says just `Function`, which is not very helpful.\r\n",
        "labels": "doc",
        "id": 44303
    },
    {
        "title": "Files ignored by git affect tests.",
        "body": "Repro:\r\n\r\n```\r\ngit checkout 5a1aeab2db\r\n./configure\r\nmake -j8 test\r\n\r\ngit checkout 8680bb9f1a\r\n./configure\r\nmake -j8 test\r\n```\r\n\r\nObserve failure\r\n\r\n```\r\n=== release test-make-doc ===                                                  \r\nPath: doctool/test-make-doc\r\nassert.js:42\r\n  throw new errors.AssertionError({\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: addons.md is not linked in toc\r\n    at Object.<anonymous> (/usr/local/google/home/yangguo/node/test/doctool/test-make-doc.js:42:10)\r\n    at Module._compile (module.js:641:30)\r\n    at Object.Module._extensions..js (module.js:652:10)\r\n    at Module.load (module.js:560:32)\r\n    at tryModuleLoad (module.js:503:12)\r\n    at Function.Module._load (module.js:495:3)\r\n    at Function.Module.runMain (module.js:682:10)\r\n    at startup (bootstrap_node.js:191:16)\r\n    at bootstrap_node.js:626:3\r\nCommand: out/Release/node /usr/local/google/home/yangguo/node/test/doctool/test-make-doc.js\r\n```\r\n\r\nThe ad-hoc fix is\r\n```\r\ngit clean -fxd\r\n```\r\nto also get rid of gitignored files.\r\n\r\nThis can be irritating for some situations for bisection and when testing particular versions on bots. Both involve switching to older commits and if gitignored files are not cleared, test fails.\r\n\r\n  ",
        "labels": "doc",
        "id": 44304
    },
    {
        "title": "Be more explicit in doc/api/synopsis.md",
        "body": "* **Version**: master\r\n* **Subsystem**: docs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nBased on https://github.com/nodejs/help/issues/1049 raised by @the-wazz\r\n\r\n[doc/api/synopsis.md](https://github.com/nodejs/node/blob/master/doc/api/synopsis.md) contains the following text:\r\n\r\n\r\n>To run the server, put the code into a file called `example.js` and execute\r\n>it with Node.js:\r\n>\r\n>```txt\r\n>$ node example.js\r\n>Server running at http://127.0.0.1:3000/\r\n>```\r\n>\r\n>Many of the examples in the documentation can be run similarly.\r\n\r\nIt would be good if this section could assume less knowledge on the part of the reader.\r\n\r\n### Useful resources\r\n\r\n- https://github.com/nodejs/help/issues/1049 goes into some detail about the things that may be unclear\r\n- https://stackoverflow.com/questions/6737824/how-to-run-a-hello-js-file-in-node-js-on-windows has a good breakdown\r\n- The [first](https://doc.rust-lang.org/book/second-edition/ch01-01-installation.html) and [second](https://doc.rust-lang.org/book/second-edition/ch01-02-hello-world.html) sections of the Rust Book also cover a lot of the same ground.\r\n\r\nIf anyone would like to pick this up feel free.\r\n  ",
        "labels": "doc",
        "id": 44305
    },
    {
        "title": "Bug with how `require` resolves modules",
        "body": "* **Version**: `v9.3.0`\r\n* **Platform**: `Linux serapath-Lenovo-Y50-70 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 18:08:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: `require`\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n* testcase: https://transfer.sh/GGepA/node_modules.zip\r\n* strace: https://gist.github.com/joepie91/5dca7be60eea67d665691dc2f156bedf\r\n\r\n```js\r\n/* given:\r\nâ”œâ”€â”€ baz\r\nâ”‚   â”œâ”€â”€ asdf.js: exports = 'asdf'\r\nâ”‚   â”œâ”€â”€ index.js: exports = 'index'\r\nâ”‚   â””â”€â”€ package.json#main: 'asdf.js'\r\nâ”œâ”€â”€ baz.js: exports = 'baz'\r\n*/\r\nrequire('./baz') // `=== 'asdf'`\r\n// shouldn't it be `=== 'baz'`\r\n// according to https://nodejs.org/api/modules.html#modules_all_together\r\n```\r\nhttps://nodejs.org/api/modules.html#modules_all_together\r\n\r\nLOAD_AS_FILE(X)\r\n...\r\n2. If X.js is a file, load X.js as JavaScript text.  STOP\r\n\r\nand  `X = './baz'` and `X.js` is a file...\r\n\r\n  ",
        "labels": "doc",
        "id": 44306
    },
    {
        "title": "`fs.existsSync` returns wrong value on windows if there are no permissions on the given file",
        "body": "* **Version**: v9.2.0\r\n* **Platform**: windows 8.1\r\n* **Subsystem**: fs\r\n\r\n### Steps to reproduce the issue\r\n\r\n1. Create a file (for example `1.txt`)\r\n2. Disable permissions inheritance and remove all inherited permissions from the file\r\n3. Execute `fs.existsSync('1.txt')`\r\n\r\n### What is the expected behavior\r\n\r\nThe file exists (and it is also listed if you `readdirSync` it's parent directory), so the return value should be `true`.\r\n\r\n### What went wrong\r\n\r\nThe return value is `false`, like the file doesn't exist. If it is working as intended, then consider this issue as a feature request. However, if you're not aware of this behavior, then I'm pretty sure it is a bug.",
        "labels": "doc",
        "id": 44307
    },
    {
        "title": "path.dirname docs don't cover windows path edge cases",
        "body": "I'm happy to try to update the docs but maybe someone that is more familiar can explain? Or maybe I should dig through the source.\r\n\r\nI'd expect `path.dirname('a/b')` to return `a` and it does but, at least on windows putting `path.dirname('/a/b')` returns `/a/b` and `path.dirname('/a/b/')` returns `/a/b/`. I believe this is node trying to deal with UNC paths which is fine, it's just that to figure this out required trial and error and it would be nice if the docs detailed the issues.\r\n\r\nFor example making a recursive `mkdir -P` style function you might expect to be able to do something like\r\n \r\n      const fs = require('fs');\r\n      const path = require('path');\r\n      function mkdirP(filename) {\r\n          if (fs.existsSync(filename)) return;\r\n          const dirname = path.dirname(filename);\r\n          if (dirname !== ???)   // not sure what to put here\r\n             mkdirP(dirname);\r\n          }\r\n          fs.mkdirSync(filename);\r\n      }\r\n\r\nThe first thing to notice is it's not clear what to check for to stop recursing.  From trial and error it appears to be\r\n\r\n     if (dirname !== '.' && !dirname.endswith('/') && !dirname.endsWith('//'))\r\n\r\nOr something along those lines. Should that be documented? Am I even close? Maybe I should only check for `/` on windows and also `:`?\r\n\r\nI'm happy to try to update the docs to cover the edge cases if anyone knows what they are (or I can go try to dig through the source and find out)",
        "labels": "doc",
        "id": 44308
    },
    {
        "title": "Doc does not contain `Buffer.prototype.reverse`",
        "body": "Doc does not contain `Buffer.prototype.reverse`.",
        "labels": "doc",
        "id": 44309
    },
    {
        "title": "doc: v8docs.nodesource.com links issue",
        "body": "We have a link [here](https://github.com/nodejs/node/blob/master/doc/api/v8.md#v8getheapspacestatistics) to this doc part:\r\n\r\nhttps://v8docs.nodesource.com/node-8.0/d5/dda/classv8_1_1_isolate.html#ac673576f24fdc7a33378f8f57e1d13a4\r\n\r\nIt is 404 now. It seems the v8docs.nodesource.com is now synchronized with the last Node.js versions [up to the minor number](https://v8docs.nodesource.com/), so the link should be this:\r\n\r\nhttps://v8docs.nodesource.com/node-8.9/d5/dda/classv8_1_1_isolate.html#ac673576f24fdc7a33378f8f57e1d13a4\r\n\r\nIs there a way to form the link so that we should not update it after each version bump?\r\n\r\ncc @nodejs/v8 ",
        "labels": "doc",
        "id": 44310
    },
    {
        "title": "CONTRIBUTING.md improvements",
        "body": "* **Version**: n/a\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nA problem with our `CONTRIBUTING.md` is that it is very long and is often needlessly wordy.\r\n\r\nMost people who are reading the doc are probably clicking through to it from the interface where they are opening a pull request or an issue.\r\n\r\nIn other words, they are just about to do something. That is a terrible time to put a super long document in front of them. Ideally, it would be a short document with just what people need.\r\n\r\nUnfortunately, that can be in tension with other purposes/uses of `CONTRIBUTING.md` such as to advertise our values and be welcoming. So, removing content might hit objections.\r\n\r\nI had intended to go through and make it more concise in a piecemeal fashion without eliminating content. See https://github.com/nodejs/node/commit/90abfd672fca7df6ead766d919935d8e4a678091 for example. But then&hellip; \r\n\r\nI went to open a pull request in ESLint and came across [this magnificent example of a `CONTRIBUTING.md`](https://github.com/eslint/eslint/blob/eb4b1e03f82e3e76db65de07b07d2f94d0a8b25e/CONTRIBUTING.md).\r\n\r\nNice and short, but links out to the things you need to know. If you're opening a bug report it doesn't put hundreds of words about change requests in front of you. That sort of thing. \r\n\r\nSo, if someone wants to try to re-organize our `CONTRIBUTING.md` to be more like that one, I'd be ðŸ‘. Necessary caveat: There are 106 other Collaborators on Node.js and they are likely to have opinions too and their opinions may contradict mine or each other's. Doc changes are hard enough as is, but do be prepared for the too-many-cooks problem. Don't get discouraged!\r\n",
        "labels": "doc",
        "id": 44311
    },
    {
        "title": "doc: many erroneous linkifications",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.3.0\r\n* **Platform**: N/A\r\n* **Subsystem**: N/A\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe NodeJS v9.x API docs for stream have [a heading](https://nodejs.org/docs/latest-v9.x/api/stream.html#stream_a_href_http_man7_org_linux_man_pages_man0_readable_read_0_html_readable_read_0_a) that is literally `<a href=\"http://man7.org/linux/man-pages/man0/readable.read.0.html\">readable.read(0)</a>` instead of the `readable.read(0)` from [previous versions](https://nodejs.org/docs/latest-v8.x/api/stream.html#stream_readable_read_0).\r\nI'd have opened a PR but I don't know where the extra characters are coming from: the source code in both the [master](https://github.com/nodejs/node/blame/master/doc/api/stream.md#L2207) and [v9.3.0](https://github.com/nodejs/node/blame/v9.3.0/doc/api/stream.md#L2207) branches show the line unchanged for two years.\r\nApologies if this has already been corrected, github searches yielded no results for either code or issues relating to man7.",
        "labels": "doc",
        "id": 44312
    },
    {
        "title": "REPL Await invalidates `const`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: HEAD\r\n* **Platform**: all\r\n* **Subsystem**: repl\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe REPL makes `const` variables not const if `await` appears in the input:\r\n\r\n```js\r\nconst x = 1; x = 2; await 0; x\r\n```",
        "labels": "doc",
        "id": 44313
    },
    {
        "title": "doc global.parseInt is undocumented.",
        "body": "I went to the [globals API docs](https://nodejs.org/dist/latest-v9.x/docs/api/globals.html), hoping to confirm that `10` is always the default radix value for `parseInt()` in nodejs, but the docs do not mention `parseInt()` at all, anywhere. Since the radix default value depends on the engine, oughtn't it be covered in the API docs, instead of leaving it to MDN?\r\n\r\nI see that other globals, for instance, `Date` (also `Math`, `JSON`, and probably others) are not documented either. Shouldn't APIs that vary from engine to engine (e.g., `Date`) be documented at nodejs.org? \r\n\r\nI'm curious why nodejs.org covers timeouts and intervals, but not the other globals.",
        "labels": "doc",
        "id": 44314
    },
    {
        "title": "Change type annotations for eventName in events API doc to {string|symbol}",
        "body": "* **Version**: master\r\n* **Platform**: all\r\n* **Subsystem**: doc\r\n\r\nOffshoot from https://github.com/nodejs/node/pull/17440#discussion_r156585107.",
        "labels": "doc",
        "id": 44315
    },
    {
        "title": "doc: autogenerated links with 404 status",
        "body": "There are some links in the docs that get 404 recently:\r\n\r\nhttp://man7.org/linux/man-pages/man1/curl.1.html in [repl.html](https://nodejs.org/download/nightly/v10.0.0-nightly201712127a055f1d39/docs/api/repl.html) (1 link).\r\nhttp://man7.org/linux/man-pages/man3/uname.3.html in [os.html](https://nodejs.org/download/nightly/v10.0.0-nightly201712127a055f1d39/docs/api/os.html) (3 links).\r\n\r\nThey are wrongly rendered:\r\n\r\n![l](https://user-images.githubusercontent.com/10393198/33910133-69ab5f54-df96-11e7-977e-9b4960c67e60.png)\r\n\r\nThey have been fixed with manually added URLs in https://github.com/nodejs/node/pull/10244 and https://github.com/nodejs/node/pull/15463, but have been reverted to autogenerated URLs (with autogenerated URLs being prioritized/rewritten above manual URLs) in the https://github.com/nodejs/node/pull/17479\r\n\r\ncc @DiegoRBaquero and @apapirovski as maybe more well-informed about the `tools/doc/html.js` script.\r\n",
        "labels": "doc",
        "id": 44316
    },
    {
        "title": "doc - fs.open does not have an explanation for File Descriptor",
        "body": "Hello,\r\n\r\nThere should be an explanation for the File Descriptor _fd_ in this section:\r\nhttps://nodejs.org/api/fs.html#fs_fs_open_path_flags_mode_callback\r\n\r\n_fd_ should have an explanation: \r\n`fd: File descriptor. It is a handle/reference to an opened file, used by the read/write methods.`\r\n\r\nThank you",
        "labels": "doc",
        "id": 44317
    },
    {
        "title": "The behavior of Buffer#compare doesn't match its documentation",
        "body": "* **Version**: v6.12.2 (linux), v8.9.3 (linux, windows), v9.2.1 (linux)\r\n* **Platform (linux)**: Linux ubuntu 4.13.0-16-generic #19-Ubuntu SMP Wed Oct 11 18:35:14 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Platform (windows)**: Windows 10 Home 64-bit (version 1703 build 15063.726)\r\n* **Subsystem**: buffer\r\n\r\nIn [the documentation for Buffer#compare](https://nodejs.org/api/buffer.html#buffer_buf_compare_target_targetstart_targetend_sourcestart_sourceend), it's stated that the `targetEnd`, `sourceStart`, and `sourceEnd` parameters are each \"ignored when `targetStart` is `undefined`\".  However, I do not observe that behavior on versions 6.12.2, 8.9.3, or 9.2.1.  Instead, the following code fails the third assertion:\r\n\r\n```\r\nconst assert = require('assert');\r\n\r\nconst foo = Buffer.from([0, 1, 2, 3]);\r\nconst bar = Buffer.from([1, 2, 3, 4]);\r\n\r\nconst LESS_THAN = -1;\r\nconst EQUAL = 0;\r\n\r\nassert.equal(foo.compare(bar), LESS_THAN, 'Without indices, foo is less.');\r\nassert.equal(foo.compare(bar, 0, 3, 1, 4), EQUAL, 'With indices which compare only the 1..3 from each buffer, foo and bar are equal.');\r\nassert.equal(foo.compare(bar, undefined, 3, 1, 4), LESS_THAN, 'With targetStart undefined, all other indices should be ignored.');\r\n```\r\n\r\nAlthough both behaviors (ignoring or not ignoring subsequent parameters) seem reasonable, it looks like the discrepancy has always existed (see 473f086a94fdc93b6d2fb61eb85430c45e6be49c, which introduced the feature), so it probably makes more sense to change the docs.",
        "labels": "doc",
        "id": 44318
    },
    {
        "title": "Promisify of method without last argument callback - undefined beahvior",
        "body": "Currently, our documentation states:\r\n\r\n> promisify() assumes that original is a function taking a callback as its final argument in all cases, and the returned function will result in undefined behavior if it does not.\r\n\r\nHowever, `undefined behavior` is a very \"harsh\" way to put what happens (since it implies the process can crash) and the behavior is pretty well defined.\r\n\r\n - If a non function is passed in - `promisify` throws. https://github.com/nodejs/node/blob/master/lib/internal/util.js#L257-L259\r\n - If a function is passed but  its `promisify.custom` is specified but not a function - it throws.\r\n - If a function is passed, but its last argument is not a node style callback - it will treat it 'as if' its last argument is a node style callback - and will pass one to it as the last argument.\r\n\r\nIt won't do something _useful_ but the behavior is defined.\r\n\r\nI think our documentation should be amended to explain that the undefined behavior here isn't \"as undefined\" as writing out of bounds of a buffer for example.\r\n\r\nI'm marking this as \"good first issue\", and \"mentor available\" in case someone wants to PR this but isn't sure how and would like guidance. \r\n\r\n",
        "labels": "doc",
        "id": 44319
    },
    {
        "title": "BUILDING.md references p. 60 of a 40 page security policy document",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: N/A\r\n* **Platform**: N/A\r\n* **Subsystem**: N/A\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nThe current [BUILDING.md instruction page in master](https://github.com/nodejs/node/blob/master/BUILDING.md#building-nodejs-with-fips-compliant-openssl) on building node with FIPS compliant OpenSSL says:\r\n`See the security policy page 60 for more details.`\r\nUnfortunately, the [current security policy pdf](http://csrc.nist.gov/groups/STM/cmvp/documents/140-1/140sp/140sp1747.pdf) at the link only has 40 pages, so it's unclear what is being referenced.\r\n",
        "labels": "doc",
        "id": 44320
    },
    {
        "title": "IPC direct writing fails on Windows",
        "body": "* **Version**: 9.2.0\r\n* **Platform**: Windows\r\n* **Subsystem**: child_process\r\n\r\nUsing a fie descriptor directly to send IPC messages is broken on\r\nWindows:\r\n\r\n* `x.js`:\r\n\r\n   ```javascript\r\n   require(\"child_process\").spawn(\"node\", [\"y.js\"],\r\n                                  {stdio: [\"ignore\", \"pipe\" , \"pipe\", \"ipc\"]})\r\n     .on(\"message\", m => console.log(\"got a message:\", m));\r\n   ```\r\n\r\n* `y.js`:\r\n\r\n   ```javascript\r\n   require('fs').createWriteStream(null, {fd: 3})\r\n     .write(`{\"m\": \"Test\"}\\n`, \"utf8\");\r\n   ```\r\n\r\nOn Linux, this works fine, but on Windows I'm getting:\r\n\r\n   ```\r\n   Assertion failed: avail >= sizeof(ipc_frame.header), file src\\win\\pipe.c, line 1593\r\n   ```\r\n\r\nIf I change `y.js` to use `process.send` it works fine again.  (There's\r\nno reason to avoid it, but we want to get IPC messages from a python\r\nsubprocess, which fails in the same way.)\r\n",
        "labels": "doc",
        "id": 44321
    },
    {
        "title": "doc: how to use advanced features of `configure` on Windows",
        "body": "Refs: https://github.com/nodejs/node/pull/17066\r\n\r\nThe `configure` script recognizes many CLI flags for special build formulas. Many are not represented by `vcbuild` shortcuts, and need to be passed either by:\r\n* Calling `python configure --XXX --YYY=PPPP` directly, followed by `vcbuild noprojgen`\r\n* Setting `set config_flags=--XXX --YYY=PPPP` before calling `vcbuild`\r\n\r\nThis should be documented.\r\n",
        "labels": "doc",
        "id": 44322
    },
    {
        "title": "doc: No \"view another version\" for async-hooks",
        "body": "* **Version**: All\r\n* **Platform**: All\r\n* **Subsystem**: async-hooks\r\n\r\nOn the [async-hooks](https://nodejs.org/dist/latest-v9.x/docs/api/async_hooks.html) page, there's no drop-down next to \"View as JSON\" to select the docs for another version. Since async-hooks is also experimental in v8, could there be a drop-down to choose between the v9 and v8 docs?",
        "labels": "doc",
        "id": 44323
    },
    {
        "title": "meta: commit messages with long URLs",
        "body": "Should we alleviate the 72 characters rule for lines with long URLs and note about it in the COLLABORATOR_GUIDE.md?\r\n\r\nExample: https://github.com/nodejs/node/pull/17107\r\n\r\nRefs: https://github.com/nodejs/core-validate-commit/issues/24",
        "labels": "doc",
        "id": 44324
    },
    {
        "title": "Typo in the 9.2.0 changelog.",
        "body": "\"[5d3a4ad1cf] - test: improve error **emssage** reporting in testNapiRun.js (Paul Ashfield) #16821\"\r\n\r\nNot sure what the exact line number is but it should be easily found using the above quote. I bolded the typo.\r\nhttps://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V9.md#9.2.0",
        "labels": "doc",
        "id": 44325
    },
    {
        "title": "REPL module context failure",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: v9.1.0\r\nPlatform: Darwin XXXX 17.2.0 Darwin Kernel Version 17.2.0: Fri Sep 29 18:27:05 PDT 2017; root:xnu-4570.20.62~3/RELEASE_X86_64 x86_64\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.1.0\r\n* **Platform**: Darwin XXXX 17.2.0 Darwin Kernel Version 17.2.0: Fri Sep 29 18:27:05 PDT 2017; root:xnu-4570.20.62~3/RELEASE_X86_64 x86_64\r\n* **Subsystem**: OSX 10.13.1\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nUsing a fresh install of Node 9.1.0, with no global packages or local dependencies. I use NVM to manage node.\r\n\r\nI am testing algorithms and trying out Node's new REPL module, attaching properties to the context at the end of my file as follows:\r\n\r\n```\r\nrepl.start().context = {\r\n    Bst: Bst,\r\n    myBst: myBst\r\n}\r\n```\r\n\r\nWhen I try to access either of these properties, I get an error:\r\n\r\n```\r\nTypeError: sandbox argument must have been converted to a context.\r\n    at ContextifyScript.Script.runInContext (vm.js:59:29)\r\n    at REPLServer.defaultEval (repl.js:244:29)\r\n    at bound (domain.js:280:14)\r\n    at REPLServer.runBound [as eval] (domain.js:293:12)\r\n    at REPLServer.onLine (repl.js:493:10)\r\n    at emitOne (events.js:125:13)\r\n    at REPLServer.emit (events.js:221:7)\r\n    at REPLServer.Interface._onLine (readline.js:287:10)\r\n    at REPLServer.Interface._line (readline.js:642:8)\r\n    at REPLServer.Interface._ttyWrite (readline.js:922:14)\r\n```\r\n\r\nIf I add just one property using dot notation `repl.start().context.Bst = Bst` then I can access that property. As an aside, I naively tried writing the following code with rather unexpected results:\r\n\r\n```\r\nrepl.start().context.Bst = Bst\r\nrepl.start().context.myBst = myBst\r\n```\r\n\r\nIf you run this code, two REPL servers will try and output to your shell at the same time, so every letter you type is typed twice, every command responded to (identically) twice. It's definitely two servers because incrementing a test variable will not increment it by 2, but display twice that the same variable has been incremented by 1 with the same result.",
        "labels": "doc",
        "id": 44326
    },
    {
        "title": "http.ClientRequest's 'error' event is undocumented",
        "body": "* **Version**: 9.1.0\r\n* **Platform**: all\r\n* **Subsystem**: doc\r\n\r\nMaybe I'm just missing something, but AFAIK all instances of `http.ClientRequest` can emit `error` events. However, I can't find any mention of this on https://nodejs.org/api/http.html#http_class_http_clientrequest.",
        "labels": "doc",
        "id": 44327
    },
    {
        "title": "fs.createWriteStream docs does not define flags",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe online node docs do not mention that you can set the 'a' flag to append when calling createWriteStream() and neither do any of the links of this method.\r\n\r\nIf there is a link to all the supported flags it would be useful since these are not obvious.  If they are directly copied to some Operating System specific C method that is documented, a link would be useful.\r\n\r\nIs this issue tracker the correct place to report documentation issues?\r\n\r\n",
        "labels": "doc",
        "id": 44328
    },
    {
        "title": "doc: \"View another version\" has not been updated in the docs",
        "body": "On all of the pages in the docs that have the \"View another version\" dropdown (e.g. on [this page](https://nodejs.org/docs/latest/api/assert.html)), the list of versions has not been updated. 9.x is not listed; and 4.x and 6.x, but not 8.x, are labeled \"LTS\".",
        "labels": "doc",
        "id": 44329
    },
    {
        "title": "doc events: Erroneous use of effects",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.0.0\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe docs contain an erroneous use of `effects` where the intended meaning seems to be `affects`.\r\n\r\nLocation:\r\n* v9.0.0 API docs\r\n* Events module\r\n* [EventEmitter.defaultMaxListeners](https://nodejs.org/api/events.html#events_eventemitter_defaultmaxlisteners) section\r\n* Second paragraph\r\n* First sentence\r\n\r\nCurrent text:\r\n>.. because the change effects _all_ `EventEmitter` instances, ..\r\n\r\nProposed correct text:\r\n>.. because the change affects _all_ `EventEmitter` instances, ..",
        "labels": "doc",
        "id": 44330
    },
    {
        "title": "doc events: Erroneous reference to EventListener",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.0.0\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe docs contain an erroneous reference to `EventListener`. I believe it's meant to be a reference to `EventEmitter`.\r\n\r\nLocation:\r\n* Node.js v9.0.0 API docs\r\n* Events module\r\n* [`Asynchronous vs. Synchronous`](https://nodejs.org/api/events.html#events_asynchronous_vs_synchronous) section\r\n* First sentence\r\n\r\nCurrent text:\r\n>The `EventListener` class calls all listeners synchronously ..\r\n\r\nProposed correct text:\r\n>The `EventEmitter` class calls all listeners synchronously ..",
        "labels": "doc",
        "id": 44331
    },
    {
        "title": "Document no-op console methods",
        "body": "I just noticed starting from Node@8, `console.debug()` is defined but it is a no-op.\r\n\r\nThis causes my library to not behaving correctly.\r\n\r\nIt would be better to at least mention in the documentation that they are there but are no-op.\r\n\r\nAre any of these has the same problem?\r\nhttps://github.com/nodejs/node/issues/1716#issuecomment-102722301\r\n",
        "labels": "doc",
        "id": 44332
    },
    {
        "title": "Doc version picker doesn't include 9 or show 8 as LTS",
        "body": "Will have a fix for this soon.\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44333
    },
    {
        "title": "Guide on introducing new dependencies in the codebase",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master\r\n* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWe have a guide on introducing new modules, and some guides(including WIP) on maintaining existing dependencies, but still need a guide on introducing one.\r\n\r\ncc @jasnell @jkrems @watilde because IIRC you have introduced new dependencies to the code base in the past year, would love to get your help on this.\r\n\r\nRefs: https://github.com/nodejs/node/pull/16637#issuecomment-340745757",
        "labels": "doc",
        "id": 44334
    },
    {
        "title": "crypto: Better documentation for cases where peer's public key is invalid",
        "body": "* **Version**: 6.11.3\r\n* **Platform**: Linux\r\n* **Subsystem**: crypto\r\n\r\nThe documentation for [ecdh.computeSecret](https://nodejs.org/api/crypto.html#crypto_ecdh_computesecret_otherpublickey_inputencoding_outputencoding) doesn't discuss what happens when the other public key doesn't lie on the curve. It just states that either a string with the given encoding or a Buffer will be returned. For other methods in the same class there are explicit documentation that these throws an error if for example the input is not valid for this curve, but not on this one.\r\n\r\nIf the own private key is static or not re-generated in each exchange, [there are attacks that recover the private key](https://www.iacr.org/archive/pkc2003/25670211/25670211.pdf). So all implementers need to handle this case as part of implementing a protocol where ECDH is used, by validating the provided public key and gracefully abort if the point is invalid. Using prime256v1 as an example, a first attempt might be to simply check that the buffer length of the input public key is 65 and the first byte is 0x04. But this is not enough since the point must also be checked against the curve equation. Since bignums are needed for this it's non-trivial to do this directly before the call, and one must rely on the library handling this.\r\n\r\nThankfully the actual implementation throws a generic error with the string `Failed to translate Buffer to a EC_POINT`, at least when I test it with prime256v1. I was hoping for a more catchable-friendly error, at least having a documented type or error code so it's easily distinguished to other errors. As far as my brain goes, I cannot find a single use case where one would not also want to check for this error since it's not a programmer error but always a possible user-input error.\r\n\r\nSince people are generally not aware how to use crypto, it's extremely important that the APIs are clear, easy to use and no mistakes are possible. So I was googling around a bit for \"createECDH computeSecret\" and found some code examples and tutorials. None of them handled this case or didn't even bring up the possibility that an attacker might give an incorrect public key. The only case I found testing this was the [official test file](https://github.com/nodejs/node/pull/13275/commits/479421927af669e013f0587e53370d2027f39bb3). Just guessing, but I'm pretty sure there's a bunch of production systems that will crash if one gives an incorrect public key. And when the programmer then checks the crash log generated I'm not sure he would even know what `Failed to translate Buffer to a EC_POINT` means.\r\n\r\nMy proposal is to first change the code to use some kind of typed error so it can be easily identified for this specific case and then update the documentation to catch this error in the example code as well as document in the `computeSecret` method how the invalid point error is reported. The example currently only uses `assert.strictEqual` to confirm that the two values are equal.",
        "labels": "doc",
        "id": 44335
    },
    {
        "title": "Is vm.createScript() deprecated?",
        "body": "Node >0.12, all platforms.\r\n\r\nFrom node 0.12 `vm.createScript` has been removed from the docs, but its currently still supported  due to this wrapper: https://github.com/nodejs/node/blob/master/lib/vm.js#L79\r\n\r\nSince it's missing from the docs, implementations are also missing them, for example TypeScript typings like `@types/node` are missing createScript. So is it deprecated or just missing from the docs?",
        "labels": "doc",
        "id": 44336
    },
    {
        "title": "doc: include the words \"constant time\" in crypto.timingSafeEqual description",
        "body": "I was looking for the timingSafeEqual function. I knew it existed because I'd used it before; I googled for \"node crypto constant time\". The crypto page is the 5th result for this search. I read a description of all of the API's and hit ctrl+f to search for \"constant time\" and didn't find any results.\r\n\r\nI finally found it after I reread the Github issue asking for the API\r\n\r\nIt's common to describe that algorithm as a \"constant time\" algorithm, for example in Go, the api is `subtle.ConstantTimeCompare`. This blog post addressing the problem recommends using \"constant-time algorithms\": https://codahale.com/a-lesson-in-timing-attacks/. Presumably the Node website would score higher on a Google search and the API would be more discoverable if it used the words \"constant time\" somewhere in the description.",
        "labels": "doc",
        "id": 44337
    },
    {
        "title": "doc: CHANGELOG.md link is incorrect for zlib security commit",
        "body": "The commit referenced in text is c2b1435b55, but the URL for the link is https://github.com/nodejs/node/commit/e82e2745af, which is incorrect.\r\n\r\nThat is, the current raw markdown is:\r\n\r\n```\r\n[[`c2b1435b55`](https://github.com/nodejs/node/commit/e82e2745af)]\r\n```\r\n\r\nThis appears to also be wrong on the website as well. Maybe security commits are an edge case in the changelog generator?",
        "labels": "doc",
        "id": 44338
    },
    {
        "title": "--prof flag not documented in --help output",
        "body": "* **Version**: v8.6.0\r\n* **Platform**: Linux btudb 3.13.0-133-generic #182-Ubuntu SMP Tue Sep 19 15:49:21 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: commandline\r\n\r\nSteps to reproduce:\r\n\r\nRun `node --help`\r\n\r\nExpected result:\r\n\r\nOutput includes short documentation for `--prof` flag, as described at https://nodejs.org/en/docs/guides/simple-profiling/.\r\n\r\nActual result:\r\n\r\nOutput does not include that documentation (but does include documentation for `--prof-process`).",
        "labels": "doc",
        "id": 44339
    },
    {
        "title": "doc: possible lacks in process.md",
        "body": "In `util.md` [there are some mentions](https://github.com/nodejs/node/blame/9c44215a91a7d367030eea441e1feea4a95d2ded/doc/api/util.md#L135-L150) of  `process.noDeprecation`, `process.traceDeprecation`, and `process.throwDeprecation` properties, but they seem not to be documented in the `process.md` doc. Is it OK?\r\n\r\nRefs: These mentions seem to be [added in 2014](https://github.com/nodejs/node/commit/8b041613420f27bc26f60287386efbdf69e4b8b1) only in the `util` doc.\r\n",
        "labels": "doc",
        "id": 44340
    },
    {
        "title": "RFC: doc: how should index.md be transformed to json",
        "body": "How `doc/api/index.md` is transformed to `out/doc/api/index.json` right now is sub optimal:\r\n\r\nHow it looks right now:\r\n<details>\r\n\r\n```json\r\n{\r\n  \"source\": \"doc/api/index.md\",\r\n  \"desc\": [\r\n    {\r\n      \"type\": \"html\",\r\n      \"pre\": false,\r\n      \"text\": \"<!-- [start-include:_toc.md] -->\\n\"\r\n    },\r\n    {\r\n      \"type\": \"space\"\r\n    },\r\n    {\r\n      \"type\": \"list_start\",\r\n      \"ordered\": false\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[About these Docs](documentation.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Usage & Example](synopsis.html)\"\r\n    },\r\n    {\r\n      \"type\": \"space\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_end\"\r\n    },\r\n    {\r\n      \"type\": \"html\",\r\n      \"pre\": false,\r\n      \"text\": \"<div class=\\\"line\\\"></div>\\n\\n\"\r\n    },\r\n    {\r\n      \"type\": \"list_start\",\r\n      \"ordered\": false\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Assertion Testing](assert.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Async Hooks](async_hooks.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Buffer](buffer.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[C++ Addons](addons.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[C/C++ Addons - N-API](n-api.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Child Processes](child_process.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Cluster](cluster.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Command Line Options](cli.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Console](console.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Crypto](crypto.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Debugger](debugger.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Deprecated APIs](deprecations.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[DNS](dns.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Domain](domain.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[ECMAScript Modules](esm.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Errors](errors.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Events](events.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[File System](fs.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Globals](globals.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[HTTP](http.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[HTTP/2](http2.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[HTTPS](https.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Inspector](inspector.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Internationalization](intl.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Modules](modules.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Net](net.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[OS](os.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Path](path.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Performance Hooks](perf_hooks.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Process](process.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Punycode](punycode.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Query Strings](querystring.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Readline](readline.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[REPL](repl.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Stream](stream.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[String Decoder](string_decoder.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Timers](timers.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[TLS/SSL](tls.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Tracing](tracing.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[TTY](tty.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[UDP/Datagram](dgram.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[URL](url.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Utilities](util.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[V8](v8.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[VM](vm.html)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[ZLIB](zlib.html)\"\r\n    },\r\n    {\r\n      \"type\": \"space\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_end\"\r\n    },\r\n    {\r\n      \"type\": \"html\",\r\n      \"pre\": false,\r\n      \"text\": \"<div class=\\\"line\\\"></div>\\n\\n\"\r\n    },\r\n    {\r\n      \"type\": \"list_start\",\r\n      \"ordered\": false\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[GitHub Repo & Issue Tracker](https://github.com/nodejs/node)\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_start\"\r\n    },\r\n    {\r\n      \"type\": \"text\",\r\n      \"text\": \"[Mailing List](http://groups.google.com/group/nodejs)\"\r\n    },\r\n    {\r\n      \"type\": \"space\"\r\n    },\r\n    {\r\n      \"type\": \"list_item_end\"\r\n    },\r\n    {\r\n      \"type\": \"list_end\"\r\n    },\r\n    {\r\n      \"type\": \"html\",\r\n      \"pre\": false,\r\n      \"text\": \"<!-- [end-include:_toc.md] -->\\n\"\r\n    }\r\n  ]\r\n}\r\n```\r\n\r\n</details>\r\n\r\nThere's some raw markdown and HTML poking around, and it's generally not very consumable.\r\n\r\nOne possible idea would be to turn the list of modules into a `modules` array, with objects containing `name` and `url` fields, and to format the general list of links (mailing list, etc.) in a similar manner.\r\n\r\nWDYT?",
        "labels": "doc",
        "id": 44341
    },
    {
        "title": "meta: articles about PR communication",
        "body": "Recently, I've come across these articles:\r\n\r\n1. A concise one, concerning more the PR author side:\r\n\r\nhttps://slack.engineering/on-empathy-pull-requests-979e4257d158\r\n\r\n2. An elaborate one, concerning more the PR reviewer side:\r\n\r\nhttps://mtlynch.io/human-code-reviews-1/\r\nhttps://mtlynch.io/human-code-reviews-2/\r\n\r\nI wonder if it is worth to find a place for referencing them in the CONTRIBUTING.md and COLLABORATOR_GUIDE.md respectively (or in some other more appropriate doc).\r\n\r\nP.S. A new one: https://css-tricks.com/code-review-etiquette/",
        "labels": "doc",
        "id": 44342
    },
    {
        "title": "Docs: child_process.exec() has duplicate options",
        "body": "`timeout` is listed twice:\r\n\r\nhttps://nodejs.org/api/child_process.html#child_process_child_process_exec_command_options_callback",
        "labels": "doc",
        "id": 44343
    },
    {
        "title": "Documentation for http.request options is incorrect",
        "body": "* **Version**: 8.7.0\r\n* **Platform**: all\r\n* **Subsystem**: `http`\r\n\r\nThe documentation for `options.agent` parameter for `http.request`, is incorrect.\r\n\r\n### Problems\r\nThe API documentation for `http.request`:\r\n1) says that if `options.agent` is `undefined`, `http.Agent` is used.\r\n2) the documentation for `port` is incorrect.\r\n3) doesn't mention `options._defaultAgent`\r\n\r\n### Corrections\r\n1) `Agent.globalAgent` is used rather than `http.Agent`.\r\n(see the `ClientRequest` constructor in lib/_http_client.js)\r\n2) There is an undocumented option `options.defaultPort`, which can be used to define the port. Otherwise the default agent's `port` is used.\r\n3) `options._defaultAgent` should be documented.\r\n\r\n",
        "labels": "doc",
        "id": 44344
    },
    {
        "title": "Improve trace_event documentation",
        "body": "* **Version**: master\r\n* **Platform**: all\r\n* **Subsystem**: `trace_events`, `docs`\r\n\r\nThe [`trace_events`](https://github.com/nodejs/node/blob/master/doc/api/tracing.md) documentation is rather short and titled wrong.\r\n\r\nWe should:\r\n\r\n* change title from `tracing` to `trace_event`\r\n* describe what each category contains:\r\n  * `v8` events are GC, compiling, and execution related\r\n  * `node` is a placeholder. Doesn't actually contain anything\r\n  * `node.async_hooks` events have an id and a special `triggerId` property.\r\n* link to the output format specifications\r\n\r\nref: https://github.com/nodejs/node/pull/15538#issuecomment-337859069",
        "labels": "doc",
        "id": 44345
    },
    {
        "title": "Docs on http.Server.listen() need clarifications on accepted args ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v4-v8\r\n* **Platform**: macOS 10.12.6\r\n* **Subsystem**: http, net\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis is in relation to https://github.com/facebook/flow/issues/1684\r\n\r\nWhile Flow typing a module that uses `http.Server.listen()`, I received an error for the idiomatic form [widely used in Node projects](https://github.com/search?l=JavaScript&q=http.createServer%28%29+listen+function&type=Code&utf8=%E2%9C%93):\r\n\r\n```\r\nconst server = http.createServer();\r\nserver.listen(8080, function listening() {});\r\n```\r\n\r\nFlow declares the types of `http.Server.listen()` like this:\r\n\r\n```\r\ndeclare module \"http\" {\r\n  declare class Server extends net$Server {\r\n    listen(port: number, hostname?: string, backlog?: number, callback?: Function): Server;\r\n    listen(path: string, callback?: Function): Server;\r\n    listen(handle: Object, callback?: Function): Server;\r\n```\r\n\r\nwhich adheres to the [documentation of the `http` module](https://nodejs.org/dist/latest-v8.x/docs/api/http.html#http_server_listen_port_hostname_backlog_callback).\r\n\r\nSince the `net` module [normalizes the arguments](https://github.com/nodejs/node/blob/53c5bf546e8e52db5b11287ab3bf1375819b369b/lib/net.js#L124-L157) and Node itself uses the shorthand forms in the docs on the same page ([Event: 'connect'](https://nodejs.org/api/http.html#http_event_connect), [Event: 'upgrade'](https://nodejs.org/api/http.html#http_event_upgrade)), I suggest to amend the documentation explaining the shorthand forms are both supported:\r\n\r\n```\r\nlisten(port, callback)\r\nlisten(port, hostname, callback)\r\n```\r\n\r\nThoughts?",
        "labels": "doc",
        "id": 44346
    },
    {
        "title": "os.cpus() docs misleading",
        "body": "The docs for [`os.cpus()`](https://github.com/nodejs/node/blob/master/doc/api/os.md#oscpus) state:\r\n\r\n> The `os.cpus()` method returns an array of objects containing information about each CPU/core installed.\r\n\r\nIt would be more accurate to use the word \"threads\" rather than \"CPU/core\". Not sure if this behaviour is intentional or due to how the OS reports cores. Either way, a note in the docs would be helpful to clarify this. Do you want a PR?\r\n\r\nExample:\r\n\r\n```\r\n$ sysctl -n machdep.cpu.brand_string\r\nIntel(R) Core(TM) i5-5257U CPU @ 2.70GHz\r\n\r\n$ sysctl -n machdep.cpu.core_count\r\n2\r\n\r\n$ sysctl -n machdep.cpu.thread_count\r\n4\r\n\r\n$ node -e \"console.log(require('os').cpus().length)\"\r\n4\r\n```",
        "labels": "doc",
        "id": 44347
    },
    {
        "title": "Cannot find a module with more than 2 dots prefix, ex require('..my-module')",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.1.0+\r\n* **Platform**: Windows 7 64-bit\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIn docs of modules:\r\n>3. If X begins with './' or '/' or '../'\r\n>   a. LOAD_AS_FILE(Y + X)\r\n>   b. LOAD_AS_DIRECTORY(Y + X)\r\n\r\nBut in [modules.js](https://github.com/nodejs/node/blob/c81fd7c5ea94685d6aaf175f24a547b3e95b5089/lib/module.js#L329), only checked './' or '..'. So, if the module name is leading with '..', It is always used as a relative path\r\n```\r\nif (request.charCodeAt(0) !== 46/*.*/ &&\r\n      (request.charCodeAt(1) !== 46/*.*/ &&\r\n       request.charCodeAt(1) !== 47/*/*/)) {\r\n    ...\r\n}\r\n```\r\nMaybe no one will name module like this, but may need mention it at docs. : )",
        "labels": "doc",
        "id": 44348
    },
    {
        "title": "Add missing sections to Collaborator Guide",
        "body": "The Collaborate Guide at https://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md is missing the following sections/details (https://github.com/nodejs/TSC/issues/382#issuecomment-336680689)\r\n\r\n* What is a Collaborator\r\n* What expectations do Collaborators have\r\n* What privileges do Collaborators get\r\n* How do I become a Collaborator\r\n\r\n\r\n\r\n",
        "labels": "doc",
        "id": 44349
    },
    {
        "title": "async_hooks: async hook stack corruption when exception prevents AsyncResource.emitAfter being called.",
        "body": "* **Version**: 8.2.1, 8.7\r\n* **Platform**:\r\n* **Subsystem**: async_hooks\r\n\r\nAccording to `async_hooks` docs,\r\n> If the user's callback throws an exception, emitAfter() will automatically be called for all asyncIds on the stack if the error is handled by a domain or 'uncaughtException' handler.\r\n\r\nHowever, this doesn't seem to work in practice. If I set up a simple AsyncResource to bind a function to its own execution context, \r\n```js\r\nclass BoundFunction extends asyncHooks.AsyncResource {\r\n  constructor(f) {\r\n    super('BOUND_FUNCTION');\r\n    this.f = f;\r\n  }\r\n\r\n  run() {\r\n    this.emitBefore();\r\n    f();\r\n    this.emitAfter();\r\n  }\r\n}\r\n```\r\n\r\nand use it like\r\n\r\n```js\r\nconst f = () => {\r\n  throw new Error('uh ho');\r\n};\r\n\r\nconst boundF = new BoundFunction(f);\r\n\r\nprocess.nextTick( () => {\r\n  try {\r\n    boundF.run();\r\n  } catch (e) {\r\n    console.log('nothing to worry about');\r\n  }\r\n});\r\n```\r\nThen I get the following output from node:\r\n```\r\n$ node src/demonstration.js\r\nnothing to worry about\r\nError: async hook stack has become corrupted (actual: 5, expected: 6)\r\n 1: node::AsyncWrap::PopAsyncIds(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 2: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [node]\r\n 3: 0xb8f43c [node]\r\n 4: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) [node]\r\n 5: 0x3aa19890463d\r\n```\r\n\r\nThis happens even if I set up handlers for uncaught exceptions and rejections:\r\n```js\r\nprocess.on('uncaughtException', (e) => { console.log('no worries'); });\r\nprocess.on('unhandledRejection', (e) => { console.log('relax bro'); });\r\n```\r\n\r\nIf I change `BoundFunction#run` to look like\r\n```js\r\nrun() {\r\n  this.emitBefore();\r\n  try {\r\n    f();\r\n  } finally {\r\n    this.emitAfter();\r\n  }\r\n}\r\n```\r\n\r\nthe error goes away. I am fine with my handler looking like that, but it's a bit confusing that the docs seem to say that it shouldn't be required.",
        "labels": "doc",
        "id": 44350
    },
    {
        "title": "doc: HTTP/2 client doc contains an undefined reference ",
        "body": "The \"HTTP/2 CONNECT client\" [docs](https://github.com/nodejs/node/blob/master/doc/api/http2.md) reference `common`, which is not referenced elsewhere in the code. \r\n\r\n```js\r\nreq.on('response', common.mustCall());\r\n```\r\n\r\nI am not sure what `common` is in this case and there are no other references to `common` in the docs.",
        "labels": "doc",
        "id": 44351
    },
    {
        "title": "doc: 404 link in doc/releases.md",
        "body": "I am not good at GPG things, so this is just a report.\r\n\r\nThis link in the [doc/releases.md#3-a-publicly-listed-gpg-key](https://github.com/nodejs/node/blob/master/doc/releases.md#3-a-publicly-listed-gpg-key) is 404:\r\n\r\nhttps://sks-keyservers.net/i/#submit\r\n\r\nRefs to possible solutions:\r\n\r\nhttps://github.com/nodejs/node/pull/15675#issuecomment-333058169\r\nhttps://github.com/nodejs/node/pull/15675#issuecomment-333066580\r\n",
        "labels": "doc",
        "id": 44352
    },
    {
        "title": "Handing spawn() stdio as socket wont duplex properly",
        "body": "* **Version**: At least v6.9.1 and v8.5.0\r\n* **Platform**: Darwin Kernel Version 14.5.0: Wed Jul 29 02:26:53 PDT 2015; x86_64\r\n\r\nI'm trying to implement a sort of `PassThrough`-style stream that can be used as mock stdio for `ChildProcess.spawn()`.  `PassThrough` itself isn't appropriate because it doesn't have a file descriptor.  So I'm doing this by creating a socket that speaks to an echo server.  What I'm finding is that the server receives the data and successfully pipes it, but the passthrough socket never seems to receive it.\r\n\r\nI've poked around the node internals a bit to figure-out why, but I don't have much to share at this time.  It looks like `spawn()` may create another socket that's readable and not writable, and uses the socket I passed as its handle [[here](https://github.com/nodejs/node/blob/2dcb7f3826a360f7cac79a58833dc4c037f67e27/lib/internal/child_process.js#L242-L254)].  But my socket remains readable and writable as I would expect, so I still can't explain the behavior!\r\n\r\nPossibly related to https://github.com/nodejs/node/issues/9413.  Here's some code to reproduce the issue and play with.\r\n\r\n```js\r\n'use strict';\r\n\r\nconst ChildProcess = require('child_process');\r\nconst Net = require('net');\r\n\r\nconst makePassThrough = (cb) => {\r\n\r\n    const srv = Net.createServer((sock) => {\r\n\r\n        sock.on('data', (data) => console.log('server sock saw data:', data.toString()));\r\n        sock.once('close', () => console.log('server sock closed'));\r\n        sock.once('end', () => console.log('server sock ended'));\r\n        sock.once('error', (err) => console.log('server sock errored', err));\r\n        sock.once('timeout', () => console.log('server sock timed-out'));\r\n\r\n        sock.pipe(sock);\r\n    });\r\n\r\n    srv.once('close', () => console.log('server closed'));\r\n    srv.once('error', cb);\r\n    srv.listen(() => {\r\n\r\n        const sock = new Net.Socket();\r\n\r\n        sock.once('close', () => console.log('client sock closed'));\r\n        sock.once('end', () => console.log('client sock ended'));\r\n        sock.once('error', (err) => console.log('client sock errored', err));\r\n        sock.once('timeout', () => console.log('client sock timed-out'));\r\n\r\n        sock.once('error', cb);\r\n        sock.connect(srv.address().port, () => cb(null, sock));\r\n    });\r\n};\r\n\r\nmakePassThrough((err, stdout) => {\r\n\r\n    if (err) {\r\n        throw err;\r\n    }\r\n\r\n    stdout.on('data', (data) => console.log('subproc stdout saw data:', data.toString()));\r\n\r\n    const subproc = ChildProcess.spawn('echo', ['is anybody out there?'], {\r\n        stdio: ['ignore', stdout, 'ignore']\r\n    });\r\n\r\n    subproc.on('close', process.exit);\r\n});\r\n\r\n/* Program outputs the following,\r\n      $ node index.js \r\n      server sock saw data: is anybody out there?\r\n      # Does not exit\r\n*/\r\n```\r\n\r\nFor my purposes I'm all setâ€“ I can use `stdio: 'pipe'` and pipe the process's stdio thru actual passthrough streams.  This is still a curiosity, though!",
        "labels": "doc",
        "id": 44353
    },
    {
        "title": "buffer.transcode: document valid encodings",
        "body": "The [documentation for `buffer.transcode` states](https://nodejs.org/api/buffer.html#buffer_buffer_transcode_source_fromenc_toenc):\r\n\r\n> Throws if the fromEnc or toEnc specify invalid character encodings or if conversion from fromEnc to toEnc is not permitted.\r\n\r\nHowever, the documentation does not specify which encodings are valid.\r\n\r\n(I was trying to transcode a Buffer into a Buffer with the same bytes, base64 encoded. My goal was to replace the `+` and `/` characters with `-` and `_` without needing to create an entirely new string or call `.replace`).",
        "labels": "doc",
        "id": 44354
    },
    {
        "title": "document the `test/common/dns` module",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.0.0-pre\r\n* **Platform**: n/a\r\n* **Subsystem**: test\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nThe module in `test/common/dns.js` should be documented in `test/common/README.md` similar to the way the other modules in  `test/common` are documented there.",
        "labels": "doc",
        "id": 44355
    },
    {
        "title": "Add a guide for uncaught exceptions in node?",
        "body": "Hi folks,\r\n\r\nBit new to node. I read that one unhandled exception can kill whole node server, is this true? (I guess yes).\r\nNow, given that I think it is not easy to program in a way you are sure that there are never uncaught exceptions, and you don't want that single uncaught exception to kill server, what are the mechanisms node offers to deal with this situation?\r\nI head about cluster. Also domains - but doc says they are deprecated.\r\nSo do you mind adding a guide (maybe here: https://nodejs.org/en/docs/guides/) on the latest trend on how to deal with uncaught exceptions in a robust manner?\r\n\r\nThis is the kind of doc I am referring to, to create doc similar to this one: https://shapeshed.com/uncaught-exceptions-in-node/\r\n(though that one is from 2012)",
        "labels": "doc",
        "id": 44356
    },
    {
        "title": "Strange behavior for CLI options -e and -p on Windows",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.5.0\r\n* **Platform**: Windows 64\r\n* **Subsystem**: cli\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nHi,\r\n\r\nAs I went through the [CLI tutorial,](https://blog.risingstack.com/mastering-the-node-js-cli-command-line-options/) I came across a strange situation while executing simple command.\r\n\r\nThe problem was with this two commands, with options `-p` and `-e`\r\n`$ node -e 'console.log(3 + 2)'`\r\nand \r\n`$ node -p '3 + 2'`\r\n\r\nOn Linux those two commands execute correctly.\r\n\r\n```\r\nlukaszs@RS18:~$ node -e 'console.log(3 + 4)'\r\n7\r\nlukaszs@RS18:~$ node -p '3 + 2'\r\n5\r\nlukaszs@RS18:~$\r\n```\r\n\r\nBut on Windows I receive this:\r\n\r\n1. First for the `node -e 'console.log(3 + 4)'`\r\n\r\n```\r\nC:\\Users\\lukaszs>node -e 'console.log(3 + 4)'\r\n[eval]:1\r\n'console.log(3\r\n^^^^^^^^^^^^^^\r\n\r\nSyntaxError: Invalid or unexpected token\r\n    at createScript (vm.js:74:10)\r\n    at Object.runInThisContext (vm.js:116:10)\r\n    at Object.<anonymous> ([eval]-wrapper:6:22)\r\n    at Module._compile (module.js:573:30)\r\n    at evalScript (bootstrap_node.js:452:27)\r\n    at startup (bootstrap_node.js:139:9)\r\n    at bootstrap_node.js:598:3\r\n```\r\n\r\nAfter I remove spaces, I got no error, but without a result:\r\n\r\n```\r\nC:\\Users\\lukaszs>node -e 'console.log(3+4)'\r\n\r\nC:\\Users\\lukaszs>\r\n```\r\nSo I change the `-e` option to `-p`, I receive this:\r\n\r\n```\r\nC:\\Users\\lukaszs>node -p 'console.log(3+4)'\r\nconsole.log(3+4)\r\n\r\nC:\\Users\\lukaszs>\r\n```\r\nNode prints my script as a string without evaluating it.\r\n\r\n2. The very similar situation was with second command: ` node -p '3 + 2'`\r\n\r\n```\r\nC:\\Users\\lukaszs>node -p '3 + 2'\r\n[eval]:1\r\n'3\r\n^^\r\n\r\nSyntaxError: Invalid or unexpected token\r\n    at createScript (vm.js:74:10)\r\n    at Object.runInThisContext (vm.js:116:10)\r\n    at Object.<anonymous> ([eval]-wrapper:6:22)\r\n    at Module._compile (module.js:573:30)\r\n    at evalScript (bootstrap_node.js:452:27)\r\n    at startup (bootstrap_node.js:139:9)\r\n    at bootstrap_node.js:598:3\r\n```\r\nAfter removing spaces, I receive string like in the previous example:\r\n\r\n```\r\nC:\\Users\\lukaszs>node -p '3+2'\r\n3+2\r\n\r\nC:\\Users\\lukaszs>\r\n```\r\n\r\n\r\nSo I went to the [CLI docs](https://nodejs.org/api/cli.html#cli_e_eval_script), I I saw this description:\r\n\r\n```\r\n-e, --eval \"script\"\r\n\r\nEvaluate the following argument as JavaScript. The modules which are predefined in the REPL can also be used in script.\r\n\r\n-p, --print \"script\"\r\n\r\nIdentical to -e but prints the result.\r\n```\r\nThere is one difference in my examples according to docs. It seams I need to use  double quote `\"` instead of single quote `'`.\r\n\r\nSo let's test it.\r\n\r\n```\r\nC:\\Users\\lukaszs>node -e \"console.log(3 + 4)\"\r\n7\r\n\r\nC:\\Users\\lukaszs>\r\n```\r\n\r\nOk, this works!\r\n\r\n```\r\nC:\\Users\\lukaszs>node -p \"3 + 2\"\r\n5\r\n\r\nC:\\Users\\lukaszs>\r\n```\r\n\r\nAnd another example works too.\r\n\r\nSo it looks like for Windows I need to use double quote `\"` but on Linux it doesn't matter what I used, because every version works on Linux.\r\n\r\n```\r\nlukaszs@RS18:~$ node -p '3 + 2'\r\n5\r\nlukaszs@RS18:~$ node -p \"3 + 2\"\r\n5\r\nlukaszs@RS18:~$ node -e 'console.log(3 + 4)'\r\n7\r\nlukaszs@RS18:~$ node -e \"console.log(3 + 4)\"\r\n7\r\nlukaszs@RS18:~$\r\n```\r\n\r\nIf this is not a bug, but expected result, I think there should be at least some info in the docs that on Windows you should use only double quote `\"`. Because without this info, going thru tutorials you can get really frustrated when you try to execute this simple command and it not work.\r\n\r\n",
        "labels": "doc",
        "id": 44357
    },
    {
        "title": "doc: links with 404 status",
        "body": "1. http://man7.org/linux/man-pages/man3/uname.3.html : 3 links in the os.html/os.md (with innerText `uname(3)`).\r\n\r\n2. http://csrc.nist.gov/publications/nistpubs/800-132/nist-sp800-132.pdf : 2 links in the crypto.html/crypto.md (with innerText `NIST SP 800-132`).\r\n\r\nWhat would be suggestions to replace them with?",
        "labels": "doc",
        "id": 44358
    },
    {
        "title": "fs.utimes Infinity support is misdocumented or regressed",
        "body": "* **Version**: 8.5.0\r\n* **Platform**: Windows\r\n* **Subsystem**: fs\r\n\r\nPotentially related to #14017.\r\n\r\nTake this code:\r\n\r\n```js\r\nfs.utimes(path, Infinity, 0)\r\n```\r\n\r\n(I needed to set the mtime to some point in the past for `make`â€™s sake so it wouldnâ€™t consider a broken file to be up to date and would try again. Not sure quite why I wrote `Infinity` for the atime rather than `Date.now() / 1000`, though I believe they were equivalent.)\r\n\r\nThe [`fs.utimes` documentation](https://nodejs.org/api/fs.html#fs_fs_utimes_path_atime_mtime_callback) is inconsistent on how infinities should be handled:\r\n\r\nIn its history, it says that in v4.1.0, â€œNumeric strings, `NaN` and `Infinity` are now allowed time specifiers.â€ There is no note saying that `NaN` and `Infinity` are no longer permitted from such-and-such a version, yet the function documentation says â€œIf the value is `NaN`, `Infinity` or `-Infinity`, an Error will be thrown.â€\r\n\r\nEither the history should be updated to indicate when infinties became illegal again, or this is a regression.\r\n\r\nThis worked on some Node 4 version, but itâ€™s not working on 8.5.0 (I just upgraded).",
        "labels": "doc",
        "id": 44359
    },
    {
        "title": "Cannot properly close/cleanup character device ReadStream (process hangs)",
        "body": "Issue observed on two distinct systems:\r\n\r\n* System 1. Linux laptop\r\n  * **Version**: 8.4.0\r\n  * **Platform**: Arch Linux 4.11.9 (x86_64)\r\n\r\n* System 2. Beaglebone Black\r\n  * **Version**: 6.10.3\r\n  * **Platform**: Linux 4.9.41 (armv71)\r\n\r\nI'm using [fs.ReadStream](https://nodejs.org/api/fs.html#fs_class_fs_readstream) to continuously read from a _character device_, e.g. `/dev/input/event0`. Receiving events works great, but on attempting to shut down the process does not exit as expected. Googling has turned up similar-sounding issues [all the way back to node-0.x](https://github.com/nodejs/node-v0.x-archive/issues/7101), but I have been unable to find a solution.\r\n\r\n**Code to reproduce (behaves the same on both aforementioned systems):**\r\n\r\n```js\r\nconst fs = require('fs')\r\nconst stream = fs.createReadStream('/dev/input/event0')\r\n\r\nstream\r\n  .on('end', () => { console.log('End') })\r\n  .on('open', fd => { console.log(`Opened (fd=${fd})`) })\r\n  .on('close', () => { console.log('Closed') })\r\n  .on('error', err => { console.log(`Error: ${err}`) })\r\n  .on('data', data => { console.log(data) })\r\n\r\nsetTimeout(() => {\r\n  console.log('Attempting to close stream')\r\n\r\n  stream.on('close', () => {\r\n    console.log(`Stream fd is now ${stream.fd}`)\r\n    process.exit(0) // Hangs\r\n  })\r\n\r\n  stream.close()\r\n}, 1000)\r\n```\r\n\r\n**Output:**\r\n\r\n```\r\nOpened (fd=9)\r\nAttempting to close stream\r\nClosed\r\nStream fd is now null\r\n(Hung here, ^C or kill process to exit)\r\n```\r\n\r\n**A few interesting (?) observations:**\r\n\r\nExplicitly obtaining the file descriptor we get identical results, **_unless_** if the `.on('data', ...)` listener is _not_ attached, in which case we can exit as expected. Removing the listener in the shutdown process does not work, however, nor do we get this behavior if the `fd` is opened by `fs.createReadStream` (i.e. simply commenting out the `.on('data', ...)` from the first sample. Adjusted sample:\r\n\r\n```js\r\nconst fs = require('fs')\r\n\r\nconst fd = fs.openSync('/dev/input/event0', 'r')\r\nconst stream = fs.createReadStream('ignored', { fd: fd })\r\n\r\nstream\r\n  .on('end', () => { console.log('End') })\r\n  //.on('open', fd => { console.log(`Opened (fd=${fd})`) }) // No event, as expected\r\n  .on('close', () => { console.log('Closed') })\r\n  .on('error', err => { console.log(`Error: ${err}`) })\r\n  //.on('data', data => { console.log(data) }) // Exit works if commented out\r\n\r\nsetTimeout(() => {\r\n  console.log('Attempting to close stream')\r\n\r\n  //stream.removeAllListeners('data') // No result\r\n\r\n  stream.on('close', () => {\r\n    console.log(`Stream fd is now ${stream.fd}`)\r\n    process.exit(0)\r\n  })\r\n\r\n  stream.close()\r\n  //fs.closeSync(fd) // Does not trigger the `close` event\r\n}, 1000)\r\n``` \r\n\r\nThis is probably not related to the problem, but I get the same result if I \"trigger\" an `end`-event by doing the following in my shutdown routine as such:\r\n\r\n```js\r\n// `.push(null)` and `.read(0)` together trigger an `end` event\r\nstream.push(null)\r\nstream.read(0)\r\n```\r\n\r\nIs this a bug, or am I simply missing something? Cheers!",
        "labels": "doc",
        "id": 44360
    },
    {
        "title": "Error on performance.timerify(fn) example",
        "body": "The example show\r\n\r\n```\r\nobs.observe({ entryTypes: 'function' });\r\n```\r\n\r\nMust be\r\n\r\n```\r\nobs.observe({ entryTypes: ['function'] });\r\n```\r\n",
        "labels": "doc",
        "id": 44361
    },
    {
        "title": "docs: empty version picker on some pages",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.5.0\r\n* **Platform**: n/a\r\n* **Subsystem**: n/a\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe version picker I added to the docs recently does not properly account for pages without the `<-- introduced_in -->` tag, or pages with the tag but without multiple version of the doc. The [n-api docs](https://nodejs.org/dist/latest-v8.x/docs/api/n-api.html) are a good example of this. The version drop down is there, but has no options when you click on it. \r\n\r\n__Affected pages:__ async_hooks, n-api, deprecations, esm, http2, inspector, intl, perf_hooks, tracing\r\n\r\nI already started working on a fix for this and will open a pr later tonight.",
        "labels": "doc",
        "id": 44362
    },
    {
        "title": "http2: Change in respondWithFile api not properly reflected in the docs",
        "body": "The `respondWithFile` api has changed between 8.4.0 and 8.5.0 with the addition of the onError option. This is important, because a simple `response.stream.on('error'...` no longer works after this change because the steam gets destroyed on an error (in particular on ENOENT) if `onError` doesn't exist so any attempt to resend a different file then crashes with stream undefined.\r\n\r\nHowever the docs, although creating an `onError` function in the example then doesn't actually use it on the call to `respondWithFile`",
        "labels": "doc",
        "id": 44363
    },
    {
        "title": "doc - wrong history entry",
        "body": "In the release notes of v.8.5.0 there is a small error (see https://github.com/nodejs/node/commit/a10856a7d31f9b641bf330fe9edfa9728f4b1c78#commitcomment-24266628).\r\n\r\nI open this as good first contribution.",
        "labels": "doc",
        "id": 44364
    },
    {
        "title": "Document how to use StringDecoder in combination with stream.Transform",
        "body": "In https://github.com/nodejs/node/issues/7315 and https://github.com/nodejs/node/pull/7425, it was discussed how to add string decoding capabilities to `Writable`. However, that is very tricky to implement without a performance regression. At the bare minimum, we should document this inside the streams API docs.\r\n\r\nSee https://github.com/mcollina/split2/blob/master/index.js as an example.\r\n",
        "labels": "doc",
        "id": 44365
    },
    {
        "title": "Incorrect information in 8.5.0 changelog",
        "body": "Per https://github.com/nodejs/node/pull/15308#issuecomment-328874385, the following needs to be removed from the 8.5.0 changelog as it is not correct: `, as is a Node.js specific flavor of the Frame Timing for measuring event loop duration.`\r\n\r\nping @MylesBorins ",
        "labels": "doc",
        "id": 44366
    },
    {
        "title": "fs.watchFile inconsistent stat return",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: tested on v8.4.0 and v6.11.2\r\n* **Platform**: GNU/Linux (Centos 7)\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nHi!\r\n\r\nI encountered the following problem when using **fs.watchFile**. I start watching a file, let's say _file1_, the file is renamed into _file2_ and then back into _file1_. \r\n\r\nOn the first rename, my listener is called with currentStat filled with 0s (correct, as the file does not exist) and some values for the previousStat. \r\n\r\nOn the second rename, when the file gets the name it had initially, the previousStat is the same one as the previousStat of the first rename (I think it should be the one filled with 0s, as the file did not exist previously) and has the same modified time as the currentStat. This way, I cannot determine that the file has reappeared. \r\n\r\nI am comparing that the modified time has changed in order to avoid false alarms triggered by file access as specified in the Node.js documentation.",
        "labels": "doc",
        "id": 44367
    },
    {
        "title": "http2 - document compat differences against h1",
        "body": "e.g.\r\n\r\nhttps://github.com/nodejs/node/issues/15318\r\nhttps://github.com/nodejs/node/issues/15317\r\nhttps://github.com/nodejs/node/issues/15312",
        "labels": "doc",
        "id": 44368
    },
    {
        "title": "http2 - modifying compat req pseudo headers",
        "body": "When modifying a compat request headers some properties that depend on pseudo headers stop working. I'm not sure if this would count as compat breaking?\r\n\r\ne.g.\r\n\r\n```js\r\nremoveAllHeaders(req)\r\nassert(req.url) // uhoh? This worked before http/2\r\n```\r\n\r\n@apapirovski",
        "labels": "doc",
        "id": 44369
    },
    {
        "title": "doc, stream: readable._destroy() description is missing in the stream.md",
        "body": "* **Subsystem**: doc, stream\r\n\r\nThere is a [link](https://github.com/nodejs/node/blame/89f207499a3db9f7dda7a99d82ffd78870cca8a7/doc/api/stream.md#L2225) to `readable._destroy()` in the `stream.md` after https://github.com/nodejs/node/commit/330c8d743e33a83f85389ea8a64e3d3854ea0048, but there is no `readable._destroy()` description in the [Implementing a Readable Stream](https://github.com/nodejs/node/blame/89f207499a3db9f7dda7a99d82ffd78870cca8a7/doc/api/stream.md#L1510) part.\r\n\r\ncc @mcollina",
        "labels": "doc",
        "id": 44370
    },
    {
        "title": "Buffer.allocUnsafeSlow() allowed version in document is incorrect, actually is v5.12.0",
        "body": "* **Version**: v6.2.0+\r\n* **Platform**: N/A\r\n* **Subsystem**: buffer, document\r\n\r\nBuffer.allocUnsafeSlow() was added in `v5.12.0`\r\n\r\n## Source Code: \r\nhttps://github.com/nodejs/node/blob/v5.10.0/lib/buffer.js\r\nhttps://github.com/nodejs/node/blob/v5.12.0/lib/buffer.js `line 160`\r\n\r\n## In Documents\r\nhttps://nodejs.org/dist/v6.2.0/docs/api/buffer.html#buffer_class_method_buffer_allocunsafeslow_size\r\n...\r\nhttps://nodejs.org/api/buffer.html#buffer_class_method_buffer_allocunsafeslow_size",
        "labels": "doc",
        "id": 44371
    },
    {
        "title": "No all-in-one place list of builtin module names in documentation",
        "body": "* **Version**:  All\r\n* **Platform**: N/A\r\n* **Subsystem**: documentation\r\n\r\nThe Node.js online documentation appears not to contain a simple list (alphabetical or by type) of builtin module names.  For someone just trying to look at a js file and determine which of its require()d dependencies are builtins and which are 3rd-party modules, this is problematic.\r\n\r\nThe docs TOC in the left column lists modules by a full name - but this doesn't always correspond to the name used to load them with require().  So for example, a `require('dgram')` doesn't match any of the section names that make up that TOC, and so it appears not to be a builtin module, when it actually is.  You need to do a full-text search on the docs to find out it's actually a builtin module.\r\n\r\nThe docs should have a section \"here's the builtin module names\" where each one links to the docs for the associated module.",
        "labels": "doc",
        "id": 44372
    },
    {
        "title": "http2 - destruction docs missing bullet",
        "body": "I think the bullet list here https://nodejs.org/dist/latest-v8.x/docs/api/http2.html#http2_destruction is missing \"`HTTP2Stream.destroy()` is called\".",
        "labels": "doc",
        "id": 44373
    },
    {
        "title": "http2 - http2stream.state docs",
        "body": "`http2stream.state` seems to be part of the public api. However, it's properties and what they mean/do is not documented?\r\n\r\ne.g. `http2stream.state.state` is a number, but what the number means is not explained.",
        "labels": "doc",
        "id": 44374
    },
    {
        "title": "http2 - rst docs",
        "body": "I'm not sure if it is out of scope of the documentation. However, it would be nice if the docs could explain a bit more about the `rst` related props and methods. How to use them, when, why and maybe examples?",
        "labels": "doc",
        "id": 44375
    },
    {
        "title": "http -  http.ClientRequest doesn't emit 'aborted'?",
        "body": "Looking through the _http_client.js code it seems to me that the ` http.ClientRequest` object never emits an Â´abortedÂ´ event (only `close`). It's just the response object that emits the `aborted` event. \r\n\r\nhttps://github.com/nodejs/node/blob/master/lib/_http_client.js#L366\r\n\r\nThat  seems to go against the docs, https://nodejs.org/api/http.html#http_event_aborted",
        "labels": "doc",
        "id": 44376
    },
    {
        "title": "Automate detection of dead doc links",
        "body": "Links in docs get regularily broken ([example](https://github.com/nodejs/node/pull/15182)), and it should be possible to have a script that iterates all links in the docs and checks for a HTTP response code of < 400.\r\n\r\nProbably not something we want to run as part of the CI, but I could see the script being run on-demand regularily.",
        "labels": "doc",
        "id": 44377
    },
    {
        "title": "http2 - HTTP2Session and Sockets",
        "body": "The following link [https://nodejs.org/api/http2.html#http2_http2sesion_and_sockets](https://nodejs.org/api/http2.html#http2_http2sesion_and_sockets) referred at [https://nodejs.org/api/http2.html#http2_http2session_socke](https://nodejs.org/api/http2.html#http2_http2session_socket) doesn't seem to work.",
        "labels": "doc",
        "id": 44378
    },
    {
        "title": "Net.md documentation never mentions signature of 'callback' argument of server.listen()",
        "body": "Several versions of `server.listen()` function are described in Net documentation: https://github.com/nodejs/node/blob/master/doc/api/net.md\r\n\r\nDocumentation also refers to `callback` argument and says that it is a function, but never mentions that first argument of that function is `error` object, in case the server failed to start.\r\n\r\nI would've added that myself and created a pull request, but I don't think I possess enough knowledge to mess with documentation of core node.js parts. Thus I just leave this issue.\r\n\r\nThanks!",
        "labels": "doc",
        "id": 44379
    },
    {
        "title": "Proposal to document StringDecoder#lastNeed",
        "body": "I propose to document `StringDecoder#lastNeed` as it is useful to check if the decoder is waiting for any input or the string result of `StringDecoder#write` is ready to be parsed.",
        "labels": "doc",
        "id": 44380
    },
    {
        "title": "http.ClientRequest documentation inconsistencies (again)",
        "body": "* **Version**:\r\nOnline docs at https://nodejs.org/dist/latest-v8.x/docs/api/http.html\r\n\r\nIt seems #5717 is still not fixed in online docs available at https://nodejs.org/dist/latest-v8.x/docs/api/http.html#http_class_http_clientrequest .",
        "labels": "doc",
        "id": 44381
    },
    {
        "title": "Discrepancies between error list and documentation",
        "body": "There are a few discrepancies between the errors defined in `lib/internal/errors.js` and those appearing in the documentation in `doc/api/errors.md`. The differences are outlined below (I compiled this list manually, and it's possible some errors are missing -- please comment if so!!), and this should be fairly straightforward to solve -- people would just need to submit PRs to fill in the missing documentation :)\r\n\r\ncc @trott\r\n\r\n---\r\n\r\n**yes** `lib/internal/errors.js`, **no** `doc/api/errors.md`\r\n\r\n- [ ] ERR_ASYNC_CALLBACK\r\n- [ ] ERR_ASYNC_TYPE\r\n- [ ] ERR_ENCODING_NOT_SUPPORTED\r\n- [ ] ERR_ENCODING_INVALID_ENCODED_DATA\r\n- [ ] ERR_HTTP_INVALID_CHAR\r\n- [ ] ERR_HTTP2_HEADER_REQUIRED\r\n- [ ] ERR_HTTP2_HEADERS_AFTER_RESPOND\r\n- [ ] ERR_HTTP2_INVALID_PACKED_SETTINGS_LENGTH\r\n- [ ] ERR_INVALID_ASYNC_ID\r\n- [ ] ERR_NAPI_CONS_FUNCTION\r\n- [ ] ERR_NAPI_CONS_PROTOTYPE_OBJECT\r\n- [ ] ERR_PARSE_HISTORY_DATA\r\n- [ ] ERR_INVALID_PERFORMANCE_MARK\r\n- [ ] ERR_OUTOFMEMORY\r\n- [ ] ERR_TLS_CERT_ALTNAME_INVALID\r\n- [ ] ERR_TLS_DH_PARAM_SIZE\r\n- [ ] ERR_TLS_HANDSHAKE_TIMEOUT\r\n- [ ] ERR_TLS_RENEGOTIATION_FAILED\r\n- [ ] ERR_TLS_REQUIRED_SERVER_NAME\r\n- [ ] ERR_TLS_SESSION_ATTACK\r\n- [ ] ERR_TRANSFORM_ALREADY_TRANSFORMING\r\n- [ ] ERR_TRANSFORM_WITH_LENGTH_0\r\n- [ ] ERR_VALID_PERFORMANCE_ENTRY_TYPE\r\n\r\n**no** `lib/internal/errors.js`, **yes** `doc/api/errors.md`\r\n\r\n- [ ] ERR_HTTP2_ERROR\r\n\r\n---\r\n\r\nSomething else to consider is how to prevent this from happening in the future. I've been playing around with some ESLint stuff, but would appreciate people's thoughts on this.",
        "labels": "doc",
        "id": 44382
    },
    {
        "title": "doc: rephrase documentation for child_process.execSync()",
        "body": "The line at the end describing about the error thrown can be worded better. \r\n>If the process times out, or has a non-zero exit code, this method will throw. The Error object will contain the entire result from child_process.spawnSync()\r\n\r\nShould be something like:\r\n>If the process times out, or has a non-zero exit code, this method will throw an Error object which will contain the entire result from child_process.spawnSync()\r\n\r\nhttps://nodejs.org/api/child_process.html#child_process_child_process_execsync_command_options\r\n\r\n[refack adding]\r\nhttps://github.com/nodejs/node/blob/467385a49b659b704973b8195328775b620ae6ab/doc/api/child_process.md#L687-L689",
        "labels": "doc",
        "id": 44383
    },
    {
        "title": "Nightly docs missing",
        "body": "Sorry, if this is a known issue or not an issue.\r\n\r\nIt seems the last full nightly docs are:\r\n\r\nhttps://nodejs.org/download/nightly/v9.0.0-nightly201708155f31d54720/docs/api/\r\n\r\nThe next 3 have only JSON:\r\n\r\nhttps://nodejs.org/download/nightly/v9.0.0-nightly20170816e9c0263696/docs/api/\r\nhttps://nodejs.org/download/nightly/v9.0.0-nightly2017081760f2fa9a8b/docs/api/\r\nhttps://nodejs.org/download/nightly/v9.0.0-nightly201708184d842e3d66/docs/api/",
        "labels": "doc",
        "id": 44384
    },
    {
        "title": "http2,doc: links missing definition",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: `8.4.0`\r\n* **Platform**: *\r\n* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nhttps://nodejs.org/api/http2.html & https://github.com/nodejs/node/blob/master/doc/api/http2.md are rendered with `[...][]` around links that don't have a definition (in the footer).\r\n\r\nFor example:\r\nhttps://github.com/nodejs/node/blob/85d7d97d8165dbd94a57ed4dbe143c745487ff8c/doc/api/http2.md#L1904-L1907\r\n![image](https://user-images.githubusercontent.com/96947/29361879-7628f6e8-8257-11e7-86b6-822d0bcfdf80.png)\r\n",
        "labels": "doc",
        "id": 44385
    },
    {
        "title": "Docs: http.ClientRequest \"timeout\" event missing",
        "body": "The [setTimeout()](https://github.com/nodejs/node/blob/master/doc/api/http.md#requestsettimeouttimeout-callback) documentation mentions an undocumented \"timeout\" event.\r\n\r\n> Same as binding to the `timeout` event",
        "labels": "doc",
        "id": 44386
    },
    {
        "title": "crypto: crypto.create* - argument \"options\" is undocumented",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: *\r\n* **Platform**: *\r\n * **Subsystem**: crypto\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n* [`crypto.createCipher`](https://github.com/nodejs/node/blob/master/doc/api/crypto.md#cryptocreatecipheralgorithm-password)\r\n* [`createCipheriv`](https://github.com/nodejs/node/blob/master/doc/api/crypto.md#cryptocreatecipherivalgorithm-key-iv)\r\n* [`createDecipher`](https://github.com/nodejs/node/blob/master/doc/api/crypto.md#cryptocreatedecipheralgorithm-password)\r\n* [`createDecipheriv`](https://github.com/nodejs/node/blob/master/doc/api/crypto.md#cryptocreatedecipherivalgorithm-key-iv)\r\n* [`createHash`](https://github.com/nodejs/node/blob/master/doc/api/crypto.md#cryptocreatehashalgorithm)\r\n* [`createHmac`](https://github.com/nodejs/node/blob/master/doc/api/crypto.md#cryptocreatehmacalgorithm-key)\r\n* [`createSign`](https://github.com/nodejs/node/blob/master/doc/api/crypto.md#cryptocreatesignalgorithm)\r\n* [`createVerify`](https://github.com/nodejs/node/blob/master/doc/api/crypto.md#cryptocreateverifyalgorithm)\r\n\r\n\r\nhave a last _optional_ argument `options` to control their `stream` behaviour\r\n\r\n/cc @nodejs/documentation @nodejs/crypto @nodejs/streams \r\n",
        "labels": "doc",
        "id": 44387
    },
    {
        "title": "`password` and `salt` parameter allows both string and buffer, but the doc only says string",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nFor `crypto.pbkdf2Sync` and `crypto.pbkdf2`, the `password` and `salt` parameter allows both string and buffer, but the doc only says string.",
        "labels": "doc",
        "id": 44388
    },
    {
        "title": "Buffer.slice: Document behavior if end > slice.length",
        "body": "The [documentation for Buffer.slice](https://nodejs.org/api/buffer.html#buffer_buf_slice_start_end) says this about end:\r\n\r\n> end <integer> Where the new Buffer will end (not inclusive). Default: buf.length\r\n\r\nIt does not describe what happens if end is greater than the length of the buffer. Does Node return a buffer of length (end - start) with zero values for the extra values? Does it return a shorter buffer? Does it throw a RangeError?",
        "labels": "doc",
        "id": 44389
    },
    {
        "title": "meta: handling of undocumented endpoint",
        "body": "Recently some undocumented \"public\" endpoints have been surfaced:\r\n<sub>partial list</sub>\r\n* ~~`tls.parseCertString()` - https://github.com/nodejs/node/pull/14218, https://github.com/nodejs/node/pull/14245~~ (update from @jasnell on 2018-08-10, this API has been since [deprecated](https://nodejs.org/dist/latest-v10.x/docs/api/deprecations.html#deprecations_dep0076_tls_parsecertstring))\r\n* ~~`REPLServer.parseREPLKeyword` - https://github.com/nodejs/node/pull/14223~~ (update from @jasnell on 2018-08-10, this API has been documented and [deprecated](https://nodejs.org/dist/latest-v10.x/docs/api/repl.html#repl_replserver_parsereplkeyword_keyword_rest))\r\n* ~~`tls.convertNPNProtocols()` - https://github.com/nodejs/node/issues/14602~~ (update from @jasnell on 2018-08-10, this API has been since removed)\r\n* ~~`ServerResponse.prototype.writeHeader()` - https://github.com/nodejs/node/pull/11355~~ (update from @jasnell on 2018-08-10, this API has been since [deprecated](https://github.com/nodejs/node/pull/11355))\r\n* ~~`subprocess.killed` - https://github.com/nodejs/node/pull/14578~~ (update from @jasnell 2018-08-10, this API has been documented)\r\n\r\nIMHO we should have explicit policy for handling these endpoints. Specifically, should they be documented or deprecated, and how. A few discussion points come to mind:\r\n1. semverity - can these endpoints be \"doc-only\" deprecated immediately (considered semver-patch)\r\n2. usefulness - should there be a standard process to assess their use (Gzemnid/GitHub search/google/SO/twitter survey)?\r\n3. \"sensitivity\" - will documenting/deprecating them generate any harm (https://github.com/nodejs/node/pull/14578, https://github.com/nodejs/node/pull/13702)\r\n\r\n/cc @nodejs/documentation @nodejs/release @nodejs/ctc @nodejs/testing @nodejs/community-committee \r\n\r\n\r\n\r\n",
        "labels": "doc",
        "id": 44390
    },
    {
        "title": "doc: confusing stream.read() documentation",
        "body": "* **Version**: all\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nCurrently in the [`readable.read()` documentation](https://nodejs.org/docs/latest/api/stream.html#stream_readable_read_size), there are two statements that seem to be at odds with each other.\r\n\r\nFirst:\r\n\r\n> If `size` bytes are not available to be read, `null` will be returned *unless* the stream has ended, in which case all of the data remaining in the internal buffer will be returned (*even if it exceeds* `size` *bytes*).\r\n\r\nand then at the end:\r\n\r\n> *Note*: Calling [stream.read([size])](https://nodejs.org/docs/latest/api/stream.html#stream_readable_read_size) after the ['end'](https://nodejs.org/docs/latest/api/stream.html#stream_event_end) event has been emitted will return `null`. No runtime error will be raised.\r\n\r\nSo the first part tells me that either `null` or some bytes will be returned and the second part seems to imply that `null` will *always* be returned after the stream ends...",
        "labels": "doc",
        "id": 44391
    },
    {
        "title": "Suggestion: Return type in function declaration & possible option to view types by clicking in doc",
        "body": "While working with Node.js, I found having the return types of a function (If given) in the function declaration instead of somewhere in the paragraph below it (As seen in the example following) might improve the documentation.\r\n\r\n\r\n![Example screenshot](http://i.imgur.com/FDwu1md.png)\r\n\r\nFurther on, it would most likely be useful to be able to click on the types. Both suggestions are popular documentation features, example is the [Rust Documentation](https://doc.rust-lang.org/std/iter/struct.Filter.html) \r\n\r\nHere a screenshot of what I mean\r\n![Example screenshot](http://i.imgur.com/XKKNWsc.png)",
        "labels": "doc",
        "id": 44392
    },
    {
        "title": "change the way the arguments are defined in the doc",
        "body": "The documentation does not reflect correctly the types of the arguments, an argument that can be null or undefined should not be defined as \"integer\" https://github.com/nodejs/node/pull/14612/files#r131284818\r\nThis comment is an example but all the documentation is like that, this require to be changed everywhere or it will be confusing, for now it's implicit but if we change it at one place we should change it everywhere.\r\nWe probably need to think about an easy and constant way to present the arguments types in the documentation, the way typescript do it could be a solution. `position?: integer|null`\r\nThx @sam-github to point this problem in the documentation.",
        "labels": "doc",
        "id": 44393
    },
    {
        "title": "Documentation should mention `encoding` instead of `defaultEncoding` as options property for `fs.createWriteStream`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 6.11.1\r\n* **Platform**: Linux 4.12.3-1-ARCH\r\n* **Subsystem**: fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n[Documentation](https://github.com/nodejs/node/blob/master/doc/api/fs.md) says that `defaultEncoding` is the right options property for `fs.createWriteStream`. But if we look into source code [1] `options` are directly passed to `WriteStream` that expects `options.encoding` [2]. At the same time `options` are passed to `Writable->WritableState` [3] that expects `options.defaultEncoding` instead [4].\r\n\r\nFor example this inconsistency reveals when you pass \"wrong\" encoding. Both following examples throw `TypeError: Unknown encoding: unknown`:\r\n```js\r\nfs.createWriteStream('....', 'unknown');\r\n```\r\nand \r\n\r\n```js\r\nfs.createWriteStream('....', { encoding: 'unknown' });\r\n```\r\n\r\nBut the following example doesn't throw anything:\r\n```js\r\nfs.createWriteStream('....', { defaultEncoding: 'unknown' });\r\n```\r\n\r\nI see there was a similar issue a while ago: https://github.com/nodejs/node-v0.x-archive/issues/7710. So at least it's confusing.\r\n\r\n[1] https://github.com/nodejs/node/blob/v6.x/lib/fs.js#L2059\r\n[2] https://github.com/nodejs/node/blob/v6.x/lib/fs.js#L2100\r\n[3] https://github.com/nodejs/node/blob/v6.x/lib/fs.js#L2077\r\n[4] https://github.com/nodejs/node/blob/v6.x/lib/_stream_writable.js#L64",
        "labels": "doc",
        "id": 44394
    },
    {
        "title": "Documentation for \"path\", \"bytesRead\", \"bytesWritten\" properties should also be in stream.html, not just fs.html",
        "body": "Relating to https://github.com/nodejs/node/issues/4327 and https://github.com/nodejs/node/pull/4368\r\n\r\nI just searched and searched and had to resort to various tricky Google queries to find that the `path` property of stream(!) objects is not documented on the \"stream\" doc page - but on the \"fs\" page.\r\n\r\nhttps://nodejs.org/dist/latest-v8.x/docs/api/fs.html#fs_writestream_path\r\n\r\nI think this belongs to https://nodejs.org/dist/latest-v8.x/docs/api/stream.html#stream_class_stream_writable and https://nodejs.org/dist/latest-v8.x/docs/api/stream.html#stream_class_stream_readable (too)\r\n\r\n**On that note,** I find it highly confusing that there is [a class `fs.WriteStream`](https://nodejs.org/dist/latest-v8.x/docs/api/fs.html#fs_class_fs_writestream) (same for ReadStream) documented. Sure, it says \"is a WriteStream\", but combined with the fact that the documentation is DIFFERENT for the class on the two pages leads to the assumption that maybe it indeed is something different? I had to check the code in `lib/fs.js` to make sure it really is the same class.\r\n\r\nSo maybe there should be only one location for stream class documentation - and that should be under \"streams\"?",
        "labels": "doc",
        "id": 44395
    },
    {
        "title": "Request: Sponsorship on Docs Page",
        "body": "**URL: https://nodejs.org/api/**\r\n**Original Request: https://github.com/nodejs/nodejs.org/issues/1304**\r\n\r\nI sent an invitation to Mikael to join [Carbon](http://carbonads.net/), and he told me itâ€™s best to seek everyone feedbacks here.\r\n\r\nI manage Carbon and want to suggest displaying Carbon on the docs page at https://nodejs.org/api/. You can check out the demo I came up with at https://s.codepen.io/carbonads/debug/xrmGJr\r\n\r\nThe main idea is to generate a consistent revenue from sponsorship for the foundation without cluttering the docs. Weâ€™ve worked with few projects to display sponsors on their docs page: **[lodash.com/docs/](https://lodash.com/docs/4.17.4), [flask.pocoo.org/docs/](http://flask.pocoo.org/docs/0.12/), and [laravel.com/docs/](https://laravel.com/docs/5.4)**\r\n\r\nCarbon partners receive 60% of the earning. You can check out some of our existing/previous sponsors at http://bit.ly/carbon-preview\r\n\r\nI know there are many things we have to consider to fund an open source project, so it would be great to learn whether Carbon can help Node.js to reach the funding goal.",
        "labels": "doc",
        "id": 44396
    },
    {
        "title": "Documentation mismatch for napi_get_value_string_* functions",
        "body": "`napi_get_value_string_*` say e.g.:\r\n\r\n> `[out] result`: Number of bytes copied into the buffer including the null. terminator.\r\n\r\nHowever, the actual implementation in Node returns the number of bytes excluding the null terminator (so for an empty string, it will return `0` and not `1`).\r\n\r\nNot sure if it's implementation or documentation issue, or I was just confused by the wording. cc @nodejs/n-api ",
        "labels": "doc",
        "id": 44397
    },
    {
        "title": "napi_get_value_string_latin1 not mentioned in N-API docs",
        "body": "`napi_get_value_string_latin1` was introduced in the implementation, but doesn't appear on the documentation page. cc @nodejs/n-api (relevant to #13556)",
        "labels": "doc",
        "id": 44398
    },
    {
        "title": "module.paths is undocumented",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.1.4\r\n* **Platform**: nodejs.org documentation\r\n* **Subsystem**: `module`\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nNode exposes the apparently non-private variable `module.paths`, but there is no documentation about it on nodejs.org, not even to say that it is really private despite the naming convention (I don't know if this is the case).",
        "labels": "doc",
        "id": 44399
    },
    {
        "title": "doc: typo in stream.md",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nThere is a typo in doc/api/stream.md in the [`stream._transform()`](https://github.com/nodejs/node/blob/0e5283b7eda5b22d73c21620a02ac5337f9de9f1/doc/api/stream.md#transform_transformchunk-encoding-callback) description: 'asychronously' should be 'asynchronously'.\r\n",
        "labels": "doc",
        "id": 44400
    },
    {
        "title": "Cluster Documentation: Missing '",
        "body": "[In the docs for clusters](https://nodejs.org/api/cluster.html#cluster_event_message), there is a missing `'`. It says:\r\n\r\n> Within a worker, `process.on('message)` may also be used.\r\n\r\nIt should say:\r\n\r\n> Within a worker, `process.on('message')` may also be used.\r\n\r\nThat's it.",
        "labels": "doc",
        "id": 44401
    },
    {
        "title": "http2: code examples does not work on Windows with port 80",
        "body": "* **Version**: master with #14239\r\n* **Platform**: Windows 7 x 64\r\n* **Subsystem**: http2\r\n\r\nRefs: https://github.com/nodejs/node/pull/14239 ([http2.md](https://github.com/jasnell/node/blob/76329637e55bd48289db0e595708a63a19202d2a/doc/api/http2.md))\r\n\r\nThe first examples from [\"Core API\"](https://github.com/jasnell/node/blob/76329637e55bd48289db0e595708a63a19202d2a/doc/api/http2.md#core-api) chapter do not work properly on Windows with port 80 but work with other ports.\r\n\r\nI've added some output and repeated request for easier debugging. Here are the code and output with port 81:\r\n\r\nServer:\r\n```js\r\nconst http2 = require('http2');\r\n\r\n// Create a plain-text HTTP/2 server\r\nconst server = http2.createServer();\r\n\r\nserver.on('stream', (stream, headers) => {\r\n  console.log('headers: ', headers);\r\n  stream.respond({\r\n    'content-type': 'text/html',\r\n    ':status': 200\r\n  });\r\n  stream.end('<h1>Hello World</h1>');\r\n});\r\n\r\nserver.listen(81);\r\n```\r\n\r\nClient:\r\n```js\r\nconst http2 = require('http2');\r\n\r\nfunction test() {\r\n  const client = http2.connect('http://localhost:81');\r\n\r\n  const req = client.request({ ':path': '/' });\r\n\r\n  req.on('response', (headers) => {\r\n    console.log(headers[':status']);\r\n    console.log(headers['date']);\r\n  });\r\n\r\n  let data = '';\r\n  req.setEncoding('utf8');\r\n  req.on('data', (d) => data += d);\r\n  req.on('end', () => { client.destroy(); console.log('data: ', data); });\r\n  req.end();\r\n}\r\n\r\nsetInterval(test, 2000);\r\n```\r\nServer output:\r\n```console\r\n(node:7960) ExperimentalWarning: The http2 module is an experimental API.\r\nheaders:  { ':scheme': 'http',\r\n  ':authority': 'localhost:81',\r\n  ':method': 'GET',\r\n  ':path': '/' }\r\nheaders:  { ':scheme': 'http',\r\n  ':authority': 'localhost:81',\r\n  ':method': 'GET',\r\n  ':path': '/' }\r\nheaders:  { ':scheme': 'http',\r\n  ':authority': 'localhost:81',\r\n  ':method': 'GET',\r\n  ':path': '/' }\r\n```\r\nClient  output:\r\n```console\r\n(node:6732) ExperimentalWarning: The http2 module is an experimental API.\r\n200\r\nSun, 16 Jul 2017 13:40:19 GMT\r\ndata:  <h1>Hello World</h1>\r\n200\r\nSun, 16 Jul 2017 13:40:21 GMT\r\ndata:  <h1>Hello World</h1>\r\n200\r\nSun, 16 Jul 2017 13:40:23 GMT\r\ndata:  <h1>Hello World</h1>\r\n```\r\nWhen I change the port in both examples into 80, I get:\r\nServer output:\r\n```console\r\n(node:4792) ExperimentalWarning: The http2 module is an experimental API.\r\n```\r\nClient  output:\r\n```console\r\n(node:1784) ExperimentalWarning: The http2 module is an experimental API.\r\ndata:\r\ndata:\r\ndata:\r\n```\r\nFWIW, I've tried to see what was going on with [TCPView](https://technet.microsoft.com/en-us/tcpview):\r\n![http2](https://user-images.githubusercontent.com/10393198/28248120-95f16e4c-6a47-11e7-892c-b97625ed83f3.png)\r\nThe first two is the Server, the last two are Client requests and they are trying to connect the 443 port.\r\n",
        "labels": "doc",
        "id": 44402
    },
    {
        "title": "n-api: from zzo38 via IRC - Some ideas for N-API",
        "body": "*edited to reflect completed tasks (@gabrielschulhof)*\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.1.3\r\n* **Subsystem**: n-api\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nhttp://zzo38computer.org/textfile/miscellaneous/napi_ext\r\n\r\n# documentation\r\n\r\n\r\n### String lifetimes.\r\n\r\nThe document should specify if N-API copies the string, to make it clear.\r\n(With SQLite, you can specify whether or not the string should be copied\r\nand if not, what to call to free it.)\r\n\r\n### Examples of asynchronous working.\r\n\r\nThere aren't any example, and it does not explain many things such as\r\nmutexes, calling JavaScript codes during the working, example of using\r\nnapi_make_callback(), thread safety, etc.\r\n\r\nSQLite has support for multithreads too (if enabled), although there is\r\nsome confusion in the N-API documentation as to what exactly is allowed\r\nwhen interfacing SQLite (and other stuff) with N-API when using the\r\nasynchronous working.\r\n\r\n\r\n### External values.\r\n\r\nThe documentation should probably mention that an external value appears\r\nas an object (sealed, frozen, with no properties and no prototype) to\r\nJavaScript codes, even though it is a separate type to native codes.\r\n\r\n\r\n### Get property names.\r\n\r\nThe documentation for napi_get_property_names() does not say whether it\r\ngets only enumerable properties or all properties, and does not say if it\r\nincludes symbols or not.\r\n\r\n\r\n### C++ wrapping.\r\n\r\nWhat is the relation to C++ (I thought this is a C API?) and what is the\r\nreason for the restrictions with napi_wrap()? Also, is it necessary to\r\ncall napi_wrap() only during the constructor callback, or is it OK to do\r\nafterward too?\r\n\r\n\r\n### Throwing exceptions.\r\n\r\nThe document says that napi_throw() throws an Error provided. Is it\r\nnecessary for it to be an Error, or can you throw any value? You should be\r\nallowed to throw any value, I should think.\r\n\r\n# Implementation\r\n\r\n### ~~Retrieving new.target.~~\r\n\r\n~~When a function is called as a constructor, new.target should be\r\nretrievable. This may replace is_construct_call since you can do the same\r\nthing with this anyways.~~\r\n*`napi_get_new_target()`*\r\n\r\n\r\n### ~~Executing JavaScript codes.~~\r\n\r\n~~Some things aren't and perhaps shouldn't be defined in N-API, but it can\r\nbe useful to execute external JavaScript codes sometimes (during\r\ninitialization, especially) in order to do such things.~~\r\n*`napi_run_script()`*\r\n\r\n### Further module arguments.\r\n\r\nIt currently (seems to) provide no way to get the \"require\", \"__dirname\",\r\nand \"__filename\" arguments of a Node.js module. If the native code is a\r\nNode.js module there should probably be some way to retrieve such values\r\n(which may be used with the above \"executing JavaScript codes\" during the\r\ninitialization).\r\n\r\n\r\n### Retrieving the finalizer for a value.\r\n\r\nFor objects created using N-API, it would help to have a function to get\r\nthe finalizer callback for the value, for example:\r\n\r\nnapi_get_value_finalizer(napi_env env,napi_value val,napi_finalize*result)\r\n\r\nThis can be used to determine who created an object, by comparing the\r\nfinalizer function pointer (which will be a null pointer if there is no\r\nfinalizer callback defined) with the address of the native code's own\r\nfunctions (there is no point calling the returned finalizer callback).\r\n\r\n\r\n### ~~Reading strings of 8-bit characters.~~\r\n\r\n~~The function napi_get_value_string_latin1() is missing. Not sure what to\r\ndo for strings having character codes that don't fit in 8-bits; it may be\r\ndefined to just use the low 8-bits, or it may be specified as undefined.~~\r\n\r\n\r\n### Support for WeakMap.\r\n\r\nN-API can already create and manipulate a Array, but there is no support\r\nto create and manipulate a WeakMap, which may sometimes be useful for\r\ninternally attaching extra data to arbitrary objects.\r\n\r\n(You might be able to define your own finalizer callbacks also using a\r\nWeakMap anyways, by giving a key for the object to check, and the value\r\nbeing a external value with a finalizer callback defined, so that it will\r\nbe called when the key object is finalized; I don't know whether or not it\r\nwill work, but it seems like it is allowed to work, at least.)\r\n\r\n\r\n### Creating functions and objects.\r\n\r\nWhen using napi_create_object() and napi_create_function(), you cannot\r\nspecify a finalizer callback, which probably should be allowed since it\r\ncan be useful to have.\r\n\r\n~~Also, napi_create_object() should allow you to optionally specify the\r\nprototype to use (which is a napi_value which is either null or a object;\r\nif it is not specified then it can use the default Object.prototype).~~\r\n*`napi_new_instance()`*\r\n\r\n\r\n### Exotic objects.\r\n\r\nA suggestion is a new N-API function to create custom exotic objects (like\r\nProxy in JavaScript, but without the extra checking).\r\n\r\n\r\n### Generator functions.\r\n\r\nA way to create generator functions with N-API functions. (You can already\r\nfake it, but real generator functions may help a bit better, will work if\r\nyou use the actual generator methods rather than others with the same\r\nname, and may be more efficient in some cases maybe.)\r\n\r\nAttaching a finalizer callback to the generator object can also help.\r\n\r\n\r\n### Immediate garbage collection.\r\n\r\nSometimes you may wish to trigger garbage collection sooner in order to\r\nmake finalizer callbacks to be called. This will not necessarily be\r\nguaranteed, although attempting it can nevertheless be useful sometimes.\r\n(This should also be provided in the \"v8\" module so that it can be used\r\nfrom JavaScript codes directly, too.)\r\n\r\n\r\n### Moving values into scopes.\r\n\r\nSometimes you might want to return a value that is not scoped and then to\r\ndelete the reference to it at the same time. In order to do this, it may\r\nbe useful to add the value to the scope so that it can be returned.\r\n\r\nN-API might automatically do this; the documentation isn't quite clear. If\r\nN-API does already do this, it should be explained, and the stuff in this\r\nsection need not be implemented.\r\n\r\nAnother alternative would be to provide another function to return values\r\nfrom a native code rather than returning it directly.\r\n\r\nAnother possibility may be to create an array and add the value into that\r\narray to prevent it from getting lost, and the array is automatically lost\r\nwhen the function returns, but that seems a bit klugy to me.\r\n\r\n",
        "labels": "doc",
        "id": 44403
    },
    {
        "title": "Documentation with breaking changes between version 6 to version 8",
        "body": "* **Version**: 8.0.0\r\n* **Platform**: All\r\n* **Subsystem**: documentation\r\n\r\nAs a user of node I would like to see a document detailing breaking changes between node 6 and node 8, or, node 7 to node 8, such as [this one](https://github.com/nodejs/node/wiki/Breaking-changes-between-v6-and-v7) (just for different versions).",
        "labels": "doc",
        "id": 44404
    },
    {
        "title": "We need to better document module_versions",
        "body": "It would appear that we shipped the 7.x line with Module version 51, which is supposed to be for [V8 5.4](https://github.com/nodejs/node/commit/b5bdff876ba62ed58664eb011a863d0960f4089b#diff-06414025f6b55f734c0e725a282a1ef2)\r\n\r\nWe shipped 7.x with V8 5.5, which [should have module version 52](https://github.com/nodejs/node/commit/91ab09fe2a5739e8e6b4133ffa23d8c5afff37d9#diff-06414025f6b55f734c0e725a282a1ef2)\r\n\r\nObviously there is nothing we can do at this point, but it is pretty bad that we made an error of this magnitude.\r\n\r\nWe should start a wiki with explicit mapping of module version -> V8 version and be sure to stick to it... this makes things especially difficult + confusing for embedders",
        "labels": "doc",
        "id": 44405
    },
    {
        "title": "Missing documentation for tls.parseCertString",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: all as of v8.1.4\r\n* **Platform**: all\r\n* **Subsystem**: all\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nThere is currently no documentation for [`tls.parseCertString`]( https://github.com/nodejs/node/blob/master/lib/tls.js#L233)\r\n\r\nSince this function exported, I'd consider it part of the public API and therefore it should probably have some documentation explaining what it does.",
        "labels": "doc",
        "id": 44406
    },
    {
        "title": "doc: process.umask doc unclear",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nhttps://github.com/nodejs/node/blob/199ad1d73f81c1d568232df418090e9ce3c4a7fb/doc/api/process.md#processumaskmask\r\n\r\nThe documentation for `process.umask` reads:\r\n\r\n> The `process.umask()` method sets or returns the Node.js process's file mode creation mask. Child processes inherit the mask from the parent process. **The old mask is return if the mask argument is given, otherwise returns the current mask.**\r\n\r\nI have emphasized the last sentence since that is the one that doesn't make any sense. Is it saying `var oldmask = process.umask()` or `var oldmask = process.umask(0)`?\r\n",
        "labels": "doc",
        "id": 44407
    },
    {
        "title": "doc: better document `--shared` build",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: *\r\n* **Platform**: *\r\n* **Subsystem**: build,doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n`./configure --shared` / `vcbuild shared` should be better documented.\r\n1. How to build\r\n2. How to use\r\n3. Support level",
        "labels": "doc",
        "id": 44408
    },
    {
        "title": "child_process,Windows: fix docs for `spawn({shell})`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: *\r\n* **Platform**: Windows\r\n* **Subsystem**: child_process\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nhttps://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options erronously states that `cmd.exe` is the default `shell` for windows, while infact it's `process.env.ComSpec`.\r\nThe same goes for:\r\n* https://nodejs.org/api/child_process.html#child_process_child_process_exec_command_options_callback\r\n* https://nodejs.org/api/child_process.html#child_process_child_process_spawnsync_command_args_options\r\n* https://nodejs.org/api/child_process.html#child_process_child_process_execsync_command_options",
        "labels": "doc",
        "id": 44409
    },
    {
        "title": "[DOC] Buffer.from / new Buffer accept Uint8Array (missing)",
        "body": "Both can accept a Uint8Array.  [Buffer.from](https://github.com/nodejs/node/blob/master/lib/buffer.js#L189-L191) explicitly checks for [Uint8Array](https://github.com/nodejs/node/blob/master/lib/buffer.js#L370)\r\n\r\nIt looks like a documentation omission.  If so, I can send a PR.",
        "labels": "doc",
        "id": 44410
    },
    {
        "title": "doc: readline on \"Git Bash\" - `winpty` required",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: Windows7, Git Bash\r\n* **Subsystem**: readline\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nOn Windows7, the Node.js application don't terminate after `rl.close()` :\r\n\r\n```js\r\nconst readline = require('readline');\r\nconst rl = readline.createInterface({\r\n  input: process.stdin,\r\n  output: process.stdout\r\n});\r\nrl.close();\r\n```\r\n\r\nIt causes [test/parallel/test-readline-interface.js](https://github.com/nodejs/node/blob/master/test/parallel/test-readline-interface.js#L507) TIMEOUT, which will not happen in v6.x.x\r\n\r\n\r\n",
        "labels": "doc",
        "id": 44411
    },
    {
        "title": "Documentation for __dirname is incorrect",
        "body": "* **Version**: 8.1.2\r\n* **Platform**: Linux 4.8.0 (Ubuntu 16.04)\r\n* **Subsystem**: Documentation\r\n\r\nIn the [documentation about Global Objects](https://nodejs.org/api/globals.html) `__dirname` is listed as a global object.\r\nIn reality it is [not](https://github.com/nodejs/node/blob/master/lib/internal/bootstrap_node.js#L546-L549).\r\n\r\nI would suggest correcting the documentation to represent this.\r\n\r\n",
        "labels": "doc",
        "id": 44412
    },
    {
        "title": "console, doc, util: console.log() and util.format() are wrongly documented and may be inconsistent",
        "body": "This is an issue that superseded https://github.com/nodejs/node/issues/6341, Previously I thought this was a pure doc issue, now it seems to me that it is a more complicated problem that needs more discussion.\r\n\r\nThe both docs fragments ([here](https://github.com/nodejs/node/blame/7de6998d899125e9d43de7dae0bb0a0ed9a76d34/doc/api/console.md#L249-L251) and [here](https://github.com/nodejs/node/blame/af3aa682ac534bb55765f5fef2755a88e5ff2580/doc/api/util.md#L189-L191)) are wrong: `util.inspect()` is not called on **each** argument if the first argument is a non-format string. This is true if the first argument is not a string at all (see [this path in code](https://github.com/nodejs/node/blob/873e2f270fa67c701d59bc99f0f815f1f69b2316/lib/util.js#L66-L72)). If the first argument is a non-format string, `util.inspect()` is called only for arguments whose `typeof` is `'object'` or `'symbol'` (except `null`) â€”  see [this path in code](https://github.com/nodejs/node/blob/873e2f270fa67c701d59bc99f0f815f1f69b2316/lib/util.js#L126-L133).\r\n\r\nCurrently, I've found out that this impacts the output with `String` and `Function` arguments (watch out for quotes in the output for strings and absolutely different output for functions):\r\n```js\r\n> console.log(1, 'str'); // .inspect()\r\n1 'str'\r\n> console.log('str', 'str'); // no .inspect()\r\nstr str\r\n\r\n> console.log(1, () => true); // .inspect()\r\n1 [Function]\r\n> console.log('str', () => true); // no .inspect()\r\nstr () => true\r\n```\r\nMaybe  there are other diferences.\r\n\r\nPossible solutions:\r\n\r\n1. Document this difference.\r\n2. As it seems to be a confusing behavior, maybe we need to unify this with a semver-major fix.\r\n\r\n**UPD**: [This fragment](https://github.com/nodejs/node/blame/af3aa682ac534bb55765f5fef2755a88e5ff2580/doc/api/util.md#L180-L183) is more correct:\r\n```js\r\n> console.log(1, 'str2'); // .inspect()\r\n1 'str2'\r\n> console.log('str %s', 'str1', 'str2'); // no .inspect()\r\nstr str1 str2\r\n\r\n> console.log(1, () => true); // .inspect()\r\n1 [Function]\r\n> console.log('str %s', 'str1', () => true); // no .inspect()\r\nstr str1 () => true\r\n```\r\nAs you can see, `util.inspect()` is not called for excessive `String` and `Function` arguments here.\r\n\r\nHowever, this doc fragment can also be improved, as functions **are** objects (maybe `typeof` should be mentioned).",
        "labels": "doc",
        "id": 44413
    },
    {
        "title": "The repl module's default setting for useGlobal invites hard-to-isolate bugs",
        "body": "* **Version**:  v8.1.2\r\n* **Platform**: Darwin bayswater.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\n* **Subsystem**: repl\r\n\r\nI think the built-in repl module's default option value of `useGlobal: false` is likely very surprising for many use cases, and should be reconsidered. For reference, the `node` CLI sets this value manually to `true`, so the REPL that Node users are accustomed to has their code run in a single shared context.\r\n\r\nWhat I just discovered today, while working on testdouble.js with its [little repl script](https://github.com/testdouble/testdouble.js/blob/master/script/repl) is that the consequences of `useGlobal` defaulting to false are quite striking. We found a very insiduous bug that manifested itself as functions defined in the REPL not seeming to have `Object` or `Function` in their prototype chain (which, of course, every `function` does).\r\n\r\nAfter lots of digging, we discovered it was due to the fact that `useGlobal` is false by default. For a minimal example of how absurd this seems, see the following output:\r\n\r\n```\r\n$ node -e 'require(\"repl\").start()'\r\n> setTimeout instanceof Function\r\nfalse\r\n```\r\n\r\nOf course, it's ridiculous that `setTimeout`, or any built-in/host method would fail an `instanceof` check with `Function`. With the `node` CLI or the `useGlobal` option manually set to `true`, however, things behave much more akin to a real-world Node.js program.\r\n\r\n```\r\n$ node -e 'require(\"repl\").start({useGlobal: true})'\r\n> setTimeout instanceof Function\r\ntrue\r\n```\r\n\r\n```\r\n$ node\r\n> setTimeout instanceof Function\r\ntrue\r\n```\r\n\r\nAs a result, it seems to me that `useGlobal: true` would have been a more sensible default for the built-in repl module, but since it's stable, maybe we can at least document the ramifications of this quirk in behavior. Thoughts?",
        "labels": "doc",
        "id": 44414
    },
    {
        "title": "doc, http: Type specification incomplete for ServerResponse.getHeader()",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.1.2 (but applicable to others)\r\n* **Platform**: all\r\n* **Subsystem**: doc, http\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n* `ServerResponse.setHeader()` specifies name as `string` and value as `string | string[]`.\r\n* `ServerResponse.writeHead()` allows an object for headers (key is header name, value is header value). All samples use `string` for keys and `string | string[]` for values - except one which uses `Buffer.byteLength(body)` which is a `number` (the sample works fine).\r\n* `ServerResponse.getHeader()` specifies to return a `string`.\r\n\r\nActually `getHeader()` returns what as passed in so it should be at least `string | string[]`.\r\nBut as `setHeader()` and `writeHead()` actually allow any stringifyable type you get also such type back as the conversion to `string` happens when writing the outgoing stream not during storing the header.\r\n\r\nNot sure here if this is worth a change; and if yes should it be in doc or code?\r\n\r\nI would guess the same is applicable to `ClientRequest`.\r\n",
        "labels": "doc",
        "id": 44415
    },
    {
        "title": "doc: formatting issue in cli docs",
        "body": "* **Version**: master\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\nIn the description for [`OPENSSL_CONF=file`](https://nodejs.org/docs/latest/api/cli.html#cli_openssl_conf_file), it currently shows:\r\n\r\n`./configure \\-\\-openssl\\-fips`\r\n\r\ninstead of:\r\n\r\n`./configure --openssl-fips`",
        "labels": "doc",
        "id": 44416
    },
    {
        "title": "doc: typo in async_hooks documentation",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\n[In the `async_hooks` docs](https://github.com/nodejs/node/blob/master/doc/api/async_hooks.md#type) there is a typo in the description for `init()`'s `type`:\r\n\r\n> Generally it will correspond the name of the resource's constructor.\r\n\r\nThe word 'with' should probably be inserted after 'correspond.'",
        "labels": "doc",
        "id": 44417
    },
    {
        "title": "Misleading documentation in crypto.publicEncrypt and publicDecrypt",
        "body": "* **Version**: Any > 4.0\r\n* **Platform**: Any\r\n* **Subsystem**: crypto / documentation\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n```js\r\n$ node -p process.versions\r\n{ http_parser: '2.7.0',\r\n  node: '8.1.0',\r\n  v8: '5.8.283.41',\r\n  uv: '1.12.0',\r\n  zlib: '1.2.11',\r\n  ares: '1.10.1-DEV',\r\n  modules: '57',\r\n  openssl: '1.0.2l',\r\n  icu: '58.2',\r\n  unicode: '9.0',\r\n  cldr: '30.0.3',\r\n  tz: '2016j' }\r\n```\r\n\r\n```js\r\n$ node -p process.versions\r\n{ http_parser: '2.7.0',\r\n  node: '4.6.1',\r\n  v8: '4.5.103.37',\r\n  uv: '1.9.1',\r\n  zlib: '1.2.8',\r\n  ares: '1.10.1-DEV',\r\n  modules: '46',\r\n  openssl: '1.0.2j-fips' }\r\n```\r\n\r\nDocumentation of the crypto session of node.js is wrong. Even in public key encrypt/decrypt it talks about:\r\n\r\n```\r\ncrypto.publicEncrypt(public_key, buffer)\r\n\r\nAdded in: v0.11.14\r\npublic_key <Object> | <string>\r\nkey <string> A PEM encoded private key.\r\n...\r\n```\r\n\r\nIt does say later that the private key can be used instead of the public key, but still it's clearly wrong. Also it is related to #13612 in a way, that whereas if private key is submitted to this function, it can contain whitespace and/or other garble before the key. On the other hand, if a public key is submitted, the public key header must start immediately from the beginning of the string without any leading whitespace or line feeds or the operation fails.\r\n",
        "labels": "doc",
        "id": 44418
    },
    {
        "title": "entry for inspector in onboarding-extras.md",
        "body": "* **Version**: master\r\n* **Platform**: all\r\n* **Subsystem**: doc\r\n\r\nWe should have an entry in onboarding-extras.md for who to /cc for inspector issues. Who should be in it? Is it @eugeneo or @nodejs/diagnostics or what?",
        "labels": "doc",
        "id": 44419
    },
    {
        "title": "\"Landing Pull Requests\" is incompatible with repo setup in CONTRIBUTING.md",
        "body": "The [\"Technical HOWTO\"](https://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md#technical-howto) section in COLLABORATOR_GUIDE.md \"assumes your repo is set up as detailed in CONTRIBUTING.md\".\r\n\r\nHowever, the [\"Step 1: Fork\"](https://github.com/nodejs/node/blob/master/CONTRIBUTING.md#step-1-fork) section in CONTRIBUTING.md suggests setting up `upstream` as `git://github.com/nodejs/node.git`. When trying to push to it, git returns the following error:\r\n\r\n```\r\nfatal: remote error:\r\n  You can't push to git://github.com/nodejs/node.git\r\n  Use https://github.com/nodejs/node.git\r\n```\r\n\r\nIs there a particular reason why CONTRIBUTING.md uses a `git://` link? Can we just replace that with `git@github.com:nodejs/node.git`?",
        "labels": "doc",
        "id": 44420
    },
    {
        "title": "setTimeout callback order isn't guaranteed",
        "body": "* **Version**: 8.0.0, master\r\n* **Platform**: Linux samtu 4.8.0-53-generic #56-Ubuntu SMP Tue May 16 00:23:44 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: timers\r\n\r\nPerhaps I expect too much, but I expect a sequence of \r\n\r\nsetTimeout(100, a)\r\nsetTimeout(100, b)\r\n\r\nto always call `a` before `b`, but this doesn't happen. I was looking at this because @hhellyer pointed out that unrefed and refed timers use different timer handles (expected), so I looked, and see that they are in two lists, however, the lists are internally designed so that new callbacks for the same time are appended to a list, guaranteeing order, but it isn't clear that those ordering guarantees are maintained across refed and unrefed timers, since they use different lists.\r\n\r\nOr, perhaps I'm seeing an artifact of timer accuracy?\r\n\r\n@Fishrock123 @mscdex You two seem familiar with the timers, what do you think, is this a problem?\r\n\r\n#### `_.js`\r\n\r\n```js\r\nfunction F(s) {\r\n  return () => console.log(s);\r\n}\r\n\r\nsetTimeout(F('A'), 100)\r\nsetTimeout(F('B'), 100).unref()\r\nsetTimeout(F('C'), 100)\r\nsetTimeout(F('D'), 100).unref()\r\n```\r\n\r\n### Output:\r\n\r\n```\r\n% ./node -v\r\nv9.0.0-pre\r\n% ./node _.js\r\nA\r\nC\r\nB\r\nD\r\n% node -v\r\nv8.0.0\r\n% node _.js\r\nA\r\nB\r\nD\r\nC\r\n% node _.js\r\nA\r\nC\r\nB\r\nD\r\n% node _.js\r\nA\r\nC\r\nB\r\nD\r\ncore/node (check-is-listening $%) % node -v\r\nv8.0.0\r\n```\r\n",
        "labels": "doc",
        "id": 44421
    },
    {
        "title": "N-API Callback Return",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v8.1.0\r\n* **Platform**: Linux 4.10.0-21-generic\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI think N-API doesn't have any documented way for return something from callbacks. we have just `napi_get_cb_info` for reading information from `napi_callback_info` and there is no specific way for write something into them but in [documentation](https://nodejs.org/api/n-api.html#n_api_napi_callback_info) mention that it can be used for *Set the return value of the callback*\r\n",
        "labels": "doc",
        "id": 44422
    },
    {
        "title": "napi_create_string_latin1 not mentioned in N-API docs",
        "body": "`napi_create_string_latin1` was introduced in the implementation, but doesn't appear on the documentation page. cc @nodejs/n-api ",
        "labels": "doc",
        "id": 44423
    },
    {
        "title": "Incorrect N-API documentation for some functions accepting strings",
        "body": "Following functions accept `const char*` according to the docs, but in fact `napi_value` according to implementation:\r\n\r\n - `napi_create_symbol`\r\n - `napi_create_error`\r\n - `napi_create_type_error`\r\n - `napi_create_range_error`\r\n\r\n/cc @nodejs/n-api",
        "labels": "doc",
        "id": 44424
    },
    {
        "title": "Whatwg protocol setter only seems to support special schemes",
        "body": "Currently the new whatwg url class doesn't seem to work with any other scheme except so called 'special schemes' in the spec:\r\nhttps://url.spec.whatwg.org/\r\n\r\nE.g. this works:\r\n```js\r\nconst { URL } = require('url');\r\nconst url = new URL('http://foo.bar');\r\nurl.protocol = 'ftp';\r\nurl.toString(); // => ftp://foo.bar\r\n```\r\n\r\nBut this doesn't work:\r\n\r\n```js\r\nconst { URL } = require('url');\r\nconst url = new URL('http://foo.bar');\r\nurl.protocol = 's3';\r\nurl.toString(); // http://foo.bar => should be s3://foo.bar\r\n```\r\n\r\nEven schemes defined here: https://www.iana.org/assignments/uri-schemes/uri-schemes.xhtml don't work.\r\n\r\nNot that this does work:\r\n```js\r\nconst { URL } = require('url');\r\nconst url = new URL('s3://foo.bar');\r\nurl.protocol; // = s3:\r\n```",
        "labels": "doc",
        "id": 44425
    },
    {
        "title": "fs.utimes truncate date",
        "body": "Version: v6.10.3\r\nPlatform: Windows 10 64-bit\r\nSubsystem: fs\r\nDisk format: NTFS\r\n\r\nThis issue is related to #13255 .\r\n\r\n```javascript\r\nlet fs = require('fs');\r\nlet src = 'path/to/src';\r\nlet src_stats = fs.statSync(src);\r\nlet dest = 'path/to/dest'\r\nif (fs.existsSync(dest)) {\r\n  fs.utimesSync(dest, src_stats.atime, src_stats.mtime);\r\n}\r\nlet dest_stats = fs.statSync(dest);\r\nconsole.log(src_stats.mtime);\r\nconsole.log(dest_stats.mtime);\r\nconsole.log(src_stats.mtime == dest_stats.mtime);\r\n```\r\n\r\noutput:\r\n```\r\n2017-05-11T06:35:33.501Z\r\n2017-05-11T06:35:33.000Z\r\nfalse\r\n```\r\n\r\nSo the millisecond part of `mtime` is discarded when setting the time but not when getting the time.\r\nWhy is this inconsistent?",
        "labels": "doc",
        "id": 44426
    },
    {
        "title": "Ubuntu Bash environment on Windows 10",
        "body": "Windows 10â€™s Fall Creators Update, Arriving September 2017\r\n\r\nMicrosoft is making it easier to set up Ubuntu for Windows 10 by bringing Ubuntu to the Windows Store. This is the same Ubuntu Bash environment you can install on current versions of Windows 10, but easier to install.\r\n\r\nFedora and openSUSE are also coming to the Store, so itâ€™s easier to set up different Linux environments.\r\n\r\nThis may or may not cause issues with installation of node. Just thought i would bring it up just in case.",
        "labels": "doc",
        "id": 44427
    },
    {
        "title": "Documentation mismatch for N-API structures",
        "body": "Documentation on the N-API page describes [`napi_property_attributes`](https://nodejs.org/api/n-api.html#n_api_napi_property_attributes) as following:\r\n\r\n```c\r\ntypedef enum {\r\n  napi_default = 0,\r\n  napi_read_only = 1 << 0,\r\n  napi_dont_enum = 1 << 1,\r\n  napi_dont_delete = 1 << 2,\r\n  napi_static_property = 1 << 10,\r\n} napi_property_attributes;\r\n```\r\n\r\nwhereas [src/node_api_types.h](https://github.com/nodejs/node-addon-api/blob/3c06bba3ea699963a21af518eb4c955cf452390a/src/node_api_types.h#L21-L30) describes it as:\r\n\r\n```c\r\ntypedef enum {\r\n  napi_default = 0,\r\n  napi_writable = 1 << 0,\r\n  napi_enumerable = 1 << 1,\r\n  napi_configurable = 1 << 2,\r\n\r\n  // Used with napi_define_class to distinguish static properties\r\n  // from instance properties. Ignored by napi_define_properties.\r\n  napi_static = 1 << 10,\r\n} napi_property_attributes;\r\n```\r\n\r\nBasically, values of all bit flags were inverted.\r\n\r\nGiven the last commit, it seems it's the documentation that is outdated here but would be nice to confirm and sync two places to agree with each other.\r\n\r\nAnother one is [`napi_property_descriptor`](https://nodejs.org/api/n-api.html#n_api_napi_property_descriptor) - website docs don't mention second `name` field of type `napi_value`.",
        "labels": "doc",
        "id": 44428
    },
    {
        "title": "[N-API] `napi_get_value_string_length` return length as type too small",
        "body": "As specified in the N-API documentation, [`napi_get_value_string_length`](https://nodejs.org/api/n-api.html#n_api_napi_get_value_string_length) returns the string length as an `int`, but the [JS spec mandates it to be an unsigned integer at most 2<sup>53</sup>-1](https://tc39.github.io/ecma262/#sec-ecmascript-language-types-string-type). It may be more appropriate here to return a `uint64_t` instead.\r\n\r\n(BTW, I use \"return\" loosely, in reference to its out parameter.)",
        "labels": "doc",
        "id": 44429
    },
    {
        "title": "tls, doc: documentation mentions unexisting clientError event",
        "body": "* **Version**: 8.0.0, 7.10.0, 6.10.3\r\n* **Subsystem**: tls, doc\r\n\r\nBefore 1ab6b21360d97719b3101153fb164c0c3eddf038 (before 6.0.0) there was a `clientError` event in `tls` module. Since 6.0.0, it was renamed to `tlsClientError`, and atm there are no mentions of `clientError` in the code of the `tls` module.\r\n\r\nBut https://nodejs.org/api/tls.html#tls_tls_createserver_options_secureconnectionlistener states\r\n> A 'clientError' is emitted on the tls.Server object whenever a handshake times out.\r\n\r\nI think that's a documentation error.\r\n\r\nI didn't re-check, though, so this should be rechecked before fixing the docs.\r\n\r\n/cc @indutny ",
        "labels": "doc",
        "id": 44430
    },
    {
        "title": "doc: http.request and https.request accepts WHATWG URL object as argument",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master\r\n* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nAfter https://github.com/nodejs/node/pull/10638 `http.request` and `https.request` (hence `http.get` and `https.get`) takes an WHATWG URL object as argument. This has not been documented yet and can be a good first contribution. Changing the type annotations in `doc/api/http.md` and `doc/api/https.md` and the description of those arguments should be enough.",
        "labels": "doc",
        "id": 44431
    },
    {
        "title": "doc: incorrect backtick usage",
        "body": "* **Version**: master, v8.x\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nhttps://nodejs.org/docs/latest/api/tls.html#tls_tls_connect_options_callback and https://nodejs.org/docs/v8.0.0/api/tls.html#tls_tls_createserver_options_secureconnectionlistener have some formatting issues in their descriptions for `NPNProtocols`. It looks like some incorrectly placed backticks.",
        "labels": "doc",
        "id": 44432
    },
    {
        "title": "Node 8.0 publish date",
        "body": "Hi, everyone\r\n      Is there a mistake about Node's publish date (version 8.0.0)? I think it should be '2017-05-25', if I wrong please correct me.",
        "labels": "doc",
        "id": 44433
    },
    {
        "title": "tty: tty.WriteStream event 'resize' on Windows",
        "body": "* **Version**: 8.0.0 rc1\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: tty\r\n\r\nIs this event supported on Windows?\r\n\r\nThe script with [this code from the doc ](https://github.com/nodejs/node/blob/master/doc/api/tty.md#event-resize) exits immediately without launching the event loop. I've tried to modify it like this:\r\n```js\r\nprocess.stdout.on('resize', () => {\r\n  console.log('screen size has changed!');\r\n  console.log(`${process.stdout.columns}x${process.stdout.rows}`);\r\n});\r\n\r\nsetInterval(()=>{}, 1000);\r\n```\r\nand then to resize the console window manually or via the console window properties, but the event handler never fired.",
        "labels": "doc",
        "id": 44434
    },
    {
        "title": "inconsistency in `StreamBase::WriteBuffer()`",
        "body": "* **Version**: v6.0+\r\n* **Platform**: All\r\n* **Subsystem**: stream_base\r\n\r\nWhether data is written as a Buffer or string is inconsistent. If the data is a string then it is copied out into a new `WriteWrap` instance. If the data is a Buffer then the Buffer is used as the data storage for the duration of the write request.\r\n\r\nThe following example of what data is sent when a Buffer is manipulated while waiting to be flushed to the kernel buffer:\r\n```js\r\n'use strict';\r\n\r\nconst net = require('net');\r\nconst print = process._rawDebug;\r\nconst data = Buffer.alloc(0x400000, 'a');  // 4 MB\r\n\r\n// Pass \"--string\" to the script to write strings instead of a Buffer.\r\nfunction getData() {\r\n  return process.argv[2] === '--string' ? data.toString() : data;\r\n}\r\n\r\nconst server = net.createServer(c => {\r\n  const val_cntr = {};\r\n  c.on('data', chunk => {\r\n    for (let i = 0; i < chunk.length; i++) {\r\n      const val = String.fromCharCode(chunk[i]);\r\n      if (!val_cntr[val]) val_cntr[val] = 0;\r\n      val_cntr[val]++;\r\n    }\r\n  });\r\n  c.on('end', () => {\r\n    print(val_cntr);\r\n    server.close();\r\n  });\r\n}).listen(0, () => {\r\n  const client = net.connect(server.address().port, () => {\r\n    client.write(getData(), () => {\r\n      client.end(getData());\r\n    });\r\n    data.fill('b');\r\n  });\r\n});\r\n```\r\nIf the Buffer is written then the output is something like `{ a: 2643141, b: 5745467 }`, but passing `--string` to the script and the output should be `{ a: 4194304, b: 4194304 }`.\r\n\r\nAt minimum I think the documentation should be updated to reflect this difference in behavior between strings and Buffers. If possible it would be nice to have a `.write()` that forced the contents of the Buffer to be copied into a `WriteWrap` instance so the Buffer can be immediately altered afterward.\r\n",
        "labels": "doc",
        "id": 44435
    },
    {
        "title": "doc: make the style of notes consistent",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: all\r\n* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nAt the moment we have a number of paragraphs starting with `Note:` in the API docs, but they tend to be stylistically inconsistent. The majority of them use a capital letter after the \"Note:\" tag itself, but some of them don't; some of them use bold formatting and some of them italic, moreover, sometimes only the \"Note\" word itself is made bold or italic, but in other cases the whole paragraph is.\r\n\r\nShould we make it consistent, and if yes, which style should we stick to and document in `doc/STYLE_GUIDE.md`?",
        "labels": "doc",
        "id": 44436
    },
    {
        "title": "Documentation for fs.watch needs to say that filename is also available for macOS",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\nQuoting the documentation for _fs.watch_ from https://nodejs.org/api/fs.html#fs_filename_argument\r\n> Providing filename argument in the callback is only supported on Linux and Windows. \r\n\r\nFilename is also available on macOS - we could update the documentation to reflect this. \r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44437
    },
    {
        "title": "Arguments list for the http upgrade event does not match example",
        "body": "in the docs for [the upgrade event](https://nodejs.org/api/http.html#http_event_upgrade) the argument list is\r\n```\r\nresponse <http.IncomingMessage>\r\nsocket <net.Socket>\r\nhead <Buffer>\r\n```\r\nbut the example uses\r\n```\r\nsrv.on('upgrade', (req, socket, head) => { ...\r\n```\r\nI feel one of them must be wrong.",
        "labels": "doc",
        "id": 44438
    },
    {
        "title": "NodeJS inspect docs broken?",
        "body": "https://nodejs.org/api/debugger.html#debugger_v8_inspector_integration_for_node_js\r\n\r\nsays I can do \r\n\r\n`node --inspect index.js`\r\n\r\nBut when I do this on my iTerm terminal, I get:\r\n\r\n`node: bad option: --inspect`\r\n\r\nAre the docs broken or am I doing something wrong?",
        "labels": "doc",
        "id": 44439
    },
    {
        "title": "Crypto docs don't explain the function signatures",
        "body": "I just spent about an hour bashing my head against the wall because the documentation for `crypto.publicEncrypt` & co. don't explain that they *return a new `Buffer` with the encrypted data* instead of encrypting the passed-in `Buffer` *in place*.\r\n\r\nYes, in hindsight, this should have been obvious, but I don't get why *these* functions don't explain their return values when so much of the *rest* of core *does*.",
        "labels": "doc",
        "id": 44440
    },
    {
        "title": "Doc link broken",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nIn the [debugging guide](https://nodejs.org/en/docs/guides/debugging-getting-started/#legacy-debugger), the \"Built-in Debugger\" link is broken. It's pointing to master and it shouldn't be.",
        "labels": "doc",
        "id": 44441
    },
    {
        "title": "net.Server.address() returns a string instead of an object for Pipes",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 6.10.0\r\n* **Platform**: Windows\r\n* **Subsystem**: net\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nAccording to the [documentation](https://nodejs.org/dist/latest-v6.x/docs/api/net.html#net_server_address) `server.address()` should return an object with `port`, `family`, and `address` properties but if I call it on a HTTP server connected via windows pipe (on IIS Node on Windows Azure) I get a plain string telling the pipe name.\r\n\r\nIs this just a documentation issue or should the return value for the pipe case adapted somehow (even port/familiy doesn't make that much sense for a pipe).\r\n",
        "labels": "doc",
        "id": 44442
    },
    {
        "title": "doc: res.getHeaders return value wrong in docs",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 7\r\n* **Platform**: *\r\n* **Subsystem**: HTTP\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nRef: https://github.com/nodejs/node/pull/12883/files#r115149721\r\n```js\r\n      const headersCopy = res.getHeaders();\r\n      assert.ok(headersCopy instanceof Object);\r\n```\r\nFails with ```AssertionError [ERR_ASSERTION]: false == true```\r\nIn contradiction to API https://nodejs.org/api/http.html#http_response_getheaders\r\n",
        "labels": "doc",
        "id": 44443
    },
    {
        "title": "`test-npm` applicability",
        "body": "* **Version**: v8.0.0-pre\r\n* **Platform**: all\r\n* **Subsystem**: doc,test\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhat's the deal with `make test-npm`? Who is supposed to run that and when?\r\n\r\nA lot of new folks have problems with it, and they're only running it because it's in `BUILDING.md`. I wonder if it should be moved in that doc, removed from that doc, annotated in that doc, or if it really is generally applicable and should be made more robust. ",
        "labels": "doc",
        "id": 44444
    },
    {
        "title": "N-API documentation appears on 7.10.0",
        "body": "https://nodejs.org/dist/latest-v7.x/docs/api/n-api.html\r\n\r\nN-API was not supposed to land on v7.x, right?",
        "labels": "doc",
        "id": 44445
    },
    {
        "title": "doc: the Â«DeprecatedÂ» stability index description is inaccurate",
        "body": "Previous discussion at https://github.com/nodejs/node/pull/12723#issuecomment-298403281.\r\n\r\nThe description of the `Deprecated` [stability index](https://nodejs.org/api/documentation.html#documentation_stability_index) in fact contradicts with the recent decision about the old Buffer API. It is currently deprecated in a sense that a complete drop-in replacement exists and that the old API usage is highly discouraged, but we recently decided on a CTC vote that we do not plan any changes there at this point. The description in the documentation directly contradicts that.\r\n\r\nCurrent description:\r\n> Deprecated: This feature is known to be problematic, and changes are planned.  Do not rely on it.  Use of the feature may cause warnings.  Backwards compatibility should not be expected.\r\n\r\nThe same question affects `domain` â€” it's labelled as `Deprecated`, but can we say now that we have plans actually removing/changing that? Related: #10843.\r\n\r\n/cc @jasnell @addaleax @Trott @MylesBorins ",
        "labels": "doc",
        "id": 44446
    },
    {
        "title": "Document how to get swap endian for the Buffer class",
        "body": "As the Buffer class currently only supports utf16 in little endian ordering, Buffer cannot be used to read in data from things like OpenType fonts, which by definition are *always* in big endian ordering, irrespective of the hardware or data reader (see https://www.microsoft.com/typography/OTSpec/otff.htm, \"data types\", `All OpenType fonts use Motorola-style byte ordering (Big Endian)`).\r\n\r\nCan Buffer be given a `utf16be` to match the already present `utf16le`, so that Buffer can be used with all utf16 data, rather than only with data that is in little endian ordering?\r\n\r\n",
        "labels": "doc",
        "id": 44447
    },
    {
        "title": "doc, test: question about test.py -v key in CONTRIBUTING.md",
        "body": "* **Version**: 8.0.0-rc.0\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: test\r\n\r\n`CONTRIBUTING.md` [states](https://github.com/nodejs/node/blob/master/CONTRIBUTING.md#step-5-test):\r\n\r\n> If you are updating tests and just want to run a single test to check it, you can use this syntax to run it exactly as the test harness would:\r\n> ```\r\n> $ python tools/test.py -v --mode=release parallel/test-stream2-transform\r\n> ```\r\n\r\nIs `-v` key intended here? I can't find this key in `Makefile` and `vcbuild.bat`. It seems it just adds more debug info:\r\n```console\r\nj:\\temp\\node-master> python tools/test.py --mode=release parallel/test-stream2-transform\r\n[00:00|% 100|+   1|-   0]: Done\r\n\r\nj:\\temp\\node-master> python tools/test.py -v --mode=release parallel/test-stream2-transform\r\n# j:\\temp\\node-master\\Release\\node.exe -p process.arch\r\n[00:00|%   0|+   0|-   0]: release test-stream2-transform # j:\\temp\\node-master\\Release\\node.exe j:\\temp\\node-master\\test\\parallel\\test-stream2-transform.js\r\n[00:00|% 100|+   1|-   0]: Done\r\n```\r\n\r\n",
        "labels": "doc",
        "id": 44448
    },
    {
        "title": "doc: undocumented entities in code example in repl.md",
        "body": "* **Subsystem**: doc, repl\r\n\r\nCurrently, we have 3 undocumented entities in code example in `repl.md`:\r\n\r\n[`replServer.lineParser.reset()`](https://github.com/nodejs/node/blame/b4fea2a3d62da5e2e3f90d7f2109f02f927f7174/doc/api/repl.md#L338)\r\n[`replServer.bufferedCommand`](https://github.com/nodejs/node/blame/b4fea2a3d62da5e2e3f90d7f2109f02f927f7174/doc/api/repl.md#L339)\r\n[`replServer.close()`](https://github.com/nodejs/node/blame/b4fea2a3d62da5e2e3f90d7f2109f02f927f7174/doc/api/repl.md#L346)\r\n\r\nThe first one [will be gone](https://github.com/nodejs/node/pull/12685) since Node.js v8.0.0\r\n\r\nThe second one can be considered as an acceptable ad-hoc internal revelation.\r\n\r\nIs it worth to document the third one, `replServer.close()`?",
        "labels": "doc",
        "id": 44449
    },
    {
        "title": "doc: link to code style guide",
        "body": "* **Subsystem**: doc\r\n\r\nIMHO we should add a link to the [Google Style Guide](https://google.github.io/styleguide/cppguide.html) according to which me are linting C++\r\nand add some __Best Practices__\r\n\r\nAfter #12540 I thought we should add something like:\r\n\r\n---\r\n#### When editing C++ \r\nIf you add a new macro or use a new external function, make sure you include the header file explicitly in the file you are editing. This makes sure your change is independent of previous changes, and makes it easier to backport",
        "labels": "doc",
        "id": 44450
    },
    {
        "title": "doc, tools: doc linting does not work in CI",
        "body": "* **Subsystem**: doc, tools\r\n\r\nIt seems https://github.com/nodejs/node/pull/12563 has not made all needed changes in build scripts to run doc linting on CI.\r\n\r\nI've tried to skim PRs from this search: [`is:pr is:open label:doc  -label:stalled`](https://github.com/nodejs/node/pulls?utf8=%E2%9C%93&q=is%3Apr%20is%3Aopen%20label%3Adoc%20%20-label%3Astalled) and run linter CI on them.\r\n\r\nSee this inconsistency: https://github.com/nodejs/node/pull/12549#issuecomment-296860563\r\n\r\nIt seems, CI uses commands not addressed in the https://github.com/nodejs/node/pull/12563 (see https://ci.nodejs.org/job/node-test-linter/8536/console).\r\n\r\nWhat should be added?\r\n\r\n",
        "labels": "doc",
        "id": 44451
    },
    {
        "title": "doc, meta: document what to do if `git push upstream master` is rejected",
        "body": "* **Subsystem**: doc, meta\r\n\r\nTrying to land a big PR after syncing the masters, while other collaborators actively pushed the same time, I've got this:\r\n```\r\nTo https://github.com/nodejs/node\r\n ! [rejected]              master -> master (fetch first)\r\nerror: failed to push some refs to 'https://github.com/nodejs/node'\r\nhint: Updates were rejected because the remote contains work that you do\r\nhint: not have locally. This is usually caused by another repository pushing\r\nhint: to the same ref. You may want to first integrate the remote changes\r\nhint: (e.g., 'git pull ...') before pushing again.\r\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\r\n```\r\n\r\nMaybe it is worth to be documented in the [COLLABORATOR_GUIDE.md#technical-howto](https://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md#technical-howto) what to do in this case.",
        "labels": "doc",
        "id": 44452
    },
    {
        "title": "Docs: http.ServerResponse is missing `socket` and `connection` fields",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v7.9.0\r\n* **Subsystem**: http\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n`http.ServerResponse` docs are missing `socket` and `connection` fields. Moreover, it should be mentioned that they're nulled after `end()` so this won't work: `resp.end(message, function(){ this.socket.destroy(); } );`",
        "labels": "doc",
        "id": 44453
    },
    {
        "title": "Document the eslint update process",
        "body": "See https://github.com/nodejs/node/pull/12563#issuecomment-296298136\r\n\r\n>As is, I'm OK with putting eslint-plugin-markdown into tools/eslint/node_modules as long as things break in an understandable way when the plugin is missing after an upgrade. For that matter, the upgrade process probably needs to be documented somewhere and that would be a good place to include the instructions to include the plugin. I might try to do that if I get some time today, but as always, I'd be thrilled if someone beats me to it. (I always forget a step in the upgrade anyway involving a symlink or something to .bin/eslint.js I think?\r\n\r\n\r\nThe symlink step was done in https://github.com/nodejs/node/pull/10771 and https://github.com/nodejs/node/pull/9299\r\n\r\nSee also https://github.com/nodejs/node/pull/9299#issuecomment-256488058\r\n\r\n>@Trott I'm not sure either. How did you create the eslint you committed? What was your sequence? We could probably figure out one that works and document in a README somewhere. Or in the next commit message. You put some effort into your commit to say what you did, but just at a high level.\r\n\r\ncc/ @Trott @vsemozhetbyt @sam-github ",
        "labels": "doc",
        "id": 44454
    },
    {
        "title": "Document that fs.futimes isn't supported on AIX",
        "body": "* **Version**: master\r\n* **Platform**: AIX\r\n* **Subsystem**: fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n`fs.futimes` isn't supported on AIX <7.1, see https://github.com/nodejs/node/pull/12583#issuecomment-296445710\r\n\r\nThis is mentioned in the [libuv docs](http://docs.libuv.org/en/v1.x/fs.html#c.uv_fs_futime):\r\n\r\n>Note AIX: This function only works for AIX 7.1 and newer. It can still be called on older versions but will return UV_ENOSYS.\r\n\r\nDo we normally duplicate such warnings in the Node docs? \r\n\r\n```js\r\n> fs.futimesSync(fd, s2.atime, s2.mtime)\r\nError: ENOSYS: function not implemented, futime\r\n    at Object.fs.futimesSync (fs.js:1216:11)\r\n    at repl:1:4\r\n    at ContextifyScript.Script.runInThisContext (vm.js:44:33)\r\n    at REPLServer.defaultEval (repl.js:239:29)\r\n    at bound (domain.js:301:14)\r\n    at REPLServer.runBound [as eval] (domain.js:314:12)\r\n    at REPLServer.onLine (repl.js:433:10)\r\n    at emitOne (events.js:120:20)\r\n    at REPLServer.emit (events.js:210:7)\r\n    at REPLServer.Interface._onLine (readline.js:262:10)\r\n```",
        "labels": "doc",
        "id": 44455
    },
    {
        "title": "doc, meta, tools: preparations for eslint-plugin-markdown",
        "body": "Since we [start using `eslint-plugin-markdown` soon](https://github.com/nodejs/node/pull/12563), some things should be done:\r\n\r\n1. Assess the impact on creating and landing doc PRs where code fragments are added or edited (or even each doc PR to be safe?). Assess running https://ci.nodejs.org/job/node-test-linter/ for them and update local ESLint configuration.\r\n\r\n2. Update docs accordingly if needed: `CONTRIBUTING.md`, `doc/onboarding.md`, `COLLABORATOR_GUIDE.md`, `.github/PULL_REQUEST_TEMPLATE.md`.\r\n\r\n3. Make sure collaborators and contributors are aware of the change.",
        "labels": "doc",
        "id": 44456
    },
    {
        "title": "UDP multicast in the cluster does not work ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:  v7.9.0 & v6.9.4\r\n* **Platform**: Linux ... x86_64 x86_64 x86_64 GNU/Linux/Centos v7.3\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n    \r\nI've tried to connect to UDP multicast from nodejs cluster.\r\nIt failed on the second process.\r\n\r\nWe are getting this error:\r\n\r\n```\r\ndgram.js:503\r\n    throw errnoException(err, 'addMembership');\r\n    ^\r\n\r\nError: addMembership EADDRINUSE\r\n    at exports._errnoException (util.js:1050:11)\r\n    at Socket.addMembership (dgram.js:503:11)\r\n    at Socket.<anonymous> (/install/multicastudp/test2.js:23:15)\r\n    at Object.onceWrapper (events.js:293:19)\r\n    at emitNone (events.js:91:20)\r\n    at Socket.emit (events.js:188:7)\r\n    at startListening (dgram.js:117:10)\r\n    at onHandle (dgram.js:200:9)\r\n    at shared (internal/cluster/child.js:105:3)\r\n    at Worker.send (internal/cluster/child.js:76:7)\r\n```\r\n\r\n\r\nCode we used:\r\n\r\n```\r\nconst cluster = require('cluster');\r\nconst dgram = require('dgram');\r\n\r\nconst udpPort = 64000;\r\nconst addr = '239.0.0.1';\r\n\r\nif(cluster.isMaster){\r\n\r\n     cluster.fork();\r\n     cluster.fork(); // << this process cause an error\r\n\r\n}else{\r\n\r\n  console.log(\"process pid: \" + process.pid);\r\n\r\n  var udpClient = dgram.createSocket({type:\"udp4\", reuseAddr:true});\r\n\r\n  udpClient.bind(udpPort, function(){\r\n    udpClient.addMembership(addr);\r\n  });\r\n\r\n}\r\n```\r\n",
        "labels": "doc",
        "id": 44457
    },
    {
        "title": "doc: typo in api/process.md",
        "body": "* **Version**: master, v7.x, v6.x\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nIn doc/api/process.md, there is a typo in the 'A note on process I/O' section where it says:\r\n\r\n<blockquote>\r\nSynchronous writes avoid problems such as output written with `console.log()` or `console.write()` being unexpectedly interleaved, ...\r\n</blockquote>\r\n\r\nwhere `console.write()` should presumably instead be `console.error()`, since `console.write()` does not exist and `console.error()` is the only other `console` method referred to in that section.",
        "labels": "doc",
        "id": 44458
    },
    {
        "title": "doc: fix documentation regarding cross-compilation",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI'm trying to cross compile from Linux to Mac. I'm not even sure it's supposed to work, but according to the [docs](https://github.com/nodejs/node/blob/master/BUILDING.md) you can specify a `dest-os` and a `--cross-compiling` so I guess it should.\r\n\r\nWhen I first tried to build on Linux for Mac, `./configure` threw some errors that XCode was not installed. I understand that you need XCode if you build on a Mac, but is this a requirement when you build for a Mac? I found that if you include `--ninja` then the XCode dependency was removed. The configuration arguments I'm using are:\r\n` ./configure --cross-compiling --without-intl --without-inspector --dest-cpu=x64 --dest-os=mac --without-snapshot --without-dtrace --ninja`\r\n\r\nHowever, if I then try to link the `.a` files on a Mac now (I'm linking against some other code I have), then I get the following:\r\n```\r\nld: warning: ld: warning: ignoring file ../node.out/mac/x64/src/libv8_libbase.a, file was built for\r\n unsupported file format ( 0x21 0x3C 0x74 0x68 0x69 0x6E 0x3E 0x0A 0x2F 0x20 0x20 0x20 0x20 \r\n0x20 0x20 0x20 ) which is not the architecture being linked (x86_64): \r\n../node.out/mac/x64/src/libv8_libbase.aignoring file ../node.out/mac/x64/src/libv8_base.a, file was built \r\nfor unsupported file format ( 0x21 0x3C 0x74 0x68 0x69 0x6E 0x3E 0x0A 0x2F 0x20 0x20 0x20 0x20 \r\n0x20 0x20 0x20 ) which is not the architecture being linked (x86_64): \r\n../node.out/mac/x64/src/libv8_base.a\r\n```\r\n\r\nAny ideas / pointers?\r\n\r\n",
        "labels": "doc",
        "id": 44459
    },
    {
        "title": "String::localeCompare support required.",
        "body": "* **Version**: v7.9.0\r\n* **Platform**: Windows 10 (64-bit)\r\n* **Subsystem**: none\r\n\r\nThe following code will print `[\"çŸ®\", \"ç¬¨\", \"åƒ\", \"a\", \"b\", \"c\"]` in a uptodate browser, which is expected. But nodejs will print `[\"a\", \"b\", \"c\", \"åƒ\", \"çŸ®\", \"ç¬¨\"]` for the same code, which is not reasonable for chinese users.\r\n\r\n```\r\nconsole.log(['çŸ®', 'åƒ', 'ç¬¨', 'a', 'c', 'b'].sort((a, b) => a.localeCompare(b, 'zh-Hans-CN')))\r\n```\r\n\r\nHope the String::localeCompare() function can be supported better, this is very useful for non-english-speaking users. thx :)",
        "labels": "doc",
        "id": 44460
    },
    {
        "title": "What are Node.js \"Linked\" modules?",
        "body": "When I was going through the source code, I found this in [node.cc](https://github.com/nodejs/node/blob/v8.x/src/node.cc#L2396),\r\n\r\n    // \"Linked\" modules are included as part of the node project.\r\n    // Like builtins they are registered *before* node::Init runs.\r\n    mp->nm_flags = NM_F_LINKED;\r\n\r\nDoes anybody know what \"Linked\" modules are? @bnoordhuis maybe?\r\n\r\n---\r\n\r\ncc @addaleax ",
        "labels": "doc",
        "id": 44461
    },
    {
        "title": "PSA: new tag \"regression\"",
        "body": "There is a new tag for issues (available also for PRs) called \"regression\" please use it in addition to \"confirmed-bug\" to indicate that something that used to work has stopped working, or in the case that CI for `master` turns red.\r\n\r\nIMHO we all should be more attentive to this list:\r\nhttps://github.com/nodejs/node/issues?q=is%3Aopen+is%3Aissue+label%3Aregression\r\n\r\n## Looking for advice as to how to document this in the guides\r\nI believe this should be reflected in one of the guides, I'm not sure which and exactly how. I'm seeking your advice.\r\n\r\n### some personal opinions\r\nFor me personally an ignored red CI is perceived as an act of disrespect to your fellow devs, and I find that offensive.\r\n\r\n1. These issues may arise from a user report, where I believe acknowledging that this is indeed a regression will help communicate that we are taking this seriously. IMHO even a lively discussion helps the reporter feel that they are being heard (e.g. #11103)\r\n\r\n2. Since the CI turning red for `master` is a situation that frustrates other contributors, and may lead to waste of others time, I posit that the respectful thing is for \"landers\" to run a post land CI job and in cases that CI turns red, open a \"regression\" issue, so that they can recruit help solving the issue ASAP. In cases where a solution seems to be far, I recommend reverting, and reopening the PR for improvement.\r\n\r\n",
        "labels": "doc",
        "id": 44462
    },
    {
        "title": "Typo in CHANGELOG.MD",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nIn the [main changelog](https://github.com/nodejs/node/blob/master/CHANGELOG.md), there is a literal '<' immediately after '7.8.0' in the version list at the top that needs to be removed.",
        "labels": "doc",
        "id": 44463
    },
    {
        "title": "process: process.kill() and signals on Windows",
        "body": "* **Version**: many\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: process\r\n\r\nThe doc [states](https://nodejs.org/api/process.html#process_signal_events):\r\n\r\n> *Note*: Windows does not support sending signals, but Node.js offers some emulation with `process.kill()`, and `ChildProcess.kill()`.\r\n\r\nWRT supporting signals on Windows, the doc makes only this remark:\r\n\r\n> `SIGTERM` is not supported on Windows, it can be listened on.\r\n\r\nAs for the rest, `process.kill()` behavior on Windows is somehow confusing and hazardous. A test file with just this line:\r\n```js\r\nprocess.kill(process.pid, SIGNAL_NAME_MENTIONED_IN_THE_DOC);\r\n```\r\ngives three types of results.\r\n\r\n1. `SIGTERM`, `SIGINT`, `SIGKILL` (despite the doc note wrt `SIGTERM`) â€” silently exit.\r\n2. `SIGUSR1`, `SIGPIPE`, `SIGSTOP`, `SIGBUS` â€” throw this error:\r\n```\r\ninternal/process.js:184\r\n        throw new Error(`Unknown signal: ${sig}`);\r\n        ^\r\n\r\nError: Unknown signal: SIGUSR1\r\n    at process.kill (internal/process.js:184:15)\r\n    at Object.<anonymous> (...\\test.js:5:9)\r\n    at Module._compile (module.js:607:30)\r\n    at Object.Module._extensions..js (module.js:618:10)\r\n    at Module.load (module.js:516:32)\r\n    at tryModuleLoad (module.js:466:12)\r\n    at Function.Module._load (module.js:458:3)\r\n    at Module.runMain (module.js:643:10)\r\n    at run (bootstrap_node.js:441:7)\r\n    at startup (bootstrap_node.js:144:9)\r\n```\r\n3. `SIGHUP`, `SIGBREAK`, `SIGWINCH`, `SIGFPE`, `SIGSEGV`, `SIGILL` â€” throw this error:\r\n```\r\ninternal/process.js:190\r\n      throw errnoException(err, 'kill');\r\n      ^\r\n\r\nError: kill ENOSYS\r\n    at exports._errnoException (util.js:1057:11)\r\n    at process.kill (internal/process.js:190:13)\r\n    at Object.<anonymous> (...\\test.js:6:9)\r\n    at Module._compile (module.js:607:30)\r\n    at Object.Module._extensions..js (module.js:618:10)\r\n    at Module.load (module.js:516:32)\r\n    at tryModuleLoad (module.js:466:12)\r\n    at Function.Module._load (module.js:458:3)\r\n    at Module.runMain (module.js:643:10)\r\n    at run (bootstrap_node.js:441:7)\r\n```\r\nAs with [this issue](https://github.com/nodejs/node/issues/12351), I am not sure, if this is a Node.js or libuv domain. Also I am not sure if this should be addressed in code or in docs. So just reporting for extra precaution.",
        "labels": "doc",
        "id": 44464
    },
    {
        "title": "doc: confusing language in util.format() docs",
        "body": "https://github.com/nodejs/node/commit/214d02040e1c46b8cac47451bf2f0e2fc15a3e0f\r\n\r\nThe intention to speed up util.format breaks the following case:\r\n\r\n```\r\nutil.format('%%')\r\n```\r\nprior to this commit, this returned '%', now it returns '%%'.\r\n\r\nImho, this is a bug and should be reverted.",
        "labels": "doc",
        "id": 44465
    },
    {
        "title": "doc,fs: document WHATWG URL support",
        "body": "* **Version**: >= 7.6.0\r\n* **Platform**: n/a\r\n* **Subsystem**: fs, url\r\n\r\n#10739 (fs: allow WHATWG URL and file: URLs as paths) was landed without documentation, because `url.URL` itself was undocumented at that time. Now `url.URL` is documented [here](https://nodejs.org/api/url.html#url_the_whatwg_url_api), so the `fs`  docs should include its support, too.\r\n\r\nI think this is about what needs to be done:\r\n- `URL` needs to be added to the lists of supported types for the filename parameters\r\n- It needs to be mentioned that only `file:///` URL objects are supported\r\n- An entry needs to be added to the `changes:` lists for the relevant methods that states the version this was added in (7.6.0) and that the support is currently still experimental.\r\n\r\nAs always, let us know here, in #node-dev on Freenode, or basically anywhere where you can reach us if you need any help or have any questions!\r\n\r\n(oh, also: please comment here if you would like to try and take this on, so people donâ€™t get in each otherâ€™s way. :smile_cat:  )",
        "labels": "doc",
        "id": 44466
    },
    {
        "title": "readdir docs donâ€™t mention when options argument was added",
        "body": "<blockquote>\r\n\r\n## [fs.readdir(path[, options], callback)](https://nodejs.org/api/fs.html#fs_fs_readdir_path_options_callback)\r\n\r\n<details open><summary>History</summary>\r\n\r\nVersion | Changes\r\n:------ | :---\r\nv7.0.0 | The callback parameter is no longer optional. Not passing it will emit a deprecation warning.\r\nv0.1.8 | Added in: v0.1.8\r\n</details>\r\n</blockquote>\r\n\r\n`options` was added in Node 6.0.0 by #5616. But itâ€™s not mentioned, which led me to writing generic code that passed through `undefined` for `options`, which naturally made it fall apart on the Node 4 LTS release that doesnâ€™t support `options` and so perceived it as just an undefined callback.\r\n\r\nThis *really* worries me. If something like this can change without any note in the history, what else is lacking history of changes that will come and bite me later? I no longer trust this documentation. At least https://nodejs.org/docs/latest-v4.x/api/fs.html#fs_fs_readdir_path_callback is still there, Iâ€™ll just need to remember to work there.",
        "labels": "doc",
        "id": 44467
    },
    {
        "title": "docs: explain why path.posix.normalize does not replace windows slashes",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 4.4.2\r\n* **Platform**: Windows 8.1 64 bit\r\n* **Subsystem**: node.js native path module\r\n\r\n---\r\n\r\n```js\r\nconsole.log('1', path.posix.normalize(\"\\\\some\\\\thing\\\\like\\\\this\"))\r\nconsole.log('2', path.posix.normalize(\"/some/thing/like/this\"))\r\nconsole.log('3', path.win32.normalize(\"\\\\some\\\\thing\\\\like\\\\this\"))\r\nconsole.log('4', path.win32.normalize(\"/some/thing/like/this\"))\r\n```\r\noutput:\r\n![image](https://cloud.githubusercontent.com/assets/4729968/24842954/f7c14fb2-1d6b-11e7-83db-c13a4fb931f2.png)\r\n\r\n~~1 output should be the same as 2s though~~\r\nDocs need to explain why this is the expected output\r\n\r\n",
        "labels": "doc",
        "id": 44468
    },
    {
        "title": "doc: are `os.uptime()` returned type and remark correct?",
        "body": "* **Version**: 8.0.0-rc.0\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: doc, os\r\n\r\nCurrently, both `os.uptime()` and `process.uptime()` return number with fractional seconds on Windows:\r\n```\r\n> os.uptime()\r\n34298.2171316\r\n> process.uptime()\r\n20.648\r\n```\r\nHowever, their docs are different here:\r\n\r\nhttps://github.com/nodejs/node/blame/7a5d07c7fbd43f3645d7f707fd6a98f2a251bdbd/doc/api/os.md#L372-L384\r\n\r\nhttps://github.com/nodejs/node/blame/47f8f7462fb198aa27ede602c43786bdbfda37a2/doc/api/process.md#L1662-L1671\r\n\r\nAre `os.uptime()` returned type `integer` and `*Note*` outdated or just OS-dependent?",
        "labels": "doc",
        "id": 44469
    },
    {
        "title": "Code example in the docs of Error.captureStackTrace needs better wording",
        "body": "Ref: https://nodejs.org/dist/latest-v7.x/docs/api/errors.html#errors_error_capturestacktrace_targetobject_constructoropt\r\n```js\r\nfunction MyError() {\r\n  Error.captureStackTrace(this, MyError);\r\n}\r\n\r\n// Without passing MyError to captureStackTrace, the MyError\r\n// frame would show up in the .stack property. By passing\r\n// the constructor, we omit that frame and all frames above it.\r\nnew MyError().stack;\r\n```\r\nResult:\r\n```\r\nError\r\n    at Object.<anonymous> (/Users/mjayaraman/SVNFiles/node/course/error.js:8:11)\r\n    at Module._compile (module.js:541:32)\r\n    at Object.Module._extensions..js (module.js:550:10)\r\n    at Module.load (module.js:458:32)\r\n    at tryModuleLoad (module.js:417:12)\r\n    at Function.Module._load (module.js:409:3)\r\n    at Function.Module.runMain (module.js:575:10)\r\n    at startup (node.js:160:18)\r\n    at node.js:456:3\r\n```\r\n```js\r\nfunction MyError() {\r\n  Error.captureStackTrace(this);\r\n}\r\n\r\n// Without passing MyError to captureStackTrace, the MyError\r\n// frame would show up in the .stack property. By passing\r\n// the constructor, we omit that frame and all frames above it.\r\nnew MyError().stack;\r\n```\r\n```\r\nError\r\n    at new MyError (/Users/mjayaraman/SVNFiles/node/course/error.js:2:9)\r\n    at Object.<anonymous> (/Users/mjayaraman/SVNFiles/node/course/error.js:8:11)\r\n    at Module._compile (module.js:541:32)\r\n    at Object.Module._extensions..js (module.js:550:10)\r\n    at Module.load (module.js:458:32)\r\n    at tryModuleLoad (module.js:417:12)\r\n    at Function.Module._load (module.js:409:3)\r\n    at Function.Module.runMain (module.js:575:10)\r\n    at startup (node.js:160:18)\r\n    at node.js:456:3\r\n```\r\n\r\nMeaning, it just omits that frame, if we pass the constructor and not the above frames.\r\n```js\r\n// the constructor, we omit that frame and all frames above it. \r\n```\r\nTo be changed to \r\n```js\r\n// the constructor, we omit that frame.\r\n```\r\nor\r\n```js\r\n// the constructor, we omit that frame, and retain all frames above it.\r\n```\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "doc",
        "id": 44470
    },
    {
        "title": "AssertionError is not documented",
        "body": "`AssertionError` is [exported](https://github.com/nodejs/node/blob/c6e0ba31ecdf633074b76b908944c37935027f04/lib/assert.js#L41) by the `assert` module.\r\nThe documentation has many mentions to `AssertionError` but the value itself is not documented. I think it deserves a paragraph.",
        "labels": "doc",
        "id": 44471
    },
    {
        "title": "Any way to bypass querystring.stringify with empty Object ?",
        "body": "I am working currently on a project that requires to send custom GET HTTP requests.\r\n\r\nI am using the default querystring builder (https://nodejs.org/api/querystring.html)\r\n\r\n    const querystring = require('querystring');\r\n\r\nThe problem is for Object (probably also for empty array) such as\r\n\r\n    { \"extendTypes\":{} }  \r\n\r\nis serialiazed as :\r\n\r\n    extendTypes=\r\n\r\nThe expected result :\r\n\r\n    extendTypes={}\r\n\r\nor its URI encoded version :\r\n\r\n    extendTypes%3D%7B%7D\r\n\r\nSo , how can I ever hope to do that ? Any way to bypass this default behalvior ?\r\n\r\nHere is my full code if you want :\r\n\r\n    function generateGetRequest(dataMap, url) {\r\n    \r\n        let queryParams = {};\r\n        let uriParams = {};\r\n    \r\n        for (let [key, value] of dataMap) {\r\n    \r\n            // if value is an object or an array\r\n            if (value instanceof Object || value instanceof Array) {\r\n                uriParams[key] = value;\r\n            } else {\r\n                // param working for superagent\r\n                queryParams[key] = value;\r\n            }\r\n    \r\n        }\r\n        let queryParamsUri = querystring.stringify(uriParams);\r\n        console.log(queryParamsUri);\r\n        let finalUrl = url + ( (Object.keys(uriParams).length > 0) ? \"?\" + queryParamsUri : \"\");\r\n    }\r\n\r\n* **Version**: 6.9.4\r\n* **Platform**: Windows 10\r\n\r\n",
        "labels": "doc",
        "id": 44472
    },
    {
        "title": "Add docs for gdbinit and lldbinit",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nCurrently when running `make install` gdbinit and [soon](https://github.com/nodejs/node/pull/12061) lldbinit are installed to `$PREFIX//share/doc/node/`, where prefix is the value specified using --prefix to configure, but there is no documentation regarding how to use these file. \r\n\r\nThis issue should add such documentation to the appropriate place. Perhaps the [guides/debugging_getting_started.md](https://github.com/nodejs/nodejs.org/blob/master/locale/en/docs/guides/debugging_getting_started.md) is a good place?\r\n\r\n",
        "labels": "doc",
        "id": 44473
    },
    {
        "title": "API Documentation for C++ Addons similar to other modules",
        "body": "Almost all NodeJS modules in the API documentation have a proper class based documentation where we can read through to get an understanding of all the methods available in a class. In case of the [C++ Addons](https://nodejs.org/dist/latest-v7.x/docs/api/addons.html) page, it is more like an examples page, along with some documentation. Is there any particular reason it is made that way?\r\n\r\nIt'd be great to have an API documentation page. Right now, I need to convert a **Local<v8::String>** from args into a **char*** to pass to another library. Any suggestion how this could be done?",
        "labels": "doc",
        "id": 44474
    },
    {
        "title": "Documentation, dns.resolvePtr(hostname) missing callback argument",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v7.8.0\r\n* **Platform**: Windows 10 Pro x64\r\n* **Subsystem**: Documentation\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`https://nodejs.org/dist/latest-v7.x/docs/api/dns.html#dns_dns_resolveptr_hostname`\r\n\r\n> dns.resolvePtr(hostname)\r\n\r\nShould be\r\n\r\ndns.resolvePtr(hostname, callback)",
        "labels": "doc",
        "id": 44475
    },
    {
        "title": "The docs for path.resolve does not state if cross platform",
        "body": "Hi!\r\n\r\nDisclaimer: Maybe I'm in the wrong issue tracker here but [nodejs/docs](https://github.com/nodejs/docs) doesn't seem to be the right place either.\r\n\r\nAs I understand it `path.resolve` is cross platform compatible but it's not apparent in the [docs](https://github.com/nodejs/node/blob/master/doc/api/path.md) compared to `path.join` where it's explicitly stated.\r\n\r\n> The path.join() method joins all given path segments together using the platform specific separator as a delimiter\r\n\r\nIf I'm right - do you accept PRs to docs?",
        "labels": "doc",
        "id": 44476
    },
    {
        "title": "domains docs bug / misconception",
        "body": "I am looking at the node docs for domain\r\n\r\nhttps://nodejs.org/api/domain.html\r\n\r\nthere seems to be a misconception about when a domain is entered\r\n\r\nhere domains do their thing:\r\n\r\n```js\r\nconst domain = require('domain');\r\nconst d = domain.create();\r\n\r\nd.once('error', function(){\r\n     // this handler will catch 'foo'\r\n});\r\n\r\nd.run(function(){\r\n   throw 'foo';\r\n});\r\n```\r\n\r\nthe following is copied from the docs page, at the bottom. the docs say that the following is the simplest way to use domains:\r\n\r\n```js\r\nconst domain = require('domain');\r\nconst fs = require('fs');\r\nconst d = domain.create();\r\nd.on('error', (er) => {\r\n  console.error('Caught error!', er);\r\n});\r\nd.run(() => {\r\n  process.nextTick(() => {\r\n    setTimeout(() => { // simulating some various async stuff\r\n      fs.open('non-existent file', 'r', (er, fd) => {\r\n        if (er) throw er;\r\n        // proceed...\r\n      });\r\n    }, 100);\r\n  });\r\n});\r\n```\r\n\r\nbut with what we said before in mind, it seems like the following is a simpler way to use domains (just omit the `process.nextTick() `call, we don't need it):\r\n\r\n```js\r\nconst domain = require('domain');\r\nconst fs = require('fs');\r\nconst d = domain.create();\r\nd.on('error', (er) => {\r\n  console.error('Caught error!', er);\r\n});\r\nd.run(() => {\r\n    setTimeout(() => { // simulating some various async stuff\r\n      fs.open('non-existent file', 'r', (er, fd) => {\r\n        if (er) throw er;\r\n        // proceed...\r\n      });\r\n    }, 100);\r\n});\r\n```\r\n\r\nIs the `process.nextTick` call really necessary to \"enter\" a domain? not to my knowledge. I would even get rid of the setTimeout(), then the example is even clearer.\r\n\r\nI think this might be a doc bug? Or ?",
        "labels": "doc",
        "id": 44477
    },
    {
        "title": "Node is casting all env vars to Strings",
        "body": "* **Version**: v6.10.0\r\n\r\n* **Platform**: Mac OS X\r\n* **Subsystem**:\r\n\r\nI might have just realised this now, but is it intended that all env vars are casted to Strings by default? See:\r\n\r\n```sh\r\nÂ» node\r\n> process.env.BANANAS = 3\r\n3\r\n> typeof process.env.BANANAS\r\n'string'\r\n> process.env.BANANAS = undefined\r\nundefined\r\n> typeof process.env.BANANAS\r\n'string'\r\n>\r\n```\r\n\r\nThank you :) ",
        "labels": "doc",
        "id": 44478
    },
    {
        "title": "Get method does not check options's Object prototype",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.10.0\r\n* **Platform**: 3.10.0-514.2.2.el7.x86_64 #1 SMP Tue Dec 6 23:06:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux AND Windows 8.1 64\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nThe get method of http and https modules does not check the prototype of the given object. I guess this replicates to all other request/response methods.\r\nThe following code is ran on a machine that does not have anything running on port 8989:\r\n```JavaScript\r\n'use strict';\r\n\r\nconst http = require(\"http\");\r\n\r\nlet options = {\r\n        port: 8989\r\n};\r\nlet optionsChild = Object.create(options);\r\n\r\nhttp.get(options, function () {\r\n        console.log(\"Success options\");\r\n}).on('error', console.error);\r\nhttp.get(optionsChild, function () {\r\n        console.log(\"Success optionsChild\");\r\n}).on('error', console.error);\r\n```\r\nAnd we receive the following output:\r\n```cmd\r\n{ Error: connect ECONNREFUSED 127.0.0.1:8989\r\n    at Object.exports._errnoException (util.js:1022:11)\r\n    at exports._exceptionWithHostPort (util.js:1045:20)\r\n    at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1087:14)\r\n  code: 'ECONNREFUSED',\r\n  errno: 'ECONNREFUSED',\r\n  syscall: 'connect',\r\n  address: '127.0.0.1',\r\n  port: 8989 }\r\nSuccess optionsChild\r\n```\r\nThis means the port takes the default value and successfully connects instead of taking the 8989 port from the prototype.\r\n1. Is this intended?\r\n\r\nThe need for this code arose from the necessity to reuse some default options in multiple requests. So I would like to ask a followup question:\r\n\r\n2. Can reusing(altering) the options Object passed to a http/https request cause unexpected behavior(requests being made to the last value of the object instead of the value at the moment of the function call or performance losses)?",
        "labels": "doc",
        "id": 44479
    },
    {
        "title": "Should we replace the word \"OS X\" with \"macOS\"?",
        "body": "Last year,Apple update MacOS X 10.11 to macOS Sierra(10.12),so \"OSX\" \"OS X\" and \"MACOSX\" more and less are old.Should we update \"OSX\" \"OS X\" and \"MACOSX\" into \"macOS\" in our code?",
        "labels": "doc",
        "id": 44480
    },
    {
        "title": "Document CI jobs",
        "body": "* **Subsystem**: doc, build\r\n\r\nSee https://github.com/nodejs/help/issues/548, we should briefly document the jobs we have in CI, probably in the [COLLABORATOR_GUIDE](https://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md).\r\n\r\nhttps://ci.nodejs.org/job/node-stress-single-test/\r\n\r\ncc/ @vsemozhetbyt ",
        "labels": "doc",
        "id": 44481
    },
    {
        "title": "Tls doc links broken",
        "body": "It seems all the links that link to elsewhere in the docs are broken?\r\n\r\nI can work on this tomorrow if it hasn't already been fixed./If it's a valid issue.\r\n\r\nExample of one of many broken links: \r\nhttps://github.com/nodejs/node/blob/master/doc/api/tls.md#serveraddress\r\n",
        "labels": "doc",
        "id": 44482
    },
    {
        "title": "Doc issue",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n6.x-latest\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nThe link here needs to be changed to not reference the master branch md file:\r\nhttps://nodejs.org/docs/latest-v6.x/api/timers.html#timers_setimmediate_callback_args\r\n\r\nthe link address is:\r\nhttps://github.com/nodejs/node/blob/master/doc/topics/event-loop-timers-and-nexttick.md\r\n\r\n(please advise if there's a better place to post this issue, or where I can submit the PR)",
        "labels": "doc",
        "id": 44483
    },
    {
        "title": "tlsClientError event does not provide access to the remote address",
        "body": "* **Version**: 7.7.4\r\n* **Platform**: Windows 32bit\r\n* **Subsystem**: HTTPS\r\n\r\nIt appears the socket parameter of the [tlsClientError](https://nodejs.org/api/tls.html#tls_event_tlsclienterror) event does not include the address of the remote machine. In fact, it seems the socket refers to the listening socket and not the client socket.\r\n\r\nThe following example will yield _undefined_ when a request is sent.\r\n\r\n```javascript\r\nrequire('https').createServer( { } ).listen(1234).on(\r\n  'tlsClientError',\r\n  (err, s) => { console.log(s.remoteAddress); }\r\n);\r\n```",
        "labels": "doc",
        "id": 44484
    },
    {
        "title": "new lint option on windows is missing documentation",
        "body": "https://github.com/nodejs/node/pull/11856#pullrequestreview-28175277\r\n/cc @liusy182\r\nNew options should be documented in `help` line (now 420) of `vcbuild.bat`",
        "labels": "doc",
        "id": 44485
    },
    {
        "title": "Document tls.Server#listen(path, callback) and possible other signatures",
        "body": "We currently support unix sockets on `https.Server` and `net.Server`, but for some reason not on `tls.Server`. Seems like an oversight to me, would anyone agree?",
        "labels": "doc",
        "id": 44486
    },
    {
        "title": "Missing word in Stream docs ",
        "body": "There is a small error in the documentation for Streams. Under the [**Readable Streams**](https://github.com/nodejs/node/blob/master/doc/api/stream.md#two-modes) section It's mentioned - \r\n\r\n> Note: If a Readable is switched into flowing mode and there are no consumers available handle the data, that data will be lost.\r\n\r\nI think the word \"to\" is missing in that sentence between the \"available\" and \"handle\" words. I think it should be - \r\n\r\n> Note: If a Readable is switched into flowing mode and there are no consumers available to handle the data, that data will be lost.",
        "labels": "doc",
        "id": 44487
    },
    {
        "title": "Node.js version mentioned as 7.7.1 instead of 7.7.2 in CHANGELOG",
        "body": "In the Node.js [changelog](https://github.com/nodejs/node/blob/master/doc/changelogs/CHANGELOG_V7.md) the latest version is mentioned as `7.7.1` instead of the `7.7.2` under the **current** section.\r\n\r\n\r\n![nodejs](https://cloud.githubusercontent.com/assets/11979293/23845990/3ee9de44-07f1-11e7-9b80-a57c2aed4c03.png)\r\n",
        "labels": "doc",
        "id": 44488
    },
    {
        "title": "data.copy() socket.on() errors",
        "body": "Version nodejs 7.7.1 (apt-get install node)\r\non lubuntu 16.04\r\n\r\nrunning the code in the demo here,\r\nhttps://nodejs.org/api/buffer.html#buffer_class_method_buffer_allocunsafeslow_size\r\n\r\nI've put the code in demo.js and then \"node demo.js\"\r\n\r\nsocket.on is not recognised as an available object\r\n\r\nReferenceError: socket is not defined\r\n    at Object.<anonymous> (/home/pater92/Desktop/WorkingVL/resources/nodejs/Nodejsdoc/buffer.js:19:1)\r\n    at Module._compile (module.js:571:32)\r\n    at Object.Module._extensions..js (module.js:580:10)\r\n    at Module.load (module.js:488:32)\r\n    at tryModuleLoad (module.js:447:12)\r\n    at Function.Module._load (module.js:439:3)\r\n    at Module.runMain (module.js:605:10)\r\n    at run (bootstrap_node.js:425:7)\r\n    at startup (bootstrap_node.js:146:9)\r\n    at bootstrap_node.js:540:3\r\n\r\nand data.copy have this error\r\n\r\ndata.copy(sb,0,0,10);\r\n     ^\r\n\r\nTypeError: data.copy is not a function\r\n    at Object.<anonymous> (/home/pater92/Desktop/WorkingVL/resources/nodejs/Nodejsdoc/buffer.js:20:6)\r\n    at Module._compile (module.js:571:32)\r\n    at Object.Module._extensions..js (module.js:580:10)\r\n    at Module.load (module.js:488:32)\r\n    at tryModuleLoad (module.js:447:12)\r\n    at Function.Module._load (module.js:439:3)\r\n    at Module.runMain (module.js:605:10)\r\n    at run (bootstrap_node.js:425:7)\r\n    at startup (bootstrap_node.js:146:9)\r\n    at bootstrap_node.js:540:3",
        "labels": "doc",
        "id": 44489
    },
    {
        "title": "doc: missing API links in process markdown",
        "body": "* **Version**: master, v7.7.0+\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\n[The \"A note on process I/O\" section](https://nodejs.org/docs/latest/api/process.html#process_a_note_on_process_i_o) in the `process.stdout` description is missing link references at the bottom of the markdown for `console.log()` and `console.error()`, causing the links to not render correctly.\r\n",
        "labels": "doc",
        "id": 44490
    },
    {
        "title": "Document that you can only listen on an already closed socket",
        "body": "* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nFrom https://github.com/nodejs/node/pull/8419#issuecomment-251793465,\r\n\r\n>@addaleax raised a possible concern with #8294 which states in the docs that you can listen() on the same socket multiple times. It should probably say more clearly that you can only listen() on an already closed socket.\r\n\r\n_**EDIT:**_ PR raised: https://github.com/nodejs/node/pull/13149/files",
        "labels": "doc",
        "id": 44491
    },
    {
        "title": "Reasons for not using GitHub's green button are unconvincing",
        "body": "The [Landing Pull Requests](https://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md#landing-pull-requests) section in COLLABORATOR_GUIDE.md admonishes against using the button for merging, but the cited reasons are arguable:\r\n\r\n>If you do, please force-push removing the merge.\r\n\r\nObsolete advice. This feature is disabled in this repo, so it's impossible to create a merge commit using the button in the first place.\r\n\r\n>The merge method will add an unnecessary merge commit.\r\n\r\nSee above. If anything, this should explain why it's disabled, rather than why one shouldn't use it.\r\n\r\n>The rebase & merge method adds metadata to the commit title.\r\n\r\nDoes \"commit title\" mean the first line of the commit message? If so, it's not clear how one can add metadata to the first line of text. Anyway, the commit messages for all commits in the PR are left unmodified.\r\n\r\n>The rebase method changes the author.\r\n\r\n[Doesn't.](https://github.com/seishun/test-test/pull/2)\r\n\r\n>The squash & merge method has been known to add metadata to the commit title.\r\n\r\nSame question as above. It does add the PR number to the first line of the commit message, but you can remove it before confirming.\r\n\r\n![image](https://cloud.githubusercontent.com/assets/988441/23556102/08a7647e-0034-11e7-97ed-021f0c8bf638.png)\r\n\r\n>If more than one author has contributed to the PR, only the latest author will be considered during the squashing.\r\n\r\nNot relevant for most PRs. Besides, how would you have multiple authors for a single commit anyway?\r\n\r\n---\r\n\r\nMy proposal: replace this whole section with a warning about the automatically added PR number.",
        "labels": "doc",
        "id": 44492
    },
    {
        "title": "Docs say that 'data' event mechanisms is preferred over 'readable'",
        "body": "In the docs saying:\r\n> Note: In general, the readable.pipe() and 'data' event mechanisms are preferred over the use of the 'readable' event.\r\n\r\nReference: https://nodejs.org/dist/latest-v6.x/docs/api/stream.html#stream_readable_streams\r\n\r\nWhat does 'general' means because of simplicity ? I think it should be better documented. Pull streams are much more efficient e.g referring to buffering and back-pressure.\r\n\r\nhttps://gist.github.com/caike/ebccc95bd46f5fa1404d\r\n",
        "labels": "doc",
        "id": 44493
    },
    {
        "title": "`arguments` property of `ReferenceError` instance?",
        "body": "* **Version**:\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: doc, errors\r\n\r\n`errors.md` [states](https://github.com/nodejs/node/blob/master/doc/api/errors.md#class-referenceerror):\r\n\r\n> `ReferenceError` instances will have an `error.arguments` property whose value is an array containing a single element: a string representing the variable that was not defined.\r\n\r\nHowever, it seems this property does not exixst anymore in the actual Node.js versions:\r\n```js\r\ntry {\r\n  doesNotExist;\r\n} catch (err) {\r\n  console.log(Object.getOwnPropertyNames(err));\r\n}\r\n```\r\n```\r\n  // v8 4.5.103.45 (Node.js 4.8.0 x64)\r\n\r\n[ 'stack', 'message' ]\r\n\r\n  // v8 5.1.281.93 (Node.js 6.10.0 x64)\r\n\r\n[ 'stack', 'message' ]\r\n\r\n  // v8 5.5.372.40 (Node.js 7.6.0 x64)\r\n\r\n[ 'stack', 'message' ]\r\n\r\n  // v8 5.6.326.55 (Node.js 8.0.0-nightly20170222a1802e670d x64)\r\n\r\n[ 'stack', 'message' ]\r\n\r\n  // v8 5.8.202 (Node.js 8.0.0-pre x64)\r\n\r\n[ 'stack', 'message' ]\r\n```\r\nIs this an unintended loss or is this property removed intentionally?",
        "labels": "doc",
        "id": 44494
    },
    {
        "title": "doc,vm: warn more prominently against executing untrusted code",
        "body": "The vm module is not a security mechanism.  There used to be a prominent warning against executing untrusted code but it seems to have been removed in recent years.\r\n\r\nI think it would be good to bring it back because the language around sandboxing can mislead users into thinking the vm module is something it's not.",
        "labels": "doc",
        "id": 44495
    },
    {
        "title": "Update the authors list",
        "body": "The `AUTHORS` list seems to be old. I would like to submit a PR for this. Thanks. ",
        "labels": "doc",
        "id": 44496
    },
    {
        "title": "Degraded performance of ia32 builds on x64 Windows and undocumented build parameter",
        "body": "* **Version**: master / vee-eight-lkgr (8.0.0-pre)\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: build, child_process\r\n\r\nI've noticed a substantial difference between downloaded Node.js binaries and binaries built locally by myself.\r\n\r\nFor example, master and  vee-eight-lkgr built today vs node.8.0.0-nightly20170221:\r\n\r\n1. Are ~3-4 MB less.\r\n2. Have degraded performance for `child_process.exec()` and `child_process.execSync()`\r\n\r\nTest script and data:\r\n```js\r\n'use strict';\r\n\r\nconsole.log(`\\n// v8 ${process.versions.v8} (Node.js ${process.versions.node})\\n`);\r\n\r\nconst exec     = require('child_process').exec;\r\nconst execSync = require('child_process').execSync;\r\n\r\nconsole.time('exec');\r\nfor (let i = 0; i < 1e2; i++) exec('echo');\r\nconsole.timeEnd('exec');\r\n\r\nconsole.time('execSync');\r\nfor (let i = 0; i < 1e2; i++) execSync('echo');\r\nconsole.timeEnd('execSync');\r\n\r\n```\r\n```\r\n// v8 4.5.103.45 (Node.js 4.8.0)\r\n\r\nexec: 362ms\r\nexecSync: 717ms\r\n\r\n// v8 5.1.281.93 (Node.js 6.10.0)\r\n\r\nexec: 317.696ms\r\nexecSync: 720.335ms\r\n\r\n// v8 5.5.372.40 (Node.js 7.6.0)\r\n\r\nexec: 329.204ms\r\nexecSync: 780.849ms\r\n\r\n// v8 5.5.372.40 (Node.js 8.0.0-nightly201702211162e284ca)\r\n\r\nexec: 355.399ms\r\nexecSync: 754.043ms\r\n\r\n// v8 5.5.372.40 (Node.js 8.0.0-pre)\r\n\r\nexec: 1708.721ms\r\nexecSync: 2392.159ms\r\n\r\n// v8 5.8.202 (Node.js 8.0.0-pre)\r\n\r\nexec: 1693.617ms\r\nexecSync: 2367.062ms\r\n```\r\nThe first 4 binaries are downloaded from the site, the last two are built locally from downloaded GitHub source zip according to `BUILDING.md` (with `chcp 1252` before building [to be on the safe side](https://github.com/nodejs/node/issues/11469)). All tests are OK.\r\n\r\nWhat am I doing possibly wrong?\r\n\r\n",
        "labels": "doc",
        "id": 44497
    },
    {
        "title": "fg(1) in readline's page is broken link",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: N/A\r\n* **Platform**: N/A\r\n* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n[This page](http://man7.org/linux/man-pages/man1/fg.1.html) is 404 now.\r\n\r\ndisputed point: https://nodejs.org/dist/latest-v7.x/docs/api/readline.html#readline_event_sigcont",
        "labels": "doc",
        "id": 44498
    },
    {
        "title": "please explain coverage flag",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 7.5\r\n* **Platform**: 64bit\r\n* **Subsystem**: Ubuntu 16.04.1 LTS\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nCould someone explain what the --coverage flag means.\r\nWhat kind of advantage will be when builded ./configure --coverage\r\n\r\nofficial hint <i>Build node with code coverage enabled</i> doesn't mean anything to me.\r\n",
        "labels": "doc",
        "id": 44499
    },
    {
        "title": "tls documentation says that checkServerIdentity function should throw an error. It should not.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 6.7.0 - 7.5.0 (at least)\r\n* **Platform**: All? tested on MacOS / Linux\r\n* **Subsystem**: TLS\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe documentation for the `checkServerIdentity` function at https://nodejs.org/api/tls.html#tls_tls_connect_options_callback \r\nstates that the provided function \"should throw an error if verification fails. \" \r\n\r\nHowever, the implementation (https://github.com/nodejs/node/blob/master/lib/_tls_wrap.js#L1083) expects a truthy value _returned_ from the function as the error, and has no try / catch logic to catch an error if thrown, with the result that if the `checkServerIdentity` function throws an error the whole process will likely exit. Either the docs or the implementation should be corrected to reflect the intended behavior.",
        "labels": "doc",
        "id": 44500
    },
    {
        "title": "Incorrect link to style guide inside CONTRIBUTING.md",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nLink to style guide in CONTRIBUTING.md is incorrect.\r\n\r\nIt should be ``doc/STYLE-GUIDE.md``, not ``doc/STYLE_GUIDE.md``\r\n",
        "labels": "doc",
        "id": 44501
    },
    {
        "title": "Usage of common.platformTimeout in tests guide",
        "body": "Hello! In 'writing tests' guide there is recommendation of usage `common.platformTimeout` in `setTimeout`. Today I've asked @Trott in IRC PM about usage of this method in some irrelevant to this issue test:\r\n<details> \r\n  <summary>Chat log (<a href=\"https://gist.github.com/notarseniy/c9971e79f42f59c6389c679619beb017\">gist</a>)</summary>\r\n   <pre><code>notarseniy\r\nThank you for idea for first PR. I've wrote a day ago to #node-dev about one thing that I found: http://logs.libuv.org/node-dev/2017-02-12#14:24:04.509\r\nTrott\r\nNot all callbacks should have `common.mustCall()`.\r\nTrott\r\nSometimes you can not say for certain how many times a callback will be called or even whether it will be called.\r\nnotarseniy\r\numm.. sorry, i misunderstood you :) Where is common.mustCall?\r\nTrott\r\nOh, sorry, you're asking about platformTimeout() and not mustCall().\r\nTrott\r\nLet me try again...\r\nTrott\r\nplatformTimeout() is not always required.\r\nTrott\r\nAnd in fact to the extent it can be avoided, all the better.\r\nTrott\r\nplatformTimeout() is a sign of a problem in the test, really. To the extent we need it, it should be used. But to the extent that we can avoid it, it is better for the tests IMO.\r\nTrott\r\nSo, basically, I wouldn't add it to a test unless you are certain there's  a problem that it helps with.\r\nnotarseniy\r\nwow, okay! probably got it. really good explanation! maybe we should write about this in https://github.com/nodejs/node/blob/master/doc/guides/writing-tests.md?\r\nTrott\r\n(I would love to be able to get rid of platformTimeout() some day, but that would involve fixing all the tests that use it, and a small number of them may not even be fixable.)\r\nTrott\r\nOh, yeah, that needs more detail for sure.</code></pre>\r\n</details>\r\n\r\ntl;dr: `common.platformTimeout` is for specific cases and probably we should avoid using it.\r\n\r\nI think there's need of redefining recommendation on timeouts for accuracy of `common.platformTimeout` usage.\r\n\r\n(sorry for spelling errors, trying to be better :)\r\n\r\n/cc @Trott ",
        "labels": "doc",
        "id": 44502
    },
    {
        "title": "WHATWG URL API is marked as `Experimental`, but is not behind a flag",
        "body": "Previous discussion in https://github.com/nodejs/node/issues/11200#issuecomment-279264599, but this deserves a separate issue.\r\n\r\nPer [the documentation](https://nodejs.org/dist/latest-v7.x/docs/api/documentation.html#documentation_stability_index):\r\n```\r\nStability: 1 - Experimental\r\nThis feature is subject to change, and is gated by a command line flag.\r\nIt may change or be removed in future versions.\r\n```\r\n\r\nThat explicitly states that all `Stability: 1 - Experimental` API in Node.js should be hidden behind a command line flag, but [The WHATWG URL API](https://nodejs.org/dist/latest-v7.x/docs/api/url.html#url_the_whatwg_url_api) (introduced in #7448) is marked as `Experimental` but is available without a command-line flag in v7.x.\r\n\r\nThis means that people might miss the Â«ExperimentalÂ» label (especially given that it's description is contradictory) and `url.URL` could be used in the wild, which limits how we could change things there (making `url.URL` not so experimental-y in fact).\r\n\r\nAlso note that the current `Accepting Modifications`/`Breaking Changes`/`Deprecations` [policy](https://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md#accepting-modifications) doesn't differentiate between `Experimental` and `Stable` APIs, it only cares about the API being public (which `url.URL` certainly is), documented (which it also is), or used in the wild (which it probably also is by now).\r\n\r\n/cc @nodejs/ctc and especially @jasnell, also @sam-github and @gibfahn ",
        "labels": "doc",
        "id": 44503
    },
    {
        "title": "socket encodings don't link to possible encoding values, and describe behaviour which does not exist",
        "body": "The documentation at:\r\n\r\nhttps://nodejs.org/api/stream.html#stream_readable_setencoding_encoding\r\n\r\n...does not describe what all of the supported encodings are (there are more than just 'UTF8' and 'hex'), nor does it link to any further documentation on them. Also, this documentation refers to \"setEncoding(null)\" as the recommended approach for binary streams, which is incorrect and does not work (this defaults to UTF8 encoding). There also appears to be an undocumented or semi-documented 'binary' encoding.\r\n\r\nOn the other hand, the documentation for use of encodings on Buffer objects is comprehensive and informative:\r\n\r\nhttps://nodejs.org/api/buffer.html#buffer_buffers_and_character_encodings\r\n\r\nReported in comment https://github.com/nodejs/node/issues/11316#issuecomment-279428948 by @RickBullotta, I have not verified `setEncoding(null)` not working.\r\n\r\n- Version: all\r\n- Platform: not relevant\r\n- Subsystem: doc, net\r\n",
        "labels": "doc",
        "id": 44504
    },
    {
        "title": "end event is not properly documented in httpClient request documentation",
        "body": "Hi, I'm wondering if there's a reason why the `'end'` event emitted from [http client request](https://nodejs.org/api/http.html#http_class_http_clientrequest) is mentioned, but not documented in the same way as the other events like [abort](https://nodejs.org/api/http.html#http_event_abort)? I'd like to know under which conditions this event fires.\r\n",
        "labels": "doc",
        "id": 44505
    },
    {
        "title": "meta: `ctc-agenda` label is misused according to the Project Governance",
        "body": "After #9072 landed in October, it (strictly speaking) removed the possiblity to bring things up to the CTC agenda without a prior failure though the consensus-seeking process.\r\n\r\nBefore:\r\n> Any community member or contributor can ask that something be added to member or contributor can ask that something be reviewed the next meeting's agenda by logging a GitHub issue. Any Collaborator, CTC member, or the moderator can add the item to the agenda by adding issue to the CTC's attention by applying the the ***ctc-agenda*** tag to the issue.\r\n\r\nAfter:\r\n> Any community member or contributor can ask that something be reviewed by the CTC by logging a GitHub issue. Any Collaborator, CTC member, or the meeting chair can bring the issue to the CTC's attention by applying the `ctc-review` label. If consensus-seeking among CTC members fails for a particular issue, it may be added to the CTC meeting agenda by adding the `ctc-agenda` label.\r\n\r\nThis (strictly speaking) blocks mentioning some issues on the `ctc-agenda` for other reasons, like making sure that more CTC members are aware of some change, like I tried to do in https://github.com/nodejs/node/pull/11304#issuecomment-279226347 (I had to remove the label), or like bringing more attention to the issue and providing some information at the meeting to speed up the `ctc-review` process.\r\n\r\nMore examples of issues/prs that should not have received the `ctc-agenda` label (at least at the time they were labeled) per the [Project Governance](https://github.com/nodejs/node/blob/master/GOVERNANCE.md): #10599 #10155 #10187 #10116 #10792 #10505 (hover to get a description). There may be more.\r\n\r\n_Yes, I'm being boring, but I think that such written rules might stop other members from bringing things up to the `ctc-agenda` and that we should follow our own rules._\r\n\r\nThe easy way would be to patch the [GOVERNANCE.md](https://github.com/nodejs/node/blob/master/GOVERNANCE.md) document, allowing bringing up issues to the CTC meeting agenda without a previous failure of a consensus-seeking process. If that is not something we want, we should better follow the process and escalate to the agenda only the issues that failed the conensus-seeking process, but I believe that will slow things down at some places without significant benefits.\r\n\r\n/cc @nodejs/ctc ",
        "labels": "doc",
        "id": 44506
    },
    {
        "title": "Documentation: Unclear if Buffer buf[i] is bounds-checked",
        "body": "From the [`buf[i]`](https://nodejs.org/api/buffer.html#buffer_buf_index) documentation for `Buffer`, it's unclear whether the following code produces undefined behavior due to out-of-bounds access or does nothing:\r\n\r\n```js\r\nnew Buffer('')[1000] = 42\r\n```\r\n\r\nI think this should be documented.\r\n\r\n(I *assume* it's bounds-checked since `console.log(new Buffer('')[1000])` prints `undefined` rather than `0`, but I haven't checked the source.)",
        "labels": "doc",
        "id": 44507
    },
    {
        "title": "Update CONTRIBUTING.md to clarify single-test running ",
        "body": "In `CONTRIBUTING.md`:\r\n\r\n<pre>\r\nYou can run tests directly with node:\r\n\r\n```text\r\n$ ./node ./test/parallel/test-stream2-transform.js\r\n```\r\n</pre>\r\n\r\nThis bit is a little problematic and can trip up new folks.\r\n\r\n* You can run tests in some directories (such as `parallel` and `sequential`) but not others (such as `message`).\r\n* If the test has a `--FLAGS` comment, then that needs to be taken into account on the command line or else the test won't work.\r\n\r\nWe could clarify all this, or we could just remove that bit of text entirely and instruct people to always use `test.py`. That second option seems like the better one to me. Discuss.\r\n\r\n@nodejs/testing",
        "labels": "doc",
        "id": 44508
    },
    {
        "title": "Document fs.createReadStream and fs.createWriteStream close and destroy methods",
        "body": "* **Version**: all\r\n* **Platform**: all\r\n* **Subsystem**: doc, fs, stream\r\n\r\nAs titled, those method are used in real-world code, so we should probably document them.\r\n\r\nRelated https://github.com/nodejs/node/issues/2950.\r\n\r\ncc @evanlucas",
        "labels": "doc",
        "id": 44509
    },
    {
        "title": "Changing Definition of \"Locked\" for Stability Index in API Docs",
        "body": "As discussed in last weeks @nodejs/ctc meeting\r\n\r\nCurrently our api docs have a [stability index](https://github.com/nodejs/node/blob/master/doc/api/documentation.md#stability-index) with fairly conservative definition of `Locked`\r\n\r\n```\r\nStability: 3 - Locked\r\nOnly bug fixes, security fixes, and performance improvements will be accepted.\r\nPlease do not suggest API changes in this area; they will be refused.\r\n```\r\n\r\nThis has been fairly useful when discussing changes to APIs that are potentially breaking, such as any change to the module system. With changes coming to the ecma262 standard on a yearly basis now, we find ourselves in a slightly different situation then when this was originally drafted. As the language changes we may be required to change locked APIs, such as assert or module, in order to accommodate the changes to the language.\r\n\r\nIt can be argued that this is already covered by `bug fixes`, but that is somewhat ambiguous, and it would be better to be explicit about it\r\n\r\nA suggested alternative text\r\n\r\n```\r\nStability: 3 - Locked\r\nOnly bug fixes, security fixes, and performance improvements will be accepted.\r\nPlease do not suggest API changes in this area; they will be refused. Locked APIs\r\nare subject to change to support new language features that are added to the ecma262\r\nspecification.\r\n```\r\n\r\nThoughts?",
        "labels": "doc",
        "id": 44510
    },
    {
        "title": "Move benchmark/README.md to doc/guide",
        "body": "The current [`benchmark/README.md`](https://github.com/nodejs/node/blob/master/benchmark/README.md) is in fact a guide on how to run and write benchmarks, I suggest we move this to [doc/guides](https://github.com/nodejs/node/tree/master/doc/guides) (where [`writing-tests.md`](https://github.com/nodejs/node/blob/master/doc/guides/writing-tests.md) is) and create another README.md that explains the directory layout/common API (like what [`test/README.md`](https://github.com/nodejs/node/blob/master/test/README.md) does).\r\n\r\ncc @nodejs/collaborators ",
        "labels": "doc",
        "id": 44511
    },
    {
        "title": "buffer: Invalid bytes length calculation",
        "body": "Node Version: v7.5.0\r\nPlatform: Windows 10 x64\r\n\r\nIt seems that `Buffer.byteLength()` method and `buffer.byteLength` returns different values for `base64` encoding. Maybe for some others too.\r\n\r\nHere is TypeScript class that works with encodings:\r\n\r\n```typescript\r\n\r\nexport type EncodingName = 'utf8' | 'utf16le' | 'ascii' | 'latin1' | 'ucs2' | 'hex' | 'base64' | 'binary';\r\n\r\n\r\nexport default class Encoding {\r\n    public static UTF8: Encoding = new Encoding('utf8');\r\n    public static UTF16LE: Encoding = new Encoding('utf16le');\r\n    public static ASCII: Encoding = new Encoding('ascii');\r\n    public static LATIN1: Encoding = new Encoding('latin1');\r\n    public static UCS2: Encoding = new Encoding('ucs2');\r\n    public static HEX: Encoding = new Encoding('hex');\r\n    public static BASE64: Encoding = new Encoding('base64');\r\n    public static BINARY: Encoding = new Encoding('binary');\r\n\r\n\r\n    public static convert(originalString: string, originalEncoding: Encoding, targetEncoding: Encoding): string {\r\n        return originalEncoding.getBytes(originalString).toString(targetEncoding.encodingName);\r\n    }\r\n\r\n\r\n    private _encodingName: EncodingName;\r\n\r\n\r\n    get encodingName(): EncodingName {\r\n        return this._encodingName;\r\n    }\r\n\r\n\r\n    constructor(encodingName: EncodingName = 'utf8') {\r\n        this._encodingName = encodingName;\r\n    }\r\n\r\n\r\n    public getBytesCount(text: string): number {\r\n        return Buffer.byteLength(text, this.encodingName);\r\n    }\r\n\r\n\r\n    public getBytes(text: string): Buffer {\r\n        return Buffer.from(text, this.encodingName);\r\n    }\r\n}\r\n\r\nlet source: string = 'abc123 \\u03C0';               // abc123 Ï€\r\nlet base64String: string = Encoding.convert(source, Encoding.UTF8, Encoding.BASE64);\r\nlet originalString: string = Encoding.convert(base64String, Encoding.BASE64, Encoding.UTF8);\r\n\r\nconsole.log(\r\n    Encoding.UTF8.getBytes(source).byteLength,      // 9\r\n    Encoding.UTF8.getBytesCount(source)             // 9\r\n);\r\n\r\nconsole.log(\r\n    Encoding.BASE64.getBytes(source).byteLength,    // 5\r\n    Encoding.BASE64.getBytesCount(source)           // 6  - Why different length?\r\n);\r\n\r\nconsole.log(originalString);                        // abc123 Ï€\r\nconsole.log(base64String);                          // YWJjMTIzIM+A\r\n\r\n```",
        "labels": "doc",
        "id": 44512
    },
    {
        "title": "Certain docs have very little information provided per API",
        "body": "Firstly this is not a rant. I just want to know if its a community decision to have docs this way or there is opportunity for me to contribute to make documentation better.\r\n\r\nI am a new to nodejs and i find the nodejs.org/.../docs are very less informative compared to any other big OSS platforms.\r\n\r\nfor example [fs.close api doc](https://nodejs.org/dist/latest-v6.x/docs/api/fs.html#fs_fs_close_fd_callback) is very vague for me.\r\n- Its just listing the arguments `fd` and `callback`. \r\n- It would be great to know if the callback has arguments and their details.\r\n- I would want to have an example associated with it.\r\n\r\nCan you share thoughts on this perspective, is there any ongoing effort in this area?",
        "labels": "doc",
        "id": 44513
    },
    {
        "title": "fs.readFileSync returns corrupt ArrayBuffer (fs.readFile works as expected)",
        "body": "* **Version**: 7.3.0\r\n* **Platform**: Darwin brunchfast.local 16.3.0 Darwin Kernel Version 16.3.0: Thu Nov 17 20:23:58 PST 2016; root:xnu-3789.31.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: fs\r\n\r\n```js\r\nvar fs = require('fs');\r\n\r\nvar myFile = require('os').homedir() + '/.bash_history';\r\n\r\nvar ab = fs.readFileSync(myFile, null).buffer;\r\n\r\n// byteLength is always 8192, no matter which file\r\n// the data is corrupt (unsafe memory read?)\r\nconsole.log(ab);\r\n\r\n// bad data\r\nconsole.log(new Uint8Array(ab));\r\n```\r\n\r\nRun the same code with the async version and all is well:\r\n\r\n```js\r\nvar fs = require('fs');\r\n\r\nvar myFile = require('os').homedir() + '/.bash_history';\r\n\r\nfs.readFile(myFile, null, function (err, nb) {\r\n\r\n  var ab = nb.buffer;\r\n  console.log(ab); // all is well\r\n  console.log(new Uint8Array(ab)); // all is well\r\n\r\n});\r\n```",
        "labels": "doc",
        "id": 44514
    },
    {
        "title": "Include $DOCS_ANALYTICS when building docs",
        "body": "**Subsystem:** docs\r\n\r\nI'm following up https://github.com/nodejs/node/pull/6601 which enables Google Analytics tracking on docs pages.\r\n\r\nFor the tracking code to be included, `$DOCS_ANALYTICS` needs to be set when running `make doc`. I've been having trouble finding who or where docs are generated when a new release is made, so I don't really know who to ping.\r\n\r\nFound the Node.js release guide wiki page which has a section named [Publish API docs](https://github.com/nodejs/node/wiki/Node.js-release-guide#publish-api-docs), but it seems outdated the `website-upload` make target doesn't exist anymore.",
        "labels": "doc",
        "id": 44515
    },
    {
        "title": "Documentation: conflicting \"Added in\" for Buffer methods",
        "body": "There as some new Buffer methods introduced to replace the now deprecated `new Buffer()` invocation. But there is conflicting information in the docs as to when these became available.\r\n\r\nFor example, according to v4 API docs:\r\n```\r\nClass Method: Buffer.allocUnsafe(size)\r\nAdded in: v4.5.0\r\n```\r\n\r\nBut according to latest API docs:\r\n```\r\nClass Method: Buffer.allocUnsafe(size)\r\nAdded in: v5.10.0\r\n```\r\n\r\nWhy the difference and which one is right? (Need to know to set the minimum supported Node version for my app.)",
        "labels": "doc",
        "id": 44516
    },
    {
        "title": "Reading a directory",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 7.4.0\r\n* **Subsystem**: fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIf you try to read a directory, the behavior will be platform specific:\r\n~~~js\r\n// linux/windows/os x\r\nfs.readFileSync(\"node_modules\");\r\n// -> Error: EISDIR: illegal operation on a directory, read\r\n\r\n// freebsd\r\nfs.readFileSync(\"node_modules\");\r\n// -> <Buffer 03 00 00 ... >\r\n~~~\r\nIs it ok? I expected the same result on all platforms",
        "labels": "doc",
        "id": 44517
    },
    {
        "title": "All links in doc/api/_toc.md point to .html instead of .md.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis issue is not related to node itself rather its documentation.\r\n\r\nBasically on the page: [/doc/api/_toc.md](https://github.com/nodejs/node/blob/master/doc/api/_toc.md)\r\n\r\nall if the links are broken due to pointing to wrong file types.\r\n",
        "labels": "doc",
        "id": 44518
    },
    {
        "title": "Conflicting \"Added in\" versions",
        "body": "I was trying to find out when `Buffer.from(array)` was added and saw [5.10 mentioned in the documentation](https://nodejs.org/api/buffer.html#buffer_class_method_buffer_from_array).\r\n\r\nSomeone later corrected me and said that it was available earlier and [earlier documentation mentions 4.5](https://nodejs.org/dist/latest-v4.x/docs/api/buffer.html#buffer_class_method_buffer_from_array).\r\n\r\nSo, something seems to be wrong here.",
        "labels": "doc",
        "id": 44519
    },
    {
        "title": "doc: http response.getHeader() documentation partially incorrect",
        "body": "* **Version**: v4.x-master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nThe `http` documentation incorrectly states that [`response.getHeader()`](https://nodejs.org/docs/latest/api/http.html#http_response_getheader_name) \"can only be called before headers get implicitly flushed,\" which is not true (AFAICT) and we explicitly even [test for the ability to safely call `response.getHeader()` after the headers/response is written](https://github.com/nodejs/node/blob/3d2aef3979cf7ac986908dbb9879216caec4a3ff/test/parallel/test-http-header-read.js). I think this sentence can be removed entirely from the `http` documentation.",
        "labels": "doc",
        "id": 44520
    },
    {
        "title": "Documentation for HttpClient \"abort\" and \"aborted\" events mixed up.",
        "body": "This issue is actually a problem with the documentation rather than the Node software itself, so I hope this is the right place to report it.\r\n\r\nIf you look at https://nodejs.org/docs/latest/api/http.html#http_event_abort you can read the following:\r\n\r\n> Event: 'abort'#\r\n> \r\n> Added in: v1.4.1\r\n> Emitted when the request has been aborted by the client. This event is only emitted on the first call to abort().\r\n> \r\n> Event: 'aborted'#\r\n> \r\n> Added in: v0.3.8\r\n> Emitted when the request has been aborted by the server and the network socket has closed.\r\n\r\nHowever, when I tested this with Node v6.9.1, a client abort actually resulted in the \"aborted\" event rather than the \"abort\" event. But I do believe it's the documentation that's actually at fault rather than the software. Note how the documentation for \"abort\" says, \"This event is only emitted on the first call to abort().\" But this only makes sense if it's describing server abortion, because that's the only case where the developer calls `abort()`. Also semantically I do think it makes sense if the \"abort\" event corresponds to the `abort()` call (both server-side abortion) and the \"aborted\" event corresponds to when an external party (the client) has aborted the request.\r\n\r\nSo to sum up, I think the documentation is mixed up :)",
        "labels": "doc",
        "id": 44521
    },
    {
        "title": "Unclear docs on copying/sharing memory for Buffer.from(arrayBuffer)",
        "body": "* **Version**: v7.4.0\r\n* **Subsystem**: docs (buffer)\r\n\r\nThe docs for [`Buffer.from(arrayBuffer)`](https://nodejs.org/api/buffer.html#buffer_class_method_buffer_from_arraybuffer_byteoffset_length) use the word copy/copying:\r\n\r\n> * byteOffset <Integer> Where to start **copying** from arrayBuffer. Default: 0\r\n> * length <Integer> How many bytes to **copy** from arrayBuffer. Default: arrayBuffer.length - byteOffset\r\n\r\nBut as far as I can tell, it always references a subarray and never copies.\r\n\r\nThe line below it:\r\n\r\n> When passed a reference to the .buffer property of a TypedArray instance, the newly created Buffer will share the same allocated memory as the TypedArray.\r\n\r\nis also confusing -- I think that's meant as an example to emphasize the point that it's shared memory, but to me it sounds like there's a situation when it would copy and not share (e.g. `Buffer.from(new ArrayBuffer(8))`.\r\n\r\nTrivial change but wanted to make sure my understanding was correct before submitting a PR. Something like: \"byteOffset - element to begin at\", \"length - number of elements to include\" and adding \"For example\" to the \"when passed a reference...\" bit.",
        "labels": "doc",
        "id": 44522
    },
    {
        "title": "doc: guide on backpressure",
        "body": "There is no guide on streams backpressure, however this is one of the most advanced topics of Node.\r\nI am very happy on reviewing the content.\r\n\r\nThis emerged from the discussion on https://github.com/nodejs/node/pull/10631\r\n\r\ncc @sam-github @nodejs/streams @nodejs/documentation ",
        "labels": "doc",
        "id": 44523
    },
    {
        "title": "node js api document should link to LTS release from each page",
        "body": "The API documentation for the LTS stuff is a little hidden on the site -- you have to either know the LTS doc URL or always enter it from the front door, whereas nodejs.org/api is quite easy to remember. \r\n\r\nIt would be really nice if the documentation for the \"live\" release had a link on that page to the relevant documentation for the LTS version (if it exists).\r\n\r\nThe postgres documentation is actually an excellent example of this:\r\n![image](https://cloud.githubusercontent.com/assets/193412/21816128/d5dfaedc-d713-11e6-9109-ac19fe766304.png)\r\n\r\nEach page has a link to various other supported (and even non-supported!) versions which makes it very easy to hop to the correct version that you're using.\r\n\r\n",
        "labels": "doc",
        "id": 44524
    },
    {
        "title": "What is the Current branch considered?",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis is a question in regards to understanding the `README.md` file. It states:\r\n\r\n> Nightly: Versions of code in this repository on the current Current branch, automatically built every 24-hours where changes exist. Use with caution.\r\n\r\nWhat exactly is the \"Current\" branch? That does not make it clear to me what branch this is. Don't know if this is me being new, but thought that this is not easy to decipher.",
        "labels": "doc",
        "id": 44525
    },
    {
        "title": "doc: missing negation in streams doc",
        "body": "\r\nfrom https://nodejs.org/dist/latest-v6.x/docs/api/stream.html#stream_errors_while_reading\r\n\r\n\r\nThe doc for `Errors While Reading` says:\r\n\r\n> Throwing an Error from within readable._read() can result in expected and inconsistent behavior depending on whether the stream is operating in flowing or paused mode. Using the 'error' event ensures consistent and predictable handling of errors.\r\n\r\nand I believe it should be `...can result in UNexpected and inconsistent behavior...`",
        "labels": "doc",
        "id": 44526
    },
    {
        "title": "errors and contradictions in docs for process.stdout/stderr",
        "body": "This situation keeps changing around, but my understanding ATM is that process.stdout and process.stderr (fd 1 and 2) are set blocking when they are files, and on UNIX (OS X/Linux) also set blocking when they are TTYs. I'm not sure what is done if they are pipes or any of the other possible UNIX devices.\r\n\r\nI think the standard way to describe this in node documentaion is that an API that \"can block\" is synchronous (it runs to completion, whether the OS blocks or not will depend on buffering, etc, but its the run-to-completion that is important), and to describe \"non-blocking\" APIs the word \"asynchronous\" is used.\r\n\r\nGiven that understanding, the docs have these problems:\r\n\r\nIn https://github.com/nodejs/node/blob/master/doc/api/process.md#processstderr\r\n\r\n> Writes can block when output is redirected to a file.\r\n\r\nShould say that stdout/err is synchronous when connected to a file. I believe that use of the word \"can\" is trying to express that blocking won't occur unless the O/S chooses to block, but its not very helpful. It could also mean \"node reserves the right to set the fd to blocking mode, or not to, so depend on nothing\", but I don't think it means that.\r\n\r\n> Note that disks are fast and operating systems normally employ write-back caching so this is very uncommon.\r\n\r\nProbably meant to be a note about previous statement, but because of list structure, reads as a note on the `i.` and `ii.` bullet points that follow.\r\n\r\nIf we wanted to, we could say \"If data is written faster than the OS I/O systems can buffer it, blocking may occur, but that blocking is unusual even when process.stderr is synchronous due to modern OS I/O buffering strategies.\".\r\n\r\n> Writes on UNIX will block by default if output is going to a TTY (a terminal).\r\n\r\nShould say its sync. Whether it blocks or not depends on whether TTY buffers fill up. The file case used the weasel-word \"can\", but here we use the emphatic `WILL`, which is a contradictory, and its not true that writes to a TTY will block, even if the fd is set to blocking.\r\n\r\n> Windows functionality differs. Writes block except when output is going to a TTY.\r\n\r\nHere its partially restating the \"can block on files\" from the earlier paragraph, except that the \"can\" is omitted. So, its a contradictory restating of previous docs. Should just say TTY writes are async on windows for historical reasons.\r\n\r\nNowhere in here does it say what happens when stdout/stderr is a pipe! An important case. Is it sync like files and TTYs? Async like TTY on Windows? Depends on system? I don't know, and the docs don't say.\r\n\r\n> To check if Node.js is being run in a TTY context, read the isTTY property on process.stderr, process.stdout, or process.stdin:\r\n\r\nHas a typo, a trailing `:`.\r\n\r\n`isTTY` does not have to have same value for stdin/out/err. This sentence should say \"stderr is attached to a TTY if the `isTTY` property is set.\", and should say nothing about stdin/stdout, leave that to their docs.\r\n\r\nIn https://github.com/nodejs/node/blob/master/doc/api/process.md#processstdout\r\n\r\nCopy and paste of the stderr docs, all comments apply to it.\r\n\r\nIn https://github.com/nodejs/node/blob/master/doc/api/process.md#tty-terminals-and-processstdout\r\n\r\n> TTY Terminals and process.stdout\r\n\r\nWrongly named, should be \"TTY Terminals and process.stdout and process.stderr\" or \"TTY Terminals and process output\".\r\n\r\n> The process.stderr and process.stdout streams are blocking when outputting to TTYs (terminals) on OS X \r\n\r\nLegally speaking, not wrong, since OS X is considered UNIX, and the above is true for UNIX, but is very misleading, since it implies they are not blocking for Windows and Linux (which is not true).\r\n\r\nShould say stderr/out are synchronous when writing to TTYs on UNIX, to agree with previous docs.\r\n\r\n> as a workaround for the operating system's small, 1kb buffer size.\r\n\r\nNot my understanding, don't know where that crept in. Its sync because users expect `console.log('hello'); process.exit(0)` to not exit until the I/O has been written, so the I/O has to be sync, not async. :-(\r\n\r\nhttps://github.com/nodejs/node/blob/master/doc/api/console.md#asynchronous-vs-synchronous-consoles\r\n\r\n> The console functions are usually asynchronous unless the destination is a file.\r\n\r\nThat directly contradicts the docs for process.stdout and process.stderr, unless by usually \"on windows\" is meant, and \"on OS X and Linux\" is considered \"unusual\", but I think its just a misstatement.\r\n\r\n> Additionally, console functions are blocking when outputting to TTYs (terminals) on OS X as a workaround for the OS's very small, 1kb buffer size. This is to prevent interleaving between stdout and stderr.\r\n\r\nCopied verbatim from https://github.com/nodejs/node/blob/master/doc/api/process.md#tty-terminals-and-processstdout, including with the problems.\r\n\r\nEntire section should be replaced by a web link to https://github.com/nodejs/node/blob/master/doc/api/process.md#tty-terminals-and-processstdout\r\n\r\n\r\nI'll PR improvements to this text after my understanding of how it currently works is confirmed.\r\n\r\n",
        "labels": "doc",
        "id": 44527
    },
    {
        "title": "Fallowing \"How to write a test for the Node.js Project\" guide",
        "body": "We have a good guide for [How to write test](https://github.com/nodejs/node/blob/master/doc/guides/writing-tests.md), but we don't follow the all the guidelines when writing or reviewing tests.\r\n\r\nSince a PR with tests is something common for newcomers I think we should review and make official the guide and add it to a more intuitive place, like the website.\r\n\r\ncc: @nodejs/collaborators ",
        "labels": "doc",
        "id": 44528
    },
    {
        "title": "References to an \"KeepAlive\" flag in the http.Agent constructor, when it is actually \"keepAlive\"",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nIn the version 7.3.0 documentation, in the page on http, in the first few paragraphs of the http.Agent section it makes references to a `KeepAlive` flag in the `http.Agent` constructor which you can specify as **true** if you'd like to keep unused sockets pooled.  Admittedly this caused me a decent amount of confusion because of the case mismatch :)",
        "labels": "doc",
        "id": 44529
    },
    {
        "title": "tls: secureConnect event will not be emitted if TLSSocket is created via constructor instead of tls.connect",
        "body": "* **Version**: 7.3\r\n* **Platform**: Any\r\n* **Subsystem**: Any\r\n\r\nIn current TLS doc, secureConnect is documented as an event of TLSSocket. However, the event will only be [emitted](https://github.com/nodejs/node/blob/db50307d5c555da1d81c5b5d736853ce8474c6d1/lib/_tls_wrap.js#L1106) if the socket is created via tls.connect. Basically there is no sensible event to listen on for the 'connect' event if the socket is created directly via new tls.TLSSocket.\r\n",
        "labels": "doc",
        "id": 44530
    },
    {
        "title": "Undocumented properties in object returned by child_process.spawnSync()",
        "body": "* **Version**: 7.3.0\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: doc, child_process\r\n\r\nThe document [mentions](https://nodejs.org/api/child_process.html#child_process_child_process_spawnsync_command_args_options) 6 regular properties in the object returned by `child_process.spawnSync()`. It seems there are 4 undocumented ones in addition.\r\n```js\r\nconsole.log(\r\n  Object.keys(require('child_process').spawnSync('node', ['-p', '1']))\r\n);\r\n```\r\n```\r\n[\r\n  'output',   // documented\r\n  'pid',      // documented\r\n  'signal',   // documented\r\n  'status',   // documented\r\n  'stderr',   // documented\r\n  'stdout',   // documented\r\n\r\n  'file',     // not documented, = first argument\r\n  'args',     // not documented, = [first argument, flattened arguments array]\r\n  'envPairs', // not documented, = [system environment variables]\r\n  'options',  // not documented, see below\r\n]\r\n```\r\nSomehow, `options` object contains just these undocumented properties duplicated + 1:\r\n```js\r\nconsole.log(\r\n  Object.keys(require('child_process').spawnSync('node', ['-p', '1']).options)\r\n);\r\n```\r\n```\r\n[\r\n  'file',     // = returnedObject.file\r\n  'args',     // = returnedObject.args\r\n  'envPairs', // = returnedObject.envPairs\r\n  'stdio'     // Child's stdio configuration\r\n]\r\n```\r\nShould these properties be documented? Are they regular for each OS? Or is this an unintended leak?",
        "labels": "doc",
        "id": 44531
    },
    {
        "title": "VM: VM is much slower when `timeout` was specified",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nNode.js v6.7.0 / Node.js 4.4.2\r\n* **Platform**:\r\nUbuntu 14.04 LTS x64 (v6.7.0) / macOS Sierra (v4.4.2)\r\n* **Subsystem**:\r\nVM\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n<img width=\"1242\" alt=\"2016-12-26 4 23 20\" src=\"https://cloud.githubusercontent.com/assets/2101743/21472575/6d8f25a6-cb24-11e6-9b9a-1cdba7a08d6b.png\">\r\n\r\n\r\nI just found there's unexpected behavior on `timeout` option of `vm.runInContext`.\r\n\r\nWhen `timeout` option was specified, Script execution on VM is much slower then `timeout` options wasn't specified.\r\n\r\nThis is two of example snippets to reproduce that problem:\r\n\r\n##### vm-normal.js\r\n```js\r\n'use strict';\r\n\r\nconst\r\n  vm = require('vm'),\r\n  sandbox = {\r\n    current: -1\r\n  };\r\n\r\nconsole.time('vm-normal');\r\n\r\nvm.createContext(sandbox);\r\n\r\nfor (let i = 0 ; i < 100000 ; i++) {\r\n  vm.runInContext(`current = ${i};`, sandbox, {\r\n    displayErrors: false\r\n  });\r\n}\r\n\r\nconsole.timeEnd('vm-normal');\r\n```\r\n\r\n##### vm-with-timeout.js\r\n```js\r\n'use strict';\r\n\r\nconst\r\n  vm = require('vm'),\r\n  sandbox = {\r\n    current: -1\r\n  };\r\n\r\nconsole.time('vm-with-timeout');\r\n\r\nvm.createContext(sandbox);\r\n\r\nfor (let i = 0 ; i < 100000 ; i++) {\r\n  vm.runInContext(`current = ${i};`, sandbox, {\r\n    displayErrors: false,\r\n    timeout: 1000\r\n  });\r\n}\r\n\r\nconsole.timeEnd('vm-with-timeout');\r\n```\r\n\r\n\r\nI think maybe that's not a bug (timer for timeout is expansive?), but that's unexpected behavior. It would be nice if that limitation should be documented on VM API documentation.\r\n",
        "labels": "doc",
        "id": 44532
    },
    {
        "title": "getHeader() returns undefined after using writeHead() in a certain circumstance",
        "body": "* **Version**: 6.9.1\r\n* **Platform**: Linux 4.4.0-21-generic #37-Ubuntu SMP x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: http\r\n\r\nIn short, calling `writeHead()` with a `ServerResponse` object which has no headers already set causes `getHeader()` to return `undefined` even if the header was set in the `writeHead()` function call. I am unfamiliar with the project, so I'm unsure if this is defined behavior or not.\r\n\r\n```js\r\n//Case 1: using setHeader, getHeader works as intended\r\nres.setHeader(\"Location\", \"index.html\");\r\nres.getHeader(\"Location\"); //index.html\r\n\r\n//Case 2: using setHeader then writeHead, getHeader works as intended\r\nres.setHeader(\"Set-Cookie\", \"hello=world\");\r\nres.writeHead(303, {Location: \"index.html\"});\r\nres.getHeader(\"Location\"); //index.html\r\n\r\n//Case 3: using writeHead when res._headers is null, getHeader does not work as intended\r\nres.writeHead(303, {Location: \"index.html\"});\r\nres.getHeader(\"Location\"); //undefined\r\n```",
        "labels": "doc",
        "id": 44533
    },
    {
        "title": "Clarify dont-land-on labels",
        "body": "The [COLLABORATOR_GUIDE](https://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md#how-can-i-help) has a section on backporting tags, but it doesn't include anything about the `dont-land-on` labels.\r\n\r\nIf something has `dont-land-on-v7.x` does that mean it doesn't apply cleanly and needs a backport PR, or that it shouldn't be backported? I'd like to help the release team out by adding these labels, but I'm not entirely clear which ones to add.\r\n\r\nAFAIK, PRs have the following states for each release branch (using v6.x as an example):\r\n 1. Should be considered for landing on v6.x: `lts-watch-v6.x`\r\n 2. Should be considered for landing on v6.x, but doesn't apply cleanly (needs backport PR): ???\r\n 3. Shouldn't be considered for landing on v6.x: **EDIT:** `dont-land-on-v6.x`\r\n 4. Will be landed on v6.x: `lts-watch-v6.x` and `land-on-v6.x`\r\n 5. Has been landed on v6.x-staging: `land-on-v6.x`\r\n 6. Has been landed on v6.x (released): ``\r\n\r\nSo `1.`, `2.`, and `3.` can be applied by a collaborator, but `4.`, `5.`, and `6.` shouldn't (they're used by the release team for triaging backports). Is this correct? What labels should a backport PR have?\r\n\r\nRelated: https://github.com/nodejs/node/pull/10058#issuecomment-267666867 and https://github.com/nodejs/node/pull/10294#issuecomment-267661411\r\n\r\ncc/ @nodejs/release \r\n\r\n#### COLLABORATOR_GUIDE\r\n\r\n> When you send your pull request, consider including information about\r\n> whether your change is breaking. If you think your patch can be backported,\r\n> please feel free to include that information in the PR thread.\r\n> \r\n> Several LTS related issue and PR labels have been provided:\r\n> \r\n> * `lts-watch-v4.x` - tells the LTS WG that the issue/PR needs to be considered\r\n>   for landing in the `v4.x-staging` branch.\r\n> * `lts-watch-v0.10` - tells the LTS WG that the issue/PR needs to be considered\r\n>   for landing in the `v0.10-staging` branch.\r\n> * `lts-watch-v0.12` - tells the LTS WG that the issue/PR needs to be considered\r\n>   for landing in the `v0.12-staging` branch.\r\n> * `land-on-v4.x` - tells the release team that the commit should be landed\r\n>   in a future v4.x release\r\n> * `land-on-v0.10` - tells the release team that the commit should be landed\r\n>   in a future v0.10 release\r\n> * `land-on-v0.12` - tells the release team that the commit should be landed\r\n>   in a future v0.12 release\r\n> \r\n> Any collaborator can attach these labels to any PR/issue. As commits are\r\n> landed into the staging branches, the `lts-watch-` label will be removed.\r\n> Likewise, as commits are landed in a LTS release, the `land-on-` label will\r\n> be removed.\r\n> \r\n> Collaborators are encouraged to help the LTS WG by attaching the appropriate\r\n> `lts-watch-` label to any PR that may impact an LTS release.\r\n> \r\n",
        "labels": "doc",
        "id": 44534
    },
    {
        "title": "crypto.pbkdf2Sync can't handle non ASCII character in Node 6.9.2",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.0.0, v6.9.2, v7.2.1\r\n* **Platform**: Mac OS X 10.11.6 and Ubuntu 16.04\r\n* **Subsystem**: crypto.pbkdf2Sync\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nAfter upgrading our servers from Node 4 to Node 6. I was not able to login with my password anymore, while my colleagues had no problem logging in. After some research I found that since my password contained the letter 'Ã¶' the crypto.pbkdf2Sync failed to create the same hash in Node 6 as in Node 4. So it is broken for non ASCII characters like 'Ã¥Ã¤Ã¶'.\r\n\r\nI made the following test that shows that the error started in version 6.0.0 of node.\r\n\r\n```javascript\r\n\r\nit('should return same hash in node 6 and 4 for non ASCII characters', function () {\r\n    var crypto = require('crypto');\r\n\r\n    var iterations = 1000,\r\n        keylen = 64,\r\n        salt = '8320c789c1869574c159c9758db370855a00cf987ebefaa240649139e53f8066',\r\n        password;\r\n\r\n    //\r\n    // ASCII Characters\r\n    //\r\n    password = 'abc';\r\n    var passwordHash1 = crypto.pbkdf2Sync(password, salt, iterations, keylen, 'sha1').toString('hex');\r\n    console.log('hash:', passwordHash1);\r\n\r\n    // GOOD\r\n    // v4.7.0\r\n    // hash: eb29636dc841231b3300a66da04c1e46007a63e5933783daca0e96ed6e4a98431a7c8d59b29146edca0aa8d40a8381e0de72a9a857993a3283494c93db33967b\r\n    // v6.0.0\r\n    // hash: eb29636dc841231b3300a66da04c1e46007a63e5933783daca0e96ed6e4a98431a7c8d59b29146edca0aa8d40a8381e0de72a9a857993a3283494c93db33967b\r\n    // v6.9.2\r\n    // hash: eb29636dc841231b3300a66da04c1e46007a63e5933783daca0e96ed6e4a98431a7c8d59b29146edca0aa8d40a8381e0de72a9a857993a3283494c93db33967b\r\n\r\n    expect(passwordHash1).toBe('eb29636dc841231b3300a66da04c1e46007a63e5933783daca0e96ed6e4a98431a7c8d59b29146edca0aa8d40a8381e0de72a9a857993a3283494c93db33967b');\r\n\r\n    //\r\n    // Non ASCII Characters\r\n    //\r\n    password = 'Ã¥Ã¤Ã¶';\r\n    var passwordHash2 = crypto.pbkdf2Sync(password, salt, iterations, keylen, 'sha1').toString('hex');\r\n\r\n    console.log('hash:', passwordHash2);\r\n    // GOOD\r\n    // v4.7.0\r\n    // hash: d29871ab324d9bbcd868185d74d205253acc45620585a44cd3e95cd53769fb3cff88f4df3dc971adf32acd25b9ec5dde3e43c7ef50d59865db6458897d9d22ee\r\n    // v5.12.0\r\n    // hash: d29871ab324d9bbcd868185d74d205253acc45620585a44cd3e95cd53769fb3cff88f4df3dc971adf32acd25b9ec5dde3e43c7ef50d59865db6458897d9d22ee\r\n\r\n    // BAD\r\n    // v6.0.0\r\n    // hash: fdb431352dd40e3ffe8e9e6fb725cd150d85ea3e41bb34fb3b3b6355324660a97cd63251628c30219ad9707dcabc316c22e4dda7a7b44ed61f43a252bee5595b\r\n    // v6.9.2\r\n    // hash: fdb431352dd40e3ffe8e9e6fb725cd150d85ea3e41bb34fb3b3b6355324660a97cd63251628c30219ad9707dcabc316c22e4dda7a7b44ed61f43a252bee5595b\r\n    // v7.2.1\r\n    // hash: fdb431352dd40e3ffe8e9e6fb725cd150d85ea3e41bb34fb3b3b6355324660a97cd63251628c30219ad9707dcabc316c22e4dda7a7b44ed61f43a252bee5595b\r\n\r\n    expect(passwordHash2).toBe('d29871ab324d9bbcd868185d74d205253acc45620585a44cd3e95cd53769fb3cff88f4df3dc971adf32acd25b9ec5dde3e43c7ef50d59865db6458897d9d22ee');\r\n});\r\n\r\n```",
        "labels": "doc",
        "id": 44535
    },
    {
        "title": "Debug call illustration in the cluster doc does not match with output in Windows",
        "body": "* **Version**: Node.js 7.2.1\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: cluster, doc\r\n\r\nIn [the preface of the cluster doc](https://nodejs.org/api/cluster.html#cluster_cluster) the first code example is followed by a shell illustration of a debug script call:\r\n```\r\n$ NODE_DEBUG=cluster node server.js\r\n23521,Master Worker 23524 online\r\n23521,Master Worker 23526 online\r\n23521,Master Worker 23523 online\r\n23521,Master Worker 23528 online\r\n```\r\nHowever, I can't get the same output in Windows:\r\n```\r\nJ:\\temp>type server.js\r\n```\r\n```js\r\nconst cluster = require('cluster');\r\nconst http = require('http');\r\nconst numCPUs = require('os').cpus().length;\r\n\r\nif (cluster.isMaster) {\r\n  // Fork workers.\r\n  for (var i = 0; i < numCPUs; i++) {\r\n    cluster.fork();\r\n  }\r\n\r\n  cluster.on('exit', (worker, code, signal) => {\r\n    console.log(`worker ${worker.process.pid} died`);\r\n  });\r\n} else {\r\n  // Workers can share any TCP connection\r\n  // In this case it is an HTTP server\r\n  http.createServer((req, res) => {\r\n    res.writeHead(200);\r\n    res.end('hello world\\n');\r\n  }).listen(8000);\r\n}\r\n```\r\n```\r\nJ:\\temp>SET NODE_DEBUG=cluster && node server.js\r\n\r\n// no debug output;\r\n// process monitor shows all four clusters are running;\r\n// servers respond successfully.\r\n\r\n// press Ctrl+C\r\n\r\n^C\r\n\r\nJ:\\temp>\r\n\r\n// environment variable check\r\n\r\nJ:\\temp>SET NODE_DEBUG\r\n\r\nNODE_DEBUG=cluster\r\n\r\nJ:\\temp>\r\n```\r\nI've tried to find in the `cluster.js` any checks for `NODE_DEBUG` or any `util.debuglog()` calls and I could not find any.\r\n\r\nIs this illustration still valid?\r\nIs it not valid only for Windows?\r\nIs this note after the illustration supposed to explain the output difference in Windows:\r\n\r\n> Please note that on Windows, it is not yet possible to set up a named pipe server in a worker.\r\n\r\nShould the document fragment be somehow clarified more?",
        "labels": "doc",
        "id": 44536
    },
    {
        "title": "Add button at reading docs",
        "body": "I'm a newbie at Nodejs and start reading documents.Something I feel to a problem, again and again, go to the sidebar for next page so why we add two buttons next and previous.",
        "labels": "doc",
        "id": 44537
    },
    {
        "title": "Benchmark docs: how to select the CRAN Mirror for R",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v7.2.0\r\n* **Platform**: OS X\r\n* **Subsystem**:\r\ndocs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIn the benchmarks docs, https://github.com/nodejs/node/blob/master/benchmark/README.md, the instructions say to install 2 R packages,\r\n\r\n`\r\ninstall.packages(\"ggplot2\")\r\ninstall.packages(\"plyr\")\r\n`\r\n\r\nbut running those commands in the R repl returns a `--- Please select a CRAN mirror for use in this session ---`\r\n\r\nshould be somehting like this,  `install.packages(\"ggplot2\", repos=\"http://cran.us.r-project.org\")`\r\n\r\n\r\nI can add a PR",
        "labels": "doc",
        "id": 44538
    },
    {
        "title": "https agent docs are incomprehensible",
        "body": "Subsystem: doc,https,http\r\n\r\nhttps://github.com/nodejs/node/blame/d8c7534fcd46283e52c8c9324d11390c6218b809/doc/api/https.md#L195-L232\r\n\r\nDocs state that a sub-set of the `tls.connect()`/secure context options can be provided to `https.request()`. \r\n\r\n> The following options from [`tls.connect()`][] can also be specified:\r\n\r\nThis is almost certainly wrong, probably all of them can be supplied.\r\n\r\nThe docs then go on to state:\r\n\r\n> In order to specify these options, use a custom [`Agent`][].\r\n\r\nIts impossible to understand what this means... are they options, or not? Do they only work with custom agents?\r\n\r\nThere is an example.... but since the example passes the *exact* same options to a custom agent constructor, and to `https.request()`, it gets even harder to understand.\r\n\r\nIt appears that the secure options may not in fact be used as options to `https.request()`... that you need to provide them to an Agent?\r\n\r\nBut none of the optoins provided to the Agent constructor in the example are supported by Agent, according to [its docs](https://nodejs.org/api/http.html#http_new_agent_options), including the secure context options, so who knows what they do.\r\n\r\nSo, at the end of reading through the docs:\r\n\r\n*I have *absolutely* no idea what secure context options are supported by https.request(), could be all, could be none as the example suggests.*\r\n\r\nMaybe the docs are completely wrong, and the only way to provide secure context options with `https.request()` is to use a custom Agent?\r\n\r\nOr maybe whether the `options` argument to `https.request()` is ignored when you have an agent, and used when you don't?\r\n\r\nIf anybody knows, feel free to document either here or in a doc PR. I might look at this later, but it wasn't particularly obvious in a quick read.\r\n\r\nAlso, https://github.com/nodejs/node/blob/master/lib/_http_client.js#L35 is a bit odd, because `null` is explicitly not documented as an option for the `agent` property, for http or https. But that's for another issue, I guess.\r\n\r\n",
        "labels": "doc",
        "id": 44539
    },
    {
        "title": "lets merge docs-requested label with the docs label",
        "body": "The distinction isn't clear, lots of people use both labels, or one at random, and no other node sub-system tries to have multiple labels.\r\n\r\nLets merge them.\r\n",
        "labels": "doc",
        "id": 44540
    },
    {
        "title": "README gpg guidelines are insufficient",
        "body": "* **Version**: n/a\r\n* **Platform**: n/a\r\n* **Subsystem**: n/a\r\n\r\nThe readme states:\r\n\r\n> You can then use gpg --verify SHASUMS256.txt.asc to verify that the file has been signed by an authorized member of the Node.js team.\r\n\r\nHowever, this operation will only verify that the file was armored by some previously trusted gpg public key. Any user that trusts more than just the node publishing keys may be vulnerable to packages published by non-nodejs team members.\r\n\r\nThis process should use `--no-default-keyring` and a keyring/key file fit for purpose, along with `--verify`",
        "labels": "doc",
        "id": 44541
    },
    {
        "title": "doc: documentation for WriteStream.cursorTo and other TTY methods",
        "body": "Even if they're deprecated and we're supposed to use the `readline` module now, the docs should say that, right?\r\n\r\nCurrently, the docs don't list `process.stdout.cursorTo` and related functions at all.\r\n\r\n### Popular modules, as well as Node itself, still use them:\r\n\r\n[node-progress module](https://github.com/visionmedia/node-progress/blob/master/lib/node-progress.js#L195)\r\n[node debugger](https://github.com/nodejs/node/blob/db1087c9757c31a82c50a1eba368d8cba95b57d0/lib/_debugger.js#L865)\r\n\r\n### Here's the full list of functions I'm referring to: \r\n\r\n[tty.js:92](https://github.com/nodejs/node/blob/db1087c9757c31a82c50a1eba368d8cba95b57d0/lib/tty.js#L92)\r\n\r\nI think it would reduce confusion if we at least mentioned these in the `process` or `stream` docs.",
        "labels": "doc",
        "id": 44542
    },
    {
        "title": "doc: doc/api/modules.md needs a better explanation of `exports`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: v8.0.0-pre\r\nPlatform: all\r\nSubsystem: doc\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v8.0.0-pre\r\n* **Platform**: all\r\n* **Subsystem**: doc\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe Modules doc needs a better explanation of the utility of `exports` vs. `module.exports`. If that's too much detail for the API doc, then perhaps we can write a guide in `doc/guides` and link to it.",
        "labels": "doc",
        "id": 44543
    },
    {
        "title": "doc: update SSL/TLS version references",
        "body": "* **Version**: v6.x+ ?\r\n* **Platform**: all\r\n* **Subsystem**: doc\r\n\r\nSince node no longer supports SSLv3 (at least out of the box, not sure offhand about when using node with shared openssl), it is probably a good idea to remove references to SSLv3 in the [`tls` documentation](https://nodejs.org/docs/latest/api/tls.html). For example:\r\n\r\n* The `secureProtocol` option examples in `tls.connect()` and `tls.createServer()` currently use `SSLv3_method`. We should probably change this to something like `TLSv1_method`. Also, it might be good to surround the name inside the backticks with single quotes since it is a string value.\r\n\r\n* `tlsSocket.getProtocol()` references `SSLv3` as a valid example return value. If using a shared openssl does not change things, this should simply be removed from the list of example return values. The list of values should probably also include single quotes inside the backticks as well.\r\n",
        "labels": "doc",
        "id": 44544
    },
    {
        "title": "Some questions about buffer doc",
        "body": "* **Version**: 7.2.0\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: doc, buffer\r\n\r\nI'm preparing a PR with some small fixes in code examples of the buffer doc and I've stumbled on some puzzles I want to clarify before the PR.\r\n\r\n1. `buf.lastIndexOf()` `byteOffset` argument [explanation](https://nodejs.org/dist/latest-v7.x/docs/api/buffer.html#buffer_buf_lastindexof_value_byteoffset_encoding).\r\n\r\nWhat does the \"(not inclusive)\" remark actually mean? In this code (not in the doc) the `byteOffset` seems to be inclusive in the search and the result.\r\n```js\r\nconsole.log(Buffer.from('0123').lastIndexOf('1', 1));\r\n```\r\n```\r\n1\r\n```\r\nThe same for this code in the doc:\r\n```js\r\nBuffer.from('this buffer is a buffer');\r\n\r\n// Prints: 5\r\nconsole.log(buf.lastIndexOf('buffer', 5));\r\n```\r\nSo the question is this one: should this remark be clarified more or should it be removed?\r\n\r\n2. [`new Buffer(size)`](https://nodejs.org/dist/latest-v7.x/docs/api/buffer.html#buffer_new_buffer_size) and [`Buffer.allocUnsafe(size)`](https://nodejs.org/dist/latest-v7.x/docs/api/buffer.html#buffer_class_method_buffer_allocunsafe_size) examples.\r\n\r\nIt happens that the actual outputs of these fragments do not match with described ones for me for most of the tests:\r\n```js\r\nconst buf = new Buffer(5);\r\n\r\n// Prints: (contents may vary): <Buffer 78 e0 82 02 01>\r\nconsole.log(buf);\r\n\r\nbuf.fill(0);\r\n\r\n// Prints: <Buffer 00 00 00 00 00>\r\nconsole.log(buf);\r\n```\r\n```js\r\nconst buf = Buffer.allocUnsafe(5);\r\n\r\n// Prints: (contents may vary): <Buffer 78 e0 82 02 01>\r\nconsole.log(buf);\r\n\r\nbuf.fill(0);\r\n\r\n// Prints: <Buffer 00 00 00 00 00>\r\nconsole.log(buf);\r\n```\r\nWhile they do output as described in the REPL, tested by script files they output the same lines in some circumstances:\r\n```\r\n<Buffer 00 00 00 00 00>\r\n<Buffer 00 00 00 00 00>\r\n```\r\nAfter some research, I've found out there is a rather strong correlation between script file size and zeroing of a buffer beginning. If the before mentioned fragments are saved in 105-176 bytes file size (adjusted by these changes: ASCII/UTF-8,  +/- BOM, +/- comments/space), the first 5 bytes are almost always empty. So I've written a weird script to find out more about this correlation. Here are some notes about results:\r\n\r\na. Zeroing scheme of buffer bytes is the same inside cycles of a script file size increasing by 8 bytes.\r\nb. Correlation is flaky, so the statistics data need to be averaged in the research script and manually filtered after the tests.\r\nc. `Buffer.alloc(size)` always works safely as intended (the stat log is empty, i.e. no non-zero bytes schemes are detected and saved).\r\nd. `Buffer.allocUnsafeSlow(size)` also has some correlation, but it is significantly flakier and does not make big zero fragments in the buffer beginning, so it could be ignored in this case.\r\n\r\nIf somebody is interested in the research code, [here is the script](https://gist.github.com/vsemozhetbyt/076a0f47779ebf89bc01dca6198ac484). In the comments there, I also give the stat data from a test run on my machine. The stat data format is \"script file size: scheme with non-zero bytes indexes in created buffers\". Repeated lines inside 8-bytes cycles are filtered. If some flaky case happens inside this cycles, it is marked by `*` at the beginning of the line. Here is also the [diff](https://gist.github.com/vsemozhetbyt/3af80b8697d7e8419e1019d04a44ca14/revisions) between `new Buffer(size)` and `Buffer.allocUnsafe(size)` stats.\r\n\r\nSo the question is this one: is this correlation depends on some hardware/software features or is it something stable? In the first case, it could be ignored, in the second case the code examples should be adjusted to fall out of size diapasons that produce big zero fragments at the beginning or buffers, otherwise, novices could be confused by these examples if they run them by themselves.\r\n\r\nSorry for my bad English and all the possible obscurity.",
        "labels": "doc",
        "id": 44545
    },
    {
        "title": "Poll phase documentation",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n~~[`/doc/topics/event-loop-timers-and-nexttick.md`](https://github.com/nodejs/node/blob/master/doc/topics/event-loop-timers-and-nexttick.md#poll)~~\r\nThe documentation has been moved (https://github.com/nodejs/node/issues/10792):\r\nhttps://github.com/nodejs/nodejs.org/blob/master/locale/en/docs/guides/event-loop-timers-and-nexttick.md\r\n\r\nThe description of the poll phase is not clear at all to me. Could someone please clarify the (sequence of the) operations in this phase?\r\n\r\nExamples:\r\n\r\n> When the event loop enters the **poll** phase _and there are no timers scheduled_, one of two things will happen:\r\n\r\nWell, what happens if _there are_ timers scheduled?\r\n\r\n> If scripts **have not** been scheduled by `setImmediate()`, the event loop will wait for callbacks to be added to the queue, then execute them immediately.\r\n\r\nUntil... what?\r\n\r\n> Once the poll queue is empty [...]\r\n\r\nThis could not even happen if we reached the system-dependent hard limit, right? Would this step be ignored in such cases?",
        "labels": "doc",
        "id": 44546
    },
    {
        "title": "doc: repl deprecation styling results in unreadable text",
        "body": "* **Version**: v7.x\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nThe styling of backtick blocks in deprecation messages was changed at some point for v7.x docs, causing [this deprecation](https://nodejs.org/docs/v7.1.0/api/repl.html#repl_node_repl_history_file) to be white on gray on red, making the text unreadable.",
        "labels": "doc",
        "id": 44547
    },
    {
        "title": "doc issue: socket server 'error' event: 'close' is not called as described in doc.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:v7.1.0\r\n* **Platform**:Darwin p14010112-no-MacBook-Pro.local 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 23 18:25:34 PDT 2016; root:xnu-3248.60.10~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI am curious that should i call server.close in server.on('error'...) handler?\r\n\r\nAccording to  the document about [net.Server 'error' event](https://nodejs.org/api/all.html#net_event_error)\r\n>Event: 'error'\\#\r\n\\<Error\\>\r\nEmitted when an error occurs. **The 'close' event will be called directly following this event**. See example in discussion of server.listen.\r\n\r\nBut in fact, the 'close' event does not happen after error.\r\n\r\nThis is my `test.js` which try to listen a privileged port 80, cause an EACCESS error and exit.\r\n```\r\nrequire('net').createServer({allowHalfOpen: false}, function(stream) {\r\n  //\r\n}).listen({host: 'localhost', port: 80}, function () {\r\n  //\r\n}).on('error', function(e) {\r\n  console.log(e.message);\r\n  setTimeout(function () {\r\n    //\r\n  },1000)\r\n}).on('close', function () {\r\n  console.log('closed')\r\n});\r\n```\r\n\r\nTo ensure the close event can be caught before process exit, i set up a 1 second timer so process will keep alive in 1 second.\r\n\r\nBut still, the close event does not happen.\r\n\r\nIf i add `this.close()` in error handler, then the 'close' does happen.\r\n\r\nAccording to another doc about [server.listen](https://nodejs.org/api/all.html#net_server_listen_port_hostname_backlog_callback), obviously node.js does not call close on error, at least for EADDRINUSE.\r\n```\r\nserver.on('error', (e) => {\r\n  if (e.code == 'EADDRINUSE') {\r\n    console.log('Address in use, retrying...');\r\n    setTimeout(() => {\r\n      server.close();                       //see here please. If it is auto closed, why need this?\r\n      server.listen(PORT, HOST);\r\n    }, 1000);\r\n  }\r\n});\r\n```\r\n\r\nSo the document is contradictory, it should be noted that 'close' will not be called automatically.\r\n\r\nRegards.",
        "labels": "doc",
        "id": 44548
    },
    {
        "title": "Buffer.isEncoding regards an empty string as a valid encoding",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: Node.js v7.1.0\r\n* **Platform**: Darwin Kernel Version 16.1.0\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nAs stated in the issue title, `Buffer.isEncoding('')` returns `true`. \r\n\r\nActually, passing an empty string to `encoding` options of `fs.readFile`, `Buffer.from` or other functions supporting `encoding` doesn't result in an error, because they use the default encoding `utf8` as a fallback in that case.\r\n\r\nFrom this point of view, `''` is also a valid encoding and `Buffer.isEncoding('') === true` looks fine. However, if we approve this behavior of `Buffer.isEncoding`, I think it's inconsistent that `Buffer.isEncoding` returns `false` when it takes other falsy values âˆ’ `false`, `null`, `undefined` etc.\r\n\r\nSo, which design of [`Buffer.isEncoding`](https://nodejs.org/dist/latest-v7.x/docs/api/buffer.html#buffer_class_method_buffer_isencoding_encoding) is most reasonable?\r\n\r\n1. There is no problem with the current behavior of `Buffer.isEncoding`.\r\n2. `Buffer.isEncoding` should return `false` when it takes `''`.\r\n3. `Buffer.isEncoding` should return `true` when it takes any falsy values.\r\n\r\nI support the second one and can create a pull request.\r\n\r\nI'd like to hear your opinion. Thanks.\r\n",
        "labels": "doc",
        "id": 44549
    },
    {
        "title": "package.json \"main\" may specify a directory; spec says it may not",
        "body": "* **Version**: v7.1.0\r\n* **Platform**: Windows 10 Enterprise version 1607, 64-bit\r\n* **Subsystem**: ?\r\n\r\n### To reproduce\r\n\r\n**a.js**\r\n\r\n```js\r\nconsole.log(require.resolve(\"./m\"));\r\nconsole.log(require.resolve(\"./m2\"));\r\n```\r\n\r\n**m/package.json**\r\n\r\n```json\r\n{ \"main\": \"main\" }\r\n```\r\n\r\n***m/main/index.js**\r\n\r\n(empty file)\r\n\r\n**m2/package.json**\r\n\r\n```json\r\n{ \"main\": \"main\" }\r\n```\r\n\r\n**m2/main/package.json**\r\n\r\n```json\r\n{ \"main\": \"main2\" }\r\n```\r\n\r\n**m2/main/main2.js**\r\n\r\n(empty file)\r\n\r\nWhen I run this, I get:\r\n\r\n```\r\nC:\\Users\\anhans\\work\\sample\\package\\m\\main\\index.js\r\nmodule.js:474\r\n    throw err;\r\n    ^\r\n\r\nError: Cannot find module './m2'\r\n```\r\n\r\n\r\n### Explanation\r\n\r\nBased on the [spec](https://nodejs.org/api/modules.html#modules_all_together), I would not expect the first `require.resolve` call to succeed.\r\n\r\nThe important line is `c. LOAD_AS_FILE(M)` at the end of LOAD_AS_DIRECTORY step 1.\r\nIt appears to not be `LOAD_AS_FILE` because `m/main/index.js` is loaded, but not `LOAD_AS_DIRECTORY` either because `m2/main/main2.js` is not loaded (i.e., package.json is not looked up recursively).\r\n\r\nThis is relevant because we want to follow the node module-resolution spec in our own module loader; but we also want it to work for a real packages like `common-tags`, which specifies the `lib` directory for its `main`. See Microsoft/TypeScript#12198.\r\n",
        "labels": "doc",
        "id": 44550
    },
    {
        "title": "child_process documentation for stdio",
        "body": "The [child_process documentation](https://github.com/nodejs/node/blob/master/doc/api/child_process.md) for `execFileSync`, `execSync` and `spawnSync` notes that `options.stdio` is an array. \r\n\r\nBut it seems it can also be a string, similar to the `stdio` options given to `child_process.spawn`.\r\n\r\nActually  `execFileSync`, `execSync` and `spawnSync` all ends [up here](https://github.com/nodejs/node/blob/master/lib/child_process.js#L428), where the options are accepted as string or array. See https://github.com/nodejs/node/blob/master/lib/internal/child_process.js#L758",
        "labels": "doc",
        "id": 44551
    },
    {
        "title": "doc: vm documentation has invalid link",
        "body": "* **Version**: v6.x, v7.x, master\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nThe [`vm.runInDebugContext()`](https://nodejs.org/docs/v7.1.0/api/vm.html#vm_vm_runindebugcontext_code) description contains an invalid link to the CLI documentation (` [command line option][cli.md]`). The missing reference just needs to be added to the bottom of the markdown document.\r\n",
        "labels": "doc",
        "id": 44552
    },
    {
        "title": "doc: crypto.privateEncrypt() padding list needs update",
        "body": "* **Version**: all\r\n* **Platform**: n/a\r\n* **Subsystem**: doc\r\n\r\nCurrently `crypto.privateEncypt()` lists `crypto.constants.RSA_PKCS1_OAEP_PADDING` as a valid `padding` value, but it is actually only allowed for `crypto.publicEncrypt()` as far as encrypting goes. This value needs to simply be removed from that list in `crypto.privateEncrypt()`'s description.\r\n",
        "labels": "doc",
        "id": 44553
    },
    {
        "title": "Documentation error.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI think there is an error in the  documentation of Node in the part of \"Assertion Testing\".\r\n\r\n_**assert.notDeepEqual(actual, expected[, message])**_\r\n\r\n> Current\r\n\r\nassert.notDeepEqual(obj1, obj4);\r\n  // OK, obj1 and **obj2** are not deeply equal\r\n\r\nI think the result must be the next...\r\n\r\nassert.notDeepEqual(obj1, obj4);\r\n  // OK, obj1 and **obj4** are not deeply equal\r\n\r\nThanks!!",
        "labels": "doc",
        "id": 44554
    },
    {
        "title": "Article on nodejs.org - outdated?",
        "body": "A friend of mine asked why https://nodejs.org/en/docs/guides/anatomy-of-an-http-transaction/ insists on putting `request.on('error')` handler.\r\n\r\nAFAIK there's no possibility to get an `error` on server `request/response` since ancient times in Node.JS. \r\n\r\nIf that's correct, then probably the article is outdated and should be updated?",
        "labels": "doc",
        "id": 44555
    },
    {
        "title": "A collection of minor issues with the docs",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 7\r\n* **Platform**: NA\r\n* **Subsystem**: NA\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nHi, I've just finished reading the docs and made a few notes about some minor issues I found. I thought I'd dump them here, I can do a PR if appropriate. I might be misunderstanding some things so didn't want to jump in.\r\n\r\n1. Should `tls.connect()` list `host` and `port` in the options if they're already params?\r\nhttps://nodejs.org/api/tls.html#tls_tls_connect_port_host_options_callback\r\n\r\n2. Seems weird that `path.resolve()` arguments are optional. Worth documenting that the method returns `'.'` if you pass nothing in?\r\nhttps://nodejs.org/api/path.html#path_path_join_paths\r\nhttps://nodejs.org/api/path.html#path_path_resolve_paths\r\n\r\n3. The params for `path.format()` and `path.parse()` are in different orders, `format()` is logically wrong based on the diagram under `parse()`\r\nhttps://nodejs.org/api/path.html#path_path_format_pathobject\r\nhttps://nodejs.org/api/path.html#path_path_parse_path\r\n\r\n4. There shouldn't be spaces in `tlsSocket.getPeerCertificate([ detailed ])`\r\nhttps://nodejs.org/api/tls.html#tls_tlssocket_getpeercertificate_detailed\r\n\r\n5. `net.Server` shows `connections` as deprecated...\r\nhttps://nodejs.org/api/net.html#net_server_connections\r\n`tls.Server` inherits from this, but doesn't show `connections` as deprecated\r\nhttps://nodejs.org/api/tls.html#tls_server_connections\r\nShould it?\r\n\r\n6. Is the `encoding` parameter allowed if the `data` parameter isn't set?\r\nShould: request.end([data][, encoding][, callback])\r\nbe: request.end([data[, encoding]][, callback])\r\n?\r\nhttps://nodejs.org/api/http.html#http_request_end_data_encoding_callback\r\n\r\n7. `dgram` has a header \"dgram module functions\" before the static methods, none of the other pages do this. Is the dgram module different, or is this just an inconsistency?\r\nhttps://nodejs.org/api/dgram.html#dgram_dgram_module_functions\r\n\r\n8. `dgram.createSocket()` has two different signatures listed. One with `type`, one with `object`.\r\nhttps://nodejs.org/api/dgram.html#dgram_dgram_createsocket_type_callback\r\nThat's cool, but the same sort of thing in the `fs` module where an `options` parameter could be a string defining the encoding, or an object that has an encoding property and something else is shown as a single signature.\r\nhttps://nodejs.org/api/fs.html#fs_fs_readfile_file_options_callback\r\nIMO they should both be like `dgram`, that is, `fs.readFile(file[, encoding], callback)` should be listed in addition to `fs.readFile(file[, options], callback)`.\r\nBut that means lots to change on the fs page.\r\n\r\n9. There is (very?) minor inconsistency in callback terminology. E.g. socket connect specifies a `connectListener` which is nice, it defines that this is a callback that is the same as 'listening' for the `connect` event.\r\nhttps://nodejs.org/api/net.html#net_socket_connect_options_connectlistener\r\nBut `server.listen` names the parameter just `callback`.\r\nhttps://nodejs.org/api/net.html#net_server_listen_options_callback\r\nPersonally my choice would be the 'on' prefix followed by the event name that would trigger it. `onConnect`, `onListening` etc. I think that would make understanding when the callbacks are called easy.\r\n\r\n10. The example of a `dgam` sending message unnecessarily converts a string to a buffer, since it will be converted to a (utf8) `Buffer` anyway. Less complexity in examples is better, right?\r\n(Also it vaguely implies that a string isn't as valid as a buffer.)\r\nhttps://nodejs.org/api/dgram.html#dgram_socket_send_msg_offset_length_port_address_callback\r\n\r\n11. Parameter names are almost always camelCase, except in crypto where they're snake_case.\r\nhttps://nodejs.org/api/crypto.html#crypto_cipher_final_output_encoding\r\nIs that an inconsistency or is there meaning in that?\r\n\r\n12. Using `util.inspect()` inside `console.log()` is redundant (I think. Isn't it?)\r\nhttps://nodejs.org/api/events.html#events_emitter_listeners_eventname\r\nhttps://nodejs.org/api/vm.html#vm_vm_runincontext_code_contextifiedsandbox_options\r\nhttps://nodejs.org/api/vm.html#vm_script_runinnewcontext_sandbox_options\r\n\r\n13. Missing apostrophe in \"run using the vm modules methods\"\r\nhttps://nodejs.org/api/vm.html#vm_what_does_it_mean_to_contextify_an_object\r\n\r\n14. I have no idea about this one, but is sandbox really optional in `script.runInNewContext()`?\r\nIf I call `script.runInNewContext(options)`, wouldn't it try and make a sandbox out of the options object? I went looking through the source but found myself in a strange land and gave up.\r\nhttps://nodejs.org/api/vm.html#vm_script_runinnewcontext_sandbox_options\r\n\r\n15. `zlib.constants` is missing \"added in version...\" (and is quite new so this is a problem)\r\nhttps://nodejs.org/api/zlib.html#zlib_zlib_constants\r\nLooks like this commit\r\nhttps://github.com/nodejs/node/commit/197a4652807bf1d830d67c1d8a4aecdf35fda6a4#diff-c245d87dba893de0b77c7574f0081633R388\r\n\r\n16. `zlib.codes` isn't documented. Is that on purpose?\r\nhttps://nodejs.org/api/zlib.html\r\n\r\n17. `zlib` methods all have `options` as an argument, but not shown in square brackets (but in the TOC they're shown in square brackets). Less important, but having the word in the argument list be linked is inconsistent with the other pages. The description contains the word 'options' which is linked to the class options section.\r\n\r\n18. Wording is strange for zlib methods, e.g. \"Returns a new `Deflate` object with an options.\"\r\nBy comparison, in `net.connect()` the equivalent wording is something like \"The options are passed to the `net.Socket` constructor\"\r\nhttps://nodejs.org/api/zlib.html\r\n\r\n19. Getting picky here ... but the wording for there being Sync version of methods is different for `fs` and `zlib`.\r\nhttps://nodejs.org/api/zlib.html#zlib_convenience_methods\r\nhttps://nodejs.org/api/fs.html#fs_file_system\r\n",
        "labels": "doc",
        "id": 44556
    },
    {
        "title": "n.kill(19) throws error",
        "body": "On versions 6 and 7 of Node.js\r\n\r\nwhen I started a child process with `const n = require('child_process').spawn`\r\n\r\nif I try,\r\n\r\n`n.kill(19)`, I get an error saying the signal is not recognized\r\n\r\nbut 19 is a valid signal\r\nhttp://stackoverflow.com/questions/9951556/why-number-9-in-kill-9-command-in-unix\r\n\r\nI would expect it to work\r\n\r\nif I do `n.kill('SIGSTOP')`, it seems to work.\r\n\r\nCan we (not) use numbers/integers with n.kill()?\r\n\r\n",
        "labels": "doc",
        "id": 44557
    },
    {
        "title": "Incorrect documentation for fs.write with Buffers",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* v4.6.0\r\n* Darwin Kernel Version 15.6.0: Thu Sep  1 15:01:16 PDT 2016; root:xnu-3248.60.11~2/RELEASE_X86_64 x86_64\r\n* fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nwhen calling:\r\n```\r\nvar buffer = new Buffer('a');\r\nfs.write(fileHandle, buffer, function(err){\r\n});\r\ncallback is not called (I spent 1 hour why callback is not called:)). I must use:\r\nfs.write(fileHandle, buffer, 0, buffer.length, function(err){\r\n});\r\n```\r\nthen callback is called\r\n\r\ndoc says: `fs.write(fd, data[, position[, encoding]], callback)`\r\nwhere data `<String> | <Buffer>`\r\n\r\ndoes not work for Buffer\r\n\r\nor, ofcourse,\r\n`fs.write(fd, buffer, offset, length[, position], callback)`\r\n\r\nwhich works",
        "labels": "doc",
        "id": 44558
    },
    {
        "title": "Questions about event-loop-timers-and-nexttick.md",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:  v7.0.0\r\n* **Platform**: win10 x64\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`/doc/topics/event-loop-timers-and-nexttick.md`\r\n\r\n### Question 1\r\n\r\nThe example:\r\n\r\n```js\r\nconst server = net.createServer(() => {}).listen(8080);\r\n\r\nserver.on('listening', () => {});\r\n```\r\n\r\n> Problem is that the .on('listening') will not have been set by that time. \r\n\r\nMy understanding is 'listening' event callback will not be executed. Then I made some changes to verify it:\r\n\r\n```js\r\nconst net = require('net');\r\nconst server = net.createServer(() => {}).listen(8080);\r\n\r\nserver.on('listening', () => {\r\n  console.log('listening');\r\n});\r\n```\r\n\r\nThe console outputs 'listening', so 'listening' event callback is executed.\r\n\r\nThe similar example:\r\n\r\n```js\r\nvar server = net.createServer();\r\nserver.on('connection', function(conn) { });\r\n\r\nserver.listen(8080);\r\nserver.on('listening', function() { });\r\n```\r\n\r\nWhat's the meanings of these words: \r\n\r\n> but the listening callback is placed in a setImmediate()\r\n\r\nIs the listening callback placed in a setImmediate()?\r\n\r\n### Question 2\r\n\r\nSection close callbacks\r\n\r\n> Otherwise it will be emitted via process.nextTick().\r\n\r\nCould give more explanations?\r\n\r\n### Question 3\r\n\r\n> The API updated fairly recently to allow passing arguments to process.nextTick() allowing it to take any arguments passed after the callback to be propagated as the arguments to the callback so you don't have to nest functions.\r\n\r\nThis is a very long sentence, I don't quite understand it, well, my English is not good. \"arguments passed after the callback\", could give an example?\r\n\r\n\r\n\r\n",
        "labels": "doc",
        "id": 44559
    },
    {
        "title": "doc: add data types to properties",
        "body": "Some of the docs specify the type for properties, while others do not. A good first contribution would be to update the properties that are missing this information. As an example, look at https://nodejs.org/api/process.html#process_process_connected vs. https://nodejs.org/api/child_process.html#child_process_child_connected. These two things represent the same concept, but the one in the `child_process` docs have the data type.\r\n",
        "labels": "doc",
        "id": 44560
    },
    {
        "title": "Why listening \"::\" (all IPv6) also get \"0.0.0.0\"(all IPv4) listened?",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:v7.0.0\r\n* **Platform**:Windows 7 Pro\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI found a strange problem, i created a simple TCP server to listen at port 5555 of \"::\"(all IPv6 interfaces) \r\n```\r\nnet.createServer(c=>console.log).listen(5555,'::')\r\n```\r\n\r\nThen i found all IPv4 interfaces are also listening port 5555.\r\n```\r\n> netstat -an | findstr /I :5555\r\n  TCP    0.0.0.0:5555           0.0.0.0:0              LISTENING\r\n  TCP    [::]:5555              [::]:0                 LISTENING\r\n```\r\n\r\nAnother relevant problem is, if i do not specify host, or use `undefined`, or empty string,\r\n```\r\nnet.createServer(c=>console.log).listen(5555)\r\n//or net.createServer(c=>console.log).listen(5555,undefined)\r\n//or net.createServer(c=>console.log).listen(5555,'')\r\n```\r\nIt should listen :: **OR** 0.0.0.0, not both, according the [document](https://nodejs.org/api/net.html#net_server_listen_port_hostname_backlog_callback):\r\n>server.listen([port][, hostname][, backlog][, callback])\r\n> If the hostname is omitted, the server will accept connections on any IPv6 address (::) when IPv6 is available, or any IPv4 address (0.0.0.0) otherwise\r\n\r\nBut the fact is both :: and 0.0.0.0 get listened.\r\n\r\nI don't know which is correct? document or implementation? Anyway, this is a bit confusing.\r\nOr maybe this is just a trick implementation of the Windows OS itself ?\r\n",
        "labels": "doc",
        "id": 44561
    },
    {
        "title": "code highlight slightly misaligned",
        "body": "* **Version**: latest master and also LIVE\r\n* **Platform**: Web Browsers\r\n* **Subsystem**: doc\r\n\r\nAs seen in the screenprint, the very first line of code section is slightly indented, in all pages.\r\n\r\n<img width=\"837\" alt=\"screen shot 2016-10-31 at 9 02 52 pm\" src=\"https://cloud.githubusercontent.com/assets/696611/19860163/bfed5d38-9fad-11e6-8879-8ca9e9908e21.png\">\r\n\r\ncc @nodejs/documentation ",
        "labels": "doc",
        "id": 44562
    },
    {
        "title": "readdirSync of drive letter lists items of cwd",
        "body": "* **Version**: v6.9.1\r\n* **Platform**: Windows 8.1 x64\r\n\r\nReaddirSync behavior depends on the current working directory (cwd/pwd) if we pass a drive letter with or without a trailing \"\\\".\r\n\r\nIt's very easy to reproduce. Here, I am on \"d:\" drive, and I have a \"d:\\Temp\" folder, containing \"A\" and \"B\" sub-folders.\r\n\r\n```\r\nD:\\Temp>  gci | % { $_.Name }\r\nA\r\nB\r\n\r\nD:\\Temp> node\r\n> var fs = require('fs');\r\nundefined\r\n> fs.readdirSync('d:')\r\n[ 'A', 'B' ]\r\n> fs.readdirSync('d:\\\\')\r\n[ '$RECYCLE.BIN',\r\n  'Cache',\r\n  'DEV',\r\n  'Installers',\r\n  'log',\r\n  'pagefile.sys',\r\n  'System Volume Information',\r\n  'Temp',\r\n  'VM' ]\r\n> .exit\r\nD:\\Temp>\r\n```\r\n\r\nIt's a very suprising behavior, and more importantly, it's not documented if expected.",
        "labels": "doc",
        "id": 44563
    },
    {
        "title": "module.children behavior does not match documentation (only tracks first requires)",
        "body": "#### TL;DR [`module.children`](https://nodejs.org/api/modules.html#modules_module_children) does not behave according to documentation.\r\n\r\nWhat be the expected behaviour of [`module.children`](https://nodejs.org/api/modules.html#modules_module_children)? \r\n\r\nDocumentations states that `module.children` is \"the module objects required by this one.\" This is false, as it only lists the children that __were required for the first time__ by the module. Since `module.parent` is correctly documented as containing \"the module that first required this one\", it seems like this may be a documentation bug. If that's the case, we should correct the documentation. \r\n\r\nConsidering the issue on another level, what is the purpose of `module.children` and `module.parent`? Having a full graph of the **first** requires, or a **partial/incomplete** graph of all require relationships, does not seem at all useful to me. Why do these exist? I propose the addition of `module` fields `requirers` and `requirees` as respective analogues of `parent` and `children`, but ones which will keep track of all requires. The code will be essentially the same as what is [currently in place](https://github.com/nodejs/node/blob/v6.9.1/lib/module.js#L42), except that instead of running on module initialisation and pushing this module into the parent module's `children` structure (which only works the first time it is required, since after that the module is initialised and cached), we run after every `require`, pushing this module into the child's `requirers`. This will generally also only run once per uncached module (except for modules with conditional or lazy requires), except still works even if the children are cached. \r\n\r\nSo, fix options here are: \r\n1) consider this a documentation bug and fix the documentation\r\n2) change the behaviour of `module.children` to match the documentation (fix basically described above)\r\n\r\nPossibly related to #7131 and #3933 \r\n",
        "labels": "doc",
        "id": 44564
    },
    {
        "title": "doc: buffer TOC incorrectly contains brackets",
        "body": "- **Version**: master, v6.x\n- **Platform**: n/a\n- **Subsystem**: doc\n\nIn the `buffer` doc TOC there is an entry called 'What makes [Buffer.allocUnsafe()] and [Buffer.allocUnsafeSlow()] \"unsafe\"?'. The brackets there should not be visible. The brackets do not exist in the v4.x docs. If I had to take a wild guess I would say the brackets were introduced when the 'deprecated' tags were added to every doc pages' TOC, as that is the immediate obvious difference between the `buffer` doc TOC in v4.x and v6.x/latest.\n",
        "labels": "doc",
        "id": 44565
    },
    {
        "title": "doc: update collaborator_guide to mention core-validate-commit",
        "body": "Subsystem: doc\n- the `COLLABORATOR_GUIDE` \n- and https://nodejs.org/en/get-involved/development/#landing-pull-requests  \n\nâ€¦should mention @evanlucas ' https://github.com/evanlucas/core-validate-commit  as a helpful tool in validating commit messages.\n\nIt could be helpful even for contributors also.\n",
        "labels": "doc",
        "id": 44566
    },
    {
        "title": "OpenSSL Doc Links",
        "body": "The following pull-request moved the OpenSSL docs breaking a lot of links in the node docs: https://github.com/openssl/openssl/pull/1758\n\nThere are now separate pages for different versions and master. For example https://www.openssl.org/docs/apps/ca.html is no longer accessible, but it's available at\nhttps://www.openssl.org/docs/man1.0.2/apps/ca.html and https://www.openssl.org/docs/manmaster/man1/ca.html\n\nI was working on a pull-request to address https://github.com/nodejs/node/issues/9025 when I came across this. I'm willing to go through and fix the existing documentation, but I was wondering whether you all would prefer the links be changed to 1.0.2 or master?\n",
        "labels": "doc",
        "id": 44567
    },
    {
        "title": "Inaccurate https.request options docs",
        "body": "- **Version**: 7.0.0\n- **Platform**: All\n- **Subsystem**: Docs\n\nI needed to explore specifying the SNI hostname independently of the hostname and the `Host` header, but the docs list the `servername` among [these bullets](https://nodejs.org/api/https.html#https_https_request_options_callback) (my emphasis):\n\n> The following options from `tls.connect()` can also be specified. _However_, _a_\n> _`globalAgent`_ _silently_ _ignores_ _these_.\n> - `pfx`: Certificate, Private key and CA certificates to use for SSL. Default `null`.\n> - `key`: Private key to use for SSL. Default `null`.\n> - `passphrase`: A string of passphrase for the private key or pfx. Default `null`.\n> - `cert`: Public x509 certificate to use. Default `null`.\n> - `ca`: A string, [`Buffer`][] or array of strings or [`Buffer`][]s of trusted\n>   certificates in PEM format. If this is omitted several well known \"root\"\n>   CAs will be used, like VeriSign. These are used to authorize connections.\n> - `ciphers`: A string describing the ciphers to use or exclude. Consult\n>   https://www.openssl.org/docs/apps/ciphers.html#CIPHER-LIST-FORMAT for\n>   details on the format.\n> - `rejectUnauthorized`: If `true`, the server certificate is verified against\n>   the list of supplied CAs. An `'error'` event is emitted if verification\n>   fails. Verification happens at the connection level, _before_ the HTTP\n>   request is sent. Default `true`.\n> - `secureProtocol`: The SSL method to use, e.g. `SSLv3_method` to force\n>   SSL version 3. The possible values depend on your installation of\n>   OpenSSL and are defined in the constant [`SSL_METHODS`][].\n> - `servername`: Servername for SNI (Server Name Indication) TLS extension.\n> \n> In order to specify these options, use a custom [`Agent`][].\n\nThat doesn't seem to be correct, though. If I do an HTTPS request without providing an `Agent` instance (thus utilizing the global agent), it does use the `servername` as the SNI hostname:\n\n``` js\nrequire('https').request({\n    hostname: 'www.github.com',\n    servername: 'sniname.com'\n}).end();\n// Error: Hostname/IP doesn't match certificate's altnames: \"Host: sniname.com. is not in the cert's altnames: DNS:github.com, DNS:www.github.com\"\n```\n\nThe `rejectUnauthorized` option also works fine without an agent.\n\nIt seems like the docs should be fixed to match reality? I'd whip up a PR, but I'm not sure exactly which of the remaining options also work without an agent, and I'm not familiar enough with TLS etc. to find out.\n\nLooks like the inaccuracy was introduced in 8ba56316, while `rejectUnauthorized` was added to the list way back in f8c335d0c (0.6.6).\n",
        "labels": "doc",
        "id": 44568
    },
    {
        "title": "http creates and uses local domain socket when given a \"host:port\" string",
        "body": "Versions 5 to 6.9.1\nPlatform: Darwin Darwin Kernel Version 16.0.0 RELEASE_X86_64 x86_64\n\n```\nvar http = require('http');\nvar server = http.createServer(function(request, response) {});\nserver.listen('127.0.0.1:9998');\n```\n\nWhen I run `node index.js` this will start the listener but a (file descriptor?) with the name `127.0.0.1:9998` is created in the same directory. `ctrl-c` from the node process will not clean  this file. `EADDRINUSE` is thrown if `node index.js` is run again without manually deleting this file. Tried this on my mac and fresh ubuntu docker image.\n",
        "labels": "doc",
        "id": 44569
    },
    {
        "title": "child_process: add public API to unref ipc channel",
        "body": "- **Version**: all\n- **Platform**: n/a\n- **Subsystem**: child_process\n\nIt would be nice to have a public API to `unref()` a child process's ipc channel. My use case for this is that I spawn a child process, send some messages back and forth via ipc, then at some point I want to detach the child process. `child.unref()` is not enough because that only unrefs the C++ ProcessWrap handle. Currently I have to resort to also doing `child._channel.unref()`. I am not sure if this should be done automatically inside `child.unref()` or if there should be a separate function or similar.\n",
        "labels": "doc",
        "id": 44570
    },
    {
        "title": "doc: need better link to signals list in process documentation",
        "body": "- **Version**: all\n- **Platform**: n/a\n- **Subsystem**: doc\n\nIn the 'Signal Events' section of the `process` documentation, there is a link to a man page that supposedly lists the names of the various signals that can be listened for. However, the page that is currently linked ([sigaction(2)](http://man7.org/linux/man-pages/man2/sigaction.2.html)) doesn't show all of the valid signals and the ones that it does show are not formatted very well. I think a better link would be to [signal(7)](http://man7.org/linux/man-pages/man7/signal.7.html), which _does_ list all of the signal names and in an easy-to-spot/read format.\n",
        "labels": "doc",
        "id": 44571
    },
    {
        "title": "streams documentation for writable.write(chunk) describes return value incorrectly",
        "body": "> The return value indicates whether the written `chunk` was buffered internally and the buffer has exceeded the `highWaterMark` configured when the stream was created.  If `false` is returned, further attempts to write data to the stream should be paused until the `'drain'` event is emitted.\n\nThis suggests that when `writable.write(chunk)` returns `false`, the passed `chunk` was not buffered. In reality, `write()` always unconditionally buffers the `chunk` regardless of what it returns. Its return value is only advisory.\n\nI would suggest language like this \n\n> The return value is `true` if the internal buffer does not exceed `highWaterMark` configured when the stream was created after admitting `chunk`.  If `false` is returned, further attempts to write data to the stream should be paused until the `'drain'` event is emitted. However, the `false` return value is only advisory and the writable stream will unconditionally accept `chunk` even if it has not not been allowed to drain.\n",
        "labels": "doc",
        "id": 44572
    },
    {
        "title": "Support Let's Encrypt in core",
        "body": "Mozilla annouced their [intent to deprecate http](https://blog.mozilla.org/security/2015/04/30/deprecating-non-secure-http/) over year and a half ago. Chrome plans to [limit new features to https](https://www.chromium.org/Home/chromium-security/deprecating-powerful-features-on-insecure-origins) and [mark http as non-secure](https://www.chromium.org/Home/chromium-security/marking-http-as-non-secure). Having a https site will only get more and more important in the future and with browsers pushing https everywhere, I expect it will be essential for most Node users who who run a server.\n\nNative Let's Encrypt support would make the complicated process of getting a certificate super easy.\n",
        "labels": "doc",
        "id": 44573
    },
    {
        "title": "doc: `process` formatting issues",
        "body": "- **Version**: master, v6.x\n- **Platform**: n/a\n- **Subsystem**: doc\n\nI noticed there are some markdown formatting issues with the `process` documentation:\n- There is a missing backtick in the description for [`process.setuid()`](https://github.com/nodejs/node/blob/50be885285c602c2aa1eb9c6010cb26fe7d186ff/doc/api/process.md#processsetuidid) after `process.setuid(id)`.\n- There are some missing link references: [here](https://github.com/nodejs/node/blob/50be885285c602c2aa1eb9c6010cb26fe7d186ff/doc/api/process.md#event-beforeexit) (`process.exitCode`), [here](https://github.com/nodejs/node/blob/50be885285c602c2aa1eb9c6010cb26fe7d186ff/doc/api/process.md#event-exit) (`process.exitCode`), and [here](https://github.com/nodejs/node/blob/50be885285c602c2aa1eb9c6010cb26fe7d186ff/doc/api/process.md#processrelease) (`LTS`).\n- In the [`process.release` section](https://github.com/nodejs/node/blob/50be885285c602c2aa1eb9c6010cb26fe7d186ff/doc/api/process.md#processrelease), there are some instances of markdown underscores for italicization showing up literally in file names/extensions: `_.tar.gz_` (2) and `_node.lib_` (1). I think if the underscores are moved right outside the backticks, the italics _should_ render correctly.\n",
        "labels": "doc",
        "id": 44574
    },
    {
        "title": "stdout, stderr and stdin are all Duplex streams but documentation states otherwise",
        "body": "- **Version**: 6.x latest (tested on 6.9.1, 6.8.1)\n- **Platform**:  Linux 3.10.0-327.28.3.el7.x86_64\n\nDocumentation define stdin as readable stream and stdout, stderr  as writable streams -\n\nhttps://nodejs.org/api/process.html\n\n> The process.stderr property returns a Writable stream equivalent to or associated with stderr (fd 2).\n> ...\n> The process.stdin property returns a Readable stream equivalent to or associated with stdin (fd 0).\n> ...\n> The process.stdout property returns a Writable stream equivalent to or associated with stdout (fd 1).\n\nBut the actual Implementation is of a Duplex stream -\n\n``` javascript\nconst Stream = require('stream');\n['stdin', 'stdout', 'stderr'].forEach((prop) => {\n    ['Duplex', 'Writable', 'Readable'].forEach((instance) => {\n        console.log(prop, `is`, instance, process[prop] instanceof Stream[instance]);\n    });\n});\n```\n\nUsing a unidirectional stream seems like the obvious choice but if this is not possible for some reason the documentation should be fixed.\n\nThis is a bit more annoying with node 4.x (I checked on v4.6.1) since Duplex stream do not extend Writable ones so this will actually evaluate to false -\n\n``` javascript\nprocess.stdout instanceof Stream.Writable\n```\n\nDocumentation doesn't mention stream type for v4.x but if the type cannot be changed from Duplex maybe it should mention that since this can cause some confusion\n",
        "labels": "doc",
        "id": 44575
    },
    {
        "title": "Incorrect documentation or bug in Node",
        "body": "Per this documentation: https://nodejs.org/dist/latest-v4.x/docs/api/buffer.html#buffer_class_method_buffer_from_array\n![image](https://cloud.githubusercontent.com/assets/781818/19485373/032d24e6-9529-11e6-9514-eb476ecb7084.png)\n\n`Buffer.from(array)` was added in v3.0. However, this example (taken from docs) fails in Node v4.2.3 and Node v4.4.4\n\n```\nconst buf = Buffer.from([0x62,0x75,0x66,0x66,0x65,0x72]);\n  // creates a new Buffer containing ASCII bytes\n  // ['b','u','f','f','e','r']  <-- fails in Node < v4.5.0 \n\n\n// error\nTypeError: this is not a typed array.\n   at Function.from (native)\n   at repl:1:20\n   at REPLServer.defaultEval (repl.js:262:27)\n   at bound (domain.js:287:14)\n   at REPLServer.runBound [as eval] (domain.js:300:12)\n   at REPLServer.<anonymous> (repl.js:431:12)\n   at emitOne (events.js:82:20)\n   at REPLServer.emit (events.js:169:7)\n   at REPLServer.Interface._onLine (readline.js:211:10)\n   at REPLServer.Interface._line (readline.js:550:8)\n```\n\nNow as per latest docs: https://nodejs.org/api/buffer.html#buffer_class_method_buffer_from_array, our friend seems to have been \"added in v5.10.0\"\n\n![image](https://cloud.githubusercontent.com/assets/781818/19485637/a3ee3280-9529-11e6-8db5-5f937425222f.png)\n\nAnd rightfully so, fails in v5.0.0\n\n```\nÎ» rpm-extract â†’ Î» git master* â†’ node -v\nv5.0.0\nÎ» rpm-extract â†’ Î» git master* â†’ node\n> console.log(Buffer.from([0x62,0x75,0x66,0x66,0x65,0x72]))\nTypeError: this is not a typed array.\n    at Function.from (native)\n    at repl:1:20\n```\n\nSo, my question is:\n- Documentation is inconsistent and misleading.\n- I want to support node v4 and v6. But this intermittent behavior will cause unwanted issues for consumers who are on > 4.0 and < 5.10.0 . What's the best way to handle this?\n\nAll the tests were done using nvm on a 64 bit OSX El Capitan.\n",
        "labels": "doc",
        "id": 44576
    },
    {
        "title": "Mention case-insensitivity in process.env docs",
        "body": "On Windows OS, environment variables are case-insensitive.\n\n```\n14:46 $ node\n> process.env.foo = \"lol\"\n'lol'\n> process.env.fOo\n'lol'\n```\n\nI think it could be beneficial to make a note about this in the docs.\n",
        "labels": "doc",
        "id": 44577
    },
    {
        "title": "`exec` and `execSync` `git clone private_repo` + timeout hangs the REPL",
        "body": "- **Version**: v6.7 (also v5.12)\n- **Platform**: Linux #138-Ubuntu SMP Fri Jun 24 17:00:34 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\n**Expected behavior**: REPL resumes working\n**Actual behavior**: Process hangs\n\nDescription:\nWhen git cloning a repo that requires entering a username and password in `child_process.exec` or `child_process.execSync` and hitting a `timeout`  then the program and shell will hang. I've tried this on multiple machines. Here is repro code that uses a private repo of mine (notice how it asks for the username and then the program and shell hangs):\n\n``` js\n> child_process.execSync('git clone https://github.com/amasad/repl-it-web', { timeout: 1000, stdio: ['ignore']})\nUsername for 'https://github.com': Error: spawnSync /bin/sh ETIMEDOUT\n    at exports._errnoException (util.js:893:11)\n    at spawnSync (child_process.js:448:20)\n    at Object.execSync (child_process.js:504:13)\n    at repl:1:15\n    at REPLServer.defaultEval (repl.js:270:27)\n    at bound (domain.js:287:14)\n    at REPLServer.runBound [as eval] (domain.js:300:12)\n    at REPLServer.<anonymous> (repl.js:439:10)\n    at emitOne (events.js:95:20)\n    at REPLServer.emit (events.js:182:7)\n```\n\nNote that if I `pkill node` from another shell then the shell starts working again. \n",
        "labels": "doc",
        "id": 44578
    },
    {
        "title": "doc: typo in http doc",
        "body": "- **Version**: v4.x/v6.x/master\n- **Platform**: n/a\n- **Subsystem**: doc\n\nThe `http` documentation has [a typo](https://github.com/nodejs/node/blob/52c7f9d22115a3ab7174654cc61c9e34335246e2/doc/api/http.md#event-connect) in the `'connect'` event description. Specifically,\n\n```\nA client server pair that show you how to listen for the `'connect'` event.\n```\n\nshould instead read something like:\n\n```\nA client and server pair that shows you how to listen for the `'connect'` event:\n```\n",
        "labels": "doc",
        "id": 44579
    },
    {
        "title": "watch always fires rename event",
        "body": "- **Version**: v6.5.0\n- **Platform**: 64-bit Windows 10\n- **Subsystem**: fs\n\nRunning the below code, the eventType will always be `rename` whether I delete, add file...:\n\n```\nfs.watch(watchDir, (eventType, fileName) => {\n    console.log(eventType);\n});\n```\n",
        "labels": "doc",
        "id": 44580
    },
    {
        "title": "SIGINT and loops",
        "body": "Version: v4.2.6\nPlatform: x86_64 GNU/Linux\n\nI don't think this is a bug but some kind of advice would be nice in the documentation of process.on() in the future. Please, consider it.\n\nIf your script is structured following the design of a C program, chances are you may have a main loop similar to this:\n\n```\nwhile (true)\n{\n    // Your program\n}\n```\n\nIf you suddenly need to do something on SIGINT, you may do this:\n\n```\nprocess.on(\"SIGINT\", function () {\n    // remove incomplete output files because user interrupted the script with CTRL+C\n    process.exit();\n});\n\nwhile (true)\n{\n    // Your program\n}\n```\n\nThis results in two issues:\n1- As noted in documentation, node does not exit when you assign a listener to SIGINT, you must call process.exit() if you want to exit, but...\n2- when you are inside the while loop, the event isn't triggered. Resulting in the script trapped in the loop and with no nice way of stopping. User must kill the process: close terminal, use Gnome System Monitor, send a SIGKILL (to node process) from pkill or similar commands.\n\nI solved it and achieved the behavior I need by changing the while loop to this:\n\n```\nvar interval = setInterval (function () {\n    // Your program\n}, 0);\n```\n\nSimilar to what you may do with javascript in client side code in a web browser to simulate a main loop.\n\nThis way, when user hits CTRL+C the event handler executes as expected.\n\nThis is not a bug, just how javascript code is executed, but if you don't know at the moment what happens when you register a listener for SIGINT you may expect that it works even while your program is inside a loop.\n\nIt took me a while to realize why CTRL+C wasn't working so I'm leaving this here.\n",
        "labels": "doc",
        "id": 44581
    },
    {
        "title": "tls.createServer secureOptions",
        "body": "I was looking for a way to limit the versions of TLS that are supported, and I came across the `secureOptions` in the `tls.createServer` [method](https://nodejs.org/api/tls.html#tls_tls_createserver_options_secureconnectionlistener) that appears to do exactly that. \n\nHowever, I noticed that the documentation doesn't reference this option. Is this something that a pull request to modify the docs would be appropriate, or is this something that you all intend to deprecate/remove in the near-future?\n",
        "labels": "doc",
        "id": 44582
    },
    {
        "title": "openssl list-public-key-algorithms on crypto docs",
        "body": "According with [docs](https://github.com/nodejs/node/blob/v6.7.0/doc/api/crypto.md#cryptocreateverifyalgorithm) `openssl list-public-key-algorithms` shows the available signing algorithms, but isn't very helpfull, in fact I'm still unable to figure out which parameter to pass to `crypto.createVerify(algorithm)` :cry: \n\nBy the way, on openssl 1.1.0b does not exists that command:\n\n``` bash\n$ openssl version\nOpenSSL 1.1.0b  26 Sep 2016\n$ openssl list-public-key-algorithms\nInvalid command 'list-public-key-algorithms'; type \"help\" for a list.\n$ openssl list -public-key-algorithms\nName: OpenSSL RSA method\n    Type: Builtin Algorithm\n    OID: rsaEncryption\n    PEM string: RSA\nName: rsa\n    Alias for: rsaEncryption\nName: OpenSSL PKCS#3 DH method\n    Type: Builtin Algorithm\n    OID: dhKeyAgreement\n    PEM string: DH\n...\n```\n",
        "labels": "doc",
        "id": 44583
    },
    {
        "title": "doc: Confusion about transform stream constructor options",
        "body": "The doc about transform stream says that the options object for the constructor can take the [following arguments](https://nodejs.org/api/stream.html#stream_new_stream_transform_options):\n- `options <Object>` Passed to both Writable and Readable constructors. Also has the following fields:\n  - `transform <Function>` Implementation for the stream._transform() method.\n  - `flush <Function>` Implementation for the stream._flush() method.\n\nBut right above that section [is an example](https://nodejs.org/api/stream.html#stream_object_mode_duplex_streams) where different options are used:\n\n``` js\nconst Transform = require('stream').Transform;\n\nconst myTransform = new Transform({\n  writableObjectMode: true, // <- This here\n\n  transform(chunk, encoding, callback) {\n    //...\n  }\n});\n```\n\nBeing new to streams, I'm unsure wether this is a simple error in the docs or not. Probably not a reference but the typescript bindings only allow both the `transform`and `flush` function as properties on the options object.\n\nIf this is just a simple error, I'm happy to update both the docs and the typescript bindings. I have enough time to kill this weekend.\n",
        "labels": "doc",
        "id": 44584
    },
    {
        "title": "Buffer.toString docs != actual",
        "body": "- **Version**: v6.7.0\n- **Platform**: Win10 x64 v1511 \n\naccording to the docs\n\n``` js\nconst buf2 = Buffer.from('tÃ©st');\n\n// Prints: tÃ©s\nconsole.log(buf2.toString('utf8', 0, 3));\n```\n\nthe actual output is\n\n```\ntÃ©\n```\n",
        "labels": "doc",
        "id": 44585
    },
    {
        "title": "Examples in debugger documentation should all use global node",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n\n<!-- Enter your issue details below this comment. -->\n\nThe examples in the documentation for the debugger `doc/api/debugger.md` should all use `node`  instead of `./node`. \n",
        "labels": "doc",
        "id": 44586
    },
    {
        "title": "url.resolve() behaves differently depending on the protocol of the base url",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v4.5.0, v6.7.0\n- **Platform**: Linux 3.16.0-76-generic x86_64, Linux 4.7.6-1-ARCH x86_64, FreeBSD 10.1-RELEASE-p26 amd64\n- **Subsystem**: url\n\n<!-- Enter your issue details below this comment. -->\n\nThe `url.resolve()` function behaves differently depending on the protocol given in the `from` parameter.\nSee this example:\n\n``` js\n> var url = require(\"url\");\nundefined\n> url.resolve(\"https://foo.tld\", \"bar\");\n'https://foo.tld/bar'\n> url.resolve(\"wss://foo.tld\", \"bar\");\n'wss://bar'\n> url.resolve(\"ftps://foo.tld\", \"bar\");\n'ftps://bar'\n```\n\nWhen reading this function's [documentation](https://nodejs.org/api/url.html#url_url_resolve_from_to), this is not a behavior that I could foresee. I would have expected `'wss://foo.tld/bar'` and `'ftps://foo.tld/bar'` as results of the last two calls respectively.\n",
        "labels": "doc",
        "id": 44587
    },
    {
        "title": "Ship manpages for all core modules",
        "body": "It would be super neat if all the Node core modules shipped manpages. E.g. the HTTP module would have a corresponding `node-http(3)` manpage. (Is section 3 the most appropriate? It's for library _calls_, so I'm not sure. Let's bikeshed.) In particular this is useful for working offline - I suspect a lot of distributions of Node don't ship the HTML docs. I know my Homebrew install sure didn't install them.\n\nI'm totally willing to put together a PR adding a build process for these, but I wanted to double-check that such a PR would be accepted.\n",
        "labels": "doc",
        "id": 44588
    },
    {
        "title": "doc: explain why we don't use the GitHub merge button",
        "body": "I get asked why we can't use the GitHub merge button at onboardings from time to time and I never know what issues with it are real and what I merely imagine.\n\nonboarding.md currently says:\n\n> - Please never use GitHub's green \"Merge Pull Request\" button.\n>   - If you do, please force-push removing the merge.\n\nAnd that's it. One or two sentences explaining the deal-breaker incompatibilities with our workflow would be great. @cjihrig? Someone else?\n",
        "labels": "doc",
        "id": 44589
    },
    {
        "title": "doc: dead external link in fs.md",
        "body": "The link to http://www.linux.org/threads/intro-to-inodes.4130 added in #6099 seems to have linkrotted.\n",
        "labels": "doc",
        "id": 44590
    },
    {
        "title": "Add Locki to API documentation",
        "body": "We do no currently have localizations for API documentation.\n\nThe system we use for the regular website is pretty heavy, doesn't port very well, and isn't very tolerant of regular changes.\n\nLocki is a new service for creating a localization community and managing the translations.\n\nHere is their URL: https://locki.io\n\n/cc @chikathreesix who runs the service and can answer any questions or concerns people have.\n",
        "labels": "doc",
        "id": 44591
    },
    {
        "title": "`fs.rmdir()` on file (not directory) has \"ENOTDIR\" on Linux/macOS vs \"ENOENT\" on Windows",
        "body": "- **Version**: 6.6.0\n- **Platform**: Darwin fulmen.local 16.1.0 Darwin Kernel Version 16.1.0: Mon Sep 12 19:36:59 PDT 2016; root:xnu-3789.20.43~78/RELEASE_X86_64 x86_64\n- **Subsystem**: \"fs\" module\n\nJust noticed an inconsistency between Windows and everything else (why, Windows, why?!) for the `fs.rmdir()` and `fs.rmdirSync()` built-in functions.\n\n``` js\nconst fs = require('fs')\nconst path = require('path')\n\nfs.rmdirSync(__filename)\n```\n\n~~Assuming you save this to a file and `node` it, this file deletes itself on Windows _instead_ of throwing an error as on Linux and macOS.~~\n\nNote that `fs.unlink()` and `fs.unlinkSync()` consistently result in Errors if used on a directory's path.\n\n**Update**: the snippet results in an \"ENOENT\" error on Windows, instead of an \"ENOTDIR\" error as on Linux / macOS\n",
        "labels": "doc",
        "id": 44592
    },
    {
        "title": "doc: guide/topic on how to use streams",
        "body": "From the discussion at NIEU2016 it emerged that the streams docs is not user friendly, and too focused on people that already know how to compose applications using streams. They describe the API, not how to use node streams in practice. In particular, it does not highlight the use of \"streams modules\": through2, from2, flush-write-stream, split2, pump, end-of-stream, duplexify, bl, etc.. and most of the things that are exposed via  https://github.com/maxogden/mississippi. Moreover, it does not clarify how the API exposed to core fits in the picture, and how to build applications on streams.\n\nThe work done by @substack on the streams handbook is a great starting point: https://github.com/substack/stream-handbook.\n\ncc @nodejs/streams @nodejs/documentation   \n",
        "labels": "doc",
        "id": 44593
    },
    {
        "title": "fs.utimes arguments documentation",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.5.0\n- **Platform**: Linux dell 4.4.20-1-MANJARO #1 SMP PREEMPT Wed Sep 7 19:11:34 UTC 2016 x86_64 GNU/Linux\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nCould the documentation of `fs.utimes` (It says the type is Integer, and NaN or Infinity, will be converted to `Date.now()`) be more clear about the arguments? It looks like I can pass `new Date()`, but `Date.now()` needs to be divided by 1000. According to MDN `Date.prototype.valueOf()` and `Date.now()` both return: \"The number of milliseconds between 1 January 1970 00:00:00 UTC and the given date.\". It would be nice if the documentation mentioned that if the value is an Integer, it will be handled as a timestamp with precision of seconds.\n\n```\nvar fs = require('fs');\n\nfs.writeFileSync('test.txt', 'abc');\nconsole.log('    ok', fs.statSync('test.txt').atime.getTime());\n\nfs.utimesSync('test.txt', new Date(), new Date());\nconsole.log('    ok', fs.statSync('test.txt').atime.getTime());\n\nconsole.log('    ok', Date.now());\n\nfs.utimesSync('test.txt', Date.now(), Date.now());\nconsole.log('not ok', fs.statSync('test.txt').atime.getTime());\n\nfs.utimesSync('test.txt', Date.now() / 1000, Date.now() / 1000);\nconsole.log('    ok', fs.statSync('test.txt').atime.getTime());\n```\n\nOutput\n\n```\n    ok 1474133782000\n    ok 1474133783000\n    ok 1474133783702\nnot ok 1474133783702000\n    ok 1474133783000\n```\n",
        "labels": "doc",
        "id": 44594
    },
    {
        "title": "Buffer.from(str, encoding) silently ignores decoding errors",
        "body": "- **Version**: Node v6.5.0\n- **Platform**: OS X 10.11\n- **Subsystem**: Buffer\n\n<!-- Enter your issue details below this comment. -->\n\n`Buffer.from` silently ignores decoding errors.\n\n``` javascript\nBuffer.from('aGVsbG8=', 'base64') // valid base64 string\n// => hello\nBuffer.from('aGV     sbG8=', 'base64') // invalid base64 string\n// => hello\n```\n\nI know this is now the expected behavior but it would be useful, e.g. when writing parsers for strict protocols, to have a `Buffer.safeFrom` which throws on decoding errors. It could also be passed as a parameter, e.g.: `Buffer.from(str, [encoding, throwOnError])`.\n",
        "labels": "doc",
        "id": 44595
    },
    {
        "title": "readline doc: events are _not_ supported on Windows.",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v7.0.0-pre (master branch)\n- **Platform**: Windows 10 Pro with `Bash on Ubuntu on Windows`\n- **Subsystem**: readline\n\n<!-- Enter your issue details below this comment. -->\n\nNow with Bash on Windows, the events `SIGCONT` and `SIGTSTP` are supported. Should we change the **Notes**  to be more specific ?\n- https://github.com/nodejs/node/blob/master/doc/api/readline.md#event-sigcont\n- https://github.com/nodejs/node/blob/master/doc/api/readline.md#event-sigtstp\n",
        "labels": "doc",
        "id": 44596
    },
    {
        "title": "help() or similar for the REPL",
        "body": "Hi, carrying this over from https://github.com/nodejs/node-v0.x-archive/issues/3916 (at least if Iâ€™m understanding it rightâ€¦?).\n\nIt would be pretty cool to have something like Pythonâ€™s `help()` for the REPL, where things like `help(list)` just show you the documentation for the `list` object/type/whatever.\n\nWe could probably include a gzipped copy of Nodeâ€™s own API docs in some format in the executable, that should not be more than a few hundred kB (213 kB for the current gzipped markdown, 544 kB for the current HTML docs).\n\nIâ€™m imagine weâ€™d want to add something like `util.help(obj)` which returns the docs for `obj`, or, if appropriate, `obj.constructor` (or a `Promise` for the docs? that might be a tad more generic).\n\nSome random thoughts:\n- I am not sure in what format the docs would best be displayed. Maybe using the markdown as it is would be a good start, since thatâ€™s essentially made for human readability â€“ some things like our links would be weird, though.\n- I would be in favour of exposing a `help` in the REPL, or maybe even supporting a tiny syntax extension like `? net.Server`.\n- I am not sure if the doctool has a role to play here. We would probably require some way of wiring up the doc sections with the corresponding objects, and they are clearly not in 1:1 relation.\n- We could, like Python does, display the docs for the methods of a given type, too. I.e., `help(net.Server)` would return the docs for everything on `net.Server.prototype`.\n- Again, like Python does (they _did_ a great job thereâ€¦), we could use `$PAGER` (aka `less` in 99Â % of cases) to display the help for things, at least when it would otherwise exceed one screen page.\n- We could make `util.help` extensible by the user like we do with `util.inspect`, by providing something like a `[util.customHelp]` Symbol property that they can attach. That propertyâ€™s value could be a string or a function returning a string with the docs for it.\n- Maybe â€“ this may be a lot harder but it could also be really _really_ awesome â€“ MDN docs for the types native to JS. That would probably require putting them in a separate package of some sort but it would be cool if the REPL had some way of knowing where to look for that.\n\n/cc @princejwesley @nodejs/documentation \n",
        "labels": "doc",
        "id": 44597
    },
    {
        "title": "How do I implement `MyObject.inspect(depth, inspectOpts)`?",
        "body": "I want to implement inspect for my own object. I want to mostly follow the semantics of `inspect` for non-custom implementations, but just by going by the documentation alone, I have no possible way of doing so. What conventions are there? How do I recursively call `inspect` while respecting depth? Do I need to handle the case of depth being null?\n\nThe [example](https://nodejs.org/api/util.html#util_custom_inspect_function_on_objects) ignores the parameters passed to it completely currently. Maybe if we had an example of a `Box` object that inspects as `\"Box<InnerInspectValue>\"` so e.g. `inspect({value: \"a\", inspect: ... })` returns `\"Box<'a'>\"` but the value can be anything (including over objects with custom inspect impls).\n",
        "labels": "doc",
        "id": 44598
    },
    {
        "title": "Reccomend allowing edits from maintainers in issue templates / Contributing.md?",
        "body": "See https://github.com/blog/2247-improving-collaboration-with-forks\n\nI wonder if we shouldn't recommend this new option\n",
        "labels": "doc",
        "id": 44599
    },
    {
        "title": "Node 6.5 fails when using --harmony-proxies flag",
        "body": "```\n$ node --version                  \nv6.5.0\n$ node --harmony_proxies          \nnode: bad option: --harmony_proxies\n$ nvm use 6.4\nNow using node v6.4.0 (npm v3.10.3)\n$ node --version        \nv6.4.0\n$ node --harmony_proxies\n> \n```\n\nI originally found this while doing a Travis build.\nhttps://travis-ci.org/IBM-Bluemix/logistics-wizard-webui/builds/156878342\n",
        "labels": "doc",
        "id": 44600
    },
    {
        "title": "Number of processes used by 'make' should not be specified in documentation",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- v6.4.0\n- Darwin 14.5.0\n- doc\n\n<!-- Enter your issue details below this comment. -->\n\nIn several of the documentation files, the number of simultaneous jobs is specified by the -j option and the number varies between files.  According to the 'make' man page, \"If the -j option is given without an argument, make  will  not  limit the number of jobs that can run simultaneously.\"  The documentation should just have a '-j' without a number, so as to remain system-agnostic.\n\nThe files in which this issue resides are as follows:\n\nhttps://github.com/nodejs/node/blob/master/doc/onboarding.md\nhttps://github.com/nodejs/node/blob/master/doc/onboarding-extras.md\nhttps://github.com/nodejs/node/blob/master/doc/guides/building-node-with-ninja.md\nhttps://github.com/nodejs/node/blob/master/CONTRIBUTING.md\nhttps://github.com/nodejs/node/blob/master/.github/PULL_REQUEST_TEMPLATE.md\n",
        "labels": "doc",
        "id": 44601
    },
    {
        "title": "Docs: Further improvements to Addon section, specifically numeric and binary IO",
        "body": "Asking about IO between C++ and JavaScript has been a common theme to the issues I have opened. I have had some questions answered before, and prompted some discussions on what kind of documentation is best. See:\n\nhttps://github.com/nodejs/node/issues/883\nhttps://github.com/nodejs/node/issues/2977\nhttps://github.com/nodejs/node/issues/3296\n\nI have done some work on examples that show the interface between C++ and node.js by internally performing the simple operation of adding one to a number. I now wish to make it output a Float64Array, but have not seen example code of how to do it, nor got it work when I tried to make one in C++ using V8.\n\nHere is the beginnings of some code which could be of use within the node documentation to demonstrate the outputting of Typed Arrays from C++: https://github.com/metabench/addone/tree/typed_arrays\n\nIn order to help developers make use of C++ for more numerically or computationally intensive tasks, it's worth improving the documentation (lowering the learning curve) for the most efficient types of IO between C++ and JavaScript.\n",
        "labels": "doc",
        "id": 44602
    },
    {
        "title": "buf.readUIntBE and buf.readUIntLE documentation examples are switched",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.4.0\n- **Platform**: Linux x260 4.6.5-200.fc23.x86_64 #1 SMP Thu Jul 28 01:10:25 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nThe documentation at https://nodejs.org/api/buffer.html#buffer_buf_readuintbe_offset_bytelength_noassert has a few examples, reproduced in part here:\n\n```\nconst buf = Buffer.from([0x12, 0x34, 0x56, 0x78, 0x90, 0xab]);\n\n// Prints: 1234567890ab\nconsole.log(buf.readUIntLE(0, 6).toString(16));\n\n// Prints: ab9078563412\nconsole.log(buf.readUIntBE(0, 6).toString(16));\n```\n\nHowever, the comments describing the output are the opposite of what they should be. The LE example outputs \"ab9078563412\" whereas the BE example outputs \"1234567890ab\".\n",
        "labels": "doc",
        "id": 44603
    },
    {
        "title": "Fix or Mark apis in the documentation that cannot be try/catch/promised",
        "body": "Certain library objects that extend EventEmitter emits error on callback that are not caught by a try/catch or Promise. If it is not possible to address this in code somehow, those objects and methods should be marked in the documentation as requiring an error listener.\n\nIMPACT:\nNode.js throws uncaught exception in edge-case situations\n\nExample 1: failing dns request\n\n``` javascript\nnode --eval \"new Promise(r => new (require('http').Server)().listen(0, '#$%'))\"\nevents.js:160\n      throw er; // Unhandled 'error' event\n      ^\n\nError: getaddrinfo ENOTFOUND #$%\n    at errnoException (dns.js:28:10)\n    at GetAddrInfoReqWrap.onlookup [as oncomplete] (dns.js:79:26)\n```\n\nExample 2: failed spawn\n\n``` javascript\nnode --eval \"new Promise(r => require('child_process').spawn('error factory'))\"\nevents.js:160\n      throw er; // Unhandled 'error' event\n      ^\n\nError: spawn error factory ENOENT\n    at exports._errnoException (util.js:1026:11)\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:182:32)\n    at onErrorNT (internal/child_process.js:348:16)\n    at _combinedTickCallback (internal/process/next_tick.js:74:11)\n    at process._tickCallback (internal/process/next_tick.js:98:9)\n```\n\n> uname --all && node --version\n> Linux c89 4.4.0-34-generic #53-Ubuntu SMP Wed Jul 27 16:06:39 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n> v6.4.0\n",
        "labels": "doc",
        "id": 44604
    },
    {
        "title": "Inaccurate Documentation?",
        "body": "- **Version**: 6.3.1\n- **Platform**: OSX (10.11.3)\n\nAccording to the [documentation](https://nodejs.org/api/net.html#net_event_end), a TCP socket's `end` event is fired when it receives a FIN packet. However, it seems that something else is also causing the event to fire off.\n### Here's my test.\n##### Server\n\n``` js\nvar net = require('net');\nnet.createServer(function () {}).listen(9000);\n```\n##### Client\n\n``` js\nvar net = require('net');\nvar socket = net.connect(9000, 'localhost');\nsocket.on('connect', function () {console.log('connected!')});\nsocket.on('error', function () {console.log('error!')});\nsocket.on('end', function () {console.log('FIN packet received!')});\nsocket.on('close', function () {console.log('closed!')});\n```\n\nThen, I start the server, start the client, and then **force kill** (SIGKILL) the server.\n\nThis is what I see in the client terminal:\n\n```\nFIN packet received!\nclosed!\n```\n\nClearly, the server could not have sent a FIN packet if it was force-killed. So something else must be triggering the `end` event on the client. Whatever it is, it's not documented. Any ideas?\n",
        "labels": "doc",
        "id": 44605
    },
    {
        "title": "TypeError: Forked processes must have an IPC channel",
        "body": "v.6.4.0\nDarwin MacBook-Pro.local 14.5.0 Darwin Kernel Version 14.5.0: Tue Sep  1 21:23:09 PDT 2015; root:xnu-2782.50.1~1/RELEASE_X86_64 x86_64\n\nI think this is my error, but maybe something to document?\n\nAfter upgrading from 6.3 -> 6.4 `fork` will not accept the following:\n\n```\nfork('...', [], {\n    stdio: [0,1,2] \n});\n```\n\nRequiring:\n\n```\nfork('...', [], {\n    stdio: [0,1,2,'ipc']\n});\n```\n\n_Not_ setting `stdio` also works...\n",
        "labels": "doc",
        "id": 44606
    },
    {
        "title": "False successfully end of request",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v4.4.0\n- **Platform**: `Linux robin-master 3.19.0-15-generic #15-Ubuntu SMP Thu Apr 16 23:32:37 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux`\n- **Subsystem**: http\n\n<!-- Enter your issue details below this comment. -->\n\nLong client requests ends successfully if data transfer closed for some reason, for example if server lost connectivity or suddenly fall.\nFor example I have one client Node.js app which make request to server Node.js app to receive a lot of chunks of data. Data transfer lasts for several time and server app falls before request completion.\nI expect to get some error on client side to inform me that transfer was not successfully ended, but emits `end` event instead of `error`. So I have a situation when I receive only part of data but don't know about it and think that request successfully ended.\n\nExample server send parts of JSON object for ~2 seconds. For test purpose I run following shell command:\n\n``` shell\ntimeout 1s node server.js & node client.js\n```\n\nBecause data transfer lasts 2 seconds client app receive only part of data but ends with emit `end` handler without any error. May be problem on `clientRequest` part of Node.js cause the same trick with `curl` as client side return `(18) transfer closed` error.\n\nExample of client app:\n\n``` javascript\nvar http = require('http');\n\nvar makeRequest = function() {\n    var req = http.request({\n        host: '127.0.0.1',\n        port: 8080,\n        method: 'POST',\n    }, function(res) {\n        var data = '';\n        res.on('data', function(chank) {\n            data += chank;\n        });\n\n        res.on('end', function() {\n            console.log('data', data);\n            console.log('succesfull end');\n        });\n\n        res.on('error', function(err) {\n            console.error(err);\n        });\n    });\n\n    req.on('error', function(err) {\n        console.error(err);\n    });\n\n    req.write('');\n    req.end();\n};\n\nsetTimeout(makeRequest, 100);\n```\n\nExample of server app\n\n``` javascript\nvar http = require('http');\n\nvar server = http.createServer();\nserver.on('request', function (req, res) {\n\n    res.write('{\"result\":[{\"some\": \"object\"}');\n\n    // it must send data pieces for ~2 sec (20*100 ms = 2000 ms) \n    var times = 20;\n    var delay = 100;\n\n    var counter = 0;\n    var timerId = setInterval(function() {\n        res.write(',{\"some\": \"object\"}');\n\n        counter++;\n        if (counter >= times) {\n            res.write(',{\"some\": \"object\"}');\n            res.write(']}');\n            res.end();\n            clearInterval(timerId);\n        }\n    }, delay);\n});\n\nvar port = 8080;\nserver.listen(port, function() {\n    console.log('listen on 127.0.0.1:' + port);\n});\n```\n",
        "labels": "doc",
        "id": 44607
    },
    {
        "title": "Error at code example of Duplex Stream in Docs",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.3.1\n- **Platform**: all\n- **Subsystem**: Duplex, Docs\n\n<!-- Enter your issue details below this comment. -->\n\nThis is the code snippet of code example of Duplex Stream in Docs.\n\n```\n  _write(chunk, encoding, callback) {\n    // The underlying source only deals with strings\n    if (Buffer.isBuffer(chunk))\n      chunk = chunk.toString(encoding);\n    this[kSource].writeSomeData(chunk, encoding);\n    callback();\n  }\n```\n\nIf incoming `chunk` is an instance of Buffer, then `encoding` argument  is supposed to be `'buffer'` rather than String encoding types. So in this example, `'buffer'` is passed as `encoding` into `toString()` and `writeSomeData()` methods instead of desired string encoding.\n",
        "labels": "doc",
        "id": 44608
    },
    {
        "title": "console.log calls inspect function on passed object",
        "body": "Version: v6.3.1\nPlatform: any\n\nCode...\n\n``` js\nconsole.log({\n    inspect: function () {\n        return 123;\n    },\n});\n```\n\n...will print:\n\n```\n123\n```\n\nThat's because `console.log` is using under the hood [util.inspect](https://nodejs.org/api/util.html#util_util_inspect_object_options) which apparently will call `inspect` method on given object if finds one. \n\nThis behaviour is very suprising and looks like a bug to someone who didn't read that particular doc. As a matter of fact I also [maintain library](https://github.com/szwacz/fs-jetpack) which has `inspect` method as part of its API. So doing console.log(myLib) will lead to obscure error.\n\n**Solution?**\nBoth APIs [console](https://nodejs.org/api/console.html) and [util](https://nodejs.org/api/util.html) have status stable so I believe there is no way to alter this behaviour.\nBut how about starting favouring `toString` over `inspect`?\nSo this code...\n\n```\nconsole.log({\n    inspect: function () {\n        return 123;\n    },\n    toString: function () {\n        return 'foo';\n    },\n});\n```\n\n...will print `foo` instead of `123`.\n\nThen at least I'll be able to define `toString` method and avoid nasty error for the users of my library.\n",
        "labels": "doc",
        "id": 44609
    },
    {
        "title": "Suggestion: http doc should mention special handling for HEAD and 304",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 4.4.7 , 6.3.1\n- **Platform**: OS X\n- **Subsystem**: http\n\n<!-- Enter your issue details below this comment. -->\n\nI think it would be a good idea to mention in the official docs that the http module will ignore any response body if the incoming request is a HEAD request, and the same behavior for 304 responses.\n\nAnd any other special handling the http module does.\n\nReasoning is, I had no way of knowing if this was official behavior since it was undocumented, and when it first existed / introduced so I had to test it myself to see across a few node versions. So it would've saved me some time and others time in the future.\n\nIf it exists already, my apologies, I tried looking through the http doc but could not find a mention.\n",
        "labels": "doc",
        "id": 44610
    },
    {
        "title": "Should we include a downloadable archive of the documentation?",
        "body": "Trying to get a local copy of the docs is something I've seen pop up in https://github.com/nodejs/node/issues/7872 and in other issues as well.\n\nShould we include an archived version of the docs in our downloads directory? It seems like this might solve the problem that people are having with attempting to build the docs from the release tarball\n",
        "labels": "doc",
        "id": 44611
    },
    {
        "title": "docs(cluster): message event docs slightly wrong/confusing",
        "body": "From [Cluster > Event: 'message'](https://nodejs.org/dist/latest-v6.x/docs/api/cluster.html#cluster_event_message_1)\n\n> Emitted when any worker receives a message.\n\nI think this should say \"sends a message.\" See [gist](https://gist.github.com/zbjornson/a7ab0ec5ea34e40a8a5695c652a9e96b) -- when a worker receives a message from the master (which is how I read the docs currently), this is not triggered in either the worker or the master. It _is_ triggered in the master when a worker sends a message.\n\nHappy to PR if I'm not misunderstanding this.\n",
        "labels": "doc",
        "id": 44612
    },
    {
        "title": "Feature request: Generated Documentation for Reference - PDF and CHM formats",
        "body": "Hi,\n\nI like Node. Is it possible for NodeJS projects to provide users with additional download documentation in PDF or CHM format for carrying around in USB. \n\nIt would be convenient to study the docs whilst the internet are not always available somewhere else especially for new learners. They can mark up, comments within the PDF documentation.\n\nKind regards\n\nTN\n",
        "labels": "doc",
        "id": 44613
    },
    {
        "title": "Document process for Semver Major Changes and Deprecation Policy",
        "body": "It would be a good idea for us to document a policy for how Semver Major changes are landed and how deprecations are handled.\n\n@isaacs has offered to write some copy, which I think should live [in our collaborator guide](https://github.com/nodejs/node/blob/master/COLLABORATOR_GUIDE.md#landing-pull-requests)\n\n@nodejs/ctc please chime in with your thoughts on this.\n",
        "labels": "doc",
        "id": 44614
    },
    {
        "title": "6.3.1 src tarball: missing files and directories",
        "body": "https://nodejs.org/dist/v6.3.1/node-v6.3.1.tar.[gx]z source tar balls seems to be screwed up: e.g.\ntools/{osx-pkg.pmdoc,pkgsrc,eslint,eslint-rules}/ are missing, whereby at least the latter 2 in turn break doc building:\n\n```\nInput file = doc/api/os.md\nmodule.js:442\n    throw err;\n    ^\n\nError: Cannot find module '/export/scratch/build/node-v6.3.1/tools/eslint/node_modules/js-yaml'\n    at Function.Module._resolveFilename (module.js:440:15)\n    at Function.Module._load (module.js:388:25)\n    at Module.require (module.js:468:17)\n    at require (internal/module.js:20:19)\n    at Object.<anonymous> (/export/scratch/build/node-v6.3.1/tools/doc/node_modules/js-yaml/index.js:15:18)\n    at Module._compile (module.js:541:32)\n    at Object.Module._extensions..js (module.js:550:10)\n    at Module.load (module.js:458:32)\n    at tryModuleLoad (module.js:417:12)\n    at Function.Module._load (module.js:409:3)\n...\n```\n",
        "labels": "doc",
        "id": 44615
    },
    {
        "title": "docs: `fs.write()` variables are not clear",
        "body": "The docs for `fs.write()` state:\n\n```\noffset and length determine the part of the buffer to be written.\n```\n\n`offset` is clear, but one must assume that `length` has the same meaning as per `buffer.slice(offset, length)`, i.e. that `length` is not relative to `offset`, but rather an absolute index into buffer as is expected (e.g. `string.slice(offset, length)`). Therefore, if one wanted to write 5 bytes from offset 12 at position 1 in the file, one would use `offset=12`, `length=12+5`.\n\n```\n... (err, written, buffer) where written specifies how many bytes were written from buffer.\n```\n\nThis is not clear.\n\nI would probably guess that `written` is a quantity number, i.e. if the first call to `fs.write()` returned `written=2`, then I would think that a count of 2 bytes had been written. I would therefore expect that `fs.write(fd, buffer, offset=12, length=17, position=1)` would return `written=5` if everything was written out, and less than `5` if a partial write occurred.\n\nWhat actually happens is that `written=17` when the write is fully written out. This is very surprising. Furthermore, if `written` now represents an absolute index, is it an absolute index into the source buffer or an absolute index into the target file? If it is an absolute index into the target file, is it relative to `position` or not? It seems that `written` is actually then an absolute index relative to the source `buffer`?\n\nWhy is `buffer` returned in the write callback? Is this the same buffer I passed, or a slice? The docs should also make that clear.\n",
        "labels": "doc",
        "id": 44616
    },
    {
        "title": "deps: fix TODO in tools/icu/README.md",
        "body": "- **Subsystem**: deps\n\n<!-- Enter your issue details below this comment. -->\n\nFix TODO in https://github.com/nodejs/node/blob/master/tools/icu/README.md\n\nsmall-icu is the default now.\n",
        "labels": "doc",
        "id": 44617
    },
    {
        "title": "http.IncomingMessage omits events when aborted on client side ",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 6.3.0\n- **Platform**: Linux offline 3.19.0-64-generic #72-Ubuntu SMP Fri Jun 24 15:12:52 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**: http\n\n<!-- Enter your issue details below this comment. -->\n\nWhen a HTTP client sends a partial body and is then aborted, the corresponding server request object does not emit `end`, `close` or `aborted` events. Only a `clientError` is emitted on the server.\n\nI looked at the existing tests concerning request abortion and it seems this is the only case that is untested.\n\nThe following code reproduces the problem:\n\n``` js\n'use strict';\nconst http = require('http');\n\n\nconst server = http.createServer((request, response) => {\n  console.log('server request');\n\n  request.on('aborted', () => console.log('server request aborted'));\n  request.on('error', (err) => console.log('server request error', err));\n\n  request.on('readable', () => console.log('server request readable', request.read()));\n  request.on('end', () => console.log('server request end'));\n\n  request.on('close', () => {\n    console.log('server request close');\n    server.close();\n  });\n});\n\nserver.on('clientError', (err) => {\n  console.log('server clientError', err);\n});\n\nserver.listen(0, () => {\n  const port = server.address().port;\n\n  const request = http.request({\n    port: port,\n    path: '/',\n    method: 'PUT'\n  }, (response) => console.log('client response'));\n\n  request.on('abort', () => console.log('client abort'));\n  request.on('error', (err) => console.log('client error', err));\n\n  request.write('Test');\n\n  setTimeout(() => {\n    request.abort();\n  }, 100);\n});\n```\n\nThe output shows that the readable stream (`request`) is left waiting for the `end` event\n\n```\nserver request\nserver request readable <Buffer 54 65 73 74>\nclient abort\nserver clientError { Error: Parse Error\n    at Error (native)\n    at Socket.socketOnEnd (_http_server.js:422:22)\n    at emitNone (events.js:91:20)\n    at Socket.emit (events.js:185:7)\n    at endReadableNT (_stream_readable.js:973:12)\n    at _combinedTickCallback (internal/process/next_tick.js:74:11)\n    at process._tickCallback (internal/process/next_tick.js:98:9) bytesParsed: 0, code: 'HPE_INVALID_EOF_STATE' }\nclient error { Error: socket hang up\n    at createHangUpError (_http_client.js:252:15)\n    at Socket.socketCloseListener (_http_client.js:284:23)\n    at emitOne (events.js:101:20)\n    at Socket.emit (events.js:188:7)\n    at TCP._handle.close [as _onclose] (net.js:492:12) code: 'ECONNRESET' }\n```\n",
        "labels": "doc",
        "id": 44618
    },
    {
        "title": "HTTP Module Documentation Missing 'Error' Event",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 6.3.0\n- **Platform**: N/A\n- **Subsystem**: HTTP\n\n<!-- Enter your issue details below this comment. -->\n\nIn the documentation for the HTTP module, the `http.request()` method details reference an `'error'` event on the `http.ClientRequest` class. But the `ClientRequest` class does not have any documentation for such an event. It's not even listed.\n",
        "labels": "doc",
        "id": 44619
    },
    {
        "title": "Crypto - sign.update, verifier.update default parameter for strings 'utf8' not really true?",
        "body": "- **Version**:v4.4.5\n- **Platform**:Linux debian-john 3.16.0-4-586 #1 Debian 3.16.7-ckt25-2 (2016-04-08) i686 GNU/Linux\n- **Subsystem**:crypto\n\n<!-- Enter your issue details below this comment. -->\n\nIn the docs here:\nhttps://nodejs.org/api/crypto.html#crypto_sign_update_data_input_encoding\n\nIt states:\n\"If encoding is not provided, and the data is a string, an encoding of 'utf8' is enforced.\"\n\nI found if I didn't specify that parameter the calculated signature would be incorrect (not matching a standard implementation using Bouncy Castle crypto apis in Windows) if there were any unicode characters in the source string to be signed. \n\nIf I specified the parameter utf8 then it worked correctly both ways between Bouncy Castle's crypto apis in windows and Node crytpo under linux.\n\nSame issue with verifier.update was found as well.\n\nI suggest the docs should be updated to specify that it's (likely) binary by default if it's a string _or_ a buffer or the sign.update and verifier.update code changed to act as documented.\n\nHere is a snippet of code I was using for testing:\n var sign = crypto.createSign('RSA-SHA256');\n var testData = 'Ð§Ñ‚Ð¾ Ñ‚Ð°ÐºÐ¾Ðµ Unicode?';\nsign.update(testData,'utf8');//<<===== The 'utf8' parameter should not be necessary as this is a string according to the docs, but it definitely is necessary.\n",
        "labels": "doc",
        "id": 44620
    },
    {
        "title": ".getPeerCertificate() on https.request()",
        "body": "- **Version**:  v4.4.6\n- **Platform**: Linux xxx 3.16.0-76-generic #98~14.04.1-Ubuntu SMP Fri Jun 24 17:04:54 UTC 2016 \n- **Subsystem**: n/a\n\nHi \n\n.getPeerCertificate() does not returned fingerprint after first https.request(). It seems to be a problem with https.agent. If i set **agent** to **false** during https.request(opts) then i got correctly the fingerprint at each time.\n\nHere is an example:\n\n``` js\nconst https = require(\"https\");\n\nfunction request() {\n    var options = {\n        hostname: 'www.google.com',\n        port: 443,\n        path: \"/\",\n        method: 'GET',\n        // turning this to True makes fingerprint works again (agent's connections are closed);\n        //agent: false, \n        rejectUnauthorized: false\n    };\n\n    var req = https.request(options, (res) => {\n        res.fingerprint = res.connection.getPeerCertificate().fingerprint;\n        var data = '';\n        res.on('data', (d) => {\n            data += d;\n        });\n        res.on('end', () => {\n            console.log(\"got data\", res.fingerprint);\n            setTimeout(request, 1000);\n        });\n\n    }).on('error', (e) => {\n        console.error(e);\n    });\n    req.end();\n}\n\nrequest();\n```\n",
        "labels": "doc",
        "id": 44621
    },
    {
        "title": "CONTRIBUTING.md assumes UNIX-like OS",
        "body": "Section 5 includes text all about `make` but doesn't provide the Windows alternative `vcbuild` commands.\n\nGood first contribution...\n",
        "labels": "doc",
        "id": 44622
    },
    {
        "title": "repl: Undocumented public methods on REPLServer.prototype",
        "body": "There are a number of methods on `REPLServer.prototype` that are clearly available in userland but are not documented. In at least a few cases, my impression is that these methods are attached to the prototype primarily in order to facilitate testing. I think this situation is non-ideal.\n- **Version**: v6.2.2\n- **Platform**: Darwin Lances-MacBook-Pro.local 15.5.0 Darwin Kernel Version 15.5.0: Tue Apr 19 18:36:36 PDT 2016; root:xnu-3248.50.21~8/RELEASE_X86_64 x86_64\n- **Subsystem**: repl, doc\n\nI have seen similar discussions as a part of various issues regarding \"semi-private\" properties that begin with an underscore on various other modules - though typically those conversations are tangential to the real issue. \n\nThis issue is similar - publicly accessible but undocumented properties. The pattern is not limited to `REPLServer`, but since this is where I have spent most of my time in the code base, it's the one I'm most familiar with now, so for now, this conversation is limited to that module. However, I do think this should be discussed at a higher level and some guidance created for dealing with these \"leaks\".\n\nAs a rule, I would say that no methods should be attached to an object's `prototype` that are undocumented. But it's not clear how to best deal with existing concerns.\n\nHere is a list of the methods found on `REPLServer.prototype` that are currently undocumented, but are fully accessible in userland.\n\n```\nREPLServer.prototype.close // inherited from readline.Interface\nREPLServer.prototype.setPrompt // inherited from readline.Interface\nREPLServer.prototype.createContext\nREPLServer.prototype.resetContext\nREPLServer.prototype.complete\nREPLServer.prototype.parseREPLKeyword\nREPLServer.prototype.memory\nREPLServer.prototype.convertToContext\n```\n\nI can see why `close` and `setPrompt` may not be documented. Although, I think ideally some mention of them should be made in the REPL context since `REPLServer` provides custom implementations of these methods. In my opinion, the others, however, should be refactored in such a way that they are not accessible in userland, or they should be documented.\n",
        "labels": "doc",
        "id": 44623
    },
    {
        "title": "Clarify \"fs.readFile\", \"fs.appendFile\", \"fs.writeFile\" documentation regarding closing",
        "body": "\"https://nodejs.org/api/fs.html#fs_fs_readfile_file_options_callback\" states that\n\n> Note: Specified file descriptors will not be closed automatically.\n\nThis is confusing for new users, because it implies that opened file should always be manually closed, leading to questions like this - http://stackoverflow.com/questions/21523890/close-file-after-fs-readfile-nulling\n\nIt should be mentioned that if \"file\" is specified as a filename, it will, indeed, be closed automatically.\n",
        "labels": "doc",
        "id": 44624
    },
    {
        "title": "doc: search engine visibility for \"node guide\" pointing to outdated third party sites",
        "body": "> Since the docs working group, imo, stalled and this has big enough significance, I am posting this here.\n\nA lot of search configurations of \"node\" in conjunction with \"guide\" yield outdated and / or third party sites as top results. Especially to Felix's Node guide.\n\nAs per [discussion on twitter](https://twitter.com/felixge/status/748847073299206144) @felixge would donate the domain, if we had and maintain something better. Since the guides wanted to attempt this, but never have gotten into broader conceptual phase (let alone tooling), we would need to act first.\n\nIf possible I would like to bring this to the attention of @nodejs/collaborators as goal for the coming months. Cheers.\n",
        "labels": "doc",
        "id": 44625
    },
    {
        "title": "Incomplete FSWatcher documentation.",
        "body": "Only the `change` and `error` events are currently documented but there are other events, such as `rename`.\n\nSee: https://nodejs.org/docs/latest/api/fs.html#fs_event_change\n\nAlso, I don't quite understand why a git branch change would cause a rename on existing files â€“ anyone care to educate me? :)\n",
        "labels": "doc",
        "id": 44626
    },
    {
        "title": "process.argv[0] contains full node.exe path on Windows, docs say it must be just \"node\"",
        "body": "- **Version**: 4.4.6.0\n- **Platform**: Windows 7 Enterprise SP1\n- **Subsystem**: no idea\n\nDocumentation https://nodejs.org/api/process.html#process_process_argv says `process.argv[0]` must be `node` but I run this code on Windows\n\n```\nconsole.log('argv[0]: ' + process.argv[0]);\n```\n\nand it outputs this\n\n```\nargv[0]: C:\\Program Files (x86)\\nodejs\\node.exe\n```\n\nwhich kind of isn't the same as `node`. It was `node` on some earlier versions - perhaps a couple years ago.\n\nHere's how I run my code: I started `cmd.exe`, `cd`d into `C:\\Program Files (x86)\\nodejs`, so it's now the current path and I run\n\n```\nnode fullPathToJsFile\n```\n",
        "labels": "doc",
        "id": 44627
    },
    {
        "title": "Improving GitHub Issue template",
        "body": "Specifically, I'm referring to the 3 fields we want people to fill out when creating an issue. I've seen a common issue for awhile now with the template where people _replace_ the field names with the values they're entering, so you end up with something like:\n- **v6.2.2**:\n- **mac**:\n- **build**:\n\ninstead of:\n- **Version**: v6.2.2\n- **Platform**: mac\n- **Subsystem**: build\n\nDoes anyone have any suggestions on how we might avoid errors like this? Adding more intro text? Un-bolding the field names? Adding \"default values\" on the right-hand side? Something else?\n",
        "labels": "doc",
        "id": 44628
    },
    {
        "title": "replServer defineCommand",
        "body": "- **Version**: v4.4.5\n- **Platform**: Linux lts 4.4.0-24-generic #43-Ubuntu SMP Wed Jun 8 19:27:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nWhen I try this demo\n\n```\n// repl_test.js\nconst repl = require('repl');\n\nvar replServer = repl.start({});\nreplServer.defineCommand('sayhello', {\n  help: 'Say hello',\n  action: function(name) {\n    this.write(`Hello, ${name}!\\n`);\n    this.displayPrompt();\n  }\n});\n```\n\nthen run this in my command line with node repl_test.js\n// and got the output with\n\n> .sayhello Node.js User\n> Hello, Node.js User!\n> SyntaxError: Unexpected identifier\n>     at Object.exports.createScript (vm.js:24:10)\n>     at REPLServer.defaultEval (repl.js:235:25)\n>     at bound (domain.js:287:14)\n>     at REPLServer.runBound [as eval](domain.js:300:12)\n>     at REPLServer.<anonymous> (repl.js:431:12)\n>     at emitOne (events.js:77:13)\n>     at REPLServer.emit (events.js:169:7)\n>     at REPLServer.Interface._onLine (readline.js:211:10)\n>     at REPLServer.Interface._line (readline.js:550:8)\n>     at REPLServer.Interface._ttyWrite (readline.js:885:20)\n\nIt got the synatax error, and I don't know why?\n",
        "labels": "doc",
        "id": 44629
    },
    {
        "title": "stream docs, writable.cork() and writable.uncork() methods",
        "body": "Working on https://github.com/nodejs/node/pull/7287 I notice that [writable.cork()](https://github.com/nodejs/node/blob/master/doc/api/stream.md#writablecork) and [writable.uncork()](https://github.com/nodejs/node/blob/master/doc/api/stream.md#writableuncork) are not together, I guess it's because the alphabetical order, but I think the experience reading the [stream documentation](https://github.com/nodejs/node/blob/master/doc/api/stream.md) is going to be better if they live together. \n",
        "labels": "doc",
        "id": 44630
    },
    {
        "title": "stream, doc: an ambiguity in the readable.read([size]) doc",
        "body": "- **Version**: 6.2.2\n- **Platform**: Windows 7 x64\n- **Subsystem**: stream, doc\n\n> The readable.read() method pulls some data out of the internal buffer and returns it. If no data available to be read, null is returned. By default, the data will be returned as a Buffer object unless an encoding has been specified using the readable.setEncoding() method or the stream is operating in object mode.\n> \n> The optional size argument specifies a specific number of bytes to read. If size bytes are not available to be read, null will be returned unless the stream has ended, in which case all of the data remaining in the internal buffer will be returned (even if it exceeds size bytes).\n\nThe first paragraph makes distinction between buffer and string mode, but in the second paragraph only bytes are mentioned. It could seem that even in the string mode the `size` argument means bytes. However, in the string mode the `size` argument means decoded characters.\n\nSave this script in the UTF-8 with BOM and run it:\n\n``` js\n/******************************************************************************/\n'use strict';\n/******************************************************************************/\nconst fs = require('fs');\n\nconst readStream = fs.createReadStream(__filename, { encoding: 'utf8' });\n\nreadStream.once('readable', () => {\n  console.log(readStream.read(3));\n});\n```\n\nThe output:\n\n```\nï»¿ /*\n```\n\nIf in the string mode the `size` argument meant bytes, the output would be just the BOM.\n",
        "labels": "doc",
        "id": 44631
    },
    {
        "title": "Wrong definition of keepAliveMsecs in http.Agent documentation",
        "body": "Documentation for `keepAliveMsecs` says:\n\n```\n When using HTTP KeepAlive,\n how often to send TCP KeepAlive packets over sockets being kept alive.\n```\n\nBut internally http.Agent just uses `keepAliveMsecs` in `socket.setKeepAlive(true, self.keepAliveMsecs);` (https://github.com/nodejs/node/blob/master/lib/_http_agent.js#L73)\n\nFrom docs for `socket.setKeepAlive([enable][, initialDelay])`:\n\n```\nSet initialDelay (in milliseconds) to set the delay between\nthe last data packet received and the first keepalive probe.\n```\n\nSo really `keepAliveMsecs` doesn't mean how often keep alive probe will be sent, it means delay between the last data received and the first keep alive probe.\n",
        "labels": "doc",
        "id": 44632
    },
    {
        "title": "process, doc: discourage use of process.exit() for control flow in docs",
        "body": "Userland library authors have a pattern for CLIs that has lead to various issues during the introduction of v6. We had a heated discussion that I would summarize as: the below pattern should have been used in like this, since it actually never ensured to deliver what it promised; but core has a historic responsibility of not breaking such widely adopted patterns.\n\n``` js\nprocess.on('exit', () => {\n    // do some post action here later\n})\n\nfunction doSomething() {\n  for (var i = 0; i < 1000; i++) {\n    process.stdout.write('some result' + i + '\\n')\n  }\n  // decide that the execution of the CLI should end here\n  process.exit()\n}\n```\n\nThe problem with this that stdout doesn't get flushed on `process.exit()`, resulting in not all all 1000 calls being printed. This became apparent in v6. Eventually this calls exit(3). In any good c++ practice exit(3) is discouraged, since functions scopes are not guaranteed to unwind properly. \n\nImo, authors should at be just return from functions, from top scope, or use proper event emitters.\n\nSomeone could open a doc PR.\n\nRef: https://github.com/nodejs/node/issues/6980, https://github.com/nodejs/node/issues/6456\n\ncc @Fishrock123 \n",
        "labels": "doc",
        "id": 44633
    },
    {
        "title": "doc: Improve \"Dockerizing a Node.js web app\"",
        "body": "I found the tutorial in https://nodejs.org/en/docs/guides/nodejs-docker-webapp/ to be _almost_ very helpful.  Just one problem: it doesn't work under OS X machine.  I figured it out the cause and cure only after a lot of digging, so this addendum may be especially helpful to other newcomers.\n### summary\n\nExplain to OS X users that they cannot use `localhost:` to connect with the node.js web app.\n### details\n\nAt the bottom of the page after \"Now you can call your app using curl (install if needed via: sudo apt-get install curl):\", add something along these lines:\n\n> If you tried the above instructions on OS X, you probably got the message\n\n```\ncurl: (7) Failed to connect to localhost port 49160: Connection refused\n```\n\n> This is because OS X maps the Docker host VM to its own address, which you can discover as follows:\n\n```\n$ docker-machine ip\n192.168.99.100\n```\n\n> To use this address instead with curl, you can do the following:\n\n```\n$ curl -i `docker-machine ip`:49160\nHTTP/1.1 200 OK\nX-Powered-By: Express\nContent-Type: text/html; charset=utf-8\nContent-Length: 12\nETag: W/\"c-8O9wgeFTmsAO9bdhtPsBsw\"\nDate: Tue, 14 Jun 2016 23:38:06 GMT\nConnection: keep-alive\n\nHello world\n```\n",
        "labels": "doc",
        "id": 44634
    },
    {
        "title": "api problem  in http module",
        "body": "> https://nodejs.org/dist/latest-v4.x/docs/api/http.html#http_http_request_options_callback\n> In this section, the demo use \n> \n> ```\n> postData.length\n> ```\n> \n> as the value of the Content-Length,I think should use  \n> \n> ```\n> Buffer.byteLength(postData)\n> ```\n> \n>  insead.\n> I use the code in the example  frequently,so I think the code should be more widely used.\n",
        "labels": "doc",
        "id": 44635
    },
    {
        "title": "node docs issue in child_process",
        "body": "Using child_process.spawn, I believe the docs are incorrect (simple typo with drastic consequences) when using the stdio option:\n\n``` js\n\nconst cp = require('child_process');\nconst n = cp.spawn('node',['foo.js'],{\n  stdio: ['ignore','ignore','ignore'],\n  detached: true\n});\n```\n\nthe above should be correct, if you wish to create a child_process that is the leader of a new process group, that won't die if the parent is killed.\n\nHowever, the child_process docs have this:\n\nhttps://nodejs.org/api/child_process.html#child_process_options_detached\n\n``` js\nconst n = cp.spawn('node',['foo.js'],{\n  stdio: ['ignore'],\n  detached: true\n});\n```\n\nI don't believe the above is correct, although this may work:\n\n``` js\nconst n = cp.spawn('node',['foo.js'],{\n  stdio: 'ignore',\n  detached: true\n});\n```\n\nthis issue had me stuck for a few days :)\n",
        "labels": "doc",
        "id": 44636
    },
    {
        "title": "zlib: there are constants documented that don't exist",
        "body": "In the zlib docs, there are a handful of constants listed that do not exist in the actual code:\n\nSpecifically:\n- `zlib.Z_BINARY`\n- `zlib.Z_TEXT`\n- `zlib.Z_ASCII`\n- `zlib.Z_UNKNOWN`\n\nSee: https://nodejs.org/dist/latest-v6.x/docs/api/zlib.html#zlib_constants\n\nRemoved in: https://github.com/nodejs/node/pull/7203\n",
        "labels": "doc",
        "id": 44637
    },
    {
        "title": "Doctool tests require absent eslint",
        "body": "- **Version**: 6.2.1\n- **Platform**: Linux veritas 3.19.0-59-generic #66~14.04.1-Ubuntu SMP Fri May 13 17:27:10 UTC 2016 x86_64 GNU/Linux\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nIt seems that several doctool tests depend on the availability of js-yaml in the source tree. js-yaml is supposedly included from the path `tools/eslint/node_modules/js-yaml`, which is not available in the source tarball. Running `make lint` in the source tree leads to the following error message:\n\n```\nLinting is not available through the source tarball.\nUse the git repo instead: git clone https://github.com/nodejs/node.git\n```\n\nThe actual offending test outputs, runnable via `/usr/bin/python tools/test.py --mode=release -J doctool`:\n\n```\n=== release test-doctool-html ===                    \nPath: doctool/test-doctool-html\nmodule.js:442\n    throw err;\n    ^\n\nError: Cannot find module '/home/jelle/temp/node-v6.2.1/tools/eslint/node_modules/js-yaml'\n    at Function.Module._resolveFilename (module.js:440:15)\n    at Function.Module._load (module.js:388:25)\n    at Module.require (module.js:468:17)\n    at require (internal/module.js:20:19)\n    at Object.<anonymous> (/home/jelle/temp/node-v6.2.1/tools/doc/node_modules/js-yaml/index.js:15:18)\n    at Module._compile (module.js:541:32)\n    at Object.Module._extensions..js (module.js:550:10)\n    at Module.load (module.js:458:32)\n    at tryModuleLoad (module.js:417:12)\n    at Function.Module._load (module.js:409:3)\nCommand: out/Release/node /home/jelle/temp/node-v6.2.1/test/doctool/test-doctool-html.js\n=== release test-doctool-json ===                    \nPath: doctool/test-doctool-json\nmodule.js:442\n    throw err;\n    ^\n\nError: Cannot find module '/home/jelle/temp/node-v6.2.1/tools/eslint/node_modules/js-yaml'\n    at Function.Module._resolveFilename (module.js:440:15)\n    at Function.Module._load (module.js:388:25)\n    at Module.require (module.js:468:17)\n    at require (internal/module.js:20:19)\n    at Object.<anonymous> (/home/jelle/temp/node-v6.2.1/tools/doc/node_modules/js-yaml/index.js:15:18)\n    at Module._compile (module.js:541:32)\n    at Object.Module._extensions..js (module.js:550:10)\n    at Module.load (module.js:458:32)\n    at tryModuleLoad (module.js:417:12)\n    at Function.Module._load (module.js:409:3)\n```\n\nI would expect that these tests should rather be skipped when running tests from an extracted tarball, or rewritten so they do not depend on eslint. Otherwise, eslint could possibly be included instead.\n\n/cc @jbergstroem @silverwind @TheAlphaNerd #6031 \n",
        "labels": "doc",
        "id": 44638
    },
    {
        "title": "Doc Markup Typo",
        "body": "I assume that \n\n> [prepare that sandbox][#vm_what_does_it_mean_to_contextify_an_object] \n\nshould be a link.\n\nhttps://nodejs.org/api/vm.html\n\n![](http://puu.sh/pigbA.png)\n",
        "labels": "doc",
        "id": 44639
    },
    {
        "title": "Module resolution description does not reflect the implementation",
        "body": "- **Version**: v4.4.3\n- **Platform**: Darwin James.local 15.5.0 Darwin Kernel Version 15.5.0: Tue Apr 19 18:36:36 PDT 2016; root:xnu-3248.50.21~8/RELEASE_X86_64 x86_64\n- **Subsystem**: Modules\n\nI've just read this:\n\nAll Together...\nhttps://nodejs.org/docs/latest/api/modules.html#modules_all_together\n\nFrom this document, if a script in /Uesrs/foo (Y) does `require('/b.js');` (X), it should be resolved to /Users/foo/b.js (Y + X). But as long as I tested, it's resolved to an absolute path (/b.js).\n\nI guess either the document or implementation is wrong.\n\nHere is the code.\nhttps://gist.github.com/tai2/b2121a67cfab8b1945cc4b292fc737dd\n",
        "labels": "doc",
        "id": 44640
    },
    {
        "title": "Adding annotations to API Documentation",
        "body": "We've been talking for a long time about how we can improve the documentation. There's something of a tension between the need for dry technical documentation and more nuanced language that might be better at teaching people. It has also been difficult to get more documentation contributions through the standard core contribution process and there are some good reasons for keeping the actual documentation in the core repo rather than somewhere else.\n\nGenius (formerly Rap Genius) released a [pretty amazing annotator](http://genius.com/web-annotator) for the web. You can annotate _any_ page with the Chrome Extension but you can also just add this to have it work for everyone:\n\n```\n<script async src=\"//genius.codes\"></script>\n```\n\nThis would allow people to start writing up more context around various parts of the documentation.  When someone is confused by a particular section of documentation we could annotate it, which would show a highlight they can click on, that talks in plainer language.\n\nThoughts?\n\n/cc @hackygolucky @ashleygwilliams \n",
        "labels": "doc",
        "id": 44641
    },
    {
        "title": "Documentation misleads embedders",
        "body": "The [most recent documentations](https://nodejs.org/api/addons.html) still claim that one can make nodeJS addons in C: _Node.js Addons are dynamically-linked shared objects, written in **C or C++**_\nHowever currently there is no official way for this to happen using pure C, only wrapper-hacking and thirdparty tools. Either stop lying in the docs or provide a source where one don't have to use namaspaces and C++-only data types to write a node extension.\n",
        "labels": "doc",
        "id": 44642
    },
    {
        "title": "Omission in the fs doc",
        "body": "- **Version**: 6.2.0\n- **Platform**: Windows 7\n- **Subsystem**: doc, fs\n\nSometimes I use the same file descriptor for writing and then reading by `readline` (possible case: write some data line by line, then reread it into an array to sort and rewrite).\n\nIt seems `fs` doc lacks for some point concerning these cases.\n\n[fs.createReadStream(path[, options])](https://nodejs.org/api/fs.html#fs_fs_createreadstream_path_options):\n\n> `options` can include `start` and `end` values to read a range of bytes from the file instead of the entire file. Both `start` and `end` are inclusive and start at 0.\n\nMaybe it should be mentioned that `start` is set by default to the file end (or to the write position) for fd that has been previously written into.\n\nTest:\n\n``` js\nconst fs = require('fs');\nconst rl = require('readline');\n\nconst file = fs.openSync('test.txt', 'w+');\n\nfs.writeSync(file, '1\\n2\\n3\\n');\n\nrl.createInterface({\n  input: fs.createReadStream(null, {fd: file})\n}).on('line', line => {\n  console.log(line);\n}).on('close', () => {\n  console.log('Closed');\n});\n```\n\nThe output is only\n\n```\nClosed\n```\n\n``` js\nconst fs = require('fs');\nconst rl = require('readline');\n\nconst file = fs.openSync('test.txt', 'w+');\n\nfs.writeSync(file, '1\\n2\\n3\\n');\n\nrl.createInterface({\n  input: fs.createReadStream(null, {fd: file, start: 0})\n}).on('line', line => {\n  console.log(line);\n}).on('close', () => {\n  console.log('Closed');\n});\n```\n\nThe output contains all the file:\n\n```\n1\n2\n3\nClosed\n```\n",
        "labels": "doc",
        "id": 44643
    },
    {
        "title": "Documentation about tests",
        "body": "I notice that we don't have any documentation about **tests**. But is something that is going to be really helpfully to have for new contributors like myself. Maybe someone with the knowledge can add some introduction like, **folder struct**, **some basic examples**, etc...\n\n@nodejs/documentation\n",
        "labels": "doc",
        "id": 44644
    },
    {
        "title": "net module `socket.setEncoding()` deprecated ?",
        "body": "Working on https://github.com/nodejs/node/pull/7038 I notice that in the `net module` we don't have `socket.setEncoding()` but in the documentation we have a [ref for that method](https://github.com/nodejs/node/blob/master/doc/api/net.md#socketsetencodingencoding).\n\nLooking in the history I found [when the method was removed](https://github.com/nodejs/node/commit/8a3befa0c65ba2ee653e3d3b39360e974536f3ef#diff-e6ef024c3775d787c38487a6309e491dL437).\n\nWe should remove that method from the documentation or I'm not seeing something here..\n",
        "labels": "doc",
        "id": 44645
    },
    {
        "title": "cli help documentation for --inspect",
        "body": "Now that --inspect is in, there should be documentation in node -h about inspect, debug, debug-brk, debug-port params.\n\nI volunteer to send this as my first node PR. I believe @Fishrock123  mentioned where I need to make this edits.\n",
        "labels": "doc",
        "id": 44646
    },
    {
        "title": "documentation format",
        "body": "Working on this Issue https://github.com/nodejs/node/issues/6578 I notice that the `tls documentation` and `net documentation` do not have the same format.\n\nIn the `net documentation` we have a deprecated method with non deprecated methods \nhttp://cl.ly/3y2m0z0s1B02\n\nIn the `tls documentation` we have a category for deprecated API's\nhttp://cl.ly/2t1R3v29293r\n\nThe `tls` format make more sense and my opinion is that all the documentation should fallow the same format. \n\nIf this make sense I'm available to create a PR.\n",
        "labels": "doc",
        "id": 44647
    },
    {
        "title": "discuss: future of the doctool in node core",
        "body": "Occasionally when talking about the doctool, a few questions pop up:\n- Should the doctool, in the long run, stay part of the Node core repository?\n- Is the current situation of it having all doctool dependencies checked in reasonable?\n- What changes are necessary and what changes are helpful for larger future changes, e.g. generating docs for the topic documents/guides/etc.?\n\nIâ€™d like it if we could work out answers to these questions here.\n\nSome things to consider:\n- In its current state, the doctool could just as well create docs for other projects, and only few things are tailored to be specific to Node core\n- Large parts of the doctoolâ€™s dependencies are shared with `eslint`, so they are already checked in in the repository\n- The doctoolâ€™s automated tests provide Node core with a minimal, regularly run test for a â€œreal-worldâ€ application\n- The doctool should work with older Node versions back to v4, e.g. for the doc-only Makefile target, although thatâ€™s not being tested currently\n- The current dependency for markdown parsing, `marked`, is effectively not maintained anymore\n- Changes to the doctool to support specific features needed for our documentation files themselves donâ€™t happen very often anymore\n\nRefs: e.g. #6495, #6974, #5408\n/cc @nodejs/documentation and specifically @eljefedelrodeodeljefe \n",
        "labels": "doc",
        "id": 44648
    },
    {
        "title": "Doc describes HTTP \"abort\" event, but not \"aborted\"",
        "body": "- **Version**: 6.2.0\n- **Platform**: Linux 3.16.0-4-amd64 # 1 SMP Debian 3.16.7-ckt25-2 (2016-04-08) x86_64 GNU/Linux\n- **Subsystem**: HTTP\n\n<!-- Enter your issue details below this comment. -->\n\n**TL;DR**: HTTP doc mentions `'abort'` event, but not `'aborted'`. The API emits both. Doc fix?\n\nCurrent doc describes an `'abort'` event on HTTP streams [here](https://github.com/nodejs/node/blame/5b72f891a8b992cb4461c917a6ca59ed95e7b2a9/doc/api/http.md#L215). That doc was added in 2ca22aac, which closed #945. #945 seems to deal with the case where `.abort()` is called on a client only. It refers to https://github.com/nodejs/node-v0.x-archive/issues/9278. As far as I can tell, current doc never mentions an `'aborted'` event.\n\nThe HTTP client emits `'abort'` from requests [here](https://github.com/nodejs/node/blob/5b72f891a8b992cb4461c917a6ca59ed95e7b2a9/lib/_http_client.js#L219).\n\nThe HTTP client also emits `'aborted'` from the corresponding response (`req.res`) [here](https://github.com/nodejs/node/blob/5b72f891a8b992cb4461c917a6ca59ed95e7b2a9/lib/_http_client.js#L272).\n\nThe HTTP server emits `'aborted'` from requests [here](https://github.com/nodejs/node/blob/5b72f891a8b992cb4461c917a6ca59ed95e7b2a9/lib/_http_server.js#L280).\n\n`'aborted'` events make it to user space. raw-body, a dep of the popular body-parser, listens for it [here](https://github.com/stream-utils/raw-body/blob/master/index.js#L228).\n\nA few questions:\n1. Is `aborted` intentionally undocumented? I see it mentioned in the CHANGELOG archives a couple of times from the 0.4.x days, [here](https://github.com/nodejs/node/blame/5b72f891a8b992cb4461c917a6ca59ed95e7b2a9/doc/changelogs/CHANGELOG_ARCHIVE.md#L2492) and originally (on Agent) [here](https://github.com/nodejs/node/blame/5b72f891a8b992cb4461c917a6ca59ed95e7b2a9/doc/changelogs/CHANGELOG_ARCHIVE.md#L2499). Would the team welcome a doc patch mentioning it?\n2. Are `abort` and `aborted` intentionally distinct events?\n\n**_Be Warned! I believe this is my first issue on Node. I've read CONTRIBUTING and friends and done my best.**_\n\nThanks to the team!\n",
        "labels": "doc",
        "id": 44649
    },
    {
        "title": "doc: intent to restructure README.md to be more advertising and introducing to docs",
        "body": "Our README.md currently is quite technical - in terms of being useful for collaboration and security-wise(?).\n\nI am convinced efforts moving towards the READE being more advertising and attractive to the reader is worthwhile.\n\nGood examples that come to mind:\n- https://github.com/kubernetes/kubernetes\n- https://github.com/docker/docker\n- https://github.com/libuv/libuv for the upper part\n\nThis would mean moving GPG stuff, maybe also the collaborator list, adding a logo etc.\n",
        "labels": "doc",
        "id": 44650
    },
    {
        "title": "doc: formatting issues for child_process docs",
        "body": "- **Version**: v5.11.0+\n- **Platform**: n/a\n- **Subsystem**: doc, child_process\n\nThere are some formatting issues for `exec()` and `execFile()` in the `child_process` docs. Specifically:\n- <s>f85412d49b0ac1b3d2fa1e9c0dfe2491ea3aa9be erroneously added a backslash in front of an asterisk that was already contained within backticks. This causes the backslash to show up when rendered. The backslash can be safely removed.</s> Fixed by ed11ac608082bf6056825786ab74ed39d773a00a.\n- The `maxBuffer` link is not styled like the other properties listed and looks out of place. My suggestion would be to have `<code>`-wrapped content within links to continue to have the same gray background color normally, but switch to the green background color on hover like normal links. There may be other instances of this in the docs, I have not checked.\n",
        "labels": "doc",
        "id": 44651
    },
    {
        "title": "Not all globals are documented",
        "body": "<!--\nThank you for reporting an issue. Please fill in the template below. If unsure\nabout something, just do as best as you're able.\n\nVersion: usually output of `node -v`\nPlatform: either `uname -a` output, or if Windows, version and 32 or 64-bit\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v4.3.1\n- **Platform**: Windows 64-bit\n- **Subsystem**: N/A\n\n<!-- Enter your issue details below this comment. -->\n\nIn the documentation of globals at [https://nodejs.org/api/globals.html](https://nodejs.org/api/globals.html) I'm missing certain globals, such as Uint16Array, Uint8Array, etc even though they are obviously globals and don't need to be required in.\n\nFor people trying to write universal javascript, it would be quite nice to have a proper documentation of all globals in node.\n\nRunning the following code will print out many globals that are missing in the global documentation page:\n\n``` js\nObject.getOwnPropertyNames(global).sort().forEach(x => console.log(x));\n```\n",
        "labels": "doc",
        "id": 44652
    },
    {
        "title": "Update Readme section on verifying signatures",
        "body": "EDIT:\r\n\r\nWe now generate detached signatures for all release lines. There is no documentation on how to verify this. An update to the Readme would be great!\r\n\r\n---\r\n_Original_\r\n\r\nThe current process for verifying releases is outputting a warning\r\n\r\n```\r\ngpg: Signature made Thu May  5 17:56:43 2016 CDT using RSA key ID 4C206CA9\r\ngpg: Good signature from \"Evan Lucas <evanlucas@me.com>\" [ultimate]\r\ngpg:                 aka \"Evan Lucas <evanlucas@keybase.io>\" [ultimate]\r\ngpg: WARNING: not a detached signature; file 'SHASUMS256.txt' was NOT verified!\r\n```\r\n\r\nA script to verify and output is included [in this gist](https://gist.github.com/TheAlphaNerd/8434eb315093ea983bb0ce7aa12d9461)\r\n",
        "labels": "doc",
        "id": 44653
    },
    {
        "title": "child_process.exec() fails with spaces in absolute or relative path to binary file",
        "body": "- **Version**: v5.10.1\n- **Platform**: Darwin Joran.local 15.4.0 Darwin Kernel Version 15.4.0: Fri Feb 26 22:08:05 PST 2016; root:xnu-3248.40.184~3/RELEASE_X86_64 x86_64\n- **Subsystem**: child_process\n\nUsing exec() to execute an absolute path to a binary, with spaces in the absolute path, e.g. `/Users/Joran/test script.sh` fails:\n\n```\n{ [Error: Command failed: /Users/Joran/test script.sh\n/bin/sh: /Users/Joran/test: No such file or directory\n]\n  killed: false,\n  code: 127,\n  signal: null,\n  cmd: '/Users/Joran/test script.sh' } '' '/bin/sh: /Users/Joran/test: No such file or directory\\n'\n```\n",
        "labels": "doc",
        "id": 44654
    },
    {
        "title": "doc,streams: internal \"private\" properties are publicly documented",
        "body": "- **Version**: v0.10.14+\n- **Platform**: all\n- **Subsystem**: doc, streams\n\nI just noticed that not only is `_readableState` publicly documented, but its access is being encouraged in the documentation too. The text was added way back in db5776cf8b51e27967cc27c2a9e07f5310dd4366. This doesn't feel right. It seems like we should be either not documenting these kinds of properties _or_ we should be providing a non-underscored API if we _really_ want that functionality to be public. I know that users will tap into `_readableState` and similar properties _anyway_ for various reasons (and that in the past there were some attempts to fix those reasons), but publicly documenting them and encouraging their use is not right IMHO.\n\n/cc @nodejs/streams \n",
        "labels": "doc",
        "id": 44655
    },
    {
        "title": "When running fs.watch on a Vagrant vm and changing a file through the host machine, the change is not detected",
        "body": "- **Version**: node 4.1.2\n- **Platform**: Ubuntu 64-bit\n- **Subsystem**: fs\n\nNot sure whether this is known behavior or a bug.\n\nI'm running Ubuntu on a Vagrant virtual machine and I have set up a shared folder so changes to the folder and all subfolders are in sync. However, if I run `fs.watch('/folder')` in the VM and change a file in that folder through the host (Windows), the change is not detected.\n",
        "labels": "doc",
        "id": 44656
    },
    {
        "title": "Document how to test if a file exists",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**: All\n- **Platform**: All\n- **Subsystem**: `fs`\n\n<!-- Enter your issue details below this comment. -->\n\nThe documentation for `fs` could use some work. Useful utilities like `exists` are being deprecated with nothing more than a note to use other operations and check the error. The problem is, there is no documentation for which errors you should expect to see. I know from _experimentation_ that `ENOENT` seems to tell me that a file does not exist, but that is not documented.\n\nIf we just had a section explaining what a file system error looks like and a list of all of the codes, that would be a huge help in knowing how to properly write code for different scenarios.\n",
        "labels": "doc",
        "id": 44657
    },
    {
        "title": "[documentation site] Back button does not scroll the page (solution included)",
        "body": "_NOTE:_ This happens in a computer view (big screen).\n\nHow to reproduce (at least in Chrome):\n- Open (for example) https://nodejs.org/api/http.html\n- Within the \"Table of Content\", click in `Class: http.ClientRequest`.\n- It will scroll down to the corresponding class definition, and the window location becomes `https://nodejs.org/api/http.html#http_class_http_clientrequest`\n- Now press the browser Back button.\n- Window location becomes `https://nodejs.org/api/http.html` again, but the page was not scrolled up.\n\nThis is because `<html>` and `<body>` have both `height: 100%` (this is OK), but then there is a main container `<div id=\"content\">` which also has `height: 100%`, and there is where the problem is:\n\nBy having a container with `height: 100%` within the body, the scroll is not done on the body itself, but on the container. And unfortunately the Back button does not scroll back a div (but just the body element).\n\nThe solution is to remove the `height: 100%` of the `<div id=\"content\">` (you can test it by removing such a CSS property in the browser inspector), but of course that requires changes for the left menu to remain fixed when the page is scrolled. Such a change just requires replacing `position: absolute` with `position: fixed` in the `<div id=\"column2\">`.\n\nTo summarize:\n- In `<div id=\"content\">` remove `height: 100%`.\n- In `<div id=\"column2\">` set `position: fixed`.\n",
        "labels": "doc",
        "id": 44658
    },
    {
        "title": "Node.js documentation is not print-friendly",
        "body": "Can not print Node.js documentation from: https://nodejs.org/api/all.html .\n\nSome CSS rules are not appropriate for print mode.\nBefore:\n![image](https://cloud.githubusercontent.com/assets/12509753/15258259/3d51cb42-1953-11e6-961d-c4f6374d4b96.png)\n\nFortunately, I found an simple solution(below).\n\nAt the bottom of style.css add this CSS rule:\n\n```\n@media print {\n\n  html  {\n    height : auto;\n  }\n\n #column2.interior {\n   display : none;\n }\n\n #column1.interior {\n   margin-left : auto;\n   overflow-y  :  auto;\n }\n\n}\n```\n\nAfter my CSS codes:\n![image](https://cloud.githubusercontent.com/assets/12509753/15258581/06e54afa-1955-11e6-9bd1-aae721cc28c2.png)\n",
        "labels": "doc",
        "id": 44659
    },
    {
        "title": "doc: fix exec stdout & stderr default type in child_process",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **v4.4.4**:\n- **Darwin**:\n\n<!-- Enter your issue details below this comment. -->\n\nThere is an inaccurate line in child_process documents.\n*\\* origin text **\nIf `encoding` is `'buffer'`, `Buffer` objects will be passed to\nthe callback instead\n\nActually, if encoding parameter can not be identified as encoding (Buffer.isEncoding)\nexec will also output buffer rather than string\n\nCould I provide a pr to fix the document?\n",
        "labels": "doc",
        "id": 44660
    },
    {
        "title": "Use Teams for the \"Who to CC in issues chart\"",
        "body": "See https://github.com/nodejs/node/blob/master/doc/onboarding-extras.md#who-to-cc-in-issues (Soon to be  a table as per https://github.com/Fishrock123/node/blob/doc/improve-onboarding-extras/doc/onboarding-extras.md#who-to-cc-in-issues)\n\nRefs https://github.com/nodejs/node/pull/6548#discussion_r61915872\n\nHere's a copy of the (soon to be current) chart directly: \n\n> | subsystem | maintainers |\n> | --- | --- |\n> | `lib/buffer` | @trevnorris |\n> | `lib/child_process` | @cjihrig, @bnoordhuis |\n> | `lib/cluster` | @cjihrig, @bnoordhuis |\n> | `lib/{crypto,tls,https}` | @nodejs/crypto |\n> | `lib/domains` | @misterdjules |\n> | `lib/{_}http{*}` | @indutny, @bnoordhuis, @mscdex, @nodejs/http |\n> | `lib/net` | @indutny, @bnoordhuis, @nodejs/streams |\n> | `lib/{_}stream{s|*}` | @nodejs/streams |\n> | `lib/repl` | @fishrock123 |\n> | `lib/timers` | @fishrock123, @misterdjules |\n> | `lib/zlib` | @indutny, @bnoordhuis |\n> | `src/async-wrap.*` | @trevnorris |\n> | `src/node_crypto.*` | @nodejs/crypto |\n> | `test/*` | @nodejs/testing |\n> | `tools/eslint`, `.eslintrc` | @silverwind, @trott |\n> | upgrading v8 | @bnoordhuis, @targos, @ofrobots |\n> | upgrading npm | @thealphanerd, @fishrock123 |\n\nBackground:\n\n> > Would much prefer to make these all team references and begin moving away from specific individuals. Doing so has worked effectively for things like lts, documentation, streams, http, and crypto. For instance, I've created a @nodejs/buffer team as an example.\n> > \n> > The downside to mentioning specific individuals is that it creates a disincentive for new collaborators to feel empowered to jump in and help with the reviews and puts too much emphasis and burden on specific individuals.\n> \n> For some areas, yes.\n> \n> For other parts of core, I think this is still correct until the knowledge becomes more distilled and distributed as more people learn the codebase, and while that is something we should work towards it doesn't necessarily reflect reality.\n",
        "labels": "doc",
        "id": 44661
    },
    {
        "title": "doc: System Error description incorrectly equates errno and code properties",
        "body": "The [documentation for System Errors](https://nodejs.org/dist/latest-v4.x/docs/api/errors.html#errors_system_errors) specifies:\n\n> Returns a string representing the error code, which is always `E` followed by a sequence of capital letters, and may be referenced in `man 2 intro`.\n> The properties `error.code` and `error.errno` are aliases of one another and return the same value.\n\nIn 4.x and (by inspection) 6.x this is incorrect; the `error.errno` property is an integer error code, as set by this code for `ErrnoException` in `src/node.cc`:\n\n```\nLocal<Object> obj = e->ToObject(env->isolate());\nobj->Set(env->errno_string(), Integer::New(env->isolate(), errorno));\nobj->Set(env->code_string(), estring);\n```\n\nReproduce with anything like:\n\n```\ntry {\n  require('fs').openSync('/no/such/file', 'r');\n} catch (e) {\n  console.log(e);\n}\n```\n",
        "labels": "doc",
        "id": 44662
    },
    {
        "title": "Spelling error",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**:\n- **Platform**:\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nI found a spelling error in the webpage -- \"https://nodejs.org/dist/latest-v4.x/docs/api/documentation.html\".\nThe original sentence is \"If you find a error in this documentation, please submit an issue or see the contributing guide for directions on how to submit a patch\".\nShould it be \"If you find an error in this documentation, please submit an issue or see the contributing guide for directions on how to submit a patch\"?\n",
        "labels": "doc",
        "id": 44663
    },
    {
        "title": "doc: search indicators missing",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**: all\n- **Platform**: all (likely, confirmed Safari, Chrome on OS X)\n- **Subsystem**: `doc`\n\nAs described in #6479 at the bottom, search indicators in browsers are missing which probably was unintentional:\n\n> Chrome (at least on a Mac) will give you indicators on the scrollbar of where cmd+f results are. Using custom styles on the scrollbar breaks this â€“ so I'm glad to see it works again in the narrow view. However, in the wide view, since the content area's scrollbars are not on the body, they still don't work there:\n\n![ccaa3852-147a-11e6-95f7-92e3780fc599-1](https://cloud.githubusercontent.com/assets/3899684/15097151/e250771e-1512-11e6-99ec-c7ba7374216a.png)\n",
        "labels": "doc",
        "id": 44664
    },
    {
        "title": "doc: change to dark code blocks with full syntax highlighting ",
        "body": "I am not sure but I couldn't find any issue where the general style of the code blocks was discussed.\n\nI stopped tracing the current style back at https://github.com/nodejs/node/commit/45cd4e211e77c34228560770a3e0199988328258, later changes were only nits changing the colors slightly to match some other thing.\n\nMain motivation for this would be, that especially in streams, where you have a lot code blocks, I tend to lose orientation, when I jump from, say, Readable stream implementation to its definition and back again.\n\nInterestingly all major language API documentations have rather subtle code blocks, most are less color in color though. We would be the first with dark code blocks. Contrary most code blogs and sites have dark blocks.\n\nCurrently we have roll-your-own syntax highlighting and I guess we code improve also there, especially when going dark.\n\n<img width=\"1038\" alt=\"child_process_node_js_v6_1_0_manual___documentation\" src=\"https://cloud.githubusercontent.com/assets/3899684/15095335/ffd75aba-14c1-11e6-955d-a6e276d55739.png\">\n\n<img width=\"1041\" alt=\"stream_node_js_v6_1_0_manual___documentation\" src=\"https://cloud.githubusercontent.com/assets/3899684/15095336/084a4dc4-14c2-11e6-8ff6-9c7cc2aa1b80.png\">\n\ncc @nodejs/documentation \n",
        "labels": "doc",
        "id": 44665
    },
    {
        "title": "Document that readline.emitKeypressEvents only works when tty is in raw mode",
        "body": "- **Version**: 6.0.0\n- **Platform**: osx 10.11.4, `uname -a`: 15.4.0 Darwin Kernel Version 15.4.0: Fri Feb 26 22:08:05 PST 2016; root:xnu-3248.40.184~3/RELEASE_X86_64 x86_64\n- **Subsystem**: [readline.emitKeypressEvents](https://nodejs.org/dist/latest-v6.x/docs/api/readline.html#readline_readline_emitkeypressevents_stream)\n\n`process.stdin` does not emit `keypress` after `readline.emitKeypressEvents(process.stdin)`, but does when a readline interface created.\n\n``` js\nconst readline = require('readline')\n\n// const rl = readline.createInterface({\n//  input: process.stdin,\n//  output: process.stdout\n// })\nreadline.emitKeypressEvents(process.stdin)\nprocess.stdin.on('keypress', () => {\n    process.stdout.write('.')\n})\n```\n\n**What happens**: On keypress, event handler is not called. If a readline interface is created, the event handler is called.\n**Expected**: `stdin` to start emitting `keypress`-events.\n",
        "labels": "doc",
        "id": 44666
    },
    {
        "title": "doc: missing require calls in some code examples",
        "body": "Hi,\nwandering through the api docs, I recognized that some code examples do\nnot have a `const foo = require('foo');` in it, but just use `foo` **without requiring** it.\n\nObviously when we talk about global modules like `Buffer` or `process` this is totally correct.\nHowever some require calls are really missing, among others, in e.g. [net module](https://nodejs.org/dist/latest-v6.x/docs/api/net.html) or [querystring module](https://nodejs.org/dist/latest-v6.x/docs/api/querystring.html).\n\nI would like to create a PR for it, adding the missing require calls.\n\n---\n\nIn this context, I would also like to mention the [PR about introducing ESLint](https://github.com/nodejs/node/pull/5053) for the docs, where [this ESLint rule](http://eslint.org/docs/rules/global-require) seems to be a good fit for this issue.\n\n---\n\nDo you guys have any thoughts or proposals for this issue before I dive in?\nThanks for your feedback. :wink: \n",
        "labels": "doc",
        "id": 44667
    },
    {
        "title": "docs do not state at what version an API was introduced (or deprecated)",
        "body": "<!-- Enter your issue details below this comment. -->\n\nnode documentation just documents the current node, but to write portable node.js, its important to know about when APIs were introduced (or changed incompatibly)\n\nI regularly find developers attempting to use features that only exist on the most recent Node.js versions, such as the `v8` module, without realizing it doesn't exist on some LTS versions.\n\nIt would be quite helpful if the API docs were annotated with the version in which an API was introduced.\n\ncc: @chrisdickinson @bhajian\n\n---\n\n(edited by @addaleax)\n\nNow that basic tooling for this feature is available in the doctool, it would be nice to see if we can get some people together for looking up the versions in which features were added/deprecated! If youâ€™d like to volunteer, Iâ€™d suggest you just comment on this issue.\n\nDocumentation files for which this is definitely worthwhile:\n- [x] assert.md â€“ @Trott in f52b2f116bf510e2af8750061ac6f8a0c9caa653 (#6688)\n- [x] buffer.md â€“ @addaleax in 4dcc692cada019cd2661ff807d829493ebf71594 (#6495)\n- [x] child_process.md â€“ @addaleax in 27d2267066add18a1eafa2ac852ffdb4ae3198be (#6927)\n- [x] cli.md â€“ @Trott in 90675818eede96a063489109f86022dd13ad75cb (#6960)\n- [x] cluster.md â€“ @addaleax in c628982a06e479f0d7d943c13131108924873ba4 (#7640)\n- [x] console.md â€“ @edsadr in 51b8a79bd46a28c2f576a579f258c2222e1a951b (#6995) \n- [x] crypto.md â€“ @lpinca in cfe8278328d190279532ab9b7fd13ae1bfd78ee2 (#8281)\n- [x] dgram.md â€“ @lpinca in 379d9162a2d992f7ff8a20d00f088ede1bf2f0fe (#8196)\n- [x] dns.md â€“ @julianduque in 71996506e9a979e73d20bd418a5c7e34a92c3f08 (#7021)\n- [x] events.md â€“ @lpinca in 769f63ccd8437045af5ddf1f418c53d2319597ed (#7822)\n- [x] fs.md â€“ @addaleax in ba10ea8f3af4a1af5c2f7df3e4f5af348f09e97b (#6717)\n- [x] http.md â€“ @addaleax in 72500f942b85e7fe66176b2807663aa225015e39 (#7392)\n- [x] https.md â€“ @addaleax in e8356b25cdf43079e8a6d74e02df67a49f64e471 (#7392)\n- [x] modules.md â€“ @lpinca in df4880de557fabafb625745c6ea75d3b755595d2 (#8250)\n- [x] net.md â€“ @italoacasas in 8bccc9e6c82c558132a28a462e9dd573ae0302c6 (#7038)\n- [x] os.md â€“ @bengl in 5a8c66a252c16b0d181fd7f1b3232941e5644971 (#6609)\n- [x] path.md â€“ @julianduque in bed44c94a0f05748fc5160610db33ed15f1f540c (#6985)\n- [x] process.md â€“ @bengl in ec67abe4a7c074bb66700c4aede56ffd4aaf3363 (#6589)\n- [x] punycode.md â€“ @firedfox in b90c52e38d47952bf6bef59d9a1c116b1972b8d9 (#6805)\n- [x] querystring.md â€“ @bengl in f7730733384cc15e8e5c842e3e1771e6f917c188 (#6593)\n- [x] readline.md â€“ @julianduque in 0ed4d8c535945865d48d50c023aba46f6286f616 (#6996)\n- [x] repl.md â€“ @addaleax in 740d8cf5e0bf85bbc756096ad40b44f19a4a4ddd (#7256)\n- [x] stream.md â€“ @italoacasas in c897d0ba71c0e73fbd37372e3dd4825e93cd251a (#7287)\n- [x] string_decoder.md â€“ @Trott in eb089e7ccd81c0951e4901df20f6dbaa084af143 (#6741)\n- [x] tls.md â€“ @italoacasas in c2e6078ed95cea135da8ebe4ef5a807e0bd0bbe2 (#7018) \n- [x] tty.md â€“ @trott in d3f3e183bfdd27a66ce4791ba0c933ab33a91512 (#6783)\n- [x] url.md â€“ @bengl in 43e4bafcaf1e40d62b4bbcd33ce8de946586e835 (#6593)\n- [x] util.md â€“ @lpinca in d9142b4bd6e48690337ac8f988719e67d7a361ce (#8206)\n- [x] v8.md â€“ @trott in b3bc36209f927bbdcdcada7e2170f91f1c32d1b3 (#6684)\n- [x] vm.md â€“ @addaleax in 16f98e589c69ffe6283aa11493fd417368708557 (#7011)\n- [x] zlib.md â€“ @addaleax in b49df8891682f0d429f7d594b9ab1185715eb4f7 (#6840)\n\nDocs for which this may or may not make sense:\n- [ ] addons.md\n- [ ] debugger.md\n- [ ] domain.md\n- [ ] globals.md\n- [x] timers.md â€“ @addaleax in cd4dbf33481ee1432b0d71a6576492acc12b4298 (#7493)\n",
        "labels": "doc",
        "id": 44668
    },
    {
        "title": "doc: invalid process.hrtime documentation",
        "body": "The current documentation for `process.hrtime()` does not include information about the optional arguments. See https://nodejs.org/dist/latest-v6.x/docs/api/process.html#process_process_hrtime\n",
        "labels": "doc",
        "id": 44669
    },
    {
        "title": "API stability level Â«LockedÂ» is inaccurate",
        "body": "Atm, these modules are listed in the documentation as being `Locked`: ~~[assert](https://nodejs.org/api/assert.html),~~ [modules](https://nodejs.org/api/modules.html), [timers](https://nodejs.org/api/timers.html).\r\n\r\n_Update: `assert` was successfully unlocked in #11304. :tada:_\r\n_Update: `timers` was successfully unlocked in #11580. :tada:_\r\n\r\n`Locked` [is defined](https://nodejs.org/api/documentation.html#documentation_stability_index) as:\r\n\r\n> **Stability: 3 - Locked**\r\n> Only fixes related to security, performance, or bug fixes will be accepted.\r\n> Please do not suggest API changes in this area; they will be refused.\r\n\r\nStill we have those changes recently landed (~ 1 year):\r\n- ~~`assert`: #3374, #639, #668, #308 (ok, that one is present since 1.0.0), borderline features/bug fixes: #2407, #4166, #3276, #636,~~\r\n- `modules`: #5950, #5689, #1812, #1363, #1185, #1162,\r\n- ~~`timers`: #4362, #3374, https://github.com/nodejs/node-v0.x-archive/pull/8884.~~\r\n\r\nAnd more proposed: #10282, #3384, #6165, #4550 (ok, the last two are not documented).\r\n\r\nHow `Locked` is defined does not fall in line with what's actually going on there. It looks more like stability level `Stable` should be used instead:\r\n\r\n> **Stability: 2 - Stable**\r\n> The API has proven satisfactory. Compatibility with the npm ecosystem\r\n> is a high priority, and will not be broken unless absolutely necessary.\r\n\r\nPerhaps we should remove `Locked` stability level whatsoever?\r\n\r\n/cc @nodejs/ctc\r\n",
        "labels": "doc",
        "id": 44670
    },
    {
        "title": "doc: isabsolute() windows examples use wrong path separator",
        "body": "Doc incorrectly uses forward slashes for path examples on Windows platform:\n\nhttps://nodejs.org/docs/latest/api/path.html#path_path_isabsolute_path\n\n```\npath.isAbsolute('//server')  // true\npath.isAbsolute('C:/foo/..') // true\n```\n\nShould be\n\n```\npath.isAbsolute('\\\\server')  // true\npath.isAbsolute('C:\\foo\\..') // true\n```\n",
        "labels": "doc",
        "id": 44671
    },
    {
        "title": "doc: replace util.inherits() with es6 classes extends",
        "body": "util.inherits() is probably long unloved. With full class support it would be worth thinking of slowly deprecating it as weakly suggested in https://github.com/nodejs/node/issues/4179 by @bnoordhuis .\n\nSince this would strongly promote the `class` keyword for the JS world we would need to think about whether we want to do this and in which form. Personally I am not a big fan of it in general - especially since es6 proposed style would have methods on a non 0 indentation level. So we could think about the following:\n\ncc @nodejs/documentation @jasnell \n\n``` js\nconst EventEmitter = require('events')\n\nclass PureES6 extends EventEmitter {\n  constructor() {\n    super()\n  }\n\n  echo(val) {\n    console.log(val)\n  }\n}\n\nlet es6 = new PureES6()\nes6.echo('A Value')\n\n\nclass Mixed extends EventEmitter {\n  constructor() {\n    super()\n  }\n\n  _echo(val) {\n    console.log(val)\n  }\n}\n\nMixed.prototype.echo = function echo (val) {\n  this._echo(val)\n}\n\nlet mixed = new Mixed()\nmixed.echo('A Value')\n\n```\n",
        "labels": "doc",
        "id": 44672
    },
    {
        "title": "doc: fs.appendFileSync wrong file argument type",
        "body": "Documentation says that _fs.appendFileSync(file, data[, options])_ accepts String or Buffer as _file_, but it accepts file descriptor too.\n\n_fs.appendFileSync(file, data[, options])_ documentation: [https://nodejs.org/dist/latest-v6.x/docs/api/fs.html#fs_fs_appendfilesync_file_data_options](https://nodejs.org/dist/latest-v6.x/docs/api/fs.html#fs_fs_appendfilesync_file_data_options)\n",
        "labels": "doc",
        "id": 44673
    },
    {
        "title": "doc: Undocumented NAPTR DNS record type",
        "body": "The DNS documentation is missing _resolveNaptr()_.\n'NAPTR' should be added as valid value for _rrtype_ below _dns.resolve(hostname[, rrtype], callback)_.\n\nDNS documentation: https://nodejs.org/dist/latest-v6.x/docs/api/dns.html\n",
        "labels": "doc",
        "id": 44674
    },
    {
        "title": "doc: dns.resolve wrong callback addresses argument description",
        "body": "The _dns.resolve(hostname[, rrtype], callback)_ description says:\n\n> The callback function has arguments (err, addresses). When successful, addresses will be an array.\n\nBut it's not true for SOA record.\n\n_dns.resolve_ documentation:\nhttps://nodejs.org/docs/latest-v6.x/api/dns.html#dns_dns_resolve_hostname_rrtype_callback\n",
        "labels": "doc",
        "id": 44675
    },
    {
        "title": "missing `close` event documentation for fs streams",
        "body": "- **Version**: all\n- **Platform**: n/a\n- **Subsystem**: `doc`\n\nCurrently there is only a mention of a `close` event in the `streams`' `Readable` section of the docs. However in the `fs` docs, it is not mentioned that either `fs.ReadStream` or `fs.WriteStream` are some of the special streams that _do_ emit `close`, but in fact _both_ of them _do_ emit `close`.\n\nSo I recommend two things:\n1. Explicitly document `close` in the events sections for `fs.ReadStream` and `fs.WriteStream`.\n2. _Either_ move the description/documentation about the `close` event from the `streams.Readable` section to earlier in the document and explain it can be emitted by any kind of stream _or_ copy the event description to at least the `streams.Writable` section.\n",
        "labels": "doc",
        "id": 44676
    },
    {
        "title": "Add supported Node.js versions in latest Docs",
        "body": "- **Version**: 6\n\nSearch engines usually show the latest docs for Node.js. Today I had the frustrating task to debug why my Buffer.from(string, encoding) function worked perfectly fine on my developer machine but threw a TypeError 'binary' is not a function. It took me a while to realise I'm running Node 4 LTS on staging and of course Node 6 on the dev machine and that Buffer.from is not working in 4 LTS, but already deprecated in 6. Worse is that Buffer.from() should have thrown the non-existing function error, as it's not listed in the v4 docs.\n\nI think it would be great help to have the supported versions for each function in the latest documentation to see when a function has been introduced and when it gets deprecated, best with colours ranging from green, orange and red (just an idea), to indicate right away the status.\n",
        "labels": "doc",
        "id": 44677
    },
    {
        "title": "undocumented console.timeEnd() change in 6.x",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**: v6.0.0\n- **Platform**: Windows 10 x64\n- **Subsystem**: console\n\n<!-- Enter your issue details below this comment. -->\n\n**_Description**_\nOn node < 6 you could call timeEnd() multiple times for the same label to receive the current elapsed time. This no longer works in node v6.\n\nThis is a side effect of this pull request https://github.com/nodejs/node/pull/3562, which fixed timers being leaked. This change completely makes sense, but it also removes (probably unintended) functionality. Should this change be in the documentation?\n\n**_Example**_\n\n``` javascript\nconsole.time('timer');\nsetTimeout(function() {\n    console.timeEnd('timer');\n}, 10);\nsetTimeout(function() {\n    console.timeEnd('timer');\n}, 20);\n```\n\n**output on node v5.9.1**\n\n```\ntimer: 11.898ms\ntimer: 20.454ms\n```\n\n**output on node v6.0.0**\n\n```\ntimer: 11.111ms\n(node:33232) Warning: No such label 'timer' for console.timeEnd()\n```\n",
        "labels": "doc",
        "id": 44678
    },
    {
        "title": "Improve documentation for build prerequisites for OS X around XCode",
        "body": "- Is a full XCode required?\n  - If not, is it recommended?\n    - If so, then what is the recommended way to get all the prerequisites?\n- If you install XCode, which of the prerequisites do you get automatically? All but Python?\n\nIt probably would make sense to split out the OS X prerequisites info from that of other Unix-like operating systems.\n",
        "labels": "doc",
        "id": 44679
    },
    {
        "title": "Docs: Scrollbar width",
        "body": "- **Version**: --\n- **Platform**: Chrome 50\n- **Subsystem**: DOCS\n\nWould it be possible to set the [scrollbar width](https://github.com/nodejs/node/blob/master/doc/api_assets/style.css#L84) to a reasonably value like `20px`? I'm on a 3440x1440px device and it is so so hard to hit that tiny little bar :)\n\n![image](https://cloud.githubusercontent.com/assets/4368785/14882563/af62dda0-0d39-11e6-8783-4a2572b77b80.png)\n",
        "labels": "doc",
        "id": 44680
    },
    {
        "title": "misprint in documentation",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- v6.0.0 \n- Documentation\n\n<!-- Enter your issue details below this comment. -->\n\nin section \"Global Objects\" you should replace \"/Users/mj/app\" to \"/Users/mjr/app\"\n",
        "labels": "doc",
        "id": 44681
    },
    {
        "title": "doc: crypto decipher.final output_encoding parameter documentation is incorrect",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**: 6.0.0\n- **Platform**: Linux 4.5.1-1-ARCH #1 SMP PREEMT x86_64 GNU/Linux\n- **Subsystem**: doc crypto\n\n<!-- Enter your issue details below this comment. -->\n\nIn the module `crypto` the documentation for [`decipher.final`](https://nodejs.org/dist/latest-v5.x/docs/api/crypto.html#crypto_decipher_final_output_encoding) seems to be wrong for the parameter `output_encoding`. It says output encoding should be `'binary'`, `'base64'` or `'hex'`, however this is contrary to the example given for _Using the decipher.update() and decipher.final() methods_. The example uses the (more logical) value of `'utf8'` and that also aligns with the documentation for `decipher.update()`.\n\nThis looks like a copy+paste error.\n\nI believe the documentations should state the possible values are `'binary'`, `'ascii'` or `'utf8'`; the same for `decipher.update()`\n\nI will make a pull request for this documentation change.\n",
        "labels": "doc",
        "id": 44682
    },
    {
        "title": "Remove duplicate entries from the AUTHORS file",
        "body": "There are a few duplicate entries there, which should probably be removed (and `.mailmap` updated).\n\nDuplicate names:\n\n```\nBenjamin Waters <benjamin.waters@outlook.com>\nBenjamin Waters <ben25890@gmail.com>\nBen Noordhuis <info@bnoordhuis.nl>\nBen Noordhuis <ben@strongloop.com>\nBrendan Ashworth <squirrelslikeacorns@gmail.com>\nBrendan Ashworth <brendan.ashworth@me.com>\nCalvin Metcalf <calvin.metcalf@gmail.com>\nCalvin Metcalf <cmetcalf@appgeo.com>\nCalvin Metcalf <calvin.metcalf@state.ma.us>\nForrest L Norvell <ogd@aoaioxxysz.net>\nForrest L Norvell <forrest@npmjs.com>\nGreg Sabia Tucker <greg@tucke.rs>\nGreg Sabia Tucker <greg@narrowlabs.com>\nIonicÄƒ BizÄƒu <bizauionica@yahoo.com>\nIonicÄƒ BizÄƒu <bizauionica@gmail.com>\nJackson Tian <shyvo1987@gmail.com>\nJackson Tian <puling.tyq@alibaba-inc.com>\nMalte-Thorben Bruns <skenqbx@googlemail.com>\nMalte-Thorben Bruns <skenqbx@gmail.com>\nMathias Buus <m@ge.tt>\nMathias Buus <mathiasbuus@gmail.com>\nMyles Borins <mborins@us.ibm.com>\nMyles Borins <myles.borins@gmail.com>\nRebecca Turner <me@re-becca.org>\nRebecca Turner <rebecca@npmjs.com>\nRefael Ackermann <refack@gmail.com>\nRefael Ackermann <refael@empeeric.com>\n```\n\nDuplicate emails:\n\n```\nSteven R. Loomis <srl@icu-project.org>\nSteven Loomis <srl@icu-project.org>\n```\n",
        "labels": "doc",
        "id": 44683
    },
    {
        "title": "Some info for EventEmitter.removeListener is missing in docs",
        "body": "- **Subsystem**: events\n\n<!-- Enter your issue details below this comment. -->\n\nDescription for `emitter.on(eventName, listener)`:\n\n> Adds the `listener` function to the end of the listeners array for the event named `eventName`. No checks are made to see if the `listener` has already been added. Multiple calls passing the same combination of `eventName` and `listener` will result in the `listener` being added, and called, multiple\n> times.\n\nThat's OK and sufficiently comprehensive (although it doesn't clarify that \"add\" is \"add as LAST\", i.e. \"push\"). However, for description on `emitter.removeListener(eventName, listener)` nothing said about a case when there are many copies of one listener in list. Does `removeListener` remove the most recently added listener or the least one? Well, actually it searches for provided listener from the end of list; but despite it may seems obvious, I had to check the [`events.js`](https://github.com/nodejs/node/blob/84ebf2b/lib/events.js#L314) source to be sure (master points to 84ebf2b at the time of this post). I suggest that it should be noted in docs.\n",
        "labels": "doc",
        "id": 44684
    },
    {
        "title": "Ambiguity in docs on console.log and util.format",
        "body": "- **Subsystem**: console, util\r\n\r\nHere is a fragment from `console` [docs](https://nodejs.org/api/console.html#console_console_log_data_args):\r\n\r\n> If formatting elements (e.g. `%d`) are not found in the first string then `util.inspect()` is called on each argument and the resulting string values are concatenated.\r\n\r\nHere is a slightly different fragment from `util` [docs](https://nodejs.org/api/util.html#util_util_format_format_args):\r\n\r\n> If the first argument is not a format string then `util.format()` returns a string that is the concatenation of all its arguments separated by spaces. Each argument is converted to a string with `util.inspect()`.\r\n\r\nHowever, the behavior of both functions differs not only due to a presence of `%` elements in the string. According to [the code](https://github.com/nodejs/node/blob/873e2f270fa67c701d59bc99f0f815f1f69b2316/lib/util.js#L66) (if I get it right), the behavior diverges due to merely `typeof` of the first argument.\r\n\r\nHere is a test code with output confusing for the naive reader (including me):\r\n\r\n``` javascript\r\nconst util = require('util');\r\n\r\nconsole.log(util.inspect(1));\r\nconsole.log(util.inspect('str'));\r\nconsole.log();\r\n\r\nconsole.log(1, 'str');\r\nconsole.log('str', 1);\r\nconsole.log();\r\n\r\nconsole.log(util.format(1, 'str'));\r\nconsole.log(util.format('str', 1));\r\nconsole.log();\r\n```\r\n\r\nThe output:\r\n\r\n```\r\n1\r\n'str'\r\n\r\n1 'str'\r\nstr 1\r\n\r\n1 'str'\r\nstr 1\r\n```\r\n\r\nThe first block shows the elements for future concatenation. The second and third ones show the output of differently disposed arguments, with none of the strings containing the `%` format elements.\r\n",
        "labels": "doc",
        "id": 44685
    },
    {
        "title": "Buffer.from not fond",
        "body": "- **Version**:v5.9.0\n- **Platform**:MINGW64_NT-10.0 DESKTOP-GBNEQPQ 2.3.0(0.290/5/3) 2015-09-29 10:48 x86_64 Msys\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nIn the API doc I find `Buffer.from(str[,encode])`  is  stable, but when I use it as `Buffer.from(\"hello\",\"utf8\")`, Node gave me the follow tip:\n\n> Buffer.from(\"hello\",'utf8')\n> TypeError: utf8 is not a function\n>     at Function.from (native)\n>     at Function.from (native)\n>     at repl:1:8\n>     at REPLServer.defaultEval (repl.js:260:27)\n>     at bound (domain.js:287:14)\n>     at REPLServer.runBound [as eval](domain.js:300:12)\n>     at REPLServer.<anonymous> (repl.js:429:12)\n>     at emitOne (events.js:95:20)\n>     at REPLServer.emit (events.js:182:7)\n>     at REPLServer.Interface._onLine (readline.js:211:10)\n\nWhen use as `Buffer.from(\"hello\")` the tip is :\n\n> TypeError: this is not a typed array.\n>     at Function.from (native)\n>     at repl:1:8\n>     at REPLServer.defaultEval (repl.js:260:27)\n>     at bound (domain.js:287:14)\n>     at REPLServer.runBound [as eval](domain.js:300:12)\n>     at REPLServer.<anonymous> (repl.js:429:12)\n>     at emitOne (events.js:95:20)\n>     at REPLServer.emit (events.js:182:7)\n>     at REPLServer.Interface._onLine (readline.js:211:10)\n>     at REPLServer.Interface._line (readline.js:550:8)\n",
        "labels": "doc",
        "id": 44686
    },
    {
        "title": "A libuv upgrade in Node v6 breaks the popular david package",
        "body": "- **Version**: v6.0.0-rc.3 (specifically, commit c3cec1eefc9f3b55a3fb7bd623b3d921f493870d)\n- **Platform**: Darwin mgol-mbpro.local 15.4.0 Darwin Kernel Version 15.4.0: Fri Feb 26 22:08:05 PST 2016; root:xnu-3248.40.184~3/RELEASE_X86_64 x86_64\n- **Subsystem**: libuv\n\nUnfortunately I don't have an isolated test case, I've only seen the `david` issue in all v6 RCs while it works fine in v5 & I reported it in https://github.com/alanshaw/david/issues/106. I did a `git bisect`, though and nailed it down to c3cec1eefc9f3b55a3fb7bd623b3d921f493870d.\n",
        "labels": "doc",
        "id": 44687
    },
    {
        "title": "path (extname, parse) cannot handle extension correctly for directory",
        "body": "- **Version**: v5.10.1\n- **Platform**: Darwin Kernel Version 15.3.0\n- **Subsystem**: path\n\nOn OS X and Linux its perfectly legal to use dot '.' in directory name.\nCurrently path.extname and path.parse handle `.` in directory name as a file extension.\n\ne.g.\n\n```\next.extname('/Users/Bob.Dev')\n> '.Dev'\n```\n\n```\next.parse('/Users/John.Smith')\n> { root: '/',\n  dir: '/Users',\n  base: 'Bob.Dev',\n  ext: '.Dev',\n  name: 'Bob' }\n```\n\nI understand that `path` don't do any validation. But this behavior is confusing an error prone.\n",
        "labels": "doc",
        "id": 44688
    },
    {
        "title": "uncaughtException documentation should mention that it not a reliable Â«restart on crashÂ» method",
        "body": "I had a discussion with a user today who apparently thought that `uncaughtException` event could be used as a reliable way to restart the application on a crash (after the cleanup and termination). Or that's how I understood what he told me.\n\nThe documentation for `uncaughtException` already has a long and expressive warning noting that the process must not be continued after receiving that exception ([ref](https://nodejs.org/api/process.html#process_warning_using_uncaughtexception_correctly)).\n\nPerhaps it should also explicitly note that the application could crash in ways that do not trigger this event, and that if one wants to restart the process in a guaranteed way â€” an external watcher should be used.\n",
        "labels": "doc",
        "id": 44689
    },
    {
        "title": "Update doc for better use of child_process.send(event, sendHandle)",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**: v5.5.0\n- **Platform**: Not useful here\n- **Subsystem**: Darwin MacBook-Pro-2.local 15.4.0 Darwin Kernel Version 15.4.0\n\n<!-- Enter your issue details below this comment. -->\n\nThe actual [DOC](https://nodejs.org/api/child_process.html#child_process_child_send_message_sendhandle_options_callback) doesn't precise that when you use `sendHandle` for sending a `net.createServer()` you can not use it in order to send a server to **multiple** children and that otherwise you will not even get an error but that everything will be messed up. There is a small mention [here](https://nodejs.org/api/child_process.html#child_process_example_sending_a_server_object) that says:\n\n> some connections can be handled by the parent and some by the **child**.\n\nOkay so this is a singular form I agree but it's in an example so this is not sufficient.\n\nBy the way, why this doesn't enable to achieve the same as per cluster multiple listen on the same port? Would be useful to not be obliged to use cluster for having multiple children listening on the same port.\n",
        "labels": "doc",
        "id": 44690
    },
    {
        "title": "Clearing require.cache of native addon makes it throw when required later.",
        "body": "- **Version**: 5.10.1 (going back to around 0.12, I think)\n- **Platform**: Darwin 14.5.0 Darwin Kernel Version 14.5.0: Wed Jul 29 02:26:53 PDT 2015; root:xnu-2782.40.9~1/RELEASE_X86_64 x86_64 i386\n- **Subsystem**: module/require\n\n`require`-ing a native addon after it has already been required and then removed from the require cache results in an error, rather than simply providing the module again.\n\nFor example, I inserted the following code into a test called `require-cache-clear`, modelled after `test/addons/hello-world`, using a dummy native module:\n\n``` js\n'use strict'\nrequire('../../common')\nconst assert = require('assert')\nconst nativeMod = './build/Release/binding'\n\nrequire(nativeMod)\ndelete require.cache[require.resolve(nativeMod)]\nassert.doesNotThrow(()=>require(nativeMod))\n```\n\nThe resulting error is:\n\n```\nError: Module did not self-register.\n    at Error (native)\n    at Object.Module._extensions..node (module.js:443:18)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:313:12)\n    at Module.require (module.js:366:17)\n    at require (internal/module.js:16:19)\n    at assert.doesNotThrow (/Users/bengl/node/test/addons/require-cache-clear/test.js:8:25)\n    at _tryBlock (assert.js:305:5)\n    at _throws (assert.js:324:12)\n    at Function.assert.doesNotThrow (assert.js:352:3)\n```\n\nA quick Google search informs me that such errors are usually the result of version mismatches, and a `node-gyp rebuild` will solve them. This isn't the case here.\n\nWe came across this due to [`mockery`](https://github.com/mfncooper/mockery/blob/master/mockery.js#L129)'s clearing of the cache. I suspect that folks using this or other modules that manipulate `require.cache`/`Module._cache` are going to (or have already) run into this at some point or another.\n\nMy best guess is that this might be related to [this comment here by @bnoordhuis](https://github.com/nodejs/node/blob/master/src/node.cc#L2265-L2267).\n",
        "labels": "doc",
        "id": 44691
    },
    {
        "title": "A more intuitive fs.mkdtemp()",
        "body": "<!--\r\nThanks for wanting to report an issue you've found in Node.js. Please fill in\r\nthe template below by replacing the html comments with an appropriate answer.\r\nIf unsure about something, just do as best as you're able.\r\n\r\nversion: `5.10.1`\r\nplatform:  `Darwin 15.3.0`\r\nsubsystem:  `fs`\r\n\r\nIt will be much easier for us to fix the issue if a test case that reproduces\r\nthe problem is provided. Ideally this test case should not have any external\r\ndependencies. We understand that it is not always possible to reduce your code\r\nto a small test case, but we would appreciate to have as\r\nmuch data as possible.\r\n\r\nThank you!\r\n-->\r\n- **Version**: `5.10.1`\r\n- **Platform**: `Darwin 15.3.0`\r\n- **Subsystem**:  `fs`\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI am happy that the Node team decided to implement `fs.mkdtemp()` - the security concerns around this behavior make me glad to see it in core.\r\n\r\nHowever, the API feels awkward to me because:\r\n- The randomness it provides is hard coded to 6 characters, which is just enough that it's _probably fine_, but not enough that I don't want to add more.\r\n- Using the `prefix` argument sounds like a good way to add random characters, but doing half the work is strange if you read code that actually does this. Additionally, _if_ I'm going to implement my own name pattern, I don't really want to _also_ have to keep in mind the one Node is using. For example, should I have to re-implement the entire `mkdtemp` just to get valid [UUIDv4](https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_.28random.29) directory names? That is genuinely useful for unit tests and also for being able to easily `mv` the temporary directory to a cache-proof URL on my server without \"renaming\" it ... lest I have to undo the suffix every time or teach my client code about it.\r\n- Using `prefix` as a directory path is messy, What would you expect this code to do?\r\n  \r\n  ``` javascript\r\n  'use strict';\r\n  \r\n  const os = require('os');\r\n  const fs = require('fs');\r\n  \r\n  fs.mkdtemp(os.tmpdir(), (err, dir) => {\r\n      if (err) {\r\n          throw err;\r\n      }\r\n      console.log('Created directory:', dir);\r\n  });\r\n  ```\r\n  \r\n  If `os.tmpdir()` returns `/tmp` for you, that will actually create a directory at the very root of your filesystem, rather than inside of `/tmp`. And it will end up being named something like `tmp-e0ew3m`. To \"fix\" this you have to use `path.join(os.tmpdir(), '/')`.\r\n\r\nI would like to propose making the API more intuitive and useful for its intended purpose: unique, convenient, secure creation of temporary directories.\r\n1. Have an explicit `cwd` argument, which is internally `path.join()`'d with the name. This is so that the name can be computed in isolation. And to prevent accidentally creating directories out in the open, where they won't actually be cleaned up.\r\n2. Replace `prefix` with (or just add) a `name` option, which is used as-is when provided. Possibly increase the default randomness for the case where one is not provided. This makes it easy to opt-out of the pattern that Node happens to use currently, which is not exposed via any kind of constant (and I don't think that would provide much value, anyway).\r\n\r\nI think these changes are best done as a breaking change, mainly to make the API less surprising. But compatibility could probably be maintained by only enabling these semantics on the options object.\r\n",
        "labels": "doc",
        "id": 44692
    },
    {
        "title": "ServerResponse doesn't inherit from stream.Writable as documented",
        "body": "- **Version**: 0.10.36\n- **Platform**: Mac OS X\n- **Subsystem**: http\n\nWhile it's possible to say `incomingMessage instanceof stream.Readable`, it's not possible to say `serverResponse instanceof stream.Writable`, where `incomingMessage` is an instance of `IncomingMessage` and `serverResponse` is an instance of `ServerResponse`.\n\nThe documentation claims:\n\n``` markdown\nClass: http.ServerResponse#\n...\nThe response implements the Writable Stream interface. \n```\n\nThis is not accurate, since it just inherits from `Stream`, not `Stream.Writable`.\n",
        "labels": "doc",
        "id": 44693
    },
    {
        "title": "stream: socket.setEncoding(null) to receive binary Buffers rather than strings has no effect",
        "body": "- **Version**: v5.8.0\n- **Platform**: Darwin 15.3.0 Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64\n- **Subsystem**: stream\n\nI've tried node 5.8.0, 5.10.0 and 4.4.2. I always receive string objects in my data handler unless I manually remove the decoder from the socket readableState:\n\n```\nconst server = net.createServer( ( c ) => {\n\n    // See https://nodejs.org/api/stream.html#stream_readable_setencoding_encoding\n    c.setEncoding( null );\n\n    // Hack that must be added to make this work as expected\n    delete c._readableState.decoder;\n\n    c.on( 'data', ( d ) => {\n\n        // Expect 'object' but get 'string' without deleting the decoder manually\n        console.log( typeof d );\n    } );\n\n} );\n```\n",
        "labels": "doc",
        "id": 44694
    },
    {
        "title": "\"Command Line Options\" document is not included in \"View on single page\"",
        "body": "- **Version**: 5.10.0\n- **Platform**: Darwin 192.168.1.7 15.4.0 Darwin Kernel Version 15.4.0: Fri Feb 26 22:08:05 PST 2016; root:xnu-3248.40.184~3/RELEASE_X86_64 x86_64\n- **Subsystem**: doc\n\n[Command Line Options](https://nodejs.org/dist/latest-v5.x/docs/api/cli.html) is not included in [View on single page](https://nodejs.org/dist/latest-v5.x/docs/api/all.html). Is this intentional? If not, I can make a PR to add it.\n",
        "labels": "doc",
        "id": 44695
    },
    {
        "title": "The current json doctool does not support grouped optional params",
        "body": "- **Version**: master 54a5287\n- **Platform**: Darwin firedfox-mbp.local 15.4.0 Darwin Kernel Version 15.4.0: Fri Feb 26 22:08:05 PST 2016; root:xnu-3248.40.184~3/RELEASE_X86_64 x86_64\n- **Subsystem**: tools, doc\n\nSome optional params in the doc are like: \n`methodName([param0, ][param1])` or `methodName([param0[, param1]])`\nSuch as:\n\n``` md\n### socket.send(msg, [offset, length,] port, address[, callback])\n## fs.writeSync(fd, data[, position[, encoding]])\n```\n\nThe current json doctool does not support grouped brackets yet. It fails to figure out what params are optional.\n\nI'll make a PR to fix it.\n",
        "labels": "doc",
        "id": 44696
    },
    {
        "title": "Some optional param comments in doc are non-standard",
        "body": "- **Version**: master 33c27f8\n- **Platform**: Darwin firedfox-mbp.local 15.4.0 Darwin Kernel Version 15.4.0: Fri Feb 26 22:08:05 PST 2016; root:xnu-3248.40.184~3/RELEASE_X86_64 x86_64\n- **Subsystem**: doc\n\nSome optional params in the doc are like: \n`methodName([param0, ][param1])` or `methodName([param0[, param1]])`\nSuch as:\n\n``` md\n### socket.send(msg, [offset, length,] port, address[, callback])\n## fs.writeSync(fd, data[, position[, encoding]])\n```\n\nThese styles prevent json.js to tell whether they are optional. \nThe correct format is: `methodName([param0][, param1])`\nSuch as:\n\n``` md\n### socket.send(msg[, offset][, length], port, address[, callback])\n## fs.writeSync(fd, data[, position][, encoding])\n```\n\nI'll make a PR to fix it.\n",
        "labels": "doc",
        "id": 44697
    },
    {
        "title": "Testing the doctool",
        "body": "Both the JSON and HTML output of the doctool are currently untested while tests could have prevented these recent issues:\n- https://github.com/nodejs/node/issues/5873\n- https://github.com/nodejs/node/issues/5942\n\nAs a start, a test could include JSON.parse and possibly some lightweight HTML validation triggered by `make test-doc` / `vcbuild test-doc`.\n",
        "labels": "doc",
        "id": 44698
    },
    {
        "title": "Error found when generating JSON doc",
        "body": "- **Version**: master [b1c0587](https://github.com/nodejs/node/commit/b1c05871a38b97ebdf5b4b8b1eaacd5f6494deec)\n- **Platform**: Darwin firedfox-mbp.local 15.3.0 Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64\n- **Subsystem**: tools\n\nWhen I run tools/doc/generate.js to build JSON format docs, I see this error:\n\n```\nInput file = fs.markdown\n/Users/firedfox/git/node/tools/doc/json.js:207\n        throw new Error('invalid list - text without current item\\n' +\n        ^\n\nError: invalid list - text without current item\n{\"type\":\"text\",\"text\":\"`callback` {Function}\"}\n[{\"type\":\"list_start\",\"ordered\":false},{\"type\":\"list_item_start\"},{\"type\":\"text\",\"text\":\"`path` {String | Buffer}\"},{\"type\":\"list_item_end\"},{\"type\":\"list_item_start\"},{\"type\":\"text\",\"text\":\"`options` {String | Object}\"},{\"type\":\"list_start\",\"ordered\":false},{\"type\":\"list_item_start\"},{\"type\":\"text\",\"text\":\"`encoding` {String} default = `'utf8'`\"},{\"type\":\"list_item_end\"},{\"type\":\"list_end\"},{\"type\":\"list_item_end\"},{\"type\":\"loose_item_start\"},{\"type\":\"text\",\"text\":\"`callback` {Function}\"},{\"type\":\"list_item_end\"},{\"type\":\"loose_item_start\"},{\"type\":\"text\",\"text\":\"`path` {String}\"},{\"type\":\"list_item_end\"},{\"type\":\"list_item_start\"},{\"type\":\"text\",\"text\":\"`callback` {Function}\"},{\"type\":\"space\"},{\"type\":\"list_item_end\"},{\"type\":\"list_end\"}]\n    at /Users/firedfox/git/node/tools/doc/json.js:207:15\n    at Array.forEach (native)\n    at processList (/Users/firedfox/git/node/tools/doc/json.js:183:8)\n    at /Users/firedfox/git/node/tools/doc/json.js:115:9\n    at Array.forEach (native)\n    at doJSON (/Users/firedfox/git/node/tools/doc/json.js:17:9)\n    at next (/Users/firedfox/git/node/tools/doc/generate.js:42:27)\n    at /Users/firedfox/git/node/tools/doc/preprocess.js:16:5\n    at processIncludes (/Users/firedfox/git/node/tools/doc/preprocess.js:26:33)\n    at preprocess (/Users/firedfox/git/node/tools/doc/preprocess.js:13:3)\n```\n\nIt's caused by the following content in fs.markdown:\n\n``` markdown\n## fs.readdir(path[, options], callback)\n\n* `path` {String | Buffer}\n* `options` {String | Object}\n  * `encoding` {String} default = `'utf8'`\n* `callback` {Function}\n\n* `path` {String}\n* `callback` {Function}\n```\n\nCurrent `processList` function in tools/doc/json.js does not recognise the second `path` and `callback`'s `{\"type\":\"loose_item_start\"}`. I'll make a PR to fix it.\n",
        "labels": "doc",
        "id": 44699
    },
    {
        "title": "socket.destroyed is left undocumented?",
        "body": "Hi, this is my first report to node.js and I apologies in advance if the issue doesn't make sense.\n\nI was going thru the documentation of the `net` module and found out that the `destroyed` property isn't documented. I was wondering if that is an official API or not to check the status of the socket connection. If not `destroyed` what else can I use to check the current status of the socket connection?\n\nNode Version : Node.js v5.9.1 Documentation\n\nThanks.\n",
        "labels": "doc",
        "id": 44700
    },
    {
        "title": "doc: Buffer buf.readInt32LE(offset[, noAssert]) example incorrect",
        "body": "- **Version**: 4.2.1\n- **Platform**: Ubuntu 14.04 64-bit\n- **Subsystem**: Buffer\n\nThe example for [`buf.readInt32LE(offset[, noAssert])`](https://nodejs.org/dist/latest-v4.x/docs/api/buffer.html#buffer_buf_readint32le_offset_noassert) appears to be incorrect.\n\n```\nconst buf = new Buffer([1,-2,3,4]);\n\nbuf.readInt32BE();\n  // returns 33424132\nbuf.readInt32LE(1);\n  // returns 67370497\n```\n\nRunning locally in a REPL:\n\n```\n$ node\n> const buf = new Buffer([1,-2,3,4]);\nundefined\n> buf.readInt32BE();\n33424132\n> buf.readInt32LE(1);\nRangeError: index out of range\n    at checkOffset (buffer.js:619:11)\n    at Buffer.readInt32LE (buffer.js:772:5)\n    at repl:1:5\n    at REPLServer.defaultEval (repl.js:164:27)\n    at bound (domain.js:280:14)\n    at REPLServer.runBound [as eval] (domain.js:293:12)\n    at REPLServer.<anonymous> (repl.js:393:12)\n    at emitOne (events.js:82:20)\n    at REPLServer.emit (events.js:169:7)\n    at REPLServer.Interface._onLine (readline.js:210:10)\n>\n```\n\nThe `offset` check is something like `offset + 3 < buffer.length`, so `4 < 4` fails as it should.\n",
        "labels": "doc",
        "id": 44701
    },
    {
        "title": "The order of end tags of list after heading in HTML doc is wrong",
        "body": "- **Version**: v5.9.0\n- **Platform**: Darwin firedfox-mbp.local 15.3.0 Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64\n- **Subsystem**: doc\n\nWhile using generate.js to convert a list after heading into HTML, the order of end tags is wrong.\n\n``` markdown\n### Heading\n* item\n```\n\nis converted to\n\n``` html\n<h3>Heading</h3>\n<div class=\"signature\"><ul>\n<li>item</li>\n</div></ul>\n```\n\nFor example:\n\n``` markdown\n### Class Method: Buffer.from(array)\n* `array` {Array}\n```\n\nis converted to\n\n``` html\n<h3>Class Method: Buffer.from(array)<span><a class=\"mark\" href=\"#buffer_class_method_buffer_from_array\" id=\"buffer_class_method_buffer_from_array\">#</a></span></h3>\n<div class=\"signature\"><ul>\n<li><code>array</code> <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array\" class=\"type\">&lt;Array&gt;</a></li>\n</div></ul>\n```\n",
        "labels": "doc",
        "id": 44702
    },
    {
        "title": "fs.readFile don't work with file descriptor",
        "body": "Function fs.readFile should understand both file name and file descriptor as the first argument, it's specified in [docs ](https://nodejs.org/dist/latest-v4.x/docs/api/fs.html#fs_fs_readfile_file_options_callback) for Node.js v4.x.\n\nI try to use code like this:\n\n```\nvar fs = require('fs');\n\nvar filename = './test/test.json';\n\nfs.open(filename, 'r', function (err, fh) {\n    console.log(arguments);\n    fs.readFile(fh, 'utf8', function () {\n        console.log(arguments);\n    });\n});\n```\n\nAnd I got that output: \n\n```\n{ '0': null, '1': 9 }\nfs.js:250\n  binding.open(pathModule._makeLong(path),\n          ^\n\nTypeError: path must be a string\n    at TypeError (native)\n    at Object.fs.readFile (fs.js:250:11)\n    at /home/ubuntu/workspace/temp.js:7:8\n    at FSReqWrap.oncomplete (fs.js:82:15)\n```\n\nMy software version:\n\n```\n$ node --version\nv4.4.1\n\n$ uname -a\nLinux topal-file_storage-2753437 4.2.0-c9 #1 SMP Fri Nov 20 14:49:01 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n```\n",
        "labels": "doc",
        "id": 44703
    },
    {
        "title": "doc: html of api doesn't allow scrolling past larger code blocks on mobile safari",
        "body": "- **Subsystem**: `doc`\n\nusers on iPhones cannot scroll past larger code blocks. It looks like a redrawing issue, since browser likely knows the correct size of the whole page. \n\nIn the screen that you see me trying to moving up or down, white not having a scroll handle outside of the code block any more\n\nref nodejs/docs#92 (closes nodejs/docs#92)\n\n![img_0268](https://cloud.githubusercontent.com/assets/3899684/13981674/c7904694-f0e5-11e5-83fa-67baf9beacbc.PNG)\n",
        "labels": "doc",
        "id": 44704
    },
    {
        "title": "Possible improvement of \"Read file stream line-by-line\" example in readline doc ",
        "body": "https://nodejs.org/api/readline.html#readline_example_read_file_stream_line_by_line\n\nWould it be for more efficiency, speed, resource saving and consistency to update this call:\n\n``` javascript\nconst rl = readline.createInterface({\n  input: fs.createReadStream('sample.txt')\n});\n```\n\nwith these options:\n\n``` javascript\nconst rl = readline.createInterface({\n  input: fs.createReadStream('sample.txt'),\n  terminal: false,\n  historySize: 0\n});\n```\n",
        "labels": "doc",
        "id": 44705
    },
    {
        "title": "cluster.on('message') not return worker ",
        "body": "- **Version**: 4.4.0, 5.9.0\n- **Platform**: Linux test 4.4.4-calculate #1 SMP PREEMPT Wed Mar 9 16:35:58 MSK 2016 x86_64 Intel(R) Core(TM) i5-3470 CPU @ 3.20GHz GenuineIntel GNU/Linux\n- **Subsystem**: cluster, documentation\n\nIn [documentation](https://nodejs.org/dist/latest-v5.x/docs/api/cluster.html#cluster_event_message_1):\n\n```\nEvent: 'message'#\nworker <cluster.Worker>\nmessage <Object>\nEmitted when any worker receives a message.\n```\n\nbut real use is:\n\n```\ncluster.on('message', msg => { /* worker isn`t known */ })\n```\n",
        "labels": "doc",
        "id": 44706
    },
    {
        "title": "path, doc: More examples for path.format()",
        "body": "The doc for `path.format()` has a bunch of details about the algorithm. Example code that demonstrates the different elements of the explanation would be useful. For example: An example of what happens if the `pathObject` argument does not have a `dir` property.\n\nThis is a good first contribution for someone looking to get familiar with the contribution process.\n",
        "labels": "doc",
        "id": 44707
    },
    {
        "title": "path, doc: Explain \"expected properties\" ",
        "body": "In the `path.format()` documentation, it refers to the \"expected properties\" of `pathObject`. Add a sentence or so explaining what those \"expected properties\" are or link to another part of the doc that explains such things.\n\nAlternatively, change that sentence to specify the `dir` and `base` properties rather than \"expected properties\" since those are actually the only two that matter in the context of the sentence that says \"expected properties\".\n\nThis is a good first contribution for someone interested in getting familiar with the contribution process.\n",
        "labels": "doc",
        "id": 44708
    },
    {
        "title": "http.ClientRequest documentation inconsistencies",
        "body": "The documentation for http.ClientRequest states that you can use\nsetHeader / getHeader / removeHeader but the motheds are not listed below\nas methods of this class.\n\nMethod addTrailers is also not mentioned although it's there ans it's working.\n",
        "labels": "doc",
        "id": 44709
    },
    {
        "title": "docs: Document `MakeCallback`",
        "body": "`MakeCallback` is required to call js from C++ properly, but it's not mentioned in docs at all.\n",
        "labels": "doc",
        "id": 44710
    },
    {
        "title": "docs: incorrect man page link in html modules doc",
        "body": "In https://nodejs.org/dist/latest-v5.x/docs/api/modules.html#modules_modules\n\nThe following line appears:\nvar mySquare = <a href=\"http://man7.org/linux/man-pages/man2/square.2.html\">square(2)</a>;\n\nWhich should just be:\nvar mySquare = square(2);\n\nLooks like the thing that generates links to man pages automatically is a little overzealous.\n",
        "labels": "doc",
        "id": 44711
    },
    {
        "title": "buffer: documentation incorrect",
        "body": "The documentation of `writeU?Int(8|((16|32)[BL]E))?` [states](https://github.com/nodejs/node/blob/master/doc/api/buffer.markdown#bufwriteintlevalue-offset-bytelength-noassert) that the return value is the number of bytes written, while it [actually is](https://github.com/nodejs/node/blob/e2488fa953ee4e9673ba51f20bc5b7eff2e0ffba/lib/buffer.js#L874) the offset plus this number.\n\nThis is inconsistent with a plain `write`, which returns only the bytes written, so before sending a PR, I wanted to ask which option is preferred: Correct the code (which might break modules & backwards compatibility) or fix the documentation.\n",
        "labels": "doc",
        "id": 44712
    },
    {
        "title": "doc:Error:captureStackTrace description inaccurate",
        "body": "From at least Node 4.2 the [documentation](https://nodejs.org/dist/latest-v4.x/docs/api/errors.html#errors_error_capturestacktrace_targetobject_constructoropt) says:\n\n> The first line of the trace, instead of being prefixed with `ErrorType:\n> message`, will be the result of calling `targetObject.toString()`.\n\nThis test program:\n\n```\nvar assert = require('assert');\n\nfunction X(msg) {\n  this.message = msg;\n}\nX.prototype.name = 'X';\nX.prototype.toString = function() { return 'toString'; }\n\nvar x = new X('something');\nassert.deepEqual(x, {message: 'something'});\nassert.equal(x.toString(), 'toString');\n\nError.captureStackTrace(x);\nassert.equal(x.stack.split('\\n')[0], 'X: something');\n```\n\nproves the description incorrect.  The first line is produced by `deps/v8/src/messages.js` in `ErrorToStringDetectCycle` from the `name` and `message` properties of `targetObject` with this logic:\n\n```\nif (name === \"\") return message;\nif (message === \"\") return name;\nreturn name + \": \" + message;\n```\n\nwhere `name` defaults to `\"Error\"` and `message` defaults to `\"\"`.\n\nI'm not good at user-facing technical documentation so I'd rather not try to craft replacement text for something that complex.\n",
        "labels": "doc",
        "id": 44713
    },
    {
        "title": "`doc/api/tls.markdown` needs punctuation fixes",
        "body": "This is a good first contribution for someone looking for such a thing.\n\nThere appear to be approximately seven uses of `-` in the prose of `tls.markdown`. Its usage in that document is mostly non-idiomatic. Most or all of them would be better as commas or other punctuation.\n",
        "labels": "doc",
        "id": 44714
    },
    {
        "title": "`doc/api/path.markdown` needs a win32 example for `path.format()`",
        "body": "Good first time contribution for someone interested in such a thing...\n",
        "labels": "doc",
        "id": 44715
    },
    {
        "title": "repl: useGlobal docs and code mismatch",
        "body": "The API documentation for REPL says, \n\n\"`useGlobal` - if set to `true`, then the repl will use the global object, instead of running scripts in a separate context. Defaults to `false`.\"\n\nThis is only true if a REPL is created programmatically. The REPL that is created by simply typing `node` on the command line defaults `useGlobal` to `true`.\n\nThis is because the internal `createRepl` function, used by `node.js` [here](https://github.com/nodejs/node/blob/master/src/node.js#L160), defaults this value to `true`. https://github.com/nodejs/node/blob/master/lib/internal/repl.js#L25 \n\nThis can be verified by simply firing up a node REPL and typing `.clear`. You should see on the REPL command line, this text, [\"Clearing context....\"](https://github.com/nodejs/node/blob/master/lib/repl.js#L1044-L1047), but you don't.\n- **Version**: 4.2.4\n- **Platform**: Darwin Cerebus.local 15.3.0 Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64\n- **Subsystem**: repl\n",
        "labels": "doc",
        "id": 44716
    },
    {
        "title": "doc: Event: 'unhandledRejection' code example not borked",
        "body": "https://nodejs.org/api/process.html#process_event_unhandledrejection\n\n``` js\nsomePromise.then((res) => {\n  return reportToUser(JSON.parse(res)); // note the typo\n}); // no `.catch` or `.then`\n```\n\nSomeone [made off](https://github.com/jasnell/node/commit/f950904650a33ad9cdb0ecf6eb6cf1df335c14ca) with the typo. When this is put back together I'd suggest updating to something like:\n\n``` js\n// note the typo (`pasre`)\n```\n",
        "labels": "doc",
        "id": 44717
    },
    {
        "title": "docs,events: ee.once() event ordering differs from documentation",
        "body": "- **Version**: v4.3.2\n- **Platform**: Linux osmith-ubuntu-t1700 4.2.0-30-generic #36-Ubuntu SMP Fri Feb 26 00:58:07 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**: events, docs\n\nDocumentation describes `ee.once()` behaviour as (emphasis mine)\n\n> Adds a one time listener function for the event. This listener is invoked only the next time event is triggered, **after** which it is removed.\n\nThe actual current behaviour is for the listener to removed, and then invoked.\n\n``` js\n'use strict';\n\nconst assert = require('assert');\nconst EventEmitter = require('events');\n\nconst order = [];\n\nnew EventEmitter()\n  .on('removeListener', () => order.push('remove'))\n  .once('foo', () => order.push('invoke'))\n  .emit('foo');\n\nprocess.on('exit', () => assert.deepEqual(order, ['invoke', 'remove']));\n```\n\n```\nassert.js:89\n  throw new assert.AssertionError({\n  ^\nAssertionError: [ 'remove', 'invoke' ] deepEqual [ 'invoke', 'remove' ]\n    at process.<anonymous> (/home/omsmith/ee-once-remove-order-test/index.js:13:33)\n    at emitOne (events.js:77:13)\n    at process.emit (events.js:169:7)\n```\n",
        "labels": "doc",
        "id": 44718
    },
    {
        "title": "There is no 'crl' option description in documentation for tls.connect() (TLS core module).",
        "body": "https://nodejs.org/api/tls.html\n\ntls.createServer() documentation cointains 'crl' option description.\nI.e. server can check CRL (Certificates Revokation List) for client certificates.\n\ntls.connect() does not cointain 'crl' option description.\nI.e. client can not check (out of the box) CRL for server certificates?\nIt looks a bit inconsistent.\nShould I use checkServerIdentity() to iterate some my CRL 'by hands'?\nOr this option is supported by tls.connect(), but is not described in the doc?\n",
        "labels": "doc",
        "id": 44719
    },
    {
        "title": "Test Directory Documentation",
        "body": "The `test` directory has a number of subdirectories that could use some explanation. It is probably a good idea to add a `README` to that directory to explain what each subdirectory is and whether or not the tests in that directory get run on the continuous integration server or not. (Look at the `test-ci` task in the Makefile to find out.)\n\nI'm labeling this `good first contribution` even though a first-time contributor might not know what all the directories are. Don't worry about it, First Time Contributor! Just take your best guess after perusing the test files in each directory for a little bit and any mistakes will get sorted out in the pull request conversation.\n",
        "labels": "doc",
        "id": 44720
    },
    {
        "title": "possibly archive \"old\" CHANGELOG.md entries (by year?)",
        "body": "[CHANGELOG.md](https://github.com/nodejs/node/blob/master/CHANGELOG.md) is huge. My local markdown viewer now locks up attempting to preview it. I think we should begin archiving it by year.\n\ncc @nodejs/ctc?\n",
        "labels": "doc",
        "id": 44721
    },
    {
        "title": "Documentation for __dirname is misleading",
        "body": "The [documentation for `__dirname`](https://nodejs.org/docs/latest/api/globals.html#globals_dirname) states that it gives _\"The name of the directory that the currently executing script resides in.\"_\n\nThis may be taken to imply that `__dirname` always refers to the path of the module that was invoked as a script from the command line. However, it actually always produces the path of the **current** module, no matter where it was required from.\n\nJust to clarify: assume I have modules\n\n```\na.js\nb/b.js\n```\n\nand `a.js` requires `b.js`. I run `node a.js`, and `b.js` uses its `__dirname`, which will refer to the `b` subdirectory. The current wording implies that it might actually refer to the directory that `a.js` is contained in since that is the \"script\" that I ran from the command line.\n",
        "labels": "doc",
        "id": 44722
    },
    {
        "title": "Documentation on how to build docs missing",
        "body": "I've made a couple updates to the docs but I can't easily review them (especially ones where e.g. links to headers are built automatically) because I can't figure out how the doc build works.\n## Expected\n\n`README.md` in the docs directory explaining how to run the markdown:arrow_right:html build & review the html output.\n## Actual\n\nNo documentation or I can't find it.\n",
        "labels": "doc",
        "id": 44723
    },
    {
        "title": "vm: variable declaration persists across two runInContext() ",
        "body": "- **Version**: 5.7.0\n- **Platform**: windows 7.1 Pro 64 bits\n- **Subsystem**: vm\n## Code\n\n``` js\nconst vm = require('vm');\nconst assert = require('assert');\nconst context = {\n    results: {}\n};\n\n// 1st execution\nconst sandBox1 = vm.createContext(context);\n\nlet sFormula1 = \"\";\nsFormula1 += \"'use strict';\\n\";\nsFormula1 += \"let x = 1;\\n\";\nsFormula1 += \"let y = 2;\\n\";\nsFormula1 += \"let z = 0 ;\\n\";\nsFormula1 += \"z = x + y;\\n\";\nsFormula1 += \"results.z = z;\\n\";\n\nvm.runInContext(sFormula1, sandBox1);\n\n// *** 2nd execution ***\n// get the value of z from the first sandbox\ncontext.results.z = sandBox1.results.z;\n// sandboxing the new context\nconst sandBox2 = vm.createContext(context);\n\nlet sFormula2 = \"\";\nsFormula2 += \"'use strict';\\n\";\nsFormula2 += \"let z = 10\\n\";\nsFormula2 += \"results.z = z;\\n\";\n\nvm.runInContext(sFormula2, sandBox2);\n\n```\n## Expected result\n\nThis code should't throw.\n## Actual result\n\nThis code throw the following error:\n\n``` js\nevalmachine.<anonymous>:1\n'use strict';\n^\n\nTypeError: Identifier 'z' has already been declared\n    at evalmachine.<anonymous>:1:1\n    at Object.exports.runInContext (vm.js:44:17)\n    at Object.<anonymous> (C:\\node-projects\\cvl-node-extdirect\\bugVM.js:33:4)\n    at Module._compile (module.js:413:34)\n    at Object.Module._extensions..js (module.js:422:10)\n    at Module.load (module.js:357:32)\n    at Function.Module._load (module.js:314:12)\n    at Function.Module.runMain (module.js:447:10)\n    at startup (node.js:141:18)\n    at node.js:933:3\n```\n\nlet declaration is block-scope, and note that it's not even the same sandbox in the two runInContext(), so how is it possible to get this error ?\n\nAm I wrong somewhere ?\n",
        "labels": "doc",
        "id": 44724
    },
    {
        "title": "Is JSON output still experimental?",
        "body": "This feature was added in Node.js v0.6.12. I believe this is a few years ago and should be stable enough. If there was any issue it would be already fixed by now. @nodejs/documentation @nodejs/website \n",
        "labels": "doc",
        "id": 44725
    },
    {
        "title": "doc: how to join a wg?",
        "body": "It is not clear from the docs how to candidate yourself to join a wg: what is the process?\n\nI think we should add a little section after https://github.com/nodejs/node/blob/master/WORKING_GROUPS.md#starting-a-wg, \"joining a WG\".\n\nRef: https://github.com/nodejs/readable-stream/pull/185#issuecomment-189118072\n\ncc @Fishrock123 \n",
        "labels": "doc",
        "id": 44726
    },
    {
        "title": "HTTP IncomingMessage links broken in 4.x docs",
        "body": "- **Version**: 4.3.1\n- **Platform**: _n/a_\n- **Subsystem**: docs\n\nlinks to `#http_http_incomingmessage` in 4.x docs should be to `#http_class_http_incomingmesage`\n\nhttps://nodejs.org/dist/latest-v4.x/docs/api/http.html\n",
        "labels": "doc",
        "id": 44727
    },
    {
        "title": "doc/bug: repl.start() prompt doesn't default to '> '",
        "body": "- **Version**: v5.7.0\n- **Platform**: Linux arch-desktop 4.4.1-2-ARCH #1 SMP PREEMPT Wed Feb 3 13:12:33 UTC 2016 x86_64 GNU/Linux\n\nFollowing the contents of `./doc/api/repl.markdown`, lines 217-227, I put this in `repl_test.js`:\n\n```\nconst repl = require('repl');\n\nvar replServer = repl.start();\nreplServer.defineCommand('sayhello', {\n  help: 'Say hello',\n  action: function(name) {\n    this.write(`Hello, ${name}!\\n`);\n    this.displayPrompt();\n  }\n});\n```\n\nRunning that, I get \n\n```\nrepl.js:198\n    throw new Error('An options Object, or a prompt String are required');\n```\n\nOn line 252 of `./doc/api/repl.markdown`, it is noted that prompt should default to `>` if an options object is passed in, but not what should happen if it is called without arguments.\n\nI took a look at `./lib/readline.js` and `./lib/repl.js` and the culprit for the code snippet failing (if the docs represent the intended functionality) is line 197-198 of `./lib/repl.js`.\n\nEither way, it seems to me that either the docs should be updated to reflect the code, or those lines in `./lib/repl.js` should be removed to make it fall back to an empty object and thus the default `>` prompt. No PR submitted because I don't know which of the directions to go in.\n",
        "labels": "doc",
        "id": 44728
    },
    {
        "title": "doc: assert.deepStrictEqual() description inaccurate",
        "body": "[`deepStrictEqual()` description](https://nodejs.org/api/assert.html#assert_assert_deepstrictequal_actual_expected_message) currently begins with:\n\n> Generally identical to `assert.deepEqual()` with the exception that primitive\n> values are compared using the strict equality operator ( `===` ).\n\nBut, `deepStrictEqual()` also [compares prototype equality](https://github.com/nodejs/node/blob/18abb3ccc2e0917e1371ab9afae4852bdeaa298c/lib/assert.js#L199). Example (`v5.6.0`):\n\n``` js\nvar assert = require(\"assert\");\n\nvar a = [0];\nvar b = {0: 0};\n\n[\"deepEqual\", \"deepStrictEqual\"].forEach(function (meth) {\n  assert[meth](a, b, \"not \" + meth);\n});\n// AssertionError: not deepStrictEqual\n```\n",
        "labels": "doc",
        "id": 44729
    },
    {
        "title": "doc net: incorrect error handling documented for listen()",
        "body": "Under the section https://nodejs.org/api/net.html#net_server_address it states that the error is passed to the `listen()` callback. This is incorrect. The error is passed to the server's `'error'` event handler. Like so:\n\n``` js\nnet.createServer()\n  .on('error', () => console.log('foo'))\n  .listen(80, () => console.log('bar'));\n// Output: foo\n```\n\nFiling this instead of simply fixing this one occurrence b/c unsure if more cases like this exist, and don't have the time to investigate at the moment.\n",
        "labels": "doc",
        "id": 44730
    },
    {
        "title": "doc,tool: parse standard error types automatically?",
        "body": "Hi guys. I decided to move discussion here from [#5322](https://github.com/nodejs/node/issues/5322#issuecomment-186229820).\n\nCurrently [errors.markdown](https://github.com/nodejs/node/blob/c4b5a451e30b3063a1fbc471052dc9baa8666d6e/doc/api/errors.markdown) has some unresolved links to standard errors description on MDN. Below there is a list of described errors:\n- `EvalError`\n- `RangeError`\n- `ReferenceError`\n- `SyntaxError`\n- `TypeError`\n- `URIError`\n\nAnd also doc tool has [type parser](https://github.com/nodejs/node/blob/c4b5a451e30b3063a1fbc471052dc9baa8666d6e/tools/doc/type-parser.js#L10) with list of global types.\n\nMaybe add these errors to global types list, so it would be possible just use `{SyntaxError}`? Also this would save some bytes.\n",
        "labels": "doc",
        "id": 44731
    },
    {
        "title": "doc: markdown links do not turn into real links",
        "body": "Hey,\n\nI noticed that in various docs, links are not shown and actual markdown appears instead.\n\n**Examples:**\n- In tls.html:\n  `tlsSocket is the [tls.TLSSocket][] that the error originated from.`\n- In net.html:\n  `The parameter backlog behaves the same as in [server.listen(port, \\[host\\], \\[backlog\\], \\[callback\\])][].`\n- In cluster.html:\n  `When no more connections exist, see [server.close()][], the IPC channel to the worker will close allowing it to die gracefully.`\n- In crypto.html:\n  `Use [crypto.getCurves()][] to obtain a list of available curve names.`\n",
        "labels": "doc",
        "id": 44732
    },
    {
        "title": "Addon documentation has some old style Init's",
        "body": "https://nodejs.org/dist/latest-v5.x/docs/api/addons.html\n\nObject Factory section\n\n```\nvoid Init(Local<Object> exports, Local<Object> module)\n```\n\nAlso \nFunction factory \n\n```\nvoid Init(Local<Object> exports, Local<Object> module) \n```\n\nFactory of wrapped objects\n\n```\nvoid InitAll(Local<Object> exports, Local<Object> module)\n```\n",
        "labels": "doc",
        "id": 44733
    },
    {
        "title": "Require with an uppercase make a new instance of module on mac osx",
        "body": "Given a file named `test.js`,\nUsing require in those two way will works, but node will create a new instance for each:\n`require('./test.js')` and `require('./Test.js')`\nTested on Mac osx 10.11.1 with node 4.2.4\n",
        "labels": "doc",
        "id": 44734
    },
    {
        "title": "Either Cluster API doc or Cluster event 'message' argument is wrong",
        "body": "https://nodejs.org/dist/latest-v5.x/docs/api/cluster.html#cluster_event_message_1\nCluster event 'message' has two arguments: worker object and message? Really? I will only get one argument - the message.\n\nEnv: Windows, 64bit, v5.5.0\n\nWould be nice if there is a worker object, because it makes life easier...\n",
        "labels": "doc",
        "id": 44735
    },
    {
        "title": "dgram `socket.send()` documentation needs clarification",
        "body": "In [the version of the `dgram` doc that is current as of this writing](https://github.com/nodejs/node/blob/6e3bccbc03ffbdf0420f4802b5d992bc27bc5b0f/doc/api/dgram.markdown), the first argument (`buf`) is described initially as:\n\n> Buffer object, string, or an array of either. Message to be sent.\n\nHowever, it is subsequently described as a Buffer object only:\n\n> The `buf` argument is a [`Buffer`] object containing the message. The `offset`\n> and `length` specify the offset within the `Buffer` where the message begins\n> and the number of bytes in the message, respectively. With messages that\n> contain  multi-byte characters, `offset` and `length` will be calculated with\n> respect to [byte length][] and not the character position.\n\nAdditionally, it is not clear what `offset` and `length` mean when the `buf` argument is an array. It's also not clear if the multi-byte caveat applies if `buf` is a string or only if `buf` is a Buffer object.\n\nIt may be worth changing the name from `buf` to `msg` or something like that.\n\n/cc @nodejs/documentation \n",
        "labels": "doc",
        "id": 44736
    },
    {
        "title": "Case-sensitive algorithm argument in crypto.createVerify()",
        "body": "Contrary to what can be seen & read in the [documentation](https://nodejs.org/docs/latest/api/crypto.html#crypto_class_verify),\n\n``` js\nconst verify = crypto.createVerify('rsa-sha256');\n```\n\n`crypto.createVerify()` throws if the algorithm argument is lowercase:\n\n```\ncrypto.js:295\n  this._handle.init(algorithm);\n               ^\n\nError: Unknown message digest\n    at Error (native)\n    at new Verify (crypto.js:295:16)\n    at Object.Verify (crypto.js:292:12)\n```\n\nIt works perfectly fine if the algorithm is uppercased. Is this intended behavior (and the documentation just needs updating) or is this indeed a minor bug?\n",
        "labels": "doc",
        "id": 44737
    },
    {
        "title": "Broken example for vm.runInDebugContext(code)",
        "body": "The current example fails\n\n``` js\nconst Debug = vm.runInDebugContext('Debug');\nDebug.scripts().forEach(function(script) { console.log(script.name); });\n```\n\nThe error I receive is\n\n``` bash\nDebug.scripts().forEach(function(script) {\n      ^\nillegal access\n```\n\nWill do more research and post in this thread\n",
        "labels": "doc",
        "id": 44738
    },
    {
        "title": "readline.question",
        "body": "So, I found [readline.question](https://github.com/nodejs/node/blob/master/doc/api/readline.markdown#rlquestionquery-callback) today, and it looks really odd.\n\nFirst, it doesn't follow the `(err, data)` nodeback convention at all (where do errors go?).\nSecond, it doesn't really feel like something that should be in core.\n\nShould it be soft-deprecated?\nShould it be \"fixed\" to conform to the node-back convention (not very likely)?\n",
        "labels": "doc",
        "id": 44739
    },
    {
        "title": "doc: stream state after unpipe is undocumented",
        "body": "The documentation doesn't mention whether unpipe leaves the stream in flowing mode, or whether a manual resume is needed. If it could mention that, I think that would be helpful. It would also be good to clarify under which circumstances (eg: always vs. when the last pipe has been removed vs. as-long-as-there-are-data-listeners etc...).\n",
        "labels": "doc",
        "id": 44740
    },
    {
        "title": "doc: Explicitly indicate that EventEmitter's listeners will still be invoked if they were removed during the emit cycle",
        "body": "As discussed in [https://github.com/nodejs/node-v0.x-archive/issues/7872](https://github.com/nodejs/node-v0.x-archive/issues/7872), EventEmitter's listeners are still called if they are removed during the emit() cycle. It was agreed that this is the intended behavior, however, there is nothing in [EventEmitter's documentation](https://nodejs.org/api/events.html) that would explicitly indicate that.\n\nI think the documentation needs to be updated to clarify this behavior, because it's not necessarily obvious.\n",
        "labels": "doc",
        "id": 44741
    },
    {
        "title": "doc: fence code blocks",
        "body": "Currently, we use 4-space indent to mark code blocks in the docs. It'd be better if we could replace them with backtick fences like ````js` or ````c++`. This has two benefits:\n\n1) It's required for syntax highlighting to work on GitHub\n2) It allows the code samples to be linted with tools like [eslint-plugin-markdown](https://github.com/eslint/eslint-plugin-markdown)\n\nBecause this would be another \"churn\" commit, I'd like to ask for opinions first.\n",
        "labels": "doc",
        "id": 44742
    },
    {
        "title": "http listen method is possible to be called twice with no error",
        "body": "I've realised that if I create an http server and I call `listen` on the same `port` and `hostname`, several times, no error is reported on `error` event and the `listen` callback is called each time.\n\nI've been surprised in finding this behaviour and I'm not sure if this is the expected one after I've tried to found this case in the docs; so I've opened this issue.\n",
        "labels": "doc",
        "id": 44743
    },
    {
        "title": "docs: Add usage example of readline line-by-line parsing",
        "body": "While authoring a parser, I came across what you would normally get in organic search and found lots of it a little dangerous. Namely the use of big module APIs from `npm` don't occur to make the biggest sense here, since `readline` has a lot of good functionality built-in. Namely consuming file through `readline`'s interface as steam.\n\nIn order to promote use of this, I'd suggest to add an example usage to the docs, which I derived from this [stackoverflow link](http://stackoverflow.com/questions/6156501/read-a-file-one-line-at-a-time-in-node-js/32599033#32599033). \n\nThis case seemed really common to me, which is why I authored the below PR.\n\n``` js\nconst readline = require('readline');\nconst fs = require('fs');\n\nconst rl = readline.createInterface({\n  input: fs.createReadStream('sample.txt')\n});\n\nrl.on('line', function (line) {\n  console.log('Line from file:', line);\n});\n```\n\nPR: #4609 \n",
        "labels": "doc",
        "id": 44744
    },
    {
        "title": "Add Buffer.prototype.lastIndexOf()",
        "body": "[The docs](https://nodejs.org/api/buffer.html#buffer_buf_indexof_value_byteoffset) only mention `indexOf`, but it's there, I would like to use it and don't feel good using undocumented API\n\n```\n$ node\n> Buffer.prototype.lastIndexOf\n[Function: lastIndexOf]\n```\n",
        "labels": "doc",
        "id": 44745
    },
    {
        "title": "doc: http `response` event options (agent.getName()?)",
        "body": "Under the `http.ClientRequest` [`response` event](https://nodejs.org/api/http.html#http_event_response) there's an `Options` section that doesn't make sense. It was originally introduced with an `http.getAgent()` method (a2328dc73c425c4d6f58cb8d97ece92adafcb96b) that appears to be gone. It appears to me that these options now belong to [`http.Agent.getName()`](https://nodejs.org/api/http.html#http_agent_getname_options), though with a rename: `socketPath => localAddress`. I'm not sure what the documentation on that param means by:\n\n> (use one of host:port or socketPath)\n",
        "labels": "doc",
        "id": 44746
    },
    {
        "title": "http.IncomingMessage isn't labeled as a class",
        "body": "https://nodejs.org/api/http.html\n\n`http.ServerResponse`, `http.Server` and `http.ClientRequest` are labelled as classes. I reckon `IncomingMessage` ought to be as well. :cow2: \n",
        "labels": "doc",
        "id": 44747
    },
    {
        "title": "Docs WG Call for Members",
        "body": "Hey all! :wave: \n\nAs a heads up, there's talk going on [in the node issue tracker](https://github.com/nodejs/node/pull/4244) about ratifying the Docs WG. As part of this, we've landed on a working proposal for where the [docs will live](https://github.com/nodejs/docs/issues/50). Per this proposal, the Docs WG will be working within the `nodejs/node` repo. This means that we can work to apply internationalization to the API docs as well. :tada:\n\nIf you've been working on the docs and would like to become part of the Docs WG, please note your interest [on this issue](https://github.com/nodejs/docs/issues/2) and we'll get you on board. There will be a meeting in late January to discuss the state of the proposal. You may want to take a gander at the [contributing](https://github.com/nodejs/docs/blob/master/CONTRIBUTING.md) and [getting-started](https://github.com/nodejs/docs/blob/master/GETTING-STARTED.md) docs, as well! They're not set in stone but they reflect the current ethos of the WG.\n\nI'll close this issue in two weeks.\n\nThanks, all!\n",
        "labels": "doc",
        "id": 44748
    },
    {
        "title": "Document return value of http.server.listen",
        "body": "As noted in https://github.com/strongloop/expressjs.com/issues/539, docs don't specify the return value of [http.server.listen](http://nodejs.org/api/http.html#http_server_listen_port_hostname_backlog_callback) but it does appear return an [http.Server](https://nodejs.org/api/http.html#http_class_http_server) object.\n\nI'd add a PR, but I'm not sure if the return value is the same for all flavors (i.e. signatures) of the function.\n",
        "labels": "doc",
        "id": 44749
    },
    {
        "title": "Bad link in README.md for LTS version",
        "body": "In the mais docs (README.md) in section Download is is stated that the latest LTS should be in a link with \"latest-lts-codename\". But in the download page https://nodejs.org/download/release/ that link does not exist, it is named only \"latest-argon\".\nPlease fix either of them so that we can make scripts that will work for future versions.\n",
        "labels": "doc",
        "id": 44750
    },
    {
        "title": "doc: http.IncomingMessage.statusMessage description out of place",
        "body": "[`statusMessage`](https://nodejs.org/api/http.html#http_message_statusmessage) description lost its place and is under `socket`.\n\nSee f4c259ab942a371c7b71408ce2a38c1f90d7211d / https://github.com/nodejs/node/pull/3662.\n",
        "labels": "doc",
        "id": 44751
    },
    {
        "title": "Improve EventEmitter documentation",
        "body": "Currently:\n\n> emitter.listenerCount(type)\n> type Value The type of event\n> \n> emitter.listeners(event)\n> Returns a copy of the array of listeners for the specified event.\n\nIn both cases, `type` and `event` arguments refer to the \"event name\", so I suggest calling both \"type\".\n",
        "labels": "doc",
        "id": 44752
    },
    {
        "title": "Undocumented Profiling Options",
        "body": "it appears that there are at least two ways to generate a profile file:\n- `node -prof foo.js`\n- `node --prof foo.js`\n\nHowever, neither of these options are documented by `node --help` (although one of them is alluded to in `--prof-process` which consumes the generated profile file as input).\n\n```\n$ node -v\nv5.3.0\n$ node --help\nUsage: node [options] [ -e script | script.js ] [arguments] \n       node debug script.js [arguments] \n\nOptions:\n  -v, --version         print Node.js version\n  -e, --eval script     evaluate script\n  -p, --print           evaluate script and print result\n  -c, --check           syntax check script without executing\n  -i, --interactive     always enter the REPL even if stdin\n                        does not appear to be a terminal\n  -r, --require         module to preload (option can be repeated)\n  --no-deprecation      silence deprecation warnings\n  --throw-deprecation   throw an exception anytime a deprecated function is used\n  --trace-deprecation   show stack traces on deprecations\n  --trace-sync-io       show stack trace when use of sync IO\n                        is detected after the first tick\n  --track-heap-objects  track heap object allocations for heap snapshots\n  --prof-process        process v8 profiler output generated\n                        using --prof\n  --v8-options          print v8 command line options\n  --tls-cipher-list=val use an alternative default TLS cipher list\n  --icu-data-dir=dir    set ICU data load path to dir\n                        (overrides NODE_ICU_DATA)\n\nEnvironment variables:\nNODE_PATH               ':'-separated list of directories\n                        prefixed to the module search path.\nNODE_DISABLE_COLORS     set to 1 to disable colors in the REPL\nNODE_ICU_DATA           data path for ICU (Intl object) data\nNODE_REPL_HISTORY       path to the persistent REPL history file\n\nDocumentation can be found at https://nodejs.org/\n$ \n```\n",
        "labels": "doc",
        "id": 44753
    },
    {
        "title": "Docs: add exception handling examples in stream",
        "body": "It is tempting to do something like this:\n\n``` js\nvar error = new Error('some error');\n\nstream\n  .pipe(through(function(chunk) {\n    throw error ;\n  }))\n  .on('error', function(err) {\n    assert.equal(error, err);\n  });\n```\n\nFor me because in promise throwing an exception equals rejection.\n\nThe docs should tell what really happens when exceptions are thrown in these kind of functions (`_read`, `_write`, `_writev`, `_transform`, `_flush`).\n",
        "labels": "doc",
        "id": 44754
    },
    {
        "title": "Proposal: Add indentation to documentation styles",
        "body": "I believe legibility of the documentation could greatly be improved by adding indentation to it, so it will be clearly visible and easy to survey to see which classes are hosting which properties.\n<br/>\nHere's a sketch depicting the suggested grouping/indentation:\n(left panel: current version; right panel: suggestion)\n\n![node indenting](https://cloud.githubusercontent.com/assets/9283914/12056657/0a0fe9b4-af39-11e5-9ec4-e17ea0d0a06c.png)\n\n_As you can see in the left panel, all kinds of information entities are written next to each other without distinction. In the example it's hard to find the corresponding class for the event when you scroll down._\n\n_In the right panel it's easy to relate and distinguish classes and their content from each other. And you can quickly see when the end of an entity description has been reached._\n",
        "labels": "doc",
        "id": 44755
    },
    {
        "title": "Bad readline behavior with line ending characters?",
        "body": "When including a trailing newline character (or carriage return character) in a string that is supplied to a write function, an RangeError is thrown (`RangeError: Maximum call stack size exceeded`). The following code snippet shows the context:\n\n``` javascript\nelse if (trimmedLine.match(/^h(elp)?$/i)) {\n    readlineInstance.write(\"Help\\n\");\n}\n```\n\nHere is an error log I created by issuing a command that passes the console output to a text file (`npm start > console_output.txt`):\n\n```\npath\\GitHubBackup\\console\\console.js:12\n        var trimmedLine = line.trim();\n                               ^\n\nRangeError: Maximum call stack size exceeded\n    at String.trim (native)\n    at consoleOptions (path\\GitHubBackup\\console\\console.js:12:25)\n    at Interface.<anonymous> (path\\GitHubBackup\\console\\console.js:46:14)\n    at emitOne (events.js:82:20)\n    at Interface.emit (events.js:169:7)\n    at Interface._onLine (readline.js:210:10)\n    at Interface.<anonymous> (readline.js:340:12)\n    at Array.forEach (native)\n    at Interface._normalWrite (readline.js:339:11)\n    at Interface.write (readline.js:309:49)\n\nnpm ERR! Windows_NT 10.0.10586\nnpm ERR! argv \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\***\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"start\"\nnpm ERR! node v5.3.0\nnpm ERR! npm  v3.5.2\nnpm ERR! code ELIFECYCLE\nnpm ERR! github.backup@0.1.0 start: `node main.js`\nnpm ERR! Exit status 1\nnpm ERR!\nnpm ERR! Failed at the github.backup@0.1.0 start script 'node main.js'.\nnpm ERR! Make sure you have the latest version of node.js and npm installed.\nnpm ERR! If you do, this is most likely a problem with the github.backup package\n,\nnpm ERR! not with npm itself.\nnpm ERR! Tell the author that this fails on your system:\nnpm ERR!     node main.js\nnpm ERR! You can get information on how to open an issue for this project with:\nnpm ERR!     npm bugs github.backup\nnpm ERR! Or if that isn't available, you can get their info via:\nnpm ERR!     npm owner ls github.backup\nnpm ERR! There is likely additional logging output above.\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     path\\GitHubBackup\\npm-debug.log\n```\n\nThe ordinary error log doesn't show the details above, only an exit status entry:\n\n```\n(...Break...)\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\n\nnpm ERR! Windows_NT 10.0.10586\nnpm ERR! argv \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\***\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"start\"\nnpm ERR! node v5.3.0\nnpm ERR! npm  v3.5.2\nnpm ERR! code ELIFECYCLE\nnpm ERR! github.backup@0.1.0 start: `node main.js`\nnpm ERR! Exit status 3221225725\nnpm ERR!\nnpm ERR! Failed at the github.backup@0.1.0 start script 'node main.js'.\nnpm ERR! Make sure you have the latest version of node.js and npm installed.\nnpm ERR! If you do, this is most likely a problem with the github.backup package\n,\nnpm ERR! not with npm itself.\nnpm ERR! Tell the author that this fails on your system:\nnpm ERR!     node main.js\nnpm ERR! You can get information on how to open an issue for this project with:\nnpm ERR!     npm bugs github.backup\nnpm ERR! Or if that isn't available, you can get their info via:\nnpm ERR!     npm owner ls github.backup\nnpm ERR! There is likely additional logging output above.\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     path\\GitHubBackup\\npm-debug.log\n```\n\nThe full code:\n\n``` javascript\n\"use strict\"\n\n// CONSTANTS\nvar CONSOLE_PROMPT_NAME = \"GitHubBackup\";\n\n// DEPENDENCIES\nvar readline = require(\"readline\");\nconst chalk = require(\"chalk\");\n\n// -CONSOLE OPTIONS\nfunction consoleOptions(line, readlineInstance) {\n    var trimmedLine = line.trim();\n\n    if (trimmedLine.match(/^q(uit)?$/i)) {\n        readlineInstance.write(\"Closing...\");\n        readlineInstance.close();\n    }\n    else if (trimmedLine.match(/^h(elp)?$/i)) {\n        readlineInstance.write(\"Help\\n\");\n    }\n\n    readlineInstance.prompt();\n}\n\nmodule.exports = function() {\n    return {\n        // -CONSOLE FUNCTIONS\n        createConsole: function() {\n            var readlineInstance;\n\n            // Setting up a prompt using the \"readline\" module\n            readlineInstance = readline.createInterface({\n                input: process.stdin,\n                output: process.stdout\n            });\n            readlineInstance.setPrompt(chalk.green(CONSOLE_PROMPT_NAME + \">\"));\n            readlineInstance.prompt();\n\n            // Monitoring user actions\n            readlineInstance.on(\"SIGINT\", function() {\n                readlineInstance.close();\n            });\n            readlineInstance.on(\"line\", function(line) {\n                consoleOptions(line, this);\n            });\n\n            return readlineInstance;\n        }\n    };\n}\n```\n\nIs this a valid behaviour of the readline module? Note again that this only happens with trailing line endings.\n",
        "labels": "doc",
        "id": 44756
    },
    {
        "title": "rfc: standardize stream.destroy() and pipe",
        "body": "A lot of modules, both internal (fs, net, http) and external (through2 and others) implement `stream.destroy()` and in fact I alway recommend using @mafintosh's [pump](http://npm.im/pump) to pipe streams. That module automatically calls `destroy()` if present, so no file descriptors are leaked in case of an error.\n\nGiven that it is a de-facto standard, we can document it in the stream API, and add a default implementation of it.\n\nMaybe we can even go further and add a pump-equivalent in core, maybe as an option to pipe.\n\ncc @nodejs/streams  \n",
        "labels": "doc",
        "id": 44757
    },
    {
        "title": "docs: clarify man(N) references",
        "body": "Reading the documentation I noticed a fair number of strange looking references:\n\n![node](https://cloud.githubusercontent.com/assets/9283914/11930193/a2c1c614-a7e1-11e5-87e0-f6ea3ea16f2c.png)\n<br/>\nIt looks as if these are supposed to be hyperlinks. But instead they are being displayed as only some name with a confusing number.\n",
        "labels": "doc",
        "id": 44758
    },
    {
        "title": "More detailed `fs` documentation ",
        "body": "The `fs` docs provide a great overview of the API, but information on their low-level operations is pretty sparse. \n\nFor example, I can't tell how two competing `fs.writeFileSync` calls from different processes will interact. Will an error be thrown by whichever process loses the race for the lock? Will the second process just wait for the lock and then overwrite the previous contents?\n\nFor reference, here are two issues would have benefited from these sorts of details:\n- https://github.com/bcoe/nyc/pull/101#issuecomment-165972363\n- https://github.com/yeoman/configstore/issues/20#issuecomment-123687587\n",
        "labels": "doc",
        "id": 44759
    },
    {
        "title": "Proposal: Documentation - Change style of parameter type",
        "body": "This is just a minor one. Yet, it's confusing when reading:\n\nIn the docs the parameter description style doesn't distinguish between the parameter's type and the actual description. There is not even a punctuation character separating these two (see image below).\n\nI suggest to use a distinct style for a parameter's type.\n\n![node](https://cloud.githubusercontent.com/assets/9283914/11907762/fd97e9d6-a5d6-11e5-8dd7-693a0f7aeba5.png)\n",
        "labels": "doc",
        "id": 44760
    },
    {
        "title": "Buffer created using new Buffer(buffer) has a different ArrayBuffer from the original one",
        "body": "Hope the title describes the issue correctly:)\n### Codes:\n\n``` js\nvar typed_array = new Uint8Array(6);\nfor(var i = 0; i < typed_array.length; i++){\n  typed_array[i] = i;\n}\n\nvar array_buffer = typed_array.buffer;\nconsole.log(\"byteLength of ArrayBuffer : \" + array_buffer.byteLength);\n\nvar node_buffer = new Buffer(array_buffer);\nconsole.log(\"Node Buffer : \");\nconsole.log(node_buffer);\n\nconsole.log(\"byteLength of ArrayBuffer in Node Buffer : \", node_buffer.buffer.byteLength);\n\nvar another_node_buffer = new Buffer(node_buffer);\nconsole.log(\"Another Node Buffer : \");\nconsole.log(another_node_buffer);\n\nconsole.log(\"byteLength of ArrayBuffer in Another Node Buffer : \", another_node_buffer.buffer.byteLength);\n```\n## node_buffer.buffer is different from another_node_buffer.buffer !\n\n![image](https://cloud.githubusercontent.com/assets/5510968/11890272/6ea41aea-a58d-11e5-8e0b-cca45d8b17bf.png)\n",
        "labels": "doc",
        "id": 44761
    },
    {
        "title": "Please document fs.WriteStream.path",
        "body": "WriteStreams have a .path property with the path of the file they write to. Please document this property so that I can reliably use it without fear of it being an unsupported feature. This will also enable me to put it into node.d.ts and push that to DefinitelyTyped.\n",
        "labels": "doc",
        "id": 44762
    },
    {
        "title": "crypto: error in ECDH example",
        "body": "@nodejs/crypto ... In crypto.markdown, the example for `ECDH.setPublicKey(public_key[, encoding])` gives an error. Documenting this as a todo to fix (note, the examples use the updated syntax being worked on in https://github.com/nodejs/node/pull/4282)\n\n```\n    const crypto = require('crypto');\n    const alice = crypto.createECDH('secp256k1');\n    const bob = crypto.createECDH('secp256k1');\n\n    // Note: This is a shortcut way to specify one of Alice's previous private\n    // keys. It would be unwise to use such a predictable private key in a real\n    // application.\n    alice.setPrivateKey(\n      crypto.createHash('sha256').update('alice', 'utf8').digest()\n    );\n\n    // Bob uses a newly generated cryptographically strong pseudorandom key pair\n    bob.generateKeys();\n\n    const alice_secret = alice.computeSecret(bob.getPublicKey(), null, 'hex');\n    const bob_secret = bob.computeSecret(alice.getPublicKey(), null, 'hex');\n\n    // alice_secret and bob_secret should be the same shared secret value\n    console.log(alice_secret === bob_secret);\n```\n\n```\ncrypto.js:526\n  var key = this._handle.getPublicKey(f);\n                         ^\n\nError: You should generate ECDH keys first\n    at Error (native)\n    at ECDH.getPublicKey (crypto.js:526:26)\n    at Object.<anonymous> (/Users/james/tmp/test.js:17:48)\n    at Module._compile (module.js:435:26)\n    at Object.Module._extensions..js (module.js:442:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:311:12)\n    at Function.Module.runMain (module.js:467:10)\n    at startup (node.js:134:18)\n    at node.js:961:3\n```\n\nAdding `alice.generateKeys()` allows the example to work.\n\n```\n    const crypto = require('crypto');\n    const alice = crypto.createECDH('secp256k1');\n    const bob = crypto.createECDH('secp256k1');\n\n    // Note: This is a shortcut way to specify one of Alice's previous private\n    // keys. It would be unwise to use such a predictable private key in a real\n    // application.\n    alice.setPrivateKey(\n      crypto.createHash('sha256').update('alice', 'utf8').digest()\n    );\n\n    // Bob and Alice use a newly generated cryptographically strong pseudorandom key pair\n    bob.generateKeys();\n    alice.generateKeys();\n\n    const alice_secret = alice.computeSecret(bob.getPublicKey(), null, 'hex');\n    const bob_secret = bob.computeSecret(alice.getPublicKey(), null, 'hex');\n\n    // alice_secret and bob_secret should be the same shared secret value\n    console.log(alice_secret === bob_secret);\n```\n",
        "labels": "doc",
        "id": 44763
    },
    {
        "title": "child_process.spawn() has undocumented 200kb buffer limit",
        "body": "The child_process.spawn() function will pause a script's execution if it writes more than 200kb of stdout that isn't captured. I discovered this when my spawned process would suspiciously pause after exactly a certain amount of output.\n\nAdding a listener for stdout that does nothing fixed it and allowed the script to run:\n\n```\nmyProcess.stdout.on('data', function (data) {});\n```\n\nThis is not documented [in the docs](https://nodejs.org/api/child_process.html#child_process_child_process_spawn_command_args_options). Is this intentional (and hence should be documented) or a bug?\n",
        "labels": "doc",
        "id": 44764
    },
    {
        "title": "HTTP Server request.setTimeout(n, cb) does sometimes call socket.destroy(), contradicting documentation",
        "body": "Hi,\nI found a (not so) corner-case issue with HTTP Server `request.setTimeout(n, cb)`:\nAccording to [the documentation](https://nodejs.org/docs/latest-argon/api/http.html#http_response_settimeout_msecs_callback) if a listener was registered to the `timeout` event on any of server, request, response, then the `http` module doesn't call `socket.destroy()`, and it's up to the listener to do it if needed.\n\nHowever, there is an issue in the implementation which breaks this promise:\n- if the listener is specifically and uniquely set on the request `timeout` event\n- and if the timeout expires when HTTP request part is finished (ie if the client has sent all the data it needed to send, and only waits for a response from the server)\n\n... then the code wrongly assumes there is no listener, and calls destroy().\n\nGist to reproduce the scenario: https://gist.github.com/triccardi-systran/312b4471c955572ed3b7\nInline it here for archiving:\n\n``` js\nvar http = require('http');\n\nvar mode;\nmode = 'requestTimeout';\n// mode = 'responseTimeout';\n// mode = 'serverTimeout';\n// mode = 'serverTimeoutExternal';\n\nvar timeout = 100;\n\nvar port = 3000;\n\n\nconsole.log('Test HTTP Server with timeout on Server, Request, Response & socket destroy: unexpected destroy on req.setTimeout(n, cb);');\n\nvar server = http.createServer(function(req, res) {\n  console.log('server', 'got request');\n\n  if (mode === 'requestTimeout') {\n    req.setTimeout(timeout, function() {\n      console.log('server', 'request timeout');\n      res.end('server hello from request timeout');\n    });\n  }\n\n  if (mode === 'responseTimeout') {\n    res.setTimeout(timeout, function() {\n      console.log('server', 'request timeout');\n      res.end('server hello from request timeout');\n    });\n  }\n\n  if (mode === 'serverTimeout' || mode === 'serverTimeoutExternal') {\n    server.setTimeout(timeout, function() {\n      console.log('server', 'request timeout');\n      res.end('server hello from request timeout');\n    });\n  }\n\n}).listen(port, function() {\n\n  console.log('client', 'sending request');\n  var req = http.request({port: port}, function(res) {\n    console.log('client', 'got response');\n    res.on('data', function (chunk) {\n      console.log('client', 'reponse', 'data:', chunk.toString());\n    });\n    res.on('finish', function () {\n      console.log('client', 'response', 'finish');\n    });\n  });\n\n  req.on('error', function(e) {\n    console.log('client', 'error', e);\n  });\n\n  req.end();\n});\n\nif (mode === 'serverTimeoutExternal') {\n  server.setTimeout(timeout);\n}\n\n// cleanup\nsetTimeout(function() {\n  console.log('exit');\n  process.exit();\n}, timeout + 100);\n\n\n/** Results:\n * same results for the following node versions: v0.10.41, v0.12.9, v4.2.3, v5.2.0\n ** mode RequestTimeout\nclient sending request\nserver got request\nclient error { [Error: socket hang up] code: 'ECONNRESET' }  <-- unexpected\n ** mode ResponseTimeout\nclient sending request\nserver got request\nserver request timeout\nclient got response\nclient reponse data: server hello from request timeout\n ** mode ServerTimeout\nclient sending request\nserver got request\n ** mode ServerTimeoutExternal\nclient sending request\nserver got request\nserver request timeout\nclient got response\nclient reponse data: server hello from request timeout\n **/\n```\n\nRelevant code:\nhttps://github.com/nodejs/node/blob/v4.2.3/lib/_http_server.js#L300 (introduced by d258fb0212530329b9941be18bc6e90d7afec5b5)\nSpecifically the `!req.complete` part of `var reqTimeout = req && !req.complete && req.emit('timeout', socket);`.\n\nIt blocks the emission of the `timeout` event on the request object, if the request ended its part.\nThis comes from nodejs/node-v0.x-archive#4967; fixed by c9a4ec9c6392fefa7ce6c66168f4c535ea0702e1.\n\nThis is part of Node.js since v0.10.0, and, is still present in latest version (v5.2.0).\n\nThis is probably just a documentation issue though: the current behavior seems correct: if the `timeout` event is not emitted, then someone has to call `socket.destroy()`.\nOtherwise, plan B: we reject the fix that introduced this behavior: the `timeout` event should always be emitted. This would make more sense as all the doc hints at the fact that the `setTimeout` functions are just helper function that forward the value to the underlying Socket object.\nIf we keep the current behavior, there are multiple locations in the documentation to update to reflect these subtleties...\n\nThis is a more general issue: the `timeout` event is not documented like other events of these classes. It's only described through indirect documentation on the various setTimeout.\n",
        "labels": "doc",
        "id": 44765
    },
    {
        "title": "Why is IncomingMessage.destroy method not documented?",
        "body": "https://github.com/nodejs/node/blob/v5.2.0/lib/_http_incoming.js#L89-L95\n",
        "labels": "doc",
        "id": 44766
    },
    {
        "title": "util.inherits does not establish prototype chain",
        "body": "In inherits.js Object.setPrototypeOf is being called with the wrong parameters.\n\nThe reason for me assuming that the wrong parameters are being used is\n\n(REPL)\n\n```\n> function MyError() {}\n> util.inherits(MyError, Error);\n> MyError\n{ [Function: MyError]\n  super_: \n   { [Function: Error]\n     captureStackTrace: [Function: captureStackTrace],\n     stackTraceLimit: 10 } }\n> Error.isPrototypeOf(MyError);\nfalse\n```\n\nWhile inheritance sort of works, the prototype chain is actually never established.\n\n```\n> myerr = new MyError()\n[Error]\n> myerr instanceof MyError\ntrue\n> myerr instanceof Error\ntrue\n```\n\nReplacing the existing call to Object.setPrototypeOf() by\n\n```\nObject.setPrototypeOf(ctor, superCtor);\n```\n\nSee https://github.com/nodejs/node/blob/master/lib/util.js#L805.\n\n(REPL)\n\n```\n> function MyError() {}\n> util.inherits(MyError, Error);\n> MyError\n[Function: OError]\n> Error.isPrototypeOf(MyError);\ntrue\n```\n\nYet, instanceof will now fail\n\n```\n> myerr = new MyError()\n[Error]\n> myerr instanceof MyError\ntrue\n> myerr instanceof Error\nfalse\n```\n\nWhen using the new class feature, everything works as expected, though\n\n(REPL)\n\n```\n> class MyError extends Error {}\n[Function: MyError]\n> Error.isPrototypeOf(MyError)\ntrue\n> myerr = new MyError()\n[Error]\n> myerr instanceof MyError\ntrue\n> myerr instanceof Error\ntrue\n```\n",
        "labels": "doc",
        "id": 44767
    },
    {
        "title": "(new TLSSocket(new net.Socket())).connect() fails silently.",
        "body": "(**EDIT** by @Trott: Turns out this is a documentation bug. Labeling `good-first-contribution` and `doc`.) \n\n``` js\n\"use strict\";\n\nconst NetSocket = require(\"net\").Socket;\nconst TlsSocket = require(\"tls\").TLSSocket;\n\nconst tlsSocket = new TlsSocket(new NetSocket());\n\ntlsSocket.once(\"connect\", function doStartup () {\n    console.log(\"The tls socket connected. Yay!\");\n});\n\ntlsSocket.connect({port: 6697, host: \"irc.freenode.net\"});\nconsole.log(\"Sent connect.\");\n```\n\nThe program ends immediately after the connect is called, telling me that the connection isn't started.\n\nNote that if we don't wrap the `net.Socket` in a `TLSSocket`, then the connect works as expected.\n",
        "labels": "doc",
        "id": 44768
    },
    {
        "title": "doc: Inspect method of buffers is missing description",
        "body": "`buffer.inspect()` is referenced at [Buffer#INSPECT_MAX_BYTES](https://github.com/nodejs/node/blob/master/doc/api/buffer.markdown#bufferinspect_max_bytes) but no description is found on the same document. Is this intended? It's an internal method only?\n",
        "labels": "doc",
        "id": 44769
    },
    {
        "title": "replace installation instructions for windows",
        "body": "Microsoft recently released `Visual C++ Build Tools 2015 (Pre-release).`\n\n@mousetraps over in https://github.com/nodejs/node-gyp/issues/629#issuecomment-153196245 documented a new preferred workflow for installing node on windows that works (including native modules).\n\nWould a few people on windows be able to test the new instructions and see if they are more successful?\n\nIf we do update the instructions we should also update https://nodejs.org/en/download/package-manager/#windows (as mentioned by @bengl) to reference where in depth instructions can be found.\n",
        "labels": "doc",
        "id": 44770
    },
    {
        "title": "Module loading implementation does not match API docs",
        "body": "The [API Documentation for modules](https://nodejs.org/api/modules.html#modules_loading_from_node_modules_folders) states:\n\n> If the module identifier passed to require() is not a native module, and does not begin with '/', '../', or './', then Node.js starts at the parent directory of the current module, and adds /node_modules, and attempts to load the module from that location.\n> \n> If it is not found there, then it moves to the parent directory, and so on, until the root of the file system is reached.\n\nIn the given example, a call to `require('bar.js')` inside a file at `'/home/ry/projects/foo.js'` would search the following locations:\n\n```\n/home/ry/projects/node_modules/bar.js\n/home/ry/node_modules/bar.js\n/home/node_modules/bar.js\n/node_modules/bar.js\n```\n\nThe documented lookup procedure makes no qualifications about the names of parent directories, so the example's `ry` and `projects` directory names are presumably arbitrary. But if we change `ry` to `'node_modules'` then the lookup is materially different:\n\n```\n/home/node_modules/projects/node_modules/bar.js\n/home/node_modules/bar.js\n/node_modules/bar.js\n```\n\nNote that the location `'/home/node_modules/node_modules/bar.js'` is not considered.\n\nThe API documentation seems to diverge slightly from the implementation here. Perhaps one should be amended to match the other?\n### Example\n\n_This is just for the curious; the point of this issue is that the module loading documentation and implementation diverge in this case._\n\nThis came up in a discussion about an undesirable consequence of `npm3`'s flattening behaviour, namely that it makes it easy to ship buggy code that forgets to declare some dependencies in its `package.json`, but still works _most_ of the time because one or more other dependencies require the missing dependency so it is installed at the top level anyway (due to flat `npm install`).\n\nFor example, suppose a module at `/home/foo` declares a dependency on `fs-extra`. Later on, it starts using `rimraf` as well but forgets to add it as a dependency. However it just works (_usually_) because `fs-extra` depends on `rimraf` and so `npm3` (_usually_) installs it at `'/home/foo/node_modules/rimraf'`. Note the _usually_ because the behaviour is also a function of other factors.\n\nA suggestion to catch this bug early was to put indirect dependencies one level deeper. So the example would look like:\n\n```\n/home/foo/package.json\n/home/foo/index.js\n/home/foo/node_modules/fs-extra\n/home/foo/node_modules/node_modules/rimraf\n```\n\nAccording to the modules API documentation, the expected behaviour is that `fs-extra` can successfully `require('rimraf')`, but if `foo` tries to `require('rimraf')` it fails.\n\nThe actual behaviour is that `require('rimraf')` fails both for `fs-extra` and for `foo`.\n",
        "labels": "doc",
        "id": 44771
    },
    {
        "title": "Undocumented `readline` methods",
        "body": "There are several exposed methods on `readline` that are not documented:\n- [`readline.getStringWidth()`](https://github.com/nodejs/node/blob/84f09647d0ea41ea1efee0431d7ac40b235ab382/lib/readline.js#L1365)\n- [`readline.isFullWidthCodePoint()`](https://github.com/nodejs/node/blob/84f09647d0ea41ea1efee0431d7ac40b235ab382/lib/readline.js#L1413)\n- [`readline.stripVTControlCharacters()`](https://github.com/nodejs/node/blob/84f09647d0ea41ea1efee0431d7ac40b235ab382/lib/readline.js#L1446)\n- [`readline.emitKeypressEvents()`](https://github.com/nodejs/node/blob/84f09647d0ea41ea1efee0431d7ac40b235ab382/lib/readline.js#L948)\n\nThey should IMHO either be documented or made internal. Preferably the latter.\n\nMost of these are already modules on npm anyways:\n- `getStringWidth` â†’ [`string-width`](https://github.com/sindresorhus/string-width)\n- `isFullWidthCodePoint` â†’ [`is-fullwidth-code-point`](https://github.com/sindresorhus/is-fullwidth-code-point)\n- `stripVTControlCharacters` â†’ [`strip-ansi`](https://github.com/chalk/strip-ansi)\n",
        "labels": "doc",
        "id": 44772
    },
    {
        "title": "Add links to previous versions of individual docs",
        "body": "I think it would be extremely useful if each page of the current docs had links to the previous versions of the documentation. I am upgrading from .10 to 4 and have found myself wanting to compare docs between the 2 versions. For example, if I'm looking at the documentation for the cluster module, I would find it helpful to have a link somewhere to jump to a different version of the docs. I think is this is a really important feature since the docs now default to 5.0, while, as far as I know, the vast majority of node users, will be on a previous version. \n",
        "labels": "doc",
        "id": 44773
    },
    {
        "title": "Clarify documentation",
        "body": "https://nodejs.org/api/stream.html\n\n```\n// give it a kick whenever the source is readable\n```\n\nLike [this](https://www.youtube.com/watch?v=1eFUkv75Agg)?\n",
        "labels": "doc",
        "id": 44774
    },
    {
        "title": "zlib: inconsistent call to flush callback on oversized buffers",
        "body": "When using an oversized buffer, the flush callback is only sometimes called.\n\n``` js\n'use strict';\nconst zlib = require('zlib');\n\nconst buf = new Buffer(100000);\nconst def = zlib.createDeflate({\n  highWaterMark:5,\n  level: 2\n});\ndef.on('drain', ()=> console.log('drained'));\ndef.write(buf, ()=> {\n  console.log('after write');\n  def.flush(zlib.Z_FULL_FLUSH, function(err) {\n    console.log('flushed');\n  });\n  def.end();\n});\n```\n\n``` text\nbash-3.2$ ./node ~/test.js\ndrained\nafter write\nbash-3.2$ ./node ~/test.js\ndrained\nafter write\nflushed\nbash-3.2$ \n```\n\nRelevant IRC Chat\n\n``` irc\n15:46 jasnell: not yet... the inconsistency seems to have something to do with the size of the buffer\n15:46 jasnell: if I drop down to Buffer(10000), it works fine\n15:46 chrisdickinson: that's < zlib window size\n15:47 chrisdickinson: it might be in limbo waiting for a corresponding read\n15:47 thealphanerd: adding a read does give a consisent flush\n15:48 jasnell: ok, makes for a rather tricky inconsistency\n15:48 jasnell: sometimes it works, sometimes it doesn't, with no indication as to why\n15:50 thealphanerd: jasnell: I think you can check to see if write returns false?\n15:51 chrisdickinson: ah\n15:51 chrisdickinson: might see how many times the handle is written to per-buffer\n15:51 chrisdickinson: https://github.com/nodejs/node/blob/v4.2.1/lib/zlib.js#L588-L593\n```\n\nWill be getting back to this to investigate. @chrisdickinson @TheAlphaNerd \n\nRelated to: https://github.com/nodejs/node/pull/3534\n",
        "labels": "doc",
        "id": 44775
    },
    {
        "title": "Documentation for different Node versions?",
        "body": "At the moment I have 5.0.0, 4.1.1 and 0.12.7 installed.\n\nIs there a solid place to know when each of these came out and what each version entails?\nConfused how we jumped from 0.12.x -> 4 somehow.\n\n(This is more of a question of course, but I'm not sure how I can label that in here) \n",
        "labels": "doc",
        "id": 44776
    },
    {
        "title": "Show \"supported since version x\" for functions in API documentation",
        "body": "I think it would be useful to show from which version a given function in the API is supported, e.g. `Buffer.prototype.indexOf()` was added in v4.x, so if I'm creating a node module that should be backwards compatible with node v0.12, I shouldn't use that function.\n\nI'll happily make pull request with this change - and please comment if you have deeper knowlege of the documentation system in case there are ways to (semi-)automate this in some way.\n",
        "labels": "doc",
        "id": 44777
    },
    {
        "title": "documentation for REPL completion is somewhat obscure",
        "body": "`On tab completion - eval will be called with .scope as an input string. It is expected to return an array of scope names to be used for the auto-completion.`\n\nthat doesn't mean much...\n",
        "labels": "doc",
        "id": 44778
    },
    {
        "title": "documentation on Stream.write misses that callback does not ensure that data written to process.stdout/.stderr is flushed",
        "body": "``` javascript\n var empty = new Buffer(0)\n  process.stdout.write(empty, function() { \n    process.stderr.write(empty, function() { \n       process.exit(code);\n    });\n  });\n```\n\ndoesn't reliable ensure that a consumer of node.js will get all data (yes - it is a PIPE, not a FILE !!).\n",
        "labels": "doc",
        "id": 44779
    },
    {
        "title": "fs.open differences on windows vs *nix",
        "body": "If you create a directory, and then try to use `fs.open` to open it, you get differing behavior on windows and *nix if the flags are `a+`.\n\nExample:\n\n``` js\n// OS X\nfs.open('<directory>', 'a+', console.log)\n// => [Error: EISDIR: illegal operation on a directory, open <directory>]\n\n// Windows\nfs.open('<directory>', 'a+', console.log)\n// => null <fd>\n```\n\nAfter looking through the libuv code, it looks like https://github.com/libuv/libuv/blob/v1.x/src/win/fs.c#L479-L480 is responsible for this. Is this intended or should this operation show the same behavior on all platforms?\n",
        "labels": "doc",
        "id": 44780
    },
    {
        "title": "nodejs process cannot exit if opened a named pipe with no one reading",
        "body": "```\n~/work/test/js $ cat write-fifo.js \n#!/usr/bin/env node\n\nrequire(\"fs\").createWriteStream(process.argv[2]);\n~/work/test/js $ mkfifo foo\n~/work/test/js $ ./write-fifo.js foo\n^C <---- it just stucks here\n130 ~/work/test/js $ ./write-fifo.js whatever-file-name\n~/work/test/js $ \n```\n\nThere is a thread blocked in `pipe_wait`, as shown in its `wchan`.\n\nCan we always open the file in non-blocking mode?  After all it has no effect for real disk files, but avoids infinite waiting when that happens to be a named pipe.\n",
        "labels": "doc",
        "id": 44781
    },
    {
        "title": "doc: 'assert' description contains backwards actual/expected",
        "body": "Documentation for `assert` describes:\n\n```\nassert(value[, message]), assert.ok(value[, message])\nTests if value is truthy. It is equivalent to assert.equal(true, !!value, message).\n```\n\nBut `assert.equal` parameters are actual value first, then expected value. The documentation should read:\n\n```\nassert(value[, message]), assert.ok(value[, message])#\nTests if value is truthy. It is equivalent to assert.equal(!!value, true, message).\n```\n",
        "labels": "doc",
        "id": 44782
    },
    {
        "title": "crypto pbkdf2 keylen: bits or bytes?",
        "body": "The api docs use 512 for the keylen:\n\n``` javascript\ncrypto.pbkdf2('secret', 'salt', 4096, 512, 'sha256', function(err, key) {\n  if (err)\n    throw err;\n  console.log(key.toString('hex'));  // 'c5e478d...1469e50'\n});\n```\n\nBut they don't mention whether the keylen is in bits or bytes.\nGiven the fact that it has a value of 512 I would expect it to be in bits, but the end result seems to generate a key of 512 bytes\n\nSome clarification would be welcome\n",
        "labels": "doc",
        "id": 44783
    },
    {
        "title": "Document process for LTS",
        "body": "So I'm currently keeping an eye out for stuff that will be back ported for LTS. One of the things I think would be great would be clarification of what is acceptable to backport and what isn't.\n\nI've read through the document available at https://github.com/nodejs/lts but afaik it is primarily talking about process.\n\nSo here are a list of things that I think make sense to backport, assuming they are non breaking.\n- Documentation\n- Changes to Tests\n- Security Fixes\n- Non breaking bug fixes\n- Non breaking optimizations\n\nDoes this look right? Is there anything I missed?\n\nI also think it would be good to document the process of LTS in the Collaborator Guide, perhaps under landing a commit. It would be really awesome if people were encouraged to let us know in their PR if they think a change could be backported to LTS. I am more than happy to whip up copy assuming we all agree on the high level concepts.\n",
        "labels": "doc",
        "id": 44784
    },
    {
        "title": "child_process.execFile returns strings where doc says it should return a Buffer",
        "body": "[Doc says](https://nodejs.org/api/child_process.html#child_process_child_process_execfile_file_args_options_callback): \n\n> callback Function called with the output when process terminates\n> - error Error\n> - stdout Buffer\n> - stderr Buffer\n\n[This was known back in 2013 already](http://stackoverflow.com/questions/18925426/child-process-the-stdout-parameter)\n\nThis points out the options parameter's encoding field can force a buffer response. However the default value is supposed to be 'utf8' according to the doc, which strongly implies that it means _character encoding_, not the type of the return value. The name of this option is terribly misleading. \n\nDemo code:\n\n```\n\"use strict\";\nvar child_process = require('child_process');\nconsole.log('node version=%s',process.version);\n\nfor (let options of [{}, {encoding:'buffer'}]) {\n  child_process.execFile(\n    'uname', ['-o'], options,\n    (error, stdout, stderr) => {\n      console.log(\n        'options is %s â†’ stdout is a %s', \n        JSON.stringify(options), \n        typeof stdout\n      )\n    }\n  );\n}\n```\n\nOutput:\n\n```\nnode version=v4.2.1\noptions is {\"encoding\":\"buffer\"} â†’ stdout is a object\noptions is {} â†’ stdout is a string\n```\n\nThe behavior or the documentation need to be changed. If the current behavior is kept, the semantic of 'encoding' should be clarified, and the name of the property should be changed (to 'return_type' for example).\n",
        "labels": "doc",
        "id": 44785
    },
    {
        "title": "Undocumented options for child_process.exec and execSync?",
        "body": "I assume that `exec` and `execSync` have the same set of options, but in the documentation some are missing:\n\nThe `shell` option mentioned in [`child_process.exec`](https://nodejs.org/api/child_process.html#child_process_child_process_exec_command_options_callback) is absent from the [`execSync`](https://nodejs.org/api/child_process.html#child_process_child_process_execsync_command_options) documentation.\n\n~~Conversely, the `input` and `stdio` options mentioned in `child_process.execSync` are absent from the `exec` documentation.~~ _Edit:_ Hm, I'm not sure if these are actually supported by `exec`. Strange.\n",
        "labels": "doc",
        "id": 44786
    },
    {
        "title": "readline mangles lines containing 0x01 (SOH) characters",
        "body": "Given a file containing the following line:\n\n```\nA[SOH]B[SOH]C[SOH]D\n```\n\n (where [SOH] is ascii character 0x01), the code below prints `DCBA`\n\n```\n'use strict';\n\nvar readline = require('readline');\n\nvar rl = readline.createInterface({\n      input: process.stdin,\n      output: process.stdout\n});\n\nrl.on('line', function(line) {\n    console.log(line);\n});\n```\n",
        "labels": "doc",
        "id": 44787
    },
    {
        "title": "http, net: socket \"inactivity\" timeout",
        "body": "https://github.com/nodejs/node/commit/d258fb0212530329b9941be18bc6e90d7afec5b5 added this explanation to [`server.timeout`](https://nodejs.org/api/http.html#http_server_timeout):\n\n> The number of milliseconds of inactivity before a socket is presumed to have timed out.\n\nI noticed that long running (but active) requests like file uploads were cancelled after the timeout had passed and I'm almost certain that there is no actual code that checks for activity on a socket.\n\nShould we update the docs so they state that the socket timeout is actually unconditional? Alternatively, we could possibly reset the timeout on activity, but that will have a perf impact.\n",
        "labels": "doc",
        "id": 44788
    },
    {
        "title": "Documentation: update 'cluster'",
        "body": "> **Stability: 2 - Stable**\n\nvs.\n\n> This feature was introduced recently, and may change in future versions. Please try it out and provide feedback.\n\nhttps://nodejs.org/api/cluster.html\n",
        "labels": "doc",
        "id": 44789
    },
    {
        "title": "doc: WORKING_GROUPS.md will be affected by iojs-* to nodejs-* rename",
        "body": "As per #2525 a bunch of WGs are renaming from `iojs-*` to `nodejs-*`. The names are, technically, not yet final. Once renames conclude, update the doc.\n",
        "labels": "doc",
        "id": 44790
    },
    {
        "title": "doc: WORKING_GROUPS.md missing Intl",
        "body": "https://github.com/nodejs/node/blob/master/WORKING_GROUPS.md is missing the [Intl](https://github.com/nodejs/Intl) WG\n",
        "labels": "doc",
        "id": 44791
    },
    {
        "title": "Fix capitalization of b.writeUint16LE(0x90ab, 0) in buffer docs",
        "body": "In https://github.com/nodejs/node/blob/master/doc/api/buffer.markdown, `b.writeUint16LE(0x90ab, 0);` should be `b.writeUInt16LE(0x90ab, 0);`. \n",
        "labels": "doc",
        "id": 44792
    },
    {
        "title": "Possible Buffer.concat documentation vagueness",
        "body": "At the [current documentation for `Buffer.concat`](https://github.com/nodejs/node/blob/aa97ae7cf80b121aa5c4a65a228a16d71cf68931/doc/api/buffer.markdown#class-method-bufferconcatlist-totallength) the second parameter explanation seems a little vague.\n\nOn our project we're trying to avoid a possible use case issue and it would be helpful to definitively explain if `totalLength` is Byte length or encoded length e.g. String length, or other... otherwise we may have an issue down the road pop-up.\n\nIt would be super helpful to clarify this in the documentation. :)\n\nTIA\n",
        "labels": "doc",
        "id": 44793
    },
    {
        "title": "streams - request for docs: can _transform or _write(v) be called in parallel?",
        "body": "The reason I ask is because I have a transform-stream that receives objects and turns those into a bunch of buffers for each single transform. Some of these buffers I have to push out always have the same length. If possible (safe) I would like to create those buffers in my transform stream constructor and simply stick new data in during each transform.\n\nSo my question: as long as I don't call the callback in _transform, is it safe to assume _transform will not be called again? If my transform is piped down to disk for example, is there a chance that me changing the buffer in the next _transform call could have an effect on the outcome of the first write to disk?\n\nIn either case, documentation on this would be most welcome. I think stream implementers (myself in this case) often really need to squeeze out all performance, and understanding how this behaves would help. Also, as long as it's not documented one way or the other, I would be scared to depend on the behavior (even if it behaves the way I hope it does), because it may change tomorrow.\n",
        "labels": "doc",
        "id": 44794
    },
    {
        "title": "What is the idiomatic/(standard?correct?) way to inherit from EventEmitter in ES6?",
        "body": "I am a bit confused because the documentation keeps referring to the EventEmitter as a 'class', and ES6 has a class keyword, but I see a massive amount of hatred for 'classes' in the Node community.\n\nI initially thought, 'great, now I will start using classes' and wrote `class MyThing extends EventEmitter` which seems simpler, but there so much intense disgust for classes being displayed, I really am not sure what the 'correct' thing to do is.  Am I supposed to coninue writing it the old way with `util.inherits`, use `class`, or is there another new way to do it in ES6?\n\nAlso if we aren't using classes in Node maybe the documentation can be updated to indicate what we _are_ doing?\n",
        "labels": "doc",
        "id": 44795
    },
    {
        "title": "Standardize `userland` vs. `user-land`",
        "body": "`userland` appears in several places in Node.js, but `user-land` also appears in a few places. Should standardize on one or the other.\n",
        "labels": "doc",
        "id": 44796
    },
    {
        "title": "CONTRIBUTING.md should direct \"help me\" type questions to the help repo",
        "body": "`CONTRIBUTING.md` should explain briefly what types of issues are appropriate for this issue tracker and provide a link to https://github.com/nodejs/help/issues for issues that are more appropriate for that issue tracker.\n",
        "labels": "doc",
        "id": 44797
    },
    {
        "title": "Windows: ftruncate to shrink file gives EPERM",
        "body": "I have a file with the following stats in a Windows VM:\n\n{\"dev\":-24039965,\"mode\":33206,\"nlink\":1,\"uid\":0,\"gid\":0,\"rdev\":0,\"ino\":562949953548321,\"size\":39035842,\"atime\":\"2015-10-03T09:59:32.677Z\",\"mtime\":\"2015-10-03T10:00:17.241Z\",\"ctime\":\"2015-10-03T10:00:17.241Z\",\"birthtime\":\"2015-10-03T09:59:32.677Z\"}\n\nTruncating this file using ftruncate from 39035842 to 38839234 byte (to make it smaller) gives EPERM.\n\nIs ftruncate simply not supported at all on Windows? I thought it was only ftruncate to enlarge a file that was not permitted on Windows?\n",
        "labels": "doc",
        "id": 44798
    },
    {
        "title": "api docs say incomingMessage.headers is read-only but it is not",
        "body": "While [http documentation](https://github.com/nodejs/node/blob/master/doc/api/http.markdown#messageheaders) says it is a Read-Only map, it isn't and nothing (not event tests) prevent from writing to an incoming message headers.\nThis is actually a feature which some might find useful (for writing express middlewares), so my\nsuggestion is to fix the documentation, not the code.\n",
        "labels": "doc",
        "id": 44799
    },
    {
        "title": "crypto.randomBytes documentation needs improvement",
        "body": "The `crypto.randomBytes` documentation is quite confusing on whether or not the function throws on a lack of entropy. The code shows that it does, but the note below says that it does not. I'm currently under the impression that it does not throw on low entropy, so this needs to be fixed. Here is how it looks now:\n\n> # crypto.randomBytes(size[, callback])\n> \n> Generates cryptographically strong pseudo-random data. Usage:\n> \n> ``` javascript\n> // async\n> crypto.randomBytes(256, function(ex, buf) {\n>   if (ex) throw ex;\n>   console.log('Have %d bytes of random data: %s', buf.length, buf);\n> });\n> // sync\n> try {\n>   var buf = crypto.randomBytes(256);\n>   console.log('Have %d bytes of random data: %s', buf.length, buf);\n> } catch (ex) {\n>   // handle error\n>   // most likely, entropy sources are drained\n> }\n> ```\n> \n> NOTE: This will block if there is insufficient entropy, although it should normally never take longer than a few milliseconds. The only time when this may conceivably block is right after boot, when the whole system is still low on entropy. \n\nRefs to: https://github.com/nodejs/node/pull/3073#discussion_r40497423 and following discussion, https://github.com/nodejs/node/commit/e5e598060eb43faf2142184d523a04f0ca2d95c3, https://github.com/nodejs/node/commit/f68a116c3c061151ab120f10fdc9230192d6b157, and [`RAND_bytes()` docs](https://github.com/openssl/openssl/blob/9b86974e0c705ea321ddbc9a9d8562c894809e5b/doc/crypto/RAND_bytes.pod). Also https://github.com/nodejs/node/issues/813.\n",
        "labels": "doc",
        "id": 44800
    },
    {
        "title": "doc: request to expand on process \"exit\" event",
        "body": "Reference: https://github.com/nodejs/node/pull/2918#discussion_r39706498\n\nThe process \"exit\" event has a lot of reasons why it will or won't be emitted. Unfortunately, these reasons are not exactly clear from the documentation. That makes it a rather useless event, unless each user goes through a painful, time-consuming trial-and-error phase to figure out how things work (in the worst case, people will find out in production). It also doesn't set a guideline for developers as to how things are supposed to work (sure, we should have unit tests to confirm things work the way they do, but still).\n\ncc @Trott \n",
        "labels": "doc",
        "id": 44801
    },
    {
        "title": "How to inherit from new Buffer implementation",
        "body": "Hi,\nI would like to know how a class could inherit from the new Buffer implementation.\n\nI'm trying to upgrade the [node-ogg module](https://github.com/TooTallNate/node-ogg) for node v4 and nan v2.\n([Here is my work so far](https://github.com/corentingurtner/node-ogg/tree/upgrade-nan))\n\nI tried this classic inheritance model: \n\n``` javascript\nfunction ogg_packet (buffer) {\n  if (!Buffer.isBuffer(buffer)) {\n    Buffer.call(this, binding.sizeof_ogg_packet);\n  } else {\n    Buffer.call(this, buffer);\n  }\n  if (this.length != binding.sizeof_ogg_packet) {\n    throw new Error('\"buffer.length\" = ' + this.length + ', expected ' + binding.sizeof_ogg_packet);\n  }\n}\ninherits(ogg_packet, Buffer);\n```\n\nBut I get this error when trying to access _this.length_ : \n\n```\nUncaught TypeError: Method Uint8Array.length called on incompatible receiver [object Object]\n```\n\nThanks\n\nNote: I also asked the question on SO:\nhttp://stackoverflow.com/questions/32555714\n",
        "labels": "doc",
        "id": 44802
    },
    {
        "title": "Small documentation markup error",
        "body": "Due to most likely a misplaced backtick after `end`, the fixed-width formatting [here](https://nodejs.org/api/buffer.html#buffer_buf_tostring_encoding_start_end) is messed up. I'd submit a quick patch, but I'm unable to find the documentation repository.\n",
        "labels": "doc",
        "id": 44803
    },
    {
        "title": "Split changelog",
        "body": "How about spliting changelog.md into separate files by 'major version' principle? Current 6723 lines and halfof megabyte of changelogs are not so good, i think. What do you say?\n",
        "labels": "doc",
        "id": 44804
    },
    {
        "title": "utf16le encoding is missed in the File System API doc for streams",
        "body": "There is an encoding list in the [Buffer API doc](https://nodejs.org/api/buffer.html#buffer_buffer): ascii, utf8, utf16le / ucs2, base64, binary, hex.\n\nHowever the lists in the File System API doc for streams are not complete.\n\n[fs.createReadStream](https://nodejs.org/api/fs.html#fs_fs_createreadstream_path_options):\n\n> \"The encoding can be 'utf8', 'ascii', or 'base64'.\"\n\n[fs.createWriteStream](https://nodejs.org/api/fs.html#fs_fs_createwritestream_path_options):\n\n> \"The defaultEncoding can be 'utf8', 'ascii', binary, or 'base64'.\"\n\nIn the both lists the \"utf16le / ucs2\" encoding is misguidingly missed.\n",
        "labels": "doc",
        "id": 44805
    },
    {
        "title": "Buffer class has no method 'indexOf' in version 0.12.5 & 0.12.7",
        "body": "As it be defined in https://nodejs.org/api/buffer.html\n\n```\nbuf.indexOf(value[, byteOffset])\n```\n\nbut when I use it like this, an error occurred\n\n```\nBuffer('qweasdzxc').indexOf('ea')\nTypeError: undefined is not a function\n    at repl:1:21\n```\n",
        "labels": "doc",
        "id": 44806
    },
    {
        "title": "Move away from a stability index to a 'weather forecast' type system.",
        "body": "Directly related to https://github.com/nodejs/node/issues/1704, I think that this might be a good way to indicate breaking changes _might_ be coming up soon. Eg, we might say the tracing api stuff is stormy, as it is under heavy development, (I think!), but a core component like buffer is 'clear skies' because we aren't expecting breaking changes and the only changes that could happen in the forecast is positive things.\n\nWe could slowly start rolling in 'weather warnings' for deprecating modules/things, and when the breaking changes are expected to arrive, that would be a 'thunder storm'.\n\nThis feels too wordsy for a system of current status, but it would mean we have more flexibility than \"rate this out of x how stable it is!\"\n\nFeedback much appreciated! Obviously we would need lots of discussion on what the forecasts mean, and documenting it all for people to check out if they need to. We could possibly use another type of forecast system, but I don't know one that might fit, so suggestions would be cool there.\n",
        "labels": "doc",
        "id": 44807
    },
    {
        "title": "API Docs: Cross-reference methods",
        "body": "For example, [fs.unlinkSync](https://nodejs.org/api/fs.html#fs_fs_unlinksync_path) says \"Asynchronous unlink(2)\", but that \"unlink(2)\" reference is just plain text. It should reference `fs.unlink`, which in turn should have actual documentation, instead of assuming the reader knows what \"unlink(2)\" actually means. Or if there is a good POSIX or whatever page that can be referenced, it should do so.\n\n`fs.unlink` is just an example, there are many methods that are documented as \"(a)sync xxx(2)\".\n\nSomewhat related, it would be helpful for the docs for `fs.unlink` to contain the word \"delete\", see also http://php.net/manual/en/function.delete.php\n",
        "labels": "doc",
        "id": 44808
    },
    {
        "title": "[Converge] merge CHANGELOG.md with joyent/node ChangeLog",
        "body": "We need 0.10 and 0.12 entries in the CHANGELOG.md here, they can be copied as-is with basic markdownification as was done in https://github.com/nodejs/node/commit/5d8b232fc\n",
        "labels": "doc",
        "id": 44809
    },
    {
        "title": "Version 3.1.0 release notes?",
        "body": "iojs.org & [/releases](https://github.com/nodejs/node/releases) have v3.1.0, but both repos' [ChangeLog](https://github.com/nodejs/node/blob/master/CHANGELOG.md) go only up to v3.0.0.\n\nMight not be a big deal, but perhaps exposes the need for the release-build script should also build the `CHANGELOG.md`?  Perhaps something readable should be human-edited, but at least the [Commits](https://github.com/nodejs/node/blob/master/CHANGELOG.md#commits) section could be automated.  Would be helpful for emergency point releases.\n",
        "labels": "doc",
        "id": 44810
    },
    {
        "title": "`http.ClientRequest` poor documentation",
        "body": "I'm using tj's superagent, and I want to inspect the actual url requesting\n\n```\nvar request = require('superagent');\n\nrequest\n   .get('<some url>')\n   .on('request',function(){\n        var req = this.req; // req instanceof http.ClientRequest\n    })\n   .end(function(err,res){\n\n    })\n```\n\nreq instanceof http.ClientRequest, but I can hardly find any property reference in the documentation on http.ClientRequest class https://iojs.org/api/http.html#http_class_http_clientrequest\n",
        "labels": "doc",
        "id": 44811
    },
    {
        "title": "changelog missing for v3.1.0 release",
        "body": "https://github.com/nodejs/node/commits/master/CHANGELOG.md\n\nLast commit was 15 days ago.\n\nThanks.\n",
        "labels": "doc",
        "id": 44812
    },
    {
        "title": "assert: inconsistency in assert.doesNotThrow",
        "body": "https://github.com/joyent/node/pull/6470 is an old PR that never landed but points to a valid issue.\n\nThe test case:\n\n``` javascript\nvar assert = require('assert');\nassert.doesNotThrow(function() {\n  throw new Error();\n});\n```\n\nPrints the error stack but does not output an AssertionError.\n\nHowever,\n\n``` javascript\nvar assert = require('assert');\nassert.doesNotThrow(function() {\n  throw new Error();\n}, Error);\n```\n\nRaises an Assertion Error (`AssertionError: Got unwanted exception (Error)..`\n\n``` javascript\nvar assert = require('assert');\nassert.doesNotThrow(function() {\n  throw 'custom message';\n});\n```\n\nAnd \n\n``` javascript\nvar assert = require('assert');\nassert.doesNotThrow(function() {\n  throw 'custom message';\n}, 'custom message');\n```\n\nBoth just output `custom message` without raising the Assertion Error.\n\nThe solution submitted in https://github.com/joyent/node/pull/6470 should be investigated as a possible fix but possibly needs to be revisited.\n",
        "labels": "doc",
        "id": 44813
    },
    {
        "title": "Moving the Docs into the documentation repo",
        "body": "At Node summit, the next steps for the documentation working group were discussed. We decided, after deliberation, that it would be best to pull _all_ documentation, including API docs, into [nodejs/docs](https://github.com/nodejs/docs). We discussed the following scenarios:\n- Keeping _all_ documentation in nodejs/node,\n- Keeping just the API docs in nodejs/node, with other docs in nodejs/docs,\n- Keeping _all_ documentation in nodejs/docs.\n\nThe problem with keeping docs in nodejs/node is that every doc team member needs to be a full contributor (r+w access) to the repo, and it was expressed that some don't want that kind of access. Additionally, having to contribute to the main repo could be intimidating to folks wishing to contribute to _just_ the docs. Localization contributors would likely have to fork the repo, also. The argument that tipped the scales in favor of splitting everything out, ultimately, is that the docs group would like to move away from versioned docs and towards embedding versioning information _into_ the docs â€” that is \"this API was introduced in version X, changed in version Y, deprecated in version Z.\" These evergreen docs remove the need to keep the docs strictly versioned alongside the code.\n\nThis **does not mean** the PRs to this repo will start being accepted sans docs changes â€” rather, PRs here should be linked to a PR to the docs repo.\n### specific actions\n\n_This is a strawman and can be modified._\n1. PR `doc/api/` from current location in Node repo into the docs repo at `src/reference`.\n   1. Doc review and cleanup. This is mostly to get rid of the doctool-isms, not to alter content at this point.\n2. In the Node repo, PR the removal of `doc/api` and `doc/api_assets`. Add a `README.md` to `doc/` explaining that the documentation is contained in the docs repo. Remove docs-related tasks in `Makefile`.\n3. Change the release build step to copy the docs repo `src/` tree (from latest tag in docs repo) into Node src tree at `doc/` before creating package installers / tarballs.\n### timeline\n\nWe should be able to start once the docs and website working group meet have a common tool for building the docs â€” there's a docs WG meeting next Tuesday where we'll check on this progress, and I'll update this issue afterwards.\n### what the world looks like afterwards\n- Documentation team will PR their content into the website repo on a regular basis.\n  - Doc team will tag those commits so the build WG can easily find the latest published docs.\n- Node PRs concerning documentation should be redirected to the docs repo.\n- Node PRs not specifically concerning documentation, but affecting documentation, should contain a link to a corresponding docs PR.\n  - Note: Node PRs _probably_ shouldn't be merged until their corresponding docs PRs are merged.\n\n/cc @nodejs/documentation @nodejs/website @nodejs/build @nodejs/tsc \n",
        "labels": "doc",
        "id": 44814
    },
    {
        "title": "Update the Readme",
        "body": "Obviously, the project README.md needs to be updated now :+1: Can we go ahead and get things renamed?\n",
        "labels": "doc",
        "id": 44815
    },
    {
        "title": "new Buffer doesn't handle unicode well",
        "body": "``` js\nvar arr = [255, 216, 255, 224, 0, 16, 74, 70, 73, 70, 0, 1]\n//length 12;\nvar buf1 = new Buffer(arr)\n// length 12\nvar hex1 = buf1.toString('hex');\n// length 24\nvar str = buf1.toString('utf8')\n// length 12\nvar buf2 = new Buffer(str);\n//length 20\nvar hex2 = buf2.toString('hex');\n// length 40;\n```\n\nresults for hex2\n\n```\nbrowserify - efbfbd00104a4649460001 \nnode - efbfbdefbfbdefbfbdefbfbd00104a4649460001\n```\n\nthe value of str in node is `ï¿½ï¿½ï¿½ï¿½\\u0000\\u0010JFIF\\u0000\\u0001` which would suggest that the issue has to do with how new Buffer handles characters in text.\n\ncc feross/buffer#66\n",
        "labels": "doc",
        "id": 44816
    },
    {
        "title": "tty: stdio properties are undefined inside exec() child",
        "body": "I'm wondering if this is intentional or a bug:\n#### parent.js\n\n``` js\nvar exec = require(\"child_process\").exec;\n\nexec(\"iojs child.js\", function (err, stdout, stderr) {\n  process.stdout.write(stdout);\n});\n```\n#### child.js\n\n``` js\nconsole.log(process.stdin.isTTY);\nconsole.log(process.stdin.isRaw);\nconsole.log(process.stdin.setRawMode);\nconsole.log(process.stdout.columns);\n```\n#### output:\n\n```\nundefined\nundefined\nundefined\nundefined\n```\n\nref: https://github.com/sindresorhus/grunt-shell/issues/95 https://github.com/tjunnone/npm-check-updates/issues/119\n",
        "labels": "doc",
        "id": 44817
    },
    {
        "title": "Path should format when 'base' missing and 'name' and 'ext' exist",
        "body": "This test shows that `name` and `ext` are not taken into account when using `path.format` without a `base`. \n\nThe common usage this is preventing is this:\n\n``` javascript\nvar src = path.parse(srcpath)\nsrc.base = null\nif(src.ext === '') src.ext = '.js'\nsrc = path.format(src)\n```\n\nHowever this doesn't do anything.\n\n``` javascript\nvar path = require('path')\nvar assert = require('assert')\n\n// pulled from https://nodejs.org/api/path.html#path_path_format_pathobject\n/* global describe, it */\n\ndescribe('node path', function () {\n\n  it('should work as documented', function () {\n    assert.equal(path.format({\n      root: '/',\n      dir: '/home/user/dir',\n      base: 'file.txt',\n      ext: '.txt',\n      name: 'file'\n    }), '/home/user/dir/file.txt')\n  })\n\n  it('should not work if missing base', function () {\n    assert.notEqual(path.format({\n      root: '/',\n      dir: '/home/user/dir',\n      ext: '.txt',\n      name: 'file'\n    }), '/home/user/dir/file.txt')\n  })\n\n  it('should show ext and name are irrelevant', function () {\n    assert.equal(path.format({\n      root: '/',\n      dir: '/home/user/dir',\n      ext: '.txt',\n      name: 'file'\n    }), path.format({\n      root: '/',\n      dir: '/home/user/dir'\n    }))\n  })\n\n})\n```\n\nhttps://github.com/nodejs/io.js/blob/master/lib/path.js#L584\n\nI can write a pull request, if anyone else thinks this is a good idea.\n",
        "labels": "doc",
        "id": 44818
    },
    {
        "title": "doc: update whatâ€™s off without `Intl`",
        "body": "Following may not behave as desired without `Intl` support:\n- `String.normalize` (noop) : #779  #1712\n- `String.localeCompare` (uses `string1 < string2`) - see https://github.com/joyent/node/issues/25762\n- `Date.toLocale`\n- `Date.toLocaleDateString`\n- `Date.toLocaleTimeString`\n- `Number.toLocaleString`\n\ncc: #238\n",
        "labels": "doc",
        "id": 44819
    },
    {
        "title": "process.send is not documented",
        "body": "While I believe this is a public API, and part of how one is supposed to communicate between workers and child processes, I was very surprised to see the `process` page not listing the `process.send` function.\n",
        "labels": "doc",
        "id": 44820
    },
    {
        "title": "fs documentation TOC unreadable due to lack of sorting",
        "body": "There are small clumps of 2 or 3 functions where there is a relationship, but its overall basically random, or order of implementation, or some other useless order. I just had to do a bunch of coding against the fs API, and navigating the docs to find one method name out of screenfulls of unordered entries was extraordinarily and unnecessarily painful.\n\nCan I alphabetize them?\n",
        "labels": "doc",
        "id": 44821
    },
    {
        "title": "FIPS build instructions",
        "body": "I'll start out by apologizing that I did not have time to review/comment on this while the initial doc was being written in https://github.com/nodejs/io.js/pull/1890 but I think we have a few issues:\n\n1) From my read of the openssl security policy (http://csrc.nist.gov/groups/STM/cmvp/documents/140-1/140sp/140sp1747.pdf)\n\nMy read is that in Appendix A, page 27 it states that unless you build in a specific way the following applies as written on page 28:\n\n<PRE>\nNote that failure to use one of the specified commands sets exactly as shown will result in a\nmodule that cannot be considered compliant with FIPS 140-2.\n</PRE>\n\n\nOur current instructions here: https://github.com/nodejs/io.js  describes building with a prefix which would not match the above instructions.  The user guide here https://openssl.org/docs/fips/UserGuide-2.0.pdf specifically calls out that you cannot use a prefix (See section 5.7.1 on page 63) \n\nI think we might be able to update the instructions to indicate to build as outlined in the security policy/user guide and then update the configure line (what is shown is where the make installed on  ubuntu 12, we probably need something more generic or to just say to point it to where make install did the installation) \n\n<PRE>\n./configure --openssl-fips=/usr/local/ssl/fips-2.0\n</PRE>\n\n\nI have a compile going to see if things build/run ok with that.  \n\n2) There is a requirement to get the source through a \"trusted\" path.  See page 87 in https://openssl.org/docs/fips/UserGuide-2.0.pdf.  What we currently describe in our readme is likely not sufficient to ensure that people understand that they have to verify with an already validated tool or get the source through a trusted path like email.\n\n3) There might be other gotchas in the security polity/user guide but I've not had time to do a full read  yet.  One I'm wondering about is 5.1 on page as I'm not sure if absolutely all of the crypto in Node comes from openssl or not.\n\nIf there is consensus that we need to adjust the doc I can put together a pull request\n",
        "labels": "doc",
        "id": 44822
    },
    {
        "title": "On filesystems which do not support birthtime, stats.birthtime can be greater than stats.mtime",
        "body": "stats.birthtime tracks ctime on filesystems which do not support birthtime, even if stats.ctime > stats.mtime or stats.ctime > stats.atime.\n\nIt would be better in this case if stats.birthtime be set to the earliest of all available timestamps.\n\nHere is a test to reproduce, which should pass on OS X and fail on Ubuntu:\n\n``` js\nvar fs = require('fs');\nconsole.log('creating...');\ntry {\n  fs.unlinkSync('testbirthtime');\n} catch (error) {}\nfs.writeFileSync('testbirthtime', '');\nconsole.log('statting...');\nvar before = fs.statSync('testbirthtime');\nif (before.mtime.getTime() === before.ctime.getTime() && before.ctime.getTime() === before.birthtime.getTime()) {\n  console.log('stats.mtime===stats.ctime===stats.birthtime');\n} else {\n  console.log(JSON.stringify(before));\n  // should never be here, unless the test is faulty.\n  throw new Error('expected stats.mtime===stats.ctime===stats.birthtime after create');\n}\n// give enough time for filesystem timestamp granularity\nconsole.log('waiting 3 seconds...');\nsetTimeout(\n  function() {\n    console.log('changing mode to bump ctime...');\n    fs.chmodSync('testbirthtime', '777');\n    console.log('statting again...');\n    var after = fs.statSync('testbirthtime');\n    try {\n      fs.unlinkSync('testbirthtime');\n    } catch (error) {}\n    if (after.birthtime.getTime() === before.birthtime.getTime()) {\n      console.log('===========');\n      console.log('TEST PASSED');\n      console.log('stats.birthtime stayed the same after chmod');\n    } else {\n      console.log('===========');\n      console.log('TEST FAILED');\n      console.log('stats.birthtime after chmod !== stats.birthtime at creation');\n      if (after.birthtime.getTime() > before.birthtime.getTime()) {\n        console.log('stats.birthtime has gone forward in time');\n      } else {\n        console.log('stats.birthtime has gone backward in time');\n      }\n      if (after.mtime.getTime() === before.mtime.getTime()) {\n        console.log('stats.mtime stayed the same after chmod');\n      }\n      if (after.birthtime.getTime() === after.ctime.getTime()) {\n        console.log('stats.birthtime now equals newer stats.ctime');\n        console.log('where birthtime is not supported by filesystem:');\n        console.log('  stats.birthtime should be earlier of stats.mtime and stats.ctime');\n      }\n    }\n  },\n  3000\n);\n```\n",
        "labels": "doc",
        "id": 44823
    },
    {
        "title": "child_process.spawn sh not killable",
        "body": "Comming from here:\nhttps://github.com/keithamus/parallelshell/issues/22\n\n(btw: Usecase for #1009)\n\nEverytime I need to spawn a process I do it like this\n\n``` js\nif (process.platform === 'win32') {\n    sh = 'cmd';\n    shFlag = '/c';\n} else {\n    sh = 'sh';\n    shFlag = '-c';\n}\nvar child = spawn(sh,[shFlag,cmd], {\n  cwd: process.cwd,\n  env: process.env,\n  stdio: ['pipe', process.stdout, process.stderr]\n})\n```\n\nThe problem: `child` is unkillable on unix.\nExample in coffee-script:\n\n``` coffee\nspawn = require(\"child_process\").spawn\nchild = spawn \"sh\", [\"-c\", \"node -e 'setTimeout(function(){},10000);'\"]\nchild.on \"close\", process.exit\nchild.kill()\nchild.kill(\"SIGINT\")\nchild.kill(\"SIGTERM\")\nchild.kill(\"SIGHUP\")\nspawn \"sh\",[\"-c\",\"kill -TERM \"+child.pid]\nspawn \"sh\",[\"-c\",\"kill -INT \"+child.pid]\nspawn \"sh\",[\"-c\",\"kill -HUP \"+child.pid]\n```\n\n(on windows it works fine with sh replaced by cmd)\nEven when I exit the process with `process.exit()`, the child stays alive.\n\nWorkaround I found:\n\n``` coffee\nspawn = require(\"child_process\").spawn\nchild = spawn \"sh\", [\"-c\", \"node -e 'setTimeout(function(){},10000);'\"], detached: true\nchild.on \"close\", process.exit\nspawn \"sh\",[\"-c\",\"kill -INT -\"+child.pid]\n```\n\nKilling by pgid works, by pid works not. Sending ^C from console works also, I assume it uses pgid always.\n",
        "labels": "doc",
        "id": 44824
    },
    {
        "title": "Documentation: process event uncaughtException pointing to deprecated module",
        "body": "On the [Process event `'uncaughtException'` documentation](https://iojs.org/api/process.html#process_event_uncaughtexception), you are pointed to use domains instead for exception handling.\n\nGiven that the domain module is pending deprecation, an alternative solution should be documented.\n",
        "labels": "doc",
        "id": 44825
    },
    {
        "title": "NPNProtocols docs need clarification / example",
        "body": "@indutny The documentation on the HTTPS page refers to the TLS page which fails to give an example (obviously 'hello' and 'world' are not true internet protocols).\n\nI'm assuming that it should be something like this:\n\n``` javascript\nhttps.createServer({\n  key: fs.readFileSync(path.join(certsPath, 'my-server.key.pem'))\n, cert: fs.readFileSync(path.join(certsPath, 'my-server.crt.pem'))\n, ca: [\n    fs.readFileSync(path.join(caCertsPath, 'intermediate.crt.pem'))\n  , fs.readFileSync(path.join(caCertsPath, 'root.crt.pem'))\n  ]\n\n  , NPNProtocols: ['http/2.0', 'spdy', 'http/1.1', 'http/1.0']\n\n});\n```\n\nBut I'm not sure if 'http/2.0' is a valid option or how I would pass off http/2.0 requests to the http/2.0 handler, etc (I'm assuming that no http2 module has yet to make it into core yet).\n",
        "labels": "doc",
        "id": 44826
    },
    {
        "title": "Reorder authors in README.md",
        "body": "(brought up in #1966, moved to its own place)\n\n@rvagg suggested that we should reorder authors to remove any significance to their wg membership, such as when they joined or if they are part of the TC.\n\nLets agree on how this should be ordered. So far, last name or github username seems to be the two options. I like the idea of using the github username (and subsequently moving that ahead of name/email).\n",
        "labels": "doc",
        "id": 44827
    },
    {
        "title": "the maxBuffer isn't complete accurate in child_process",
        "body": "The `maxBuffer` is not complete accurate when data include unicode and encoding is set.\n",
        "labels": "doc",
        "id": 44828
    },
    {
        "title": "Adding a method named 'inspect' to an object does not work as expected",
        "body": "I understand this has probably been like this for a while but I've never created a method named `inspect` on an object.  Just spent over two hours trying to debug this.  \n\nAt the very least this should be very well documented.  Right now the first link in Google for `node inspect reserved` is a [stackoverflow answer](http://stackoverflow.com/questions/11652454/in-nodejs-inspect-acts-like-a-reserved-word) and there is no mention of this behavior in the documentation. \n\nObviously running this code in Chrome, Firefox, Safari, etc works as expected.\n\n```\n> process.versions\n{ http_parser: '2.5.0',\n  node: '2.0.2',\n  v8: '4.2.77.20',\n  uv: '1.5.0',\n  zlib: '1.2.8',\n  ares: '1.10.1-DEV',\n  modules: '44',\n  openssl: '1.0.2a' }\n> function Test(){ };\nundefined\n> Test.prototype.inspect = function(){ return 'hahaha';}\n[Function]\n> var t = new Test()\nundefined\n> t\nhahaha\n```\n",
        "labels": "doc",
        "id": 44829
    },
    {
        "title": "fs.readFile with encoding as 2nd argument is not documented",
        "body": "It is very common to call fs.readFile with the encoding name directly as the 2nd argument. Like\n\n```\nfs.readFile('my_file.txt', 'utf8', cb)\n```\n\nYet this call signature is not clearly documented:\n\nhttps://iojs.org/api/fs.html#fs_fs_readfile_filename_options_callback (link date 2015-05-26)\n",
        "labels": "doc",
        "id": 44830
    },
    {
        "title": "Document long-term technical debt",
        "body": "There are longstanding known issues in node which are (mostly) in my head only.\nFor some of them there currently isn't a plan on how to prioritize them.\nIt feels futile to open issues for these topics, because they'll be buried soon under a pile of short-term, actionable bug reports.\n\nThe goal here is to capture some tacit knowledge and share with more people.\n\nAn example (which would be documented in much more detail):\n- The process IPC doesn't support backpressure and silently drops messages when overloaded.\n\nMany of the things I know about are actually windows issues:\n- Cluster is very inefficient on windows (I know why - long story).\n- The IPC pipe implementation in libuv is a mess\n- fs.chmod() probably doesn't do the right thing\n- Command line formatting (for child_process.exec) could be improved to work better for batch files.\n\nI would not mind setting myself down to document what I know and submit it as a PR. But would it be helpful/worthwhile? Please advise @nodejs/tsc.\n",
        "labels": "doc",
        "id": 44831
    },
    {
        "title": "README.md should say what io.js is",
        "body": "May I suggest, for those arriving here for the first time, that the readme tell what io.js is in the very first paragraph?\n\nSaying that it began as a fork of joyent/node hardly tells what one would use io.js for, or what the io.js project is trying to be. Are you trying to replace node? I have no idea.\n",
        "labels": "doc",
        "id": 44832
    },
    {
        "title": "doc: Stability 2 (stable) listed as \"unstable\" in fs docs",
        "body": "https://github.com/nodejs/io.js/blob/master/doc/api/documentation.markdown#stability-index indicates that Stability 2 = Stable but there are three places in the `doc/fs.md` where Stability 2 is marked Unstable. Not sure if the doc about stability index needs clarification, or if the `fs` doc needs to update those indices to different values, or ... ?\n",
        "labels": "doc",
        "id": 44833
    },
    {
        "title": "Update Repository Tagline",
        "body": "The io.js repository tagline currently says, \"A friendly fork of Node.js with an open governance model\", this should be updated to more accurately reflect the current state of the foundation. It's minor, yes, but these things tend to be important.\n\n/cc @mikeal @nodejs/tsc  \n",
        "labels": "doc",
        "id": 44834
    },
    {
        "title": "Impossible to install: There is no clear instruction on how to install IO.JS on MAC OS X.",
        "body": "I've opened the main site https://iojs.org/ and tried to find out, how to install io.js â€” nothing.\nNothing on main page, nothing in FAQ section. \n\nOk.\n\nI've tried to install via homebrew\n\n```\n$ brew install iojs\n==> Downloading https://homebrew.bintray.com/bottles/iojs-2.0.1.yosemite.bottle.tar.gz\nAlready downloaded: /Library/Caches/Homebrew/iojs-2.0.1.yosemite.bottle.tar.gz\n==> Pouring iojs-2.0.1.yosemite.bottle.tar.gz\n==> Caveats\niojs was installed without npm.\n\niojs currently requires a patched npm (i.e. not the npm installed by node).\n\nThis formula is keg-only, which means it was not symlinked into /usr/local.\n\niojs conflicts with node (which is currently more established)\n\nGenerally there are no consequences of this for you. If you build your\nown software and it requires this formula, you'll need to add to your\nbuild variables:\n\n    LDFLAGS:  -L/usr/local/opt/iojs/lib\n    CPPFLAGS: -I/usr/local/opt/iojs/include\n\n==> Summary\nðŸº  /usr/local/Cellar/iojs/2.0.1: 134 files, 13M\n```\n\nOk, then\n\n```\n$ iojs\nzsh: command not found: iojs\n$ io.js\nzsh: command not found: io.js\n$ node -v\nzsh: command not found: node\n```\n\nI've found good article http://blog.modulus.io/install-nodejs-and-iojs-together-safely\nbut this works only for current session.\n\nIf I open another tty this does not work.\n\nOk.\n\nThere are some articles how to install iojs using nvm, but they dont work too.\n\nUPD: I found .pkg download on main site.\nI think this source of installation should be more noticeable\n",
        "labels": "doc",
        "id": 44835
    },
    {
        "title": "Put a warning against misusing `*Sync` methods to the API docs.",
        "body": "_Taking apart #1665._\n\nWhile  #1674 looks like a good thing, almost eveyone seems to think that it replaces #1665. But it doesn't touch the initial point of #1665 â€” to discourage using `*Sync` versions of the methods that could be async.\n\nThe reasoning is mostly the same as in #1665.\n\nTwo alternatives here:\n1. Create a separate page with a warning against improper usage of blocking methods and add a small but instantly visible reference from every `*Sync` method documentation to that page.\n   Sample:\n   \n   > ## fs.accessSync(path[, mode])\n   > \n   > Warning: this is **blocking call**, do not use in an asynchronous enviroment unless you know what you are doing. More info on **some nice title (link)**. \n   > \n   > Synchronous version of fs.access. This throws if any accessibility checks fail, and does nothing otherwise.\n2. Create a separate page with a warning and move all `*Sync` methods documentation to that page, leaving only references (possibly with headers) to it on the corresponding module pages. \n   Sample:\n   \n   > ## fs.accessSync(path[, mode])\n   > \n   > A **blocking call**, the documentation is listed on **some nice title (link)**. \n\n_Notice: I am not a native English speaker and can be a bit wrong with woridings._\n",
        "labels": "doc",
        "id": 44836
    },
    {
        "title": "document new es6 features from v8 4.2",
        "body": "Classes under strict, object literals, anything else?\n\n/cc @domenic\n",
        "labels": "doc",
        "id": 44837
    },
    {
        "title": "question: error reference in docs for `fs` (and others)?",
        "body": "It's a shame the docs for `fs` lack a list of the possible errors you'll see. To gracefully handle the different errors you either need to know the error codes/messages off by heart, or find them by trial and error.\n\nI wanted to check if there's any interest before I made a PR to include these errors in the docs.\n\np.s there's a [great module for this](https://github.com/rvagg/node-errno) already.\n",
        "labels": "doc",
        "id": 44838
    },
    {
        "title": "`generate.js` doc tool produces incomplete json",
        "body": "The output from\n\n```\n$ node generate.js ../../doc/api/debugger.markdown\n```\n\ndoesn't correspond to its markdown source. For example, `### Info` section is missing, both `### Execution control` & `### Various` sections lack expected `desc` property.\n",
        "labels": "doc",
        "id": 44839
    },
    {
        "title": "docs: state behavior for url pathname and percent encoding",
        "body": "Shouldn't be stated in the docs that url module does NOT touch `pathname` or pathname part of `path` (no percent encoding/decoding) when extracting-from/putting-into urls?\n\n```\n> url.parse('https://example.com/pathname%20with%20fun%20incorporated%3d/?adf=f4&er4=%40',false);\n{ protocol: 'https:',\n  slashes: true,\n  auth: null,\n  host: 'example.com',\n  port: null,\n  hostname: 'example.com',\n  hash: null,\n  search: '?adf=f4&er4=%40',\n  query: 'adf=f4&er4=%40',\n  pathname: '/pathname%20with%20fun%20incorporated%3d/',\n  path: '/pathname%20with%20fun%20incorporated%3d/?adf=f4&er4=%40',\n  href: 'https://example.com/pathname%20with%20fun%20incorporated%3d/?adf=f4&er4=%40' }\n\n> url.parse('https://example.com/pathname%20with%20fun%20incorporated%3d/?adf=f4&er4=%40',true);\n{ protocol: 'https:',\n  slashes: true,\n  auth: null,\n  host: 'example.com',\n  port: null,\n  hostname: 'example.com',\n  hash: null,\n  search: '?adf=f4&er4=%40',\n  query: { adf: 'f4', er4: '@' },\n  pathname: '/pathname%20with%20fun%20incorporated%3d/',\n  path: '/pathname%20with%20fun%20incorporated?adf=f4&er4=%40',\n  href: 'https://example.com/pathname%20with%20fun%20incorporated?adf=f4&er4=%40' }\n\n```\n\nIn fact, it does not do any percent encoding/decoding at all in query/search -with the exception of opt-in querystring parsing (`parseQueryString` argument) or when encoding an object including query params to a full url-.\nIn this case (querystring/search whatever you call it) it is pretty obvious (decoding without parsing leads to incorrect data, ie: `'?a=%26b'`), and it is kind of implicitly documented in the examples, though.\n\nBut stating it clearly in the docs for `pathname` and pathname part in `path` should let api users avoid the 'implemetation' vs 'intended' behavior dilemma: trusty, future-proof('till api change) behavior.\n\nI'm ssuming that it is intended behavior. If it happens to be an implementation detail... i'm not related to the project but if asked would be +1 on current behavior: raw original data available, that can be decoded if needed, so we don't lose upper/lowercase info for percent escapes (of significance to oauth1.0a).\n\nNotes: http module: `url` property in `IncomingMessage`s (`http.Server` 'request' event) is consistent with url module behavior right now. \"Fix\" docs too ?\n\nPD: My humble apologies for the poor quality of my mind's English implementation.\n",
        "labels": "doc",
        "id": 44840
    },
    {
        "title": "Changelogs are noisy",
        "body": "I have a few complaints about the changelogs and was wondering if anyone shared them. In order of decreasing importance:\n- npm takes up half or more of the headlining \"notable changes\" space. I think it should get a budget of one sentence, and the rest can be links to the one or more npm changelog entries.\n- known issues is incomplete and repetitive. Pretty much all of [the 19 issues tagged as bug](https://github.com/iojs/io.js/labels/bug) count as \"known issues\". Probably others do too. And this section just stays the same release after release. Can we replace it with a link to the bug tag (or to a new known issues tag, if there's some distinction I'm missing between them)? If we need a snapshot of issues at a given point in time, can we collapse it into a single list like \"Known issues: #x, #y, #z\" instead of summarizing them over and over?\n- The commits list seems a bit redundant. Could we just link to the GitHub compare tags view? That way people can more easily expand to see the whole commit message.\n\nI say all this with love, as the readable changelogs are one of the best parts of io.js :). I just want to make them a bit more usable.\n",
        "labels": "doc",
        "id": 44841
    },
    {
        "title": "http: agent.keepAlive option",
        "body": "Good day! Documentation of `agent.keepAlive` says:\n\n>  Keep sockets around in a pool to be used by other requests in the future. Default = `false`\n\nBut if you dig into [_http_agent.js code](https://github.com/iojs/io.js/blob/v1.x/lib/_http_agent.js#L74), you will find `socket.setKeepAlive(true, self.keepAliveMsecs);` call, which is not quite responsible for keeping sockets in pool, but from [socket.setKeepAlive](https://iojs.org/api/net.html#net_socket_setkeepalive_enable_initialdelay) documentation:\n\n> Enable/disable keep-alive functionality, and optionally set the initial delay before the first keepalive probe is sent on an idle socket. enable defaults to false.\n\nWhich is pointing to TCP layer [dead-peer-detection](http://tldp.org/HOWTO/TCP-Keepalive-HOWTO/overview.html).\n\nI think there is an error in documentation (which leads to some confusion) - may be it should be changed to something like:\n\n> agent.keepAlive â€” if enabled, calls [socket.setKeepAlive](https://iojs.org/api/net.html#net_socket_setkeepalive_enable_initialdelay) on incoming sockets\n\nMay be I'm getting code in `_http_agent.js` wrong.\n",
        "labels": "doc",
        "id": 44842
    },
    {
        "title": "Document require('console').Console class",
        "body": "The default `console` object is an instance of `Console`, maybe we can document it for developers.\n",
        "labels": "doc",
        "id": 44843
    },
    {
        "title": "Document code style guidelines",
        "body": "After #1220, the need for meta-documentation seems prevalent, and the lack of it leads to unproductive discussions, as in #1241. If only we had a good, solid answer. This should also reduce the amount of unproductive discussion related to style nits in PRs - I'd say a large majority of edits a _new contributor_ has to do, primarily deals with style.\n\nHere's my proposal for the guidelines with what I could scrounge up from code as is. We can also discuss sharing a style guide with another project, like [airbnb](https://github.com/airbnb/javascript), but I think the core style is different from any others, as is.\n\nWhen in doubt, `make lint`. This style guide doesn't cover stuff that fails lint (I think).\n# JavaScript\n## Variables\n- `const` should always be used over `var` for variables that never change, such as require'd modules\n- `let` should not be used [until v8 speed against `var` increases]\n- variable names should be camelCase, unless they are a FunctionConstructor\n## Conditionals\n- when using a conditional such as `if {} else if {} else {}`, it must all have braces or it must all not have braces, no mixing of braces\n- for simple `if` conditionals, do not use braces ([ref](https://github.com/iojs/io.js/blob/v1.x/lib/_http_outgoing.js#L81))\n## Equality\n- whenever possible, use strict equality (`===`) rather than loose equality (`==`), unless you are dependent on type coercion\n## Lines\n- as the closure linter insists on 80 character lines, splitting up conditionals and strings must be done with the operand at the end of the previous line ([ref](https://github.com/iojs/io.js/blob/v1.x/lib/_http_outgoing.js#L112))\n- indentations are two spaces\n## Comments\n- `// Comments should start with a capital, include correct punctuation, and have a period.`\n- todo format: `TODO(username): More text here.` Can also use `FIXME(username)`.\n- `// XXX(username)` for hacks - however very few should exist if possible\n## Modules\n- modules should be split into separate, smaller modules (such as `_stream_x` and `_http_x`) when they are too large to fit into one concisely\n- module import statements should be done permanently, at the top of each module\n### util\n- we love you util, but in core, your `util.isXXX` functions are not to be used and should be replaced with their respective inline equivalents\n## et cetera\n- do not introduce style-only changes in a commit that deals with another feature or fix; each commit should relate to only one change\n# C++\n\nI don't know C++, anyone want to jump in?\n\nOther notes:\n- I think that the new errors document would be a subset of this, unless we decided to put them into separate markdown files\n- I have no idea where this file would go\n",
        "labels": "doc",
        "id": 44844
    },
    {
        "title": "Breaking change: cluster connection behavior when between workers",
        "body": "[Already reported this on node 0.12](https://github.com/joyent/node/issues/10427), thought I should report it here as well.\n\nOn OSX, I've noticed a big difference between the way that connections are dealt with by a master process when there are no workers ready to take care of that incoming connection. In node `0.10.36` (and before), the connection would be held open, and a worker that hadn't been started when that request was made would have the chance to handle it. In all versions of iojs (and node `0.12.0`), incoming connections when between workers are outright refused.\n\nAt the very least, this should be documented.\n\nExample code and output on both node `0.10.36` and iojs `1.6.1` follows:\n\n``` javascript\nvar cluster = require('cluster');\nvar http = require('http');\nvar supertest = require('supertest');\nvar PORT = 3000;\n\n// cluster.schedulingPolicy = cluster.SCHED_NONE;\n\nif (!cluster.isMaster) {\n  http.createServer(function (req, res) {\n    if (req.url === '/error') {\n      setTimeout(function() {\n        throw new Error('something went wrong!');\n      }, 500);\n    }\n    else {\n      res.writeHead(200, {'Content-Type': 'text/plain'});\n      res.end('Hello World\\n');\n    }\n  }).listen(PORT);\n\n  console.log('Worker %s running at port %s', cluster.worker.id, PORT);\n}\nelse {\n  var count = 0;\n  var request = supertest('http://localhost:' + PORT);\n\n  var hitWorker = function(count) {\n    console.log('%s: Worker listening! Hitting it...', count);\n\n    request\n      .get('/error')\n      .expect(200, function(err, res) {\n        console.log('%s: Worker taken down, now making second request', count);\n\n        request\n          .get('/')\n          .expect('Hello World\\n')\n          .expect(200, function(err, res) {\n            console.log('%s: Second request complete. Error:', count, err);\n          });\n      });\n  };\n\n  cluster.on('disconnect', function() {\n    count +=1;\n    if (count < 2) {\n      cluster.fork();\n    }\n  });\n\n  cluster.on('listening', function() {\n    hitWorker(count);\n  });\n\n  // start just one worker\n  cluster.fork();\n\n  var interval = setInterval(function() {\n    console.log('...');\n  }, 1000);\n  interval.unref();\n}\n```\n## output\n\niojs 1.6.1 (scheduling policy does not make a difference):\n\n```\nWorker 1 running at port 3000\n0: Worker listening! Hitting it...\n/Users/scottnonnenberg/Development/thehelp/cluster/test.js:12\n        throw new Error('something went wrong!');\n              ^\nError: something went wrong!\n    at null._onTimeout (/Users/scottnonnenberg/Development/thehelp/cluster/test.js:12:15)\n    at Timer.listOnTimeout (timers.js:88:15)\n0: Worker taken down, now making second request\n0: Second request complete. Error: { [Error: connect ECONNREFUSED 127.0.0.1:3000]\n  code: 'ECONNREFUSED',\n  errno: 'ECONNREFUSED',\n  syscall: 'connect',\n  address: '127.0.0.1',\n  port: 3000 }\nWorker 2 running at port 3000\n1: Worker listening! Hitting it...\n...\n/Users/scottnonnenberg/Development/thehelp/cluster/test.js:12\n        throw new Error('something went wrong!');\n              ^\nError: something went wrong!\n    at null._onTimeout (/Users/scottnonnenberg/Development/thehelp/cluster/test.js:12:15)\n    at Timer.listOnTimeout (timers.js:88:15)\n1: Worker taken down, now making second request\n1: Second request complete. Error: { [Error: connect ECONNREFUSED 127.0.0.1:3000]\n  code: 'ECONNREFUSED',\n  errno: 'ECONNREFUSED',\n  syscall: 'connect',\n  address: '127.0.0.1',\n  port: 3000 }\n...\n```\n\nnode 0.10.36:\n\n```\nWorker 1 running at port 3000\n0: Worker listening! Hitting it...\n\n/Users/scottnonnenberg/Development/thehelp/cluster/test.js:13\n        throw new Error('something went wrong!');\n              ^\nError: something went wrong!\n    at null._onTimeout (/test.js:13:15)\n    at Timer.listOnTimeout [as ontimeout] (timers.js:112:15)\n0: Worker taken down, now making second request\nWorker 2 running at port 3000\n1: Worker listening! Hitting it...\n0: Second request complete. Error: null\n...\n\n/Users/scottnonnenberg/Development/thehelp/cluster/test.js:13\n        throw new Error('something went wrong!');\n              ^\nError: something went wrong!\n    at null._onTimeout (/test.js:13:15)\n    at Timer.listOnTimeout [as ontimeout] (timers.js:112:15)\n1: Worker taken down, now making second request\n...\n...\n...\n...\n^C\n```\n\nThis version hangs, because third worker not started, and master keeps connection open. Note also that '0: second request complete' actually comes after '1: worker listening!'. This is because that initial second request actually ends up hitting the second worker. \n",
        "labels": "doc",
        "id": 44845
    },
    {
        "title": "Dns resolver ipv6",
        "body": "require('http') is responsible for passing the host to the dns resolver, when the the address you want to bind on is ipv6 the dns resolver should return the ipv6 address instead of the ipv4 one.\n",
        "labels": "doc",
        "id": 44846
    },
    {
        "title": "Stream not emitting data event after pipe+unpipe",
        "body": "The following should log 'ok' to the console but nothing is logged.\n\n``` javascript\nvar stream = require('stream');\nvar pass = new stream.PassThrough();\nvar writable = new stream.Writable();\n\npass.pipe(writable); pass.unpipe(writable);\npass.on('data', function(chunk){ console.log(chunk.toString()); });\npass.write('ok');\n```\n\nOf course, commenting the line `pass.pipe(writable); pass.unpipe(writable);` fix the problem.\n\nCan you explain me why?\n",
        "labels": "doc",
        "id": 44847
    },
    {
        "title": "Documentation Style Guidelines",
        "body": "Do they exist? If not, they should be created.\n\nI'd be willing to help with the creation in a few days.\n",
        "labels": "doc",
        "id": 44848
    },
    {
        "title": "Can we document the AtExit function for addons?",
        "body": "The function AtExit act as a module shutdown callback, and was added in this commit https://github.com/bnoordhuis/node/commit/1c20cac, but was never documented (why?). \n\nI'm pretty sure many addon developers wanted something like that, but probably never used that function because it is not documented anywhere.\n\nThere is a pull request [here](https://github.com/joyent/node/pull/8461) with documentation, but it was not merged into node for unknown reasons.\n",
        "labels": "doc",
        "id": 44849
    },
    {
        "title": "repl: document auto-loading",
        "body": "this is my first attempt to io.js . I Installed version 1.3 on my mac, osx yosemite, via macports. I looked for documentation at https://iojs.org/api/ to use `fs` module. reading at [fs documentation](https://iojs.org/api/dns.html) the first statement is\n\n```\nUse require('fs') to access this module. \n```\n\nThe same statement is repeated on every module but, trying to use the CLI shell, i noticed several modules (probably all) are already loaded\n\n```\n~ leonardo$ iojs\n>\n...\ncluster                       console\ncrypto                        dgram\ndns                           domain\nescape                        events\nfs                            global\nhttp                          https\nmodule                        net\nos                            path\nprocess                       punycode\nquerystring                   readline\nrequire                       root\nsetImmediate                  setInterval\nsetTimeout                    smalloc\nstream                        string_decoder\ntls                           tty\nunescape                      url\nutil                          v8\nvm                            zlib\n...\n\n> cfs = require('fs')\n> fs == cfs\ntrue\n```\n\nso, if my guess is correct, the documentation should be updated to reflect the fact that `require` actually is not required for the standard module if using the CLI shell.\n",
        "labels": "doc",
        "id": 44850
    },
    {
        "title": "Document promises in promises.markdown.",
        "body": "When discussing promises in io.js in IRC. @Fishrock123 suggested we consider a promises.markdown file explaining how to use promises in io, explain the rationale and approaches to the rejection event hooks added to `process` and common io.js related issues (working with a promise API and so on).\n- Should such a page exist? \n- What information should such a page include?\n- Where should it be linked to?\n",
        "labels": "doc",
        "id": 44851
    },
    {
        "title": "util: discrepancy in format() docs vs behavior",
        "body": "There is a discrepancy between how the docs say `util.format()` works, and what really happens. The docs state:\n\n> If there are more arguments than placeholders, the extra arguments are converted to strings with util.inspect() and these strings are concatenated, delimited by a space.\n\nHowever, [only objects and symbols actually use `util.inspect()`](https://github.com/iojs/io.js/blob/v1.x/lib/util.js#L33-L37). The required change is trivial, and I think we should bring behavior into line with what the docs say, but this is a slightly breaking change (there is at least one test that fails).\n\nOriginally reported in #931\n",
        "labels": "doc",
        "id": 44852
    },
    {
        "title": "Remove stability designations in core JS API",
        "body": "For several years we've been marking the core API with a sliding scale of \"stability.\"\n\nIt seemed like a good idea at the time but is at best, a poorly messaged note about how much work is happening on an API, and at worst an outright lie.\n\nEven if a module has the lowest level of stability attached we may, and actually have been, guaranteeing backwards compatibility if enough of the ecosystem depends on it.\n\nStreams is laughably marked \"Unstable\" at the moment. While it is true that streams have been changing a huge amount of effort in each change has gone in to guaranteeing backwards compatibility. That kind of compatibility is not what anyone would expect from an API being messaged as \"Unstable.\"\n",
        "labels": "doc",
        "id": 44853
    },
    {
        "title": "net: wrong docs for socket 'connect' event registration",
        "body": "I'am playing around with a few issues in the net module.\n\nAs said in the docs the parameter 'connectionListener' (callback) in the functions net.createConnection, net.connect and socket.connect will be added as an listener for the 'connect' event.\n\nIf you have a look in the socket.connect function, which is called from every of these functions, the 'connect' event is fired only once. (net.js line 864: self.once('connect', cb);) It is not saved or added as a permanent listener.\n\nI think this should be corrected in the docs. If you create a socket with the net.createConnection function and reuse this socket and connect again with the socket.connect function you have to register again for the 'connect' event. If you rely on the docs you only will get one event fired.\n\nI can make a PR for this, but first wanted to get some comments about this cause I am not 100% sure if I got this right.\n",
        "labels": "doc",
        "id": 44854
    },
    {
        "title": "Documentation: Should have Addons documentation easily findable, should explain how to use a Typed Array in C++ that is given as a parameter",
        "body": "I also posted an issue at https://github.com/joyent/node/issues/9247\n\nIt would be useful if writing of addons was shown at a much higher level within the documentation. I don't even know where it exists within the io.js documentation (or node either). I've used Google to find information on writing addons.\n\nSpecifically, I'd like to make use of a Float32Array that has been given to a C++ function in an addon. Advice on this would be appreciated, but it's worth having in the docs too.\n",
        "labels": "doc",
        "id": 44855
    },
    {
        "title": "doc: Improving documents to look better on mobile devices",
        "body": "I'm looking for feedback and suggestions to improve the readability of the docs on mobile devices. Specifically meaning that the docs need to be responsive to screen sizes. I can start working on it and if possible figure out who else wants to pitch in. I'm not sure what the guidelines are for the docs, what accessibility standards we need to adhere too etc... Also I think this would allow more people in the community to get involved with io.js efforts.\n\nFor examples of responsive docs see\n- http://hapijs.com/api\n- https://developer.spotify.com/web-api/\n\nThere's more to fixing the docs for mobile than adding the viewport meta tag. I added the tag locally and a lot of text exceeded the width of the page.\n",
        "labels": "doc",
        "id": 44856
    },
    {
        "title": "Error logging",
        "body": "Hello there,\n\n On Node.js most error loggings are awful (ex: `ENOENT` error). Most of the time it requires a web research to find its meaning. \n\nIs it possible to improve this in io.js ? I mean, if I don't find any technical constraints, may I propose a pull request about it? \n",
        "labels": "doc",
        "id": 44857
    },
    {
        "title": "Quick code sample in README",
        "body": "It would be nice if there was a minimal product included within the README for completely new users to build from source and test that their product is working. A \"hello world\" code and then how to execute it, really.\n",
        "labels": "doc",
        "id": 44858
    },
    {
        "title": "Add missing collaborators to README",
        "body": "We're missing some new collaborators from the README, would the following people mind submitting a PR to get their details on there please?\n- [x] @sam-github (#791)\n- [x] @geek (#835)\n- [x] @shigeki\n\nIt's a helpful part of the onboarding process for a couple of reasons:\n1. practice & a safe way to check that you're on the right wavelength re git workflow\n2. demonstrate that the project really is open\n3. provide additional kudos to those putting in the hard work here\n",
        "labels": "doc",
        "id": 44859
    },
    {
        "title": "Confusing documentation or bad implementation for util.isObject",
        "body": "The documentation for `util.isObject` states:\n\n> Returns true if the given \"object\" is strictly an Object. false otherwise. \n\nWhat exactly does \"strictly an Object\" mean? That the type of the argument is Object? Nope:\n\n``` js\n> var f = function(){}\nundefined\n> util.isObject(f)\nfalse\n```\n\nOr maybe it does an `instanceof` check? That also isn't the case:\n\n``` js\n> var o = Object.create(null)\nundefined\n> o instanceof Object\nfalse\n> util.isObject(o)\ntrue\n```\n\nDoes it check that the [[Class]] internal property is \"Object\"? Also no:\n\n``` js\n> Object.prototype.toString.call(JSON)\n'[object JSON]'\n> util.isObject(JSON)\ntrue\n```\n\nEither the docs should be updated to clarify the behavior, or the implementation should be fixed. I would vote for the latter, otherwise the function name is confusing.\n",
        "labels": "doc",
        "id": 44860
    },
    {
        "title": "Should Node.js references be changed to io.js in Docs?",
        "body": "Except when specifically distinguishing between Node.js and io.js, should the Node.js and Node references in the docs be changes to io.js?\n\nIf so, I'm willing to make those changes. Just thought I'd ask first.\n",
        "labels": "doc",
        "id": 44861
    },
    {
        "title": "Vendor iojs/doc-tool / integrate build",
        "body": "The @iojs/website team has accepted ownership of [iojs/doc-tool](https://github.com/iojs/doc-tool). As I understand it, they're currently figuring out whether to run with the existing tool, or adopt an existing tool.\n\nOn our end, to enable them to move forward we need to:\n- Vendor the doctool.\n- Add a script to update the vendored version of doctool.\n- Modify the makefile expectations such that the doctool is handed the directory full of docs files and the output directory, instead of each file individually.\n\nThe docs themselves will still live in this repo, but the tooling for building them will live in a separate repo.\n",
        "labels": "doc",
        "id": 44862
    },
    {
        "title": "Highlight the minimum required RAM to build iojs from source",
        "body": "I had an issue with building from source on my virtual machine because I had only dedicated it 512mb of RAM, but when I bumped the virtual machines RAM up to 2gb, it built fine. Maybe there should be a dedicated document with instructions for building, with detailed documentation on each of the ./configure commands? Simply so people can read it before ever touching ./configure, or make doc.\n",
        "labels": "doc",
        "id": 44863
    },
    {
        "title": "Dash docsets",
        "body": "",
        "labels": "doc",
        "id": 44864
    },
    {
        "title": "An owner for the docs",
        "body": "Nobody really \"owns\" the docs.\n\nWhen I review a docs PR (and there are plenty) I check only for factual correctness. Nobody really looks for consistency in writing style, presentation, order etc.\n\nIt'd be great if we could find someone to fill this role.\n\n@mikeal @iojs/tc \n",
        "labels": "doc",
        "id": 44865
    },
    {
        "title": "Fix the broken collaborator merge process for docs/readme",
        "body": "Node has a large amount of simple changes that take forever to get merged, if at all.  The same thing is starting to occur in iojs land, with simple PRs piling up.  A large reason for this is the upfront time suck that is the collaborator merge process (https://github.com/iojs/io.js/blob/v1.x/COLLABORATOR_GUIDE.md#technical-howto). \n\nSolution: Allow core contributors to click the green button for doc/readme changes that have a clean commit message.  Use the PR itself to track the review.  \n\nI would really like to see core contributors be able to merge _any_ pull request that has been rebased and has a clean commit message.\n\nThe upfront time cost of the current merging process far outweighs any time savings you will see when you are tracking down an issue.  Mainly because the former occurs 100% of the time and the latter rarely occurs. \n",
        "labels": "doc",
        "id": 44866
    },
    {
        "title": "Documentation and how to install io.js",
        "body": "I would like to test how well the io.js goes along with the Visual Editor of the MediaWiki environment, but I am simply get getting the documentation or whatever this README.md is supposed to be. \n\nHow do I install io.js and activate it? Linux would be the working environment. \n",
        "labels": "doc",
        "id": 44867
    },
    {
        "title": "JSON API specification",
        "body": "I already mentioned this idea in the `node-forward` repository two months ago [1] but since `IO.js` has been announced, I thought that I would rephrase it and repost it here.\n\nCurrently the `Node.js` (and `IO.js` too if I'm not mistaken) specifications are generated using the local NPM package [`node-doc-generator`](https://github.com/iojs/io.js/blob/v1.x/tools/doc/package.json) developed by @isaacs almost three years ago.\n\nThis module generates HTML by parsing the markdown language using some simple rules.\n\nIn my opinion, the process should be the other way around. The API reference should be specified in some kind of pre-agreed upon JSON structure that would also be exposed to the `IO.js` API. Doing this would have the following advantages:\n- 1) If you have a JSON data source (the specification), you can easily render the HTML using a templating engine like any other website.\n- 2) Designers would already be used to this kind of site \"architecture\" which makes it much easier for them to contribute.\n- 3) Internationalisation could be easily integrated by using already proved solutions like `i18n` templating engine helpers (e.g: [`handlebars-helper-i18n`](https://github.com/helpers/handlebars-helper-i18n) in the case of [`handlebars.js`](https://github.com/wycats/handlebars.js)\n- 4) It gives you the possibility of separating the `ÃŒO.js` site into another Git module that would make use of this JSON specification\n\nThis would only be a first step. Here a two examples of tools that I'd like to develop as a follow-up and that would be possible thanks to the JSON specification mentioned above:\n- fuzz testing and dynamic test generation to test the native API's parameter validation as well as error returning / throwing\n- debug module that intercepts native API calls and throws verbose, explicit errors in case of invalid input data\n\nI also imagine that generating `TypeScript`/`Flow`/`ATScript` definition files for the native `IO.js` API would be more automatic and version controlled.\n\nAnyway, I think that a JSON specification could have a lot of use cases both in the core API as well as a data source for package developers. \nI also believe that a stricter specification would limit the number of GitHub issues opened due to strange behaviours encountered in cases where parameters were not validated correctly.\n(For some examples you can click on my original post. [1])\n\nAs I said in the previous thread, since it's not a C/C++ feature, I'd be willing to contribute actively.\n\nSince this subject was in part talked about in the last [`IO.js` TC meeting](https://www.youtube.com/watch?v=_U9ftC-Yy98), I thought that this issue could get the `tc-agenda` GitHub label so that this issue could move forward quicker.\nI will by the way attend the next `IO.js` TC meeting on the 21/01/2015.\n\nAlso, if we ever need help on the design side of the site, I can ask my company's designer.\n\n[1] Link to the original `node-forward` thread: https://github.com/node-forward/discussions/issues/15\n",
        "labels": "doc",
        "id": 44868
    },
    {
        "title": "Security Policies",
        "body": "We should have well documented policies around vulnerability disclosure, reporting and security advisory notices.\n\nI bet @evilpacket has things to say :)\n",
        "labels": "doc",
        "id": 44869
    },
    {
        "title": "Order docs alphabetically",
        "body": "Would it be possible to have the docs Markdown files ordered alphabetically to make it easier to use as a reference?\n\nI am happy to do work towards this but I am not familiar enough with the documentation process to know if there would be any side-effects, such as with the JSON output.\n",
        "labels": "doc",
        "id": 44870
    },
    {
        "title": "Rename ChildProcess `exec` and `fork` to something which is not entirely confusing to system developers",
        "body": "The ChildProcess module's `exec` and `fork` methods sound a bit similar to the system calls of that name, but behave entirely differently. I've been bit by this a few times already.\n\nTo reduce confusion and make it easier to understand what is going on, these should be renamed to something like similarly functional methods in other environements (for example `exec` I believe is very similar to `system`, OTOH I'm not sure what I would do with `fork`).\n\nAlso, it would be great if IO.js will add implementation for `fork` and `exec` system calls so that developers can take advantage of these powerfull primitives to create their own multi-process mechanisms.\n",
        "labels": "doc",
        "id": 44871
    },
    {
        "title": "The README is oriented towards Node",
        "body": "Although it is a reasonably small file, the project's readme is the central core of all the project's documentation, but it still uses documentation from Node.js. Some examples:\n\n![image 1](http://i.imgur.com/9XBxLAJ.png)\n![image 2](http://i.imgur.com/9MSqnzb.png)\n\nI'd suggest that a change is made to the readme so that it has more of a belonging to iojs, even if 'proper' documentation hasn't been written yet.\n",
        "labels": "doc",
        "id": 44872
    },
    {
        "title": "https module sometimes emits 'empty' Error",
        "body": "* **Version**: v14.16.0\r\n* **Platform**: Darwin Kernel Version 20.3.0 (macOS 11.2.3)\r\n* **Subsystem**: https\r\n\r\n### What steps will reproduce the bug?\r\n\r\nEvery few times this is run, the request emits an error with `name == 'Error'`, `message == ''`, and `stack = 'Error'`. There is nothing attached to the error object that reveals what the underlying error is.\r\n\r\n```javascript\r\nconst url = \"https://deeplearning.podomatic.com/rss2.xml\"\r\nconst http = require('https')\r\n\r\nhttp.get(url, function(res) {\r\n  res.on(\"error\", err => {\r\n    console.log(\"response error\")\r\n  }).on(\"end\", () => {\r\n    console.log(\"response end\")\r\n  }).on(\"close\", () => {\r\n    console.log(\"response close\")\r\n  }).on(\"pause\", () => {\r\n    console.log(\"response pause\")\r\n  }).on(\"resume\", () => {\r\n    console.log(\"response resume\")\r\n  }).on(\"data\", chunk => {\r\n    console.log(\"response data\")\r\n  })\r\n}).on(\"error\", err => {\r\n  console.log(`request error:\\n  Message:${err.message}\\n  Name: ${err.name}\\n  Stack: ${err.stack}\\n`)\r\n}).on(\"end\", () => {\r\n  console.log(\"request end\")\r\n}).on(\"close\", () => {\r\n  console.log(\"request close\")\r\n}).on(\"finish\", () => {\r\n  console.log(\"request finish\")\r\n}).on(\"abort\", () => {\r\n  console.log(\"request abort\")\r\n}).on(\"connect\", () => {\r\n  console.log(\"request connect\")\r\n}).on(\"continue\", () => {\r\n  console.log(\"request continue\")\r\n}).on(\"drain\", () => {\r\n  console.log(\"request drain\")\r\n}).on(\"information\", () => {\r\n  console.log(\"request information\")\r\n}).on(\"pipe\", () => {\r\n  console.log(\"request pipe\")\r\n}).on(\"response\", () => {\r\n  console.log(\"request response\")\r\n}).on(\"socket\", () => {\r\n  console.log(\"request socket\")\r\n}).on(\"timeout\", () => {\r\n  console.log(\"request timeout\")\r\n}).on(\"unpipe\", () => {\r\n  console.log(\"request unpipe\")\r\n}).on(\"upgrade\", () => {\r\n  console.log(\"request upgrade\")\r\n})\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nFrequently, but probably less than 50% of the time.\r\n\r\n### What is the expected behavior?\r\n\r\nIf an error is emitted, it should contain information about the underlying error.\r\n\r\n### What do you see instead?\r\n\r\nIf an error is emitted, it has no information about the underlying error.\r\n\r\n### Additional information\r\n\r\n* The response code is always 200.\r\n* ~~The file this URL points to is always fully downloaded after a single `data` event is emitted.~~  This bit was just a coincidence, the error, if it is emitted, is always emitted after the last `data` event.\r\n* This happens in node 12.18.x as well\r\n* This happens on repl.it as well, so it isn't just my machine.\r\n* The request error is emitted after the response emits `end` but before the request emits `close`\r\n* Downloading this file with curl does not fail\r\n* `podomatic.com` is the only domain I've noticed this with so far.\r\n\r\nWhen no error is emitted, the output of the repro script looks like:\r\n\r\n```\r\nrequest socket\r\nrequest finish\r\nrequest response\r\nresponse resume\r\nresponse data\r\nresponse end\r\nrequest close\r\nresponse close\r\n```\r\n\r\nWhen it does emit an error, the output of the repro script looks like:\r\n\r\n```\r\nrequest socket\r\nrequest finish\r\nrequest response\r\nresponse resume\r\nresponse data\r\nresponse end\r\nrequest error:\r\n  Message:\r\n  Name: Error\r\n  Stack: Error\r\n\r\nrequest close\r\nresponse close\r\n```\r\n\r\nI suspect there is a configuration issue with the affected domain, but the error message node emits should indicate what the underlying problem is.\r\n",
        "labels": "confirmed-bug",
        "id": 44873
    },
    {
        "title": "URL: Forbid | (pipe) in URL host",
        "body": "Refs: https://github.com/whatwg/url/pull/589\r\n\r\nThis should not be allowed per recent spec change: `new URL('http://exa|mple.org')`;",
        "labels": "confirmed-bug",
        "id": 44874
    },
    {
        "title": "Http2 throws non-descriptive error \"Error [ERR_HTTP2_ERROR]: The user callback function failed\"",
        "body": "* **Version**: 14.16.0, 15.12.0\r\n* **Platform**: 18.7.0 Darwin Kernel Version 18.7.0: Mon Aug 31 20:53:32 PDT 2020; root:xnu-4903.278.44~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: http2\r\n\r\n### What steps will reproduce the bug?\r\n```\r\nasync function main() {\r\n  const client = http2.connect('https://www.postgresql.org');\r\n  const stream = client.request({\r\n    ':method': 'GET',\r\n    ':path': '/',\r\n    'accept-encoding': 'gzip, deflate, br',\r\n  });\r\n\r\n  const buffer: Buffer[] = [];\r\n  for await (const data of stream) {\r\n    buffer.push(data);\r\n  }\r\n  const response = Buffer.concat(buffer).toString();\r\n  console.log(response);\r\n}\r\n\r\nmain().catch(err => console.log('Http2 User Error', err));\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nIt will happen every time. When looking deeper into http2 frames, it appears the use of the Varnish? gzip module on the end site is causing an EOF frame to be incorrectly sent. nghttp2 treats any http2 violation as fatal, and so does nodejs.\r\n\r\n### What is the expected behavior?\r\nIdeally, there would be a way to allow the code to continue since this is really just an invalid EOF code. Chrome's handling of http2 seems to handle this fine. They're obviously more interested in a lenient solution to http2 errors than nodejs.\r\n\r\nIf there's not a way to provide a lenient mode, or to decide what to do in the case of frame errors, I would have expected this to throw a more descriptive error that says something about the end site having an invalid http2 implementation.\r\n\r\n### What do you see instead?\r\nThe following are a snippet of running the example with NODE_DEBUG=http2*,stream* NODE_DEBUG_NATIVE=http2\r\n```\r\nSTREAM 3518: need readable true\r\nSTREAM 3518: length less than watermark true\r\nSTREAM 3518: do read\r\nHttpStream 1 (23) [Http2Session client (19)] reading starting\r\nSTREAM 3518: read undefined\r\nSTREAM 3518: need readable true\r\nSTREAM 3518: length less than watermark true\r\nSTREAM 3518: reading or ended false\r\nSTREAM 3518: read undefined\r\nSTREAM 3518: need readable true\r\nSTREAM 3518: length less than watermark true\r\nSTREAM 3518: reading or ended false\r\nHttp2Session client (19) complete frame received: type: 0\r\nHttp2Session client (19) handling data frame for stream 1\r\nHttp2Session client (19) complete frame received: type: 0\r\nHttp2Session client (19) handling data frame for stream 1\r\nHttp2Session client (19) fatal error receiving data: -902\r\nHTTP2 3518: Http2Session client: destroying\r\nHTTP2 3518: Http2Session client: start closing/destroying Error [ERR_HTTP2_ERROR]: The user callback function failed\r\n    at Http2Session.onSessionInternalError (internal/http2/core.js:751:26) {\r\n  code: 'ERR_HTTP2_ERROR',\r\n  errno: -902\r\n}\r\nHTTP2 3518: Http2Stream 1 [Http2Session client]: destroying stream\r\n```\r\n\r\n### Additional information\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 44875
    },
    {
        "title": "\"crypto.createDiffieHellman\" results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.15.1\r\n* **Platform**:  Linux 5.8.0-38-generic #43~20.04.1-Ubuntu SMP Tue Jan 12 16:39:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto.createDiffieHellman\r\n\r\n### What steps will reproduce the bug?\r\nSetup a node instance,\r\n```\r\nÂ» node\r\n```\r\nand run the following javascript code.\r\n```\r\ncrypto.createDiffieHellman('',true);\r\n```\r\nThen an abort occurs.\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nThis abort can always be triggered following the steps above.\r\n\r\n### What is the expected behavior?\r\nIf any error occurs, an exception or other similar error-reporting stuff should be thrown. There is no reason to abort the whole node process.\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n```\r\nÂ» node\r\ncrypto.createDiffieHellman('',true);\r\nnode[79037]: ../src/util-inl.h:490:node::ArrayBufferViewContents<T, kStackStorageSize>::ArrayBufferViewContents(v8::Local<v8::Value>) [with T = char; long unsigned int kStackStorageSize = 64]: Assertion `value->IsArrayBufferView()' failed.\r\n 1: 0xa03530 node::Abort() [node]\r\n 2: 0xa035ae  [node]\r\n 3: 0xb396fa node::ArrayBufferViewContents<char, 64ul>::ArrayBufferViewContents(v8::Local<v8::Value>) [node]\r\n 4: 0xb30625 node::crypto::DiffieHellman::New(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 5: 0xbe4695  [node]\r\n 6: 0xbe4c9f  [node]\r\n 7: 0xbe52c6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 8: 0x13ff259  [node]\r\n[1]    79037 abort (core dumped)  node\r\n                                                                                                                                                                                                                                                 \r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44876
    },
    {
        "title": "\"clearImmediate\" results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.15.1\r\n* **Platform**: Linux 5.8.0-38-generic #43~20.04.1-Ubuntu SMP Tue Jan 12 16:39:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: clearImmediate\r\n\r\n### What steps will reproduce the bug?\r\nSetup a node instance,\r\n```\r\nÂ» node\r\n```\r\nand run the following javascript code.\r\n```\r\nclearImmediate({hasRef: true, _onImmediate: 100000000000000000})\r\n```\r\nThen an abort occurs.\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nThis abort can always be triggered following the steps above.\r\n\r\n### What is the expected behavior?\r\nIf any error occurs, an exception or other similar error-reporting stuff should be thrown. There is no reason to abort the whole node process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n```\r\nÂ» node\r\nWelcome to Node.js v14.15.1.\r\nType \".help\" for more information.\r\n> clearImmediate({hasRef: true, _onImmediate: 100000000000000000})\r\nnode[65197]: ../src/async_wrap.cc:623:static void node::AsyncWrap::QueueDestroyAsyncId(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `args[0]->IsNumber()' failed.\r\n 1: 0xa03530 node::Abort() [node]\r\n 2: 0xa035ae  [node]\r\n 3: 0x979ceb node::AsyncWrap::QueueDestroyAsyncId(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 4: 0xbe369b  [node]\r\n 5: 0xbe4c46  [node]\r\n 6: 0xbe52c6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 7: 0x13ff259  [node]\r\n[1]    65197 abort (core dumped)  node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44877
    },
    {
        "title": "\"tty.isatty\" results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.15.1\r\n* **Platform**:  Linux 5.8.0-38-generic #43~20.04.1-Ubuntu SMP Tue Jan 12 16:39:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: tty.isatty\r\n\r\n### What steps will reproduce the bug?\r\nSetup a node instance,\r\n```\r\nÂ» node\r\n```\r\nand run the following javascript code.\r\n```\r\ntty = require('tty');tty.isatty(1000000000000000000);\r\n```\r\nThen an abort occurs.\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nThis abort can always be triggered following the steps above.\r\n\r\n### What is the expected behavior?\r\nIf any error occurs, an exception or other similar error-reporting stuff should be thrown. There is no reason to abort the whole node process.\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n```\r\nÂ» node                                                                                                                                                                                                                                                 134 â†µ zys@zys-X299-UD4-Pro\r\nWelcome to Node.js v14.15.1.\r\nType \".help\" for more information.\r\n> tty = require('tty');tty.isatty(1000000000000000000);\r\nnode[57893]: ../src/tty_wrap.cc:73:static void node::TTYWrap::IsTTY(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `(fd) >= (0)' failed.\r\n 1: 0xa03530 node::Abort() [node]\r\n 2: 0xa035ae  [node]\r\n 3: 0xaea222  [node]\r\n 4: 0xbe369b  [node]\r\n 5: 0xbe4c46  [node]\r\n 6: 0xbe52c6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 7: 0x13ff259  [node]\r\n[1]    57893 abort (core dumped)  node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44878
    },
    {
        "title": "crypto: verify with callback crashes when private key is used",
        "body": "Introduced in #37500 (released with v15.12.0) the function call crashes node when a private key object is passed to verify when using the callback argument.\r\n\r\n```js\r\nconst crypto = require('crypto');\r\nconst assert = require('assert');\r\n\r\nconst data = Buffer.from('hello');\r\nconst { privateKey } = crypto.generateKeyPairSync('ed25519');\r\nconst signature = crypto.sign(null, data, privateKey);\r\n\r\nassert(crypto.verify(null, data, privateKey, signature)); // OK\r\n\r\ncrypto.verify(null, data, privateKey, signature, (err, verified) => { // ðŸ’¥\r\n  assert(!err);\r\n  assert(verified);\r\n});\r\n```\r\n\r\n```\r\nnode[49326]: ../src/crypto/crypto_sig.cc:850:static bool node::crypto::SignTraits::DeriveBits(node::Environment *, const node::crypto::SignConfiguration &, node::crypto::ByteSource *): Assertion `(params.key->GetKeyType()) == (kKeyTypePublic)' failed.\r\n```\r\n\r\nThis can never happen in webcrypto where this implementation was first used but it is a valid input for one shot verify.\r\n\r\nI'm looking into a fix and expanding the test suite.\r\n\r\ncc @jasnell ",
        "labels": "confirmed-bug",
        "id": 44879
    },
    {
        "title": "child_process 'spawn' event is emitted too soon",
        "body": "**Version**: `15.1.0` thru `15.11.0` (see screenshot below)\n**Platform**: `Darwin CALLMT20389 19.6.0 Darwin Kernel Version 19.6.0: Thu Oct 29 22:56:45 PDT 2020; root:xnu-6153.141.2.2~1/RELEASE_X86_64 x86_64`\n\n### What steps will reproduce the bug?\n\nRun the following simple repro example:\n\n```console\n$> node ./parent.mjs\n```\n\n<details>\n<summary>parent.mjs</summary>\n\n```js\nimport { fork } from 'child_process';\n\n\nconst subprocess = fork('./child.mjs');\n\nsubprocess.on('close', (...args) => { console.error('[PARENT] received', ...args) });\nsubprocess.on('disconnect', (...args) => { console.error('[PARENT] received', ...args) });\nsubprocess.on('error', (...args) => { console.error('[PARENT] received', ...args) });\nsubprocess.on('exit', (...args) => { console.error('[PARENT] received', ...args) });\nsubprocess.on('message', (...args) => { console.log('[PARENT] received', ...args) });\nsubprocess.on('spawn', () => {\n  console.log({\n    'parent::subprocess.send': subprocess.send({ hello: 'child' })\n  });\n});\n```\n</details>\n\n<details>\n<summary>child.mjs</summary>\n\n```js\nprocess.on('message', (...args) => { console.log('[CHILD] received', ...args) });\n\nprocess.send({ hello: 'parent' });\n```\n</details>\n\n### How often does it reproduce? Is there a required condition?\n\n100% of the time (dozens of executions)\n\n### What is the expected behavior?\n\nchild's process.on('message') should be triggered (parent's message should be received and logged to console).\n\n### What do you see instead?\n\nOnly parent's subprocess.on('message') is triggered:\n\n```console\n$> node ./parent.mjs\n{ 'parent::subprocess.send': true }\n[PARENT] received { hello: 'parent' }\n```\n\n![image](https://user-images.githubusercontent.com/3012099/111513980-b0865500-8727-11eb-8d07-617170365ded.jpeg)\n\n### Additional info\n\nI installed node via nvm. I verified the version of node actually running is truly 15.11.0 by console logging `process.version` in both parent.mjs and child.mjs (both output `v15.11.0`)",
        "labels": "confirmed-bug",
        "id": 44880
    },
    {
        "title": "Nodejs runs out of memory trying to connect to HTTPS host with self-signed certificate",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: 15.11.0 (also tested with 12 and 14 on same machine)\r\nPlatform: Ubuntu 16.04 (Linux 4.4.0-1127.8.2.vz7.151.14 #1 SMP Tue Jun 9 12:58:54 MSK 2020 x86_64 x86_64 x86_64 GNU/Linux)\r\nSubsystem: https\r\n-->\r\n\r\n* **Version**: 15.11.0 (also tested with 12 and 14 on same machine)\r\n* **Platform**: Ubuntu 16.04 (Linux 4.4.0-1127.8.2.vz7.151.14 #1 SMP Tue Jun 9 12:58:54 MSK 2020 x86_64 x86_64 x86_64 GNU/Linux)\r\n* **Subsystem**: https\r\n\r\n### What steps will reproduce the bug?\r\n\r\nWhen trying to connect to a https-enabled host and using a self-signed certificate provided to node via `NODE_EXTRA_CA_CERTS` node hangs for a few minutes, using more and more memory, until it exits with `Allocation failed - JavaScript heap out of memory`. Full stacktrace below.\r\n\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThe server needs to be up and the correct server certificate needs to be used.\r\n\r\n### What is the expected behavior?\r\n\r\nI would expect the connection to  be made successfully, since the self-signed certificate has been provided to node.\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n```\r\n<--- Last few GCs --->\r\n\r\n[15068:0x52f3bd0]   324861 ms: Scavenge (reduce) 4053.6 (4128.3) -> 4053.4 (4129.3) MB, 72.6 / 0.0 ms  (average mu = 0.851, current mu = 0.769) allocation failure\r\n[15068:0x52f3bd0]   325180 ms: Scavenge (reduce) 4054.9 (4129.3) -> 4054.8 (4131.1) MB, 86.6 / 0.0 ms  (average mu = 0.851, current mu = 0.769) allocation failure\r\n[15068:0x52f3bd0]   325442 ms: Scavenge (reduce) 4056.6 (4131.1) -> 4056.4 (4132.6) MB, 71.5 / 0.0 ms  (average mu = 0.851, current mu = 0.769) allocation failure\r\n\r\n\r\n<--- JS stacktrace --->\r\n\r\nFATAL ERROR: MarkCompactCollector: young object promotion failed Allocation failed - JavaScript heap out of memory\r\n 1: 0xa7f490 node::Abort() [node]\r\n 2: 0x9a5c4d node::FatalError(char const*, char const*) [node]\r\n 3: 0xc6c2ae v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [node]\r\n 4: 0xc6c627 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [node]\r\n 5: 0xe360a5  [node]\r\n 6: 0xe65633 v8::internal::EvacuateNewSpaceVisitor::Visit(v8::internal::HeapObject, int) [node]\r\n 7: 0xe721e6 v8::internal::FullEvacuator::RawEvacuatePage(v8::internal::MemoryChunk*, long*) [node]\r\n 8: 0xe5e30f v8::internal::Evacuator::EvacuatePage(v8::internal::MemoryChunk*) [node]\r\n 9: 0xe5e588 v8::internal::PageEvacuationTask::RunInParallel(v8::internal::ItemParallelJob::Task::Runner) [node]\r\n10: 0xe503a9 v8::internal::ItemParallelJob::Run() [node]\r\n11: 0xe74170 void v8::internal::MarkCompactCollectorBase::CreateAndExecuteEvacuationTasks<v8::internal::FullEvacuator, v8::internal::MarkCompactCollector>(v8::internal::MarkCompactCollector*, v8::internal::ItemParallelJob*, v8::internal::MigrationObserver*, long) [node]\r\n12: 0xe749b3 v8::internal::MarkCompactCollector::EvacuatePagesInParallel() [node]\r\n13: 0xe74d75 v8::internal::MarkCompactCollector::Evacuate() [node]\r\n14: 0xe874e1 v8::internal::MarkCompactCollector::CollectGarbage() [node]\r\n15: 0xe433a8 v8::internal::Heap::MarkCompact() [node]\r\n16: 0xe44d38 v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [node]\r\n17: 0xe482dc v8::internal::Heap::AllocateRawWithRetryOrFailSlowPath(int, v8::internal::AllocationType, v8::internal::AllocationOrigin, v8::internal::AllocationAlignment) [node]\r\n18: 0xe0bf3a v8::internal::Factory::AllocateRaw(int, v8::internal::AllocationType, v8::internal::AllocationAlignment) [node]\r\n19: 0xe05444 v8::internal::FactoryBase<v8::internal::Factory>::AllocateRawWithImmortalMap(int, v8::internal::AllocationType, v8::internal::Map, v8::internal::AllocationAlignment) [node]\r\n20: 0xe07540 v8::internal::FactoryBase<v8::internal::Factory>::NewRawOneByteString(int, v8::internal::AllocationType) [node]\r\n21: 0xe1955e v8::internal::Factory::NewStringFromOneByte(v8::internal::Vector<unsigned char const> const&, v8::internal::AllocationType) [node]\r\n22: 0xc839e2 v8::String::NewFromOneByte(v8::Isolate*, unsigned char const*, v8::NewStringType, int) [node]\r\n23: 0xbb5914 node::crypto::GetFingerprintDigest(node::Environment*, evp_md_st const*, x509_st*) [node]\r\n24: 0xbb736e node::crypto::X509ToObject(node::Environment*, x509_st*) [node]\r\n25: 0xbb81e4 node::crypto::GetPeerCert(node::Environment*, std::unique_ptr<ssl_st, node::FunctionDeleter<ssl_st, &SSL_free> > const&, bool, bool) [node]\r\n26: 0xc2b567 node::crypto::TLSWrap::GetPeerCertificate(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n27: 0xcd8cbb  [node]\r\n28: 0xcda26c  [node]\r\n29: 0xcda8e6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n30: 0x14fa219  [node]\r\n./run.sh: line 5: 15068 Aborted                 node index.js\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nAll files iÂ´ve used to reproduce: [node_https_test.zip](https://github.com/nodejs/node/files/6140472/node_https_test.zip)\r\nhttps_renew_cert.sh is a script used to generate the key/certificate pair. (Sample certificate and key is also included in the zip, so you donÂ´t have to regenerate them, if you donÂ´t have oppenssl installed)\r\nserver.js is the server. Execute with node server.js.\r\nindex.js is the client. Started from run.sh\r\nrun.sh: Starts the client and sets `NODE_EXTRA_CA_CERTS`. (You need to update the path to the certificate)\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44881
    },
    {
        "title": "deepStrictEqual not commutative by not accounting for non-enumerable properties",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:\r\n  * 14.x (but probably also others)\r\n* **Platform**:\r\n  * all\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst { deepStrictEqual } = require(\"assert\");\r\n\r\nconst a = {};\r\nconst b = {};\r\n\r\na.x = 1;\r\n\r\nObject.defineProperties(b, {\r\n  x: {\r\n    value: 1,\r\n    writable: true,\r\n  },\r\n  y: {\r\n    value: 5,\r\n    writable: true,\r\n    enumerable: true,\r\n    configurable: true,\r\n  },\r\n});\r\n\r\nconsole.log({ a, b });\r\ndeepStrictEqual(a, b); // does not assert\r\ndeepStrictEqual(b, a); // does assert\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways\r\n\r\n### What is the expected behavior?\r\nI expect deepStrictEqual to be at least commutative. (Whether it should handle non-enumerable properties may be up for discussion)\r\n\r\n### What do you see instead?\r\n`deepStrictEqual(b, a)` does throw an assertion while `deepStrictEqual(a, b)` does not.\r\n\r\n\r\n### Additional information\r\nIf you point me in the right direction I'm willing to fix it myself.",
        "labels": "confirmed-bug",
        "id": 44882
    },
    {
        "title": "HTTP Response read past end",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.8.*\r\n* **Platform**: All\r\n* **Subsystem**: http\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```mjs\r\nimport net from 'net';\r\nimport http from 'http';\r\n\r\n// create a simple server with too small of content-length\r\nconst body = 'HTTP/1.1 200 OK\\r\\n' +\r\n  'Content-Length: 5\\r\\n' +\r\n  'Connection: close\\r\\n' +\r\n  '\\r\\n' +\r\n  '2ad731e3-4dcd-4f70-b871-0ad284b29ffc'\r\nconst server = net.createServer((conn) => conn.end(body));\r\nconst port = 9191;\r\nserver.listen(port, () => {\r\n  // try to GET from the server\r\n  http.get('http://localhost:' + port);\r\n});\r\n\r\n// causes Error: Parse Error: Expected HTTP/\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\nNo error, doesn't read past content-length and/or doesn't try to parse a second response from a `connection: close` response. Unclear on expected HTTP semantics and common leniency here. Likely shouldn't do either I suspect.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n```console\r\n$ node bug.js\r\nnode:events:355\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: Parse Error: Expected HTTP/\r\n    at Socket.socketOnData (node:_http_client:502:22)\r\n    at Socket.emit (node:events:378:20)\r\n    at addChunk (node:internal/streams/readable:313:12)\r\n    at readableAddChunk (node:internal/streams/readable:288:9)\r\n    at Socket.Readable.push (node:internal/streams/readable:227:10)\r\n    at TCP.onStreamRead (node:internal/stream_base_commons:190:23)\r\nEmitted 'error' event on ClientRequest instance at:\r\n    at Socket.socketOnData (node:_http_client:509:9)\r\n    at Socket.emit (node:events:378:20)\r\n    [... lines matching original stack trace ...]\r\n    at TCP.onStreamRead (node:internal/stream_base_commons:190:23) {\r\n  bytesParsed: 62,\r\n  code: 'HPE_INVALID_CONSTANT',\r\n  reason: 'Expected HTTP/',\r\n  rawPacket: Buffer(93) [Uint8Array] [\r\n     72,  84,  84,  80,  47,  49,  46,  49,  32,  50,  48,  48,\r\n     32,  79,  75,  13,  10,  67, 111, 110, 116, 101, 110, 116,\r\n     45,  76, 101, 110, 103, 116, 104,  58,  32,  53,  13,  10,\r\n     67, 111, 110, 110, 101,  99, 116, 105, 111, 110,  58,  32,\r\n     99, 108, 111, 115, 101,  13,  10,  13,  10,  50,  97, 100,\r\n     55,  51,  49, 101,  51,  45,  52, 100,  99, 100,  45,  52,\r\n    102,  55,  48,  45,  98,  56,  55,  49,  45,  48,  97, 100,\r\n     50,  56,  52,  98,  50,  57, 102, 102,  99\r\n  ]\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44883
    },
    {
        "title": "Crash when mode is to big in fs.createWriteStream",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v` \r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: `v14.15.4`, `v15.9.0`\r\n* **Platform**:  Ubuntu, Mac OS\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\nNode.js crashes on such code:\r\n```js\r\nconst {createWriteStream} = require('fs');\r\n\r\ncreateWriteStream('./1.txt', {\r\n    mode: 2176057344,\r\n});\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\nExpected to throw, like it happen when mode is `111111111111111`:\r\n\r\n```js\r\nnode:internal/validators:102\r\n      throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value);\r\n      ^\r\n\r\nRangeError [ERR_OUT_OF_RANGE]: The value of \"mode\" is out of range. It must be >= 0 && <= 4294967295. Received 111_111_111_111_111\r\n    at parseFileMode (node:internal/validators:68:5)\r\n    at Object.open (node:fs:473:12)\r\n    at WriteStream._construct (node:internal/fs/streams:64:17)\r\n    at constructNT (node:internal/streams/destroy:288:25)\r\n    at processTicksAndRejections (node:internal/process/task_queues:80:21) {\r\n  code: 'ERR_OUT_OF_RANGE'\r\n}\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nI see a crash:\r\n\r\n```\r\nnode[70201]: ../src/node_file.cc:1715:void node::fs::Open(const FunctionCallbackInfo<v8::Value> &): Assertion `args[2]->IsInt32()' failed.\r\n 1: 0x1012e4da5 node::Abort() (.cold.1) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 2: 0x1000a6239 node::Abort() [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 3: 0x1000a60a1 node::Assert(node::AssertionInfo const&) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 4: 0x1000ae8d2 node::fs::Open(v8::FunctionCallbackInfo<v8::Value> const&) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 5: 0x10025a4e8 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 6: 0x100259a7c v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 7: 0x1002591a2 v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 8: 0x100a7a359 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\nAbort trap: 6\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44884
    },
    {
        "title": "ModuleWrap::SyntheticModuleEvaluationStepsCallback should return a Promise",
        "body": "Top-level await expects that all module script evaluation returns a Promise.  As such, [ModuleWrap::SyntheticModuleEvaluationStepsCallback](https://github.com/nodejs/node/blob/51249a11c09c7ec23eda17327f650fa59a72cba5/src/module_wrap.cc#L644) should be updated to return a resolved Promise now that V8 has enabled top-level await by default.\r\n\r\nUnfortunately I don't have a spec reference that I can point to here because the Stage 1 [Built-in modules proposal](https://github.com/tc39/proposal-built-in-modules) isn't yet updated for top-level await.\r\n\r\nFor reference, the corresponding change for Blink is https://chromium-review.googlesource.com/c/chromium/src/+/2568823.\r\n\r\nI discovered this issue when working on this V8 bugfix: https://chromium-review.googlesource.com/c/v8/v8/+/2673794. My first attempt at a fix failed the Node integration tests because it assumed that the Synthetic Module callback steps return a Promise.  For now, I'm adding a workaround for this in V8 but if Node can make this update then we'd like to eventually remove that workaround.\r\n",
        "labels": "confirmed-bug",
        "id": 44885
    },
    {
        "title": "Crash on node api add-on finalization",
        "body": "* **Version**: v10.23.2, v12.20.1, v14.15.4, v15.8.0 (all latest lts and current version)\r\n* **Platform**: all\r\n* **Subsystem**: node-api\r\n\r\n### What steps will reproduce the bug?\r\n\r\nRepo to re-produce: https://github.com/legendecas/repro-napi-v8impl-refbase-double-free\r\n\r\n```\r\n$ make\r\nv14.15.4\r\nforce gc\r\nfish: 'node --expose_gc index.js' terminated by signal SIGSEGV (Address boundary error)\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n\r\nNo segment faults.\r\n\r\n### What do you see instead?\r\n\r\nSegment faults on double free of `v8impl::<anonymous>::RefBase`. The `RefBase`s were deleted once one module's napi_env was going to destroy, and the installed weak `v8impl::Persistent`s of `v8impl::<anonymous>Reference` was not destroyed and these `RefBase` will be deleted again on finalization callbacks.\r\n",
        "labels": "confirmed-bug",
        "id": 44886
    },
    {
        "title": "fs: error when fd = -0",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v15.2.0\r\n* **Platform**: Ubuntu-18.04\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```console\r\nâ¯ node -p 'fs.fstatSync(-0)'\r\nnode[10415]: ../src/node_file.cc:1077:void node::fs::FStat(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `args[0]->IsInt32()' failed.\r\n 1: 0xb0c720 node::Abort() [node]\r\n 2: 0xb0c7a1  [node]\r\n 3: 0xb1944f  [node]\r\n 4: 0xdb938c  [node]\r\n 5: 0xdbb317 v8::internal::Builtin_HandleApiCall(int, unsigned int*, v8::internal::Isolate*) [node]\r\n 6: 0x16e6017  [node]\r\n 7: 0x168b379  [node]\r\n 8: 0x1684cf2  [node]\r\n 9: 0x168b379  [node]\r\n10: 0x168949a  [node]\r\n11: 0x16892bb  [node]\r\n12: 0xece07e  [node]\r\n13: 0xecf072 v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) [node]\r\n14: 0xd40619 v8::Script::Run(v8::Local<v8::Context>) [node]\r\n15: 0xafc6d3 node::contextify::ContextifyScript::EvalMachine(node::Environment*, long long, bool, bool, bool, std::shared_ptr<v8::MicrotaskQueue>, v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n16: 0xafceb1 node::contextify::ContextifyScript::RunInThisContext(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n17: 0xdb938c  [node]\r\n18: 0xdbb317 v8::internal::Builtin_HandleApiCall(int, unsigned int*, v8::internal::Isolate*) [node]\r\n19: 0x16e6017  [node]\r\n20: 0x168b379  [node]\r\n21: 0x168b379  [node]\r\n22: 0x168b379  [node]\r\n23: 0x168b379  [node]\r\n24: 0x168b379  [node]\r\n25: 0x168b379  [node]\r\n26: 0x168949a  [node]\r\n27: 0x16892bb  [node]\r\n28: 0xece07e  [node]\r\n29: 0xecf072 v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) [node]\r\n30: 0xd504c1 v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) [node]\r\n31: 0xacbcdf node::ExecuteBootstrapper(node::Environment*, char const*, std::vector<v8::Local<v8::String>, std::allocator<v8::Local<v8::String> > >*, std::vector<v8::Local<v8::Value>, std::allocator<v8::Local<v8::Value> > >*) [node]\r\n32: 0xacc007  [node]\r\n33: 0xacd5ef node::StartExecution(node::Environment*, std::function<v8::MaybeLocal<v8::Value> (node::StartExecutionCallbackInfo const&)>) [node]\r\n34: 0xa51397 node::LoadEnvironment(node::Environment*) [node]\r\n35: 0xb5bd4e node::NodeMainInstance::Run(node::EnvSerializeInfo const*) [node]\r\n36: 0xacfec9 node::Start(int, char**) [node]\r\n37: 0xa46c39 main [node]\r\n38: 0xb7a31f21 __libc_start_main [/lib/i386-linux-gnu/libc.so.6]\r\n[1]    10415 abort (core dumped)  node -p 'fs.fstatSync(-0)'\r\n\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nNo error.",
        "labels": "confirmed-bug",
        "id": 44887
    },
    {
        "title": "specific scenario causes infinite recursion in util.inspect (max stack size exceeded)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v15.6.0\r\n* **Platform**: Microsoft Windows NT 10.0.19042.0 x64\r\n* **Subsystem**: util\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```js\r\nconst { inspect } = require(\"util\");\r\n\r\nclass A {\r\n    constructor(B) {\r\n        this.B = B;\r\n    }\r\n    get b() {\r\n        return this.B;\r\n    }\r\n}\r\n\r\nclass B {\r\n    constructor() {\r\n        this.A = new A(this);\r\n    }\r\n    get a() {\r\n        return this.A;\r\n    }\r\n}\r\n\r\nconst test = new B();\r\nconst result = inspect(test, {\r\n    depth:1,\r\n    getters:true,\r\n    showHidden:true\r\n});\r\n\r\nconsole.log(result);\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nHappens when both `getters` and `showHidden` are enabled and the class contains circular references accessible by getters\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThe `depth` option should short circuit the circular references and display no more than 2 levels of depth.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nA giant wall of text.\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nAlso tested on node v15.4.0 and NWJS running node v15.3.0 but did not test in v14.\r\n\r\nIssue discovered when attempting to inspect a `client` instance from the `discord.js` library, which makes use of such circular references.\r\n\r\nEDIT: just tested in v15.2.0 and it works correctly. It seems the issue was introduced with v15.3.0\r\n",
        "labels": "confirmed-bug",
        "id": 44888
    },
    {
        "title": "[linux-armv7l] http.request() fails with HPE_INVALID_CONSTANT error ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: tested on Node v14.15.4, v15.6.0 and v14.7.x\r\n* **Platform**: Linux 5.4.51-v7l+ armv7l GNU/Linux (it's a Raspberry Pi 4 running Debian 10)\r\n* **Subsystem**: http\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\nRun the following:\r\n\r\n```node\r\nconst http = require(`http`)\r\nconst url = `http://51.77.66.14/Trilogia%20%20John%20Wick%202014-2019%20REMUX%204K%20HDR%20Latino/John%20Wick%203%20Parabellum%202019%20REMUX%204K%20HDR%20Latino.mkv`\r\nconst byteOffset = 2595000000\r\n\r\nconst req = http.request(url, {\r\n  method: `GET`,\r\n  headers: {\r\n    'Range': `bytes=${byteOffset}-`,\r\n  }\r\n}, (res) => {\r\n  console.log(`STATUS:`, res.statusCode);\r\n  console.log(`HEADERS:`, res.headers);\r\n  // res.setEncoding('hex');\r\n  res.on('data', (chunk) => {\r\n    // needs to be registered so that the body is parsed\r\n  });\r\n})\r\n\r\nreq.on('error', (err) => {\r\n  console.error(err)\r\n});\r\nreq.end();\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nOne this platform, always.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nNo error, the response should be parsed just fine. I know the responding web server might be (at least partially) at fault, but the issue does not appear on win32 (Windows 10) or in Linux/WSL1 (openSUSE & Debian) on x64, so this probably isn't desired behavior.\r\n\r\nFor what it's worth, both `curl` and `wget` don't face this issue either.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n```node\r\nSTATUS: 206\r\nHEADERS: {\r\n  date: 'Sun, 24 Jan 2021 18:03:49 GMT',\r\n  server: 'Apache/2.4.29 (Ubuntu)',\r\n  'last-modified': 'Sun, 05 Jan 2020 20:21:31 GMT',\r\n  etag: '\"f9ac35f5c-59b6a49dd4bc5\"',\r\n  'accept-ranges': 'bytes',\r\n  'content-length': '64426004636',\r\n  'content-range': 'bytes 2595000000-67021004635/67021004636',\r\n  connection: 'close',\r\n  'content-type': 'video/x-matroska'\r\n}\r\nError: Parse Error: Expected HTTP/\r\n    at Socket.socketOnData (_http_client.js:509:22)\r\n    at Socket.emit (events.js:315:20)\r\n    at addChunk (internal/streams/readable.js:309:12)\r\n    at readableAddChunk (internal/streams/readable.js:284:9)\r\n    at Socket.Readable.push (internal/streams/readable.js:223:10)\r\n    at TCP.onStreamRead (internal/stream_base_commons.js:188:23) {\r\n  bytesParsed: 335,\r\n  code: 'HPE_INVALID_CONSTANT',\r\n  reason: 'Expected HTTP/',\r\n  rawPacket: <Buffer 9a 40 a4 1b 3b aa 46 a5 7e e7 09 dd 35 3f 9e 93 b6 bc 75 3e 04 ac dc e6 f8 cd 99 c4 7f 07 98 0c e7 f9 c3 2c e8 d2 20 ff d0 98 98 48 c0 ef 07 66 60 5d ... 1350 more bytes>\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nThe requested file is quite large, so if it doesn't throw an error after a few seconds, don't wait for it to finish. I wish I had another URL to shared, but right now I only have this one. Although I am very sure I've encountered this error several times before (but didn't look into it further).\r\n\r\nAlso, notice the `byteOffset`. The issue happens at a specific byte range, hence the offset. The offset isn't totally exact, but should narrow it down to a few megabytes...\r\n\r\nI really hope someone can figure out what's going on here. I'm building a download manager and it's very unfortunate that it doesn't work reliably on my server...",
        "labels": "confirmed-bug",
        "id": 44889
    },
    {
        "title": "Unhandled `'error'` event on aborted request",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v8.17.0, v10.23.1, v12.20.1, v14.15.4, v15.5.1\r\n* **Platform**: Darwin imac.local 20.2.0 Darwin Kernel Version 20.2.0: Wed Dec  2 20:39:59 PST 2020; root:xnu-7195.60.75~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: http\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```\r\n$ cat test.js \r\nconst http = require('http');\r\n\r\nconst req = http.get('http://[2604:1380:45f1:3f00::1]:4002');\r\n\r\nreq.on('error', console.error);\r\nreq.abort();\r\n```\r\n\r\n```\r\n$ node test.js \r\nnode:events:353\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: connect EHOSTUNREACH 2604:1380:45f1:3f00::1:4002 - Local (:::49474)\r\n    at internalConnect (node:net:910:16)\r\n    at defaultTriggerAsyncIdScope (node:internal/async_hooks:430:12)\r\n    at node:net:1001:9\r\n    at processTicksAndRejections (node:internal/process/task_queues:75:11)\r\nEmitted 'error' event on Socket instance at:\r\n    at emitErrorNT (node:internal/streams/destroy:188:8)\r\n    at emitErrorCloseNT (node:internal/streams/destroy:153:3)\r\n    at processTicksAndRejections (node:internal/process/task_queues:80:21) {\r\n  errno: -65,\r\n  code: 'EHOSTUNREACH',\r\n  syscall: 'connect',\r\n  address: '2604:1380:45f1:3f00::1',\r\n  port: 4002\r\n}\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways. No required condition.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThe error is handled by the `'error'` event listener.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThe error is not handled.\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nIf `req.abort()` is removed the error is correctly handled.\r\n",
        "labels": "confirmed-bug",
        "id": 44890
    },
    {
        "title": "--inspect crash in Node >=14.0.0 when accessing global variable in devtools",
        "body": "* **Version**: >=14.0.0\r\n* **Platform**: Linux ubuntu 5.4.0-59-generic #65~18.04.1-Ubuntu SMP Mon Dec 14 15:59:40 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n### What steps will reproduce the bug?\r\nRun below _test.js_ by using  `node --inspect=0.0.0.0:9229 test.js` and inspect the file with `chrome://inspect` in Chrome (I am using Windows 10).\r\nIn the chrome dev tools try to access the \"test\" variable by typing `test `in the devtools. The node process will crash on the first try or on your next couple calls.\r\n\r\n```js\r\n// test.js\r\nfunction registerGlobals(objects){\r\n    Object.keys(objects).forEach((key) => {\r\n        (globalThis)[key] = objects[key];\r\n    });\r\n};\r\n\r\nvar test = {\r\n    blaat: 'some value'\r\n};\r\nregisterGlobals({\r\n    test\r\n});\r\n\r\nsetInterval(() => {\r\n    console.log('hearthbeat');\r\n}, 1000);\r\n\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nIt happends consistently after the first 1-5 tries when accessing the \"test\" global variable.\r\n\r\n### What is the expected behavior?\r\nNot crash and return the results like in Node <= 13\r\n\r\n### What do you see instead?\r\n```\r\nnode --inspect=0.0.0.0:9229 test\r\nDebugger listening on ws://0.0.0.0:9229/e7de75b7-eb6f-4fee-a374-0666c9644a98\r\nFor help, see: https://nodejs.org/en/docs/inspector\r\nDebugger attached.\r\ntest\r\ntest\r\ntest\r\ntest\r\ntest\r\n\r\n\r\n#\r\n# Fatal error in , line 0\r\n# Check failed: !isolate->has_pending_exception().\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 0x7fffb56adfb0\r\n 1: 0xa96131  [node]\r\n 2: 0x19614f4 V8_Fatal(char const*, ...) [node]\r\n 3: 0xc191fa  [node]\r\n 4: 0xc1c634 v8::internal::Builtin_ConsoleLog(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 5: 0x13a6339  [node]\r\nIllegal instruction (core dumped)\r\n```\r\n\r\n### Additional information\r\nThis only started happenening since Node version 14.0.0. Before, in v13.14.0, this crash does not happen.\r\n",
        "labels": "confirmed-bug",
        "id": 44891
    },
    {
        "title": "net: blockList.addSubnet throw Assertion `args[2]->IsInt32()' failed when prefix is NaN ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.4.0\r\n* **Platform**: macOS 10.15.7\r\n* **Subsystem**: net\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```js\r\nconst net = require('net');\r\nconst blockList = new net.BlockList();\r\nblockList.addSubnet('', NaN);\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nEverytime.\r\n\r\n### What is the expected behavior?\r\nthrow `ERR_OUT_OF_RANGE ` error.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n```\r\n> blockList.addSubnet('', NaN)\r\nnode[2155]: ../src/node_sockaddr.cc:614:static void node::SocketAddressBlockListWrap::AddSubnet(const FunctionCallbackInfo<v8::Value> &): Assertion `args[2]->IsInt32()' failed.\r\n 1: 0x101379d05 node::Abort() (.cold.1) [/usr/local/bin/node]\r\n 2: 0x1000bde89 node::Abort() [/usr/local/bin/node]\r\n 3: 0x1000bdcf1 node::Assert(node::AssertionInfo const&) [/usr/local/bin/node]\r\n 4: 0x1001420e4 node::SocketAddressBlockListWrap::AddSubnet(v8::FunctionCallbackInfo<v8::Value> const&) [/usr/local/bin/node]\r\n 5: 0x1002a3728 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [/usr/local/bin/node]\r\n 6: 0x1002a2cbc v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/usr/local/bin/node]\r\n 7: 0x1002a23e7 v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/usr/local/bin/node]\r\n 8: 0x100ac42d9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/usr/local/bin/node]\r\n 9: 0x100a5d402 Builtins_InterpreterEntryTrampoline [/usr/local/bin/node]\r\n[1]    2155 abort      node\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44892
    },
    {
        "title": "The Node.js will stuck when exec `Object.defineProperty(Array.prototype, '-1', {get: function(){return this[this.length - 1]}})` in REPL",
        "body": "* **Version**: v15.3.0\r\n* **Platform**: Linux *** 5.9.11-3-MANJARO #1 SMP PREEMPT Sat Nov 28 09:08:57 UTC 2020 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n```js\r\nObject.defineProperty(Array.prototype, '-1', {get: function(){return this[this.length - 1]}})\r\n```\r\n\r\nWhen exec these code in REPL, the Node.js will let cpu occupancy rate become 100% and stuck itself.\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n100% reproduce.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n```bash\r\n> Object.defineProperty(Array.prototype, '-1', {get: function(){return this[this.length - 1]}})\r\nObject(0) []\r\n> \r\n```\r\n### Additional information\r\nIt can be reproduce in Node.js v14.8.0 on my Android's termux.\r\n <!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44893
    },
    {
        "title": "make check failure for macOS arch64",
        "body": "Commit 0b6d3070a1 \r\n\r\nmacOS 11.1  aarch64\r\n\r\nXcode 12.3\r\n\r\n```bash\r\nmake; make check\r\n\r\n=== release test-worker-prof ===                                              \r\nPath: sequential/test-worker-prof\r\nnode:assert:119\r\n  throw new AssertionError(obj);\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: child exited with signal: {\r\n  status: null,\r\n  signal: 'SIGSEGV',\r\n  output: [ null, '', '' ],\r\n  pid: 73280,\r\n  stdout: '',\r\n  stderr: ''\r\n}\r\n    at Object.<anonymous> (/Users/USERNAME/github/node/test/sequential/test-worker-prof.js:58:10)\r\n    at Module._compile (node:internal/modules/cjs/loader:1108:14)\r\n    at Object.Module._extensions..js (node:internal/modules/cjs/loader:1137:10)\r\n    at Module.load (node:internal/modules/cjs/loader:973:32)\r\n    at Function.Module._load (node:internal/modules/cjs/loader:813:14)\r\n    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:76:12)\r\n    at node:internal/main/run_main_module:17:47 {\r\n  generatedMessage: false,\r\n  code: 'ERR_ASSERTION',\r\n  actual: 'SIGSEGV',\r\n  expected: null,\r\n  operator: 'strictEqual'\r\n}\r\nCommand: out/Release/node /Users/USERNAME/github/node/test/sequential/test-worker-prof.js\r\n[02:41|% 100|+ 3282|-   1]: Done                                              \r\nmake[1]: *** [jstest] Error 1\r\nmake: *** [test] Error 2\r\n```",
        "labels": "confirmed-bug",
        "id": 44894
    },
    {
        "title": "Calling res.end() twice stalls follow-up HTTP request (drain event is missing)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 14.0.0...14.15.3 (latest lts), 15.0.0...15.5.0 (latest stable)\r\n* **Platform**: macos / ubuntu / windows\r\n* **Subsystem**: N/A\r\n\r\n### What steps will reproduce the bug?\r\n\r\nOriginally, I noticed this behaviour in a Next.js app and it took me quite a while to drill down to the bottom of it. You can find a plain MWE here: https://github.com/kachkaev/node-http-response-double-end-call-breaking-drain-event (no NPM packages involved). \r\n\r\nSince Node version 14.0.0, calling `res.end()` twice in a body-less response seems to be silencing the `drain` event in a follow-up HTTP request if it uses the same connection. This can happen in practice when redirecting a client to a heavy page and using [compression](https://www.npmjs.com/package/compression) package as middleware.\r\n\r\nI understand that calling `res.end()` twice is a developer mistake, however it does not seem right to have to debug such a small oversight for more than two working days ðŸ˜… When using [`res.redirect(...)` helper method in Next.js](https://github.com/vercel/next.js/blob/9b3edd3b2476b9915fe8c94071a77ac8e8f14499/packages/next/next-server/server/api-utils.ts#L195-L217), itâ€™s easy to forget that itâ€™s not only doing `res.writeHead(...)` for you, but also calls `res.end()`. Seeing `res.redirect(...); res.end()` does not feel too wrong initially and there is no feedback from the server or the tooling to suggest that this involves `res.end()` being called twice.\r\n\r\nHere are the reproduction steps from the server POV:\r\n\r\n1. A client establishes a connection and requests a page that results with a redirect:\r\n\r\n    ```ts\r\n    res.writeHead(302, { Location: \"/another-page\" });\r\n    res.end();\r\n    res.end(); // called twice intentionally\r\n    ```\r\n\r\n2. The same client immediately comes back with another request, which is meant to return 200 and contain some payload.\r\n\r\n    - If the size of the payload is small enough to fit a single `res.write(...)`, all works fine.\r\n    \r\n    - If the payload involves `res.write(...) === true` â†’ `res.on(\"drain\", () => {...})`, the second request is never finished because the `drain` event is never invoked.\r\n    \r\nYou can look into how `compression` is using `res.write(...)` + `res.on(\"drain\", ...)` to find a practical example: https://github.com/expressjs/compression/blob/3fea81d0eaed1eb872bf3e0405f20d9e175ab2cf/index.js#L193-L218\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nI am able to silence the `drain` event quite reliably on any Node version â‰¥14.0.0 on any OS. See the [GitHub Workflow for my MWE](https://github.com/kachkaev/node-http-response-double-end-call-breaking-drain-event/actions/runs/442932230).\r\n\r\n### What is the expected behavior?\r\n\r\nIdeally, I would expect the second `res.end()` to not produce any side effects or at least to give me a warning. All works fine in Node v13.14.0 and below.\r\n\r\n### What do you see instead?\r\n\r\nI stumbled across some magic behaviour which took more than two days to investigate ðŸ˜…\r\n\r\n### Additional information\r\n\r\nThe unwanted side effect from a double call to `res.end()` is negated:\r\n\r\n- if the follow-up request does not share the connection with the first (body-less) request (i.e. `curl` called twice);\r\n- or if `res.write(\"\")` is added to the first (body-less) request\r\n\r\nBoth observations are included into GitHub Workflows within the MWE repo. I also tried playing with `res.end(\"\")` as a replacement for `res.write(\"\")`, but it did not help.",
        "labels": "confirmed-bug",
        "id": 44895
    },
    {
        "title": "gunzipSync DOA in Node 14.15.2",
        "body": "* **Version**: 14.15.2\r\n* **Platform**: Linux lbvm 5.4.0-56-generic #62~18.04.1-Ubuntu SMP Tue Nov 24 10:07:50 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\nAny code using `gunzipSync` will crash\r\n\r\n```\r\n$ cat gunzip.js \r\nconst { gunzipSync } = require('zlib');\r\nconsole.log(gunzipSync('fooobar'));\r\n\r\n$ node -v\r\nv14.15.2\r\n\r\n$ node gunzip.js \r\ninternal/streams/readable.js:193\r\n  const isDuplex = this instanceof Stream.Duplex;\r\n                        ^\r\n\r\nTypeError: Right-hand side of 'instanceof' is not an object\r\n    at Gunzip.Readable (internal/streams/readable.js:193:25)\r\n    at Gunzip.Duplex (internal/streams/duplex.js:56:12)\r\n    at Gunzip.Transform (internal/streams/transform.js:117:10)\r\n    at Gunzip.ZlibBase (zlib.js:271:13)\r\n    at Gunzip.Zlib (zlib.js:669:12)\r\n    at new Gunzip (zlib.js:732:8)\r\n    at syncBufferWrapper (zlib.js:765:29)\r\n    at Object.<anonymous> (/home/ledion/workspaces/js2bin/gunzip.js:2:13)\r\n    at Module._compile (internal/modules/cjs/loader.js:1063:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1092:10)\r\n```\r\n\r\nThe regression seems to have been introduced in 14.15.2 and is present in 14.15.3.\r\n\r\nMaybe related to #35239? cc @mcollina \r\n",
        "labels": "confirmed-bug",
        "id": 44896
    },
    {
        "title": "`new URL` gives wrong result on leading backslash",
        "body": "<!--\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v15.4.0\r\n* **Platform**: `Linux 5b80145d2618 4.19.0-13-amd64 #1 SMP Debian 4.19.160-2 (2020-11-28) x86_64 GNU/Linux`\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\nParse a relative-URL string that begins with a backslash. For example:\r\n```\r\n> new URL(\"\\\\x\", \"https://example/foo/bar\").href\r\n'https://example/foo//x'\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\nThe leading backslash should have the same behavior as if it were a proper `/`. The input would be treated as a path-absolute URL (replacing the whole path from the base URL), or a scheme-relative URL (replacing all but the scheme from the base URL).\r\n\r\nFor example:\r\n`new URL(\"\\\\x\", \"https://example/foo/bar\").href` -> `\"https://example/x\"`\r\n`new URL(\"\\\\\\\\x\", \"https://example/foo/bar\").href` -> `\"https://x/\"`\r\n\r\n### What do you see instead?\r\n\r\nThe leading backslash is treated incorrectly. The effect seems to be as if the input were a path-relative-URL string -- the base URL's path, except for its last component, appears in the result. In the example:\r\n```\r\n> new URL(\"\\\\x\", \"https://example/foo/bar\").href\r\n'https://example/foo//x'\r\n```\r\n\r\n### Additional information\r\n\r\nThe behavior of `new URL` is documented as being defined by the WHATWG [URL Standard](https://url.spec.whatwg.org/). An input string like `\\x`, with a leading backslash, is never a \"valid URL string\" as defined in that standard... but the standard nevertheless defines what the `URL` constructor should return for it.\r\n\r\nBecause the example input `\\x` is so short, it's not hard to walk through [the URL parser](https://url.spec.whatwg.org/#url-parsing) as defined in the URL Standard and confirm what result the standard calls for. For the base URL of `https://example/`, it goes from \"scheme start state\" to \"no scheme state\" to \"relative state\" to \"relative slash state\" to \"path state\", following exactly the same track as an input of `/x` would do, except only that `\\x` emits a validation error. In the URL parser as defined by the URL Standard, a \"validation error\" [does not affect the parser's result](https://url.spec.whatwg.org/#validation-error), so the resulting URL should be the same as for `/x`.\r\n\r\nAs a different kind of check, Chrome (87.0.4280.88) gives the correct answer according to the spec. In the browser console:\r\n```\r\n> new URL(\"\\\\x\", \"https://example/foo/bar\").href\r\n\"https://example/x\"\r\n```\r\n\r\nSo does Firefox (78.0):\r\n```\r\nÂ» new URL(\"\\\\x\", \"https://example/foo/bar\").href\r\nâ† \"https://example/x\"\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 44897
    },
    {
        "title": "Object.assign / spread of http request object difference between v14.15.1 and v14.15.2",
        "body": "* **Version**: 14.15.2\r\n* **Platform**: any\r\n* **Subsystem**: any\r\n\r\n### What steps will reproduce the bug?\r\n\r\nWhile trying to create a cloned version of an http request object, prototype properties/methods such as `headers` and `get` get lost.\r\n\r\n```js\r\nconst assert = require('assert');\r\nconst http = require('http');\r\n\r\nconst server = http\r\n  .createServer((req, res) => {\r\n    const dummyReq = { ...req };\r\n    res.writeHead(200, { 'Content-Type': 'text/plain' });\r\n    res.end('ok');\r\n    assert.deepStrictEqual(req.headers, dummyReq.headers);\r\n  })\r\n  .listen();\r\n\r\nserver.on('listening', () => {\r\n  http.get(`http://localhost:${server.address().port}`);\r\n});\r\n```\r\n\r\n### What is the expected behavior?\r\n\r\nI honestly don't know if the behavior from 14.15.1 or from 14.15.2 is expected.\r\n\r\nBehavior until 14.15.1:  `dummyReq.headers` is not `undefined`.\r\n\r\n### What do you see instead?\r\n\r\nOutput in 14.15.2: `dummyReq.headers` is `undefined`.\r\n\r\n### Additional info\r\n\r\nThe same happens while using `Object.assign`",
        "labels": "confirmed-bug",
        "id": 44898
    },
    {
        "title": "doc: Piping multiple streams to the same Writable stream might not end",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 15.4.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux pop-os 5.8.0-7630-generic 20.10~61c3910-Ubuntu SMP Thu Nov 26 00:10:35 UTC  x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: stream\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/stream.html#stream_readable_pipe_destination_options\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nThe documentation for `readable.pipe()` reads:\r\n\r\n> ... The flow of data will be automatically managed so that the destination Writable stream is not overwhelmed by a faster Readable stream.\r\n\r\nSo when we open a Writable stream and then pipe multiple Readable streams into this Writable stream; the stream becomes full/congested and needs to drain but then we pipe more Readable streams into this stream. This seems to sometimes cause a Readable stream to not end and thus does not pipe its data to the Writable stream.\r\n\r\nBug in electron/asar explaining the issue https://github.com/electron/asar/issues/210.\r\n\r\nSince electron/asar does this in basically a `for await`-loop, we get stuck waiting for a Readable stream which never ends.\r\n\r\nIs this expected behavior when piping multiple Readable streams into one Writable stream? Should one check `writable.writableNeedDrain` before piping a Readable stream?\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "confirmed-bug",
        "id": 44899
    },
    {
        "title": "Worker thread throws error when started from `--require` script",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.4.0\r\n* **Platform**: Linux\r\n* **Subsystem**: worker_threads\r\n\r\n### What steps will reproduce the bug?\r\n\r\nRun the following at a bash shell:\r\n\r\n```\r\ntouch empty.js\r\necho \"new (require('worker_threads').Worker)('./empty.js')\" > create-worker.js\r\nnode -r ./create-worker.js ./empty.js\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nIt reproduces every time.  It happens when the worker is created by a `--require` script.\r\n\r\n### What is the expected behavior?\r\n\r\nNo errors from the worker_thread.\r\n\r\n### What do you see instead?\r\n\r\nLogs the following:\r\n```\r\nnode:events:353\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\nTypeError [Error]: undefined is not an integer typed array.\r\n    at Atomics.load (<anonymous>)\r\n    at process.cwd (node:internal/main/worker_thread:140:38)\r\n    at MessagePort.<anonymous> (node:internal/main/worker_thread:153:48)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (node:internal/event_target:422:41)\r\n    at MessagePort.exports.emitMessage (node:internal/per_context/messageport:18:26)\r\nEmitted 'error' event on process instance at:\r\n    at emitUnhandledRejectionOrErr (node:internal/event_target:602:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (node:internal/event_target:426:9)\r\n    at MessagePort.exports.emitMessage (node:internal/per_context/messageport:18:26)\r\n```\r\n\r\n### Additional information\r\n\r\nThe line number referenced in the error is here: https://github.com/nodejs/node/blob/master/lib/internal/main/worker_thread.js#L140\r\n\r\nBased on a brief look at the code, I guess node is assuming that the worker receives a bootstrapping message with a bunch of values, one of them being `cwdCounter`.  But when created via `--require`, that message is not sent or has not arrived yet.",
        "labels": "confirmed-bug",
        "id": 44900
    },
    {
        "title": "fs.mkdir with recursive option and invalid name hangs the program",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.18.0\r\n* **Platform**: Windows10\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n```js\r\nconst fs = require(\"fs\");\r\nconst path = \"./to-delete/s:d\";\r\n\r\nfs.mkdir(path, { recursive: true }, (err) => {\r\n  if (err) {\r\n    console.log(err);\r\n    return;\r\n  }\r\n  console.log(\"success\");\r\n});\r\n```\r\n### How often does it reproduce? Is there a required condition?\r\nUsing **:** (double dots) character in folder name after the first prefix will make the program freeze\r\n### What is the expected behavior?\r\nThrow an error\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nThe program hangs\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n--\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44901
    },
    {
        "title": "Cannot set a breakpoint on some modules",
        "body": "# Environment\r\n- macOS 10.15.7\r\n- Node.js 15.x.x\r\n\r\n# Steps to Reproduce\r\n```\r\n$ node inspect -e \"console.log('hello')\"\r\n< Debugger listening on ws://127.0.0.1:9229/c66c9b5b-fe08-43df-8494-0cd1609f277d\r\n< For help, see: https://nodejs.org/en/docs/inspector\r\n< Debugger attached.\r\nBreak on start in [eval]:1\r\n> 1 console.log('hello')\r\ndebug> step\r\nbreak in internal/console/constructor.js:341\r\n 339 const consoleMethods = {\r\n 340   log(...args) {\r\n>341     this[kWriteToConsole](kUseStdout, this[kFormatForStdout](args));\r\n 342   },\r\n 343\r\ndebug> step\r\nbreak in internal/console/constructor.js:305\r\n 303     ...consolePropAttributes,\r\n 304     value: function(args) {\r\n>305       const opts = this[kGetInspectOptions](this._stdout);\r\n 306       return formatWithOptions(opts, ...args);\r\n 307     }\r\ndebug> out\r\nbreak in internal/console/constructor.js:341\r\n 339 const consoleMethods = {\r\n 340   log(...args) {\r\n>341     this[kWriteToConsole](kUseStdout, this[kFormatForStdout](args));\r\n 342   },\r\n 343\r\ndebug> step\r\nbreak in internal/console/constructor.js:242\r\n 240     ...consolePropAttributes,\r\n 241     value: function(streamSymbol, string) {\r\n>242       const ignoreErrors = this._ignoreErrors;\r\n 243       const groupIndent = this[kGroupIndent];\r\n 244\r\ndebug> list()\r\n 237     }\r\n 238   },\r\n 239   [kWriteToConsole]: {\r\n 240     ...consolePropAttributes,\r\n 241     value: function(streamSymbol, string) {\r\n>242       const ignoreErrors = this._ignoreErrors;\r\n 243       const groupIndent = this[kGroupIndent];\r\n 244\r\n 245       const useStdout = streamSymbol === kUseStdout;\r\n 246       const stream = useStdout ? this._stdout : this._stderr;\r\n 247       const errorHandler = useStdout ?\r\ndebug> setBreakpoint(245)\r\nUncaught Error: Could not resolve breakpoint - undefined\r\n    at _pending.<computed> (internal/deps/node-inspect/lib/internal/inspect_client.js:243:27)\r\n    at Client._handleChunk (internal/deps/node-inspect/lib/internal/inspect_client.js:213:11)\r\n    at Socket.emit (events.js:314:20)\r\n    at Socket.EventEmitter.emit (domain.js:486:12)\r\n    at addChunk (_stream_readable.js:321:12)\r\n    at readableAddChunk (_stream_readable.js:297:9)\r\n    at Socket.Readable.push (_stream_readable.js:236:10)\r\n    at TCP.onStreamRead (internal/stream_base_commons.js:192:23)\r\n    at TCP.callbackTrampoline (internal/async_hooks.js:129:14) {\r\n  code: -32000\r\n}\r\ndebug> cont\r\n< hello\r\n< Waiting for the debugger to disconnect...\r\ndebug>\r\n```\r\n\r\n# Expected Behavior\r\nAble to set a breakpoint without any errors.\r\n\r\n# Actual Behavior\r\nCannot set a breakpoint. Getting an error and a stack trace shown on [Steps to Reproduce](#Steps-to-Reproduce) section.\r\n\r\n# Analysis\r\nIf this is indeed a bug and not the expected behavior, I understand that 7a447bc is the commit that introduced this. How I reached this opinion is:\r\n\r\n1. Observed this issue on my local Node.js installation, which is `15.3.0`.\r\n1. Using the [n version manager] for Node.js, tested it on all Node.js versions from `14.4.0` to `14.15.1`. Observed that the issue does not happen on any of these versions.\r\n1. Then tested it with `15.0.0` and `15.0.1`. The issue was observed in both versions (as well as my initial Node.js version, which is `15.3.0`). Deduced that the issue starts with version 15.\r\n1. Using the [n version manager], did a binary search on [Node.js nightly] binaries from `v14.0.0-nightly20200421c3554307c6` (the last version that starts with `v14`) to `v16.0.0-nightly20201021c2ceb15fd5` (the first version that starts with `v16`). That is, I performed a manual `git bisect`; first I downloaded `v14.0.0-nightly20200421c3554307c6` and observed that it works fine. Then I downloaded `v16.0.0-nightly20201021c2ceb15fd5` and observed that the issue is present. Then downloaded the version that's in the middle of them (which is `v15.0.0-nightly2020072341c1e72b76`) and observed that the issue is present.\r\n1. After a couple steps, I have realized that `v15.0.0-nightly20200717bf0d82c102` is the last version that issue is _not_ observed and `v15.0.0-nightly202007187a447bcd54` is the first version that issue is observed. Upon observing this, I ran a [comparison on GitHub] between the commits of these versions (which are bf0d82c102 for the last working version and 7a447bcd54 for the first broken version). GitHub told me that the following are the commits between those versions:\r\n    - bf0d82c\r\n    - 08e8997\r\n    - 5aeaff6\r\n    - d10c59f\r\n    - d379b00\r\n    - 404302f\r\n    - ef9964f\r\n    - f045387\r\n    - 1faf6f4\r\n    - 7ecb285\r\n    - 0b8ae5f\r\n    - c943cb4\r\n    - f8bde7c\r\n    - b1c3909\r\n    - 7a447bc\r\n1. Downloaded the [Node.js source code], checked out bf0d82c, configured (`./configure`) and built it (`make -j8`) on my machine (which is macOS 10.15.7 with xcode-select version 2373). Observed that it works properly.\r\n1. Then, consecutively, checked out all commits (starting with 08e8997 and going towards 7a447bc), built them and tested them. Observed that the issue does not happen in any of them except the last commit, which is 7a447bc.\r\n1. Hence, if this is indeed a bug, I deduced that 7a447bc is the commit that introduced this bug.\r\n\r\n<details>\r\n  <summary>My nightly build test results for reference (click on the arrow to expand)</summary>\r\n\r\n  ```\r\n  WORKS - v15.0.0-nightly20200422d08bd41248/                 22-Apr-2020 07:30                   -\r\n  v15.0.0-nightly202004236a07eca49c/                 23-Apr-2020 07:30                   -\r\n  v15.0.0-nightly202004240619b600b2/                 24-Apr-2020 07:00                   -\r\n  v15.0.0-nightly2020042524a4e6153d/                 25-Apr-2020 07:30                   -\r\n  v15.0.0-nightly20200426f8d5474839/                 26-Apr-2020 07:00                   -\r\n  v15.0.0-nightly202004275ee1e31e38/                 27-Apr-2020 07:30                   -\r\n  v15.0.0-nightly20200428307c67be17/                 28-Apr-2020 08:30                   -\r\n  v15.0.0-nightly20200429e7b99e027b/                 29-Apr-2020 07:30                   -\r\n  v15.0.0-nightly202004302496db8e09/                 30-Apr-2020 07:30                   -\r\n  v15.0.0-nightly20200501e9518254d7/                 01-May-2020 08:30                   -\r\n  v15.0.0-nightly202005027c36ec38f1/                 02-May-2020 07:00                   -\r\n  v15.0.0-nightly20200503b0aba53195/                 03-May-2020 07:00                   -\r\n  v15.0.0-nightly20200504bde5f9baf7/                 04-May-2020 08:30                   -\r\n  v15.0.0-nightly20200505c17dcb3253/                 05-May-2020 08:30                   -\r\n  v15.0.0-nightly2020050686fdaa7455/                 06-May-2020 07:30                   -\r\n  v15.0.0-nightly202005078607f9ec5c/                 07-May-2020 07:00                   -\r\n  v15.0.0-nightly20200508bcdbd57134/                 08-May-2020 07:30                   -\r\n  v15.0.0-nightly20200509be7fd2d517/                 09-May-2020 07:00                   -\r\n  v15.0.0-nightly2020051094e5b5c77d/                 10-May-2020 07:00                   -\r\n  v15.0.0-nightly202005118a6fab02ad/                 11-May-2020 07:00                   -\r\n  v15.0.0-nightly202005128c5d58b5a7/                 12-May-2020 07:00                   -\r\n  v15.0.0-nightly202005135bb4d01fbe/                 13-May-2020 07:30                   -\r\n  v15.0.0-nightly20200514eaa16cd477/                 14-May-2020 07:30                   -\r\n  v15.0.0-nightly2020051524bf1adacc/                 15-May-2020 07:30                   -\r\n  v15.0.0-nightly20200516b533fb3508/                 16-May-2020 07:00                   -\r\n  v15.0.0-nightly20200517b3ca8869a6/                 17-May-2020 07:30                   -\r\n  v15.0.0-nightly20200518ef1eb8d439/                 18-May-2020 08:30                   -\r\n  v15.0.0-nightly20200519fe1b9e09a8/                 19-May-2020 07:30                   -\r\n  v15.0.0-nightly20200520a82001a387/                 20-May-2020 07:30                   -\r\n  v15.0.0-nightly20200521cd4985c488/                 21-May-2020 07:00                   -\r\n  v15.0.0-nightly2020052251af89fe45/                 22-May-2020 07:00                   -\r\n  v15.0.0-nightly20200523a416692e93/                 23-May-2020 07:00                   -\r\n  v15.0.0-nightly20200524dd5f209213/                 24-May-2020 08:30                   -\r\n  v15.0.0-nightly20200525458677f5ef/                 25-May-2020 07:00                   -\r\n  v15.0.0-nightly202005265007611294/                 26-May-2020 08:30                   -\r\n  v15.0.0-nightly202005279949a2e1e3/                 27-May-2020 08:30                   -\r\n  v15.0.0-nightly2020052847044a91c6/                 28-May-2020 08:30                   -\r\n  v15.0.0-nightly202005296a1df3b5af/                 29-May-2020 07:30                   -\r\n  v15.0.0-nightly20200530d79c330186/                 30-May-2020 07:00                   -\r\n  v15.0.0-nightly202005312935f72ae1/                 31-May-2020 08:30                   -\r\n  v15.0.0-nightly20200602b1704e4347/                 02-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200603680fb8fc62/                 03-Jun-2020 07:30                   -\r\n  v15.0.0-nightly202006043a7a5d7e62/                 04-Jun-2020 07:30                   -\r\n  v15.0.0-nightly202006053e2a300710/                 05-Jun-2020 07:30                   -\r\n  WORKS - v15.0.0-nightly202006063ac50e1209/                 06-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200607d8eef83757/                 07-Jun-2020 08:30                   -\r\n  v15.0.0-nightly202006088a4b5c63e0/                 08-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200609921f75534c/                 09-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200610362e4a1aec/                 10-Jun-2020 14:30                   -\r\n  v15.0.0-nightly20200611f4e805c860/                 11-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200612bba9b008ef/                 12-Jun-2020 07:30                   -\r\n  v15.0.0-nightly202006137b46793eee/                 13-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200614c17d2f9901/                 14-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200615f645cc7318/                 15-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200616b371213d3d/                 16-Jun-2020 09:00                   -\r\n  v15.0.0-nightly20200617ee7f0e3f75/                 17-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200618a4f3206b76/                 18-Jun-2020 07:30                   -\r\n  v15.0.0-nightly2020061956967afdca/                 19-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200620fdf10adef8/                 20-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200622122038c6a2/                 22-Jun-2020 07:00                   -\r\n  v15.0.0-nightly2020062386cbad837b/                 23-Jun-2020 06:30                   -\r\n  v15.0.0-nightly20200624d8f8723577/                 24-Jun-2020 07:00                   -\r\n  v15.0.0-nightly20200625e405e82f74/                 25-Jun-2020 07:00                   -\r\n  v15.0.0-nightly20200626e18afe45d2/                 26-Jun-2020 07:00                   -\r\n  v15.0.0-nightly20200627f63436d190/                 27-Jun-2020 07:00                   -\r\n  v15.0.0-nightly20200628f89530fccc/                 28-Jun-2020 09:00                   -\r\n  WORKS - v15.0.0-nightly2020062990d5f35f7a/                 29-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200630c23d2fd3f8/                 30-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200701e2b468eb5c/                 01-Jul-2020 07:30                   -\r\n  v15.0.0-nightly20200702c118304ad0/                 02-Jul-2020 08:30                   -\r\n  v15.0.0-nightly202007031dc837ed9a/                 03-Jul-2020 07:30                   -\r\n  v15.0.0-nightly20200704bff7de3b43/                 04-Jul-2020 08:00                   -\r\n  v15.0.0-nightly2020070556dbe466fd/                 05-Jul-2020 07:00                   -\r\n  v15.0.0-nightly2020070667ba825037/                 06-Jul-2020 08:30                   -\r\n  v15.0.0-nightly2020070730612316e4/                 07-Jul-2020 07:30                   -\r\n  v15.0.0-nightly20200708e0ecde9737/                 08-Jul-2020 07:30                   -\r\n  v15.0.0-nightly202007096ae1b9c457/                 09-Jul-2020 07:00                   -\r\n  WORKS - v15.0.0-nightly202007101237955d41/                 10-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200711c176d5fac2/                 11-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200712ac6ecd6b7f/                 12-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200714c7627da837/                 14-Jul-2020 08:00                   -\r\n  v15.0.0-nightly202007153b130327fa/                 15-Jul-2020 08:00                   -\r\n  v15.0.0-nightly20200716d46fc91be4/                 16-Jul-2020 08:00                   -\r\n  WORKS - v15.0.0-nightly20200717bf0d82c102/                 17-Jul-2020 08:00                   -\r\n  DOES NOT WORK - v15.0.0-nightly202007187a447bcd54/                 18-Jul-2020 07:30                   -\r\n  DOES NOT WORK - v15.0.0-nightly202007190c81cadec6/                 19-Jul-2020 08:30                   -\r\n  NO BINARY FOR MACOS - v15.0.0-nightly20200720a51436cbea/                 20-Jul-2020 06:30                   -\r\n  v15.0.0-nightly202007212c05beeb54/                 21-Jul-2020 08:00                   -\r\n  v15.0.0-nightly20200722b0b52b2023/                 22-Jul-2020 09:00                   -\r\n  DOES NOT WORK - v15.0.0-nightly2020072341c1e72b76/                 23-Jul-2020 09:00                   -\r\n  v15.0.0-nightly20200724d1e4e8eaba/                 24-Jul-2020 07:30                   -\r\n  v15.0.0-nightly20200725de192246bc/                 25-Jul-2020 07:00                   -\r\n  v15.0.0-nightly2020072631ba9a20bd/                 26-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200727db54b57042/                 27-Jul-2020 07:00                   -\r\n  v15.0.0-nightly202007286fd09e4f36/                 28-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200729360bf9b289/                 29-Jul-2020 08:30                   -\r\n  v15.0.0-nightly202007301fe39f0b4b/                 30-Jul-2020 08:30                   -\r\n  v15.0.0-nightly20200731dc00a07426/                 31-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200801cc7ec889e8/                 01-Aug-2020 07:00                   -\r\n  v15.0.0-nightly2020080273d713b16e/                 02-Aug-2020 07:00                   -\r\n  v15.0.0-nightly20200803a9c5b873ca/                 03-Aug-2020 07:00                   -\r\n  v15.0.0-nightly2020080474df7496ff/                 04-Aug-2020 07:00                   -\r\n  v15.0.0-nightly2020080584b35b2867/                 05-Aug-2020 07:00                   -\r\n  v15.0.0-nightly20200806df17fcdc71/                 06-Aug-2020 07:00                   -\r\n  v15.0.0-nightly2020080746bef7b771/                 07-Aug-2020 07:00                   -\r\n  v15.0.0-nightly20200808ac5773b1c3/                 08-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008098825eb4d73/                 09-Aug-2020 07:00                   -\r\n  v15.0.0-nightly20200810dd0c5228ac/                 10-Aug-2020 08:00                   -\r\n  v15.0.0-nightly20200811f8a0e62bbf/                 11-Aug-2020 07:00                   -\r\n  v15.0.0-nightly202008122f27f1144e/                 12-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008137a1220a1d7/                 17-Aug-2020 22:30                   -\r\n  v15.0.0-nightly202008145864fca7bc/                 17-Aug-2020 22:30                   -\r\n  v15.0.0-nightly202008158da8ec9c7e/                 17-Aug-2020 22:30                   -\r\n  v15.0.0-nightly20200816375b859428/                 17-Aug-2020 22:30                   -\r\n  v15.0.0-nightly2020081742a3a7f97d/                 17-Aug-2020 23:00                   -\r\n  v15.0.0-nightly20200818ca5ff723d1/                 21-Aug-2020 22:30                   -\r\n  v15.0.0-nightly202008196e97a735c8/                 21-Aug-2020 23:00                   -\r\n  v15.0.0-nightly2020082003293aa3a1/                 21-Aug-2020 23:00                   -\r\n  v15.0.0-nightly202008217aeff6b8c8/                 21-Aug-2020 23:00                   -\r\n  v15.0.0-nightly2020082244e6a6af67/                 22-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008238e8d429277/                 23-Aug-2020 08:30                   -\r\n  v15.0.0-nightly20200824c3d337db5d/                 24-Aug-2020 09:00                   -\r\n  v15.0.0-nightly20200825010383a174/                 25-Aug-2020 08:30                   -\r\n  v15.0.0-nightly20200826c6b96895cc/                 26-Aug-2020 09:00                   -\r\n  v15.0.0-nightly202008278ec3b55e5b/                 27-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008280848f56cb3/                 28-Aug-2020 08:30                   -\r\n  v15.0.0-nightly2020082994fcac7876/                 29-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008305c020762bb/                 30-Aug-2020 07:30                   -\r\n  v15.0.0-nightly20200831e1edd6bbfa/                 31-Aug-2020 07:30                   -\r\n  v15.0.0-nightly2020090159cad32b51/                 01-Sep-2020 07:30                   -\r\n  v15.0.0-nightly20200902e2ffa454d3/                 02-Sep-2020 07:00                   -\r\n  v15.0.0-nightly20200903b23a932bfd/                 03-Sep-2020 08:30                   -\r\n  v15.0.0-nightly202009043b925219c3/                 04-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20200905186230527b/                 05-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20200906e326c41fbc/                 08-Sep-2020 12:00                   -\r\n  v15.0.0-nightly20200907bb9117ee9f/                 08-Sep-2020 12:30                   -\r\n  v15.0.0-nightly202009086f2af08245/                 08-Sep-2020 12:30                   -\r\n  v15.0.0-nightly202009091204400d64/                 09-Sep-2020 08:30                   -\r\n  v15.0.0-nightly202009104c9b79ed5a/                 10-Sep-2020 07:00                   -\r\n  v15.0.0-nightly202009114f176c9110/                 11-Sep-2020 07:30                   -\r\n  v15.0.0-nightly20200912541d296d56/                 12-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20200913b123e0806f/                 13-Sep-2020 07:00                   -\r\n  v15.0.0-nightly202009149d12c14b19/                 14-Sep-2020 07:00                   -\r\n  v15.0.0-nightly202009152b3eb101b5/                 15-Sep-2020 07:30                   -\r\n  v15.0.0-nightly202009169cf9e4aebc/                 16-Sep-2020 08:30                   -\r\n  v15.0.0-nightly2020091718462e0c1d/                 17-Sep-2020 08:30                   -\r\n  v15.0.0-nightly202009182d868fe822/                 18-Sep-2020 07:30                   -\r\n  v15.0.0-nightly2020091931b3202d59/                 19-Sep-2020 08:00                   -\r\n  v15.0.0-nightly20200920770ad3a52d/                 20-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20200921039c274dde/                 21-Sep-2020 09:00                   -\r\n  v15.0.0-nightly20200922d71b467bbe/                 22-Sep-2020 08:30                   -\r\n  v15.0.0-nightly202009233b10f7f933/                 23-Sep-2020 07:00                   -\r\n  v15.0.0-nightly20200924d6fe46f749/                 25-Sep-2020 11:30                   -\r\n  v15.0.0-nightly20200925785a5f9ae1/                 25-Sep-2020 11:30                   -\r\n  v15.0.0-nightly20200926aa99bb47bf/                 26-Sep-2020 08:00                   -\r\n  v15.0.0-nightly20200927af92317909/                 27-Sep-2020 09:00                   -\r\n  v15.0.0-nightly202009286fc3b0ddb9/                 28-Sep-2020 08:00                   -\r\n  v15.0.0-nightly202009291e8cb08edc/                 29-Sep-2020 07:30                   -\r\n  v15.0.0-nightly20200930ee9e3e75aa/                 30-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20201001726143e683/                 01-Oct-2020 07:00                   -\r\n  v15.0.0-nightly202010024a6005c56a/                 02-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201003e7bb8b6dc0/                 03-Oct-2020 08:00                   -\r\n  v15.0.0-nightly20201004e6d5af3c95/                 04-Oct-2020 08:30                   -\r\n  v15.0.0-nightly202010055e605c0dd9/                 05-Oct-2020 09:00                   -\r\n  v15.0.0-nightly20201006642f2064c0/                 06-Oct-2020 08:00                   -\r\n  v15.0.0-nightly20201007bc0c094b74/                 07-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201008ccc822c7c8/                 08-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201009c8b950a7af/                 09-Oct-2020 07:00                   -\r\n  v15.0.0-nightly202010108d8e06a345/                 10-Oct-2020 07:00                   -\r\n  v15.0.0-nightly2020101191e0d9bc30/                 11-Oct-2020 07:00                   -\r\n  v15.0.0-nightly202010122d83e743d9/                 12-Oct-2020 07:00                   -\r\n  v15.0.0-nightly2020101344a66adbaa/                 13-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201014d5e64952fe/                 14-Oct-2020 08:30                   -\r\n  v15.0.0-nightly202010154079bfd462/                 15-Oct-2020 21:00                   -\r\n  v15.0.0-nightly20201016c143266b55/                 16-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201017a3731309cc/                 17-Oct-2020 11:00                   -\r\n  v15.0.0-nightly20201018ee85eb9f8a/                 18-Oct-2020 07:30                   -\r\n  v15.0.0-nightly20201019c55f661551/                 19-Oct-2020 07:00                   -\r\n  v15.0.0-nightly2020102011f1ad939f/                 20-Oct-2020 07:00                   -\r\n  DOES NOT WORK - v16.0.0-nightly20201021c2ceb15fd5/                 21-Oct-2020 07:00                   -\r\n  ```\r\n</details>\r\n\r\nPlease view [Other Places This Issue is Mentioned](#Other-Places-This-Issue-is-Mentioned) for more information on this issue and a GIF demonstration of the issue.\r\n\r\n@joyeecheung\r\n@addaleax\r\n\r\n[n version manager]: https://github.com/tj/n\r\n[Node.js nightly]: https://nodejs.org/download/nightly/\r\n[comparison on GitHub]: https://github.com/nodejs/node/compare/bf0d82c102...7a447bcd54\r\n[Node.js source code]: https://github.com/nodejs/node\r\n\r\n# Other Places This Issue is Mentioned\r\n- https://github.com/nodejs/diagnostics/issues/455\r\n- https://github.com/nodejs/help/issues/3104\r\n- https://stackoverflow.com/questions/65113609/node-js-breakpoints-not-working-on-modules\r\n",
        "labels": "confirmed-bug",
        "id": 44902
    },
    {
        "title": "Asynchronous dir.close() throws immediately, if already closed",
        "body": "* **Version**: v12.12.0 - v14.15.1\r\n* **Platform**: platform-independent\r\n* **Subsystem**: lib/internal/fs/dir.js\r\n\r\n### What steps will reproduce the bug?\r\nCalling asynchronous version of dir.close() with dir already closed, e.g. by it's async iterator.\r\n```\r\nconst fs = require('fs')\r\n\r\nconst dir = fs.opendirSync('.')  // Using async function in this example just for brevity.\r\n\r\ndir.closeSync()     //  In my actual code, here is an async loop over dir.entries() which may terminate in the middle.\r\n\r\ntry {\r\n  dir.close((error) => {\r\n    if(!error) return\r\n    // We never get ERR_DIR_CLOSED here...\r\n  })\r\n} catch (error) {\r\n    // ... but here instead (but we should see only ERR_INVALID_CALLBACK here).\r\n}\r\n```\r\n### How often does it reproduce? Is there a required condition?\r\nAlways, when dir.close() is called redundantly.\r\n### What is the expected behavior?\r\nAsynchronous functions should forward errors via callback, unless the provided callback argument itself is invalid.\r\n### What do you see instead?\r\nError is thrown immediately (synchronously), This is especially embarrassing with promises API:\r\n```\r\ntry {\r\n  dir.close().then(() => console.log('closed the dir just now')\r\n  ).catch(error => console.log('something wrong', error))\r\n} catch (error) {\r\n  if(error.code === 'ERR_DIR_CLOSED') console.log('Oh no... again!')\r\n  else console.log('a real surprise!', e)\r\n}\r\n```\r\n### Additional information\r\nIf this behaviour is intentional, it should be documented; otherwise I would gladly provide a fix.",
        "labels": "confirmed-bug",
        "id": 44903
    },
    {
        "title": "doc: history shows wrong version for conditional package export support",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 12.16.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: All\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: loader\r\n\r\n## Location\r\n\r\nModules: Packages\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/packages.html#packages_exports\r\n\r\n## Description\r\n\r\nUnder the \"history\" section, the docs say that conditional export support was added and also unflagged in 12.16, which doesn't seem to be the case. 12.17.0 appears to be the first version that supports conditional exports and I can't get either conditional exports or the `--experimental-conditional-exports` flag to work in 12.16.0.\r\n\r\n![image](https://user-images.githubusercontent.com/2898433/99498789-1d811c80-29cc-11eb-9505-0978cad0b281.png)\r\n\r\n---\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "confirmed-bug",
        "id": 44904
    },
    {
        "title": "Issue with mksnapshot and binding data",
        "body": "@joyeecheung ... I'm running into an issue with the node_mksnapshot tool during build. It apparently does not know how to handle BindingData for native modules when the snapshot is created...\r\n\r\nI'm working on a rework of `internalBinding('trace_events')` module, and attempting to add binding data to it:\r\n\r\n```cpp\r\n  TraceEventsState* const state =\r\n      env->AddBindingData<TraceEventsState>(context, target);\r\n  if (state == nullptr) return;\r\n```\r\n\r\nThe `trace_events` module is loaded during bootstrap, so the created `TraceEventsState` object is attached as the binding data at that step.\r\n\r\nUnfortunately, this causes `node_mksnapshot` to crash:\r\n\r\n```\r\nglobal handle not serialized: 0x327e5e9f3281: [JS_API_OBJECT_TYPE] in OldSpace\r\n - map: 0x2c1d4730fe89 <Map(HOLEY_ELEMENTS)> [FastProperties]\r\n - prototype: 0x218677ec84b1 <Object map = 0x2c1d473101a1>\r\n - elements: 0x1fd3c5ec0b29 <FixedArray[0]> [HOLEY_ELEMENTS]\r\n - embedder fields: 1\r\n - properties: 0x1fd3c5ec0b29 <FixedArray[0]> {}\r\n - embedder fields = {\r\n    22006, aligned pointer: 0x55f6648c31e0\r\n }\r\n\r\n\r\n\r\n#\r\n# Fatal error in , line 0\r\n# Check failed: handle_checker.CheckGlobalAndEternalHandles().\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 0x7ffd2543d6c0\r\n 1: 0x55f65ee301a1  [/home/james/node/node/out/Release/node_mksnapshot]\r\n 2: 0x55f65fd6af3e V8_Fatal(char const*, ...) [/home/james/node/node/out/Release/node_mksnapshot]\r\n 3: 0x55f65f3e3823 v8::SnapshotCreator::CreateBlob(v8::SnapshotCreator::FunctionCodeHandling) [/home/james/node/node/out/Release/node_mksnapshot]\r\n 4: 0x55f65ed1c016 node::SnapshotBuilder::Generate(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >) [/home/james/node/node/out/Release/node_mksnapshot]\r\n 5: 0x55f65e953832 main [/home/james/node/node/out/Release/node_mksnapshot]\r\n 6: 0x7f2df6bb1b97 __libc_start_main [/lib/x86_64-linux-gnu/libc.so.6]\r\n 7: 0x55f65e95b42a _start [/home/james/node/node/out/Release/node_mksnapshot]\r\nIllegal instruction (core dumped)\r\nnode.target.mk:26: recipe for target '/home/james/node/node/out/Release/obj/gen/node_snapshot.cc' failed\r\nmake[1]: *** [/home/james/node/node/out/Release/obj/gen/node_snapshot.cc] Error 132\r\nrm 82c869d3ddd844a851343f4dda5865e1e173131d.intermediate 53b6ae97571ad65714c594648ab8f1c04245ce26.intermediate\r\nMakefile:104: recipe for target 'node' failed\r\nmake: *** [node] Error 2\r\n```\r\n\r\nWe should be able to attach `BindingData` to any of the internal native modules without having to fight with this. I know that addaleax's original implementation design for this bit covered but I'm not sure of the details so I'm not entirely sure what is missing in the version of your approach that landed here.",
        "labels": "confirmed-bug",
        "id": 44905
    },
    {
        "title": "stream: regression in v14, this.push(null) in Transform doesn't emit end",
        "body": "* **Version**: v14.5.0\r\n* **Platform**: Ubuntu/Linux\r\n* **Subsystem**: stream\r\n\r\n```js\r\nlet stream = require('stream');\r\n\r\nlet src = new stream.Readable({\r\n  read() {\r\n    console.log('push')\r\n    this.push(Buffer.alloc(20000));\r\n  }\r\n});\r\n\r\nlet dst = new stream.Transform({\r\n  transform(chunk, output, fn) {\r\n    this.push(null);\r\n    fn();\r\n  }\r\n});\r\n\r\nsrc.pipe(dst);\r\n\r\nfunction parser_end(error) {\r\n  console.log('parser ended', error);\r\n  dst.removeAllListeners();\r\n}\r\n\r\ndst.once('data', data => console.log(data));\r\ndst.once('end', () => parser_end());\r\ndst.on('error', error => parser_end(error));\r\n```\r\n\r\n* Expected behavior (tested on node v10, 12): `end` event is emitted by `dst`, transform stops, source pauses.\r\n* Actual behavior (tested on node v14): `end` event **does not** get emitted by `dst`, transform runs indefinitely.",
        "labels": "confirmed-bug",
        "id": 44906
    },
    {
        "title": "generateKeyPair with blank passphrase prompts \"Enter PEM pass phrase\" in Node 15",
        "body": "* **Version**: v15.0.1\r\n* **Platform**: Darwin DaveMBP.local 18.7.0 Darwin Kernel Version 18.7.0: Mon Aug 31 20:53:32 PDT 2020; root:xnu-4903.278.44~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst crypto = require('crypto');\r\n\r\ncrypto.generateKeyPair('rsa', {\r\n  modulusLength: 2048,\r\n  privateKeyEncoding: {\r\n    type: 'pkcs8',\r\n    format: 'pem',\r\n    cipher: 'aes-256-cbc',\r\n    passphrase: '', // <-- blank string passphrase\r\n  },\r\n  publicKeyEncoding: { type: 'spki', format: 'pem' },\r\n},  (err, publicKey, privateKey) => console.log(`got key\\n\\n${publicKey}\\n\\n${privateKey}`));\r\n```\r\n\r\n### What is the expected behaviour?\r\n\r\nIn NodeJS 14 and below, the above generates an output without any prompts.\r\n\r\n### What do you see instead?\r\n\r\nSince NodeJS 15, the above issues a prompt on the terminal:\r\n\r\n> ```\r\n> Enter PEM pass phrase:\r\n> ```\r\n\r\nWhich hangs until the user provides input (i.e. forever on a CI server).\r\n\r\n### Additional information\r\n\r\nIt seems reasonable for a blank string to be rejected as an input here if a cipher is being used, but it should either work or throw an exception. Triggering a command-line prompt is not a good user experience, and makes this relatively difficult to track-down.\r\n\r\nIn my particular case, I allow users of my project to configure a blank passphrase to mean \"don't bother encrypting this\", which I can achieve myself by detecting a blank passphrase and passing `undefined` for both `cipher` and `passphrase` in Node 15, which is fine. My personal preference would be for this to throw if given a blank passphrase, but that would still be a breaking change from 14, so maybe the way to go is to allow blank passphrases as before.",
        "labels": "confirmed-bug",
        "id": 44907
    },
    {
        "title": "`crypto.scryptSync` regression in Node 15: routines:EVP_PBE_scrypt:memory limit exceeded",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.0.1\r\n* **Platform**: Linux 64 bits\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n\r\nCreate `main.js` and run it.\r\n\r\n```\r\n// main.js\r\nconst crypto = require(\"crypto\");\r\n// 2-3 iteration steps are enough to cause the error, but it's not deterministic so I am running it 100 times to make sure the error occurs\r\nfor (let i = 0; i < 100; i++) {\r\n  crypto.scryptSync('', '', 64, { N: 128, r: 1, p: 1 })\r\n}\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nCalling `scryptSync` a few times always produces this error. This is not deterministic: sometimes 2 calls were enough, sometimes I need 3 calls.\r\n\r\n### What is the expected behavior?\r\n\r\nThe script completes without any error\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nI see the following error:\r\n\r\n```\r\nnode:internal/crypto/scrypt:81\r\n    throw err;\r\n    ^\r\n\r\nError: error:060B50AC:digital envelope routines:EVP_PBE_scrypt:memory limit exceeded\r\n    at Object.scryptSync (node:internal/crypto/scrypt:78:29)\r\n    at Object.<anonymous> (/data/projects/main.js:3:10)\r\n    at Module._compile (node:internal/modules/cjs/loader:1083:30)\r\n    at Object.Module._extensions..js (node:internal/modules/cjs/loader:1112:10)\r\n    at Module.load (node:internal/modules/cjs/loader:948:32)\r\n    at Function.Module._load (node:internal/modules/cjs/loader:789:14)\r\n    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:72:12)\r\n    at node:internal/main/run_main_module:17:47\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nThis is a regression in Node 15. Running the same code on the same computer with Node 14.14.0 works fine.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44908
    },
    {
        "title": "Function has non-object prototype 'null' in instanceof check, when I use node but it is fine in Browser",
        "body": "Looks like a Node.js bug. Logging an object should never crash. The same works in the browser:\r\n```\r\nfunction X () {}\r\nX.prototype = null;\r\nx = {};\r\nx.constructor = X;\r\nconsole.log(x);\r\n```\r\n\r\nNode.js:\r\n```\r\nUncaught TypeError: Function has non-object prototype 'null' in instanceof check\r\n    at Function.[Symbol.hasInstance] (<anonymous>)\r\n    at getConstructorName (internal/util/inspect.js:535:13)\r\n    at formatRaw (internal/util/inspect.js:803:23)\r\n    at formatValue (internal/util/inspect.js:793:10)\r\n    at inspect (internal/util/inspect.js:326:10)\r\n    at formatWithOptionsInternal (internal/util/inspect.js:1994:40)\r\n    at formatWithOptions (internal/util/inspect.js:1878:10)\r\n    at Object.value (internal/console/constructor.js:306:14)\r\n    at Object.log (internal/console/constructor.js:341:61)\r\n```\r\nBrowser:\r\n```\r\n{constructor: Æ’}\r\n```\r\n\r\n**node Verison:  v14.14.0**",
        "labels": "confirmed-bug",
        "id": 44909
    },
    {
        "title": "StringDecoder undocumented size limit",
        "body": "* **Version**: v12.13.0\r\n* **Platform**: Windows 10 (64bit)\r\n* **Subsystem**: string_decoder, stream\r\n\r\n### What steps will reproduce the bug?\r\n \r\n```\r\nconst buf = Buffer.alloc(1024 * 1024 * 1024, 'a');\r\nconst sd = new (require('string_decoder').StringDecoder)();\r\nsd.write(buf).length\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThe above causes the issue 100% reliably for me.\r\n\r\n### What is the expected behavior?\r\n\r\nEither the decoded buffer or an exception explaining that the input buffer is too long.\r\n\r\n### What do you see instead?\r\n\r\n> TypeError: Cannot read property 'length' of undefined\r\n\r\nSo sd.write(_large buffer_) returns undefined\r\n\r\nThe reason I'm including stream as an affected subsystem is this line which originally led me to this issue: https://github.com/nodejs/readable-stream/blob/040b813e60ecf0d68ac1461a3fc3157ea5785950/lib/_stream_readable.js#L277\r\n\r\nSo what happens is that if you have a stream (a pipe used for IPC in my case) and the other side sends an large chunk of data, the recipient throws an exception before any application code is invoked that could handle it gracefully.\r\n\r\n### Additional information\r\n\r\nI don't know exactly how large the buffer has to be. In my application (electron 8.5.2 with node 12.13.0) this started happening at around 600MB, when reproducing in node on the command line I had to increase the buffer to 1GB.\r\n\r\nJust to clarify: I understand that there will be a limit on how large these buffers can get, I just wish it would report an error that my application code can handle because right now I don't see how I could write robust client code that can deal with the other side sending crap.",
        "labels": "confirmed-bug",
        "id": 44910
    },
    {
        "title": "HTTP: Connection resets after 60 seconds in node.js upload application",
        "body": "* **Version**: v12.19.0\r\n* **Platform**: Linux *snip* 4.15.0-121-generic #123-Ubuntu SMP Mon Oct 5 16:16:40 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux (Ubuntu 18.04.5 LTS)\r\n* **Subsystem**: http\r\n\r\n### What steps will reproduce the bug?\r\n\r\nThe client depends on node-fetch v2.6.1\r\n\r\n`testServer.js`\r\n```\r\n// -- DevNull Start --\r\nvar util         = require('util')\r\n  , stream       = require('stream')\r\n  , Writable     = stream.Writable\r\n  , setImmediate = setImmediate || function (fn) { setTimeout(fn, 0) }\r\n  ;\r\nutil.inherits(DevNull, Writable);\r\nfunction DevNull (opts) {\r\n  if (!(this instanceof DevNull)) return new DevNull(opts);\r\n  opts = opts || {};\r\n  Writable.call(this, opts);\r\n}\r\nDevNull.prototype._write = function (chunk, encoding, cb) {\r\n  setImmediate(cb);\r\n}\r\n// -- DevNull End --\r\nconst http = require('http');\r\nconst server = http.createServer();\r\nserver.on('request', async (req, res) => {\r\n  try {\r\n    req.socket.on('end', function() { \r\n      console.log('SOCKET END: other end of the socket sends a FIN packet');\r\n    });\r\n    req.socket.on('timeout', function() { \r\n      console.log('SOCKET TIMEOUT');\r\n    });\r\n    req.socket.on('error', function(error) { \r\n      console.log('SOCKET ERROR: ' + JSON.stringify(error));\r\n    });\r\n    req.socket.on('close', function(had_error) { \r\n      console.log('SOCKET CLOSED. IT WAS ERROR: ' + had_error);\r\n    });\r\n    const writeStream = DevNull();\r\n    const promise = new Promise((resolve, reject) => {\r\n      req.on('end', resolve);\r\n      req.on('error', reject);\r\n    });\r\n    req.pipe(writeStream);\r\n    await promise;\r\n    res.writeHead(200);\r\n    res.end('OK');\r\n  } catch (err) {\r\n    res.writeHead(500);\r\n    res.end(err.message);\r\n  }\r\n});\r\nserver.listen(8081)\r\n  .on('listening', () => { console.log('Listening on port', server.address().port); });\r\n```\r\n\r\n`testClient.js`\r\n```\r\n// -- RandomStream Start --\r\nvar crypto = require('crypto');\r\nvar stream = require('stream');\r\nvar util = require('util');\r\nvar Readable = stream.Readable;\r\nfunction RandomStream(length, options) {\r\n  // allow calling with or without new\r\n  if (!(this instanceof RandomStream)) {\r\n    return new RandomStream(length, options);\r\n  }\r\n  // init Readable\r\n  Readable.call(this, options);\r\n  // save the length to generate\r\n  this.lenToGenerate = length;\r\n}\r\nutil.inherits(RandomStream, Readable);\r\nRandomStream.prototype._read = function (size) {\r\n  if (!size) size = 1024; // default size\r\n  var ready = true;\r\n  while (ready) { // only cont while push returns true\r\n    if (size > this.lenToGenerate) { // only this left\r\n      size = this.lenToGenerate;\r\n    }\r\n    if (size) {\r\n      ready = this.push(crypto.randomBytes(size));\r\n      this.lenToGenerate -= size;\r\n    }\r\n    // when done, push null and exit loop\r\n    if (!this.lenToGenerate) {\r\n      this.push(null);\r\n      ready = false;\r\n    }\r\n  }\r\n};\r\n// -- RandomStream End --\r\nconst fetch = require('node-fetch');\r\nconst runSuccess = async () => { // Runs in ~35 seconds\r\n  const t = Date.now();\r\n  try {\r\n    const resp = await fetch('http://localhost:8081/test', {\r\n      method: 'PUT',\r\n      body: new RandomStream(256e6) // new RandomStream(1024e6)\r\n    });\r\n    const data = await resp.text();\r\n    console.log(Date.now() - t, data);\r\n  } catch (err) {\r\n    console.warn(Date.now() - t, err);\r\n  }\r\n};\r\nconst runFail = async () => { // Fails after 60 seconds\r\n  const t = Date.now();\r\n  try {\r\n    const resp = await fetch('http://localhost:8081/test', {\r\n      method: 'PUT',\r\n      body: new RandomStream(1024e6)\r\n    });\r\n    const data = await resp.text();\r\n    console.log(Date.now() - t, data);\r\n  } catch (err) {\r\n    console.warn(Date.now() - t, err);\r\n  }\r\n};\r\n// runSuccess().then(() => process.exit(0));\r\nrunFail().then(() => process.exit(0));\r\n```\r\n\r\n- Install node-fetch in the same folder as the reproduction scripts: `npm i node-fetch`\r\n- Start the server with `node testServer.js` - This creates a new HTTP server listening on port 8081\r\n- Run the client with `node testClient.js`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThe value inside RandomStream needs to be high enough to cause the request to take longer than 60 seconds.\r\n\r\n### What is the expected behavior?\r\n\r\nIn Node.js 10:\r\n```\r\n$ node testClient.js\r\n145014 'OK'\r\n```\r\n\r\n### What do you see instead?\r\n\r\nIn Node.js 12:\r\n```\r\n$ node testClient.js\r\n60014 FetchError: request to http://localhost:8081/test failed, reason: write ECONNRESET\r\n    at ClientRequest.<anonymous> (/home/*snip*/node_modules/node-fetch/lib/index.js:1461:11)\r\n    at ClientRequest.emit (events.js:326:22)\r\n    at Socket.socketErrorListener (_http_client.js:428:9)\r\n    at Socket.emit (events.js:314:20)\r\n    at errorOrDestroy (internal/streams/destroy.js:108:12)\r\n    at onwriteError (_stream_writable.js:418:5)\r\n    at onwrite (_stream_writable.js:445:5)\r\n    at internal/streams/destroy.js:50:7\r\n    at Socket._destroy (net.js:681:5)\r\n    at Socket.destroy (internal/streams/destroy.js:38:8) {\r\n  type: 'system',\r\n  errno: 'ECONNRESET',\r\n  code: 'ECONNRESET'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\nIf there is any workaround, please let me know.\r\n",
        "labels": "confirmed-bug",
        "id": 44911
    },
    {
        "title": "fs.ftruncate silently accepts negative offsets rather than failing with ERR_INVALID",
        "body": "fs.ftruncate and fd.ftruncateSync both silently ignore negative offsets:\r\n\r\nhttps://github.com/nodejs/node/blob/2cfdf28413fd9a7bfab65cb49cff6e50ab0c21ec/lib/fs.js#L840\r\n\r\nThis didn't always do behave like this.. looks like it was introduced in 8974df15a973e97a74cf9fb0ccb45c11baa7b54a\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```\r\nvar fs = require(\"fs\");\r\nvar fd = fs.openSync(\"f\", 'w+');\r\nconsole.log(fs.ftruncateSync(fd, -99));\r\n```\r\n\r\n### What is the expected behavior?\r\n\r\nThe ftruncate POSIX function is described as returning EINVAL when given a negative offset:\r\nhttps://linux.die.net/man/2/ftruncate\r\n\r\nIn emscripten we emulate a POSIX environment on top of the Web and on top of node and expect ftruncate to fail in the same way. \r\n\r\nWe can obviously add a check to our code as a workaround but this does seem like a bug in node.\r\n\r\n### What do you see instead?\r\n\r\nSilently assumed `0` length is what the caller really wants.\r\n",
        "labels": "confirmed-bug",
        "id": 44912
    },
    {
        "title": "Segfault on v12.19.0",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:v12.19.0\r\n* **Platform**: RHEL\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\nUsing node js and running the component test with cucumber-js\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAfter Upgrading to v12.19.0 - issue has been consistent\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n/home/user1/GIT/cp1/r1/r1/node_modules/segfault-handler/build/Release/segfault-handler.node(+0x2c61)[0x7f9e881fbc61]\r\n/lib64/libpthread.so.0(+0xf6d0)[0x7f9ea0eb06d0]\r\nnode[0x9cf96e]\r\nnode(_ZN2v88internal13GlobalHandles40InvokeSecondPassPhantomCallbacksFromTaskEv+0x19b)[0xd17c4b]\r\nnode(_ZN2v88internal14CancelableTask3RunEv+0x23)[0xc953e3]\r\nnode(_ZN4node22PerIsolatePlatformData17RunForegroundTaskESt10unique_ptrIN2v84TaskESt14default_deleteIS3_EE+0xc4)[0xa86d54]\r\nnode(_ZN4node22PerIsolatePlatformData28FlushForegroundTasksInternalEv+0x165)[0xa87a15]\r\nnode[0x136f0ae]\r\nnode[0x1382165]\r\nnode(uv_run+0x11f)[0x136f8ef]\r\nnode(_ZN4node16NodeMainInstance3RunEv+0x1f6)[0xa5aac6]\r\nnode(_ZN4node5StartEiPPc+0x2ac)[0x9e85cc]\r\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x7f9ea0af6445]\r\nnode[0x9819b5]\r\n\r\n\r\n### Additional information\r\nI am using native code build with node-gyp \r\n\r\n",
        "labels": "confirmed-bug",
        "id": 44913
    },
    {
        "title": "Crash when using NODE_OPTIONS=--experimental-specifier-resolution=node with some .bin executables",
        "body": "* **Version**: 14.13.0\r\n* **Platform**: macOS 10.15.6\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n`NODE_OPTIONS=--experimental-specifier-resolution=node node_modules/.bin/semver --version`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n100%\r\n\r\n### What is the expected behavior?\r\nRuns just like when `NODE_OPTIONS` isn't set\r\n\r\n### What do you see instead?\r\nThis error:\r\n```\r\ninternal/process/esm_loader.js:74\r\n    internalBinding('errors').triggerUncaughtException(\r\n                              ^\r\n\r\nTypeError [ERR_INVALID_RETURN_PROPERTY_VALUE]: Expected string to be returned for the \"format\" from the \"loader getFormat\" function but got type object.\r\n    at Loader.getFormat (internal/modules/esm/loader.js:110:13)\r\n    at async Loader.getModuleJob (internal/modules/esm/loader.js:230:20)\r\n    at async Loader.import (internal/modules/esm/loader.js:164:17)\r\n    at async Object.loadESM (internal/process/esm_loader.js:68:5) {\r\n  code: 'ERR_INVALID_RETURN_PROPERTY_VALUE'\r\n}\r\n```\r\n\r\n### Additional information\r\nAlso happens with `he`, `mocha`, `node-which`, and `tsc`\r\n",
        "labels": "confirmed-bug",
        "id": 44914
    },
    {
        "title": "[worker_threads]: Main thread receives Error object when the worker throws a primitive value",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.7.0\r\n* **Platform**: Darwin suin 18.7.0 Darwin Kernel Version 18.7.0: Mon Feb 10 21:08:45 PST 2020; root:xnu-4903.278.28~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: N/A\r\n\r\n### What steps will reproduce the bug?\r\n\r\nSummary: Since Node v14.7.0, when primitive values are thrown in a worker, the main thread receives it as Error objects.\r\n\r\nI'm not sure this is actually a bug. But I couldn't find out the information about this breaking change. So I have created this issue. If this is an expected change, please close this issue.\r\n\r\n```js\r\n// main.js\r\nconst { Worker } = require('worker_threads')\r\nconst worker = new Worker('./worker.js')\r\nconsole.log(process.versions.node)\r\nworker.on('error', err => {\r\n  console.error(err)\r\n})\r\n```\r\n\r\n```js\r\n// worker.js\r\nthrow 'Error was thrown in worker'\r\n```\r\n\r\nin Node v14.6.0:\r\n\r\n```\r\n$ node main.js\r\n14.6.0\r\nError was thrown in worker\r\n```\r\n\r\nin Node v14.7.0:\r\n\r\n```\r\n$ node main.js\r\n14.7.0\r\nError [ERR_UNHANDLED_ERROR]: Unhandled error. ('Error was thrown in worker')\r\n    at process.emit (events.js:303:17)\r\n    at emitUnhandledRejectionOrErr (internal/event_target.js:541:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (internal/event_target.js:356:9)\r\n    at MessagePort.exports.emitMessage (internal/per_context/messageport.js:18:26) {\r\n  code: 'ERR_UNHANDLED_ERROR',\r\n  context: 'Error was thrown in worker'\r\n}\r\n```\r\n\r\nOther primitives:\r\n\r\n<details>\r\n\r\n__Undefined__\r\n\r\n```js\r\n// worker.js\r\nthrow undefined\r\n```\r\n\r\n```\r\n$ node main.js\r\n14.6.0\r\nundefined\r\n\r\n$ node main.js\r\n14.7.0\r\nError [ERR_UNHANDLED_ERROR]: Unhandled error. (undefined)\r\n    at process.emit (events.js:303:17)\r\n    at emitUnhandledRejectionOrErr (internal/event_target.js:541:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (internal/event_target.js:356:9)\r\n    at MessagePort.exports.emitMessage (internal/per_context/messageport.js:18:26) {\r\n  code: 'ERR_UNHANDLED_ERROR',\r\n  context: undefined\r\n}\r\n```\r\n\r\n__Number__\r\n\r\n```js\r\n// worker.js\r\nthrow 0\r\n```\r\n\r\n```\r\n$ node main.js\r\n14.6.0\r\n0\r\n\r\n$ node main.js\r\n14.7.0\r\nError [ERR_UNHANDLED_ERROR]: Unhandled error. (0)\r\n    at process.emit (events.js:303:17)\r\n    at emitUnhandledRejectionOrErr (internal/event_target.js:541:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (internal/event_target.js:356:9)\r\n    at MessagePort.exports.emitMessage (internal/per_context/messageport.js:18:26) {\r\n  code: 'ERR_UNHANDLED_ERROR',\r\n  context: 0\r\n}\r\n```\r\n\r\n__Symbol__\r\n\r\n```js\r\n// worker.js\r\nthrow Symbol('this is a symbol')\r\n```\r\n\r\n```\r\n$ node main.js\r\n14.6.0\r\nSymbol(this is a symbol)\r\n\r\n$ node main.js\r\n14.7.0\r\nError [ERR_UNHANDLED_ERROR]: Unhandled error. (Symbol(this is a symbol))\r\n    at process.emit (events.js:303:17)\r\n    at emitUnhandledRejectionOrErr (internal/event_target.js:541:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (internal/event_target.js:356:9)\r\n    at MessagePort.exports.emitMessage (internal/per_context/messageport.js:18:26)\r\n```\r\n\r\n</details>\r\n\r\n\r\n\r\n\r\n\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThere is no condition.\r\n\r\n### What is the expected behavior?\r\n\r\nI'm not sure which is valid behavior, but at point of view of backward compatibilities, it would be the expected behavior that the main thread receives the unhandled primitive error as the primitive value instead of the Error object like the Node v14.6.0 behavior.\r\n\r\n### What do you see instead?\r\n\r\nThe main thread gets the Error object.\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44915
    },
    {
        "title": "Node 14.13 problematic (default?) import combinations",
        "body": "There are some import combinations which do not work together any longer (each import alone works fine)\r\n\r\n* **Version**:v14.13.0\r\n* **Platform**: Darwin mbpMarkus 19.6.0 Darwin Kernel Version 19.6.0: Mon Aug 31 22:12:52 PDT 2020; root:xnu-6153.141.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nimport recast from \"recast\";\r\nimport lockfile from '@yarnpkg/lockfile';\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways (starting with node 14.13)\r\n\r\n### What is the expected behavior?\r\ntwo default exports provided\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n```\r\nnode issue.mjs \r\nnode_modules/recast/lib/lines.js:580\r\n    assert_1.default.ok(tabWidth || tabless, \"No tab width specified but encountered tabs in string\\n\" + string);\r\n                     ^\r\n\r\nTypeError: assert_1.default.ok is not a function\r\n    at fromString (node_modules/recast/lib/lines.js:580:22)\r\n    at Object.<anonymous> (/node_modules/recast/lib/lines.js:654:18)\r\n    at Module._compile (internal/modules/cjs/loader.js:1085:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1114:10)\r\n    at Module.load (internal/modules/cjs/loader.js:950:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:791:14)\r\n    at Module.require (internal/modules/cjs/loader.js:974:19)\r\n    at require (internal/modules/cjs/helpers.js:88:18)\r\n    at Object.<anonymous> (node_modules/recast/lib/parser.js:11:15)\r\n    at Module._compile (internal/modules/cjs/loader.js:1085:30)\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\nSaw the problem with other combinations of imports to\r\n",
        "labels": "confirmed-bug",
        "id": 44916
    },
    {
        "title": "[v12.x] icu: broken date locale string format on zh-CN",
        "body": "* **Version**: v12.17.0-12.18.4\r\n* **Platform**: all\r\n* **Subsystem**: icu\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```\r\n$ LANG=zh_CN.UTF-8 node -p 'new Date().toLocaleString()'\r\n2020-9-28 3:33:35 â”œF10: PMâ”¤\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n\r\n\r\nnode v12.16.3 (small-icu, English only)\r\n```\r\n$ LANG=zh_CN.UTF-8 node -p 'new Date().toLocaleString()'\r\n2020-9-28 15:34:08\r\n```\r\n\r\nnode v14.12.0 (full-icu)\r\n```\r\n$ LANG=zh_CN.UTF-8 node -p 'new Date().toLocaleString()'\r\n2020/9/28 ä¸‹åˆ3:35:06\r\n```\r\n\r\nBoth cases are correct.\r\n\r\n### What do you see instead?\r\n\r\nInvalid and meaningless symbol characters \"â”œF10: PMâ”¤\" in localized strings.\r\n\r\n### Additional information\r\n\r\nReverting https://github.com/nodejs/node/pull/33337 (5c0232a632, 2d76ae7497) can fix the issue.\r\n",
        "labels": "confirmed-bug",
        "id": 44917
    },
    {
        "title": "fs.readFile does not account file system flag 'a+' in Node 14.11",
        "body": "I tried to find similar issues but couldn't, sorry if it is already reported.\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:\r\nv14.11.0\r\n* **Platform**:\r\nDarwin MacBook-Pro-Daniil.local 18.7.0 Darwin Kernel Version 18.7.0: Thu Jun 20 18:42:21 PDT 2019; root:xnu-4903.270.47~4/RELEASE_X86_64 x86_64\r\n\r\n### What steps will reproduce the bug?\r\n\r\nWith `a+` flag file should be created if it does not exist. It works with `readFileSync`, but fails with `readFile`\r\nThere is also similar problem with `w+` flag and maybe others, but I did not tested all of them.\r\n\r\n```js\r\nconst fs = require('fs');\r\n\r\nconst content = fs.readFileSync('./nonexistingfile1', {\r\n  encoding: 'utf-8',\r\n  flag: 'a+',\r\n});\r\n\r\nconsole.log(content); // content is empty string, so file was created\r\n\r\nfs.readFile(\r\n  './nonexistingfile2',\r\n  { encoding: 'utf-8', flag: 'a+' },\r\n  (err, data) => {\r\n    console.log(err, data);\r\n    // [Error: ENOENT: no such file or directory, open './nonexistingfile2'] {\r\n    //   errno: -2,\r\n    //   code: 'ENOENT',\r\n    //   syscall: 'open',\r\n    //   path: './nonexistingfile2'\r\n    // }\r\n  }\r\n);\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways with node v14.11\r\nWorks fine in node v12.18.4\r\n\r\n### What is the expected behavior?\r\n\r\nFile is created before reading and there is no ENOENT error\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nENOENT error\r\n\r\n```\r\n    [Error: ENOENT: no such file or directory, open './nonexistingfile2'] {\r\n      errno: -2,\r\n      code: 'ENOENT',\r\n      syscall: 'open',\r\n      path: './nonexistingfile2'\r\n    }\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 44918
    },
    {
        "title": "http2: Node crashes with an assertion error if an http2 server is closed after receiving and rejecting very large headers",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 14.10.0\r\n* **Platform**: Linux DESKTOP-OKC3QBQ 4.4.0-18362-Microsoft #1049-Microsoft Thu Aug 14 12:01:00 PST 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: http2\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst http2 = require('http2');\r\n\r\nconst server = http2.createServer({\r\n  maxSendHeaderBlockLength: Number.MAX_SAFE_INTEGER\r\n});\r\n\r\nserver.on('stream', (stream, headers) => {\r\n  stream.respond();\r\n  stream.end();\r\n});\r\n\r\nserver.listen(8080, () => {\r\n  const clientSession = http2.connect('http://localhost:8080', {\r\n    maxSendHeaderBlockLength: Number.MAX_SAFE_INTEGER\r\n  });\r\n\r\n  clientSession.on('error', (error) => {\r\n    console.log(error);\r\n  })\r\n\r\n  const stream = clientSession.request({\r\n    'test-header': 'A'.repeat(90000)\r\n  });\r\n\r\n  stream.on('close', () => {\r\n    console.log(`Stream closed with RST_STREAM code ${stream.rstCode}`);\r\n    server.close();\r\n  });\r\n\r\n  stream.on('error', (error) => {\r\n    console.log(error);\r\n  })\r\n\r\n  stream.end();\r\n});\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThis reproduction is 100% consistent.\r\n\r\n### What is the expected behavior?\r\n\r\n```\r\nError [ERR_HTTP2_SESSION_ERROR]: Session closed with error code 9\r\n    at Http2Session.onGoawayData (internal/http2/core.js:642:21) {\r\n  code: 'ERR_HTTP2_SESSION_ERROR'\r\n}\r\nStream closed with RST_STREAM code 9\r\nError [ERR_HTTP2_SESSION_ERROR]: Session closed with error code 9\r\n    at Http2Session.onGoawayData (internal/http2/core.js:642:21) {\r\n  code: 'ERR_HTTP2_SESSION_ERROR'\r\n}\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n```\r\nError [ERR_HTTP2_SESSION_ERROR]: Session closed with error code 9\r\n    at Http2Session.onGoawayData (internal/http2/core.js:642:21) {\r\n  code: 'ERR_HTTP2_SESSION_ERROR'\r\n}\r\nStream closed with RST_STREAM code 9\r\nError [ERR_HTTP2_SESSION_ERROR]: Session closed with error code 9\r\n    at Http2Session.onGoawayData (internal/http2/core.js:642:21) {\r\n  code: 'ERR_HTTP2_SESSION_ERROR'\r\n}\r\nnode[5776]: ../src/node_http2.cc:522:virtual node::http2::Http2Session::~Http2Session(): Assertion `(current_nghttp2_memory_) == (0)' failed.\r\n 1: 0xa02dd0 node::Abort() [node]\r\n 2: 0xa02e4e  [node]\r\n 3: 0xa274aa node::http2::Http2Session::~Http2Session() [node]\r\n 4: 0xa27611 node::http2::Http2Session::~Http2Session() [node]\r\n 5: 0x9a9dbb node::Environment::RunCleanup() [node]\r\n 6: 0x96d3d7 node::FreeEnvironment(node::Environment*) [node]\r\n 7: 0xa42d6f node::NodeMainInstance::Run() [node]\r\n 8: 0x9d10e5 node::Start(int, char**) [node]\r\n 9: 0x7f9b63f60830 __libc_start_main [/lib/x86_64-linux-gnu/libc.so.6]\r\n10: 0x9697bc  [node]\r\nAborted (core dumped)\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nThis is related to #35218 regarding the handling of very large request headers.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44919
    },
    {
        "title": "Promise.reject() crashes repl when using --unhandled-rejections=strict",
        "body": "* **Version**: 14.11.0\r\n* **Platform**: macOS Catalina 10.15.6\r\n\r\nI have also reproduced this in Node 12.18.4.\r\n\r\n### What steps will reproduce the bug?\r\n\r\nLaunch the repl with this command:\r\n\r\n```\r\nnode --unhandled-rejections=strict\r\n```\r\n\r\n(`--unhandled-rejections=throw` has the same issue.)\r\n\r\nOn the repl command line, type `Promise.reject()`.\r\n\r\n### What is the expected behavior?\r\n\r\nWhen an uncaught error is thrown in the repl, the repl should print \"Uncaught error\" without terminating the process. For example:\r\n\r\n```\r\n> throw new Error()\r\nUncaught Error\r\n> void setTimeout(_=>{throw new Error()}, 0)\r\nundefined\r\n> Uncaught Error\r\n```\r\n\r\n### What do you see instead?\r\n\r\nThe process crashes.\r\n\r\n```\r\n> Promise.reject()\r\nPromise { <rejected> undefined }\r\n> internal/process/promises.js:213\r\n        triggerUncaughtException(err, true /* fromPromise */);\r\n        ^\r\n\r\n[UnhandledPromiseRejection: This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). The promise rejected with the reason \"undefined\".] {\r\n  code: 'ERR_UNHANDLED_REJECTION'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\nThis bug will become more important in Node 15 when `--unhandled-rejections=throw` becomes the default, per PR #33021. At that point, the bug will repro when launching `node` using the default settings with no flags.",
        "labels": "confirmed-bug",
        "id": 44920
    },
    {
        "title": "esm: provide more detailed error message when named import of cjs module",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWhen I try to make named import for commonjs package, error throws:\r\n```\r\nThe requested module 'redux' is expected to be of type CommonJS, which does not support named exports. CommonJS modules can be imported by importing the default export.\r\nFor example:\r\nimport pkg from 'redux';\r\nconst { compose } = pkg;\r\n```\r\n\r\nIn large project it can be hard to find in which file error is thrown\r\n\r\n**Describe the solution you'd like**\r\nIt would be great append path to module, where \r\n```\r\nThe requested from '/path/to/module.js' module 'redux' is expected to be of type CommonJS, which does not support named exports. CommonJS modules can be imported by importing the default export.\r\nFor example:\r\nimport pkg from 'redux';\r\nconst { compose } = pkg;\r\n```",
        "labels": "confirmed-bug",
        "id": 44921
    },
    {
        "title": "Coredump when passing `undefined` as address from custom `lookup` function",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.15.0\r\n* **Platform**: Linux desktop-home 5.4.53 #1-NixOS SMP Wed Jul 22 07:33:18 UTC 2020 x86_64 GNU/Linux\r\n* **Subsystem**: net / TCP\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\n\"use strict\";\r\n\r\nconst http = require(\"http\");\r\n\r\nhttp.get({\r\n\thost: \"google.com:80\",\r\n\tpath: \"/\",\r\n\tlookup: function (host, options, callback) {\r\n\t\tcallback(null, undefined, 4);\r\n\t\t// Note the `undefined` here instead of an IP!\r\n\t}\r\n});\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nCompletely reproducible.\r\n\r\n### What is the expected behavior?\r\n\r\nShould produce a (catchable/handleable) error indicating that an invalid value was passed from `lookup` rather than aborting, since this is public API.\r\n\r\n### What do you see instead?\r\n\r\n```\r\nnode[18969]: ../src/tcp_wrap.cc:312:static void node::TCPWrap::Connect(const v8::FunctionCallbackInfo<v8::Value>&, std::function<int(const char*, T*)>) [with T = sockaddr_in]: Assertion `args[1]->IsString()' failed.\r\n 1: 0x9345f8 node::Abort() [node]\r\n 2: 0x934691  [node]\r\n 3: 0x9fda20 void node::TCPWrap::Connect<sockaddr_in>(v8::FunctionCallbackInfo<v8::Value> const&, std::function<int (char const*, sockaddr_in*)>) [node]\r\n 4: 0x9fc95c node::TCPWrap::Connect(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 5: 0xb0e819 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [node]\r\n 6: 0xb0ebd0  [node]\r\n 7: 0xb0fa6a  [node]\r\n 8: 0xb0fcf9 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 9: 0x12af4f9  [node]\r\nAborted (core dumped)\r\n```\r\n\r\n### Additional information\r\n\r\nN/A",
        "labels": "confirmed-bug",
        "id": 44922
    },
    {
        "title": "url.pathToFileURL doesn't generate valid URLs for UNC paths",
        "body": "\r\n* Node.js version: v12.18.3 and v14.8.0\r\n\r\n* Platform: Windows 10 (10.0.19041)\r\n\r\n* Subsystem: `url`\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst url = require(\"url\")\r\nurl.pathToFileURL(\"\\\\\\\\laptop\\\\My Documents\\\\FileSchemeURIs.doc\")\r\n```\r\n\r\n### Expected behavior\r\n\r\nAs per [Microsoft's UNC URI documentation](https://docs.microsoft.com/en-us/archive/blogs/ie/file-uris-in-windows)):\r\n\r\n`file://laptop/My%20Documents/FileSchemeURIs.doc`\r\n\r\n### Actual behavior\r\n\r\n```\r\nURL {\r\n  href: 'file:///laptop/My%20Documents/FileSchemeURIs.doc',\r\n  origin: 'null',\r\n  protocol: 'file:',\r\n  username: '',\r\n  password: '',\r\n  host: '',\r\n  hostname: '',\r\n  port: '',\r\n  pathname: '/laptop/My%20Documents/FileSchemeURIs.doc',\r\n  search: '',\r\n  searchParams: URLSearchParams {},\r\n  hash: ''\r\n}\r\n```\r\n\r\n1. `hostname` should be `laptop` (not `''`).\r\n\r\n2.  `pathname` should be `/My%20Documents/FileSchemeURIs.doc` (not be prefixed by `/laptop/`).\r\n",
        "labels": "confirmed-bug",
        "id": 44923
    },
    {
        "title": "http data streaming Error: socket hang up after 60 seconds (tested on windows)",
        "body": "\r\nThis works fine on node 12>18 LTS\r\n\r\nVersion: v14.7.0`\r\nPlatform: windows 10 64 bit and windows server \r\n\r\n-->\r\n\r\n* **Version**:\r\n### What steps will reproduce the bug?\r\n\r\nClient code:\r\n```\r\nhttp=require('http')\r\n  // An object of options to indicate where to post to\r\n  var post_options = {\r\n    host: '127.0.0.1', //'34.255.202.222',\r\n    port: '80',\r\n    path: '/test',\r\n    method: 'POST',\r\n    headers: {        \r\n        'Content-Type': 'text/html; charset=UTF-8'        \r\n    }\r\n};\r\n\r\n// Set up the request\r\nvar post_req = http.request(post_options, function(res) {    \r\n    res.on('data', function (chunk) {\r\n        console.log('Response: ' + chunk);\r\n    });\r\n});\r\n\r\n// post the data\r\nsetInterval(() => {\r\n    post_req.write(`another chunk ${new Date()}`); \r\n}, 100);\r\n```\r\n\r\n\r\nServer code:\r\n```\r\nconst http = require('http')\r\n\r\nconst server = http.createServer(function(request, response) {\r\n  if (request.method == 'POST') {\r\n    response.writeHead(200, {'Content-Type': 'text/html'})\r\n    console.log('POST')\r\n    let zz=0;\r\n    request.on('data', function(data) {\r\n      zz += data.length;\r\n      process.stdout.write(\"Downloading \" +data+\" \"+ zz/1000 + \" bytes\\r\");\r\n       \r\n    })\r\n    request.on('end', function() {\r\n      console.log('Body: ' + zz)\r\n      \r\n      response.end('post received')\r\n    })\r\n  } \r\n  })\r\nconst port = 80\r\nconst host = '127.0.0.1'\r\nserver.keepAliveTimeout=100000;\r\nserver.listen(port)\r\nconsole.log(`Listening at http://${host}:${port}`)\r\n```\r\n\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways\r\n\r\n### What is the expected behavior?\r\nSoctet will continue \r\n\r\n### What do you see instead?\r\n\r\n```\r\n\r\nevents.js:291\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: socket hang up\r\n\u001b[90m    at connResetException (internal/errors.js:612:14)\u001b[39m\r\n\u001b[90m    at Socket.socketOnEnd (_http_client.js:493:23)\u001b[39m\r\n\u001b[90m    at Socket.emit (events.js:326:22)\u001b[39m\r\n\u001b[90m    at endReadableNT (_stream_readable.js:1244:12)\u001b[39m\r\n\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\r\nEmitted 'error' event on ClientRequest instance at:\r\n\u001b[90m    at Socket.socketOnEnd (_http_client.js:493:9)\u001b[39m\r\n\u001b[90m    at Socket.emit (events.js:326:22)\u001b[39m\r\n\u001b[90m    at endReadableNT (_stream_readable.js:1244:12)\u001b[39m\r\n\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m {\r\n  code: \u001b[32m'ECONNRESET'\u001b[39m\r\n}\r\n\r\n`",
        "labels": "confirmed-bug",
        "id": 44924
    },
    {
        "title": "dns.resolveSoa returns EBADRESP if hostname has a CNAME record",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version(s)**: v12.16.3 / v12.18.3 / v12.18.0\r\n* **Platform**: Windows / Windows Subsystem for Linux (Debian) / Red Hat Enterprise Linux Server release 7.8\r\n* **Subsystem**: DNS\r\n\r\n### What steps will reproduce the bug?\r\n```\r\nconst dns = require('dns');\r\nconst resolver = new dns.promises.Resolver();\r\n\r\n// **************************************************************\r\n\r\nasync function test(hostname) {\r\n  let data = '';\r\n\r\n  console.log('hostname:', hostname);\r\n\r\n  try {\r\n    data = await resolver.resolveCname(hostname);\r\n    console.log('CNAME result:', data);\r\n  } catch (error) {\r\n    console.log('CNAME result:', error.message);\r\n  }\r\n\r\n  try {\r\n    data = await resolver.resolveSoa(hostname);\r\n    console.log('SOA result:', JSON.stringify(data));\r\n  } catch (error) {\r\n    console.log('SOA result:', error.message);\r\n  }\r\n\r\n  console.log();\r\n}\r\n\r\n// **************************************************************\r\n\r\n(async function main() {\r\n  await test('support.microsoft.com');\r\n})();\r\n```\r\n\r\n### Actual Results\r\nhostname: support.microsoft.com\r\nCNAME result: [ 'ev.support.microsoft.com.edgekey.net' ]\r\nSOA result: querySoa EBADRESP support.microsoft.com\r\n\r\n### Expected Results\r\nhostname: support.microsoft.com\r\nCNAME result: [ 'ev.support.microsoft.com.edgekey.net' ]\r\nSOA result: querySoa ENODATA support.microsoft.com\r\n\r\n### Additional information\r\nThis seems to happen for any hostname with a CNAME record.\r\n\r\nAnother example:\r\n\r\nhostname: store.gocomics.com\r\nCNAME result: [ 'gocomicsstore.wpengine.com' ]\r\nSOA result: querySoa EBADRESP store.gocomics.com\r\n\r\nI would expect to get an 'ENODATA' instead of 'EBADRESP', as with the other resolveXXX() calls.\r\n\r\nFor a hostname with an SOA record but no CNAME, you get:\r\n\r\nhostname: microsoft.com\r\nCNAME result: queryCname ENODATA microsoft.com\r\nSOA result: {\"nsname\":\"ns1-205.azure-dns.com\",\"hostmaster\":\"azuredns- \r\n hostmaster.microsoft.com\",\"serial\":1,\"refresh\":3600,\"retry\":300,\"expire\":2419200,\"minttl\":300}\r\n",
        "labels": "confirmed-bug",
        "id": 44925
    },
    {
        "title": "Crash at v8::Object::GetRealNamedPropertyAttributes",
        "body": "* **Version**:\r\nv14.6.0\r\n\r\n* **Platform**:\r\nubuntu 19.04\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst vm = require('vm');\r\n\r\nvar handler = {\r\n    getOwnPropertyDescriptor: () => {\r\n        return {};\r\n    }\r\n};\r\n\r\nconst source = `p=6`;\r\n\r\nvar proxy = new Proxy({}, handler);\r\nconst ctx = vm.createContext(proxy);\r\n\r\nscript = new vm.Script(source);\r\nscript.runInContext(ctx);\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nnothing\r\n\r\n### What is the expected behavior?\r\nno error\r\n\r\n### What do you see instead?\r\ncrash\r\n\r\n![image](https://user-images.githubusercontent.com/61380567/89140737-7fcd2300-d57d-11ea-8855-d4adc7878c3d.png)\r\nattachment [core.zip](https://github.com/nodejs/node/files/5013582/core.zip)\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 44926
    },
    {
        "title": "fs.rmdirSync stuck in busy-loop on Windows",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.18.3\r\n* **Platform**: Windows 10, 64-bit, Version 10.0.17763.1339\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```\r\nconst fs = require('fs');\r\nconst { tmpdir } = require('os');\r\nconst { join } = require('path');\r\n\r\nfunction rmdirRecursiveSync() {\r\n  const root = fs.mkdtempSync(join(tmpdir(), 'fs-'));\r\n\r\n  const middle = join(root, 'middle');\r\n  fs.mkdirSync(middle);\r\n  fs.mkdirSync(join(middle, 'leaf')); // make `middle` non-empty\r\n  fs.chmodSync(middle, 0);\r\n\r\n  fs.rmdirSync(root, { recursive: true });\r\n}\r\n\r\nrmdirRecursiveSync();\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThe bug reliably reprodices on windows.\r\n\r\n### What is the expected behavior?\r\n\r\nI expect `fs.rmdirSync()` to fail the same way as `fs.rmdir()` does. But it does not.\r\n\r\nLinux produces expected behavior throwing an error:\r\n\r\n```\r\nError: EACCES: permission denied, scandir '/tmp/fs-0wJvqH/middle'\r\n    at readdirSync (fs.js:948:3)\r\n    at _rmdirSync (internal/fs/rimraf.js:242:7)\r\n    at rimrafSync (internal/fs/rimraf.js:191:7)\r\n    at internal/fs/rimraf.js:245:9\r\n    at Array.forEach (<anonymous>)\r\n    at _rmdirSync (internal/fs/rimraf.js:242:45)\r\n    at rimrafSync (internal/fs/rimraf.js:191:7)\r\n    at Object.rmdirSync (fs.js:838:12)\r\n    at rmdirRecursiveSync (/â€¦/rmdirRecursiveSync.js:13:6)\r\n    at Object.<anonymous> (/â€¦/rmdirRecursiveSync.js:16:1) {\r\n  errno: -13,\r\n  syscall: 'scandir',\r\n  code: 'EACCES',\r\n  path: '/tmp/fs-0wJvqH/middle'\r\n}\r\n```\r\n\r\nWindows async `fs.rmdir({recursive:true})` instead of `fs.rmdirSync()` gives expected behavior as well, it passes an error to the callback:\r\n\r\n```\r\n[Error: EPERM: operation not permitted, rmdir 'C:\\â€¦\\Temp\\fs-vJZvJ7\\middle'] {\r\n  errno: -4048,\r\n  code: 'EPERM',\r\n  syscall: 'rmdir',\r\n  path: 'C:\\\\â€¦\\\\Temp\\\\fs-vJZvJ7\\\\middle'\r\n}\r\n```\r\n\r\n### What do you see instead?\r\n\r\nNode process is stuck with 100%-CPU busy-loop.\r\n\r\n### Additional information\r\n\r\n[Process Monitor](https://docs.microsoft.com/en-us/sysinternals/downloads/procmon) suggests a busy-loop while endlessly retrying to delete a file, the log excerpt is pasted below:\r\n\r\n```\r\n\"Time of Day\",\"Operation\",\"Path\",\"Result\",\"Detail\"\r\n...\r\n\"2:02:16.0518106 PM\",\"SetDispositionInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"CANNOT DELETE\",\"Delete: True\"\r\n\"2:02:16.0518663 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0527830 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Data/List Directory, Read Attributes, Synchronize, Disposition: Open, Options: Synchronous IO Non-Alert, Open For Backup, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0528985 PM\",\"QueryDirectory\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"0: ., 1: .., FileInformationClass: FileDirectoryInformation\"\r\n\"2:02:16.0529916 PM\",\"QueryDirectory\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"NO MORE FILES\",\"\"\r\n\"2:02:16.0530399 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0543568 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Attributes, Synchronize, Disposition: Open, Options: Synchronous IO Non-Alert, Open For Backup, Open Reparse Point, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0544702 PM\",\"QueryAllInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"BUFFER OVERFLOW\",\"CreationTime: 7/31/2020 12:40:00 PM, LastAccessTime: 7/31/2020 2:02:14 PM, LastWriteTime: 7/31/2020 12:40:00 PM, ChangeTime: 7/31/2020 12:40:00 PM, FileAttributes: RD, AllocationSize: 0, EndOfFile: 0, NumberOfLinks: 1, DeletePending: False, Directory: True, IndexNumber: 0x100000007cc38, EaSize: 0, Access: Read Attributes, Synchronize, Position: 0, Mode: Synchronous IO Non-Alert, AlignmentRequirement: Word\"\r\n\"2:02:16.0545350 PM\",\"QueryInformationVolume\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"BUFFER OVERFLOW\",\"VolumeCreationTime: 3/19/2019 10:40:48 PM, VolumeSerialNumber: B4A6-FEC6, SupportsObjects: True, VolumeLabel: WinÇ´\"\r\n\"2:02:16.0545884 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0554352 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Attributes, Delete, Synchronize, Disposition: Open, Options: Directory, Synchronous IO Non-Alert, Open For Backup, Open Reparse Point, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0555403 PM\",\"QueryAttributeTagFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Attributes: RD, ReparseTag: 0x0\"\r\n\"2:02:16.0555972 PM\",\"SetDispositionInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"CANNOT DELETE\",\"Delete: True\"\r\n\"2:02:16.0557121 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0565707 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Data/List Directory, Read Attributes, Synchronize, Disposition: Open, Options: Synchronous IO Non-Alert, Open For Backup, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0566833 PM\",\"QueryDirectory\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"0: ., 1: .., FileInformationClass: FileDirectoryInformation\"\r\n\"2:02:16.0568326 PM\",\"QueryDirectory\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"NO MORE FILES\",\"\"\r\n\"2:02:16.0569022 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0572185 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Attributes, Synchronize, Disposition: Open, Options: Synchronous IO Non-Alert, Open For Backup, Open Reparse Point, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0573269 PM\",\"QueryAllInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"BUFFER OVERFLOW\",\"CreationTime: 7/31/2020 12:40:00 PM, LastAccessTime: 7/31/2020 2:02:14 PM, LastWriteTime: 7/31/2020 12:40:00 PM, ChangeTime: 7/31/2020 12:40:00 PM, FileAttributes: RD, AllocationSize: 0, EndOfFile: 0, NumberOfLinks: 1, DeletePending: False, Directory: True, IndexNumber: 0x100000007cc38, EaSize: 0, Access: Read Attributes, Synchronize, Position: 0, Mode: Synchronous IO Non-Alert, AlignmentRequirement: Word\"\r\n\"2:02:16.0573616 PM\",\"QueryInformationVolume\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"BUFFER OVERFLOW\",\"VolumeCreationTime: 3/19/2019 10:40:48 PM, VolumeSerialNumber: B4A6-FEC6, SupportsObjects: True, VolumeLabel: WinÇ´\"\r\n\"2:02:16.0573888 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0576180 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Attributes, Delete, Synchronize, Disposition: Open, Options: Directory, Synchronous IO Non-Alert, Open For Backup, Open Reparse Point, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0576756 PM\",\"QueryAttributeTagFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Attributes: RD, ReparseTag: 0x0\"\r\n\"2:02:16.0577024 PM\",\"SetDispositionInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"CANNOT DELETE\",\"Delete: True\"\r\n...\r\n```",
        "labels": "confirmed-bug",
        "id": 44927
    },
    {
        "title": "AsyncLocalStorage: Cannot read property 'Symbol(kResourceStore)'",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.6.0 (works on v14.5.0)\r\n* **Platform**: Unix\r\n* **Subsystem**: async_hooks\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\nI'm not entirely sure yet, but will continue investigating. Any pointers would be appreciated. \r\n\r\nSadly the code itself is private, but I'll try to extract a reproduction.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nI only see this crash reliably on every test run on one of our services, all the others seem to work fine.\r\n\r\nThe service works on v14.4.0 and v14.5.0, so this seems to be a regression introduced in v14.6.0.\r\n\r\n### What is the expected behavior?\r\n\r\nWorking AsyncLocalStorage.\r\n\r\n### What do you see instead?\r\n\r\nAn exception\r\n\r\n```\r\nTypeError: Cannot read property 'Symbol(kResourceStore)' of undefined\r\n    at AsyncLocalStorage._propagate (async_hooks.js:246:34)\r\n    at AsyncHook.init (async_hooks.js:222:22)\r\n    at emitInitNative (internal/async_hooks.js:198:43)\r\n    at emitInitScript (internal/async_hooks.js:466:3)\r\n    at initAsyncResource (internal/timers.js:155:5)\r\n    at new Timeout (internal/timers.js:188:3)\r\n    at setUnrefTimeout (internal/timers.js:370:17)\r\n    at cache (internal/http.js:27:3)\r\n    at utcDate (internal/http.js:19:18)\r\n    at ServerResponse._storeHeader (_http_outgoing.js:391:26)\r\n    at ServerResponse.writeHead (_http_server.js:313:8)\r\n    at ServerResponse._implicitHeader (_http_server.js:240:8)\r\n    at write_ (_http_outgoing.js:663:9)\r\n    at ServerResponse.end (_http_outgoing.js:776:5)\r\n    at /app/node_modules/@opentelemetry/plugin-http/build/src/http.js:213:87\r\n    at HttpPlugin._safeExecute (/app/node_modules/@opentelemetry/plugin-http/build/src/http.js:303:20)\r\n    at ServerResponse.response.end (/app/node_modules/@opentelemetry/plugin-http/build/src/http.js:213:49)\r\n```\r\n\r\nLikely the result of `executionAsyncResource()` returning `undefined` here:\r\nhttps://github.com/nodejs/node/blob/13c5a1629cd025ba560f34f6d3190b2f38d184d4/lib/async_hooks.js#L219\r\n\r\n### Additional information\r\n\r\nAsyncLocalStorage is used using https://github.com/open-telemetry/opentelemetry-js/tree/v0.10.1 and via the `AsyncLocalStorageContextManager` https://github.com/open-telemetry/opentelemetry-js/blob/v0.10.1/packages/opentelemetry-context-async-hooks/src/AsyncLocalStorageContextManager.ts\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44928
    },
    {
        "title": "Windows fs symlink TypeError on Buffer target value",
        "body": "* **Version**: 14.5.0+\r\n* **Platform**: Windows 10 x64\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\nOn Windows:\r\n\r\n```js\r\nconst fs = require('fs');\r\nfs.symlinkSync(Buffer.from('target'), 'link');\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways happens on Windows since 14.5.0, it may be necessary to enable symlink support on Windows (I'm not 100% sure how that all works). Does not happen on Linux or macOS.\r\n\r\n### What is the expected behavior?\r\n\r\nNo error, and the symlink should be created. [Buffer is listed as a valid target type.](https://nodejs.org/api/fs.html#fs_fs_symlinksync_target_path_type)\r\n\r\n### What do you see instead?\r\n\r\n> TypeError [ERR_INVALID_ARG_TYPE]: The \"path\" argument must be of type string. Received an instance of Buffer\r\n\r\n```\r\ninternal/validators.js:121\r\n    throw new ERR_INVALID_ARG_TYPE(name, 'string', value);\r\n    ^\r\n\r\nTypeError [ERR_INVALID_ARG_TYPE]: The \"path\" argument must be of type string. Received an instance of Buffer\r\n    at validateString (internal/validators.js:121:11)\r\n    at Object.isAbsolute (path.js:353:5)\r\n    at preprocessSymlinkDestination (internal/fs/utils.js:345:18)\r\n    at Object.symlinkSync (fs.js:1118:19)\r\n    at Object.<anonymous> (C:\\Users\\travis\\build\\AlexanderOMara\\issue-node-symlink-buffer-windows\\main.js:5:4)\r\n    at Module._compile (internal/modules/cjs/loader.js:1236:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1257:10)\r\n    at Module.load (internal/modules/cjs/loader.js:1085:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:950:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:60:12) {\r\n  code: 'ERR_INVALID_ARG_TYPE'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\nI created [a test repo](https://github.com/AlexanderOMara/issue-node-symlink-buffer-windows) which [is tested via Travis CI](https://travis-ci.com/github/AlexanderOMara/issue-node-symlink-buffer-windows/builds/177173620).\r\n\r\nOn a side-note, the `path` argument can be a Buffer, it's just the `target` argument with the issue.\r\n",
        "labels": "confirmed-bug",
        "id": 44929
    },
    {
        "title": "stream: non-readable Duplex async construct race condition",
        "body": "@nodejs/streams @ronag\r\n\r\nTry..\r\n\r\n```js\r\nconst { Duplex } = require('stream');\r\n\r\nclass M extends Duplex {\r\n  constructor() {\r\n    super({ readable: false });\r\n  }\r\n\r\n  _construct(callback) {\r\n    setTimeout(() => {\r\n      console.log(1);\r\n      callback();\r\n    }, 2000);\r\n  }\r\n\r\n  _write(chunk, encoding, callback) {\r\n    console.log(chunk.toString());\r\n    callback();\r\n  }\r\n\r\n  _read() {\r\n    this.push(null);\r\n  }\r\n}\r\n\r\nconst m = new M();\r\nm.resume();\r\nm.end('foo');\r\nm.on('close', () => console.log('destroyed'));\r\n```\r\n\r\nOutputs:\r\n\r\n```\r\nfoo\r\ndestroyed\r\n1\r\n```\r\n\r\nNote that the auto-destruction of the `Duplex` does not appropriately wait for the completion of the async `_construct()`. Changing the construction options to `{ readable: true }` causes the code to work as expected:\r\n\r\n```js\r\nconst { Duplex } = require('stream');\r\n\r\nclass M extends Duplex {\r\n  constructor() {\r\n    super({ readable: true});\r\n  }\r\n\r\n  _construct(callback) {\r\n    setTimeout(() => {\r\n      console.log(1);\r\n      callback();\r\n    }, 2000);\r\n  }\r\n\r\n  _write(chunk, encoding, callback) {\r\n    console.log(chunk.toString());\r\n    callback();\r\n  }\r\n\r\n  _read() {\r\n    this.push(null);\r\n  }\r\n}\r\n\r\nconst m = new M();\r\nm.resume();\r\nm.end('foo');\r\nm.on('close', () => console.log('destroyed'));\r\n```\r\n\r\nOutputs:\r\n\r\n```\r\nfoo\r\n1\r\ndestroyed\r\n```",
        "labels": "confirmed-bug",
        "id": 44930
    },
    {
        "title": "AsyncLocalStorage does not work with http.Agent",
        "body": "* **Version**: 14.5.0\r\n* **Platform**: macos\r\n* **Subsystem**: async_hooks\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\n'use strict';\r\n\r\nconst http = require('http');\r\nconst { AsyncLocalStorage } = require('async_hooks');\r\n\r\nconst session = new AsyncLocalStorage();\r\n\r\nconst agent = new http.Agent({\r\n  maxSockets: 1\r\n});\r\n\r\nconst get = (path, callback) => {\r\n  http.request({\r\n    agent,\r\n    host: 'example.com',\r\n\r\n    method: 'GET',\r\n    path,\r\n  }, callback).end();\r\n};\r\n\r\nlet id = 0;\r\nconst server = http.createServer((req, res) => {\r\n  session.run(id++, () => {\r\n    console.error('new req', session.getStore());\r\n    get('/', (remote) => {\r\n      console.error('remote response', session.getStore());\r\n      remote.pipe(res);\r\n    });\r\n  });\r\n}).listen(0, () => {\r\n  const { port } = server.address();\r\n  http.request({ port }).end();\r\n  http.request({ port }).end();\r\n});\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways. No conditions.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nI expect this code to print:\r\n```\r\nnew req 0\r\nnew req 1\r\nremote response 0\r\nremote response 1\r\n```\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n```\r\nnew req 0\r\nnew req 1\r\nremote response 0\r\nremote response 0\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nThis is very much expected behavior of CLS storage. Any sort of pooling would result in similar issues. What's concerning is that it can happen with use of an existing core primitive (`http.Agent`). In fact, use of any agent with `maxSockets !== Infinity` or `keepAlive` set to `true` would result in similar behavior.\r\n\r\nThis behavior can be documented, but I'd imagine that such documentation would look like an incompatibility within Node.js core. Given that whole `async_hooks` module experimental - should we consider removing `AsyncLocalStorage` instead?\r\n\r\ncc @nodejs/collaborators ",
        "labels": "confirmed-bug",
        "id": 44931
    },
    {
        "title": "fsPromises.truncate doesn't close fd.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.18.1\r\n* **Platform**: Linux 5.4.0-37-generic #41-Ubuntu SMP x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\nfsPromises.truncate(path) will result in a warning a few seconds later: `(node:1387179) Warning: Closing file descriptor 22 on garbage collection` - Using the callback truncate `await new Promise((res, rej) => { fs.truncate(file, (err, ret) => { if(err) rej(err); else res(ret) }) })` works fine without such warning.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEvery time.\r\n\r\n### What is the expected behavior?\r\n\r\nNot having this warning.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44932
    },
    {
        "title": "DEP0097 warning triggered in REPL.",
        "body": "* **Version**: v15.0.0-pre\r\n* **Platform**: Linux 4.15.0-108-generic #109-Ubuntu SMP Fri Jun 19 11:33:10 UTC 2020 x86_64 \r\n* **Subsystem**: REPL\r\n\r\n### What steps will reproduce the bug?\r\n1. Run Node REPL.\r\n2. Choose your favorite global object.\r\n3. Type it into the REPL with the dot-style property accessor like so: `<global object>.`\r\n4. Hit tab.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways.\r\n\r\n### What is the expected behavior?\r\nDeprecation warning is not shown.\r\n\r\n### What do you see instead?\r\nDeprecation warning is shown.\r\n\r\n```\r\n./node --trace-deprecation\r\nWelcome to Node.js v15.0.0-pre.\r\nType \".help\" for more information.\r\n> Array. /* hit tab */\r\nArray.__defineGetter__      Array.__defineSetter__      Array.__lookupGetter__      Array.__lookupSetter__      Array.__proto__             Array.hasOwnProperty        Array.isPrototypeOf\r\nArray.propertyIsEnumerable  Array.toLocaleString        Array.valueOf\r\n\r\nArray.apply                 Array.arguments             Array.bind                  Array.call                  Array.caller                Array.constructor           Array.toString\r\n\r\nArray.from                  Array.isArray               Array.length                Array.name                  Array.of                    Array.prototype\r\n\r\n> Array.(node:13081) [DEP0097] DeprecationWarning: Using a domain property in MakeCallback is deprecated. Use the async_context variant of MakeCallback or the AsyncResource class instead.\r\n    at emitMakeCallbackDeprecation (domain.js:123:13)\r\n    at Connection.topLevelDomainCallback (domain.js:134:5)\r\n    at Connection.callbackTrampoline (internal/async_hooks.js:121:14)\r\n    at Session.post (inspector.js:118:28)\r\n    at internal/repl/utils.js:291:15\r\n    at sendInspectorCommand (internal/util/inspector.js:16:12)\r\n    at getInputPreview (internal/repl/utils.js:290:5)\r\n    at showPreview (internal/repl/utils.js:443:5)\r\n    at REPLServer.repl._refreshLine (internal/repl/utils.js:462:5)\r\n    at readline.js:567:10\r\n```\r\n\r\n### Additional information\r\nThis warning is triggered in several other ways in REPL. For example certain function calls can trigger it:\r\n```\r\n> child_process.execFile('vim', [], {timeout: 1});\r\n...\r\n> (node:14593) [DEP0097] DeprecationWarning: Using a domain property in MakeCallback is deprecated. Use the async_context variant of MakeCallback or the AsyncResource class instead.\r\n    at emitMakeCallbackDeprecation (domain.js:123:13)\r\n    at Pipe.topLevelDomainCallback (domain.js:134:5)\r\n    at Pipe.callbackTrampoline (internal/async_hooks.js:121:14)\r\n```\r\nIt makes me believe there is a common point for whole REPL that triggers this warning. I am eager to investigate further if provided with some clues (especially on how to debug asynchronous handling in the C++ part of node).",
        "labels": "confirmed-bug",
        "id": 44933
    },
    {
        "title": "VM aborts when error thrown when in property setter",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.14.1\r\n* **Platform**: Recreated on Catalina 10.15.4 and Windows 10 x64\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```js\r\nconst repl = require('repl');\r\nconst r = repl.start('> ');\r\nObject.defineProperty(r.context, 'db', {\r\n  set: (val) => {\r\n    throw new Error('test error');\r\n  }\r\n});\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEvery time\r\n\r\n### What is the expected behavior?\r\n\r\nThe error that is thrown should be reported in the default eval function, and it should be catchable.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n```\r\nFATAL ERROR: v8::FromJust Maybe value is Nothing.\r\n 1: 0x10007f231 node::Abort() [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 2: 0x10007f3b5 node::OnFatalError(char const*, char const*) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 3: 0x100178f00 v8::V8::FromJustIsNothing() [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 4: 0x100399618 v8::internal::PropertyCallbackArguments::CallNamedSetter(v8::internal::Handle<v8::internal::InterceptorInfo>, v8::internal::Handle<v8::internal::Name>, v8::internal::Handle<v8::internal::Object>) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 5: 0x1004aaa32 v8::internal::(anonymous namespace)::SetPropertyWithInterceptorInternal(v8::internal::LookupIterator*, v8::internal::Handle<v8::internal::InterceptorInfo>, v8::Maybe<v8::internal::ShouldThrow>, v8::internal::Handle<v8::internal::Object>) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 6: 0x1004ef1ab v8::internal::Object::SetPropertyInternal(v8::internal::LookupIterator*, v8::internal::Handle<v8::internal::Object>, v8::Maybe<v8::internal::ShouldThrow>, v8::internal::StoreOrigin, bool*) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 7: 0x1004eefe8 v8::internal::Object::SetProperty(v8::internal::LookupIterator*, v8::internal::Handle<v8::internal::Object>, v8::internal::StoreOrigin, v8::Maybe<v8::internal::ShouldThrow>) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 8: 0x10038ce16 v8::internal::StoreIC::Store(v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Name>, v8::internal::Handle<v8::internal::Object>, v8::internal::StoreOrigin) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 9: 0x10038c725 v8::internal::StoreGlobalIC::Store(v8::internal::Handle<v8::internal::Name>, v8::internal::Handle<v8::internal::Object>) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n10: 0x100392436 v8::internal::Runtime_StoreGlobalICNoFeedback_Miss(int, unsigned long*, v8::internal::Isolate*) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n11: 0x1009311f9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_NoBuiltinExit [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n12: 0x100985e16 Builtins_StaGlobalHandler [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\nAbort trap: 6\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\nWe need to be able to throw an error if a user tries to assign a context value to a disallowed type.\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44934
    },
    {
        "title": "http.IncomingMessage doesn't fire callback on 'timeout'",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:14.3.0\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\nSource code from `lib/_http_incoming.js`:\r\n```js\r\nIncomingMessage.prototype.setTimeout = function setTimeout(msecs, callback) {\r\n  if (callback)\r\n    this.on('timeout', callback);\r\n  this.socket.setTimeout(msecs);\r\n  return this;\r\n};\r\n```\r\n\r\nIncomingMessage doesn't emit 'timeout' so callback will never be fired\r\n### How often does it reproduce? Is there a required condition?\r\n\r\n### What is the expected behavior?\r\n```js\r\nIncomingMessage.prototype.setTimeout = function setTimeout(msecs, callback) {\r\n   this.socket.setTimeout(msecs,callback);\r\n  return this;\r\n};\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nEDIT(trivikr): put code in a code block ",
        "labels": "confirmed-bug",
        "id": 44935
    },
    {
        "title": "stream: end(callback) does not propagate write after end to callback",
        "body": "```js\r\nw.end();\r\nw.end('asd', (err) => {\r\n  assert.strictEqual(err.code, 'ERR_STREAM_WRITE_AFTER_END'); // Fails\r\n});\r\n```",
        "labels": "confirmed-bug",
        "id": 44936
    },
    {
        "title": "OutgoingMessage doesn't always emit close",
        "body": "Following test fails:\r\n\r\n```js\r\n  const msg = new OutgoingMessage();\r\n  assert.strictEqual(msg.destroyed, false);\r\n  msg.destroy();\r\n  assert.strictEqual(msg.destroyed, true);\r\n  let callbackCalled = false;\r\n  msg.write('asd', common.mustCall((err) => {\r\n    assert.strictEqual(err.code, 'ERR_STREAM_DESTROYED');\r\n    callbackCalled = true;\r\n  }));\r\n  msg.on('error', common.mustCall((err) => {\r\n    assert.strictEqual(err.code, 'ERR_STREAM_DESTROYED');\r\n    assert.strictEqual(callbackCalled, true);\r\n  }));\r\n  msg.on('close', common.mustCall(() => {\r\n    // Won't call\r\n    msg.end();\r\n  }));\r\n```",
        "labels": "confirmed-bug",
        "id": 44937
    },
    {
        "title": "Crash in module_wrap.cc with malformed loader",
        "body": "loader.mjs:\r\n\r\n```js\r\nexport function transformSource() {\r\n  return {\r\n    source: {\r\n      boom: true,\r\n    },\r\n  };\r\n}\r\n```\r\n\r\ntest.mjs:\r\n\r\n```js\r\nimport fs from 'fs';\r\n```\r\n\r\n```\r\n> node --loader ./loader.mjs test.mjs\r\nC:\\Program Files\\PowerShell\\7\\pwsh.exe[28872]: c:\\ws\\src\\module_wrap.cc:131: Assertion `args[2]->IsString()' failed.\r\n```",
        "labels": "confirmed-bug",
        "id": 44938
    },
    {
        "title": "[ES modules] package.json located in root path can't be resolved when checking `type` field",
        "body": "* **Version**: `v14.2.0`\r\n* **Platform**: `Linux c89b7c439bd7 4.19.76-linuxkit #1 SMP Fri Apr 3 15:53:26 UTC 2020 x86_64 Linux`\r\n\r\n### What steps will reproduce the bug?\r\n\r\nCreate docker image that generates `package.json` and `index.js` in *root of filesystem*:\r\n```docker\r\nFROM node:14-alpine\r\n\r\nRUN echo '{ \"type\": \"module\" }' > package.json\r\nRUN echo 'import fs from \"fs\";' > index.js\r\n\r\nCMD [\"node\", \"index.js\"]\r\n```\r\nBuild and run the container:\r\n```bash\r\ndocker build -t app .\r\ndocker run --rm app\r\n```\r\nOutput:\r\n```\r\n(node:1) Warning: To load an ES module, set \"type\": \"module\" in the package.json or use the .mjs extension.\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n/index.js:1\r\nimport fs from \"fs\";\r\n^^^^^^\r\n\r\nSyntaxError: Cannot use import statement outside a module\r\n    at Object.compileFunction (vm.js:344:18)\r\n    at wrapSafe (internal/modules/cjs/loader.js:1106:15)\r\n    at Module._compile (internal/modules/cjs/loader.js:1140:27)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1196:10)\r\n    at Module.load (internal/modules/cjs/loader.js:1040:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:929:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12)\r\n    at internal/main/run_main_module.js:17:47\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n`index.js` should be loaded as es module because the nearest `package.json` has `\"type\": \"module\"` field.\r\n\r\n### What do you see instead?\r\n`index.js` is being loaded as commonjs.\r\n\r\n### Additional information\r\nIf `package.json` and `index.js` are generated in some subdirectory - everything works. You can check it with the following image:\r\n```docker\r\nFROM node:14-alpine\r\n\r\n# add workdir to generate files in /app not in /\r\nWORKDIR app \r\n\r\nRUN echo '{ \"type\": \"module\" }' > package.json\r\nRUN echo 'import fs from \"fs\";' > index.js\r\n\r\nCMD [\"node\", \"index.js\"]\r\n```\r\n\r\nThe reason of such behavior is [this line](https://github.com/nodejs/node/blob/c1ee70ec168eedc3f9d193473d141b9c03e2df88/lib/internal/modules/cjs/loader.js#L289):\r\n```\r\n(separatorIndex = checkPath.lastIndexOf(path.sep)) > rootSeparatorIndex\r\n```\r\nWhen `checkPath = '/index.js'`, both `separatorIndex` and `rootSeparatorIndex` are equals to `0` and condition does not pass.\r\n",
        "labels": "confirmed-bug",
        "id": 44939
    },
    {
        "title": "Console output for class instance __proto__ seems wrong",
        "body": "Consider following code\r\n```\r\nclass A {\r\n    getA() { return 0; }\r\n    constructor() {}\r\n}\r\nclass B extends A {\r\n    getB() { return 0; }\r\n    constructor() { super(); }\r\n}\r\nconsole.log((new A()));\r\nconsole.log((new A()).__proto__);\r\nconsole.log((new A()).__proto__ instanceof A);\r\nconsole.log((new A()).__proto__ instanceof Object);\r\nconsole.log((new B()));\r\nconsole.log((new B()).__proto__);\r\nconsole.log((new B()).__proto__ instanceof B);\r\nconsole.log((new B()).__proto__ instanceof A);\r\n```\r\n\r\nNode 14 produces:\r\n\r\n```\r\nA {}\r\nA {}\r\nfalse\r\ntrue\r\nB {}\r\nB {}\r\nfalse\r\ntrue\r\n```\r\n\r\nThis is wrong since `(new B()).__proto__` is an instance of `A`. I guess the confusing part is that `(new B()).__proto__.constructor` is `class B` (which is because of https://tc39.es/ecma262/#sec-makeconstructor)\r\n\r\nFor reference, Chrome DevTools produces:\r\n\r\n```\r\nAÂ {}\r\n{constructor: Æ’, getA: Æ’}\r\nfalse\r\ntrue\r\nBÂ {}\r\nAÂ {constructor: Æ’, getB: Æ’}\r\nfalse\r\ntrue\r\n```",
        "labels": "confirmed-bug",
        "id": 44940
    },
    {
        "title": "Duplex stream is not returning whether it is in object mode correctly",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.16.0\r\n* **Platform**: MacOS\r\n* **Subsystem**: Darwin ... 19.4.0 Darwin Kernel Version 19.4.0: Wed Mar  4 22:28:40 PST 2020; root:xnu-6153.101.6~15/RELEASE_X86_64 x86_64\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\n// open the node repl\r\nx = new stream.Duplex({writableObjectMode: true})\r\nx.writableObjectMode // undefined - should be true\r\n```\r\nbut the mode is set correctly:\r\n```js\r\n...\r\n_writableState: WritableState {\r\n    objectMode: true,\r\n   ...\r\n```\r\n\r\nit does work on a Writable stream:\r\n\r\n```js\r\nx = new stream.Writable({objectMode: true})\r\nx.writableObjectMode // true\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\n100%\r\n\r\n### What is the expected behavior?\r\n\r\nReturn the actual value of whether the stream is in object mode.",
        "labels": "confirmed-bug",
        "id": 44941
    },
    {
        "title": "fs readdir with buffer and file types problem",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.16.3\r\n* **Platform**: linux64\r\n* **Subsystem**: gentoo\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\nreading directory with files names using buffer as path does not work.\r\n```\r\nconst fs = require('fs');\r\nfs.readdir( Buffer.from( \".\"),{withFileTypes:true,encoding:\"buffer\"},(e,d)=>console.log(\"dir\",d));\r\n```\r\nIt works correct in version 12.14.0 but after upgrade it stopped to work.\r\nusing it without files types works:\r\n// fs.readdir( Buffer.from( \".\"),{withFileTypes:false,encoding:\"buffer\"},(e,d)=>console.log(\"dir\",d));\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nevery time\r\n\r\n### What is the expected behavior?\r\nget directory entries with file types i.e. array of Dirent objects\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nerror message:\r\n```\r\nUncaught:\r\nTypeError [ERR_INVALID_ARG_TYPE]: The \"path\" argument must be of type string. Received an instance of Buffer\r\n    at validateString (internal/validators.js:117:11)\r\n    at Object.join (path.js:1039:7)\r\n    at getDirents (internal/fs/utils.js:159:39)\r\n    at FSReqCallback.req.oncomplete (fs.js:858:7) {\r\n  code: 'ERR_INVALID_ARG_TYPE'\r\n}\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\nThis bug is degradation because it doesn't exists in version 12.14.0 and present in versions 12.16.1 and 12.16.3 at least. \r\nI use buffer instead of string because working with my old archives with non utf-8 names.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44942
    },
    {
        "title": "Node v12.16.2 memory issues after upgrade from v8 (<--- Last few GCs --->)",
        "body": "This issue is continuation of [#32737](https://github.com/nodejs/node/issues/32737)\r\n\r\n**Version:**\r\nv12.16.2 (but v12.13 on production)\r\n\r\n**Platform:**\r\nDarwin Kernel Version 19.4.0: Wed Mar  4 22:28:40 PST 2020; root:xnu-6153.101.6~15/RELEASE_X86_64 x86_64\r\n(but docker with node:12.13.0-alpine on production)\r\n\r\n**Subsystem:**\r\n? runtime, heap, garbage collection\r\n\r\n**Description:**\r\nAs in previous ticket: \"We recently upgrade our production servers with docker containers with node v8 to docker containers with node v12.10 (node:12.13.0-alpine). At first all seems fine, but then we started noticing pod restarts by Kubernetes being OOM Killed. Since the upgrade, memory usage seems to increase over time sometimes in steep inclines until reaching ~500MB at which time they are killed by Kuberenetes.\"\r\n\r\nWith the same code base and dependencies, when switching between 3 versions of node (8.17.0, 10.20.1, 12.16.2) different memory usage observed. With version 12.16.2 node service crashes with logs:\r\n\r\n```\r\nTESTED_SERVICE.GetData took 1691 ms (queue-time = 409 ms, process-time = 1282 ms, processing-count = 100, queue-size = 124)\"}\r\n{\"@timestamp\":\"2020-05-06T10:49:42.337Z\",\"level\":\"debug\",\"message\":\"GRPC server call TESTED_SERVICE.GetData took 1724 ms (queue-time = 431 ms, process-time = 1293 ms, processing-count = 100, queue-size = 123)\"}\r\n\r\n<--- Last few GCs --->\r\ncr[35106:0x102aac000] 10407728 ms: Mark-sweep 543.8 (546.1) -> 543.7 (546.1) MB, 158.9 / 0.0 ms  (+ 2.9 ms in 2 steps since start of marking, biggest step 2.9 ms, walltime since start of marking 163 ms) (average mu = 0.102, current mu = 0.010) finalize incr[35106:0x102aac000] 10407914 ms: Mark-sweep 543.8 (546.1) -> 543.7 (546.1) MB, 177.3 / 0.0 ms  (+ 5.1 ms in 2 steps since start of marking, biggest step 5.0 ms, walltime since start of marking 186 ms) (average mu = 0.058, current mu = 0.018) finalize incr\r\n\r\n<--- JS stacktrace --->\r\n\r\n==== JS stack trace =========================================\r\n\r\n    0: ExitFrame [pc: 0x10097d5b9]\r\n    1: StubFrame [pc: 0x1009e8f05]\r\nSecurity context: 0x1fc1cc0c08d1 <JSObject>\r\n    2: new constructor(aka Op) [0x1fc1b415e939] [/Users/robertdittmann/Documents/Tutorials/node-memory-test/node_modules/protobufjs/src/writer.js:21] [bytecode=0x1fc1cf4764f1 offset=0](this=0x1fc1ca0d2b61 <Op map = 0x1fc11cbd1199>,0x1fc1b415e979 <JSFunction noop (sfi = 0x1fc1712aee81)>,0,0)\r\n    3: ConstructFrame [pc: 0x1008fe7...\r\n\r\nFATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory\r\n 1: 0x1010248bd node::Abort() (.cold.1) [/usr/local/bin/node]\r\n 2: 0x100084c4d node::FatalError(char const*, char const*) [/usr/local/bin/node]\r\n 3: 0x100084d8e node::OnFatalError(char const*, char const*) [/usr/local/bin/node]\r\n 4: 0x100186477 v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [/usr/local/bin/node]\r\n 5: 0x100186417 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [/usr/local/bin/node]\r\n 6: 0x1003141c5 v8::internal::Heap::FatalProcessOutOfMemory(char const*) [/usr/local/bin/node]\r\n 7: 0x100315a3a v8::internal::Heap::RecomputeLimits(v8::internal::GarbageCollector) [/usr/local/bin/node]\r\n 8: 0x10031246c v8::internal::Heap::PerformGarbageCollection(v8::internal::GarbageCollector, v8::GCCallbackFlags) [/usr/local/bin/node]\r\n 9: 0x10031026e v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [/usr/local/bin/node]\r\n10: 0x10030f2b1 v8::internal::Heap::HandleGCRequest() [/usr/local/bin/node]\r\n11: 0x1002d4551 v8::internal::StackGuard::HandleInterrupts() [/usr/local/bin/node]\r\n12: 0x10063e79c v8::internal::Runtime_StackGuard(int, unsigned long*, v8::internal::Isolate*) [/usr/local/bin/node]\r\n13: 0x10097d5b9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_NoBuiltinExit [/usr/local/bin/node]\r\n14: 0x1009e8f05 Builtins_StackCheckHandler [/usr/local/bin/node]\r\n[1]    35106 abort      node --max-old-space-size=384 app.js\r\n```\r\n\r\n**What steps will reproduce the bug?**\r\n\r\n1. Download prepared sample \"slim version\" of service code (without other parts like Redis, DynamoDB, Prometheus, Zippkin, Routes etc.): [node-sample](https://github.com/RobertDittmann/node-memory-test)\r\n2. Download prepared sample client: [java-sample](https://github.com/RobertDittmann/nodememorytest)\r\n3. Change node version on 12.16.2\r\n4. For node service (rebuild and run):\r\n```\r\nrm -rf node-modules\r\nnpm install\r\nnode --max-old-space-size=384 app.js\r\n```\r\n5. For java service (rebuild and run):\r\n```\r\nmvn clean install\r\nmvn spring-boot:run\r\n```\r\n6. After around 3-4 hours node service should throws above exception. Node service in its directory will fill with data csv file called **memory_usage.csv** (it contains process memory in MB per 1 minute).\r\n\r\nSame situation appears on production environment but it takes few days to happen. \r\n\r\nBelow comparison of node vesions:\r\n\r\n- node v12.16.2 started with command: node --max-old-space-size=384 app.js (crashed - results as above logs)\r\n ![image](https://user-images.githubusercontent.com/11576433/81183989-23735b00-8fb0-11ea-95e9-10124ac1b99c.png)\r\n\r\n- node v12.16.2 started with command: node app.js \r\n![image](https://user-images.githubusercontent.com/11576433/81184343-97156800-8fb0-11ea-8f3e-00336a6f5a1c.png)\r\n\r\n- node v10.20.1 started with command: node app.js (it shows also memory when load stopped)\r\n![image](https://user-images.githubusercontent.com/11576433/81184587-d8a61300-8fb0-11ea-820e-2626c71c3145.png)\r\n\r\n- node v8.17.0 started with command: node app.js \r\n![image](https://user-images.githubusercontent.com/11576433/81184779-186cfa80-8fb1-11ea-882a-ef16d9f03ed9.png)\r\n\r\n\r\n**How often does it reproduce? Is there a required condition?**\r\nAlways. \r\n\r\n**What is the expected behavior?**\r\nA stable heapUsed like in v8.17 and no spikes in memory usage causing OOM kills/ GCs issues.\r\n\r\n**What do you see instead?**\r\nMemory increase and GCs issues.\r\n\r\n**Additional information**\r\nI am looking for solutions. Seems that used last years services cannot be used with LTS v12 on production. \r\n\r\nPlease let me know how I can help further,\r\n\r\nKind regards,\r\nRobert\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 44943
    },
    {
        "title": "Segfault with unref on a worker with ArrayBuffer in `transferList`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.2.0\r\n* **Platform**: mac OS 10.13.6\r\n\r\n\r\n### What steps will reproduce the bug?\r\nWhen communicating a Uint8 Array Buffer from a worker to the parent process with `postMessage`, which is included in the `transferList` argument and then calling `unref` on the worker, I get a Segfault: `'node index.js' terminated by signal SIGSEGV (Address boundary error)`.\r\n\r\n`index.js`\r\n```js\r\nconst path = require('path')\r\nconst { Worker } = require('worker_threads')\r\n\r\nconst worker = new Worker(path.join(__dirname, 'worker.js'))\r\nworker.postMessage({})\r\nworker.on('message', (message) => {\r\n  const hash = Buffer.from(message.value).toString('hex')\r\n  console.log(hash)\r\n  worker.unref()\r\n})\r\n```\r\n\r\n`worker.js`\r\n```js\r\nconst fs = require('fs')\r\nconst crypto = require('crypto')\r\nconst { parentPort } = require('worker_threads')\r\n\r\nparentPort.on('message', (message) => {\r\n  const hasher = crypto.createHash('sha256')\r\n  fs.createReadStream('example.txt')\r\n    .pipe(hasher)\r\n    .on('finish', () => {\r\n      const { buffer } = hasher.read()\r\n      parentPort.postMessage({ value: buffer }, [buffer])\r\n    })\r\n})\r\n```\r\n\r\n\r\nReproduction here: https://github.com/timsuchanek/segfault-node-14\r\n\r\n### lldb backtrace\r\n```\r\nProcess 40610 stopped\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x20)\r\n    frame #0: 0x000000010007b095 node`node::Buffer::New(node::Environment*, char*, unsigned long, bool)::$_2::__invoke(void*, unsigned long, void*) + 21\r\nnode`node::Buffer::New(node::Environment*, char*, unsigned long, bool)::$_2::__invoke(void*, unsigned long, void*):\r\n->  0x10007b095 <+21>: movq   0x20(%rcx), %rcx\r\n    0x10007b099 <+25>: movq   %rax, %rdi\r\n    0x10007b09c <+28>: popq   %rbp\r\n    0x10007b09d <+29>: jmpq   *%rcx\r\nTarget 0: (node) stopped.\r\n```\r\n\r\n\r\nThis works fine in Node 13 or lower and it seems, that this bug was introduced in Node 14.",
        "labels": "confirmed-bug",
        "id": 44944
    },
    {
        "title": "repl: Extra `/` on completion after `require`",
        "body": "* **Version**: v14.1.0\r\n* **Platform**: Linux lt2.cfware.com 5.5.10-100.fc30.x86_64 #1 SMP Wed Mar 18 14:34:46 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: REPL\r\n\r\n### What steps will reproduce the bug?\r\n\r\nInstall a package that has sub-directories (lets say `nano` for an example).  Run repl with `node` and type `require('nano` without the closing quote:\r\n![Screenshot from 2020-05-04 14-29-04](https://user-images.githubusercontent.com/903597/81000158-dd819000-8e13-11ea-8e4b-6bca9b6cb305.png)\r\n\r\nNote the position of the cursor and the suggested `/`, this is valid.  Typing `')` to close the `require` call does not remove the suggested `/`.  At this point pressing keyboard left, end or tab causes an additional `/` to be displayed.\r\n\r\nTyping `require('nano/')` then pressing tab causes `nano/lib/` and `nano/package` to be suggested.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nEvery time.\r\n\r\n### What is the expected behavior?\r\nCompletion of the string passed to `require()` should end as soon as the closing `'` is typed.\r\n\r\n### What do you see instead?\r\n\r\n![Screenshot from 2020-05-04 14-40-51](https://user-images.githubusercontent.com/903597/81001197-6220de00-8e15-11ea-83df-7bd3abd5d388.png)\r\n\r\n### Additional information\r\nSorry for using screen-captures it's difficult to show what I'm seeing otherwise.",
        "labels": "confirmed-bug",
        "id": 44945
    },
    {
        "title": "Segfault importing ESM module twice",
        "body": "@nodejs/modules...\r\n\r\n```\r\nWelcome to Node.js v14.1.0.\r\nType \".help\" for more information.\r\n> import('piscina')\r\nPromise { <pending> }\r\n> import('piscina').then(console.log)\r\nPromise { <pending> }\r\n> [Module] {\r\n  Piscina: [Function: Piscina],\r\n  default: [Function: Piscina],\r\n  isWorkerThread: false,\r\n  version: '1.2.0',\r\n  workerData: undefined\r\n}\r\n> import('piscina').then(console.log)\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nSpotted this while working on a module. Happens regularly for me with any ESM. Calling import twice on the same module leads to a segfault. Happens regularly but may take a few calls to import to trigger... lldb backtrace shows:\r\n\r\n```\r\n* thread #1, name = 'node', stop reason = signal SIGSEGV: invalid address (fault address: 0x10)\r\n  * frame #0: 0x0000000000978050 node`node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::ScriptOrModule>, v8::Local<v8::String>) (.cold.291)\r\n    frame #1: 0x000000000431adc0\r\n    frame #2: 0x0000000000ce6a58 node`v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::Handle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>) + 120\r\n    frame #3: 0x000000000105530f node`v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) + 175\r\n```",
        "labels": "confirmed-bug",
        "id": 44946
    },
    {
        "title": "`node --loader` treats entrypoint as ESM when should be loaded as CJS",
        "body": "* **Version**: 14.1.0\r\n* **Platform**: Ubuntu 19\r\n* **Subsystem**: entrypoint handling\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```\r\nmkdir empty-dir\r\ncd empty-dir\r\necho '{}' > package.json\r\ntouch entrypoint\r\ntouch hooks.mjs\r\nnode ./entrypoint # <-- no error; no output; exit code 0\r\nnode --loader ./hooks.mjs ./entrypoint # <-- error that \"\" is not a recognized file extension by the default ESM loader\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\n`./entrypoint` is executed as a CommonJS module whether or not `--loader` is passed.\r\n\r\n### What do you see instead?\r\n\r\nWhen --loader is passed, node always tries to load entrypoint scripts as ESM, ignoring that `package.json` wants the file to be treated as CJS.  This does not happen when --loader is omitted, suggesting that this behavior is a bug.\r\n\r\n```\r\n\"\" is not a recognized file extension by the default ESM loader\r\n(node:26067) ExperimentalWarning: --experimental-loader is an experimental feature. This feature could change at any time\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\ninternal/modules/run_main.js:54\r\n    internalBinding('errors').triggerUncaughtException(\r\n                              ^\r\n\r\nTypeError [ERR_UNKNOWN_FILE_EXTENSION]: Unknown file extension \"\" for /d/Personal-dev/@TypeStrong/ts-node-repros/empty-dir/entrypoint\r\n    at Loader.defaultGetFormat [as _getFormat] (internal/modules/esm/get_format.js:65:15)\r\n    at Loader.getFormat (internal/modules/esm/loader.js:113:42)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:244:31)\r\n    at async Loader.import (internal/modules/esm/loader.js:178:17) {\r\n  code: 'ERR_UNKNOWN_FILE_EXTENSION'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\n#33223 \r\n",
        "labels": "confirmed-bug",
        "id": 44947
    },
    {
        "title": "[BUG] Segfault on combo of global ctors, ostream, wasi",
        "body": "This is an issue for node's WASI integration with emscripten.\r\n\r\nboth global ctors need to be called, and ostream being used in the WASM standalone mode (emsdk latest upstream). \r\n\r\nI have a case where I need to call the global static initializers(need to call _start before running other functions), but also have ostream in the code. \r\n\r\nWhat was happening is that when ostream is being used in the code and it somehow triggers certain things to be added to global ctors, and then calling global ctors resulted in a segfault. So far I only get this error on node14, and I am not sure if it is related to the use of WASI.\r\n\r\n### C++\r\n```c++\r\n#include <emscripten.h>\r\n#include <vector>\r\n#include <sstream>\r\n\r\n// static intializer, need to call _start\r\nstatic std::vector<int> x = {1, 2, 3};\r\n\r\nextern \"C\" {\r\nEMSCRIPTEN_KEEPALIVE\r\nint GetX(int i) {\r\n   // use of ostream somehow makes _start fail.\r\n    std::ostringstream os;\r\n    os << \"x\";\r\n    return x[i];\r\n}\r\n}\r\n```\r\n```Makefile\r\nwasm_test.wasm: wasm_test.cc\r\n\t@mkdir -p $(@D)\r\n\temcc -O3 -std=c++11 -o $@ $<\r\n```\r\n\r\n### NodeJS\r\n\r\n```js\r\nconst { WASI } = require('wasi');\r\n\r\nconst wasi = new WASI({\r\n    args: process.argv,\r\n    env: process.env\r\n  });\r\n\r\nconst binary = require('fs').readFileSync('build/wasm_test.wasm');\r\n\r\nWebAssembly.instantiate(binary,\r\n    { env: {}, wasi_snapshot_preview1: wasi.wasiImport }).then(({ instance }) => {\r\n  // trigger ctors\r\n  instance.exports._start();\r\n  // test the static vars are correctly initialized.\r\n  console.log(instance.exports.GetX(0));\r\n});\r\n```\r\n```\r\nnode --experimental-wasi-unstable-preview1  --experimental-wasm-bigint test_wasm.js \r\n```\r\n\r\nRelevant issue in the emscripten https://github.com/emscripten-core/emscripten/issues/11001",
        "labels": "confirmed-bug",
        "id": 44948
    },
    {
        "title": "fs.stat or fs.lstat throws unknown error on some files (reparse point)",
        "body": "* **Version**: v12.16.2\r\n* **Platform**: 64 bit Microsoft Windows 10 [Version 10.0.18362.778]\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\n1. Check if `%USERPROFILE%\\AppData\\Local\\Microsoft\\WindowsApps` exists.\r\n2. Install https://www.microsoft.com/en-us/p/python-38/9mssztt1n39l\r\n3. Call `fs.statSync(\"c:\\\\Users\\\\kanadig\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\python.exe\")`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThis repros 100%, make sure you are calling it on the files under `%USERPROFILE%\\AppData\\Local\\Microsoft\\WindowsApps\\` with 0 size.\r\n\r\n### What is the expected behavior?\r\n\r\nShould not throw exception.\r\n\r\n### What do you see instead?\r\n\r\n```\r\n> fs.statSync(\"c:\\\\Users\\\\bpasero\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\GameBarElevatedFT_Alias.exe\")                 \r\nThrown:                                                                                                                  \r\n{ Error: UNKNOWN: unknown error, stat 'c:\\Users\\bpasero\\AppData\\Local\\Microsoft\\WindowsApps\\GameBarElevatedFT_Alias.exe' \r\n    at Object.statSync (fs.js:855:3)                                                                                     \r\n  errno: -4094,                                                                                                          \r\n  syscall: 'stat',                                                                                                       \r\n  code: 'UNKNOWN',                                                                                                       \r\n  path:                                                                                                                  \r\n   'c:\\\\Users\\\\bpasero\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\GameBarElevatedFT_Alias.exe' }                           \r\n> fs.lstatSync(\"c:\\\\Users\\\\bpasero\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\GameBarElevatedFT_Alias.exe\")                \r\nThrown:                                                                                                                  \r\n{ Error: UNKNOWN: unknown error, lstat 'c:\\Users\\bpasero\\AppData\\Local\\Microsoft\\WindowsApps\\GameBarElevatedFT_Alias.exe'\r\n    at Object.lstatSync (fs.js:845:3)                                                                                    \r\n  errno: -4094,                                                                                                          \r\n  syscall: 'lstat',                                                                                                      \r\n  code: 'UNKNOWN',                                                                                                       \r\n  path:                                                                                                                  \r\n   'c:\\\\Users\\\\bpasero\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\GameBarElevatedFT_Alias.exe' }                           \r\n>     \r\n```\r\n\r\n### Additional information\r\n\r\nSee https://github.com/microsoft/vscode/issues/95828\r\n",
        "labels": "confirmed-bug",
        "id": 44949
    },
    {
        "title": "Copying then pasting text directly into node REPL freezes it - Windows",
        "body": "As subject says. It only happens with large amounts of text, maybe something in relation to the buffer size?\r\n\r\nnode version v12.16.2\r\n64 bit Windows 10\r\n* **Subsystem**: none\r\n\r\n### What steps will reproduce the bug?\r\n\r\nOpen CMD, type \"node\" press enter to get the node repl. Now copy the below code, then right click in the node console to paste text. It will only paste the first line of code and freeze up node. It becomes completely unresponsive.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nEverytime when the copied code seems to be over a certain size. Don't know what that size is but happens no matter what the code is. The sample code provided will replicate the issue.\r\n\r\n### What is the expected behavior?\r\nAll text is pasted and executed line by line like other copy and paste operations.\r\n\r\n### What do you see instead?\r\n\r\nNode locks up after the first line of the copied text\r\n\r\n### Additional information\r\n\r\nSample code below. Here is a quick vid of node locking up as described above. https://streamable.com/ep7wqt The cursor just flashes but it is unresponsive to key strokes and doesn't do anything else.\r\nNOTE; the code has been changed to take out the IP so IF does execute it will error as I just replaced some keywords with random text. Ignore this, the point of it is to show that it won't copy and paste past the first line, it will freeze.\r\n\r\n```\r\n//{\"_id\":\"56aba3108d6d183da42403c2\"}\r\n//placeholder\r\nconst request = require('request');\r\nvar mongoose = require (\"mongoose\");\r\nvar lodash = require (\"lodash\");\r\nvar myFuncs = require(\"./functions\");\r\n\r\n\r\n\r\nvar item_urls;\r\nvar options = {\r\n    json: true\r\n  };\r\n\r\nvar test = [] ;\r\nfunction updateDB (){\r\n    var url = \"get stuff\";\r\n\r\n\r\n    request(url, options, (error, res, body) =>{\r\n        if (error) {\r\n            return console.log(error)\r\n          };\r\n\r\n          if (!error && res.statusCode == 200) {\r\n            console.log(\"executing cb1\");\r\n            item_urls = body.payload.items;\r\n            myFuncs.fixItemIDs (item_urls);\r\n            var primes = item_urls.filter(item => item.item_name.includes(\"Strun Wraith Set\")); \r\n            for (item in primes) \r\n            {\r\n                let url = `https://get more stuff/v1/items/${primes[item].url_name}`;\r\n               // console.log (url);\r\n                request(url, options, (error, res, body) =>{\r\n                    if (error) {\r\n                        return console.log(error)\r\n                      };\r\n\r\n                      if (!error && res.statusCode == 200) {\r\n\r\n                          console.log(`Getting item ${url}`);\r\n                          test.push(body.payload.item);\r\n                          myFuncs.fixItemIDs (test);\r\n                      }\r\n                    });\r\n\r\n            };  \r\n            console.log (\"done\");          \r\n\r\n\r\n          };\r\n    });\r\n}\r\n\r\nupdateDB();\r\n```",
        "labels": "confirmed-bug",
        "id": 44950
    },
    {
        "title": "Confusing error message in fs.utils",
        "body": "https://github.com/nodejs/node/blob/f22a9cac36f731d5bdbf1b7c542b36fa4c13f4de/lib/internal/fs/utils.js#L543\r\n\r\nThis check can produce confusing error message when `offse`t is equal to `bufferLength`. Which is error, but message shows, that it is correct (<=)\r\n```\r\nif (offset < 0 || offset >= bufferLength) {\r\n      throw new ERR_OUT_OF_RANGE('offset',\r\n                                 `>= 0 && <= ${bufferLength}`, offset);\r\n    }\r\n```\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 44951
    },
    {
        "title": "'buffer.Buffer.prototype.lastIndexOf' results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.16.0\r\n* **Platform**: Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: buffer\r\n\r\n### What steps will reproduce the bug?\r\nDirectly run the following code snippet using node:\r\n```\r\nlet buffer = require('buffer');\r\nnew buffer.Buffer.prototype.lastIndexOf(1, 'str');\r\n```\r\nIt is worth noting that the following code would not cause this abort:\r\n```\r\nnew  require('buffer').Buffer.prototype.lastIndexOf(1, 'str');\r\n```\r\nThus we doubt there may be something wrong in somewhere.\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\nThis is a misuse of 'buffer.Buffer.prototype.lastIndexOf'. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nThis is the stack dump produced during abort:\r\n```\r\n./node[40968]: ../src/node_buffer.cc:1014:void node::Buffer::(anonymous namespace)::IndexOfNumber(const FunctionCallbackInfo<v8::Value> &): Assertion `args[2]->IsNumber()' failed.\r\n 1: 0x13f9b30 node::Abort() [./node]\r\n 2: 0x13f9709  [./node]\r\n 3: 0x13b765e  [./node]\r\n 4: 0x17b379c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [./node]\r\n 5: 0x17b23d5  [./node]\r\n 6: 0x17b1092  [./node]\r\n 7: 0x2717a59  [./node]\r\n[2]    40968 abort      ./node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44952
    },
    {
        "title": "process.setuid results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.16.0\r\n* **Platform**:  Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: process\r\n\r\n### What steps will reproduce the bug?\r\nDirectly run the following code snippet using node:\r\n```\r\nrequire('process').setuid(-0)\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\nThe argument to 'process.setuid' should be a Uint32 or string value, but we passed a -0 into it. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nThis is the stack dump produced during abort:\r\n```\r\n./node[37487]: ../src/node_credentials.cc:247:void node::credentials::SetUid(const FunctionCallbackInfo<v8::Value> &): Assertion `args[0]->IsUint32() || args[0]->IsString()' failed.\r\n 1: 0x13f9b30 node::Abort() [./node]\r\n 2: 0x13f9709  [./node]\r\n 3: 0x13ea56b  [./node]\r\n 4: 0x17b379c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [./node]\r\n 5: 0x17b23d5  [./node]\r\n 6: 0x17b1092  [./node]\r\n 7: 0x2717a59  [./node]\r\n[2]    37487 abort      ./node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44953
    },
    {
        "title": "'crypto.createDiffieHellman(prime: string, prime_encoding: HexBase64Latin1Encoding)' results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.16.0\r\n* **Platform**: Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\nDirectly run the following code snippet using node:\r\n```\r\nrequire('crypto').createDiffieHellman('str', 3.14);\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\nThe second argument to 'crypto.createDiffieHellman(prime: string, prime_encoding: HexBase64Latin1Encoding)' should be a 'HexBase64Latin1Encoding' value as the encoding of the first argument, but we passed a float pointer value into it. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nThis is the stack dump produced during abort:\r\n```\r\n./node[36752]: ../src/util-inl.h:495:node::ArrayBufferViewContents<char, 64>::ArrayBufferViewContents(v8::Local<v8::Value>) [T = char, kStackStorageSize = 64]: Assertion `value->IsArrayBufferView()' failed.\r\n 1: 0x13f9b30 node::Abort() [./node]\r\n 2: 0x13f9709  [./node]\r\n 3: 0x160c480 node::crypto::DiffieHellman::DiffieHellmanGroup(v8::FunctionCallbackInfo<v8::Value> const&) [./node]\r\n 4: 0x17b379c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [./node]\r\n 5: 0x17b1c91  [./node]\r\n 6: 0x17b104c  [./node]\r\n 7: 0x2717a59  [./node]\r\n[1]    36752 abort      ./node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44954
    },
    {
        "title": "'worker_threads.receiveMessageOnPort' results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:v12.16.0\r\n* **Platform**:Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: process\r\n\r\n### What steps will reproduce the bug?\r\nDirectly run the following code snippet using node:\r\n```\r\nrequire('worker_threads').receiveMessageOnPort(0)\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\n\r\nThe argument to 'worker_threads.receiveMessageOnPort' should be a 'MessagePort' object, but we passed an integer value into it. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nThis is the stack dump produced during abort:\r\n```\r\n./node[17081]: ../src/node_messaging.cc:878:static void node::worker::MessagePort::ReceiveMessage(const FunctionCallbackInfo<v8::Value> &): Assertion `args[0]->IsObject()' failed.\r\n 1: 0x13f9b30 node::Abort() [./node]\r\n 2: 0x13f9709  [./node]\r\n 3: 0x148b6c0 node::worker::MessagePort::ReceiveMessage(v8::FunctionCallbackInfo<v8::Value> const&) [./node]\r\n 4: 0x17b379c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [./node]\r\n 5: 0x17b23d5  [./node]\r\n 6: 0x17b1092  [./node]\r\n 7: 0x2717a59  [./node]\r\n[1]    17081 abort      ./node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44955
    },
    {
        "title": "`crypto.createDiffieHellman` results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.16.0\r\n* **Platform**: Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\nDirectly run the following code snippet using `node`:\r\n\r\n```javascript\r\nrequire('crypto').createDiffieHellman(0.123)\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThe argument to `crypto.createDiffieHellman` should be an integer, but we passed a floating point number into it. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThis is the stack dump produced during `abort`:\r\n```\r\nnode[55090]: ../src/node_buffer.cc:211:char *node::Buffer::Data(Local<v8::Value>): Assertion `val->IsArrayBufferView()' failed.\r\n 1: 0x10003c597 node::Abort() [/usr/local/bin/node]\r\n 2: 0x10003b5b9 node::AddEnvironmentCleanupHook(v8::Isolate*, void (*)(void*), void*) [/usr/local/bin/node]\r\n 3: 0x10004e3dd node::Buffer::Data(v8::Local<v8::Object>) [/usr/local/bin/node]\r\n 4: 0x10011f6c3 node::crypto::DiffieHellman::New(v8::FunctionCallbackInfo<v8::Value> const&) [/usr/local/bin/node]\r\n 5: 0x10023663f v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo*) [/usr/local/bin/node]\r\n 6: 0x1002357db v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<true>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/usr/local/bin/node]\r\n 7: 0x1002351f7 v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/usr/local/bin/node]\r\n 8: 0x2b916465be3d\r\n[1]    55090 abort      node\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44956
    },
    {
        "title": "repl: repl command preview interacts badly with `--trace-sync-io`",
        "body": "When launching the node.js REPL with the `--trace-sync-io` option, then typing sync fs statements, the repl prints one or two trace sync io statements for every key press following the opening `(` ... See screenshot:\r\n\r\n![image](https://user-images.githubusercontent.com/439929/78677080-2806ff80-789c-11ea-8eb4-c31d0b4e5706.png)\r\n\r\n/cc @BridgeAR ",
        "labels": "confirmed-bug",
        "id": 44957
    },
    {
        "title": "fs.Stat fails on pre-epoch mtime (<1970-01-01T00:00:00Z)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v13.10.1\r\n* **Platform**: Darwin dirac.imetrical.com 18.7.0 Darwin Kernel Version 18.7.0: Sun Dec  1 18:59:03 PST 2019; root:xnu-4903.278.19~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: fs.stat\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\n// statPreEpoch.js\r\nconst fs = require('fs')\r\nconst path = 'coco.txt'\r\nconst { mtime } = fs.statSync(path)\r\nconsole.log(`mtime of ${path}: ${mtime}`)\r\n```\r\n\r\n*This is on Darwin (macOS)*\r\n\r\n```bash\r\n# This is correct\r\n$ touch -mt 197001010000.00 coco.txt\r\n$ stat coco.txt \r\n16777220 104232499 -rw-r--r-- 1 daniel staff 0 0 \"Mar 19 13:26:22 2020\" \"Jan  1 00:00:00 1970\" \"Mar 19 15:01:21 2020\" \"Dec 31 19:00:00 1969\" 4096 0 0 coco.txt\r\n$ node statPreEpoch.js \r\nmtime of coco.txt: Thu Jan 01 1970 00:00:00 GMT-0500 (GMT-05:00)\r\n\r\n# This is the bug:\r\ntouch -mt 196805160000.00 coco.txt \r\nstat coco.txt \r\n16777220 104232499 -rw-r--r-- 1 daniel staff 0 0 \"Mar 19 13:26:22 2020\" \"May 16 00:00:00 1968\" \"Mar 19 15:00:23 2020\" \"Dec 31 19:00:00 1969\" 4096 0 0 coco.txt\r\n$ node statPreEpoch.js \r\nmtime of coco.txt: Invalid Date\r\n```\r\n\r\nThis is on Linux (in Docker\r\n```bash\r\n$ docker run --rm -it -v $(pwd)/statPreEpoch.js:/src/statPreEpoch.js node:13.10 bash\r\n$ uname -a\r\nLinux 38f95bbffb38 4.19.76-linuxkit #1 SMP Thu Oct 17 19:31:58 UTC 2019 x86_64 GNU/Linux\r\n$ touch -mt 197001010000.00 coco.txt\r\n$ stat coco.txt \r\n  File: coco.txt\r\n  Size: 0         \tBlocks: 0          IO Block: 4096   regular empty file\r\nDevice: abh/171d\tInode: 2910905     Links: 1\r\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\r\nAccess: 2020-03-19 19:10:48.080137057 +0000\r\nModify: 1970-01-01 00:00:00.000000000 +0000\r\nChange: 2020-03-19 19:10:48.080137057 +0000\r\n$ node  /src/statPreEpoch.js\r\nmtime of coco.txt: Thu Jan 01 1970 00:00:00 GMT+0000 (Coordinated Universal Time)\r\n\r\n# This is the bug\r\n$ touch -mt 196805160000.00 coco.txt \r\n$ stat coco.txt \r\n  File: coco.txt\r\n  Size: 0         \tBlocks: 0          IO Block: 4096   regular empty file\r\nDevice: abh/171d\tInode: 2910905     Links: 1\r\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\r\nAccess: 2020-03-19 19:10:48.080137057 +0000\r\nModify: 1968-05-16 00:00:00.000000000 +0000\r\nChange: 2020-03-19 19:12:24.343012135 +0000\r\n Birth: -\r\n$ node  /src/statPreEpoch.js\r\nmtime of coco.txt: Invalid Date\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEvery time that mtime < unix epoch (1970-01-01T00:00:00Z)\r\n\r\n### What is the expected behavior?\r\n\r\nReturn a valid Date Object, for example\r\n\r\n```bash\r\n$ node  /src/statPreEpoch.js\r\nmtime of coco.txt: Thu May 16 1968 00:00:00 GMT+0000 (Coordinated Universal Time)\r\n```\r\n\r\n```js\r\n> new Date(\"1968-05-16T00:00:00-04:00\")\r\n1968-05-16T04:00:00.000Z\r\n> new Date(\"1968-05-16T00:00:00-04:00\").getTime()\r\n-51393600000\r\n```\r\n\r\n### What do you see instead?\r\n\r\n```bash\r\n$ node  /src/statPreEpoch.js\r\nmtime of coco.txt: Invalid Date\r\n```\r\n\r\n### Additional information\r\n\r\nI discovered this behavior by trying to use `fs.utimes` which is also not able to correctly handle dates before unix epoch, although `fs.utimes` seems to have a workaround by using the string representation of unix time.",
        "labels": "confirmed-bug",
        "id": 44958
    },
    {
        "title": "crypto.privateDecrypt keeps failing after \"Passphrase required\" error",
        "body": "* **Version**: v13.10.1\r\n* **Platform**: Ubuntu 18.04\r\n* **Subsystem**: crypto\r\n\r\nIf you call `crypto.privateDecrypt(...)` with an passphrase-encrypted private RSA key PEM but without providing a passphrase, it correctly raises `TypeError: Passphrase required for encrypted key`. But after that, if you try to call it again with an *unencrypted* private RSA key PEM, then the same error is raised. It seems like the first call corrupts some internal state (maybe openssl one) breaking subsequent calls. Example follows:\r\n\r\n```js\r\n// 1- Generate RSA key pair\r\nconst crypto = require('crypto')\r\nconst pair = crypto.generateKeyPairSync('rsa', { modulusLength : 1024 })\r\n\r\n// 2- Create a PEM uncrypted and the same one but encrypted with a passphrase\r\nconst privPEM        = pair.privateKey.export({ type : 'pkcs1', format : 'pem'})\r\nconst privPEMcrypted = pair.privateKey.export({ type : 'pkcs1', format : 'pem', \r\n                                                cipher : 'aes128', passphrase : 'mysecret'})\r\n\r\n// 3- Encrypt some data with public Key, works OK.\r\nconst dataEncrypted = crypto.publicEncrypt(pair.publicKey, Buffer.from(\"raw data\"))\r\n\r\n// 4- Try to decrypt it using the uncrypted Priv PEM (FIRST TIME)\r\nconst decrypt = (pem) => crypto.privateDecrypt(pem, dataEncrypted).toString()\r\n\r\n// As expected, this works ok:\r\nconsole.log('decrypt privPEM 1:', decrypt(privPEM)) \r\n\r\n// 5- Now try to decrypt it using the crypted Priv PEM but WITHOUT specifing a\r\n// passphrase. This will expectedly fail raising an exception:\r\ntry { \r\n    decrypt(privPEMcrypted)\r\n    // => TypeError: Passphrase required for encrypted key\r\n} catch(e) {\r\n    console.log('Ok, I expected this error:', e)\r\n}\r\n\r\n// 6- Now repeat the SAME step 4, this will FAIL with the same 'Passphrase\r\n// required for encrypted key' error from step 5, but this PEM is uncrypted, so\r\n// we found a bug.\r\nconsole.log(\"\\n\\nNow this must not fail... but it does:\")\r\n\r\nconsole.log('decrypt privPEM 2:', decrypt(privPEM))\r\n// => TypeError: Passphrase required for encrypted key\r\n```\r\nOutput:\r\n\r\n```\r\n$ node test-crypto-bug.js \r\ndecrypt privPEM 1: raw data\r\nOk, I expected this error: TypeError: Passphrase required for encrypted key\r\n    at Object.privateDecrypt (internal/crypto/cipher.js:63:12)\r\n    at decrypt (/tmp/test-crypto-bug.js:14:33)\r\n    at Object.<anonymous> (/tmp/test-crypto-bug.js:22:5)\r\n    at Module._compile (internal/modules/cjs/loader.js:1147:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1167:10)\r\n    at Module.load (internal/modules/cjs/loader.js:996:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:896:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12)\r\n    at internal/main/run_main_module.js:17:47 {\r\n  code: 'ERR_MISSING_PASSPHRASE'\r\n}\r\n\r\n\r\nNow this must not fail... but it does:\r\ninternal/crypto/cipher.js:63\r\n    return method(data, format, type, passphrase, buffer, padding, oaepHash,\r\n           ^\r\n\r\nTypeError: Passphrase required for encrypted key\r\n    at Object.privateDecrypt (internal/crypto/cipher.js:63:12)\r\n    at decrypt (/tmp/test-crypto-bug.js:14:33)\r\n    at Object.<anonymous> (/tmp/test-crypto-bug.js:33:35)\r\n    at Module._compile (internal/modules/cjs/loader.js:1147:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1167:10)\r\n    at Module.load (internal/modules/cjs/loader.js:996:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:896:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12)\r\n    at internal/main/run_main_module.js:17:47 {\r\n  code: 'ERR_MISSING_PASSPHRASE'\r\n}\r\n/tmp$ \r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 44959
    },
    {
        "title": "\"Cannot find module\" when main file not `index.js` with experimental-specifier-resolution=node",
        "body": "* **Version**: 13.9.0\r\n* **Platform**: Linux\r\n\r\n### What steps will reproduce the bug?\r\n\r\n1. Clone https://github.com/dandv/node-cant-find-module-with-main-not-index.js\r\n2. `npm start`\r\n\r\n### What is the expected behavior?\r\n\r\nThe script should display `Success!`, and does do so if `mypackage/Lib.js` is renamed to `mypackage/index.js`.\r\n\r\n### What do you see instead?\r\n\r\n```\r\ninternal/modules/esm/resolve.js:61\r\n  let url = moduleWrapResolve(specifier, parentURL);\r\n            ^\r\n\r\nError: Cannot find module /home/dandv/prg/node-cant-find-module-with-main-not-index.js/mypackage imported from /home/dandv/prg/node-cant-find-module-with-main-not-index.js/run.js\r\n    at Loader.defaultResolve [as _resolve] (internal/modules/esm/resolve.js:61:13)\r\n    at Loader.resolve (internal/modules/esm/loader.js:85:40)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:191:28)\r\n    at ModuleWrap.<anonymous> (internal/modules/esm/module_job.js:42:40)\r\n    at link (internal/modules/esm/module_job.js:41:36) {\r\n  code: 'ERR_MODULE_NOT_FOUND'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\nI'm trying to run node with `-experimental-specifier-resolution=node` because [TypeScript can't output .mjs files](https://github.com/microsoft/TypeScript/issues/18442) and I want to use extension-less `import` statements. I prefer to use `Lib.js` instead of `index.js` to distinguish in my IDE between the main files of multiple packages in my monorepo that otherwise would all look like `index.js`.",
        "labels": "confirmed-bug",
        "id": 44960
    },
    {
        "title": "SSL_Error_rx_Record_too_long after upgrading from Node 13.8 to 13.9 or 13.10",
        "body": "* **Version**: 13.9, 13.10\r\n* **Platform**: All\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\nI am maintainer of [cWS](https://github.com/ClusterWS/cWS) which is C++ WebSocket  bindings for Node js. To reproduce issue you can fork repo use node 13.8 then run `node ./examples/ssl.js` and navigate to `https://localhost:3000` (in dev tools you will see that wss connection established properly). Then after upgrading to node 13.9 or 13.10 wss connection does not work any more. In Firefox i am getting `ssl_error_rx_record_too_long`. By the way cWS runs on `TLSv1_2_method`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways\r\n\r\n### What is the expected behavior?\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nWork the same way as Node 13.8 and correctly establish wss connection and work\r\n\r\n### What do you see instead?\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nSSL errors after connect\r\n",
        "labels": "confirmed-bug",
        "id": 44961
    },
    {
        "title": "CLS store gets reset on the first callback in http scenario",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: Linux\r\n* **Subsystem**: async_hooks\r\n\r\n### What steps will reproduce the bug?\r\n\r\nI have been trying to write some new scenarios for AsyncLocalStorage class, as mentioned in https://github.com/nodejs/node/issues/31978, and came across this issue:\r\n\r\n\r\n```js\r\nconst { AsyncLocalStorage } = require('async_hooks');\r\nconst http = require('http')\r\nconst cls = new AsyncLocalStorage();\r\n\r\nconst server = http.createServer((req, res) => {\r\n  res.write('hello')\r\n  setTimeout(() => {\r\n    res.end(' world!')\r\n  }, 1000)\r\n})\r\n\r\nserver.listen(12000, () => {\r\n  cls.run(() => {\r\n    const req = http.get('http://localhost:12000', (res) => {\r\n      const store = cls.getStore()\r\n      store.set('foo', '')\r\n      res.on('data', (d) => { console.log(cls.getStore()) });\r\n    })\r\n    req.end()\r\n  })\r\n})\r\n```\r\n\r\nIn this simple client-server program, the server is sending two chunks of data, forcing the `ondata` handler to be invoked twice.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nevery time\r\n\r\n### What is the expected behavior?\r\n\r\nI get an empty Map every time in the ondata callback\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nUnfortunately, the store is `undefined` after the first invocation:\r\n\r\n```trace\r\n$ node foo.js\r\nMap(1) { 'foo' => '' }\r\nundefined\r\n^C\r\n$\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nIf I replace this with a simple timer code, this logic works fine:\r\n\r\n```js\r\nconst { AsyncLocalStorage } = require('async_hooks');\r\nconst cls = new AsyncLocalStorage();\r\n\r\ncls.run(() => {\r\n  const store = cls.getStore()\r\n  store.set('foo', 'bar')\r\n  setInterval(() => {\r\n    console.log(cls.getStore().get('foo'))\r\n  }, 1000)\r\n}) \r\n```\r\n\r\n$ node timer.js\r\n```trace\r\nbar\r\nbar\r\nbar\r\nbar\r\n^C\r\n```\r\n\r\n\r\nAm I missing something?\r\n\r\nPing @vdeturckheim \r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44962
    },
    {
        "title": "Building LTS v12.x on Windows Fails The system cannot find the file specified.\"",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.x\r\n* **Platform**: Windows\r\n* **Subsystem**:\r\n\r\nI took the documentation specified in Building.md and converted that into a DockerFile. I had to make some additions to supplement the boxstarter scripts because that ran into errors installing the build tools. To get around that issue I installed those first via npm, [following guidelines in this post](https://spin.atomicobject.com/2019/03/27/node-gyp-windows/), then called the boxstarter scripts. This enabled me to get passed that particular problem but now I have a new issue which is detailed below in the console output. I have included a dockerfile to reproduce the issue. Any assistance will be greatly appreciated.\r\n\r\nOutput of the build\r\n```Powershell\r\nC:\\node>.\\vcbuild full-icu download-all\r\nLooking for Python\r\nPython 2 found in C:\\Python27\\\\python.exe\r\nLooking for NASM\r\nLooking for Visual Studio 2017\r\nFound MSVS version 15.0\r\nconfigure  \"--download=all\" --with-intl=full-icu --dest-cpu=x64\r\nINFO: Using floating patch \"tools/icu/patches/64/source/common/putil.cpp\" from \"tools/icu\"\r\nINFO: Using floating patch \"tools/icu/patches/64/source/i18n/dtptngen.cpp\" from \"tools/icu\"\r\nWarning: Missing input files:\r\ntools\\msvs\\genfiles\\node_etw_provider.rc\r\ntools\\msvs\\genfiles\\node_etw_provider.h\r\ntools\\v8_gypfiles\\..\\..\\deps\\v8\\src\\regexp\\regexp-special-case.h\r\nINFO: configure completed successfully\r\nProject files generated.\r\nThe system cannot find the file specified.\r\n```\r\n\r\nDockerfile to reproduce the behaviour\r\n\r\n```Dockerfile\r\nARG version=ltsc2019\r\nFROM mcr.microsoft.com/windows/servercore:$version\r\n\r\nENV chocolateyUseWindowsCompression false\r\n\r\nRUN powershell -Command \\\r\n    iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1')); \\\r\n    choco feature disable --name showDownloadProgress  \r\n\r\nRUN powershell choco install nodejs-lts -y\r\nRUN npm install --global --production windows-build-tools\r\nRUN npm config set msvs_version 2017 -global\r\nRUN npm install --global node-gyp --no-optional\r\nRUN powershell choco install vim -y \r\n\r\n\r\nRUN powershell -Command \\\r\n    iex ((New-Object System.Net.WebClient).DownloadString('https://boxstarter.org/bootstrapper.ps1')) ; \\\r\n    Get-Boxstarter -Force ; \\\r\n    Install-BoxstarterPackage https://raw.githubusercontent.com/nodejs/node/master/tools/bootstrap/windows_boxstarter -DisableReboots\r\n\r\nRUN powershell git clone https://github.com/nodejs/node.git\r\nRUN powershell  Set-Location -Path C:\\Node; git checkout v12.x    \r\n\r\nRUN powershell Set-Location -Path C:\\Node; .\\vcbuild full-icu download-all\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 44963
    },
    {
        "title": "Async generator: catched error on last yield is wrongly rethrown",
        "body": "* **Version**: v13.9.0\r\n* **Platform**: Linux and MacOS\r\n* **Subsystem**: ?\r\n\r\nAlso reproduced in v12 but not in v10 or v11.\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nasync function* gen() {\r\n  try {\r\n    yield 42\r\n  } catch(e) {\r\n    console.log('Error caught!')\r\n  }\r\n}\r\n\r\n(async () => {\r\n  const g = gen()\r\n  await g.next() // go to yield 42\r\n  try {\r\n    await g.throw(new Error()) // throw error from the yield\r\n  } catch (e) {\r\n    console.error('e has been rethrown !')\r\n  }\r\n})()\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThis happens only:\r\n - with async generators\r\n - on the last yield\r\n - without any explicit return (in the generator)\r\n\r\n### What is the expected behavior?\r\n\r\n`g.throw()` should return a result `{ done: true, value: undefined }`\r\n\r\n### What do you see instead?\r\n\r\n`g.throw()` rethrows the error.\r\n\r\n### Additional information\r\n",
        "labels": "confirmed-bug",
        "id": 44964
    },
    {
        "title": "Verification with dsaEncoding ieee-p1363 fails.",
        "body": "When you verify a 'ieee-p1363' encoded signature it fails, even if the signature is correct.\r\n* **Version**: v13.8.0\r\n* **Platform**: 64-bit Windows 10\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n```\r\nconst crypto = require('crypto');\r\nconst key = crypto.generateKeyPairSync('ec', { namedCurve: 'P-256' });\r\n\r\n//ieee-p1363 signature, which seems to be the correct.\r\nconst signatureP1363 = crypto.createSign('SHA256').update('abc').sign({ key: key.privateKey, dsaEncoding: 'ieee-p1363' });\r\n//ieee-p1363 verification, which fails.\r\nconsole.log(crypto.createVerify('SHA256').update('abc').verify({ key: key.publicKey, dsaEncoding: 'ieee-p1363' }, signatureP1363));\r\n\r\n//Compared to der signature and verification, which work as expected:\r\nconst signatureDER = crypto.createSign('SHA256').update('abc').sign({ key: key.privateKey, dsaEncoding: 'der' });\r\nconsole.log(crypto.createVerify('SHA256').update('abc').verify({ key: key.publicKey, dsaEncoding: 'der' }, signatureDER));\r\n```\r\n\r\n### Additional information\r\nThe problem seems to be the verification algorithm, not the signing algorithm. You can test that the generated signature is correct in chrome using:\r\n\r\n```\r\n//key.publicKey.export({ format: 'der', type: 'spki' }).toString('base64');\r\nconst base64key = 'MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE/V0xKgeZJeIFra+gshXB6OpM5IKuhHwcBkpu5ZdMZZM62x+GahHJdrll+Q3aihYNfakkzf7W65dIdDAhLImu0w==';\r\n//signatureP1363.toString('base64');\r\nconst base64sig = '+aocUpmRHRSxfpCJpwCCuQoFagatOlsFganmXiqtztFo9iBHqE6z7A7KQcMs1k9VASt3cgtkJqyPKAY4OTyJ8A==';\r\n//Verify the signature\r\nconst uint8key = Uint8Array.from(atob(base64key), (c) => c.charCodeAt(0));\r\nconst uint8sig = Uint8Array.from(atob(base64sig), (c) => c.charCodeAt(0));\r\nconst uint8data = Uint8Array.from('abc', (c) => c.charCodeAt(0));\r\nconst params = { name: 'ECDSA', hash: 'SHA-256', namedCurve: 'P-256' };\r\nconst cryptokey = await window.crypto.subtle.importKey('spki', uint8key, params, false, ['verify']);\r\nawait window.crypto.subtle.verify(params, cryptokey, uint8sig, uint8data);\r\n```",
        "labels": "confirmed-bug",
        "id": 44965
    },
    {
        "title": "12.16/13.8: http response listener throwing does not result in emit of uncaughtException",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.16.0 | 13.8.0\r\n* **Platform**: Darwin Kernel Version 18.6.0\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\nThrowing from a response listener (callback) to `http.get()` will not trigger `process.once('uncaughtException', () => {})`. Interestingly, throwing from a request listener (callback) to `http.createServer()`  will still. \r\n\r\nThis behavior changed with 12.16.0, I'm guessing likely due to the porting of the emit changes?\r\n\r\n```js\r\nconst http = require('http')\r\n\r\nlet server\r\nlet request\r\n\r\nprocess.once('uncaughtException', function() {\r\n  // never gets here from response listener in 12.16, works fine < 12.16.\r\n  console.log('in uncaughtException handler')\r\n\r\n  server.close(done)\r\n})\r\n\r\nserver = http.createServer(function cb_createServer(request, response) {\r\n  // Throw from request listener will result in uncaughtException\r\n  //throw new Error('wat')\r\n  response.writeHead(200, {'Content-Type': 'text/plain'})\r\n  response.end()\r\n})\r\n\r\nserver.listen(8183, function() {\r\n  request = http.get({host: 'localhost', port: 8183}, function() {\r\n    // Throw from response listener will not result in uncaughtException\r\n    throw new Error('whoah')\r\n  })\r\n})\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nConsistently does not trigger `uncaughtException` / does not allow handling via `process.on('uncaughtException', ...)`.\r\n\r\n### What is the expected behavior?\r\n\r\nShould be able to notice the uncaught exception thrown from the handler.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44966
    },
    {
        "title": "package self-reference works without a flag in node v12.16",
        "body": "Repro: clone https://github.com/ljharb/has-package-exports\r\n\r\nIt has a dev dep of `\"has-package-exports\": \"file:.\"`, so that in every node version, i can `require('has-package-exports')` from within the package, and it works.\r\n\r\nIn node v13.6 and v12.15, `node test` passes without issuing `(node:96292) ExperimentalWarning: Package name self resolution is an experimental feature. This feature could change at any time` as a warning.\r\n\r\nIn node v13.7, the warning is correctly issued, and the local dev dep is byassed.\r\n\r\nHowever, in node v12.16, without passing any flags, the warning is issued and the local dev dep is bypassed. v12.16 and v12.15 should behave identically with respect to this feature, regardless of the presence of \"exports\" in package.json.\r\n\r\ncc @nodejs/modules-active-members ",
        "labels": "confirmed-bug",
        "id": 44967
    },
    {
        "title": "child_process: spawnSync crashes trying to terminate setuid child because of maxBuffer exceeded",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v13.8.0, v12.16.0\r\n* **Platform**: macOS 10.15.3, Ubuntu 16.04.6 (4.15.0-70-generic)\r\n* **Subsystem**: child_process, src/spawn_sync.c\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```\r\n$ cat test.c\r\n#include <unistd.h>\r\n#include <stdio.h>\r\nint main() { setuid(0); while (1) printf(\"hello\"); }\r\n\r\n$ gcc -o test test.c; sudo chown root test; sudo chmod 4755 test\r\n\r\n$ node -e \"require('child_process').spawnSync('./test')\"\r\n```\r\n\r\nOR\r\n\r\n```\r\n$ node -e \"require('child_process').spawnSync('sudo', ['bash', '-c', 'ls -lR /'])\"\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nI expect to get `ENOBUF` (because of maxBuffer reached) and/or `EPERM` (because child process cannot be killed), so I can handle it somehow - but not crash.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n```\r\nnode[68984]: ../src/spawn_sync.cc:611:void node::SyncProcessRunner::Kill(): Assertion `r >= 0 || r == UV_ESRCH' failed.\r\n 1: 0x100ba0c4a node::Abort() (.cold.1) [/usr/local/bin/node]\r\n 2: 0x100084961 node::FatalError(char const*, char const*) [/usr/local/bin/node]\r\n 3: 0x100084719 node::AppendExceptionLine(node::Environment*, v8::Local<v8::Value>, v8::Local<v8::Message>, node::ErrorHandlingMode) [/usr/local/bin/node]\r\n 4: 0x10010657d node::SyncProcessRunner::Kill() [/usr/local/bin/node]\r\n 5: 0x1006cb116 uv__stream_io [/usr/local/bin/node]\r\n 6: 0x1006d23a8 uv__io_poll [/usr/local/bin/node]\r\n 7: 0x1006c2fa2 uv_run [/usr/local/bin/node]\r\n 8: 0x10010598f node::SyncProcessRunner::TryInitializeAndRunLoop(v8::Local<v8::Value>) [/usr/local/bin/node]\r\n 9: 0x100105674 node::SyncProcessRunner::Run(v8::Local<v8::Value>) [/usr/local/bin/node]\r\n10: 0x100105513 node::SyncProcessRunner::Spawn(v8::FunctionCallbackInfo<v8::Value> const&) [/usr/local/bin/node]\r\n11: 0x1001cb578 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [/usr/local/bin/node]\r\n12: 0x1001cac02 v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/usr/local/bin/node]\r\n13: 0x1001ca40e v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/usr/local/bin/node]\r\n14: 0x1007503d9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/usr/local/bin/node]\r\nzsh: abort      node -e \"require('child_process').spawnSync('./test')\"\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nAccording to documentation, `child_process.spawnSync()` terminates child process if it's output is larger than `maxBuffer`. If child process can't be killed (because of setuid call), node crashes in `CHECK()` below https://github.com/nodejs/node/blob/master/src/spawn_sync.cc#L611:\r\n\r\n```\r\n    // If uv_kill failed with an error that isn't ESRCH, the user probably\r\n    // specified an invalid or unsupported signal. Signal this to the user as\r\n    // and error and kill the process with SIGKILL instead.\r\n    if (r < 0 && r != UV_ESRCH) {\r\n      SetError(r);\r\n\r\n      r = uv_process_kill(&uv_process_, SIGKILL);\r\n      CHECK(r >= 0 || r == UV_ESRCH);\r\n    }\r\n```\r\n\r\nShouldn't we also check for UV_EPERM?",
        "labels": "confirmed-bug",
        "id": 44968
    },
    {
        "title": "https module sometimes emits 'empty' Error",
        "body": "* **Version**: v14.16.0\r\n* **Platform**: Darwin Kernel Version 20.3.0 (macOS 11.2.3)\r\n* **Subsystem**: https\r\n\r\n### What steps will reproduce the bug?\r\n\r\nEvery few times this is run, the request emits an error with `name == 'Error'`, `message == ''`, and `stack = 'Error'`. There is nothing attached to the error object that reveals what the underlying error is.\r\n\r\n```javascript\r\nconst url = \"https://deeplearning.podomatic.com/rss2.xml\"\r\nconst http = require('https')\r\n\r\nhttp.get(url, function(res) {\r\n  res.on(\"error\", err => {\r\n    console.log(\"response error\")\r\n  }).on(\"end\", () => {\r\n    console.log(\"response end\")\r\n  }).on(\"close\", () => {\r\n    console.log(\"response close\")\r\n  }).on(\"pause\", () => {\r\n    console.log(\"response pause\")\r\n  }).on(\"resume\", () => {\r\n    console.log(\"response resume\")\r\n  }).on(\"data\", chunk => {\r\n    console.log(\"response data\")\r\n  })\r\n}).on(\"error\", err => {\r\n  console.log(`request error:\\n  Message:${err.message}\\n  Name: ${err.name}\\n  Stack: ${err.stack}\\n`)\r\n}).on(\"end\", () => {\r\n  console.log(\"request end\")\r\n}).on(\"close\", () => {\r\n  console.log(\"request close\")\r\n}).on(\"finish\", () => {\r\n  console.log(\"request finish\")\r\n}).on(\"abort\", () => {\r\n  console.log(\"request abort\")\r\n}).on(\"connect\", () => {\r\n  console.log(\"request connect\")\r\n}).on(\"continue\", () => {\r\n  console.log(\"request continue\")\r\n}).on(\"drain\", () => {\r\n  console.log(\"request drain\")\r\n}).on(\"information\", () => {\r\n  console.log(\"request information\")\r\n}).on(\"pipe\", () => {\r\n  console.log(\"request pipe\")\r\n}).on(\"response\", () => {\r\n  console.log(\"request response\")\r\n}).on(\"socket\", () => {\r\n  console.log(\"request socket\")\r\n}).on(\"timeout\", () => {\r\n  console.log(\"request timeout\")\r\n}).on(\"unpipe\", () => {\r\n  console.log(\"request unpipe\")\r\n}).on(\"upgrade\", () => {\r\n  console.log(\"request upgrade\")\r\n})\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nFrequently, but probably less than 50% of the time.\r\n\r\n### What is the expected behavior?\r\n\r\nIf an error is emitted, it should contain information about the underlying error.\r\n\r\n### What do you see instead?\r\n\r\nIf an error is emitted, it has no information about the underlying error.\r\n\r\n### Additional information\r\n\r\n* The response code is always 200.\r\n* ~~The file this URL points to is always fully downloaded after a single `data` event is emitted.~~  This bit was just a coincidence, the error, if it is emitted, is always emitted after the last `data` event.\r\n* This happens in node 12.18.x as well\r\n* This happens on repl.it as well, so it isn't just my machine.\r\n* The request error is emitted after the response emits `end` but before the request emits `close`\r\n* Downloading this file with curl does not fail\r\n* `podomatic.com` is the only domain I've noticed this with so far.\r\n\r\nWhen no error is emitted, the output of the repro script looks like:\r\n\r\n```\r\nrequest socket\r\nrequest finish\r\nrequest response\r\nresponse resume\r\nresponse data\r\nresponse end\r\nrequest close\r\nresponse close\r\n```\r\n\r\nWhen it does emit an error, the output of the repro script looks like:\r\n\r\n```\r\nrequest socket\r\nrequest finish\r\nrequest response\r\nresponse resume\r\nresponse data\r\nresponse end\r\nrequest error:\r\n  Message:\r\n  Name: Error\r\n  Stack: Error\r\n\r\nrequest close\r\nresponse close\r\n```\r\n\r\nI suspect there is a configuration issue with the affected domain, but the error message node emits should indicate what the underlying problem is.\r\n",
        "labels": "confirmed-bug",
        "id": 44969
    },
    {
        "title": "URL: Forbid | (pipe) in URL host",
        "body": "Refs: https://github.com/whatwg/url/pull/589\r\n\r\nThis should not be allowed per recent spec change: `new URL('http://exa|mple.org')`;",
        "labels": "confirmed-bug",
        "id": 44970
    },
    {
        "title": "Http2 throws non-descriptive error \"Error [ERR_HTTP2_ERROR]: The user callback function failed\"",
        "body": "* **Version**: 14.16.0, 15.12.0\r\n* **Platform**: 18.7.0 Darwin Kernel Version 18.7.0: Mon Aug 31 20:53:32 PDT 2020; root:xnu-4903.278.44~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: http2\r\n\r\n### What steps will reproduce the bug?\r\n```\r\nasync function main() {\r\n  const client = http2.connect('https://www.postgresql.org');\r\n  const stream = client.request({\r\n    ':method': 'GET',\r\n    ':path': '/',\r\n    'accept-encoding': 'gzip, deflate, br',\r\n  });\r\n\r\n  const buffer: Buffer[] = [];\r\n  for await (const data of stream) {\r\n    buffer.push(data);\r\n  }\r\n  const response = Buffer.concat(buffer).toString();\r\n  console.log(response);\r\n}\r\n\r\nmain().catch(err => console.log('Http2 User Error', err));\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nIt will happen every time. When looking deeper into http2 frames, it appears the use of the Varnish? gzip module on the end site is causing an EOF frame to be incorrectly sent. nghttp2 treats any http2 violation as fatal, and so does nodejs.\r\n\r\n### What is the expected behavior?\r\nIdeally, there would be a way to allow the code to continue since this is really just an invalid EOF code. Chrome's handling of http2 seems to handle this fine. They're obviously more interested in a lenient solution to http2 errors than nodejs.\r\n\r\nIf there's not a way to provide a lenient mode, or to decide what to do in the case of frame errors, I would have expected this to throw a more descriptive error that says something about the end site having an invalid http2 implementation.\r\n\r\n### What do you see instead?\r\nThe following are a snippet of running the example with NODE_DEBUG=http2*,stream* NODE_DEBUG_NATIVE=http2\r\n```\r\nSTREAM 3518: need readable true\r\nSTREAM 3518: length less than watermark true\r\nSTREAM 3518: do read\r\nHttpStream 1 (23) [Http2Session client (19)] reading starting\r\nSTREAM 3518: read undefined\r\nSTREAM 3518: need readable true\r\nSTREAM 3518: length less than watermark true\r\nSTREAM 3518: reading or ended false\r\nSTREAM 3518: read undefined\r\nSTREAM 3518: need readable true\r\nSTREAM 3518: length less than watermark true\r\nSTREAM 3518: reading or ended false\r\nHttp2Session client (19) complete frame received: type: 0\r\nHttp2Session client (19) handling data frame for stream 1\r\nHttp2Session client (19) complete frame received: type: 0\r\nHttp2Session client (19) handling data frame for stream 1\r\nHttp2Session client (19) fatal error receiving data: -902\r\nHTTP2 3518: Http2Session client: destroying\r\nHTTP2 3518: Http2Session client: start closing/destroying Error [ERR_HTTP2_ERROR]: The user callback function failed\r\n    at Http2Session.onSessionInternalError (internal/http2/core.js:751:26) {\r\n  code: 'ERR_HTTP2_ERROR',\r\n  errno: -902\r\n}\r\nHTTP2 3518: Http2Stream 1 [Http2Session client]: destroying stream\r\n```\r\n\r\n### Additional information\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 44971
    },
    {
        "title": "\"crypto.createDiffieHellman\" results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.15.1\r\n* **Platform**:  Linux 5.8.0-38-generic #43~20.04.1-Ubuntu SMP Tue Jan 12 16:39:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto.createDiffieHellman\r\n\r\n### What steps will reproduce the bug?\r\nSetup a node instance,\r\n```\r\nÂ» node\r\n```\r\nand run the following javascript code.\r\n```\r\ncrypto.createDiffieHellman('',true);\r\n```\r\nThen an abort occurs.\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nThis abort can always be triggered following the steps above.\r\n\r\n### What is the expected behavior?\r\nIf any error occurs, an exception or other similar error-reporting stuff should be thrown. There is no reason to abort the whole node process.\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n```\r\nÂ» node\r\ncrypto.createDiffieHellman('',true);\r\nnode[79037]: ../src/util-inl.h:490:node::ArrayBufferViewContents<T, kStackStorageSize>::ArrayBufferViewContents(v8::Local<v8::Value>) [with T = char; long unsigned int kStackStorageSize = 64]: Assertion `value->IsArrayBufferView()' failed.\r\n 1: 0xa03530 node::Abort() [node]\r\n 2: 0xa035ae  [node]\r\n 3: 0xb396fa node::ArrayBufferViewContents<char, 64ul>::ArrayBufferViewContents(v8::Local<v8::Value>) [node]\r\n 4: 0xb30625 node::crypto::DiffieHellman::New(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 5: 0xbe4695  [node]\r\n 6: 0xbe4c9f  [node]\r\n 7: 0xbe52c6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 8: 0x13ff259  [node]\r\n[1]    79037 abort (core dumped)  node\r\n                                                                                                                                                                                                                                                 \r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44972
    },
    {
        "title": "\"clearImmediate\" results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.15.1\r\n* **Platform**: Linux 5.8.0-38-generic #43~20.04.1-Ubuntu SMP Tue Jan 12 16:39:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: clearImmediate\r\n\r\n### What steps will reproduce the bug?\r\nSetup a node instance,\r\n```\r\nÂ» node\r\n```\r\nand run the following javascript code.\r\n```\r\nclearImmediate({hasRef: true, _onImmediate: 100000000000000000})\r\n```\r\nThen an abort occurs.\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nThis abort can always be triggered following the steps above.\r\n\r\n### What is the expected behavior?\r\nIf any error occurs, an exception or other similar error-reporting stuff should be thrown. There is no reason to abort the whole node process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n```\r\nÂ» node\r\nWelcome to Node.js v14.15.1.\r\nType \".help\" for more information.\r\n> clearImmediate({hasRef: true, _onImmediate: 100000000000000000})\r\nnode[65197]: ../src/async_wrap.cc:623:static void node::AsyncWrap::QueueDestroyAsyncId(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `args[0]->IsNumber()' failed.\r\n 1: 0xa03530 node::Abort() [node]\r\n 2: 0xa035ae  [node]\r\n 3: 0x979ceb node::AsyncWrap::QueueDestroyAsyncId(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 4: 0xbe369b  [node]\r\n 5: 0xbe4c46  [node]\r\n 6: 0xbe52c6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 7: 0x13ff259  [node]\r\n[1]    65197 abort (core dumped)  node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44973
    },
    {
        "title": "\"tty.isatty\" results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.15.1\r\n* **Platform**:  Linux 5.8.0-38-generic #43~20.04.1-Ubuntu SMP Tue Jan 12 16:39:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: tty.isatty\r\n\r\n### What steps will reproduce the bug?\r\nSetup a node instance,\r\n```\r\nÂ» node\r\n```\r\nand run the following javascript code.\r\n```\r\ntty = require('tty');tty.isatty(1000000000000000000);\r\n```\r\nThen an abort occurs.\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nThis abort can always be triggered following the steps above.\r\n\r\n### What is the expected behavior?\r\nIf any error occurs, an exception or other similar error-reporting stuff should be thrown. There is no reason to abort the whole node process.\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n```\r\nÂ» node                                                                                                                                                                                                                                                 134 â†µ zys@zys-X299-UD4-Pro\r\nWelcome to Node.js v14.15.1.\r\nType \".help\" for more information.\r\n> tty = require('tty');tty.isatty(1000000000000000000);\r\nnode[57893]: ../src/tty_wrap.cc:73:static void node::TTYWrap::IsTTY(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `(fd) >= (0)' failed.\r\n 1: 0xa03530 node::Abort() [node]\r\n 2: 0xa035ae  [node]\r\n 3: 0xaea222  [node]\r\n 4: 0xbe369b  [node]\r\n 5: 0xbe4c46  [node]\r\n 6: 0xbe52c6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 7: 0x13ff259  [node]\r\n[1]    57893 abort (core dumped)  node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44974
    },
    {
        "title": "crypto: verify with callback crashes when private key is used",
        "body": "Introduced in #37500 (released with v15.12.0) the function call crashes node when a private key object is passed to verify when using the callback argument.\r\n\r\n```js\r\nconst crypto = require('crypto');\r\nconst assert = require('assert');\r\n\r\nconst data = Buffer.from('hello');\r\nconst { privateKey } = crypto.generateKeyPairSync('ed25519');\r\nconst signature = crypto.sign(null, data, privateKey);\r\n\r\nassert(crypto.verify(null, data, privateKey, signature)); // OK\r\n\r\ncrypto.verify(null, data, privateKey, signature, (err, verified) => { // ðŸ’¥\r\n  assert(!err);\r\n  assert(verified);\r\n});\r\n```\r\n\r\n```\r\nnode[49326]: ../src/crypto/crypto_sig.cc:850:static bool node::crypto::SignTraits::DeriveBits(node::Environment *, const node::crypto::SignConfiguration &, node::crypto::ByteSource *): Assertion `(params.key->GetKeyType()) == (kKeyTypePublic)' failed.\r\n```\r\n\r\nThis can never happen in webcrypto where this implementation was first used but it is a valid input for one shot verify.\r\n\r\nI'm looking into a fix and expanding the test suite.\r\n\r\ncc @jasnell ",
        "labels": "confirmed-bug",
        "id": 44975
    },
    {
        "title": "child_process 'spawn' event is emitted too soon",
        "body": "**Version**: `15.1.0` thru `15.11.0` (see screenshot below)\n**Platform**: `Darwin CALLMT20389 19.6.0 Darwin Kernel Version 19.6.0: Thu Oct 29 22:56:45 PDT 2020; root:xnu-6153.141.2.2~1/RELEASE_X86_64 x86_64`\n\n### What steps will reproduce the bug?\n\nRun the following simple repro example:\n\n```console\n$> node ./parent.mjs\n```\n\n<details>\n<summary>parent.mjs</summary>\n\n```js\nimport { fork } from 'child_process';\n\n\nconst subprocess = fork('./child.mjs');\n\nsubprocess.on('close', (...args) => { console.error('[PARENT] received', ...args) });\nsubprocess.on('disconnect', (...args) => { console.error('[PARENT] received', ...args) });\nsubprocess.on('error', (...args) => { console.error('[PARENT] received', ...args) });\nsubprocess.on('exit', (...args) => { console.error('[PARENT] received', ...args) });\nsubprocess.on('message', (...args) => { console.log('[PARENT] received', ...args) });\nsubprocess.on('spawn', () => {\n  console.log({\n    'parent::subprocess.send': subprocess.send({ hello: 'child' })\n  });\n});\n```\n</details>\n\n<details>\n<summary>child.mjs</summary>\n\n```js\nprocess.on('message', (...args) => { console.log('[CHILD] received', ...args) });\n\nprocess.send({ hello: 'parent' });\n```\n</details>\n\n### How often does it reproduce? Is there a required condition?\n\n100% of the time (dozens of executions)\n\n### What is the expected behavior?\n\nchild's process.on('message') should be triggered (parent's message should be received and logged to console).\n\n### What do you see instead?\n\nOnly parent's subprocess.on('message') is triggered:\n\n```console\n$> node ./parent.mjs\n{ 'parent::subprocess.send': true }\n[PARENT] received { hello: 'parent' }\n```\n\n![image](https://user-images.githubusercontent.com/3012099/111513980-b0865500-8727-11eb-8d07-617170365ded.jpeg)\n\n### Additional info\n\nI installed node via nvm. I verified the version of node actually running is truly 15.11.0 by console logging `process.version` in both parent.mjs and child.mjs (both output `v15.11.0`)",
        "labels": "confirmed-bug",
        "id": 44976
    },
    {
        "title": "Nodejs runs out of memory trying to connect to HTTPS host with self-signed certificate",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: 15.11.0 (also tested with 12 and 14 on same machine)\r\nPlatform: Ubuntu 16.04 (Linux 4.4.0-1127.8.2.vz7.151.14 #1 SMP Tue Jun 9 12:58:54 MSK 2020 x86_64 x86_64 x86_64 GNU/Linux)\r\nSubsystem: https\r\n-->\r\n\r\n* **Version**: 15.11.0 (also tested with 12 and 14 on same machine)\r\n* **Platform**: Ubuntu 16.04 (Linux 4.4.0-1127.8.2.vz7.151.14 #1 SMP Tue Jun 9 12:58:54 MSK 2020 x86_64 x86_64 x86_64 GNU/Linux)\r\n* **Subsystem**: https\r\n\r\n### What steps will reproduce the bug?\r\n\r\nWhen trying to connect to a https-enabled host and using a self-signed certificate provided to node via `NODE_EXTRA_CA_CERTS` node hangs for a few minutes, using more and more memory, until it exits with `Allocation failed - JavaScript heap out of memory`. Full stacktrace below.\r\n\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThe server needs to be up and the correct server certificate needs to be used.\r\n\r\n### What is the expected behavior?\r\n\r\nI would expect the connection to  be made successfully, since the self-signed certificate has been provided to node.\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n```\r\n<--- Last few GCs --->\r\n\r\n[15068:0x52f3bd0]   324861 ms: Scavenge (reduce) 4053.6 (4128.3) -> 4053.4 (4129.3) MB, 72.6 / 0.0 ms  (average mu = 0.851, current mu = 0.769) allocation failure\r\n[15068:0x52f3bd0]   325180 ms: Scavenge (reduce) 4054.9 (4129.3) -> 4054.8 (4131.1) MB, 86.6 / 0.0 ms  (average mu = 0.851, current mu = 0.769) allocation failure\r\n[15068:0x52f3bd0]   325442 ms: Scavenge (reduce) 4056.6 (4131.1) -> 4056.4 (4132.6) MB, 71.5 / 0.0 ms  (average mu = 0.851, current mu = 0.769) allocation failure\r\n\r\n\r\n<--- JS stacktrace --->\r\n\r\nFATAL ERROR: MarkCompactCollector: young object promotion failed Allocation failed - JavaScript heap out of memory\r\n 1: 0xa7f490 node::Abort() [node]\r\n 2: 0x9a5c4d node::FatalError(char const*, char const*) [node]\r\n 3: 0xc6c2ae v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [node]\r\n 4: 0xc6c627 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [node]\r\n 5: 0xe360a5  [node]\r\n 6: 0xe65633 v8::internal::EvacuateNewSpaceVisitor::Visit(v8::internal::HeapObject, int) [node]\r\n 7: 0xe721e6 v8::internal::FullEvacuator::RawEvacuatePage(v8::internal::MemoryChunk*, long*) [node]\r\n 8: 0xe5e30f v8::internal::Evacuator::EvacuatePage(v8::internal::MemoryChunk*) [node]\r\n 9: 0xe5e588 v8::internal::PageEvacuationTask::RunInParallel(v8::internal::ItemParallelJob::Task::Runner) [node]\r\n10: 0xe503a9 v8::internal::ItemParallelJob::Run() [node]\r\n11: 0xe74170 void v8::internal::MarkCompactCollectorBase::CreateAndExecuteEvacuationTasks<v8::internal::FullEvacuator, v8::internal::MarkCompactCollector>(v8::internal::MarkCompactCollector*, v8::internal::ItemParallelJob*, v8::internal::MigrationObserver*, long) [node]\r\n12: 0xe749b3 v8::internal::MarkCompactCollector::EvacuatePagesInParallel() [node]\r\n13: 0xe74d75 v8::internal::MarkCompactCollector::Evacuate() [node]\r\n14: 0xe874e1 v8::internal::MarkCompactCollector::CollectGarbage() [node]\r\n15: 0xe433a8 v8::internal::Heap::MarkCompact() [node]\r\n16: 0xe44d38 v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [node]\r\n17: 0xe482dc v8::internal::Heap::AllocateRawWithRetryOrFailSlowPath(int, v8::internal::AllocationType, v8::internal::AllocationOrigin, v8::internal::AllocationAlignment) [node]\r\n18: 0xe0bf3a v8::internal::Factory::AllocateRaw(int, v8::internal::AllocationType, v8::internal::AllocationAlignment) [node]\r\n19: 0xe05444 v8::internal::FactoryBase<v8::internal::Factory>::AllocateRawWithImmortalMap(int, v8::internal::AllocationType, v8::internal::Map, v8::internal::AllocationAlignment) [node]\r\n20: 0xe07540 v8::internal::FactoryBase<v8::internal::Factory>::NewRawOneByteString(int, v8::internal::AllocationType) [node]\r\n21: 0xe1955e v8::internal::Factory::NewStringFromOneByte(v8::internal::Vector<unsigned char const> const&, v8::internal::AllocationType) [node]\r\n22: 0xc839e2 v8::String::NewFromOneByte(v8::Isolate*, unsigned char const*, v8::NewStringType, int) [node]\r\n23: 0xbb5914 node::crypto::GetFingerprintDigest(node::Environment*, evp_md_st const*, x509_st*) [node]\r\n24: 0xbb736e node::crypto::X509ToObject(node::Environment*, x509_st*) [node]\r\n25: 0xbb81e4 node::crypto::GetPeerCert(node::Environment*, std::unique_ptr<ssl_st, node::FunctionDeleter<ssl_st, &SSL_free> > const&, bool, bool) [node]\r\n26: 0xc2b567 node::crypto::TLSWrap::GetPeerCertificate(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n27: 0xcd8cbb  [node]\r\n28: 0xcda26c  [node]\r\n29: 0xcda8e6 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n30: 0x14fa219  [node]\r\n./run.sh: line 5: 15068 Aborted                 node index.js\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nAll files iÂ´ve used to reproduce: [node_https_test.zip](https://github.com/nodejs/node/files/6140472/node_https_test.zip)\r\nhttps_renew_cert.sh is a script used to generate the key/certificate pair. (Sample certificate and key is also included in the zip, so you donÂ´t have to regenerate them, if you donÂ´t have oppenssl installed)\r\nserver.js is the server. Execute with node server.js.\r\nindex.js is the client. Started from run.sh\r\nrun.sh: Starts the client and sets `NODE_EXTRA_CA_CERTS`. (You need to update the path to the certificate)\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44977
    },
    {
        "title": "deepStrictEqual not commutative by not accounting for non-enumerable properties",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:\r\n  * 14.x (but probably also others)\r\n* **Platform**:\r\n  * all\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst { deepStrictEqual } = require(\"assert\");\r\n\r\nconst a = {};\r\nconst b = {};\r\n\r\na.x = 1;\r\n\r\nObject.defineProperties(b, {\r\n  x: {\r\n    value: 1,\r\n    writable: true,\r\n  },\r\n  y: {\r\n    value: 5,\r\n    writable: true,\r\n    enumerable: true,\r\n    configurable: true,\r\n  },\r\n});\r\n\r\nconsole.log({ a, b });\r\ndeepStrictEqual(a, b); // does not assert\r\ndeepStrictEqual(b, a); // does assert\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways\r\n\r\n### What is the expected behavior?\r\nI expect deepStrictEqual to be at least commutative. (Whether it should handle non-enumerable properties may be up for discussion)\r\n\r\n### What do you see instead?\r\n`deepStrictEqual(b, a)` does throw an assertion while `deepStrictEqual(a, b)` does not.\r\n\r\n\r\n### Additional information\r\nIf you point me in the right direction I'm willing to fix it myself.",
        "labels": "confirmed-bug",
        "id": 44978
    },
    {
        "title": "HTTP Response read past end",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.8.*\r\n* **Platform**: All\r\n* **Subsystem**: http\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```mjs\r\nimport net from 'net';\r\nimport http from 'http';\r\n\r\n// create a simple server with too small of content-length\r\nconst body = 'HTTP/1.1 200 OK\\r\\n' +\r\n  'Content-Length: 5\\r\\n' +\r\n  'Connection: close\\r\\n' +\r\n  '\\r\\n' +\r\n  '2ad731e3-4dcd-4f70-b871-0ad284b29ffc'\r\nconst server = net.createServer((conn) => conn.end(body));\r\nconst port = 9191;\r\nserver.listen(port, () => {\r\n  // try to GET from the server\r\n  http.get('http://localhost:' + port);\r\n});\r\n\r\n// causes Error: Parse Error: Expected HTTP/\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\nNo error, doesn't read past content-length and/or doesn't try to parse a second response from a `connection: close` response. Unclear on expected HTTP semantics and common leniency here. Likely shouldn't do either I suspect.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n```console\r\n$ node bug.js\r\nnode:events:355\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: Parse Error: Expected HTTP/\r\n    at Socket.socketOnData (node:_http_client:502:22)\r\n    at Socket.emit (node:events:378:20)\r\n    at addChunk (node:internal/streams/readable:313:12)\r\n    at readableAddChunk (node:internal/streams/readable:288:9)\r\n    at Socket.Readable.push (node:internal/streams/readable:227:10)\r\n    at TCP.onStreamRead (node:internal/stream_base_commons:190:23)\r\nEmitted 'error' event on ClientRequest instance at:\r\n    at Socket.socketOnData (node:_http_client:509:9)\r\n    at Socket.emit (node:events:378:20)\r\n    [... lines matching original stack trace ...]\r\n    at TCP.onStreamRead (node:internal/stream_base_commons:190:23) {\r\n  bytesParsed: 62,\r\n  code: 'HPE_INVALID_CONSTANT',\r\n  reason: 'Expected HTTP/',\r\n  rawPacket: Buffer(93) [Uint8Array] [\r\n     72,  84,  84,  80,  47,  49,  46,  49,  32,  50,  48,  48,\r\n     32,  79,  75,  13,  10,  67, 111, 110, 116, 101, 110, 116,\r\n     45,  76, 101, 110, 103, 116, 104,  58,  32,  53,  13,  10,\r\n     67, 111, 110, 110, 101,  99, 116, 105, 111, 110,  58,  32,\r\n     99, 108, 111, 115, 101,  13,  10,  13,  10,  50,  97, 100,\r\n     55,  51,  49, 101,  51,  45,  52, 100,  99, 100,  45,  52,\r\n    102,  55,  48,  45,  98,  56,  55,  49,  45,  48,  97, 100,\r\n     50,  56,  52,  98,  50,  57, 102, 102,  99\r\n  ]\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44979
    },
    {
        "title": "Crash when mode is to big in fs.createWriteStream",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v` \r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: `v14.15.4`, `v15.9.0`\r\n* **Platform**:  Ubuntu, Mac OS\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\nNode.js crashes on such code:\r\n```js\r\nconst {createWriteStream} = require('fs');\r\n\r\ncreateWriteStream('./1.txt', {\r\n    mode: 2176057344,\r\n});\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\nExpected to throw, like it happen when mode is `111111111111111`:\r\n\r\n```js\r\nnode:internal/validators:102\r\n      throw new ERR_OUT_OF_RANGE(name, `>= ${min} && <= ${max}`, value);\r\n      ^\r\n\r\nRangeError [ERR_OUT_OF_RANGE]: The value of \"mode\" is out of range. It must be >= 0 && <= 4294967295. Received 111_111_111_111_111\r\n    at parseFileMode (node:internal/validators:68:5)\r\n    at Object.open (node:fs:473:12)\r\n    at WriteStream._construct (node:internal/fs/streams:64:17)\r\n    at constructNT (node:internal/streams/destroy:288:25)\r\n    at processTicksAndRejections (node:internal/process/task_queues:80:21) {\r\n  code: 'ERR_OUT_OF_RANGE'\r\n}\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nI see a crash:\r\n\r\n```\r\nnode[70201]: ../src/node_file.cc:1715:void node::fs::Open(const FunctionCallbackInfo<v8::Value> &): Assertion `args[2]->IsInt32()' failed.\r\n 1: 0x1012e4da5 node::Abort() (.cold.1) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 2: 0x1000a6239 node::Abort() [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 3: 0x1000a60a1 node::Assert(node::AssertionInfo const&) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 4: 0x1000ae8d2 node::fs::Open(v8::FunctionCallbackInfo<v8::Value> const&) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 5: 0x10025a4e8 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 6: 0x100259a7c v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 7: 0x1002591a2 v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\n 8: 0x100a7a359 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/Users/coderaiser/.nvm/versions/node/v14.15.4/bin/node]\r\nAbort trap: 6\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44980
    },
    {
        "title": "ModuleWrap::SyntheticModuleEvaluationStepsCallback should return a Promise",
        "body": "Top-level await expects that all module script evaluation returns a Promise.  As such, [ModuleWrap::SyntheticModuleEvaluationStepsCallback](https://github.com/nodejs/node/blob/51249a11c09c7ec23eda17327f650fa59a72cba5/src/module_wrap.cc#L644) should be updated to return a resolved Promise now that V8 has enabled top-level await by default.\r\n\r\nUnfortunately I don't have a spec reference that I can point to here because the Stage 1 [Built-in modules proposal](https://github.com/tc39/proposal-built-in-modules) isn't yet updated for top-level await.\r\n\r\nFor reference, the corresponding change for Blink is https://chromium-review.googlesource.com/c/chromium/src/+/2568823.\r\n\r\nI discovered this issue when working on this V8 bugfix: https://chromium-review.googlesource.com/c/v8/v8/+/2673794. My first attempt at a fix failed the Node integration tests because it assumed that the Synthetic Module callback steps return a Promise.  For now, I'm adding a workaround for this in V8 but if Node can make this update then we'd like to eventually remove that workaround.\r\n",
        "labels": "confirmed-bug",
        "id": 44981
    },
    {
        "title": "Crash on node api add-on finalization",
        "body": "* **Version**: v10.23.2, v12.20.1, v14.15.4, v15.8.0 (all latest lts and current version)\r\n* **Platform**: all\r\n* **Subsystem**: node-api\r\n\r\n### What steps will reproduce the bug?\r\n\r\nRepo to re-produce: https://github.com/legendecas/repro-napi-v8impl-refbase-double-free\r\n\r\n```\r\n$ make\r\nv14.15.4\r\nforce gc\r\nfish: 'node --expose_gc index.js' terminated by signal SIGSEGV (Address boundary error)\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n\r\nNo segment faults.\r\n\r\n### What do you see instead?\r\n\r\nSegment faults on double free of `v8impl::<anonymous>::RefBase`. The `RefBase`s were deleted once one module's napi_env was going to destroy, and the installed weak `v8impl::Persistent`s of `v8impl::<anonymous>Reference` was not destroyed and these `RefBase` will be deleted again on finalization callbacks.\r\n",
        "labels": "confirmed-bug",
        "id": 44982
    },
    {
        "title": "fs: error when fd = -0",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v15.2.0\r\n* **Platform**: Ubuntu-18.04\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```console\r\nâ¯ node -p 'fs.fstatSync(-0)'\r\nnode[10415]: ../src/node_file.cc:1077:void node::fs::FStat(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `args[0]->IsInt32()' failed.\r\n 1: 0xb0c720 node::Abort() [node]\r\n 2: 0xb0c7a1  [node]\r\n 3: 0xb1944f  [node]\r\n 4: 0xdb938c  [node]\r\n 5: 0xdbb317 v8::internal::Builtin_HandleApiCall(int, unsigned int*, v8::internal::Isolate*) [node]\r\n 6: 0x16e6017  [node]\r\n 7: 0x168b379  [node]\r\n 8: 0x1684cf2  [node]\r\n 9: 0x168b379  [node]\r\n10: 0x168949a  [node]\r\n11: 0x16892bb  [node]\r\n12: 0xece07e  [node]\r\n13: 0xecf072 v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) [node]\r\n14: 0xd40619 v8::Script::Run(v8::Local<v8::Context>) [node]\r\n15: 0xafc6d3 node::contextify::ContextifyScript::EvalMachine(node::Environment*, long long, bool, bool, bool, std::shared_ptr<v8::MicrotaskQueue>, v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n16: 0xafceb1 node::contextify::ContextifyScript::RunInThisContext(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n17: 0xdb938c  [node]\r\n18: 0xdbb317 v8::internal::Builtin_HandleApiCall(int, unsigned int*, v8::internal::Isolate*) [node]\r\n19: 0x16e6017  [node]\r\n20: 0x168b379  [node]\r\n21: 0x168b379  [node]\r\n22: 0x168b379  [node]\r\n23: 0x168b379  [node]\r\n24: 0x168b379  [node]\r\n25: 0x168b379  [node]\r\n26: 0x168949a  [node]\r\n27: 0x16892bb  [node]\r\n28: 0xece07e  [node]\r\n29: 0xecf072 v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) [node]\r\n30: 0xd504c1 v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) [node]\r\n31: 0xacbcdf node::ExecuteBootstrapper(node::Environment*, char const*, std::vector<v8::Local<v8::String>, std::allocator<v8::Local<v8::String> > >*, std::vector<v8::Local<v8::Value>, std::allocator<v8::Local<v8::Value> > >*) [node]\r\n32: 0xacc007  [node]\r\n33: 0xacd5ef node::StartExecution(node::Environment*, std::function<v8::MaybeLocal<v8::Value> (node::StartExecutionCallbackInfo const&)>) [node]\r\n34: 0xa51397 node::LoadEnvironment(node::Environment*) [node]\r\n35: 0xb5bd4e node::NodeMainInstance::Run(node::EnvSerializeInfo const*) [node]\r\n36: 0xacfec9 node::Start(int, char**) [node]\r\n37: 0xa46c39 main [node]\r\n38: 0xb7a31f21 __libc_start_main [/lib/i386-linux-gnu/libc.so.6]\r\n[1]    10415 abort (core dumped)  node -p 'fs.fstatSync(-0)'\r\n\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nNo error.",
        "labels": "confirmed-bug",
        "id": 44983
    },
    {
        "title": "specific scenario causes infinite recursion in util.inspect (max stack size exceeded)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v15.6.0\r\n* **Platform**: Microsoft Windows NT 10.0.19042.0 x64\r\n* **Subsystem**: util\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```js\r\nconst { inspect } = require(\"util\");\r\n\r\nclass A {\r\n    constructor(B) {\r\n        this.B = B;\r\n    }\r\n    get b() {\r\n        return this.B;\r\n    }\r\n}\r\n\r\nclass B {\r\n    constructor() {\r\n        this.A = new A(this);\r\n    }\r\n    get a() {\r\n        return this.A;\r\n    }\r\n}\r\n\r\nconst test = new B();\r\nconst result = inspect(test, {\r\n    depth:1,\r\n    getters:true,\r\n    showHidden:true\r\n});\r\n\r\nconsole.log(result);\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nHappens when both `getters` and `showHidden` are enabled and the class contains circular references accessible by getters\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThe `depth` option should short circuit the circular references and display no more than 2 levels of depth.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nA giant wall of text.\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nAlso tested on node v15.4.0 and NWJS running node v15.3.0 but did not test in v14.\r\n\r\nIssue discovered when attempting to inspect a `client` instance from the `discord.js` library, which makes use of such circular references.\r\n\r\nEDIT: just tested in v15.2.0 and it works correctly. It seems the issue was introduced with v15.3.0\r\n",
        "labels": "confirmed-bug",
        "id": 44984
    },
    {
        "title": "[linux-armv7l] http.request() fails with HPE_INVALID_CONSTANT error ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: tested on Node v14.15.4, v15.6.0 and v14.7.x\r\n* **Platform**: Linux 5.4.51-v7l+ armv7l GNU/Linux (it's a Raspberry Pi 4 running Debian 10)\r\n* **Subsystem**: http\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\nRun the following:\r\n\r\n```node\r\nconst http = require(`http`)\r\nconst url = `http://51.77.66.14/Trilogia%20%20John%20Wick%202014-2019%20REMUX%204K%20HDR%20Latino/John%20Wick%203%20Parabellum%202019%20REMUX%204K%20HDR%20Latino.mkv`\r\nconst byteOffset = 2595000000\r\n\r\nconst req = http.request(url, {\r\n  method: `GET`,\r\n  headers: {\r\n    'Range': `bytes=${byteOffset}-`,\r\n  }\r\n}, (res) => {\r\n  console.log(`STATUS:`, res.statusCode);\r\n  console.log(`HEADERS:`, res.headers);\r\n  // res.setEncoding('hex');\r\n  res.on('data', (chunk) => {\r\n    // needs to be registered so that the body is parsed\r\n  });\r\n})\r\n\r\nreq.on('error', (err) => {\r\n  console.error(err)\r\n});\r\nreq.end();\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nOne this platform, always.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nNo error, the response should be parsed just fine. I know the responding web server might be (at least partially) at fault, but the issue does not appear on win32 (Windows 10) or in Linux/WSL1 (openSUSE & Debian) on x64, so this probably isn't desired behavior.\r\n\r\nFor what it's worth, both `curl` and `wget` don't face this issue either.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n```node\r\nSTATUS: 206\r\nHEADERS: {\r\n  date: 'Sun, 24 Jan 2021 18:03:49 GMT',\r\n  server: 'Apache/2.4.29 (Ubuntu)',\r\n  'last-modified': 'Sun, 05 Jan 2020 20:21:31 GMT',\r\n  etag: '\"f9ac35f5c-59b6a49dd4bc5\"',\r\n  'accept-ranges': 'bytes',\r\n  'content-length': '64426004636',\r\n  'content-range': 'bytes 2595000000-67021004635/67021004636',\r\n  connection: 'close',\r\n  'content-type': 'video/x-matroska'\r\n}\r\nError: Parse Error: Expected HTTP/\r\n    at Socket.socketOnData (_http_client.js:509:22)\r\n    at Socket.emit (events.js:315:20)\r\n    at addChunk (internal/streams/readable.js:309:12)\r\n    at readableAddChunk (internal/streams/readable.js:284:9)\r\n    at Socket.Readable.push (internal/streams/readable.js:223:10)\r\n    at TCP.onStreamRead (internal/stream_base_commons.js:188:23) {\r\n  bytesParsed: 335,\r\n  code: 'HPE_INVALID_CONSTANT',\r\n  reason: 'Expected HTTP/',\r\n  rawPacket: <Buffer 9a 40 a4 1b 3b aa 46 a5 7e e7 09 dd 35 3f 9e 93 b6 bc 75 3e 04 ac dc e6 f8 cd 99 c4 7f 07 98 0c e7 f9 c3 2c e8 d2 20 ff d0 98 98 48 c0 ef 07 66 60 5d ... 1350 more bytes>\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nThe requested file is quite large, so if it doesn't throw an error after a few seconds, don't wait for it to finish. I wish I had another URL to shared, but right now I only have this one. Although I am very sure I've encountered this error several times before (but didn't look into it further).\r\n\r\nAlso, notice the `byteOffset`. The issue happens at a specific byte range, hence the offset. The offset isn't totally exact, but should narrow it down to a few megabytes...\r\n\r\nI really hope someone can figure out what's going on here. I'm building a download manager and it's very unfortunate that it doesn't work reliably on my server...",
        "labels": "confirmed-bug",
        "id": 44985
    },
    {
        "title": "Unhandled `'error'` event on aborted request",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v8.17.0, v10.23.1, v12.20.1, v14.15.4, v15.5.1\r\n* **Platform**: Darwin imac.local 20.2.0 Darwin Kernel Version 20.2.0: Wed Dec  2 20:39:59 PST 2020; root:xnu-7195.60.75~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: http\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```\r\n$ cat test.js \r\nconst http = require('http');\r\n\r\nconst req = http.get('http://[2604:1380:45f1:3f00::1]:4002');\r\n\r\nreq.on('error', console.error);\r\nreq.abort();\r\n```\r\n\r\n```\r\n$ node test.js \r\nnode:events:353\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: connect EHOSTUNREACH 2604:1380:45f1:3f00::1:4002 - Local (:::49474)\r\n    at internalConnect (node:net:910:16)\r\n    at defaultTriggerAsyncIdScope (node:internal/async_hooks:430:12)\r\n    at node:net:1001:9\r\n    at processTicksAndRejections (node:internal/process/task_queues:75:11)\r\nEmitted 'error' event on Socket instance at:\r\n    at emitErrorNT (node:internal/streams/destroy:188:8)\r\n    at emitErrorCloseNT (node:internal/streams/destroy:153:3)\r\n    at processTicksAndRejections (node:internal/process/task_queues:80:21) {\r\n  errno: -65,\r\n  code: 'EHOSTUNREACH',\r\n  syscall: 'connect',\r\n  address: '2604:1380:45f1:3f00::1',\r\n  port: 4002\r\n}\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways. No required condition.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThe error is handled by the `'error'` event listener.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThe error is not handled.\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nIf `req.abort()` is removed the error is correctly handled.\r\n",
        "labels": "confirmed-bug",
        "id": 44986
    },
    {
        "title": "--inspect crash in Node >=14.0.0 when accessing global variable in devtools",
        "body": "* **Version**: >=14.0.0\r\n* **Platform**: Linux ubuntu 5.4.0-59-generic #65~18.04.1-Ubuntu SMP Mon Dec 14 15:59:40 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n### What steps will reproduce the bug?\r\nRun below _test.js_ by using  `node --inspect=0.0.0.0:9229 test.js` and inspect the file with `chrome://inspect` in Chrome (I am using Windows 10).\r\nIn the chrome dev tools try to access the \"test\" variable by typing `test `in the devtools. The node process will crash on the first try or on your next couple calls.\r\n\r\n```js\r\n// test.js\r\nfunction registerGlobals(objects){\r\n    Object.keys(objects).forEach((key) => {\r\n        (globalThis)[key] = objects[key];\r\n    });\r\n};\r\n\r\nvar test = {\r\n    blaat: 'some value'\r\n};\r\nregisterGlobals({\r\n    test\r\n});\r\n\r\nsetInterval(() => {\r\n    console.log('hearthbeat');\r\n}, 1000);\r\n\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nIt happends consistently after the first 1-5 tries when accessing the \"test\" global variable.\r\n\r\n### What is the expected behavior?\r\nNot crash and return the results like in Node <= 13\r\n\r\n### What do you see instead?\r\n```\r\nnode --inspect=0.0.0.0:9229 test\r\nDebugger listening on ws://0.0.0.0:9229/e7de75b7-eb6f-4fee-a374-0666c9644a98\r\nFor help, see: https://nodejs.org/en/docs/inspector\r\nDebugger attached.\r\ntest\r\ntest\r\ntest\r\ntest\r\ntest\r\n\r\n\r\n#\r\n# Fatal error in , line 0\r\n# Check failed: !isolate->has_pending_exception().\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 0x7fffb56adfb0\r\n 1: 0xa96131  [node]\r\n 2: 0x19614f4 V8_Fatal(char const*, ...) [node]\r\n 3: 0xc191fa  [node]\r\n 4: 0xc1c634 v8::internal::Builtin_ConsoleLog(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 5: 0x13a6339  [node]\r\nIllegal instruction (core dumped)\r\n```\r\n\r\n### Additional information\r\nThis only started happenening since Node version 14.0.0. Before, in v13.14.0, this crash does not happen.\r\n",
        "labels": "confirmed-bug",
        "id": 44987
    },
    {
        "title": "net: blockList.addSubnet throw Assertion `args[2]->IsInt32()' failed when prefix is NaN ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.4.0\r\n* **Platform**: macOS 10.15.7\r\n* **Subsystem**: net\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```js\r\nconst net = require('net');\r\nconst blockList = new net.BlockList();\r\nblockList.addSubnet('', NaN);\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nEverytime.\r\n\r\n### What is the expected behavior?\r\nthrow `ERR_OUT_OF_RANGE ` error.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n```\r\n> blockList.addSubnet('', NaN)\r\nnode[2155]: ../src/node_sockaddr.cc:614:static void node::SocketAddressBlockListWrap::AddSubnet(const FunctionCallbackInfo<v8::Value> &): Assertion `args[2]->IsInt32()' failed.\r\n 1: 0x101379d05 node::Abort() (.cold.1) [/usr/local/bin/node]\r\n 2: 0x1000bde89 node::Abort() [/usr/local/bin/node]\r\n 3: 0x1000bdcf1 node::Assert(node::AssertionInfo const&) [/usr/local/bin/node]\r\n 4: 0x1001420e4 node::SocketAddressBlockListWrap::AddSubnet(v8::FunctionCallbackInfo<v8::Value> const&) [/usr/local/bin/node]\r\n 5: 0x1002a3728 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [/usr/local/bin/node]\r\n 6: 0x1002a2cbc v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/usr/local/bin/node]\r\n 7: 0x1002a23e7 v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/usr/local/bin/node]\r\n 8: 0x100ac42d9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/usr/local/bin/node]\r\n 9: 0x100a5d402 Builtins_InterpreterEntryTrampoline [/usr/local/bin/node]\r\n[1]    2155 abort      node\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44988
    },
    {
        "title": "The Node.js will stuck when exec `Object.defineProperty(Array.prototype, '-1', {get: function(){return this[this.length - 1]}})` in REPL",
        "body": "* **Version**: v15.3.0\r\n* **Platform**: Linux *** 5.9.11-3-MANJARO #1 SMP PREEMPT Sat Nov 28 09:08:57 UTC 2020 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n```js\r\nObject.defineProperty(Array.prototype, '-1', {get: function(){return this[this.length - 1]}})\r\n```\r\n\r\nWhen exec these code in REPL, the Node.js will let cpu occupancy rate become 100% and stuck itself.\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n100% reproduce.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n```bash\r\n> Object.defineProperty(Array.prototype, '-1', {get: function(){return this[this.length - 1]}})\r\nObject(0) []\r\n> \r\n```\r\n### Additional information\r\nIt can be reproduce in Node.js v14.8.0 on my Android's termux.\r\n <!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44989
    },
    {
        "title": "make check failure for macOS arch64",
        "body": "Commit 0b6d3070a1 \r\n\r\nmacOS 11.1  aarch64\r\n\r\nXcode 12.3\r\n\r\n```bash\r\nmake; make check\r\n\r\n=== release test-worker-prof ===                                              \r\nPath: sequential/test-worker-prof\r\nnode:assert:119\r\n  throw new AssertionError(obj);\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: child exited with signal: {\r\n  status: null,\r\n  signal: 'SIGSEGV',\r\n  output: [ null, '', '' ],\r\n  pid: 73280,\r\n  stdout: '',\r\n  stderr: ''\r\n}\r\n    at Object.<anonymous> (/Users/USERNAME/github/node/test/sequential/test-worker-prof.js:58:10)\r\n    at Module._compile (node:internal/modules/cjs/loader:1108:14)\r\n    at Object.Module._extensions..js (node:internal/modules/cjs/loader:1137:10)\r\n    at Module.load (node:internal/modules/cjs/loader:973:32)\r\n    at Function.Module._load (node:internal/modules/cjs/loader:813:14)\r\n    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:76:12)\r\n    at node:internal/main/run_main_module:17:47 {\r\n  generatedMessage: false,\r\n  code: 'ERR_ASSERTION',\r\n  actual: 'SIGSEGV',\r\n  expected: null,\r\n  operator: 'strictEqual'\r\n}\r\nCommand: out/Release/node /Users/USERNAME/github/node/test/sequential/test-worker-prof.js\r\n[02:41|% 100|+ 3282|-   1]: Done                                              \r\nmake[1]: *** [jstest] Error 1\r\nmake: *** [test] Error 2\r\n```",
        "labels": "confirmed-bug",
        "id": 44990
    },
    {
        "title": "Calling res.end() twice stalls follow-up HTTP request (drain event is missing)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 14.0.0...14.15.3 (latest lts), 15.0.0...15.5.0 (latest stable)\r\n* **Platform**: macos / ubuntu / windows\r\n* **Subsystem**: N/A\r\n\r\n### What steps will reproduce the bug?\r\n\r\nOriginally, I noticed this behaviour in a Next.js app and it took me quite a while to drill down to the bottom of it. You can find a plain MWE here: https://github.com/kachkaev/node-http-response-double-end-call-breaking-drain-event (no NPM packages involved). \r\n\r\nSince Node version 14.0.0, calling `res.end()` twice in a body-less response seems to be silencing the `drain` event in a follow-up HTTP request if it uses the same connection. This can happen in practice when redirecting a client to a heavy page and using [compression](https://www.npmjs.com/package/compression) package as middleware.\r\n\r\nI understand that calling `res.end()` twice is a developer mistake, however it does not seem right to have to debug such a small oversight for more than two working days ðŸ˜… When using [`res.redirect(...)` helper method in Next.js](https://github.com/vercel/next.js/blob/9b3edd3b2476b9915fe8c94071a77ac8e8f14499/packages/next/next-server/server/api-utils.ts#L195-L217), itâ€™s easy to forget that itâ€™s not only doing `res.writeHead(...)` for you, but also calls `res.end()`. Seeing `res.redirect(...); res.end()` does not feel too wrong initially and there is no feedback from the server or the tooling to suggest that this involves `res.end()` being called twice.\r\n\r\nHere are the reproduction steps from the server POV:\r\n\r\n1. A client establishes a connection and requests a page that results with a redirect:\r\n\r\n    ```ts\r\n    res.writeHead(302, { Location: \"/another-page\" });\r\n    res.end();\r\n    res.end(); // called twice intentionally\r\n    ```\r\n\r\n2. The same client immediately comes back with another request, which is meant to return 200 and contain some payload.\r\n\r\n    - If the size of the payload is small enough to fit a single `res.write(...)`, all works fine.\r\n    \r\n    - If the payload involves `res.write(...) === true` â†’ `res.on(\"drain\", () => {...})`, the second request is never finished because the `drain` event is never invoked.\r\n    \r\nYou can look into how `compression` is using `res.write(...)` + `res.on(\"drain\", ...)` to find a practical example: https://github.com/expressjs/compression/blob/3fea81d0eaed1eb872bf3e0405f20d9e175ab2cf/index.js#L193-L218\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nI am able to silence the `drain` event quite reliably on any Node version â‰¥14.0.0 on any OS. See the [GitHub Workflow for my MWE](https://github.com/kachkaev/node-http-response-double-end-call-breaking-drain-event/actions/runs/442932230).\r\n\r\n### What is the expected behavior?\r\n\r\nIdeally, I would expect the second `res.end()` to not produce any side effects or at least to give me a warning. All works fine in Node v13.14.0 and below.\r\n\r\n### What do you see instead?\r\n\r\nI stumbled across some magic behaviour which took more than two days to investigate ðŸ˜…\r\n\r\n### Additional information\r\n\r\nThe unwanted side effect from a double call to `res.end()` is negated:\r\n\r\n- if the follow-up request does not share the connection with the first (body-less) request (i.e. `curl` called twice);\r\n- or if `res.write(\"\")` is added to the first (body-less) request\r\n\r\nBoth observations are included into GitHub Workflows within the MWE repo. I also tried playing with `res.end(\"\")` as a replacement for `res.write(\"\")`, but it did not help.",
        "labels": "confirmed-bug",
        "id": 44991
    },
    {
        "title": "gunzipSync DOA in Node 14.15.2",
        "body": "* **Version**: 14.15.2\r\n* **Platform**: Linux lbvm 5.4.0-56-generic #62~18.04.1-Ubuntu SMP Tue Nov 24 10:07:50 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\nAny code using `gunzipSync` will crash\r\n\r\n```\r\n$ cat gunzip.js \r\nconst { gunzipSync } = require('zlib');\r\nconsole.log(gunzipSync('fooobar'));\r\n\r\n$ node -v\r\nv14.15.2\r\n\r\n$ node gunzip.js \r\ninternal/streams/readable.js:193\r\n  const isDuplex = this instanceof Stream.Duplex;\r\n                        ^\r\n\r\nTypeError: Right-hand side of 'instanceof' is not an object\r\n    at Gunzip.Readable (internal/streams/readable.js:193:25)\r\n    at Gunzip.Duplex (internal/streams/duplex.js:56:12)\r\n    at Gunzip.Transform (internal/streams/transform.js:117:10)\r\n    at Gunzip.ZlibBase (zlib.js:271:13)\r\n    at Gunzip.Zlib (zlib.js:669:12)\r\n    at new Gunzip (zlib.js:732:8)\r\n    at syncBufferWrapper (zlib.js:765:29)\r\n    at Object.<anonymous> (/home/ledion/workspaces/js2bin/gunzip.js:2:13)\r\n    at Module._compile (internal/modules/cjs/loader.js:1063:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1092:10)\r\n```\r\n\r\nThe regression seems to have been introduced in 14.15.2 and is present in 14.15.3.\r\n\r\nMaybe related to #35239? cc @mcollina \r\n",
        "labels": "confirmed-bug",
        "id": 44992
    },
    {
        "title": "`new URL` gives wrong result on leading backslash",
        "body": "<!--\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v15.4.0\r\n* **Platform**: `Linux 5b80145d2618 4.19.0-13-amd64 #1 SMP Debian 4.19.160-2 (2020-11-28) x86_64 GNU/Linux`\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\nParse a relative-URL string that begins with a backslash. For example:\r\n```\r\n> new URL(\"\\\\x\", \"https://example/foo/bar\").href\r\n'https://example/foo//x'\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\nThe leading backslash should have the same behavior as if it were a proper `/`. The input would be treated as a path-absolute URL (replacing the whole path from the base URL), or a scheme-relative URL (replacing all but the scheme from the base URL).\r\n\r\nFor example:\r\n`new URL(\"\\\\x\", \"https://example/foo/bar\").href` -> `\"https://example/x\"`\r\n`new URL(\"\\\\\\\\x\", \"https://example/foo/bar\").href` -> `\"https://x/\"`\r\n\r\n### What do you see instead?\r\n\r\nThe leading backslash is treated incorrectly. The effect seems to be as if the input were a path-relative-URL string -- the base URL's path, except for its last component, appears in the result. In the example:\r\n```\r\n> new URL(\"\\\\x\", \"https://example/foo/bar\").href\r\n'https://example/foo//x'\r\n```\r\n\r\n### Additional information\r\n\r\nThe behavior of `new URL` is documented as being defined by the WHATWG [URL Standard](https://url.spec.whatwg.org/). An input string like `\\x`, with a leading backslash, is never a \"valid URL string\" as defined in that standard... but the standard nevertheless defines what the `URL` constructor should return for it.\r\n\r\nBecause the example input `\\x` is so short, it's not hard to walk through [the URL parser](https://url.spec.whatwg.org/#url-parsing) as defined in the URL Standard and confirm what result the standard calls for. For the base URL of `https://example/`, it goes from \"scheme start state\" to \"no scheme state\" to \"relative state\" to \"relative slash state\" to \"path state\", following exactly the same track as an input of `/x` would do, except only that `\\x` emits a validation error. In the URL parser as defined by the URL Standard, a \"validation error\" [does not affect the parser's result](https://url.spec.whatwg.org/#validation-error), so the resulting URL should be the same as for `/x`.\r\n\r\nAs a different kind of check, Chrome (87.0.4280.88) gives the correct answer according to the spec. In the browser console:\r\n```\r\n> new URL(\"\\\\x\", \"https://example/foo/bar\").href\r\n\"https://example/x\"\r\n```\r\n\r\nSo does Firefox (78.0):\r\n```\r\nÂ» new URL(\"\\\\x\", \"https://example/foo/bar\").href\r\nâ† \"https://example/x\"\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 44993
    },
    {
        "title": "Object.assign / spread of http request object difference between v14.15.1 and v14.15.2",
        "body": "* **Version**: 14.15.2\r\n* **Platform**: any\r\n* **Subsystem**: any\r\n\r\n### What steps will reproduce the bug?\r\n\r\nWhile trying to create a cloned version of an http request object, prototype properties/methods such as `headers` and `get` get lost.\r\n\r\n```js\r\nconst assert = require('assert');\r\nconst http = require('http');\r\n\r\nconst server = http\r\n  .createServer((req, res) => {\r\n    const dummyReq = { ...req };\r\n    res.writeHead(200, { 'Content-Type': 'text/plain' });\r\n    res.end('ok');\r\n    assert.deepStrictEqual(req.headers, dummyReq.headers);\r\n  })\r\n  .listen();\r\n\r\nserver.on('listening', () => {\r\n  http.get(`http://localhost:${server.address().port}`);\r\n});\r\n```\r\n\r\n### What is the expected behavior?\r\n\r\nI honestly don't know if the behavior from 14.15.1 or from 14.15.2 is expected.\r\n\r\nBehavior until 14.15.1:  `dummyReq.headers` is not `undefined`.\r\n\r\n### What do you see instead?\r\n\r\nOutput in 14.15.2: `dummyReq.headers` is `undefined`.\r\n\r\n### Additional info\r\n\r\nThe same happens while using `Object.assign`",
        "labels": "confirmed-bug",
        "id": 44994
    },
    {
        "title": "doc: Piping multiple streams to the same Writable stream might not end",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!--\r\n\r\nThank you for wanting to make nodejs.org better!\r\n\r\nThis template is for issues with the Node.js API\r\nreference documentation.\r\n\r\nFor problems with nodejs.org beyond the API\r\nreference documentation, please open an issue\r\nusing the issue tracker for our site repository.\r\n\r\n  https://github.com/nodejs/nodejs.org\r\n\r\nFor more general support, please open an issue\r\nusing the issue tracker for our help repository.\r\n\r\n  https://github.com/nodejs/help\r\n\r\n---\r\n\r\nFor the issue title, please enter a one-line\r\nsummary after â€œdoc: â€ (preferably 50 characters\r\nor less and no more than 72).\r\n\r\nThe â€œâœï¸â€ are placeholders signifying requests for\r\ninput. Replace them with your responses.\r\n\r\nIf you are unsure of something, do your best.\r\n\r\n-->\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 15.4.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: Linux pop-os 5.8.0-7630-generic 20.10~61c3910-Ubuntu SMP Thu Nov 26 00:10:35 UTC  x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: stream\r\n\r\n## Location\r\n\r\n_Section of the site where the content exists_\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/stream.html#stream_readable_pipe_destination_options\r\n\r\n## Description\r\n\r\n_Concise explanation of the problem_\r\n\r\n<!-- If applicable, include any screenshots that\r\nmay help solve the problem. -->\r\n\r\nThe documentation for `readable.pipe()` reads:\r\n\r\n> ... The flow of data will be automatically managed so that the destination Writable stream is not overwhelmed by a faster Readable stream.\r\n\r\nSo when we open a Writable stream and then pipe multiple Readable streams into this Writable stream; the stream becomes full/congested and needs to drain but then we pipe more Readable streams into this stream. This seems to sometimes cause a Readable stream to not end and thus does not pipe its data to the Writable stream.\r\n\r\nBug in electron/asar explaining the issue https://github.com/electron/asar/issues/210.\r\n\r\nSince electron/asar does this in basically a `for await`-loop, we get stuck waiting for a Readable stream which never ends.\r\n\r\nIs this expected behavior when piping multiple Readable streams into one Writable stream? Should one check `writable.writableNeedDrain` before piping a Readable stream?\r\n\r\n---\r\n\r\n<!-- Use â€œ[x]â€ to check the box below if you are\r\ninterested in contributing. -->\r\n\r\n- [ ] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "confirmed-bug",
        "id": 44995
    },
    {
        "title": "Worker thread throws error when started from `--require` script",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.4.0\r\n* **Platform**: Linux\r\n* **Subsystem**: worker_threads\r\n\r\n### What steps will reproduce the bug?\r\n\r\nRun the following at a bash shell:\r\n\r\n```\r\ntouch empty.js\r\necho \"new (require('worker_threads').Worker)('./empty.js')\" > create-worker.js\r\nnode -r ./create-worker.js ./empty.js\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nIt reproduces every time.  It happens when the worker is created by a `--require` script.\r\n\r\n### What is the expected behavior?\r\n\r\nNo errors from the worker_thread.\r\n\r\n### What do you see instead?\r\n\r\nLogs the following:\r\n```\r\nnode:events:353\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\nTypeError [Error]: undefined is not an integer typed array.\r\n    at Atomics.load (<anonymous>)\r\n    at process.cwd (node:internal/main/worker_thread:140:38)\r\n    at MessagePort.<anonymous> (node:internal/main/worker_thread:153:48)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (node:internal/event_target:422:41)\r\n    at MessagePort.exports.emitMessage (node:internal/per_context/messageport:18:26)\r\nEmitted 'error' event on process instance at:\r\n    at emitUnhandledRejectionOrErr (node:internal/event_target:602:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (node:internal/event_target:426:9)\r\n    at MessagePort.exports.emitMessage (node:internal/per_context/messageport:18:26)\r\n```\r\n\r\n### Additional information\r\n\r\nThe line number referenced in the error is here: https://github.com/nodejs/node/blob/master/lib/internal/main/worker_thread.js#L140\r\n\r\nBased on a brief look at the code, I guess node is assuming that the worker receives a bootstrapping message with a bunch of values, one of them being `cwdCounter`.  But when created via `--require`, that message is not sent or has not arrived yet.",
        "labels": "confirmed-bug",
        "id": 44996
    },
    {
        "title": "fs.mkdir with recursive option and invalid name hangs the program",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or output of `\"$([Environment]::OSVersion | ForEach-Object VersionString) $(if ([Environment]::Is64BitOperatingSystem) { \"x64\" } else { \"x86\" })\"` in PowerShell console (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.18.0\r\n* **Platform**: Windows10\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n```js\r\nconst fs = require(\"fs\");\r\nconst path = \"./to-delete/s:d\";\r\n\r\nfs.mkdir(path, { recursive: true }, (err) => {\r\n  if (err) {\r\n    console.log(err);\r\n    return;\r\n  }\r\n  console.log(\"success\");\r\n});\r\n```\r\n### How often does it reproduce? Is there a required condition?\r\nUsing **:** (double dots) character in folder name after the first prefix will make the program freeze\r\n### What is the expected behavior?\r\nThrow an error\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nThe program hangs\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n--\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 44997
    },
    {
        "title": "Cannot set a breakpoint on some modules",
        "body": "# Environment\r\n- macOS 10.15.7\r\n- Node.js 15.x.x\r\n\r\n# Steps to Reproduce\r\n```\r\n$ node inspect -e \"console.log('hello')\"\r\n< Debugger listening on ws://127.0.0.1:9229/c66c9b5b-fe08-43df-8494-0cd1609f277d\r\n< For help, see: https://nodejs.org/en/docs/inspector\r\n< Debugger attached.\r\nBreak on start in [eval]:1\r\n> 1 console.log('hello')\r\ndebug> step\r\nbreak in internal/console/constructor.js:341\r\n 339 const consoleMethods = {\r\n 340   log(...args) {\r\n>341     this[kWriteToConsole](kUseStdout, this[kFormatForStdout](args));\r\n 342   },\r\n 343\r\ndebug> step\r\nbreak in internal/console/constructor.js:305\r\n 303     ...consolePropAttributes,\r\n 304     value: function(args) {\r\n>305       const opts = this[kGetInspectOptions](this._stdout);\r\n 306       return formatWithOptions(opts, ...args);\r\n 307     }\r\ndebug> out\r\nbreak in internal/console/constructor.js:341\r\n 339 const consoleMethods = {\r\n 340   log(...args) {\r\n>341     this[kWriteToConsole](kUseStdout, this[kFormatForStdout](args));\r\n 342   },\r\n 343\r\ndebug> step\r\nbreak in internal/console/constructor.js:242\r\n 240     ...consolePropAttributes,\r\n 241     value: function(streamSymbol, string) {\r\n>242       const ignoreErrors = this._ignoreErrors;\r\n 243       const groupIndent = this[kGroupIndent];\r\n 244\r\ndebug> list()\r\n 237     }\r\n 238   },\r\n 239   [kWriteToConsole]: {\r\n 240     ...consolePropAttributes,\r\n 241     value: function(streamSymbol, string) {\r\n>242       const ignoreErrors = this._ignoreErrors;\r\n 243       const groupIndent = this[kGroupIndent];\r\n 244\r\n 245       const useStdout = streamSymbol === kUseStdout;\r\n 246       const stream = useStdout ? this._stdout : this._stderr;\r\n 247       const errorHandler = useStdout ?\r\ndebug> setBreakpoint(245)\r\nUncaught Error: Could not resolve breakpoint - undefined\r\n    at _pending.<computed> (internal/deps/node-inspect/lib/internal/inspect_client.js:243:27)\r\n    at Client._handleChunk (internal/deps/node-inspect/lib/internal/inspect_client.js:213:11)\r\n    at Socket.emit (events.js:314:20)\r\n    at Socket.EventEmitter.emit (domain.js:486:12)\r\n    at addChunk (_stream_readable.js:321:12)\r\n    at readableAddChunk (_stream_readable.js:297:9)\r\n    at Socket.Readable.push (_stream_readable.js:236:10)\r\n    at TCP.onStreamRead (internal/stream_base_commons.js:192:23)\r\n    at TCP.callbackTrampoline (internal/async_hooks.js:129:14) {\r\n  code: -32000\r\n}\r\ndebug> cont\r\n< hello\r\n< Waiting for the debugger to disconnect...\r\ndebug>\r\n```\r\n\r\n# Expected Behavior\r\nAble to set a breakpoint without any errors.\r\n\r\n# Actual Behavior\r\nCannot set a breakpoint. Getting an error and a stack trace shown on [Steps to Reproduce](#Steps-to-Reproduce) section.\r\n\r\n# Analysis\r\nIf this is indeed a bug and not the expected behavior, I understand that 7a447bc is the commit that introduced this. How I reached this opinion is:\r\n\r\n1. Observed this issue on my local Node.js installation, which is `15.3.0`.\r\n1. Using the [n version manager] for Node.js, tested it on all Node.js versions from `14.4.0` to `14.15.1`. Observed that the issue does not happen on any of these versions.\r\n1. Then tested it with `15.0.0` and `15.0.1`. The issue was observed in both versions (as well as my initial Node.js version, which is `15.3.0`). Deduced that the issue starts with version 15.\r\n1. Using the [n version manager], did a binary search on [Node.js nightly] binaries from `v14.0.0-nightly20200421c3554307c6` (the last version that starts with `v14`) to `v16.0.0-nightly20201021c2ceb15fd5` (the first version that starts with `v16`). That is, I performed a manual `git bisect`; first I downloaded `v14.0.0-nightly20200421c3554307c6` and observed that it works fine. Then I downloaded `v16.0.0-nightly20201021c2ceb15fd5` and observed that the issue is present. Then downloaded the version that's in the middle of them (which is `v15.0.0-nightly2020072341c1e72b76`) and observed that the issue is present.\r\n1. After a couple steps, I have realized that `v15.0.0-nightly20200717bf0d82c102` is the last version that issue is _not_ observed and `v15.0.0-nightly202007187a447bcd54` is the first version that issue is observed. Upon observing this, I ran a [comparison on GitHub] between the commits of these versions (which are bf0d82c102 for the last working version and 7a447bcd54 for the first broken version). GitHub told me that the following are the commits between those versions:\r\n    - bf0d82c\r\n    - 08e8997\r\n    - 5aeaff6\r\n    - d10c59f\r\n    - d379b00\r\n    - 404302f\r\n    - ef9964f\r\n    - f045387\r\n    - 1faf6f4\r\n    - 7ecb285\r\n    - 0b8ae5f\r\n    - c943cb4\r\n    - f8bde7c\r\n    - b1c3909\r\n    - 7a447bc\r\n1. Downloaded the [Node.js source code], checked out bf0d82c, configured (`./configure`) and built it (`make -j8`) on my machine (which is macOS 10.15.7 with xcode-select version 2373). Observed that it works properly.\r\n1. Then, consecutively, checked out all commits (starting with 08e8997 and going towards 7a447bc), built them and tested them. Observed that the issue does not happen in any of them except the last commit, which is 7a447bc.\r\n1. Hence, if this is indeed a bug, I deduced that 7a447bc is the commit that introduced this bug.\r\n\r\n<details>\r\n  <summary>My nightly build test results for reference (click on the arrow to expand)</summary>\r\n\r\n  ```\r\n  WORKS - v15.0.0-nightly20200422d08bd41248/                 22-Apr-2020 07:30                   -\r\n  v15.0.0-nightly202004236a07eca49c/                 23-Apr-2020 07:30                   -\r\n  v15.0.0-nightly202004240619b600b2/                 24-Apr-2020 07:00                   -\r\n  v15.0.0-nightly2020042524a4e6153d/                 25-Apr-2020 07:30                   -\r\n  v15.0.0-nightly20200426f8d5474839/                 26-Apr-2020 07:00                   -\r\n  v15.0.0-nightly202004275ee1e31e38/                 27-Apr-2020 07:30                   -\r\n  v15.0.0-nightly20200428307c67be17/                 28-Apr-2020 08:30                   -\r\n  v15.0.0-nightly20200429e7b99e027b/                 29-Apr-2020 07:30                   -\r\n  v15.0.0-nightly202004302496db8e09/                 30-Apr-2020 07:30                   -\r\n  v15.0.0-nightly20200501e9518254d7/                 01-May-2020 08:30                   -\r\n  v15.0.0-nightly202005027c36ec38f1/                 02-May-2020 07:00                   -\r\n  v15.0.0-nightly20200503b0aba53195/                 03-May-2020 07:00                   -\r\n  v15.0.0-nightly20200504bde5f9baf7/                 04-May-2020 08:30                   -\r\n  v15.0.0-nightly20200505c17dcb3253/                 05-May-2020 08:30                   -\r\n  v15.0.0-nightly2020050686fdaa7455/                 06-May-2020 07:30                   -\r\n  v15.0.0-nightly202005078607f9ec5c/                 07-May-2020 07:00                   -\r\n  v15.0.0-nightly20200508bcdbd57134/                 08-May-2020 07:30                   -\r\n  v15.0.0-nightly20200509be7fd2d517/                 09-May-2020 07:00                   -\r\n  v15.0.0-nightly2020051094e5b5c77d/                 10-May-2020 07:00                   -\r\n  v15.0.0-nightly202005118a6fab02ad/                 11-May-2020 07:00                   -\r\n  v15.0.0-nightly202005128c5d58b5a7/                 12-May-2020 07:00                   -\r\n  v15.0.0-nightly202005135bb4d01fbe/                 13-May-2020 07:30                   -\r\n  v15.0.0-nightly20200514eaa16cd477/                 14-May-2020 07:30                   -\r\n  v15.0.0-nightly2020051524bf1adacc/                 15-May-2020 07:30                   -\r\n  v15.0.0-nightly20200516b533fb3508/                 16-May-2020 07:00                   -\r\n  v15.0.0-nightly20200517b3ca8869a6/                 17-May-2020 07:30                   -\r\n  v15.0.0-nightly20200518ef1eb8d439/                 18-May-2020 08:30                   -\r\n  v15.0.0-nightly20200519fe1b9e09a8/                 19-May-2020 07:30                   -\r\n  v15.0.0-nightly20200520a82001a387/                 20-May-2020 07:30                   -\r\n  v15.0.0-nightly20200521cd4985c488/                 21-May-2020 07:00                   -\r\n  v15.0.0-nightly2020052251af89fe45/                 22-May-2020 07:00                   -\r\n  v15.0.0-nightly20200523a416692e93/                 23-May-2020 07:00                   -\r\n  v15.0.0-nightly20200524dd5f209213/                 24-May-2020 08:30                   -\r\n  v15.0.0-nightly20200525458677f5ef/                 25-May-2020 07:00                   -\r\n  v15.0.0-nightly202005265007611294/                 26-May-2020 08:30                   -\r\n  v15.0.0-nightly202005279949a2e1e3/                 27-May-2020 08:30                   -\r\n  v15.0.0-nightly2020052847044a91c6/                 28-May-2020 08:30                   -\r\n  v15.0.0-nightly202005296a1df3b5af/                 29-May-2020 07:30                   -\r\n  v15.0.0-nightly20200530d79c330186/                 30-May-2020 07:00                   -\r\n  v15.0.0-nightly202005312935f72ae1/                 31-May-2020 08:30                   -\r\n  v15.0.0-nightly20200602b1704e4347/                 02-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200603680fb8fc62/                 03-Jun-2020 07:30                   -\r\n  v15.0.0-nightly202006043a7a5d7e62/                 04-Jun-2020 07:30                   -\r\n  v15.0.0-nightly202006053e2a300710/                 05-Jun-2020 07:30                   -\r\n  WORKS - v15.0.0-nightly202006063ac50e1209/                 06-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200607d8eef83757/                 07-Jun-2020 08:30                   -\r\n  v15.0.0-nightly202006088a4b5c63e0/                 08-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200609921f75534c/                 09-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200610362e4a1aec/                 10-Jun-2020 14:30                   -\r\n  v15.0.0-nightly20200611f4e805c860/                 11-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200612bba9b008ef/                 12-Jun-2020 07:30                   -\r\n  v15.0.0-nightly202006137b46793eee/                 13-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200614c17d2f9901/                 14-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200615f645cc7318/                 15-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200616b371213d3d/                 16-Jun-2020 09:00                   -\r\n  v15.0.0-nightly20200617ee7f0e3f75/                 17-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200618a4f3206b76/                 18-Jun-2020 07:30                   -\r\n  v15.0.0-nightly2020061956967afdca/                 19-Jun-2020 08:30                   -\r\n  v15.0.0-nightly20200620fdf10adef8/                 20-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200622122038c6a2/                 22-Jun-2020 07:00                   -\r\n  v15.0.0-nightly2020062386cbad837b/                 23-Jun-2020 06:30                   -\r\n  v15.0.0-nightly20200624d8f8723577/                 24-Jun-2020 07:00                   -\r\n  v15.0.0-nightly20200625e405e82f74/                 25-Jun-2020 07:00                   -\r\n  v15.0.0-nightly20200626e18afe45d2/                 26-Jun-2020 07:00                   -\r\n  v15.0.0-nightly20200627f63436d190/                 27-Jun-2020 07:00                   -\r\n  v15.0.0-nightly20200628f89530fccc/                 28-Jun-2020 09:00                   -\r\n  WORKS - v15.0.0-nightly2020062990d5f35f7a/                 29-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200630c23d2fd3f8/                 30-Jun-2020 07:30                   -\r\n  v15.0.0-nightly20200701e2b468eb5c/                 01-Jul-2020 07:30                   -\r\n  v15.0.0-nightly20200702c118304ad0/                 02-Jul-2020 08:30                   -\r\n  v15.0.0-nightly202007031dc837ed9a/                 03-Jul-2020 07:30                   -\r\n  v15.0.0-nightly20200704bff7de3b43/                 04-Jul-2020 08:00                   -\r\n  v15.0.0-nightly2020070556dbe466fd/                 05-Jul-2020 07:00                   -\r\n  v15.0.0-nightly2020070667ba825037/                 06-Jul-2020 08:30                   -\r\n  v15.0.0-nightly2020070730612316e4/                 07-Jul-2020 07:30                   -\r\n  v15.0.0-nightly20200708e0ecde9737/                 08-Jul-2020 07:30                   -\r\n  v15.0.0-nightly202007096ae1b9c457/                 09-Jul-2020 07:00                   -\r\n  WORKS - v15.0.0-nightly202007101237955d41/                 10-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200711c176d5fac2/                 11-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200712ac6ecd6b7f/                 12-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200714c7627da837/                 14-Jul-2020 08:00                   -\r\n  v15.0.0-nightly202007153b130327fa/                 15-Jul-2020 08:00                   -\r\n  v15.0.0-nightly20200716d46fc91be4/                 16-Jul-2020 08:00                   -\r\n  WORKS - v15.0.0-nightly20200717bf0d82c102/                 17-Jul-2020 08:00                   -\r\n  DOES NOT WORK - v15.0.0-nightly202007187a447bcd54/                 18-Jul-2020 07:30                   -\r\n  DOES NOT WORK - v15.0.0-nightly202007190c81cadec6/                 19-Jul-2020 08:30                   -\r\n  NO BINARY FOR MACOS - v15.0.0-nightly20200720a51436cbea/                 20-Jul-2020 06:30                   -\r\n  v15.0.0-nightly202007212c05beeb54/                 21-Jul-2020 08:00                   -\r\n  v15.0.0-nightly20200722b0b52b2023/                 22-Jul-2020 09:00                   -\r\n  DOES NOT WORK - v15.0.0-nightly2020072341c1e72b76/                 23-Jul-2020 09:00                   -\r\n  v15.0.0-nightly20200724d1e4e8eaba/                 24-Jul-2020 07:30                   -\r\n  v15.0.0-nightly20200725de192246bc/                 25-Jul-2020 07:00                   -\r\n  v15.0.0-nightly2020072631ba9a20bd/                 26-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200727db54b57042/                 27-Jul-2020 07:00                   -\r\n  v15.0.0-nightly202007286fd09e4f36/                 28-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200729360bf9b289/                 29-Jul-2020 08:30                   -\r\n  v15.0.0-nightly202007301fe39f0b4b/                 30-Jul-2020 08:30                   -\r\n  v15.0.0-nightly20200731dc00a07426/                 31-Jul-2020 07:00                   -\r\n  v15.0.0-nightly20200801cc7ec889e8/                 01-Aug-2020 07:00                   -\r\n  v15.0.0-nightly2020080273d713b16e/                 02-Aug-2020 07:00                   -\r\n  v15.0.0-nightly20200803a9c5b873ca/                 03-Aug-2020 07:00                   -\r\n  v15.0.0-nightly2020080474df7496ff/                 04-Aug-2020 07:00                   -\r\n  v15.0.0-nightly2020080584b35b2867/                 05-Aug-2020 07:00                   -\r\n  v15.0.0-nightly20200806df17fcdc71/                 06-Aug-2020 07:00                   -\r\n  v15.0.0-nightly2020080746bef7b771/                 07-Aug-2020 07:00                   -\r\n  v15.0.0-nightly20200808ac5773b1c3/                 08-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008098825eb4d73/                 09-Aug-2020 07:00                   -\r\n  v15.0.0-nightly20200810dd0c5228ac/                 10-Aug-2020 08:00                   -\r\n  v15.0.0-nightly20200811f8a0e62bbf/                 11-Aug-2020 07:00                   -\r\n  v15.0.0-nightly202008122f27f1144e/                 12-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008137a1220a1d7/                 17-Aug-2020 22:30                   -\r\n  v15.0.0-nightly202008145864fca7bc/                 17-Aug-2020 22:30                   -\r\n  v15.0.0-nightly202008158da8ec9c7e/                 17-Aug-2020 22:30                   -\r\n  v15.0.0-nightly20200816375b859428/                 17-Aug-2020 22:30                   -\r\n  v15.0.0-nightly2020081742a3a7f97d/                 17-Aug-2020 23:00                   -\r\n  v15.0.0-nightly20200818ca5ff723d1/                 21-Aug-2020 22:30                   -\r\n  v15.0.0-nightly202008196e97a735c8/                 21-Aug-2020 23:00                   -\r\n  v15.0.0-nightly2020082003293aa3a1/                 21-Aug-2020 23:00                   -\r\n  v15.0.0-nightly202008217aeff6b8c8/                 21-Aug-2020 23:00                   -\r\n  v15.0.0-nightly2020082244e6a6af67/                 22-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008238e8d429277/                 23-Aug-2020 08:30                   -\r\n  v15.0.0-nightly20200824c3d337db5d/                 24-Aug-2020 09:00                   -\r\n  v15.0.0-nightly20200825010383a174/                 25-Aug-2020 08:30                   -\r\n  v15.0.0-nightly20200826c6b96895cc/                 26-Aug-2020 09:00                   -\r\n  v15.0.0-nightly202008278ec3b55e5b/                 27-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008280848f56cb3/                 28-Aug-2020 08:30                   -\r\n  v15.0.0-nightly2020082994fcac7876/                 29-Aug-2020 08:30                   -\r\n  v15.0.0-nightly202008305c020762bb/                 30-Aug-2020 07:30                   -\r\n  v15.0.0-nightly20200831e1edd6bbfa/                 31-Aug-2020 07:30                   -\r\n  v15.0.0-nightly2020090159cad32b51/                 01-Sep-2020 07:30                   -\r\n  v15.0.0-nightly20200902e2ffa454d3/                 02-Sep-2020 07:00                   -\r\n  v15.0.0-nightly20200903b23a932bfd/                 03-Sep-2020 08:30                   -\r\n  v15.0.0-nightly202009043b925219c3/                 04-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20200905186230527b/                 05-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20200906e326c41fbc/                 08-Sep-2020 12:00                   -\r\n  v15.0.0-nightly20200907bb9117ee9f/                 08-Sep-2020 12:30                   -\r\n  v15.0.0-nightly202009086f2af08245/                 08-Sep-2020 12:30                   -\r\n  v15.0.0-nightly202009091204400d64/                 09-Sep-2020 08:30                   -\r\n  v15.0.0-nightly202009104c9b79ed5a/                 10-Sep-2020 07:00                   -\r\n  v15.0.0-nightly202009114f176c9110/                 11-Sep-2020 07:30                   -\r\n  v15.0.0-nightly20200912541d296d56/                 12-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20200913b123e0806f/                 13-Sep-2020 07:00                   -\r\n  v15.0.0-nightly202009149d12c14b19/                 14-Sep-2020 07:00                   -\r\n  v15.0.0-nightly202009152b3eb101b5/                 15-Sep-2020 07:30                   -\r\n  v15.0.0-nightly202009169cf9e4aebc/                 16-Sep-2020 08:30                   -\r\n  v15.0.0-nightly2020091718462e0c1d/                 17-Sep-2020 08:30                   -\r\n  v15.0.0-nightly202009182d868fe822/                 18-Sep-2020 07:30                   -\r\n  v15.0.0-nightly2020091931b3202d59/                 19-Sep-2020 08:00                   -\r\n  v15.0.0-nightly20200920770ad3a52d/                 20-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20200921039c274dde/                 21-Sep-2020 09:00                   -\r\n  v15.0.0-nightly20200922d71b467bbe/                 22-Sep-2020 08:30                   -\r\n  v15.0.0-nightly202009233b10f7f933/                 23-Sep-2020 07:00                   -\r\n  v15.0.0-nightly20200924d6fe46f749/                 25-Sep-2020 11:30                   -\r\n  v15.0.0-nightly20200925785a5f9ae1/                 25-Sep-2020 11:30                   -\r\n  v15.0.0-nightly20200926aa99bb47bf/                 26-Sep-2020 08:00                   -\r\n  v15.0.0-nightly20200927af92317909/                 27-Sep-2020 09:00                   -\r\n  v15.0.0-nightly202009286fc3b0ddb9/                 28-Sep-2020 08:00                   -\r\n  v15.0.0-nightly202009291e8cb08edc/                 29-Sep-2020 07:30                   -\r\n  v15.0.0-nightly20200930ee9e3e75aa/                 30-Sep-2020 08:30                   -\r\n  v15.0.0-nightly20201001726143e683/                 01-Oct-2020 07:00                   -\r\n  v15.0.0-nightly202010024a6005c56a/                 02-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201003e7bb8b6dc0/                 03-Oct-2020 08:00                   -\r\n  v15.0.0-nightly20201004e6d5af3c95/                 04-Oct-2020 08:30                   -\r\n  v15.0.0-nightly202010055e605c0dd9/                 05-Oct-2020 09:00                   -\r\n  v15.0.0-nightly20201006642f2064c0/                 06-Oct-2020 08:00                   -\r\n  v15.0.0-nightly20201007bc0c094b74/                 07-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201008ccc822c7c8/                 08-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201009c8b950a7af/                 09-Oct-2020 07:00                   -\r\n  v15.0.0-nightly202010108d8e06a345/                 10-Oct-2020 07:00                   -\r\n  v15.0.0-nightly2020101191e0d9bc30/                 11-Oct-2020 07:00                   -\r\n  v15.0.0-nightly202010122d83e743d9/                 12-Oct-2020 07:00                   -\r\n  v15.0.0-nightly2020101344a66adbaa/                 13-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201014d5e64952fe/                 14-Oct-2020 08:30                   -\r\n  v15.0.0-nightly202010154079bfd462/                 15-Oct-2020 21:00                   -\r\n  v15.0.0-nightly20201016c143266b55/                 16-Oct-2020 07:00                   -\r\n  v15.0.0-nightly20201017a3731309cc/                 17-Oct-2020 11:00                   -\r\n  v15.0.0-nightly20201018ee85eb9f8a/                 18-Oct-2020 07:30                   -\r\n  v15.0.0-nightly20201019c55f661551/                 19-Oct-2020 07:00                   -\r\n  v15.0.0-nightly2020102011f1ad939f/                 20-Oct-2020 07:00                   -\r\n  DOES NOT WORK - v16.0.0-nightly20201021c2ceb15fd5/                 21-Oct-2020 07:00                   -\r\n  ```\r\n</details>\r\n\r\nPlease view [Other Places This Issue is Mentioned](#Other-Places-This-Issue-is-Mentioned) for more information on this issue and a GIF demonstration of the issue.\r\n\r\n@joyeecheung\r\n@addaleax\r\n\r\n[n version manager]: https://github.com/tj/n\r\n[Node.js nightly]: https://nodejs.org/download/nightly/\r\n[comparison on GitHub]: https://github.com/nodejs/node/compare/bf0d82c102...7a447bcd54\r\n[Node.js source code]: https://github.com/nodejs/node\r\n\r\n# Other Places This Issue is Mentioned\r\n- https://github.com/nodejs/diagnostics/issues/455\r\n- https://github.com/nodejs/help/issues/3104\r\n- https://stackoverflow.com/questions/65113609/node-js-breakpoints-not-working-on-modules\r\n",
        "labels": "confirmed-bug",
        "id": 44998
    },
    {
        "title": "Asynchronous dir.close() throws immediately, if already closed",
        "body": "* **Version**: v12.12.0 - v14.15.1\r\n* **Platform**: platform-independent\r\n* **Subsystem**: lib/internal/fs/dir.js\r\n\r\n### What steps will reproduce the bug?\r\nCalling asynchronous version of dir.close() with dir already closed, e.g. by it's async iterator.\r\n```\r\nconst fs = require('fs')\r\n\r\nconst dir = fs.opendirSync('.')  // Using async function in this example just for brevity.\r\n\r\ndir.closeSync()     //  In my actual code, here is an async loop over dir.entries() which may terminate in the middle.\r\n\r\ntry {\r\n  dir.close((error) => {\r\n    if(!error) return\r\n    // We never get ERR_DIR_CLOSED here...\r\n  })\r\n} catch (error) {\r\n    // ... but here instead (but we should see only ERR_INVALID_CALLBACK here).\r\n}\r\n```\r\n### How often does it reproduce? Is there a required condition?\r\nAlways, when dir.close() is called redundantly.\r\n### What is the expected behavior?\r\nAsynchronous functions should forward errors via callback, unless the provided callback argument itself is invalid.\r\n### What do you see instead?\r\nError is thrown immediately (synchronously), This is especially embarrassing with promises API:\r\n```\r\ntry {\r\n  dir.close().then(() => console.log('closed the dir just now')\r\n  ).catch(error => console.log('something wrong', error))\r\n} catch (error) {\r\n  if(error.code === 'ERR_DIR_CLOSED') console.log('Oh no... again!')\r\n  else console.log('a real surprise!', e)\r\n}\r\n```\r\n### Additional information\r\nIf this behaviour is intentional, it should be documented; otherwise I would gladly provide a fix.",
        "labels": "confirmed-bug",
        "id": 44999
    },
    {
        "title": "doc: history shows wrong version for conditional package export support",
        "body": "# ðŸ“— API Reference Docs Problem\r\n\r\n<!-- The output of â€œnode --versionâ€. -->\r\n\r\n- **Version**: 12.16.0\r\n\r\n<!-- The output of â€œuname -aâ€ (UNIX) or version\r\nand 32-bit or 64-bit (Windows). -->\r\n\r\n- **Platform**: All\r\n\r\n<!-- The name of affected core module. -->\r\n\r\n- **Subsystem**: loader\r\n\r\n## Location\r\n\r\nModules: Packages\r\n\r\nAffected URL(s):\r\n\r\n- https://nodejs.org/api/packages.html#packages_exports\r\n\r\n## Description\r\n\r\nUnder the \"history\" section, the docs say that conditional export support was added and also unflagged in 12.16, which doesn't seem to be the case. 12.17.0 appears to be the first version that supports conditional exports and I can't get either conditional exports or the `--experimental-conditional-exports` flag to work in 12.16.0.\r\n\r\n![image](https://user-images.githubusercontent.com/2898433/99498789-1d811c80-29cc-11eb-9505-0978cad0b281.png)\r\n\r\n---\r\n\r\n- [x] I would like to work on this issue and\r\n      submit a pull request.\r\n",
        "labels": "confirmed-bug",
        "id": 45000
    },
    {
        "title": "Issue with mksnapshot and binding data",
        "body": "@joyeecheung ... I'm running into an issue with the node_mksnapshot tool during build. It apparently does not know how to handle BindingData for native modules when the snapshot is created...\r\n\r\nI'm working on a rework of `internalBinding('trace_events')` module, and attempting to add binding data to it:\r\n\r\n```cpp\r\n  TraceEventsState* const state =\r\n      env->AddBindingData<TraceEventsState>(context, target);\r\n  if (state == nullptr) return;\r\n```\r\n\r\nThe `trace_events` module is loaded during bootstrap, so the created `TraceEventsState` object is attached as the binding data at that step.\r\n\r\nUnfortunately, this causes `node_mksnapshot` to crash:\r\n\r\n```\r\nglobal handle not serialized: 0x327e5e9f3281: [JS_API_OBJECT_TYPE] in OldSpace\r\n - map: 0x2c1d4730fe89 <Map(HOLEY_ELEMENTS)> [FastProperties]\r\n - prototype: 0x218677ec84b1 <Object map = 0x2c1d473101a1>\r\n - elements: 0x1fd3c5ec0b29 <FixedArray[0]> [HOLEY_ELEMENTS]\r\n - embedder fields: 1\r\n - properties: 0x1fd3c5ec0b29 <FixedArray[0]> {}\r\n - embedder fields = {\r\n    22006, aligned pointer: 0x55f6648c31e0\r\n }\r\n\r\n\r\n\r\n#\r\n# Fatal error in , line 0\r\n# Check failed: handle_checker.CheckGlobalAndEternalHandles().\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 0x7ffd2543d6c0\r\n 1: 0x55f65ee301a1  [/home/james/node/node/out/Release/node_mksnapshot]\r\n 2: 0x55f65fd6af3e V8_Fatal(char const*, ...) [/home/james/node/node/out/Release/node_mksnapshot]\r\n 3: 0x55f65f3e3823 v8::SnapshotCreator::CreateBlob(v8::SnapshotCreator::FunctionCodeHandling) [/home/james/node/node/out/Release/node_mksnapshot]\r\n 4: 0x55f65ed1c016 node::SnapshotBuilder::Generate(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > >) [/home/james/node/node/out/Release/node_mksnapshot]\r\n 5: 0x55f65e953832 main [/home/james/node/node/out/Release/node_mksnapshot]\r\n 6: 0x7f2df6bb1b97 __libc_start_main [/lib/x86_64-linux-gnu/libc.so.6]\r\n 7: 0x55f65e95b42a _start [/home/james/node/node/out/Release/node_mksnapshot]\r\nIllegal instruction (core dumped)\r\nnode.target.mk:26: recipe for target '/home/james/node/node/out/Release/obj/gen/node_snapshot.cc' failed\r\nmake[1]: *** [/home/james/node/node/out/Release/obj/gen/node_snapshot.cc] Error 132\r\nrm 82c869d3ddd844a851343f4dda5865e1e173131d.intermediate 53b6ae97571ad65714c594648ab8f1c04245ce26.intermediate\r\nMakefile:104: recipe for target 'node' failed\r\nmake: *** [node] Error 2\r\n```\r\n\r\nWe should be able to attach `BindingData` to any of the internal native modules without having to fight with this. I know that addaleax's original implementation design for this bit covered but I'm not sure of the details so I'm not entirely sure what is missing in the version of your approach that landed here.",
        "labels": "confirmed-bug",
        "id": 45001
    },
    {
        "title": "stream: regression in v14, this.push(null) in Transform doesn't emit end",
        "body": "* **Version**: v14.5.0\r\n* **Platform**: Ubuntu/Linux\r\n* **Subsystem**: stream\r\n\r\n```js\r\nlet stream = require('stream');\r\n\r\nlet src = new stream.Readable({\r\n  read() {\r\n    console.log('push')\r\n    this.push(Buffer.alloc(20000));\r\n  }\r\n});\r\n\r\nlet dst = new stream.Transform({\r\n  transform(chunk, output, fn) {\r\n    this.push(null);\r\n    fn();\r\n  }\r\n});\r\n\r\nsrc.pipe(dst);\r\n\r\nfunction parser_end(error) {\r\n  console.log('parser ended', error);\r\n  dst.removeAllListeners();\r\n}\r\n\r\ndst.once('data', data => console.log(data));\r\ndst.once('end', () => parser_end());\r\ndst.on('error', error => parser_end(error));\r\n```\r\n\r\n* Expected behavior (tested on node v10, 12): `end` event is emitted by `dst`, transform stops, source pauses.\r\n* Actual behavior (tested on node v14): `end` event **does not** get emitted by `dst`, transform runs indefinitely.",
        "labels": "confirmed-bug",
        "id": 45002
    },
    {
        "title": "generateKeyPair with blank passphrase prompts \"Enter PEM pass phrase\" in Node 15",
        "body": "* **Version**: v15.0.1\r\n* **Platform**: Darwin DaveMBP.local 18.7.0 Darwin Kernel Version 18.7.0: Mon Aug 31 20:53:32 PDT 2020; root:xnu-4903.278.44~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst crypto = require('crypto');\r\n\r\ncrypto.generateKeyPair('rsa', {\r\n  modulusLength: 2048,\r\n  privateKeyEncoding: {\r\n    type: 'pkcs8',\r\n    format: 'pem',\r\n    cipher: 'aes-256-cbc',\r\n    passphrase: '', // <-- blank string passphrase\r\n  },\r\n  publicKeyEncoding: { type: 'spki', format: 'pem' },\r\n},  (err, publicKey, privateKey) => console.log(`got key\\n\\n${publicKey}\\n\\n${privateKey}`));\r\n```\r\n\r\n### What is the expected behaviour?\r\n\r\nIn NodeJS 14 and below, the above generates an output without any prompts.\r\n\r\n### What do you see instead?\r\n\r\nSince NodeJS 15, the above issues a prompt on the terminal:\r\n\r\n> ```\r\n> Enter PEM pass phrase:\r\n> ```\r\n\r\nWhich hangs until the user provides input (i.e. forever on a CI server).\r\n\r\n### Additional information\r\n\r\nIt seems reasonable for a blank string to be rejected as an input here if a cipher is being used, but it should either work or throw an exception. Triggering a command-line prompt is not a good user experience, and makes this relatively difficult to track-down.\r\n\r\nIn my particular case, I allow users of my project to configure a blank passphrase to mean \"don't bother encrypting this\", which I can achieve myself by detecting a blank passphrase and passing `undefined` for both `cipher` and `passphrase` in Node 15, which is fine. My personal preference would be for this to throw if given a blank passphrase, but that would still be a breaking change from 14, so maybe the way to go is to allow blank passphrases as before.",
        "labels": "confirmed-bug",
        "id": 45003
    },
    {
        "title": "`crypto.scryptSync` regression in Node 15: routines:EVP_PBE_scrypt:memory limit exceeded",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 15.0.1\r\n* **Platform**: Linux 64 bits\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n\r\nCreate `main.js` and run it.\r\n\r\n```\r\n// main.js\r\nconst crypto = require(\"crypto\");\r\n// 2-3 iteration steps are enough to cause the error, but it's not deterministic so I am running it 100 times to make sure the error occurs\r\nfor (let i = 0; i < 100; i++) {\r\n  crypto.scryptSync('', '', 64, { N: 128, r: 1, p: 1 })\r\n}\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nCalling `scryptSync` a few times always produces this error. This is not deterministic: sometimes 2 calls were enough, sometimes I need 3 calls.\r\n\r\n### What is the expected behavior?\r\n\r\nThe script completes without any error\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nI see the following error:\r\n\r\n```\r\nnode:internal/crypto/scrypt:81\r\n    throw err;\r\n    ^\r\n\r\nError: error:060B50AC:digital envelope routines:EVP_PBE_scrypt:memory limit exceeded\r\n    at Object.scryptSync (node:internal/crypto/scrypt:78:29)\r\n    at Object.<anonymous> (/data/projects/main.js:3:10)\r\n    at Module._compile (node:internal/modules/cjs/loader:1083:30)\r\n    at Object.Module._extensions..js (node:internal/modules/cjs/loader:1112:10)\r\n    at Module.load (node:internal/modules/cjs/loader:948:32)\r\n    at Function.Module._load (node:internal/modules/cjs/loader:789:14)\r\n    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:72:12)\r\n    at node:internal/main/run_main_module:17:47\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nThis is a regression in Node 15. Running the same code on the same computer with Node 14.14.0 works fine.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45004
    },
    {
        "title": "Function has non-object prototype 'null' in instanceof check, when I use node but it is fine in Browser",
        "body": "Looks like a Node.js bug. Logging an object should never crash. The same works in the browser:\r\n```\r\nfunction X () {}\r\nX.prototype = null;\r\nx = {};\r\nx.constructor = X;\r\nconsole.log(x);\r\n```\r\n\r\nNode.js:\r\n```\r\nUncaught TypeError: Function has non-object prototype 'null' in instanceof check\r\n    at Function.[Symbol.hasInstance] (<anonymous>)\r\n    at getConstructorName (internal/util/inspect.js:535:13)\r\n    at formatRaw (internal/util/inspect.js:803:23)\r\n    at formatValue (internal/util/inspect.js:793:10)\r\n    at inspect (internal/util/inspect.js:326:10)\r\n    at formatWithOptionsInternal (internal/util/inspect.js:1994:40)\r\n    at formatWithOptions (internal/util/inspect.js:1878:10)\r\n    at Object.value (internal/console/constructor.js:306:14)\r\n    at Object.log (internal/console/constructor.js:341:61)\r\n```\r\nBrowser:\r\n```\r\n{constructor: Æ’}\r\n```\r\n\r\n**node Verison:  v14.14.0**",
        "labels": "confirmed-bug",
        "id": 45005
    },
    {
        "title": "StringDecoder undocumented size limit",
        "body": "* **Version**: v12.13.0\r\n* **Platform**: Windows 10 (64bit)\r\n* **Subsystem**: string_decoder, stream\r\n\r\n### What steps will reproduce the bug?\r\n \r\n```\r\nconst buf = Buffer.alloc(1024 * 1024 * 1024, 'a');\r\nconst sd = new (require('string_decoder').StringDecoder)();\r\nsd.write(buf).length\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThe above causes the issue 100% reliably for me.\r\n\r\n### What is the expected behavior?\r\n\r\nEither the decoded buffer or an exception explaining that the input buffer is too long.\r\n\r\n### What do you see instead?\r\n\r\n> TypeError: Cannot read property 'length' of undefined\r\n\r\nSo sd.write(_large buffer_) returns undefined\r\n\r\nThe reason I'm including stream as an affected subsystem is this line which originally led me to this issue: https://github.com/nodejs/readable-stream/blob/040b813e60ecf0d68ac1461a3fc3157ea5785950/lib/_stream_readable.js#L277\r\n\r\nSo what happens is that if you have a stream (a pipe used for IPC in my case) and the other side sends an large chunk of data, the recipient throws an exception before any application code is invoked that could handle it gracefully.\r\n\r\n### Additional information\r\n\r\nI don't know exactly how large the buffer has to be. In my application (electron 8.5.2 with node 12.13.0) this started happening at around 600MB, when reproducing in node on the command line I had to increase the buffer to 1GB.\r\n\r\nJust to clarify: I understand that there will be a limit on how large these buffers can get, I just wish it would report an error that my application code can handle because right now I don't see how I could write robust client code that can deal with the other side sending crap.",
        "labels": "confirmed-bug",
        "id": 45006
    },
    {
        "title": "HTTP: Connection resets after 60 seconds in node.js upload application",
        "body": "* **Version**: v12.19.0\r\n* **Platform**: Linux *snip* 4.15.0-121-generic #123-Ubuntu SMP Mon Oct 5 16:16:40 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux (Ubuntu 18.04.5 LTS)\r\n* **Subsystem**: http\r\n\r\n### What steps will reproduce the bug?\r\n\r\nThe client depends on node-fetch v2.6.1\r\n\r\n`testServer.js`\r\n```\r\n// -- DevNull Start --\r\nvar util         = require('util')\r\n  , stream       = require('stream')\r\n  , Writable     = stream.Writable\r\n  , setImmediate = setImmediate || function (fn) { setTimeout(fn, 0) }\r\n  ;\r\nutil.inherits(DevNull, Writable);\r\nfunction DevNull (opts) {\r\n  if (!(this instanceof DevNull)) return new DevNull(opts);\r\n  opts = opts || {};\r\n  Writable.call(this, opts);\r\n}\r\nDevNull.prototype._write = function (chunk, encoding, cb) {\r\n  setImmediate(cb);\r\n}\r\n// -- DevNull End --\r\nconst http = require('http');\r\nconst server = http.createServer();\r\nserver.on('request', async (req, res) => {\r\n  try {\r\n    req.socket.on('end', function() { \r\n      console.log('SOCKET END: other end of the socket sends a FIN packet');\r\n    });\r\n    req.socket.on('timeout', function() { \r\n      console.log('SOCKET TIMEOUT');\r\n    });\r\n    req.socket.on('error', function(error) { \r\n      console.log('SOCKET ERROR: ' + JSON.stringify(error));\r\n    });\r\n    req.socket.on('close', function(had_error) { \r\n      console.log('SOCKET CLOSED. IT WAS ERROR: ' + had_error);\r\n    });\r\n    const writeStream = DevNull();\r\n    const promise = new Promise((resolve, reject) => {\r\n      req.on('end', resolve);\r\n      req.on('error', reject);\r\n    });\r\n    req.pipe(writeStream);\r\n    await promise;\r\n    res.writeHead(200);\r\n    res.end('OK');\r\n  } catch (err) {\r\n    res.writeHead(500);\r\n    res.end(err.message);\r\n  }\r\n});\r\nserver.listen(8081)\r\n  .on('listening', () => { console.log('Listening on port', server.address().port); });\r\n```\r\n\r\n`testClient.js`\r\n```\r\n// -- RandomStream Start --\r\nvar crypto = require('crypto');\r\nvar stream = require('stream');\r\nvar util = require('util');\r\nvar Readable = stream.Readable;\r\nfunction RandomStream(length, options) {\r\n  // allow calling with or without new\r\n  if (!(this instanceof RandomStream)) {\r\n    return new RandomStream(length, options);\r\n  }\r\n  // init Readable\r\n  Readable.call(this, options);\r\n  // save the length to generate\r\n  this.lenToGenerate = length;\r\n}\r\nutil.inherits(RandomStream, Readable);\r\nRandomStream.prototype._read = function (size) {\r\n  if (!size) size = 1024; // default size\r\n  var ready = true;\r\n  while (ready) { // only cont while push returns true\r\n    if (size > this.lenToGenerate) { // only this left\r\n      size = this.lenToGenerate;\r\n    }\r\n    if (size) {\r\n      ready = this.push(crypto.randomBytes(size));\r\n      this.lenToGenerate -= size;\r\n    }\r\n    // when done, push null and exit loop\r\n    if (!this.lenToGenerate) {\r\n      this.push(null);\r\n      ready = false;\r\n    }\r\n  }\r\n};\r\n// -- RandomStream End --\r\nconst fetch = require('node-fetch');\r\nconst runSuccess = async () => { // Runs in ~35 seconds\r\n  const t = Date.now();\r\n  try {\r\n    const resp = await fetch('http://localhost:8081/test', {\r\n      method: 'PUT',\r\n      body: new RandomStream(256e6) // new RandomStream(1024e6)\r\n    });\r\n    const data = await resp.text();\r\n    console.log(Date.now() - t, data);\r\n  } catch (err) {\r\n    console.warn(Date.now() - t, err);\r\n  }\r\n};\r\nconst runFail = async () => { // Fails after 60 seconds\r\n  const t = Date.now();\r\n  try {\r\n    const resp = await fetch('http://localhost:8081/test', {\r\n      method: 'PUT',\r\n      body: new RandomStream(1024e6)\r\n    });\r\n    const data = await resp.text();\r\n    console.log(Date.now() - t, data);\r\n  } catch (err) {\r\n    console.warn(Date.now() - t, err);\r\n  }\r\n};\r\n// runSuccess().then(() => process.exit(0));\r\nrunFail().then(() => process.exit(0));\r\n```\r\n\r\n- Install node-fetch in the same folder as the reproduction scripts: `npm i node-fetch`\r\n- Start the server with `node testServer.js` - This creates a new HTTP server listening on port 8081\r\n- Run the client with `node testClient.js`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThe value inside RandomStream needs to be high enough to cause the request to take longer than 60 seconds.\r\n\r\n### What is the expected behavior?\r\n\r\nIn Node.js 10:\r\n```\r\n$ node testClient.js\r\n145014 'OK'\r\n```\r\n\r\n### What do you see instead?\r\n\r\nIn Node.js 12:\r\n```\r\n$ node testClient.js\r\n60014 FetchError: request to http://localhost:8081/test failed, reason: write ECONNRESET\r\n    at ClientRequest.<anonymous> (/home/*snip*/node_modules/node-fetch/lib/index.js:1461:11)\r\n    at ClientRequest.emit (events.js:326:22)\r\n    at Socket.socketErrorListener (_http_client.js:428:9)\r\n    at Socket.emit (events.js:314:20)\r\n    at errorOrDestroy (internal/streams/destroy.js:108:12)\r\n    at onwriteError (_stream_writable.js:418:5)\r\n    at onwrite (_stream_writable.js:445:5)\r\n    at internal/streams/destroy.js:50:7\r\n    at Socket._destroy (net.js:681:5)\r\n    at Socket.destroy (internal/streams/destroy.js:38:8) {\r\n  type: 'system',\r\n  errno: 'ECONNRESET',\r\n  code: 'ECONNRESET'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\nIf there is any workaround, please let me know.\r\n",
        "labels": "confirmed-bug",
        "id": 45007
    },
    {
        "title": "fs.ftruncate silently accepts negative offsets rather than failing with ERR_INVALID",
        "body": "fs.ftruncate and fd.ftruncateSync both silently ignore negative offsets:\r\n\r\nhttps://github.com/nodejs/node/blob/2cfdf28413fd9a7bfab65cb49cff6e50ab0c21ec/lib/fs.js#L840\r\n\r\nThis didn't always do behave like this.. looks like it was introduced in 8974df15a973e97a74cf9fb0ccb45c11baa7b54a\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```\r\nvar fs = require(\"fs\");\r\nvar fd = fs.openSync(\"f\", 'w+');\r\nconsole.log(fs.ftruncateSync(fd, -99));\r\n```\r\n\r\n### What is the expected behavior?\r\n\r\nThe ftruncate POSIX function is described as returning EINVAL when given a negative offset:\r\nhttps://linux.die.net/man/2/ftruncate\r\n\r\nIn emscripten we emulate a POSIX environment on top of the Web and on top of node and expect ftruncate to fail in the same way. \r\n\r\nWe can obviously add a check to our code as a workaround but this does seem like a bug in node.\r\n\r\n### What do you see instead?\r\n\r\nSilently assumed `0` length is what the caller really wants.\r\n",
        "labels": "confirmed-bug",
        "id": 45008
    },
    {
        "title": "Segfault on v12.19.0",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:v12.19.0\r\n* **Platform**: RHEL\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\nUsing node js and running the component test with cucumber-js\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAfter Upgrading to v12.19.0 - issue has been consistent\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n/home/user1/GIT/cp1/r1/r1/node_modules/segfault-handler/build/Release/segfault-handler.node(+0x2c61)[0x7f9e881fbc61]\r\n/lib64/libpthread.so.0(+0xf6d0)[0x7f9ea0eb06d0]\r\nnode[0x9cf96e]\r\nnode(_ZN2v88internal13GlobalHandles40InvokeSecondPassPhantomCallbacksFromTaskEv+0x19b)[0xd17c4b]\r\nnode(_ZN2v88internal14CancelableTask3RunEv+0x23)[0xc953e3]\r\nnode(_ZN4node22PerIsolatePlatformData17RunForegroundTaskESt10unique_ptrIN2v84TaskESt14default_deleteIS3_EE+0xc4)[0xa86d54]\r\nnode(_ZN4node22PerIsolatePlatformData28FlushForegroundTasksInternalEv+0x165)[0xa87a15]\r\nnode[0x136f0ae]\r\nnode[0x1382165]\r\nnode(uv_run+0x11f)[0x136f8ef]\r\nnode(_ZN4node16NodeMainInstance3RunEv+0x1f6)[0xa5aac6]\r\nnode(_ZN4node5StartEiPPc+0x2ac)[0x9e85cc]\r\n/lib64/libc.so.6(__libc_start_main+0xf5)[0x7f9ea0af6445]\r\nnode[0x9819b5]\r\n\r\n\r\n### Additional information\r\nI am using native code build with node-gyp \r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45009
    },
    {
        "title": "Crash when using NODE_OPTIONS=--experimental-specifier-resolution=node with some .bin executables",
        "body": "* **Version**: 14.13.0\r\n* **Platform**: macOS 10.15.6\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n`NODE_OPTIONS=--experimental-specifier-resolution=node node_modules/.bin/semver --version`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n100%\r\n\r\n### What is the expected behavior?\r\nRuns just like when `NODE_OPTIONS` isn't set\r\n\r\n### What do you see instead?\r\nThis error:\r\n```\r\ninternal/process/esm_loader.js:74\r\n    internalBinding('errors').triggerUncaughtException(\r\n                              ^\r\n\r\nTypeError [ERR_INVALID_RETURN_PROPERTY_VALUE]: Expected string to be returned for the \"format\" from the \"loader getFormat\" function but got type object.\r\n    at Loader.getFormat (internal/modules/esm/loader.js:110:13)\r\n    at async Loader.getModuleJob (internal/modules/esm/loader.js:230:20)\r\n    at async Loader.import (internal/modules/esm/loader.js:164:17)\r\n    at async Object.loadESM (internal/process/esm_loader.js:68:5) {\r\n  code: 'ERR_INVALID_RETURN_PROPERTY_VALUE'\r\n}\r\n```\r\n\r\n### Additional information\r\nAlso happens with `he`, `mocha`, `node-which`, and `tsc`\r\n",
        "labels": "confirmed-bug",
        "id": 45010
    },
    {
        "title": "[worker_threads]: Main thread receives Error object when the worker throws a primitive value",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.7.0\r\n* **Platform**: Darwin suin 18.7.0 Darwin Kernel Version 18.7.0: Mon Feb 10 21:08:45 PST 2020; root:xnu-4903.278.28~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: N/A\r\n\r\n### What steps will reproduce the bug?\r\n\r\nSummary: Since Node v14.7.0, when primitive values are thrown in a worker, the main thread receives it as Error objects.\r\n\r\nI'm not sure this is actually a bug. But I couldn't find out the information about this breaking change. So I have created this issue. If this is an expected change, please close this issue.\r\n\r\n```js\r\n// main.js\r\nconst { Worker } = require('worker_threads')\r\nconst worker = new Worker('./worker.js')\r\nconsole.log(process.versions.node)\r\nworker.on('error', err => {\r\n  console.error(err)\r\n})\r\n```\r\n\r\n```js\r\n// worker.js\r\nthrow 'Error was thrown in worker'\r\n```\r\n\r\nin Node v14.6.0:\r\n\r\n```\r\n$ node main.js\r\n14.6.0\r\nError was thrown in worker\r\n```\r\n\r\nin Node v14.7.0:\r\n\r\n```\r\n$ node main.js\r\n14.7.0\r\nError [ERR_UNHANDLED_ERROR]: Unhandled error. ('Error was thrown in worker')\r\n    at process.emit (events.js:303:17)\r\n    at emitUnhandledRejectionOrErr (internal/event_target.js:541:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (internal/event_target.js:356:9)\r\n    at MessagePort.exports.emitMessage (internal/per_context/messageport.js:18:26) {\r\n  code: 'ERR_UNHANDLED_ERROR',\r\n  context: 'Error was thrown in worker'\r\n}\r\n```\r\n\r\nOther primitives:\r\n\r\n<details>\r\n\r\n__Undefined__\r\n\r\n```js\r\n// worker.js\r\nthrow undefined\r\n```\r\n\r\n```\r\n$ node main.js\r\n14.6.0\r\nundefined\r\n\r\n$ node main.js\r\n14.7.0\r\nError [ERR_UNHANDLED_ERROR]: Unhandled error. (undefined)\r\n    at process.emit (events.js:303:17)\r\n    at emitUnhandledRejectionOrErr (internal/event_target.js:541:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (internal/event_target.js:356:9)\r\n    at MessagePort.exports.emitMessage (internal/per_context/messageport.js:18:26) {\r\n  code: 'ERR_UNHANDLED_ERROR',\r\n  context: undefined\r\n}\r\n```\r\n\r\n__Number__\r\n\r\n```js\r\n// worker.js\r\nthrow 0\r\n```\r\n\r\n```\r\n$ node main.js\r\n14.6.0\r\n0\r\n\r\n$ node main.js\r\n14.7.0\r\nError [ERR_UNHANDLED_ERROR]: Unhandled error. (0)\r\n    at process.emit (events.js:303:17)\r\n    at emitUnhandledRejectionOrErr (internal/event_target.js:541:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (internal/event_target.js:356:9)\r\n    at MessagePort.exports.emitMessage (internal/per_context/messageport.js:18:26) {\r\n  code: 'ERR_UNHANDLED_ERROR',\r\n  context: 0\r\n}\r\n```\r\n\r\n__Symbol__\r\n\r\n```js\r\n// worker.js\r\nthrow Symbol('this is a symbol')\r\n```\r\n\r\n```\r\n$ node main.js\r\n14.6.0\r\nSymbol(this is a symbol)\r\n\r\n$ node main.js\r\n14.7.0\r\nError [ERR_UNHANDLED_ERROR]: Unhandled error. (Symbol(this is a symbol))\r\n    at process.emit (events.js:303:17)\r\n    at emitUnhandledRejectionOrErr (internal/event_target.js:541:11)\r\n    at MessagePort.[nodejs.internal.kHybridDispatch] (internal/event_target.js:356:9)\r\n    at MessagePort.exports.emitMessage (internal/per_context/messageport.js:18:26)\r\n```\r\n\r\n</details>\r\n\r\n\r\n\r\n\r\n\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThere is no condition.\r\n\r\n### What is the expected behavior?\r\n\r\nI'm not sure which is valid behavior, but at point of view of backward compatibilities, it would be the expected behavior that the main thread receives the unhandled primitive error as the primitive value instead of the Error object like the Node v14.6.0 behavior.\r\n\r\n### What do you see instead?\r\n\r\nThe main thread gets the Error object.\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45011
    },
    {
        "title": "Node 14.13 problematic (default?) import combinations",
        "body": "There are some import combinations which do not work together any longer (each import alone works fine)\r\n\r\n* **Version**:v14.13.0\r\n* **Platform**: Darwin mbpMarkus 19.6.0 Darwin Kernel Version 19.6.0: Mon Aug 31 22:12:52 PDT 2020; root:xnu-6153.141.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nimport recast from \"recast\";\r\nimport lockfile from '@yarnpkg/lockfile';\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways (starting with node 14.13)\r\n\r\n### What is the expected behavior?\r\ntwo default exports provided\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n```\r\nnode issue.mjs \r\nnode_modules/recast/lib/lines.js:580\r\n    assert_1.default.ok(tabWidth || tabless, \"No tab width specified but encountered tabs in string\\n\" + string);\r\n                     ^\r\n\r\nTypeError: assert_1.default.ok is not a function\r\n    at fromString (node_modules/recast/lib/lines.js:580:22)\r\n    at Object.<anonymous> (/node_modules/recast/lib/lines.js:654:18)\r\n    at Module._compile (internal/modules/cjs/loader.js:1085:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1114:10)\r\n    at Module.load (internal/modules/cjs/loader.js:950:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:791:14)\r\n    at Module.require (internal/modules/cjs/loader.js:974:19)\r\n    at require (internal/modules/cjs/helpers.js:88:18)\r\n    at Object.<anonymous> (node_modules/recast/lib/parser.js:11:15)\r\n    at Module._compile (internal/modules/cjs/loader.js:1085:30)\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\nSaw the problem with other combinations of imports to\r\n",
        "labels": "confirmed-bug",
        "id": 45012
    },
    {
        "title": "[v12.x] icu: broken date locale string format on zh-CN",
        "body": "* **Version**: v12.17.0-12.18.4\r\n* **Platform**: all\r\n* **Subsystem**: icu\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```\r\n$ LANG=zh_CN.UTF-8 node -p 'new Date().toLocaleString()'\r\n2020-9-28 3:33:35 â”œF10: PMâ”¤\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n\r\n\r\nnode v12.16.3 (small-icu, English only)\r\n```\r\n$ LANG=zh_CN.UTF-8 node -p 'new Date().toLocaleString()'\r\n2020-9-28 15:34:08\r\n```\r\n\r\nnode v14.12.0 (full-icu)\r\n```\r\n$ LANG=zh_CN.UTF-8 node -p 'new Date().toLocaleString()'\r\n2020/9/28 ä¸‹åˆ3:35:06\r\n```\r\n\r\nBoth cases are correct.\r\n\r\n### What do you see instead?\r\n\r\nInvalid and meaningless symbol characters \"â”œF10: PMâ”¤\" in localized strings.\r\n\r\n### Additional information\r\n\r\nReverting https://github.com/nodejs/node/pull/33337 (5c0232a632, 2d76ae7497) can fix the issue.\r\n",
        "labels": "confirmed-bug",
        "id": 45013
    },
    {
        "title": "fs.readFile does not account file system flag 'a+' in Node 14.11",
        "body": "I tried to find similar issues but couldn't, sorry if it is already reported.\r\n\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:\r\nv14.11.0\r\n* **Platform**:\r\nDarwin MacBook-Pro-Daniil.local 18.7.0 Darwin Kernel Version 18.7.0: Thu Jun 20 18:42:21 PDT 2019; root:xnu-4903.270.47~4/RELEASE_X86_64 x86_64\r\n\r\n### What steps will reproduce the bug?\r\n\r\nWith `a+` flag file should be created if it does not exist. It works with `readFileSync`, but fails with `readFile`\r\nThere is also similar problem with `w+` flag and maybe others, but I did not tested all of them.\r\n\r\n```js\r\nconst fs = require('fs');\r\n\r\nconst content = fs.readFileSync('./nonexistingfile1', {\r\n  encoding: 'utf-8',\r\n  flag: 'a+',\r\n});\r\n\r\nconsole.log(content); // content is empty string, so file was created\r\n\r\nfs.readFile(\r\n  './nonexistingfile2',\r\n  { encoding: 'utf-8', flag: 'a+' },\r\n  (err, data) => {\r\n    console.log(err, data);\r\n    // [Error: ENOENT: no such file or directory, open './nonexistingfile2'] {\r\n    //   errno: -2,\r\n    //   code: 'ENOENT',\r\n    //   syscall: 'open',\r\n    //   path: './nonexistingfile2'\r\n    // }\r\n  }\r\n);\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways with node v14.11\r\nWorks fine in node v12.18.4\r\n\r\n### What is the expected behavior?\r\n\r\nFile is created before reading and there is no ENOENT error\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nENOENT error\r\n\r\n```\r\n    [Error: ENOENT: no such file or directory, open './nonexistingfile2'] {\r\n      errno: -2,\r\n      code: 'ENOENT',\r\n      syscall: 'open',\r\n      path: './nonexistingfile2'\r\n    }\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45014
    },
    {
        "title": "http2: Node crashes with an assertion error if an http2 server is closed after receiving and rejecting very large headers",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 14.10.0\r\n* **Platform**: Linux DESKTOP-OKC3QBQ 4.4.0-18362-Microsoft #1049-Microsoft Thu Aug 14 12:01:00 PST 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: http2\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst http2 = require('http2');\r\n\r\nconst server = http2.createServer({\r\n  maxSendHeaderBlockLength: Number.MAX_SAFE_INTEGER\r\n});\r\n\r\nserver.on('stream', (stream, headers) => {\r\n  stream.respond();\r\n  stream.end();\r\n});\r\n\r\nserver.listen(8080, () => {\r\n  const clientSession = http2.connect('http://localhost:8080', {\r\n    maxSendHeaderBlockLength: Number.MAX_SAFE_INTEGER\r\n  });\r\n\r\n  clientSession.on('error', (error) => {\r\n    console.log(error);\r\n  })\r\n\r\n  const stream = clientSession.request({\r\n    'test-header': 'A'.repeat(90000)\r\n  });\r\n\r\n  stream.on('close', () => {\r\n    console.log(`Stream closed with RST_STREAM code ${stream.rstCode}`);\r\n    server.close();\r\n  });\r\n\r\n  stream.on('error', (error) => {\r\n    console.log(error);\r\n  })\r\n\r\n  stream.end();\r\n});\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThis reproduction is 100% consistent.\r\n\r\n### What is the expected behavior?\r\n\r\n```\r\nError [ERR_HTTP2_SESSION_ERROR]: Session closed with error code 9\r\n    at Http2Session.onGoawayData (internal/http2/core.js:642:21) {\r\n  code: 'ERR_HTTP2_SESSION_ERROR'\r\n}\r\nStream closed with RST_STREAM code 9\r\nError [ERR_HTTP2_SESSION_ERROR]: Session closed with error code 9\r\n    at Http2Session.onGoawayData (internal/http2/core.js:642:21) {\r\n  code: 'ERR_HTTP2_SESSION_ERROR'\r\n}\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n```\r\nError [ERR_HTTP2_SESSION_ERROR]: Session closed with error code 9\r\n    at Http2Session.onGoawayData (internal/http2/core.js:642:21) {\r\n  code: 'ERR_HTTP2_SESSION_ERROR'\r\n}\r\nStream closed with RST_STREAM code 9\r\nError [ERR_HTTP2_SESSION_ERROR]: Session closed with error code 9\r\n    at Http2Session.onGoawayData (internal/http2/core.js:642:21) {\r\n  code: 'ERR_HTTP2_SESSION_ERROR'\r\n}\r\nnode[5776]: ../src/node_http2.cc:522:virtual node::http2::Http2Session::~Http2Session(): Assertion `(current_nghttp2_memory_) == (0)' failed.\r\n 1: 0xa02dd0 node::Abort() [node]\r\n 2: 0xa02e4e  [node]\r\n 3: 0xa274aa node::http2::Http2Session::~Http2Session() [node]\r\n 4: 0xa27611 node::http2::Http2Session::~Http2Session() [node]\r\n 5: 0x9a9dbb node::Environment::RunCleanup() [node]\r\n 6: 0x96d3d7 node::FreeEnvironment(node::Environment*) [node]\r\n 7: 0xa42d6f node::NodeMainInstance::Run() [node]\r\n 8: 0x9d10e5 node::Start(int, char**) [node]\r\n 9: 0x7f9b63f60830 __libc_start_main [/lib/x86_64-linux-gnu/libc.so.6]\r\n10: 0x9697bc  [node]\r\nAborted (core dumped)\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nThis is related to #35218 regarding the handling of very large request headers.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45015
    },
    {
        "title": "Promise.reject() crashes repl when using --unhandled-rejections=strict",
        "body": "* **Version**: 14.11.0\r\n* **Platform**: macOS Catalina 10.15.6\r\n\r\nI have also reproduced this in Node 12.18.4.\r\n\r\n### What steps will reproduce the bug?\r\n\r\nLaunch the repl with this command:\r\n\r\n```\r\nnode --unhandled-rejections=strict\r\n```\r\n\r\n(`--unhandled-rejections=throw` has the same issue.)\r\n\r\nOn the repl command line, type `Promise.reject()`.\r\n\r\n### What is the expected behavior?\r\n\r\nWhen an uncaught error is thrown in the repl, the repl should print \"Uncaught error\" without terminating the process. For example:\r\n\r\n```\r\n> throw new Error()\r\nUncaught Error\r\n> void setTimeout(_=>{throw new Error()}, 0)\r\nundefined\r\n> Uncaught Error\r\n```\r\n\r\n### What do you see instead?\r\n\r\nThe process crashes.\r\n\r\n```\r\n> Promise.reject()\r\nPromise { <rejected> undefined }\r\n> internal/process/promises.js:213\r\n        triggerUncaughtException(err, true /* fromPromise */);\r\n        ^\r\n\r\n[UnhandledPromiseRejection: This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). The promise rejected with the reason \"undefined\".] {\r\n  code: 'ERR_UNHANDLED_REJECTION'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\nThis bug will become more important in Node 15 when `--unhandled-rejections=throw` becomes the default, per PR #33021. At that point, the bug will repro when launching `node` using the default settings with no flags.",
        "labels": "confirmed-bug",
        "id": 45016
    },
    {
        "title": "esm: provide more detailed error message when named import of cjs module",
        "body": "<!--\r\nThank you for suggesting an idea to make Node.js better.\r\n\r\nPlease fill in as much of the template below as you're able.\r\n-->\r\n\r\n**Is your feature request related to a problem? Please describe.**\r\nWhen I try to make named import for commonjs package, error throws:\r\n```\r\nThe requested module 'redux' is expected to be of type CommonJS, which does not support named exports. CommonJS modules can be imported by importing the default export.\r\nFor example:\r\nimport pkg from 'redux';\r\nconst { compose } = pkg;\r\n```\r\n\r\nIn large project it can be hard to find in which file error is thrown\r\n\r\n**Describe the solution you'd like**\r\nIt would be great append path to module, where \r\n```\r\nThe requested from '/path/to/module.js' module 'redux' is expected to be of type CommonJS, which does not support named exports. CommonJS modules can be imported by importing the default export.\r\nFor example:\r\nimport pkg from 'redux';\r\nconst { compose } = pkg;\r\n```",
        "labels": "confirmed-bug",
        "id": 45017
    },
    {
        "title": "Coredump when passing `undefined` as address from custom `lookup` function",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.15.0\r\n* **Platform**: Linux desktop-home 5.4.53 #1-NixOS SMP Wed Jul 22 07:33:18 UTC 2020 x86_64 GNU/Linux\r\n* **Subsystem**: net / TCP\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\n\"use strict\";\r\n\r\nconst http = require(\"http\");\r\n\r\nhttp.get({\r\n\thost: \"google.com:80\",\r\n\tpath: \"/\",\r\n\tlookup: function (host, options, callback) {\r\n\t\tcallback(null, undefined, 4);\r\n\t\t// Note the `undefined` here instead of an IP!\r\n\t}\r\n});\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nCompletely reproducible.\r\n\r\n### What is the expected behavior?\r\n\r\nShould produce a (catchable/handleable) error indicating that an invalid value was passed from `lookup` rather than aborting, since this is public API.\r\n\r\n### What do you see instead?\r\n\r\n```\r\nnode[18969]: ../src/tcp_wrap.cc:312:static void node::TCPWrap::Connect(const v8::FunctionCallbackInfo<v8::Value>&, std::function<int(const char*, T*)>) [with T = sockaddr_in]: Assertion `args[1]->IsString()' failed.\r\n 1: 0x9345f8 node::Abort() [node]\r\n 2: 0x934691  [node]\r\n 3: 0x9fda20 void node::TCPWrap::Connect<sockaddr_in>(v8::FunctionCallbackInfo<v8::Value> const&, std::function<int (char const*, sockaddr_in*)>) [node]\r\n 4: 0x9fc95c node::TCPWrap::Connect(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 5: 0xb0e819 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [node]\r\n 6: 0xb0ebd0  [node]\r\n 7: 0xb0fa6a  [node]\r\n 8: 0xb0fcf9 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 9: 0x12af4f9  [node]\r\nAborted (core dumped)\r\n```\r\n\r\n### Additional information\r\n\r\nN/A",
        "labels": "confirmed-bug",
        "id": 45018
    },
    {
        "title": "url.pathToFileURL doesn't generate valid URLs for UNC paths",
        "body": "\r\n* Node.js version: v12.18.3 and v14.8.0\r\n\r\n* Platform: Windows 10 (10.0.19041)\r\n\r\n* Subsystem: `url`\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst url = require(\"url\")\r\nurl.pathToFileURL(\"\\\\\\\\laptop\\\\My Documents\\\\FileSchemeURIs.doc\")\r\n```\r\n\r\n### Expected behavior\r\n\r\nAs per [Microsoft's UNC URI documentation](https://docs.microsoft.com/en-us/archive/blogs/ie/file-uris-in-windows)):\r\n\r\n`file://laptop/My%20Documents/FileSchemeURIs.doc`\r\n\r\n### Actual behavior\r\n\r\n```\r\nURL {\r\n  href: 'file:///laptop/My%20Documents/FileSchemeURIs.doc',\r\n  origin: 'null',\r\n  protocol: 'file:',\r\n  username: '',\r\n  password: '',\r\n  host: '',\r\n  hostname: '',\r\n  port: '',\r\n  pathname: '/laptop/My%20Documents/FileSchemeURIs.doc',\r\n  search: '',\r\n  searchParams: URLSearchParams {},\r\n  hash: ''\r\n}\r\n```\r\n\r\n1. `hostname` should be `laptop` (not `''`).\r\n\r\n2.  `pathname` should be `/My%20Documents/FileSchemeURIs.doc` (not be prefixed by `/laptop/`).\r\n",
        "labels": "confirmed-bug",
        "id": 45019
    },
    {
        "title": "http data streaming Error: socket hang up after 60 seconds (tested on windows)",
        "body": "\r\nThis works fine on node 12>18 LTS\r\n\r\nVersion: v14.7.0`\r\nPlatform: windows 10 64 bit and windows server \r\n\r\n-->\r\n\r\n* **Version**:\r\n### What steps will reproduce the bug?\r\n\r\nClient code:\r\n```\r\nhttp=require('http')\r\n  // An object of options to indicate where to post to\r\n  var post_options = {\r\n    host: '127.0.0.1', //'34.255.202.222',\r\n    port: '80',\r\n    path: '/test',\r\n    method: 'POST',\r\n    headers: {        \r\n        'Content-Type': 'text/html; charset=UTF-8'        \r\n    }\r\n};\r\n\r\n// Set up the request\r\nvar post_req = http.request(post_options, function(res) {    \r\n    res.on('data', function (chunk) {\r\n        console.log('Response: ' + chunk);\r\n    });\r\n});\r\n\r\n// post the data\r\nsetInterval(() => {\r\n    post_req.write(`another chunk ${new Date()}`); \r\n}, 100);\r\n```\r\n\r\n\r\nServer code:\r\n```\r\nconst http = require('http')\r\n\r\nconst server = http.createServer(function(request, response) {\r\n  if (request.method == 'POST') {\r\n    response.writeHead(200, {'Content-Type': 'text/html'})\r\n    console.log('POST')\r\n    let zz=0;\r\n    request.on('data', function(data) {\r\n      zz += data.length;\r\n      process.stdout.write(\"Downloading \" +data+\" \"+ zz/1000 + \" bytes\\r\");\r\n       \r\n    })\r\n    request.on('end', function() {\r\n      console.log('Body: ' + zz)\r\n      \r\n      response.end('post received')\r\n    })\r\n  } \r\n  })\r\nconst port = 80\r\nconst host = '127.0.0.1'\r\nserver.keepAliveTimeout=100000;\r\nserver.listen(port)\r\nconsole.log(`Listening at http://${host}:${port}`)\r\n```\r\n\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways\r\n\r\n### What is the expected behavior?\r\nSoctet will continue \r\n\r\n### What do you see instead?\r\n\r\n```\r\n\r\nevents.js:291\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: socket hang up\r\n\u001b[90m    at connResetException (internal/errors.js:612:14)\u001b[39m\r\n\u001b[90m    at Socket.socketOnEnd (_http_client.js:493:23)\u001b[39m\r\n\u001b[90m    at Socket.emit (events.js:326:22)\u001b[39m\r\n\u001b[90m    at endReadableNT (_stream_readable.js:1244:12)\u001b[39m\r\n\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m\r\nEmitted 'error' event on ClientRequest instance at:\r\n\u001b[90m    at Socket.socketOnEnd (_http_client.js:493:9)\u001b[39m\r\n\u001b[90m    at Socket.emit (events.js:326:22)\u001b[39m\r\n\u001b[90m    at endReadableNT (_stream_readable.js:1244:12)\u001b[39m\r\n\u001b[90m    at processTicksAndRejections (internal/process/task_queues.js:80:21)\u001b[39m {\r\n  code: \u001b[32m'ECONNRESET'\u001b[39m\r\n}\r\n\r\n`",
        "labels": "confirmed-bug",
        "id": 45020
    },
    {
        "title": "dns.resolveSoa returns EBADRESP if hostname has a CNAME record",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version(s)**: v12.16.3 / v12.18.3 / v12.18.0\r\n* **Platform**: Windows / Windows Subsystem for Linux (Debian) / Red Hat Enterprise Linux Server release 7.8\r\n* **Subsystem**: DNS\r\n\r\n### What steps will reproduce the bug?\r\n```\r\nconst dns = require('dns');\r\nconst resolver = new dns.promises.Resolver();\r\n\r\n// **************************************************************\r\n\r\nasync function test(hostname) {\r\n  let data = '';\r\n\r\n  console.log('hostname:', hostname);\r\n\r\n  try {\r\n    data = await resolver.resolveCname(hostname);\r\n    console.log('CNAME result:', data);\r\n  } catch (error) {\r\n    console.log('CNAME result:', error.message);\r\n  }\r\n\r\n  try {\r\n    data = await resolver.resolveSoa(hostname);\r\n    console.log('SOA result:', JSON.stringify(data));\r\n  } catch (error) {\r\n    console.log('SOA result:', error.message);\r\n  }\r\n\r\n  console.log();\r\n}\r\n\r\n// **************************************************************\r\n\r\n(async function main() {\r\n  await test('support.microsoft.com');\r\n})();\r\n```\r\n\r\n### Actual Results\r\nhostname: support.microsoft.com\r\nCNAME result: [ 'ev.support.microsoft.com.edgekey.net' ]\r\nSOA result: querySoa EBADRESP support.microsoft.com\r\n\r\n### Expected Results\r\nhostname: support.microsoft.com\r\nCNAME result: [ 'ev.support.microsoft.com.edgekey.net' ]\r\nSOA result: querySoa ENODATA support.microsoft.com\r\n\r\n### Additional information\r\nThis seems to happen for any hostname with a CNAME record.\r\n\r\nAnother example:\r\n\r\nhostname: store.gocomics.com\r\nCNAME result: [ 'gocomicsstore.wpengine.com' ]\r\nSOA result: querySoa EBADRESP store.gocomics.com\r\n\r\nI would expect to get an 'ENODATA' instead of 'EBADRESP', as with the other resolveXXX() calls.\r\n\r\nFor a hostname with an SOA record but no CNAME, you get:\r\n\r\nhostname: microsoft.com\r\nCNAME result: queryCname ENODATA microsoft.com\r\nSOA result: {\"nsname\":\"ns1-205.azure-dns.com\",\"hostmaster\":\"azuredns- \r\n hostmaster.microsoft.com\",\"serial\":1,\"refresh\":3600,\"retry\":300,\"expire\":2419200,\"minttl\":300}\r\n",
        "labels": "confirmed-bug",
        "id": 45021
    },
    {
        "title": "Crash at v8::Object::GetRealNamedPropertyAttributes",
        "body": "* **Version**:\r\nv14.6.0\r\n\r\n* **Platform**:\r\nubuntu 19.04\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nconst vm = require('vm');\r\n\r\nvar handler = {\r\n    getOwnPropertyDescriptor: () => {\r\n        return {};\r\n    }\r\n};\r\n\r\nconst source = `p=6`;\r\n\r\nvar proxy = new Proxy({}, handler);\r\nconst ctx = vm.createContext(proxy);\r\n\r\nscript = new vm.Script(source);\r\nscript.runInContext(ctx);\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nnothing\r\n\r\n### What is the expected behavior?\r\nno error\r\n\r\n### What do you see instead?\r\ncrash\r\n\r\n![image](https://user-images.githubusercontent.com/61380567/89140737-7fcd2300-d57d-11ea-8855-d4adc7878c3d.png)\r\nattachment [core.zip](https://github.com/nodejs/node/files/5013582/core.zip)\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45022
    },
    {
        "title": "fs.rmdirSync stuck in busy-loop on Windows",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.18.3\r\n* **Platform**: Windows 10, 64-bit, Version 10.0.17763.1339\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```\r\nconst fs = require('fs');\r\nconst { tmpdir } = require('os');\r\nconst { join } = require('path');\r\n\r\nfunction rmdirRecursiveSync() {\r\n  const root = fs.mkdtempSync(join(tmpdir(), 'fs-'));\r\n\r\n  const middle = join(root, 'middle');\r\n  fs.mkdirSync(middle);\r\n  fs.mkdirSync(join(middle, 'leaf')); // make `middle` non-empty\r\n  fs.chmodSync(middle, 0);\r\n\r\n  fs.rmdirSync(root, { recursive: true });\r\n}\r\n\r\nrmdirRecursiveSync();\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThe bug reliably reprodices on windows.\r\n\r\n### What is the expected behavior?\r\n\r\nI expect `fs.rmdirSync()` to fail the same way as `fs.rmdir()` does. But it does not.\r\n\r\nLinux produces expected behavior throwing an error:\r\n\r\n```\r\nError: EACCES: permission denied, scandir '/tmp/fs-0wJvqH/middle'\r\n    at readdirSync (fs.js:948:3)\r\n    at _rmdirSync (internal/fs/rimraf.js:242:7)\r\n    at rimrafSync (internal/fs/rimraf.js:191:7)\r\n    at internal/fs/rimraf.js:245:9\r\n    at Array.forEach (<anonymous>)\r\n    at _rmdirSync (internal/fs/rimraf.js:242:45)\r\n    at rimrafSync (internal/fs/rimraf.js:191:7)\r\n    at Object.rmdirSync (fs.js:838:12)\r\n    at rmdirRecursiveSync (/â€¦/rmdirRecursiveSync.js:13:6)\r\n    at Object.<anonymous> (/â€¦/rmdirRecursiveSync.js:16:1) {\r\n  errno: -13,\r\n  syscall: 'scandir',\r\n  code: 'EACCES',\r\n  path: '/tmp/fs-0wJvqH/middle'\r\n}\r\n```\r\n\r\nWindows async `fs.rmdir({recursive:true})` instead of `fs.rmdirSync()` gives expected behavior as well, it passes an error to the callback:\r\n\r\n```\r\n[Error: EPERM: operation not permitted, rmdir 'C:\\â€¦\\Temp\\fs-vJZvJ7\\middle'] {\r\n  errno: -4048,\r\n  code: 'EPERM',\r\n  syscall: 'rmdir',\r\n  path: 'C:\\\\â€¦\\\\Temp\\\\fs-vJZvJ7\\\\middle'\r\n}\r\n```\r\n\r\n### What do you see instead?\r\n\r\nNode process is stuck with 100%-CPU busy-loop.\r\n\r\n### Additional information\r\n\r\n[Process Monitor](https://docs.microsoft.com/en-us/sysinternals/downloads/procmon) suggests a busy-loop while endlessly retrying to delete a file, the log excerpt is pasted below:\r\n\r\n```\r\n\"Time of Day\",\"Operation\",\"Path\",\"Result\",\"Detail\"\r\n...\r\n\"2:02:16.0518106 PM\",\"SetDispositionInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"CANNOT DELETE\",\"Delete: True\"\r\n\"2:02:16.0518663 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0527830 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Data/List Directory, Read Attributes, Synchronize, Disposition: Open, Options: Synchronous IO Non-Alert, Open For Backup, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0528985 PM\",\"QueryDirectory\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"0: ., 1: .., FileInformationClass: FileDirectoryInformation\"\r\n\"2:02:16.0529916 PM\",\"QueryDirectory\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"NO MORE FILES\",\"\"\r\n\"2:02:16.0530399 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0543568 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Attributes, Synchronize, Disposition: Open, Options: Synchronous IO Non-Alert, Open For Backup, Open Reparse Point, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0544702 PM\",\"QueryAllInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"BUFFER OVERFLOW\",\"CreationTime: 7/31/2020 12:40:00 PM, LastAccessTime: 7/31/2020 2:02:14 PM, LastWriteTime: 7/31/2020 12:40:00 PM, ChangeTime: 7/31/2020 12:40:00 PM, FileAttributes: RD, AllocationSize: 0, EndOfFile: 0, NumberOfLinks: 1, DeletePending: False, Directory: True, IndexNumber: 0x100000007cc38, EaSize: 0, Access: Read Attributes, Synchronize, Position: 0, Mode: Synchronous IO Non-Alert, AlignmentRequirement: Word\"\r\n\"2:02:16.0545350 PM\",\"QueryInformationVolume\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"BUFFER OVERFLOW\",\"VolumeCreationTime: 3/19/2019 10:40:48 PM, VolumeSerialNumber: B4A6-FEC6, SupportsObjects: True, VolumeLabel: WinÇ´\"\r\n\"2:02:16.0545884 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0554352 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Attributes, Delete, Synchronize, Disposition: Open, Options: Directory, Synchronous IO Non-Alert, Open For Backup, Open Reparse Point, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0555403 PM\",\"QueryAttributeTagFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Attributes: RD, ReparseTag: 0x0\"\r\n\"2:02:16.0555972 PM\",\"SetDispositionInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"CANNOT DELETE\",\"Delete: True\"\r\n\"2:02:16.0557121 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0565707 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Data/List Directory, Read Attributes, Synchronize, Disposition: Open, Options: Synchronous IO Non-Alert, Open For Backup, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0566833 PM\",\"QueryDirectory\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"0: ., 1: .., FileInformationClass: FileDirectoryInformation\"\r\n\"2:02:16.0568326 PM\",\"QueryDirectory\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"NO MORE FILES\",\"\"\r\n\"2:02:16.0569022 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0572185 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Attributes, Synchronize, Disposition: Open, Options: Synchronous IO Non-Alert, Open For Backup, Open Reparse Point, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0573269 PM\",\"QueryAllInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"BUFFER OVERFLOW\",\"CreationTime: 7/31/2020 12:40:00 PM, LastAccessTime: 7/31/2020 2:02:14 PM, LastWriteTime: 7/31/2020 12:40:00 PM, ChangeTime: 7/31/2020 12:40:00 PM, FileAttributes: RD, AllocationSize: 0, EndOfFile: 0, NumberOfLinks: 1, DeletePending: False, Directory: True, IndexNumber: 0x100000007cc38, EaSize: 0, Access: Read Attributes, Synchronize, Position: 0, Mode: Synchronous IO Non-Alert, AlignmentRequirement: Word\"\r\n\"2:02:16.0573616 PM\",\"QueryInformationVolume\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"BUFFER OVERFLOW\",\"VolumeCreationTime: 3/19/2019 10:40:48 PM, VolumeSerialNumber: B4A6-FEC6, SupportsObjects: True, VolumeLabel: WinÇ´\"\r\n\"2:02:16.0573888 PM\",\"CloseFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"\"\r\n\"2:02:16.0576180 PM\",\"CreateFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Desired Access: Read Attributes, Delete, Synchronize, Disposition: Open, Options: Directory, Synchronous IO Non-Alert, Open For Backup, Open Reparse Point, Attributes: n/a, ShareMode: Read, Write, Delete, AllocationSize: n/a, OpenResult: Opened\"\r\n\"2:02:16.0576756 PM\",\"QueryAttributeTagFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"SUCCESS\",\"Attributes: RD, ReparseTag: 0x0\"\r\n\"2:02:16.0577024 PM\",\"SetDispositionInformationFile\",\"C:\\â€¦\\Temp\\fs-Y3XBJk\\middle\\leaf\",\"CANNOT DELETE\",\"Delete: True\"\r\n...\r\n```",
        "labels": "confirmed-bug",
        "id": 45023
    },
    {
        "title": "AsyncLocalStorage: Cannot read property 'Symbol(kResourceStore)'",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.6.0 (works on v14.5.0)\r\n* **Platform**: Unix\r\n* **Subsystem**: async_hooks\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\nI'm not entirely sure yet, but will continue investigating. Any pointers would be appreciated. \r\n\r\nSadly the code itself is private, but I'll try to extract a reproduction.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nI only see this crash reliably on every test run on one of our services, all the others seem to work fine.\r\n\r\nThe service works on v14.4.0 and v14.5.0, so this seems to be a regression introduced in v14.6.0.\r\n\r\n### What is the expected behavior?\r\n\r\nWorking AsyncLocalStorage.\r\n\r\n### What do you see instead?\r\n\r\nAn exception\r\n\r\n```\r\nTypeError: Cannot read property 'Symbol(kResourceStore)' of undefined\r\n    at AsyncLocalStorage._propagate (async_hooks.js:246:34)\r\n    at AsyncHook.init (async_hooks.js:222:22)\r\n    at emitInitNative (internal/async_hooks.js:198:43)\r\n    at emitInitScript (internal/async_hooks.js:466:3)\r\n    at initAsyncResource (internal/timers.js:155:5)\r\n    at new Timeout (internal/timers.js:188:3)\r\n    at setUnrefTimeout (internal/timers.js:370:17)\r\n    at cache (internal/http.js:27:3)\r\n    at utcDate (internal/http.js:19:18)\r\n    at ServerResponse._storeHeader (_http_outgoing.js:391:26)\r\n    at ServerResponse.writeHead (_http_server.js:313:8)\r\n    at ServerResponse._implicitHeader (_http_server.js:240:8)\r\n    at write_ (_http_outgoing.js:663:9)\r\n    at ServerResponse.end (_http_outgoing.js:776:5)\r\n    at /app/node_modules/@opentelemetry/plugin-http/build/src/http.js:213:87\r\n    at HttpPlugin._safeExecute (/app/node_modules/@opentelemetry/plugin-http/build/src/http.js:303:20)\r\n    at ServerResponse.response.end (/app/node_modules/@opentelemetry/plugin-http/build/src/http.js:213:49)\r\n```\r\n\r\nLikely the result of `executionAsyncResource()` returning `undefined` here:\r\nhttps://github.com/nodejs/node/blob/13c5a1629cd025ba560f34f6d3190b2f38d184d4/lib/async_hooks.js#L219\r\n\r\n### Additional information\r\n\r\nAsyncLocalStorage is used using https://github.com/open-telemetry/opentelemetry-js/tree/v0.10.1 and via the `AsyncLocalStorageContextManager` https://github.com/open-telemetry/opentelemetry-js/blob/v0.10.1/packages/opentelemetry-context-async-hooks/src/AsyncLocalStorageContextManager.ts\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45024
    },
    {
        "title": "Windows fs symlink TypeError on Buffer target value",
        "body": "* **Version**: 14.5.0+\r\n* **Platform**: Windows 10 x64\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\nOn Windows:\r\n\r\n```js\r\nconst fs = require('fs');\r\nfs.symlinkSync(Buffer.from('target'), 'link');\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways happens on Windows since 14.5.0, it may be necessary to enable symlink support on Windows (I'm not 100% sure how that all works). Does not happen on Linux or macOS.\r\n\r\n### What is the expected behavior?\r\n\r\nNo error, and the symlink should be created. [Buffer is listed as a valid target type.](https://nodejs.org/api/fs.html#fs_fs_symlinksync_target_path_type)\r\n\r\n### What do you see instead?\r\n\r\n> TypeError [ERR_INVALID_ARG_TYPE]: The \"path\" argument must be of type string. Received an instance of Buffer\r\n\r\n```\r\ninternal/validators.js:121\r\n    throw new ERR_INVALID_ARG_TYPE(name, 'string', value);\r\n    ^\r\n\r\nTypeError [ERR_INVALID_ARG_TYPE]: The \"path\" argument must be of type string. Received an instance of Buffer\r\n    at validateString (internal/validators.js:121:11)\r\n    at Object.isAbsolute (path.js:353:5)\r\n    at preprocessSymlinkDestination (internal/fs/utils.js:345:18)\r\n    at Object.symlinkSync (fs.js:1118:19)\r\n    at Object.<anonymous> (C:\\Users\\travis\\build\\AlexanderOMara\\issue-node-symlink-buffer-windows\\main.js:5:4)\r\n    at Module._compile (internal/modules/cjs/loader.js:1236:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1257:10)\r\n    at Module.load (internal/modules/cjs/loader.js:1085:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:950:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:60:12) {\r\n  code: 'ERR_INVALID_ARG_TYPE'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\nI created [a test repo](https://github.com/AlexanderOMara/issue-node-symlink-buffer-windows) which [is tested via Travis CI](https://travis-ci.com/github/AlexanderOMara/issue-node-symlink-buffer-windows/builds/177173620).\r\n\r\nOn a side-note, the `path` argument can be a Buffer, it's just the `target` argument with the issue.\r\n",
        "labels": "confirmed-bug",
        "id": 45025
    },
    {
        "title": "stream: non-readable Duplex async construct race condition",
        "body": "@nodejs/streams @ronag\r\n\r\nTry..\r\n\r\n```js\r\nconst { Duplex } = require('stream');\r\n\r\nclass M extends Duplex {\r\n  constructor() {\r\n    super({ readable: false });\r\n  }\r\n\r\n  _construct(callback) {\r\n    setTimeout(() => {\r\n      console.log(1);\r\n      callback();\r\n    }, 2000);\r\n  }\r\n\r\n  _write(chunk, encoding, callback) {\r\n    console.log(chunk.toString());\r\n    callback();\r\n  }\r\n\r\n  _read() {\r\n    this.push(null);\r\n  }\r\n}\r\n\r\nconst m = new M();\r\nm.resume();\r\nm.end('foo');\r\nm.on('close', () => console.log('destroyed'));\r\n```\r\n\r\nOutputs:\r\n\r\n```\r\nfoo\r\ndestroyed\r\n1\r\n```\r\n\r\nNote that the auto-destruction of the `Duplex` does not appropriately wait for the completion of the async `_construct()`. Changing the construction options to `{ readable: true }` causes the code to work as expected:\r\n\r\n```js\r\nconst { Duplex } = require('stream');\r\n\r\nclass M extends Duplex {\r\n  constructor() {\r\n    super({ readable: true});\r\n  }\r\n\r\n  _construct(callback) {\r\n    setTimeout(() => {\r\n      console.log(1);\r\n      callback();\r\n    }, 2000);\r\n  }\r\n\r\n  _write(chunk, encoding, callback) {\r\n    console.log(chunk.toString());\r\n    callback();\r\n  }\r\n\r\n  _read() {\r\n    this.push(null);\r\n  }\r\n}\r\n\r\nconst m = new M();\r\nm.resume();\r\nm.end('foo');\r\nm.on('close', () => console.log('destroyed'));\r\n```\r\n\r\nOutputs:\r\n\r\n```\r\nfoo\r\n1\r\ndestroyed\r\n```",
        "labels": "confirmed-bug",
        "id": 45026
    },
    {
        "title": "AsyncLocalStorage does not work with http.Agent",
        "body": "* **Version**: 14.5.0\r\n* **Platform**: macos\r\n* **Subsystem**: async_hooks\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\n'use strict';\r\n\r\nconst http = require('http');\r\nconst { AsyncLocalStorage } = require('async_hooks');\r\n\r\nconst session = new AsyncLocalStorage();\r\n\r\nconst agent = new http.Agent({\r\n  maxSockets: 1\r\n});\r\n\r\nconst get = (path, callback) => {\r\n  http.request({\r\n    agent,\r\n    host: 'example.com',\r\n\r\n    method: 'GET',\r\n    path,\r\n  }, callback).end();\r\n};\r\n\r\nlet id = 0;\r\nconst server = http.createServer((req, res) => {\r\n  session.run(id++, () => {\r\n    console.error('new req', session.getStore());\r\n    get('/', (remote) => {\r\n      console.error('remote response', session.getStore());\r\n      remote.pipe(res);\r\n    });\r\n  });\r\n}).listen(0, () => {\r\n  const { port } = server.address();\r\n  http.request({ port }).end();\r\n  http.request({ port }).end();\r\n});\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways. No conditions.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nI expect this code to print:\r\n```\r\nnew req 0\r\nnew req 1\r\nremote response 0\r\nremote response 1\r\n```\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n```\r\nnew req 0\r\nnew req 1\r\nremote response 0\r\nremote response 0\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nThis is very much expected behavior of CLS storage. Any sort of pooling would result in similar issues. What's concerning is that it can happen with use of an existing core primitive (`http.Agent`). In fact, use of any agent with `maxSockets !== Infinity` or `keepAlive` set to `true` would result in similar behavior.\r\n\r\nThis behavior can be documented, but I'd imagine that such documentation would look like an incompatibility within Node.js core. Given that whole `async_hooks` module experimental - should we consider removing `AsyncLocalStorage` instead?\r\n\r\ncc @nodejs/collaborators ",
        "labels": "confirmed-bug",
        "id": 45027
    },
    {
        "title": "fsPromises.truncate doesn't close fd.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.18.1\r\n* **Platform**: Linux 5.4.0-37-generic #41-Ubuntu SMP x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\nfsPromises.truncate(path) will result in a warning a few seconds later: `(node:1387179) Warning: Closing file descriptor 22 on garbage collection` - Using the callback truncate `await new Promise((res, rej) => { fs.truncate(file, (err, ret) => { if(err) rej(err); else res(ret) }) })` works fine without such warning.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEvery time.\r\n\r\n### What is the expected behavior?\r\n\r\nNot having this warning.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45028
    },
    {
        "title": "DEP0097 warning triggered in REPL.",
        "body": "* **Version**: v15.0.0-pre\r\n* **Platform**: Linux 4.15.0-108-generic #109-Ubuntu SMP Fri Jun 19 11:33:10 UTC 2020 x86_64 \r\n* **Subsystem**: REPL\r\n\r\n### What steps will reproduce the bug?\r\n1. Run Node REPL.\r\n2. Choose your favorite global object.\r\n3. Type it into the REPL with the dot-style property accessor like so: `<global object>.`\r\n4. Hit tab.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways.\r\n\r\n### What is the expected behavior?\r\nDeprecation warning is not shown.\r\n\r\n### What do you see instead?\r\nDeprecation warning is shown.\r\n\r\n```\r\n./node --trace-deprecation\r\nWelcome to Node.js v15.0.0-pre.\r\nType \".help\" for more information.\r\n> Array. /* hit tab */\r\nArray.__defineGetter__      Array.__defineSetter__      Array.__lookupGetter__      Array.__lookupSetter__      Array.__proto__             Array.hasOwnProperty        Array.isPrototypeOf\r\nArray.propertyIsEnumerable  Array.toLocaleString        Array.valueOf\r\n\r\nArray.apply                 Array.arguments             Array.bind                  Array.call                  Array.caller                Array.constructor           Array.toString\r\n\r\nArray.from                  Array.isArray               Array.length                Array.name                  Array.of                    Array.prototype\r\n\r\n> Array.(node:13081) [DEP0097] DeprecationWarning: Using a domain property in MakeCallback is deprecated. Use the async_context variant of MakeCallback or the AsyncResource class instead.\r\n    at emitMakeCallbackDeprecation (domain.js:123:13)\r\n    at Connection.topLevelDomainCallback (domain.js:134:5)\r\n    at Connection.callbackTrampoline (internal/async_hooks.js:121:14)\r\n    at Session.post (inspector.js:118:28)\r\n    at internal/repl/utils.js:291:15\r\n    at sendInspectorCommand (internal/util/inspector.js:16:12)\r\n    at getInputPreview (internal/repl/utils.js:290:5)\r\n    at showPreview (internal/repl/utils.js:443:5)\r\n    at REPLServer.repl._refreshLine (internal/repl/utils.js:462:5)\r\n    at readline.js:567:10\r\n```\r\n\r\n### Additional information\r\nThis warning is triggered in several other ways in REPL. For example certain function calls can trigger it:\r\n```\r\n> child_process.execFile('vim', [], {timeout: 1});\r\n...\r\n> (node:14593) [DEP0097] DeprecationWarning: Using a domain property in MakeCallback is deprecated. Use the async_context variant of MakeCallback or the AsyncResource class instead.\r\n    at emitMakeCallbackDeprecation (domain.js:123:13)\r\n    at Pipe.topLevelDomainCallback (domain.js:134:5)\r\n    at Pipe.callbackTrampoline (internal/async_hooks.js:121:14)\r\n```\r\nIt makes me believe there is a common point for whole REPL that triggers this warning. I am eager to investigate further if provided with some clues (especially on how to debug asynchronous handling in the C++ part of node).",
        "labels": "confirmed-bug",
        "id": 45029
    },
    {
        "title": "VM aborts when error thrown when in property setter",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.14.1\r\n* **Platform**: Recreated on Catalina 10.15.4 and Windows 10 x64\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```js\r\nconst repl = require('repl');\r\nconst r = repl.start('> ');\r\nObject.defineProperty(r.context, 'db', {\r\n  set: (val) => {\r\n    throw new Error('test error');\r\n  }\r\n});\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEvery time\r\n\r\n### What is the expected behavior?\r\n\r\nThe error that is thrown should be reported in the default eval function, and it should be catchable.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n```\r\nFATAL ERROR: v8::FromJust Maybe value is Nothing.\r\n 1: 0x10007f231 node::Abort() [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 2: 0x10007f3b5 node::OnFatalError(char const*, char const*) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 3: 0x100178f00 v8::V8::FromJustIsNothing() [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 4: 0x100399618 v8::internal::PropertyCallbackArguments::CallNamedSetter(v8::internal::Handle<v8::internal::InterceptorInfo>, v8::internal::Handle<v8::internal::Name>, v8::internal::Handle<v8::internal::Object>) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 5: 0x1004aaa32 v8::internal::(anonymous namespace)::SetPropertyWithInterceptorInternal(v8::internal::LookupIterator*, v8::internal::Handle<v8::internal::InterceptorInfo>, v8::Maybe<v8::internal::ShouldThrow>, v8::internal::Handle<v8::internal::Object>) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 6: 0x1004ef1ab v8::internal::Object::SetPropertyInternal(v8::internal::LookupIterator*, v8::internal::Handle<v8::internal::Object>, v8::Maybe<v8::internal::ShouldThrow>, v8::internal::StoreOrigin, bool*) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 7: 0x1004eefe8 v8::internal::Object::SetProperty(v8::internal::LookupIterator*, v8::internal::Handle<v8::internal::Object>, v8::internal::StoreOrigin, v8::Maybe<v8::internal::ShouldThrow>) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 8: 0x10038ce16 v8::internal::StoreIC::Store(v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Name>, v8::internal::Handle<v8::internal::Object>, v8::internal::StoreOrigin) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n 9: 0x10038c725 v8::internal::StoreGlobalIC::Store(v8::internal::Handle<v8::internal::Name>, v8::internal::Handle<v8::internal::Object>) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n10: 0x100392436 v8::internal::Runtime_StoreGlobalICNoFeedback_Miss(int, unsigned long*, v8::internal::Isolate*) [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n11: 0x1009311f9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_NoBuiltinExit [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\n12: 0x100985e16 Builtins_StaGlobalHandler [/Users/anna/.nvm/versions/node/v12.14.1/bin/node]\r\nAbort trap: 6\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\nWe need to be able to throw an error if a user tries to assign a context value to a disallowed type.\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45030
    },
    {
        "title": "http.IncomingMessage doesn't fire callback on 'timeout'",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:14.3.0\r\n* **Platform**:\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\nSource code from `lib/_http_incoming.js`:\r\n```js\r\nIncomingMessage.prototype.setTimeout = function setTimeout(msecs, callback) {\r\n  if (callback)\r\n    this.on('timeout', callback);\r\n  this.socket.setTimeout(msecs);\r\n  return this;\r\n};\r\n```\r\n\r\nIncomingMessage doesn't emit 'timeout' so callback will never be fired\r\n### How often does it reproduce? Is there a required condition?\r\n\r\n### What is the expected behavior?\r\n```js\r\nIncomingMessage.prototype.setTimeout = function setTimeout(msecs, callback) {\r\n   this.socket.setTimeout(msecs,callback);\r\n  return this;\r\n};\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nEDIT(trivikr): put code in a code block ",
        "labels": "confirmed-bug",
        "id": 45031
    },
    {
        "title": "stream: end(callback) does not propagate write after end to callback",
        "body": "```js\r\nw.end();\r\nw.end('asd', (err) => {\r\n  assert.strictEqual(err.code, 'ERR_STREAM_WRITE_AFTER_END'); // Fails\r\n});\r\n```",
        "labels": "confirmed-bug",
        "id": 45032
    },
    {
        "title": "OutgoingMessage doesn't always emit close",
        "body": "Following test fails:\r\n\r\n```js\r\n  const msg = new OutgoingMessage();\r\n  assert.strictEqual(msg.destroyed, false);\r\n  msg.destroy();\r\n  assert.strictEqual(msg.destroyed, true);\r\n  let callbackCalled = false;\r\n  msg.write('asd', common.mustCall((err) => {\r\n    assert.strictEqual(err.code, 'ERR_STREAM_DESTROYED');\r\n    callbackCalled = true;\r\n  }));\r\n  msg.on('error', common.mustCall((err) => {\r\n    assert.strictEqual(err.code, 'ERR_STREAM_DESTROYED');\r\n    assert.strictEqual(callbackCalled, true);\r\n  }));\r\n  msg.on('close', common.mustCall(() => {\r\n    // Won't call\r\n    msg.end();\r\n  }));\r\n```",
        "labels": "confirmed-bug",
        "id": 45033
    },
    {
        "title": "Crash in module_wrap.cc with malformed loader",
        "body": "loader.mjs:\r\n\r\n```js\r\nexport function transformSource() {\r\n  return {\r\n    source: {\r\n      boom: true,\r\n    },\r\n  };\r\n}\r\n```\r\n\r\ntest.mjs:\r\n\r\n```js\r\nimport fs from 'fs';\r\n```\r\n\r\n```\r\n> node --loader ./loader.mjs test.mjs\r\nC:\\Program Files\\PowerShell\\7\\pwsh.exe[28872]: c:\\ws\\src\\module_wrap.cc:131: Assertion `args[2]->IsString()' failed.\r\n```",
        "labels": "confirmed-bug",
        "id": 45034
    },
    {
        "title": "[ES modules] package.json located in root path can't be resolved when checking `type` field",
        "body": "* **Version**: `v14.2.0`\r\n* **Platform**: `Linux c89b7c439bd7 4.19.76-linuxkit #1 SMP Fri Apr 3 15:53:26 UTC 2020 x86_64 Linux`\r\n\r\n### What steps will reproduce the bug?\r\n\r\nCreate docker image that generates `package.json` and `index.js` in *root of filesystem*:\r\n```docker\r\nFROM node:14-alpine\r\n\r\nRUN echo '{ \"type\": \"module\" }' > package.json\r\nRUN echo 'import fs from \"fs\";' > index.js\r\n\r\nCMD [\"node\", \"index.js\"]\r\n```\r\nBuild and run the container:\r\n```bash\r\ndocker build -t app .\r\ndocker run --rm app\r\n```\r\nOutput:\r\n```\r\n(node:1) Warning: To load an ES module, set \"type\": \"module\" in the package.json or use the .mjs extension.\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\n/index.js:1\r\nimport fs from \"fs\";\r\n^^^^^^\r\n\r\nSyntaxError: Cannot use import statement outside a module\r\n    at Object.compileFunction (vm.js:344:18)\r\n    at wrapSafe (internal/modules/cjs/loader.js:1106:15)\r\n    at Module._compile (internal/modules/cjs/loader.js:1140:27)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1196:10)\r\n    at Module.load (internal/modules/cjs/loader.js:1040:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:929:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12)\r\n    at internal/main/run_main_module.js:17:47\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways.\r\n\r\n### What is the expected behavior?\r\n`index.js` should be loaded as es module because the nearest `package.json` has `\"type\": \"module\"` field.\r\n\r\n### What do you see instead?\r\n`index.js` is being loaded as commonjs.\r\n\r\n### Additional information\r\nIf `package.json` and `index.js` are generated in some subdirectory - everything works. You can check it with the following image:\r\n```docker\r\nFROM node:14-alpine\r\n\r\n# add workdir to generate files in /app not in /\r\nWORKDIR app \r\n\r\nRUN echo '{ \"type\": \"module\" }' > package.json\r\nRUN echo 'import fs from \"fs\";' > index.js\r\n\r\nCMD [\"node\", \"index.js\"]\r\n```\r\n\r\nThe reason of such behavior is [this line](https://github.com/nodejs/node/blob/c1ee70ec168eedc3f9d193473d141b9c03e2df88/lib/internal/modules/cjs/loader.js#L289):\r\n```\r\n(separatorIndex = checkPath.lastIndexOf(path.sep)) > rootSeparatorIndex\r\n```\r\nWhen `checkPath = '/index.js'`, both `separatorIndex` and `rootSeparatorIndex` are equals to `0` and condition does not pass.\r\n",
        "labels": "confirmed-bug",
        "id": 45035
    },
    {
        "title": "Console output for class instance __proto__ seems wrong",
        "body": "Consider following code\r\n```\r\nclass A {\r\n    getA() { return 0; }\r\n    constructor() {}\r\n}\r\nclass B extends A {\r\n    getB() { return 0; }\r\n    constructor() { super(); }\r\n}\r\nconsole.log((new A()));\r\nconsole.log((new A()).__proto__);\r\nconsole.log((new A()).__proto__ instanceof A);\r\nconsole.log((new A()).__proto__ instanceof Object);\r\nconsole.log((new B()));\r\nconsole.log((new B()).__proto__);\r\nconsole.log((new B()).__proto__ instanceof B);\r\nconsole.log((new B()).__proto__ instanceof A);\r\n```\r\n\r\nNode 14 produces:\r\n\r\n```\r\nA {}\r\nA {}\r\nfalse\r\ntrue\r\nB {}\r\nB {}\r\nfalse\r\ntrue\r\n```\r\n\r\nThis is wrong since `(new B()).__proto__` is an instance of `A`. I guess the confusing part is that `(new B()).__proto__.constructor` is `class B` (which is because of https://tc39.es/ecma262/#sec-makeconstructor)\r\n\r\nFor reference, Chrome DevTools produces:\r\n\r\n```\r\nAÂ {}\r\n{constructor: Æ’, getA: Æ’}\r\nfalse\r\ntrue\r\nBÂ {}\r\nAÂ {constructor: Æ’, getB: Æ’}\r\nfalse\r\ntrue\r\n```",
        "labels": "confirmed-bug",
        "id": 45036
    },
    {
        "title": "Duplex stream is not returning whether it is in object mode correctly",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.16.0\r\n* **Platform**: MacOS\r\n* **Subsystem**: Darwin ... 19.4.0 Darwin Kernel Version 19.4.0: Wed Mar  4 22:28:40 PST 2020; root:xnu-6153.101.6~15/RELEASE_X86_64 x86_64\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\n// open the node repl\r\nx = new stream.Duplex({writableObjectMode: true})\r\nx.writableObjectMode // undefined - should be true\r\n```\r\nbut the mode is set correctly:\r\n```js\r\n...\r\n_writableState: WritableState {\r\n    objectMode: true,\r\n   ...\r\n```\r\n\r\nit does work on a Writable stream:\r\n\r\n```js\r\nx = new stream.Writable({objectMode: true})\r\nx.writableObjectMode // true\r\n```\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\n100%\r\n\r\n### What is the expected behavior?\r\n\r\nReturn the actual value of whether the stream is in object mode.",
        "labels": "confirmed-bug",
        "id": 45037
    },
    {
        "title": "fs readdir with buffer and file types problem",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.16.3\r\n* **Platform**: linux64\r\n* **Subsystem**: gentoo\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\nreading directory with files names using buffer as path does not work.\r\n```\r\nconst fs = require('fs');\r\nfs.readdir( Buffer.from( \".\"),{withFileTypes:true,encoding:\"buffer\"},(e,d)=>console.log(\"dir\",d));\r\n```\r\nIt works correct in version 12.14.0 but after upgrade it stopped to work.\r\nusing it without files types works:\r\n// fs.readdir( Buffer.from( \".\"),{withFileTypes:false,encoding:\"buffer\"},(e,d)=>console.log(\"dir\",d));\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nevery time\r\n\r\n### What is the expected behavior?\r\nget directory entries with file types i.e. array of Dirent objects\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nerror message:\r\n```\r\nUncaught:\r\nTypeError [ERR_INVALID_ARG_TYPE]: The \"path\" argument must be of type string. Received an instance of Buffer\r\n    at validateString (internal/validators.js:117:11)\r\n    at Object.join (path.js:1039:7)\r\n    at getDirents (internal/fs/utils.js:159:39)\r\n    at FSReqCallback.req.oncomplete (fs.js:858:7) {\r\n  code: 'ERR_INVALID_ARG_TYPE'\r\n}\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\nThis bug is degradation because it doesn't exists in version 12.14.0 and present in versions 12.16.1 and 12.16.3 at least. \r\nI use buffer instead of string because working with my old archives with non utf-8 names.\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45038
    },
    {
        "title": "Node v12.16.2 memory issues after upgrade from v8 (<--- Last few GCs --->)",
        "body": "This issue is continuation of [#32737](https://github.com/nodejs/node/issues/32737)\r\n\r\n**Version:**\r\nv12.16.2 (but v12.13 on production)\r\n\r\n**Platform:**\r\nDarwin Kernel Version 19.4.0: Wed Mar  4 22:28:40 PST 2020; root:xnu-6153.101.6~15/RELEASE_X86_64 x86_64\r\n(but docker with node:12.13.0-alpine on production)\r\n\r\n**Subsystem:**\r\n? runtime, heap, garbage collection\r\n\r\n**Description:**\r\nAs in previous ticket: \"We recently upgrade our production servers with docker containers with node v8 to docker containers with node v12.10 (node:12.13.0-alpine). At first all seems fine, but then we started noticing pod restarts by Kubernetes being OOM Killed. Since the upgrade, memory usage seems to increase over time sometimes in steep inclines until reaching ~500MB at which time they are killed by Kuberenetes.\"\r\n\r\nWith the same code base and dependencies, when switching between 3 versions of node (8.17.0, 10.20.1, 12.16.2) different memory usage observed. With version 12.16.2 node service crashes with logs:\r\n\r\n```\r\nTESTED_SERVICE.GetData took 1691 ms (queue-time = 409 ms, process-time = 1282 ms, processing-count = 100, queue-size = 124)\"}\r\n{\"@timestamp\":\"2020-05-06T10:49:42.337Z\",\"level\":\"debug\",\"message\":\"GRPC server call TESTED_SERVICE.GetData took 1724 ms (queue-time = 431 ms, process-time = 1293 ms, processing-count = 100, queue-size = 123)\"}\r\n\r\n<--- Last few GCs --->\r\ncr[35106:0x102aac000] 10407728 ms: Mark-sweep 543.8 (546.1) -> 543.7 (546.1) MB, 158.9 / 0.0 ms  (+ 2.9 ms in 2 steps since start of marking, biggest step 2.9 ms, walltime since start of marking 163 ms) (average mu = 0.102, current mu = 0.010) finalize incr[35106:0x102aac000] 10407914 ms: Mark-sweep 543.8 (546.1) -> 543.7 (546.1) MB, 177.3 / 0.0 ms  (+ 5.1 ms in 2 steps since start of marking, biggest step 5.0 ms, walltime since start of marking 186 ms) (average mu = 0.058, current mu = 0.018) finalize incr\r\n\r\n<--- JS stacktrace --->\r\n\r\n==== JS stack trace =========================================\r\n\r\n    0: ExitFrame [pc: 0x10097d5b9]\r\n    1: StubFrame [pc: 0x1009e8f05]\r\nSecurity context: 0x1fc1cc0c08d1 <JSObject>\r\n    2: new constructor(aka Op) [0x1fc1b415e939] [/Users/robertdittmann/Documents/Tutorials/node-memory-test/node_modules/protobufjs/src/writer.js:21] [bytecode=0x1fc1cf4764f1 offset=0](this=0x1fc1ca0d2b61 <Op map = 0x1fc11cbd1199>,0x1fc1b415e979 <JSFunction noop (sfi = 0x1fc1712aee81)>,0,0)\r\n    3: ConstructFrame [pc: 0x1008fe7...\r\n\r\nFATAL ERROR: Ineffective mark-compacts near heap limit Allocation failed - JavaScript heap out of memory\r\n 1: 0x1010248bd node::Abort() (.cold.1) [/usr/local/bin/node]\r\n 2: 0x100084c4d node::FatalError(char const*, char const*) [/usr/local/bin/node]\r\n 3: 0x100084d8e node::OnFatalError(char const*, char const*) [/usr/local/bin/node]\r\n 4: 0x100186477 v8::Utils::ReportOOMFailure(v8::internal::Isolate*, char const*, bool) [/usr/local/bin/node]\r\n 5: 0x100186417 v8::internal::V8::FatalProcessOutOfMemory(v8::internal::Isolate*, char const*, bool) [/usr/local/bin/node]\r\n 6: 0x1003141c5 v8::internal::Heap::FatalProcessOutOfMemory(char const*) [/usr/local/bin/node]\r\n 7: 0x100315a3a v8::internal::Heap::RecomputeLimits(v8::internal::GarbageCollector) [/usr/local/bin/node]\r\n 8: 0x10031246c v8::internal::Heap::PerformGarbageCollection(v8::internal::GarbageCollector, v8::GCCallbackFlags) [/usr/local/bin/node]\r\n 9: 0x10031026e v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) [/usr/local/bin/node]\r\n10: 0x10030f2b1 v8::internal::Heap::HandleGCRequest() [/usr/local/bin/node]\r\n11: 0x1002d4551 v8::internal::StackGuard::HandleInterrupts() [/usr/local/bin/node]\r\n12: 0x10063e79c v8::internal::Runtime_StackGuard(int, unsigned long*, v8::internal::Isolate*) [/usr/local/bin/node]\r\n13: 0x10097d5b9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_NoBuiltinExit [/usr/local/bin/node]\r\n14: 0x1009e8f05 Builtins_StackCheckHandler [/usr/local/bin/node]\r\n[1]    35106 abort      node --max-old-space-size=384 app.js\r\n```\r\n\r\n**What steps will reproduce the bug?**\r\n\r\n1. Download prepared sample \"slim version\" of service code (without other parts like Redis, DynamoDB, Prometheus, Zippkin, Routes etc.): [node-sample](https://github.com/RobertDittmann/node-memory-test)\r\n2. Download prepared sample client: [java-sample](https://github.com/RobertDittmann/nodememorytest)\r\n3. Change node version on 12.16.2\r\n4. For node service (rebuild and run):\r\n```\r\nrm -rf node-modules\r\nnpm install\r\nnode --max-old-space-size=384 app.js\r\n```\r\n5. For java service (rebuild and run):\r\n```\r\nmvn clean install\r\nmvn spring-boot:run\r\n```\r\n6. After around 3-4 hours node service should throws above exception. Node service in its directory will fill with data csv file called **memory_usage.csv** (it contains process memory in MB per 1 minute).\r\n\r\nSame situation appears on production environment but it takes few days to happen. \r\n\r\nBelow comparison of node vesions:\r\n\r\n- node v12.16.2 started with command: node --max-old-space-size=384 app.js (crashed - results as above logs)\r\n ![image](https://user-images.githubusercontent.com/11576433/81183989-23735b00-8fb0-11ea-95e9-10124ac1b99c.png)\r\n\r\n- node v12.16.2 started with command: node app.js \r\n![image](https://user-images.githubusercontent.com/11576433/81184343-97156800-8fb0-11ea-8f3e-00336a6f5a1c.png)\r\n\r\n- node v10.20.1 started with command: node app.js (it shows also memory when load stopped)\r\n![image](https://user-images.githubusercontent.com/11576433/81184587-d8a61300-8fb0-11ea-820e-2626c71c3145.png)\r\n\r\n- node v8.17.0 started with command: node app.js \r\n![image](https://user-images.githubusercontent.com/11576433/81184779-186cfa80-8fb1-11ea-882a-ef16d9f03ed9.png)\r\n\r\n\r\n**How often does it reproduce? Is there a required condition?**\r\nAlways. \r\n\r\n**What is the expected behavior?**\r\nA stable heapUsed like in v8.17 and no spikes in memory usage causing OOM kills/ GCs issues.\r\n\r\n**What do you see instead?**\r\nMemory increase and GCs issues.\r\n\r\n**Additional information**\r\nI am looking for solutions. Seems that used last years services cannot be used with LTS v12 on production. \r\n\r\nPlease let me know how I can help further,\r\n\r\nKind regards,\r\nRobert\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45039
    },
    {
        "title": "Segfault with unref on a worker with ArrayBuffer in `transferList`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v14.2.0\r\n* **Platform**: mac OS 10.13.6\r\n\r\n\r\n### What steps will reproduce the bug?\r\nWhen communicating a Uint8 Array Buffer from a worker to the parent process with `postMessage`, which is included in the `transferList` argument and then calling `unref` on the worker, I get a Segfault: `'node index.js' terminated by signal SIGSEGV (Address boundary error)`.\r\n\r\n`index.js`\r\n```js\r\nconst path = require('path')\r\nconst { Worker } = require('worker_threads')\r\n\r\nconst worker = new Worker(path.join(__dirname, 'worker.js'))\r\nworker.postMessage({})\r\nworker.on('message', (message) => {\r\n  const hash = Buffer.from(message.value).toString('hex')\r\n  console.log(hash)\r\n  worker.unref()\r\n})\r\n```\r\n\r\n`worker.js`\r\n```js\r\nconst fs = require('fs')\r\nconst crypto = require('crypto')\r\nconst { parentPort } = require('worker_threads')\r\n\r\nparentPort.on('message', (message) => {\r\n  const hasher = crypto.createHash('sha256')\r\n  fs.createReadStream('example.txt')\r\n    .pipe(hasher)\r\n    .on('finish', () => {\r\n      const { buffer } = hasher.read()\r\n      parentPort.postMessage({ value: buffer }, [buffer])\r\n    })\r\n})\r\n```\r\n\r\n\r\nReproduction here: https://github.com/timsuchanek/segfault-node-14\r\n\r\n### lldb backtrace\r\n```\r\nProcess 40610 stopped\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x20)\r\n    frame #0: 0x000000010007b095 node`node::Buffer::New(node::Environment*, char*, unsigned long, bool)::$_2::__invoke(void*, unsigned long, void*) + 21\r\nnode`node::Buffer::New(node::Environment*, char*, unsigned long, bool)::$_2::__invoke(void*, unsigned long, void*):\r\n->  0x10007b095 <+21>: movq   0x20(%rcx), %rcx\r\n    0x10007b099 <+25>: movq   %rax, %rdi\r\n    0x10007b09c <+28>: popq   %rbp\r\n    0x10007b09d <+29>: jmpq   *%rcx\r\nTarget 0: (node) stopped.\r\n```\r\n\r\n\r\nThis works fine in Node 13 or lower and it seems, that this bug was introduced in Node 14.",
        "labels": "confirmed-bug",
        "id": 45040
    },
    {
        "title": "repl: Extra `/` on completion after `require`",
        "body": "* **Version**: v14.1.0\r\n* **Platform**: Linux lt2.cfware.com 5.5.10-100.fc30.x86_64 #1 SMP Wed Mar 18 14:34:46 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: REPL\r\n\r\n### What steps will reproduce the bug?\r\n\r\nInstall a package that has sub-directories (lets say `nano` for an example).  Run repl with `node` and type `require('nano` without the closing quote:\r\n![Screenshot from 2020-05-04 14-29-04](https://user-images.githubusercontent.com/903597/81000158-dd819000-8e13-11ea-8e4b-6bca9b6cb305.png)\r\n\r\nNote the position of the cursor and the suggested `/`, this is valid.  Typing `')` to close the `require` call does not remove the suggested `/`.  At this point pressing keyboard left, end or tab causes an additional `/` to be displayed.\r\n\r\nTyping `require('nano/')` then pressing tab causes `nano/lib/` and `nano/package` to be suggested.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nEvery time.\r\n\r\n### What is the expected behavior?\r\nCompletion of the string passed to `require()` should end as soon as the closing `'` is typed.\r\n\r\n### What do you see instead?\r\n\r\n![Screenshot from 2020-05-04 14-40-51](https://user-images.githubusercontent.com/903597/81001197-6220de00-8e15-11ea-83df-7bd3abd5d388.png)\r\n\r\n### Additional information\r\nSorry for using screen-captures it's difficult to show what I'm seeing otherwise.",
        "labels": "confirmed-bug",
        "id": 45041
    },
    {
        "title": "Segfault importing ESM module twice",
        "body": "@nodejs/modules...\r\n\r\n```\r\nWelcome to Node.js v14.1.0.\r\nType \".help\" for more information.\r\n> import('piscina')\r\nPromise { <pending> }\r\n> import('piscina').then(console.log)\r\nPromise { <pending> }\r\n> [Module] {\r\n  Piscina: [Function: Piscina],\r\n  default: [Function: Piscina],\r\n  isWorkerThread: false,\r\n  version: '1.2.0',\r\n  workerData: undefined\r\n}\r\n> import('piscina').then(console.log)\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nSpotted this while working on a module. Happens regularly for me with any ESM. Calling import twice on the same module leads to a segfault. Happens regularly but may take a few calls to import to trigger... lldb backtrace shows:\r\n\r\n```\r\n* thread #1, name = 'node', stop reason = signal SIGSEGV: invalid address (fault address: 0x10)\r\n  * frame #0: 0x0000000000978050 node`node::loader::ImportModuleDynamically(v8::Local<v8::Context>, v8::Local<v8::ScriptOrModule>, v8::Local<v8::String>) (.cold.291)\r\n    frame #1: 0x000000000431adc0\r\n    frame #2: 0x0000000000ce6a58 node`v8::internal::Isolate::RunHostImportModuleDynamicallyCallback(v8::internal::Handle<v8::internal::Script>, v8::internal::Handle<v8::internal::Object>) + 120\r\n    frame #3: 0x000000000105530f node`v8::internal::Runtime_DynamicImportCall(int, unsigned long*, v8::internal::Isolate*) + 175\r\n```",
        "labels": "confirmed-bug",
        "id": 45042
    },
    {
        "title": "`node --loader` treats entrypoint as ESM when should be loaded as CJS",
        "body": "* **Version**: 14.1.0\r\n* **Platform**: Ubuntu 19\r\n* **Subsystem**: entrypoint handling\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```\r\nmkdir empty-dir\r\ncd empty-dir\r\necho '{}' > package.json\r\ntouch entrypoint\r\ntouch hooks.mjs\r\nnode ./entrypoint # <-- no error; no output; exit code 0\r\nnode --loader ./hooks.mjs ./entrypoint # <-- error that \"\" is not a recognized file extension by the default ESM loader\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\n`./entrypoint` is executed as a CommonJS module whether or not `--loader` is passed.\r\n\r\n### What do you see instead?\r\n\r\nWhen --loader is passed, node always tries to load entrypoint scripts as ESM, ignoring that `package.json` wants the file to be treated as CJS.  This does not happen when --loader is omitted, suggesting that this behavior is a bug.\r\n\r\n```\r\n\"\" is not a recognized file extension by the default ESM loader\r\n(node:26067) ExperimentalWarning: --experimental-loader is an experimental feature. This feature could change at any time\r\n(Use `node --trace-warnings ...` to show where the warning was created)\r\ninternal/modules/run_main.js:54\r\n    internalBinding('errors').triggerUncaughtException(\r\n                              ^\r\n\r\nTypeError [ERR_UNKNOWN_FILE_EXTENSION]: Unknown file extension \"\" for /d/Personal-dev/@TypeStrong/ts-node-repros/empty-dir/entrypoint\r\n    at Loader.defaultGetFormat [as _getFormat] (internal/modules/esm/get_format.js:65:15)\r\n    at Loader.getFormat (internal/modules/esm/loader.js:113:42)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:244:31)\r\n    at async Loader.import (internal/modules/esm/loader.js:178:17) {\r\n  code: 'ERR_UNKNOWN_FILE_EXTENSION'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\n#33223 \r\n",
        "labels": "confirmed-bug",
        "id": 45043
    },
    {
        "title": "[BUG] Segfault on combo of global ctors, ostream, wasi",
        "body": "This is an issue for node's WASI integration with emscripten.\r\n\r\nboth global ctors need to be called, and ostream being used in the WASM standalone mode (emsdk latest upstream). \r\n\r\nI have a case where I need to call the global static initializers(need to call _start before running other functions), but also have ostream in the code. \r\n\r\nWhat was happening is that when ostream is being used in the code and it somehow triggers certain things to be added to global ctors, and then calling global ctors resulted in a segfault. So far I only get this error on node14, and I am not sure if it is related to the use of WASI.\r\n\r\n### C++\r\n```c++\r\n#include <emscripten.h>\r\n#include <vector>\r\n#include <sstream>\r\n\r\n// static intializer, need to call _start\r\nstatic std::vector<int> x = {1, 2, 3};\r\n\r\nextern \"C\" {\r\nEMSCRIPTEN_KEEPALIVE\r\nint GetX(int i) {\r\n   // use of ostream somehow makes _start fail.\r\n    std::ostringstream os;\r\n    os << \"x\";\r\n    return x[i];\r\n}\r\n}\r\n```\r\n```Makefile\r\nwasm_test.wasm: wasm_test.cc\r\n\t@mkdir -p $(@D)\r\n\temcc -O3 -std=c++11 -o $@ $<\r\n```\r\n\r\n### NodeJS\r\n\r\n```js\r\nconst { WASI } = require('wasi');\r\n\r\nconst wasi = new WASI({\r\n    args: process.argv,\r\n    env: process.env\r\n  });\r\n\r\nconst binary = require('fs').readFileSync('build/wasm_test.wasm');\r\n\r\nWebAssembly.instantiate(binary,\r\n    { env: {}, wasi_snapshot_preview1: wasi.wasiImport }).then(({ instance }) => {\r\n  // trigger ctors\r\n  instance.exports._start();\r\n  // test the static vars are correctly initialized.\r\n  console.log(instance.exports.GetX(0));\r\n});\r\n```\r\n```\r\nnode --experimental-wasi-unstable-preview1  --experimental-wasm-bigint test_wasm.js \r\n```\r\n\r\nRelevant issue in the emscripten https://github.com/emscripten-core/emscripten/issues/11001",
        "labels": "confirmed-bug",
        "id": 45044
    },
    {
        "title": "fs.stat or fs.lstat throws unknown error on some files (reparse point)",
        "body": "* **Version**: v12.16.2\r\n* **Platform**: 64 bit Microsoft Windows 10 [Version 10.0.18362.778]\r\n* **Subsystem**: fs\r\n\r\n### What steps will reproduce the bug?\r\n\r\n1. Check if `%USERPROFILE%\\AppData\\Local\\Microsoft\\WindowsApps` exists.\r\n2. Install https://www.microsoft.com/en-us/p/python-38/9mssztt1n39l\r\n3. Call `fs.statSync(\"c:\\\\Users\\\\kanadig\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\python.exe\")`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThis repros 100%, make sure you are calling it on the files under `%USERPROFILE%\\AppData\\Local\\Microsoft\\WindowsApps\\` with 0 size.\r\n\r\n### What is the expected behavior?\r\n\r\nShould not throw exception.\r\n\r\n### What do you see instead?\r\n\r\n```\r\n> fs.statSync(\"c:\\\\Users\\\\bpasero\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\GameBarElevatedFT_Alias.exe\")                 \r\nThrown:                                                                                                                  \r\n{ Error: UNKNOWN: unknown error, stat 'c:\\Users\\bpasero\\AppData\\Local\\Microsoft\\WindowsApps\\GameBarElevatedFT_Alias.exe' \r\n    at Object.statSync (fs.js:855:3)                                                                                     \r\n  errno: -4094,                                                                                                          \r\n  syscall: 'stat',                                                                                                       \r\n  code: 'UNKNOWN',                                                                                                       \r\n  path:                                                                                                                  \r\n   'c:\\\\Users\\\\bpasero\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\GameBarElevatedFT_Alias.exe' }                           \r\n> fs.lstatSync(\"c:\\\\Users\\\\bpasero\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\GameBarElevatedFT_Alias.exe\")                \r\nThrown:                                                                                                                  \r\n{ Error: UNKNOWN: unknown error, lstat 'c:\\Users\\bpasero\\AppData\\Local\\Microsoft\\WindowsApps\\GameBarElevatedFT_Alias.exe'\r\n    at Object.lstatSync (fs.js:845:3)                                                                                    \r\n  errno: -4094,                                                                                                          \r\n  syscall: 'lstat',                                                                                                      \r\n  code: 'UNKNOWN',                                                                                                       \r\n  path:                                                                                                                  \r\n   'c:\\\\Users\\\\bpasero\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps\\\\GameBarElevatedFT_Alias.exe' }                           \r\n>     \r\n```\r\n\r\n### Additional information\r\n\r\nSee https://github.com/microsoft/vscode/issues/95828\r\n",
        "labels": "confirmed-bug",
        "id": 45045
    },
    {
        "title": "Copying then pasting text directly into node REPL freezes it - Windows",
        "body": "As subject says. It only happens with large amounts of text, maybe something in relation to the buffer size?\r\n\r\nnode version v12.16.2\r\n64 bit Windows 10\r\n* **Subsystem**: none\r\n\r\n### What steps will reproduce the bug?\r\n\r\nOpen CMD, type \"node\" press enter to get the node repl. Now copy the below code, then right click in the node console to paste text. It will only paste the first line of code and freeze up node. It becomes completely unresponsive.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nEverytime when the copied code seems to be over a certain size. Don't know what that size is but happens no matter what the code is. The sample code provided will replicate the issue.\r\n\r\n### What is the expected behavior?\r\nAll text is pasted and executed line by line like other copy and paste operations.\r\n\r\n### What do you see instead?\r\n\r\nNode locks up after the first line of the copied text\r\n\r\n### Additional information\r\n\r\nSample code below. Here is a quick vid of node locking up as described above. https://streamable.com/ep7wqt The cursor just flashes but it is unresponsive to key strokes and doesn't do anything else.\r\nNOTE; the code has been changed to take out the IP so IF does execute it will error as I just replaced some keywords with random text. Ignore this, the point of it is to show that it won't copy and paste past the first line, it will freeze.\r\n\r\n```\r\n//{\"_id\":\"56aba3108d6d183da42403c2\"}\r\n//placeholder\r\nconst request = require('request');\r\nvar mongoose = require (\"mongoose\");\r\nvar lodash = require (\"lodash\");\r\nvar myFuncs = require(\"./functions\");\r\n\r\n\r\n\r\nvar item_urls;\r\nvar options = {\r\n    json: true\r\n  };\r\n\r\nvar test = [] ;\r\nfunction updateDB (){\r\n    var url = \"get stuff\";\r\n\r\n\r\n    request(url, options, (error, res, body) =>{\r\n        if (error) {\r\n            return console.log(error)\r\n          };\r\n\r\n          if (!error && res.statusCode == 200) {\r\n            console.log(\"executing cb1\");\r\n            item_urls = body.payload.items;\r\n            myFuncs.fixItemIDs (item_urls);\r\n            var primes = item_urls.filter(item => item.item_name.includes(\"Strun Wraith Set\")); \r\n            for (item in primes) \r\n            {\r\n                let url = `https://get more stuff/v1/items/${primes[item].url_name}`;\r\n               // console.log (url);\r\n                request(url, options, (error, res, body) =>{\r\n                    if (error) {\r\n                        return console.log(error)\r\n                      };\r\n\r\n                      if (!error && res.statusCode == 200) {\r\n\r\n                          console.log(`Getting item ${url}`);\r\n                          test.push(body.payload.item);\r\n                          myFuncs.fixItemIDs (test);\r\n                      }\r\n                    });\r\n\r\n            };  \r\n            console.log (\"done\");          \r\n\r\n\r\n          };\r\n    });\r\n}\r\n\r\nupdateDB();\r\n```",
        "labels": "confirmed-bug",
        "id": 45046
    },
    {
        "title": "Confusing error message in fs.utils",
        "body": "https://github.com/nodejs/node/blob/f22a9cac36f731d5bdbf1b7c542b36fa4c13f4de/lib/internal/fs/utils.js#L543\r\n\r\nThis check can produce confusing error message when `offse`t is equal to `bufferLength`. Which is error, but message shows, that it is correct (<=)\r\n```\r\nif (offset < 0 || offset >= bufferLength) {\r\n      throw new ERR_OUT_OF_RANGE('offset',\r\n                                 `>= 0 && <= ${bufferLength}`, offset);\r\n    }\r\n```\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45047
    },
    {
        "title": "'buffer.Buffer.prototype.lastIndexOf' results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.16.0\r\n* **Platform**: Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: buffer\r\n\r\n### What steps will reproduce the bug?\r\nDirectly run the following code snippet using node:\r\n```\r\nlet buffer = require('buffer');\r\nnew buffer.Buffer.prototype.lastIndexOf(1, 'str');\r\n```\r\nIt is worth noting that the following code would not cause this abort:\r\n```\r\nnew  require('buffer').Buffer.prototype.lastIndexOf(1, 'str');\r\n```\r\nThus we doubt there may be something wrong in somewhere.\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\nThis is a misuse of 'buffer.Buffer.prototype.lastIndexOf'. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nThis is the stack dump produced during abort:\r\n```\r\n./node[40968]: ../src/node_buffer.cc:1014:void node::Buffer::(anonymous namespace)::IndexOfNumber(const FunctionCallbackInfo<v8::Value> &): Assertion `args[2]->IsNumber()' failed.\r\n 1: 0x13f9b30 node::Abort() [./node]\r\n 2: 0x13f9709  [./node]\r\n 3: 0x13b765e  [./node]\r\n 4: 0x17b379c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [./node]\r\n 5: 0x17b23d5  [./node]\r\n 6: 0x17b1092  [./node]\r\n 7: 0x2717a59  [./node]\r\n[2]    40968 abort      ./node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45048
    },
    {
        "title": "process.setuid results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.16.0\r\n* **Platform**:  Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: process\r\n\r\n### What steps will reproduce the bug?\r\nDirectly run the following code snippet using node:\r\n```\r\nrequire('process').setuid(-0)\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\nThe argument to 'process.setuid' should be a Uint32 or string value, but we passed a -0 into it. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nThis is the stack dump produced during abort:\r\n```\r\n./node[37487]: ../src/node_credentials.cc:247:void node::credentials::SetUid(const FunctionCallbackInfo<v8::Value> &): Assertion `args[0]->IsUint32() || args[0]->IsString()' failed.\r\n 1: 0x13f9b30 node::Abort() [./node]\r\n 2: 0x13f9709  [./node]\r\n 3: 0x13ea56b  [./node]\r\n 4: 0x17b379c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [./node]\r\n 5: 0x17b23d5  [./node]\r\n 6: 0x17b1092  [./node]\r\n 7: 0x2717a59  [./node]\r\n[2]    37487 abort      ./node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45049
    },
    {
        "title": "'crypto.createDiffieHellman(prime: string, prime_encoding: HexBase64Latin1Encoding)' results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v12.16.0\r\n* **Platform**: Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\nDirectly run the following code snippet using node:\r\n```\r\nrequire('crypto').createDiffieHellman('str', 3.14);\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\nThe second argument to 'crypto.createDiffieHellman(prime: string, prime_encoding: HexBase64Latin1Encoding)' should be a 'HexBase64Latin1Encoding' value as the encoding of the first argument, but we passed a float pointer value into it. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\nThis is the stack dump produced during abort:\r\n```\r\n./node[36752]: ../src/util-inl.h:495:node::ArrayBufferViewContents<char, 64>::ArrayBufferViewContents(v8::Local<v8::Value>) [T = char, kStackStorageSize = 64]: Assertion `value->IsArrayBufferView()' failed.\r\n 1: 0x13f9b30 node::Abort() [./node]\r\n 2: 0x13f9709  [./node]\r\n 3: 0x160c480 node::crypto::DiffieHellman::DiffieHellmanGroup(v8::FunctionCallbackInfo<v8::Value> const&) [./node]\r\n 4: 0x17b379c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [./node]\r\n 5: 0x17b1c91  [./node]\r\n 6: 0x17b104c  [./node]\r\n 7: 0x2717a59  [./node]\r\n[1]    36752 abort      ./node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45050
    },
    {
        "title": "'worker_threads.receiveMessageOnPort' results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**:v12.16.0\r\n* **Platform**:Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: process\r\n\r\n### What steps will reproduce the bug?\r\nDirectly run the following code snippet using node:\r\n```\r\nrequire('worker_threads').receiveMessageOnPort(0)\r\n```\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\n\r\nThe argument to 'worker_threads.receiveMessageOnPort' should be a 'MessagePort' object, but we passed an integer value into it. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nThis is the stack dump produced during abort:\r\n```\r\n./node[17081]: ../src/node_messaging.cc:878:static void node::worker::MessagePort::ReceiveMessage(const FunctionCallbackInfo<v8::Value> &): Assertion `args[0]->IsObject()' failed.\r\n 1: 0x13f9b30 node::Abort() [./node]\r\n 2: 0x13f9709  [./node]\r\n 3: 0x148b6c0 node::worker::MessagePort::ReceiveMessage(v8::FunctionCallbackInfo<v8::Value> const&) [./node]\r\n 4: 0x17b379c v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [./node]\r\n 5: 0x17b23d5  [./node]\r\n 6: 0x17b1092  [./node]\r\n 7: 0x2717a59  [./node]\r\n[1]    17081 abort      ./node\r\n```\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45051
    },
    {
        "title": "`crypto.createDiffieHellman` results in an abort",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.16.0\r\n* **Platform**: Linux vul337 4.15.0-91-generic #92-Ubuntu SMP Fri Feb 28 11:09:48 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\nDirectly run the following code snippet using `node`:\r\n\r\n```javascript\r\nrequire('crypto').createDiffieHellman(0.123)\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nNo. This potential bug can always be reproduced.\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThe argument to `crypto.createDiffieHellman` should be an integer, but we passed a floating point number into it. The function should throw an exception or other similar error-reporting stuff rather than crash the whole nodejs process.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nThis is the stack dump produced during `abort`:\r\n```\r\nnode[55090]: ../src/node_buffer.cc:211:char *node::Buffer::Data(Local<v8::Value>): Assertion `val->IsArrayBufferView()' failed.\r\n 1: 0x10003c597 node::Abort() [/usr/local/bin/node]\r\n 2: 0x10003b5b9 node::AddEnvironmentCleanupHook(v8::Isolate*, void (*)(void*), void*) [/usr/local/bin/node]\r\n 3: 0x10004e3dd node::Buffer::Data(v8::Local<v8::Object>) [/usr/local/bin/node]\r\n 4: 0x10011f6c3 node::crypto::DiffieHellman::New(v8::FunctionCallbackInfo<v8::Value> const&) [/usr/local/bin/node]\r\n 5: 0x10023663f v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo*) [/usr/local/bin/node]\r\n 6: 0x1002357db v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<true>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/usr/local/bin/node]\r\n 7: 0x1002351f7 v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/usr/local/bin/node]\r\n 8: 0x2b916465be3d\r\n[1]    55090 abort      node\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45052
    },
    {
        "title": "repl: repl command preview interacts badly with `--trace-sync-io`",
        "body": "When launching the node.js REPL with the `--trace-sync-io` option, then typing sync fs statements, the repl prints one or two trace sync io statements for every key press following the opening `(` ... See screenshot:\r\n\r\n![image](https://user-images.githubusercontent.com/439929/78677080-2806ff80-789c-11ea-8eb4-c31d0b4e5706.png)\r\n\r\n/cc @BridgeAR ",
        "labels": "confirmed-bug",
        "id": 45053
    },
    {
        "title": "fs.Stat fails on pre-epoch mtime (<1970-01-01T00:00:00Z)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v13.10.1\r\n* **Platform**: Darwin dirac.imetrical.com 18.7.0 Darwin Kernel Version 18.7.0: Sun Dec  1 18:59:03 PST 2019; root:xnu-4903.278.19~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: fs.stat\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\n// statPreEpoch.js\r\nconst fs = require('fs')\r\nconst path = 'coco.txt'\r\nconst { mtime } = fs.statSync(path)\r\nconsole.log(`mtime of ${path}: ${mtime}`)\r\n```\r\n\r\n*This is on Darwin (macOS)*\r\n\r\n```bash\r\n# This is correct\r\n$ touch -mt 197001010000.00 coco.txt\r\n$ stat coco.txt \r\n16777220 104232499 -rw-r--r-- 1 daniel staff 0 0 \"Mar 19 13:26:22 2020\" \"Jan  1 00:00:00 1970\" \"Mar 19 15:01:21 2020\" \"Dec 31 19:00:00 1969\" 4096 0 0 coco.txt\r\n$ node statPreEpoch.js \r\nmtime of coco.txt: Thu Jan 01 1970 00:00:00 GMT-0500 (GMT-05:00)\r\n\r\n# This is the bug:\r\ntouch -mt 196805160000.00 coco.txt \r\nstat coco.txt \r\n16777220 104232499 -rw-r--r-- 1 daniel staff 0 0 \"Mar 19 13:26:22 2020\" \"May 16 00:00:00 1968\" \"Mar 19 15:00:23 2020\" \"Dec 31 19:00:00 1969\" 4096 0 0 coco.txt\r\n$ node statPreEpoch.js \r\nmtime of coco.txt: Invalid Date\r\n```\r\n\r\nThis is on Linux (in Docker\r\n```bash\r\n$ docker run --rm -it -v $(pwd)/statPreEpoch.js:/src/statPreEpoch.js node:13.10 bash\r\n$ uname -a\r\nLinux 38f95bbffb38 4.19.76-linuxkit #1 SMP Thu Oct 17 19:31:58 UTC 2019 x86_64 GNU/Linux\r\n$ touch -mt 197001010000.00 coco.txt\r\n$ stat coco.txt \r\n  File: coco.txt\r\n  Size: 0         \tBlocks: 0          IO Block: 4096   regular empty file\r\nDevice: abh/171d\tInode: 2910905     Links: 1\r\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\r\nAccess: 2020-03-19 19:10:48.080137057 +0000\r\nModify: 1970-01-01 00:00:00.000000000 +0000\r\nChange: 2020-03-19 19:10:48.080137057 +0000\r\n$ node  /src/statPreEpoch.js\r\nmtime of coco.txt: Thu Jan 01 1970 00:00:00 GMT+0000 (Coordinated Universal Time)\r\n\r\n# This is the bug\r\n$ touch -mt 196805160000.00 coco.txt \r\n$ stat coco.txt \r\n  File: coco.txt\r\n  Size: 0         \tBlocks: 0          IO Block: 4096   regular empty file\r\nDevice: abh/171d\tInode: 2910905     Links: 1\r\nAccess: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)\r\nAccess: 2020-03-19 19:10:48.080137057 +0000\r\nModify: 1968-05-16 00:00:00.000000000 +0000\r\nChange: 2020-03-19 19:12:24.343012135 +0000\r\n Birth: -\r\n$ node  /src/statPreEpoch.js\r\nmtime of coco.txt: Invalid Date\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nEvery time that mtime < unix epoch (1970-01-01T00:00:00Z)\r\n\r\n### What is the expected behavior?\r\n\r\nReturn a valid Date Object, for example\r\n\r\n```bash\r\n$ node  /src/statPreEpoch.js\r\nmtime of coco.txt: Thu May 16 1968 00:00:00 GMT+0000 (Coordinated Universal Time)\r\n```\r\n\r\n```js\r\n> new Date(\"1968-05-16T00:00:00-04:00\")\r\n1968-05-16T04:00:00.000Z\r\n> new Date(\"1968-05-16T00:00:00-04:00\").getTime()\r\n-51393600000\r\n```\r\n\r\n### What do you see instead?\r\n\r\n```bash\r\n$ node  /src/statPreEpoch.js\r\nmtime of coco.txt: Invalid Date\r\n```\r\n\r\n### Additional information\r\n\r\nI discovered this behavior by trying to use `fs.utimes` which is also not able to correctly handle dates before unix epoch, although `fs.utimes` seems to have a workaround by using the string representation of unix time.",
        "labels": "confirmed-bug",
        "id": 45054
    },
    {
        "title": "crypto.privateDecrypt keeps failing after \"Passphrase required\" error",
        "body": "* **Version**: v13.10.1\r\n* **Platform**: Ubuntu 18.04\r\n* **Subsystem**: crypto\r\n\r\nIf you call `crypto.privateDecrypt(...)` with an passphrase-encrypted private RSA key PEM but without providing a passphrase, it correctly raises `TypeError: Passphrase required for encrypted key`. But after that, if you try to call it again with an *unencrypted* private RSA key PEM, then the same error is raised. It seems like the first call corrupts some internal state (maybe openssl one) breaking subsequent calls. Example follows:\r\n\r\n```js\r\n// 1- Generate RSA key pair\r\nconst crypto = require('crypto')\r\nconst pair = crypto.generateKeyPairSync('rsa', { modulusLength : 1024 })\r\n\r\n// 2- Create a PEM uncrypted and the same one but encrypted with a passphrase\r\nconst privPEM        = pair.privateKey.export({ type : 'pkcs1', format : 'pem'})\r\nconst privPEMcrypted = pair.privateKey.export({ type : 'pkcs1', format : 'pem', \r\n                                                cipher : 'aes128', passphrase : 'mysecret'})\r\n\r\n// 3- Encrypt some data with public Key, works OK.\r\nconst dataEncrypted = crypto.publicEncrypt(pair.publicKey, Buffer.from(\"raw data\"))\r\n\r\n// 4- Try to decrypt it using the uncrypted Priv PEM (FIRST TIME)\r\nconst decrypt = (pem) => crypto.privateDecrypt(pem, dataEncrypted).toString()\r\n\r\n// As expected, this works ok:\r\nconsole.log('decrypt privPEM 1:', decrypt(privPEM)) \r\n\r\n// 5- Now try to decrypt it using the crypted Priv PEM but WITHOUT specifing a\r\n// passphrase. This will expectedly fail raising an exception:\r\ntry { \r\n    decrypt(privPEMcrypted)\r\n    // => TypeError: Passphrase required for encrypted key\r\n} catch(e) {\r\n    console.log('Ok, I expected this error:', e)\r\n}\r\n\r\n// 6- Now repeat the SAME step 4, this will FAIL with the same 'Passphrase\r\n// required for encrypted key' error from step 5, but this PEM is uncrypted, so\r\n// we found a bug.\r\nconsole.log(\"\\n\\nNow this must not fail... but it does:\")\r\n\r\nconsole.log('decrypt privPEM 2:', decrypt(privPEM))\r\n// => TypeError: Passphrase required for encrypted key\r\n```\r\nOutput:\r\n\r\n```\r\n$ node test-crypto-bug.js \r\ndecrypt privPEM 1: raw data\r\nOk, I expected this error: TypeError: Passphrase required for encrypted key\r\n    at Object.privateDecrypt (internal/crypto/cipher.js:63:12)\r\n    at decrypt (/tmp/test-crypto-bug.js:14:33)\r\n    at Object.<anonymous> (/tmp/test-crypto-bug.js:22:5)\r\n    at Module._compile (internal/modules/cjs/loader.js:1147:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1167:10)\r\n    at Module.load (internal/modules/cjs/loader.js:996:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:896:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12)\r\n    at internal/main/run_main_module.js:17:47 {\r\n  code: 'ERR_MISSING_PASSPHRASE'\r\n}\r\n\r\n\r\nNow this must not fail... but it does:\r\ninternal/crypto/cipher.js:63\r\n    return method(data, format, type, passphrase, buffer, padding, oaepHash,\r\n           ^\r\n\r\nTypeError: Passphrase required for encrypted key\r\n    at Object.privateDecrypt (internal/crypto/cipher.js:63:12)\r\n    at decrypt (/tmp/test-crypto-bug.js:14:33)\r\n    at Object.<anonymous> (/tmp/test-crypto-bug.js:33:35)\r\n    at Module._compile (internal/modules/cjs/loader.js:1147:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:1167:10)\r\n    at Module.load (internal/modules/cjs/loader.js:996:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:896:14)\r\n    at Function.executeUserEntryPoint [as runMain] (internal/modules/run_main.js:71:12)\r\n    at internal/main/run_main_module.js:17:47 {\r\n  code: 'ERR_MISSING_PASSPHRASE'\r\n}\r\n/tmp$ \r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45055
    },
    {
        "title": "\"Cannot find module\" when main file not `index.js` with experimental-specifier-resolution=node",
        "body": "* **Version**: 13.9.0\r\n* **Platform**: Linux\r\n\r\n### What steps will reproduce the bug?\r\n\r\n1. Clone https://github.com/dandv/node-cant-find-module-with-main-not-index.js\r\n2. `npm start`\r\n\r\n### What is the expected behavior?\r\n\r\nThe script should display `Success!`, and does do so if `mypackage/Lib.js` is renamed to `mypackage/index.js`.\r\n\r\n### What do you see instead?\r\n\r\n```\r\ninternal/modules/esm/resolve.js:61\r\n  let url = moduleWrapResolve(specifier, parentURL);\r\n            ^\r\n\r\nError: Cannot find module /home/dandv/prg/node-cant-find-module-with-main-not-index.js/mypackage imported from /home/dandv/prg/node-cant-find-module-with-main-not-index.js/run.js\r\n    at Loader.defaultResolve [as _resolve] (internal/modules/esm/resolve.js:61:13)\r\n    at Loader.resolve (internal/modules/esm/loader.js:85:40)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:191:28)\r\n    at ModuleWrap.<anonymous> (internal/modules/esm/module_job.js:42:40)\r\n    at link (internal/modules/esm/module_job.js:41:36) {\r\n  code: 'ERR_MODULE_NOT_FOUND'\r\n}\r\n```\r\n\r\n### Additional information\r\n\r\nI'm trying to run node with `-experimental-specifier-resolution=node` because [TypeScript can't output .mjs files](https://github.com/microsoft/TypeScript/issues/18442) and I want to use extension-less `import` statements. I prefer to use `Lib.js` instead of `index.js` to distinguish in my IDE between the main files of multiple packages in my monorepo that otherwise would all look like `index.js`.",
        "labels": "confirmed-bug",
        "id": 45056
    },
    {
        "title": "SSL_Error_rx_Record_too_long after upgrading from Node 13.8 to 13.9 or 13.10",
        "body": "* **Version**: 13.9, 13.10\r\n* **Platform**: All\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\nI am maintainer of [cWS](https://github.com/ClusterWS/cWS) which is C++ WebSocket  bindings for Node js. To reproduce issue you can fork repo use node 13.8 then run `node ./examples/ssl.js` and navigate to `https://localhost:3000` (in dev tools you will see that wss connection established properly). Then after upgrading to node 13.9 or 13.10 wss connection does not work any more. In Firefox i am getting `ssl_error_rx_record_too_long`. By the way cWS runs on `TLSv1_2_method`\r\n\r\n### How often does it reproduce? Is there a required condition?\r\nAlways\r\n\r\n### What is the expected behavior?\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nWork the same way as Node 13.8 and correctly establish wss connection and work\r\n\r\n### What do you see instead?\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\nSSL errors after connect\r\n",
        "labels": "confirmed-bug",
        "id": 45057
    },
    {
        "title": "CLS store gets reset on the first callback in http scenario",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: Linux\r\n* **Subsystem**: async_hooks\r\n\r\n### What steps will reproduce the bug?\r\n\r\nI have been trying to write some new scenarios for AsyncLocalStorage class, as mentioned in https://github.com/nodejs/node/issues/31978, and came across this issue:\r\n\r\n\r\n```js\r\nconst { AsyncLocalStorage } = require('async_hooks');\r\nconst http = require('http')\r\nconst cls = new AsyncLocalStorage();\r\n\r\nconst server = http.createServer((req, res) => {\r\n  res.write('hello')\r\n  setTimeout(() => {\r\n    res.end(' world!')\r\n  }, 1000)\r\n})\r\n\r\nserver.listen(12000, () => {\r\n  cls.run(() => {\r\n    const req = http.get('http://localhost:12000', (res) => {\r\n      const store = cls.getStore()\r\n      store.set('foo', '')\r\n      res.on('data', (d) => { console.log(cls.getStore()) });\r\n    })\r\n    req.end()\r\n  })\r\n})\r\n```\r\n\r\nIn this simple client-server program, the server is sending two chunks of data, forcing the `ondata` handler to be invoked twice.\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nevery time\r\n\r\n### What is the expected behavior?\r\n\r\nI get an empty Map every time in the ondata callback\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\nUnfortunately, the store is `undefined` after the first invocation:\r\n\r\n```trace\r\n$ node foo.js\r\nMap(1) { 'foo' => '' }\r\nundefined\r\n^C\r\n$\r\n```\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\nIf I replace this with a simple timer code, this logic works fine:\r\n\r\n```js\r\nconst { AsyncLocalStorage } = require('async_hooks');\r\nconst cls = new AsyncLocalStorage();\r\n\r\ncls.run(() => {\r\n  const store = cls.getStore()\r\n  store.set('foo', 'bar')\r\n  setInterval(() => {\r\n    console.log(cls.getStore().get('foo'))\r\n  }, 1000)\r\n}) \r\n```\r\n\r\n$ node timer.js\r\n```trace\r\nbar\r\nbar\r\nbar\r\nbar\r\n^C\r\n```\r\n\r\n\r\nAm I missing something?\r\n\r\nPing @vdeturckheim \r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45058
    },
    {
        "title": "Building LTS v12.x on Windows Fails The system cannot find the file specified.\"",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.x\r\n* **Platform**: Windows\r\n* **Subsystem**:\r\n\r\nI took the documentation specified in Building.md and converted that into a DockerFile. I had to make some additions to supplement the boxstarter scripts because that ran into errors installing the build tools. To get around that issue I installed those first via npm, [following guidelines in this post](https://spin.atomicobject.com/2019/03/27/node-gyp-windows/), then called the boxstarter scripts. This enabled me to get passed that particular problem but now I have a new issue which is detailed below in the console output. I have included a dockerfile to reproduce the issue. Any assistance will be greatly appreciated.\r\n\r\nOutput of the build\r\n```Powershell\r\nC:\\node>.\\vcbuild full-icu download-all\r\nLooking for Python\r\nPython 2 found in C:\\Python27\\\\python.exe\r\nLooking for NASM\r\nLooking for Visual Studio 2017\r\nFound MSVS version 15.0\r\nconfigure  \"--download=all\" --with-intl=full-icu --dest-cpu=x64\r\nINFO: Using floating patch \"tools/icu/patches/64/source/common/putil.cpp\" from \"tools/icu\"\r\nINFO: Using floating patch \"tools/icu/patches/64/source/i18n/dtptngen.cpp\" from \"tools/icu\"\r\nWarning: Missing input files:\r\ntools\\msvs\\genfiles\\node_etw_provider.rc\r\ntools\\msvs\\genfiles\\node_etw_provider.h\r\ntools\\v8_gypfiles\\..\\..\\deps\\v8\\src\\regexp\\regexp-special-case.h\r\nINFO: configure completed successfully\r\nProject files generated.\r\nThe system cannot find the file specified.\r\n```\r\n\r\nDockerfile to reproduce the behaviour\r\n\r\n```Dockerfile\r\nARG version=ltsc2019\r\nFROM mcr.microsoft.com/windows/servercore:$version\r\n\r\nENV chocolateyUseWindowsCompression false\r\n\r\nRUN powershell -Command \\\r\n    iex ((new-object net.webclient).DownloadString('https://chocolatey.org/install.ps1')); \\\r\n    choco feature disable --name showDownloadProgress  \r\n\r\nRUN powershell choco install nodejs-lts -y\r\nRUN npm install --global --production windows-build-tools\r\nRUN npm config set msvs_version 2017 -global\r\nRUN npm install --global node-gyp --no-optional\r\nRUN powershell choco install vim -y \r\n\r\n\r\nRUN powershell -Command \\\r\n    iex ((New-Object System.Net.WebClient).DownloadString('https://boxstarter.org/bootstrapper.ps1')) ; \\\r\n    Get-Boxstarter -Force ; \\\r\n    Install-BoxstarterPackage https://raw.githubusercontent.com/nodejs/node/master/tools/bootstrap/windows_boxstarter -DisableReboots\r\n\r\nRUN powershell git clone https://github.com/nodejs/node.git\r\nRUN powershell  Set-Location -Path C:\\Node; git checkout v12.x    \r\n\r\nRUN powershell Set-Location -Path C:\\Node; .\\vcbuild full-icu download-all\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45059
    },
    {
        "title": "Async generator: catched error on last yield is wrongly rethrown",
        "body": "* **Version**: v13.9.0\r\n* **Platform**: Linux and MacOS\r\n* **Subsystem**: ?\r\n\r\nAlso reproduced in v12 but not in v10 or v11.\r\n\r\n### What steps will reproduce the bug?\r\n\r\n```js\r\nasync function* gen() {\r\n  try {\r\n    yield 42\r\n  } catch(e) {\r\n    console.log('Error caught!')\r\n  }\r\n}\r\n\r\n(async () => {\r\n  const g = gen()\r\n  await g.next() // go to yield 42\r\n  try {\r\n    await g.throw(new Error()) // throw error from the yield\r\n  } catch (e) {\r\n    console.error('e has been rethrown !')\r\n  }\r\n})()\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nThis happens only:\r\n - with async generators\r\n - on the last yield\r\n - without any explicit return (in the generator)\r\n\r\n### What is the expected behavior?\r\n\r\n`g.throw()` should return a result `{ done: true, value: undefined }`\r\n\r\n### What do you see instead?\r\n\r\n`g.throw()` rethrows the error.\r\n\r\n### Additional information\r\n",
        "labels": "confirmed-bug",
        "id": 45060
    },
    {
        "title": "Verification with dsaEncoding ieee-p1363 fails.",
        "body": "When you verify a 'ieee-p1363' encoded signature it fails, even if the signature is correct.\r\n* **Version**: v13.8.0\r\n* **Platform**: 64-bit Windows 10\r\n* **Subsystem**: crypto\r\n\r\n### What steps will reproduce the bug?\r\n```\r\nconst crypto = require('crypto');\r\nconst key = crypto.generateKeyPairSync('ec', { namedCurve: 'P-256' });\r\n\r\n//ieee-p1363 signature, which seems to be the correct.\r\nconst signatureP1363 = crypto.createSign('SHA256').update('abc').sign({ key: key.privateKey, dsaEncoding: 'ieee-p1363' });\r\n//ieee-p1363 verification, which fails.\r\nconsole.log(crypto.createVerify('SHA256').update('abc').verify({ key: key.publicKey, dsaEncoding: 'ieee-p1363' }, signatureP1363));\r\n\r\n//Compared to der signature and verification, which work as expected:\r\nconst signatureDER = crypto.createSign('SHA256').update('abc').sign({ key: key.privateKey, dsaEncoding: 'der' });\r\nconsole.log(crypto.createVerify('SHA256').update('abc').verify({ key: key.publicKey, dsaEncoding: 'der' }, signatureDER));\r\n```\r\n\r\n### Additional information\r\nThe problem seems to be the verification algorithm, not the signing algorithm. You can test that the generated signature is correct in chrome using:\r\n\r\n```\r\n//key.publicKey.export({ format: 'der', type: 'spki' }).toString('base64');\r\nconst base64key = 'MFkwEwYHKoZIzj0CAQYIKoZIzj0DAQcDQgAE/V0xKgeZJeIFra+gshXB6OpM5IKuhHwcBkpu5ZdMZZM62x+GahHJdrll+Q3aihYNfakkzf7W65dIdDAhLImu0w==';\r\n//signatureP1363.toString('base64');\r\nconst base64sig = '+aocUpmRHRSxfpCJpwCCuQoFagatOlsFganmXiqtztFo9iBHqE6z7A7KQcMs1k9VASt3cgtkJqyPKAY4OTyJ8A==';\r\n//Verify the signature\r\nconst uint8key = Uint8Array.from(atob(base64key), (c) => c.charCodeAt(0));\r\nconst uint8sig = Uint8Array.from(atob(base64sig), (c) => c.charCodeAt(0));\r\nconst uint8data = Uint8Array.from('abc', (c) => c.charCodeAt(0));\r\nconst params = { name: 'ECDSA', hash: 'SHA-256', namedCurve: 'P-256' };\r\nconst cryptokey = await window.crypto.subtle.importKey('spki', uint8key, params, false, ['verify']);\r\nawait window.crypto.subtle.verify(params, cryptokey, uint8sig, uint8data);\r\n```",
        "labels": "confirmed-bug",
        "id": 45061
    },
    {
        "title": "12.16/13.8: http response listener throwing does not result in emit of uncaughtException",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: 12.16.0 | 13.8.0\r\n* **Platform**: Darwin Kernel Version 18.6.0\r\n* **Subsystem**:\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\nThrowing from a response listener (callback) to `http.get()` will not trigger `process.once('uncaughtException', () => {})`. Interestingly, throwing from a request listener (callback) to `http.createServer()`  will still. \r\n\r\nThis behavior changed with 12.16.0, I'm guessing likely due to the porting of the emit changes?\r\n\r\n```js\r\nconst http = require('http')\r\n\r\nlet server\r\nlet request\r\n\r\nprocess.once('uncaughtException', function() {\r\n  // never gets here from response listener in 12.16, works fine < 12.16.\r\n  console.log('in uncaughtException handler')\r\n\r\n  server.close(done)\r\n})\r\n\r\nserver = http.createServer(function cb_createServer(request, response) {\r\n  // Throw from request listener will result in uncaughtException\r\n  //throw new Error('wat')\r\n  response.writeHead(200, {'Content-Type': 'text/plain'})\r\n  response.end()\r\n})\r\n\r\nserver.listen(8183, function() {\r\n  request = http.get({host: 'localhost', port: 8183}, function() {\r\n    // Throw from response listener will not result in uncaughtException\r\n    throw new Error('whoah')\r\n  })\r\n})\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nConsistently does not trigger `uncaughtException` / does not allow handling via `process.on('uncaughtException', ...)`.\r\n\r\n### What is the expected behavior?\r\n\r\nShould be able to notice the uncaught exception thrown from the handler.\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n",
        "labels": "confirmed-bug",
        "id": 45062
    },
    {
        "title": "package self-reference works without a flag in node v12.16",
        "body": "Repro: clone https://github.com/ljharb/has-package-exports\r\n\r\nIt has a dev dep of `\"has-package-exports\": \"file:.\"`, so that in every node version, i can `require('has-package-exports')` from within the package, and it works.\r\n\r\nIn node v13.6 and v12.15, `node test` passes without issuing `(node:96292) ExperimentalWarning: Package name self resolution is an experimental feature. This feature could change at any time` as a warning.\r\n\r\nIn node v13.7, the warning is correctly issued, and the local dev dep is byassed.\r\n\r\nHowever, in node v12.16, without passing any flags, the warning is issued and the local dev dep is bypassed. v12.16 and v12.15 should behave identically with respect to this feature, regardless of the presence of \"exports\" in package.json.\r\n\r\ncc @nodejs/modules-active-members ",
        "labels": "confirmed-bug",
        "id": 45063
    },
    {
        "title": "child_process: spawnSync crashes trying to terminate setuid child because of maxBuffer exceeded",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n-->\r\n\r\n* **Version**: v13.8.0, v12.16.0\r\n* **Platform**: macOS 10.15.3, Ubuntu 16.04.6 (4.15.0-70-generic)\r\n* **Subsystem**: child_process, src/spawn_sync.c\r\n\r\n### What steps will reproduce the bug?\r\n\r\n<!--\r\nEnter details about your bug, preferably a simple code snippet that can be\r\nrun using `node` directly without installing third-party dependencies.\r\n-->\r\n\r\n```\r\n$ cat test.c\r\n#include <unistd.h>\r\n#include <stdio.h>\r\nint main() { setuid(0); while (1) printf(\"hello\"); }\r\n\r\n$ gcc -o test test.c; sudo chown root test; sudo chmod 4755 test\r\n\r\n$ node -e \"require('child_process').spawnSync('./test')\"\r\n```\r\n\r\nOR\r\n\r\n```\r\n$ node -e \"require('child_process').spawnSync('sudo', ['bash', '-c', 'ls -lR /'])\"\r\n```\r\n\r\n### How often does it reproduce? Is there a required condition?\r\n\r\nAlways\r\n\r\n### What is the expected behavior?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\nI expect to get `ENOBUF` (because of maxBuffer reached) and/or `EPERM` (because child process cannot be killed), so I can handle it somehow - but not crash.\r\n\r\n### What do you see instead?\r\n\r\n<!--\r\nIf possible please provide textual output instead of screenshots.\r\n-->\r\n\r\n```\r\nnode[68984]: ../src/spawn_sync.cc:611:void node::SyncProcessRunner::Kill(): Assertion `r >= 0 || r == UV_ESRCH' failed.\r\n 1: 0x100ba0c4a node::Abort() (.cold.1) [/usr/local/bin/node]\r\n 2: 0x100084961 node::FatalError(char const*, char const*) [/usr/local/bin/node]\r\n 3: 0x100084719 node::AppendExceptionLine(node::Environment*, v8::Local<v8::Value>, v8::Local<v8::Message>, node::ErrorHandlingMode) [/usr/local/bin/node]\r\n 4: 0x10010657d node::SyncProcessRunner::Kill() [/usr/local/bin/node]\r\n 5: 0x1006cb116 uv__stream_io [/usr/local/bin/node]\r\n 6: 0x1006d23a8 uv__io_poll [/usr/local/bin/node]\r\n 7: 0x1006c2fa2 uv_run [/usr/local/bin/node]\r\n 8: 0x10010598f node::SyncProcessRunner::TryInitializeAndRunLoop(v8::Local<v8::Value>) [/usr/local/bin/node]\r\n 9: 0x100105674 node::SyncProcessRunner::Run(v8::Local<v8::Value>) [/usr/local/bin/node]\r\n10: 0x100105513 node::SyncProcessRunner::Spawn(v8::FunctionCallbackInfo<v8::Value> const&) [/usr/local/bin/node]\r\n11: 0x1001cb578 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [/usr/local/bin/node]\r\n12: 0x1001cac02 v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/usr/local/bin/node]\r\n13: 0x1001ca40e v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/usr/local/bin/node]\r\n14: 0x1007503d9 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/usr/local/bin/node]\r\nzsh: abort      node -e \"require('child_process').spawnSync('./test')\"\r\n```\r\n\r\n### Additional information\r\n\r\n<!--\r\nTell us anything else you think we should know.\r\n-->\r\n\r\nAccording to documentation, `child_process.spawnSync()` terminates child process if it's output is larger than `maxBuffer`. If child process can't be killed (because of setuid call), node crashes in `CHECK()` below https://github.com/nodejs/node/blob/master/src/spawn_sync.cc#L611:\r\n\r\n```\r\n    // If uv_kill failed with an error that isn't ESRCH, the user probably\r\n    // specified an invalid or unsupported signal. Signal this to the user as\r\n    // and error and kill the process with SIGKILL instead.\r\n    if (r < 0 && r != UV_ESRCH) {\r\n      SetError(r);\r\n\r\n      r = uv_process_kill(&uv_process_, SIGKILL);\r\n      CHECK(r >= 0 || r == UV_ESRCH);\r\n    }\r\n```\r\n\r\nShouldn't we also check for UV_EPERM?",
        "labels": "confirmed-bug",
        "id": 45064
    },
    {
        "title": "fs,crypto: AAD decryption of fs stream > 32768 bytes fails",
        "body": "<!-- Please remove this line and fill the template -->\r\n\r\n* **Node.js Version**: v12.15.0\r\n* **OS**: Linux 5.5.2-arch1-1\r\n* **Scope (install, code, runtime, meta, other?)**: code\r\n* **Module (and version) (if relevant)**: crypto (openssl: '1.1.1d')\r\n\r\nWith a 32768 bytes message, the AES-128-CCM cipher and decipher both work well. \r\nWith a 32769 bytes message, the AES-128-CCM cipher works well, but the decipher failed with a message:\r\n\r\n```\r\nError: Unsupported state or unable to authenticate data\r\n    at Decipheriv._flush (internal/crypto/cipher.js:139:29)\r\n    at Decipheriv.prefinish (_stream_transform.js:140:10)\r\n    at Decipheriv.emit (events.js:223:5)\r\n    at prefinish (_stream_writable.js:670:14)\r\n    at finishMaybe (_stream_writable.js:678:5)\r\n    at endWritable (_stream_writable.js:698:3)\r\n    at Decipheriv.Writable.end (_stream_writable.js:627:5)\r\n    at ReadStream.onend (_stream_readable.js:693:10)\r\n    at Object.onceWrapper (events.js:312:28)\r\n    at ReadStream.emit (events.js:228:7)\r\n```\r\n\r\nI can't understand why. Whatever I change the AAD/IV/authTagLength, it canâ€˜t work.\r\n\r\nHere is my code:\r\n\r\n```js\r\n// execute after: dd if=/dev/random of=random.bin count=1 bs=32769\r\nconst $Crypto = require(\"crypto\");\r\nconst $fs = require(\"fs\");\r\n\r\nconst key = $Crypto.randomBytes(16);\r\n\r\nconst iv = $Crypto.randomBytes(8);\r\n\r\nconst aad = $Crypto.randomBytes(1);\r\n\r\nconst stream = $Crypto.createCipheriv(\"aes-128-ccm\", key, iv, {\r\n    authTagLength: 16\r\n});\r\n\r\nstream.setAAD(aad, {\r\n    plaintextLength: 32769\r\n});\r\n\r\n$fs.createReadStream(\"./random.bin\").pipe(stream).pipe(\r\n    $fs.createWriteStream(\"./random.bin.ciphertext\")\r\n).on(\"finish\", function() {\r\n\r\n    console.info(\"encrypted\");\r\n\r\n    const destream = $Crypto.createDecipheriv(\"aes-128-ccm\", key, iv, {\r\n        authTagLength: 16\r\n    });\r\n    \r\n    destream.setAAD(aad, {\r\n        plaintextLength: 32769\r\n    });\r\n\r\n    destream.setAuthTag(stream.getAuthTag());\r\n    \r\n    $fs.createReadStream(\"./random.bin.ciphertext\").pipe(destream).pipe(\r\n        $fs.createWriteStream(\"./random.bin.plaintext\")\r\n    );\r\n});\r\n```",
        "labels": "confirmed-bug",
        "id": 45065
    },
    {
        "title": "Chown not conform to glibc's chown",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: `v12.4.0`\r\nPlatform: `Linux 5.5.2-arch1-1#1 SMP PREEMPT Tue, 04 Feb 2020 18:56:18 +0000 x86_64 GNU/Linux`\r\nSubsystem: `fs`\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `v12.4.0`\r\n* **Platform**: `Linux 5.5.2-arch1-1#1 SMP PREEMPT Tue, 04 Feb 2020 18:56:18 +0000 x86_64 GNU/Linux`\r\n* **Subsystem**: `fs`\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nHi,\r\n\r\nWhen using `fs.chown`, I can't find a way to change only one of the two ids. It seems node isn't actually conforming to the `glibc` call linked in the documentation. When passing -1 (which according to [chown](http://man7.org/linux/man-pages/man2/chown.2.html) should result in a noop for this id), I get an error :\r\n\r\n```\r\nThe value of \"uid\" is out of range. It must be >= 0 && < 4294967296. Received -1\r\n```\r\n\r\nIs there a way to specify only one of the two ids ? If yes, can I kindly suggest that it should be added to the docs ?\r\n\r\nThanks\r\n",
        "labels": "confirmed-bug",
        "id": 45066
    },
    {
        "title": "Investigate flaky test-benchmark-misc ",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: Master\r\n* **Platform**: Custom Suites Freestyle\r\n* **Subsystem**: benchmark\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n```\r\ninternal/readline/utils.js:163\r\n  return str.replace(ansi, '');\r\n             ^\r\n\r\nTypeError: Cannot read property 'replace' of undefined\r\n    at stripVTControlCharacters (internal/readline/utils.js:163:14)\r\n    at getStringWidth (internal/readline/utils.js:71:11)\r\n    at main (/home/iojs/build/workspace/node-test-commit-custom-suites-freestyle/benchmark/misc/getstringwidth.js:24:5)\r\n    at /home/iojs/build/workspace/node-test-commit-custom-suites-freestyle/benchmark/common.js:40:28\r\n    at processTicksAndRejections (internal/process/task_queues.js:79:11)\r\nassert.js:102\r\n  throw new AssertionError(obj);\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: Expected values to be strictly equal:\r\n\r\n1 !== 0\r\n\r\n```\r\n\r\nThis has been failing node-daily-master since 10-01-2020. \r\nhttps://ci.nodejs.org/view/Node.js%20Daily/job/node-daily-master/1802/\r\nhttps://ci.nodejs.org/view/Node.js%20Daily/job/node-daily-master/1803/\r\nhttps://ci.nodejs.org/view/Node.js%20Daily/job/node-daily-master/1804/\r\nhttps://ci.nodejs.org/view/Node.js%20Daily/job/node-daily-master/1805/\r\nhttps://ci.nodejs.org/view/Node.js%20Daily/job/node-daily-master/1806/",
        "labels": "confirmed-bug",
        "id": 45067
    },
    {
        "title": "new tls.TLSSocket issue",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10.x+\r\n* **Platform**: All\r\n* **Subsystem**: tls\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhen I try to create a secure connection over an existing stream, implementing something similar to STARTTLS, the suggested way is to use new tls.TLSSocket(<duplex stream>).\r\n\r\nI also want to use mutual certification authentication but the tlsSocket.authorized is never set to true for the Server even when the client certificate is signed correctly by the expected CA. From the _tls_wrap.js code, it seems this flag is only set for the server when the underlying stream is an actual socket.\r\n\r\nOn the client side things are working as expected, as the client side connection is created with tls.connect().\r\n\r\nIt used to be that the deprecated pair returned by tls.createSecurePair() has access to the internal SSL object, which I can use verifyError() to check the validity of the client certificate. But this hidden feature has also been removed in recent versions.\r\n\r\nWhat is the correct approach to mca for \"upgraded\" connection?\r\n",
        "labels": "confirmed-bug",
        "id": 45068
    },
    {
        "title": "repl: bug when the length of preview output is exactly equal to the terminal width",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: macOS\r\n* **Subsystem**: repl\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhen the length of preview output is exactly equal to the terminal width, the cursor's position move to the end of current line, which seems to be a bug.\r\n\r\n![Kapture 2020-01-10 at 17 56 23](https://user-images.githubusercontent.com/23313266/72143954-9c7fee80-33d2-11ea-8622-f13d4fc1d214.gif)\r\n\r\n/cc @BridgeAR ",
        "labels": "confirmed-bug",
        "id": 45069
    },
    {
        "title": "unable to build master, linking fails",
        "body": "I'm using clang 9.0.0 on linux 5.4. gcc libc++ is at 9.2.0\r\n\r\n```\r\n/usr/bin/ld: node/out/Release/mkcodecache: section .tbss._ZN2v88internal12trap_handler21g_thread_in_wasm_codeE lma 0x3ad7d10 adjusted to 0x3ad7d18\r\n/usr/bin/ld: node/out/Release/mkcodecache: section .tbss._ZN2v88internal4wasm12_GLOBAL__N_123current_code_refs_scopeE lma 0x3ad7d10 adjusted to 0x3ad7d1c\r\n/usr/bin/ld: node/out/Release/node_mksnapshot: section .tbss._ZN2v88internal12trap_handler21g_thread_in_wasm_codeE lma 0x3adc138 adjusted to 0x3adc140\r\n/usr/bin/ld: node/out/Release/node_mksnapshot: section .tbss._ZN2v88internal4wasm12_GLOBAL__N_123current_code_refs_scopeE lma 0x3adc138 adjusted to 0x3adc144\r\n/usr/bin/ld: /usr/lib/libc_nonshared.a(elf-init.oS): in function `__libc_csu_init':\r\n(.text+0x9): undefined reference to `__init_array_start'\r\n/usr/bin/ld: (.text+0x20): undefined reference to `__init_array_end'\r\n/usr/bin/ld: node/out/Release/mkcodecache: hidden symbol `__init_array_end' isn't defined\r\n/usr/bin/ld: final link failed: bad value\r\nclang-9: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake[1]: *** [mkcodecache.target.mk:211: node/out/Release/mkcodecache] Error 1\r\nmake[1]: *** Waiting for unfinished jobs....\r\n/usr/bin/ld: /usr/lib/libc_nonshared.a(elf-init.oS): in function `__libc_csu_init':\r\n(.text+0x9): undefined reference to `__init_array_start'\r\n/usr/bin/ld: (.text+0x20): undefined reference to `__init_array_end'\r\n/usr/bin/ld: node/out/Release/node_mksnapshot: hidden symbol `__init_array_end' isn't defined\r\n/usr/bin/ld: final link failed: bad value\r\nclang-9: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake[1]: *** [node_mksnapshot.target.mk:211: node/out/Release/node_mksnapshot] Error 1\r\n/usr/bin/ld: node/out/Release/cctest: section .tbss._ZN2v88internal12trap_handler21g_thread_in_wasm_codeE lma 0x3d1a090 adjusted to 0x3d1a098\r\n/usr/bin/ld: node/out/Release/cctest: section .tbss._ZN2v88internal4wasm12_GLOBAL__N_123current_code_refs_scopeE lma 0x3d1a090 adjusted to 0x3d1a09c\r\n/usr/bin/ld: /usr/lib/libc_nonshared.a(elf-init.oS): in function `__libc_csu_init':\r\n(.text+0x9): undefined reference to `__init_array_start'\r\n/usr/bin/ld: (.text+0x20): undefined reference to `__init_array_end'\r\n/usr/bin/ld: /node/out/Release/cctest: hidden symbol `__init_array_end' isn't defined\r\n/usr/bin/ld: final link failed: bad value\r\nclang-9: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake[1]: *** [cctest.target.mk:236: node/out/Release/cctest] Error 1\r\nrm 2c2d90d92af32fa2bd6374898760f9e3aec01744.intermediate 92dd4eeebf8d109ba8aadeb5d36dbd389740ec6b.intermediate f12c036df8642cb80f280f6ba7af1a2f28745260.intermediate 81e1bdc2cb7a88361a91e3d45a5b35e6715c2ab6.intermediate\r\nmake: *** [Makefile:101: node] Error 2\r\n```",
        "labels": "confirmed-bug",
        "id": 45070
    },
    {
        "title": "13.5 broke tap's error handling",
        "body": "* **Version**: 13.5.0\r\n* **Platform**: Darwin tau.local 19.0.0 Darwin Kernel Version 19.0.0: Thu Oct 17 16:17:15 PDT 2019; root:xnu-6153.41.3~29/RELEASE_X86_64 x86_64 (but irrelevant to this issue)\r\n* **Subsystem**: async hooks\r\n\r\nThe change in https://github.com/nodejs/node/pull/30965 means that Node now relies on `process._fatalException` calling `emitAfter(asyncId);`\r\n\r\nHowever, this cannot be done in userland code, because the `emitAfter` method is not exposed.\r\n\r\nWith the deprecation of domains in Node.js version 4, [as far as I've been able to tell](https://github.com/nodejs/node/issues/10843), patching `process._fatalException` and tracking the process flow through async hooks is the _only_ way to reliably tie an error back to a chain of continuations.  (And it doesn't even work 100% reliably, because [Promises break async hooks](https://github.com/nodejs/node/issues/26794).)\r\n\r\nFor node-tap, in order to fail the appropriate test when an error is thrown or promise is rejected (most of the time, at least), I'm using [async-hook-domain](http://npm.im/async-hook-domain).  I used to use domains, but was scared off by the noisy warnings.\r\n\r\nNow, a test like this:\r\n\r\n```js\r\nconst t = require('tap')\r\nt.test('failure', t => {\r\n  throw new Error('nope')\r\n})\r\n```\r\n\r\nwhich should output this:\r\n\r\n```\r\n$ node fail.js\r\nTAP version 13\r\n# Subtest: failure\r\n    not ok 1 - nope\r\n      ---\r\n      stack: |\r\n        Test.<anonymous> (fail.js:3:9)\r\n      at:\r\n        line: 3\r\n        column: 9\r\n        file: fail.js\r\n        function: Test.<anonymous>\r\n      tapCaught: testFunctionThrow\r\n      test: failure\r\n      source: |\r\n        t.test('failure', t => {\r\n          throw new Error('nope')\r\n        --------^\r\n        })\r\n      ...\r\n\r\n    1..1\r\n    # failed 1 test\r\nnot ok 1 - failure # time=18.611ms\r\n```\r\n\r\ninstead (as of 503900b4633a541ecbebc159487f775c2669f54d) outputs this:\r\n\r\n```\r\n$ node fail.js\r\nTAP version 13\r\n# Subtest: failure\r\n    not ok 1 - nope\r\n      ---\r\n      stack: |\r\n        Test.<anonymous> (fail.js:3:9)\r\n      at:\r\n        line: 3\r\n        column: 9\r\n        file: fail.js\r\n        function: Test.<anonymous>\r\n      tapCaught: testFunctionThrow\r\n      test: failure\r\n      source: |\r\n        t.test('failure', t => {\r\n          throw new Error('nope')\r\n        --------^\r\n        })\r\n      ...\r\n\r\n    1..1\r\n    # failed 1 test\r\nnot ok 1 - failure # time=18.611ms\r\n\r\nError: async hook stack has become corrupted (actual: 18, expected: 1)\r\n 1: 0x10000b8d9 node::AsyncHooks::pop_async_id(double) [/usr/local/bin/node]\r\n 2: 0x10000189a node::InternalCallbackScope::Close() [/usr/local/bin/node]\r\n 3: 0x10000149a node::InternalCallbackScope::~InternalCallbackScope() [/usr/local/bin/node]\r\n 4: 0x1000b3f45 node::NodeMainInstance::Run() [/usr/local/bin/node]\r\n 5: 0x10005e46f node::Start(int, char**) [/usr/local/bin/node]\r\n 6: 0x7fff657932e5 start [/usr/lib/system/libdyld.dylib]\r\n 7: 0x2\r\n```\r\n\r\nWhat has to happen to get error handling and continuation tracking shipped in core?  The pieces are all there, they're just not exposed in any kind of useful way.  I'm happy to help.\r\n\r\nFailing that, I'd suggest reverting 503900b4633a541ecbebc159487f775c2669f54d.",
        "labels": "confirmed-bug",
        "id": 45071
    },
    {
        "title": "fs.writeFileSync(path) literaly writes \"undefined\" to the file",
        "body": "* **Version**: v13.3.0\r\n* **Platform**: Linux pc 5.3.15-1-MANJARO #1 SMP PREEMPT Thu Dec 5 11:01:29 UTC 2019 x86_64 GNU/Linux\r\n* **Subsystem**: fs\r\n\r\nWhen executing:\r\n```js\r\nrequire('fs').writeFileSync('/tmp/empty-file');\r\n```\r\nIt creates a file containing \"undefined\" string:\r\n```bash\r\n% hexdump -C /tmp/empty-file\r\n00000000  75 6e 64 65 66 69 6e 65  64                       |undefined|\r\n00000009\r\n```\r\n\r\nThis is unexpected behavior as I just wanted to create an empty file. I expect it to either write an empty file or throw but in no case have \"undefined\" written as the file content.",
        "labels": "confirmed-bug",
        "id": 45072
    },
    {
        "title": "Running `benchmark/http/incoming_headers.js` fails with error \"autocannon produced strange output\"",
        "body": "* **Version**: master, v12.14.0, v10.18.0\r\n* **Platform**: Ubuntu\r\n* **Subsystem**: http\r\n\r\n**Describe the bug**\r\nRunning `benchmark/http/incoming_headers.js` fails with error \"autocannon produced strange output\" for:\r\n* master\r\n* v12.14.0\r\n* v10.18.0\r\n\r\n**To Reproduce**\r\nFollow instructions in [running benchmarks](https://github.com/nodejs/node/blob/651c43082698ba3bfa4f2417944719f771c09f04/benchmark/writing-and-running-benchmarks.md#running-benchmarks) to run `benchmark/http/incoming_headers.js`\r\n\r\nExample:\r\n```console\r\n$ node -v\r\nv12.14.0\r\n\r\n$ node benchmark/http/incoming_headers.js\r\nError: autocannon produced strange output: {\"url\":\"http://127.0.0.1:12346/\",\"requests\":{\"average\":0,\"mean\":0,\"stddev\":0,\"min\":0,\"max\":0,\"total\":0,\"p0_001\":0,\"p0_01\":0,\"p0_1\":0,\"p1\":0,\"p2_5\":0,\"p10\":0,\"p25\":0,\"p50\":0,\"p75\":0,\"p90\":0,\"p97_5\":0,\"p99\":0,\"p99_9\":0,\"p99_99\":0,\"p99_999\":0,\"sent\":89280},\"latency\":{\"average\":0,\"mean\":0,\"stddev\":0,\"min\":0,\"max\":0,\"p0_001\":0,\"p0_01\":0,\"p0_1\":0,\"p1\":0,\"p2_5\":0,\"p10\":0,\"p25\":0,\"p50\":0,\"p75\":0,\"p90\":0,\"p97_5\":0,\"p99\":0,\"p99_9\":0,\"p99_99\":0,\"p99_999\":0},\"throughput\":{\"average\":0,\"mean\":0,\"stddev\":0,\"min\":0,\"max\":0,\"total\":0,\"p0_001\":0,\"p0_01\":0,\"p0_1\":0,\"p1\":0,\"p2_5\":0,\"p10\":0,\"p25\":0,\"p50\":0,\"p75\":0,\"p90\":0,\"p97_5\":0,\"p99\":0,\"p99_9\":0,\"p99_99\":0,\"p99_999\":0},\"errors\":0,\"timeouts\":0,\"duration\":5.03,\"start\":\"2019-12-18T17:05:17.412Z\",\"finish\":\"2019-12-18T17:05:22.440Z\",\"connections\":50,\"pipelining\":1,\"non2xx\":0,\"1xx\":0,\"2xx\":0,\"3xx\":0,\"4xx\":0,\"5xx\":0}\r\n\r\n    at ChildProcess.<anonymous> (/home/trivikr/workspace/node/benchmark/_http-benchmarkers.js:235:16)\r\n    at Object.onceWrapper (events.js:300:26)\r\n    at ChildProcess.emit (events.js:210:5)\r\n    at maybeClose (internal/child_process.js:1021:16)\r\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:283:5)\r\n\r\n$ nvm use 10\r\nNow using node v10.18.0 (npm v6.13.4)\r\n\r\n$ node benchmark/http/incoming_headers.js\r\nError: autocannon produced strange output: {\"url\":\"http://127.0.0.1:12346/\",\"requests\":{\"average\":0,\"mean\":0,\"stddev\":0,\"min\":0,\"max\":0,\"total\":0,\"p0_001\":0,\"p0_01\":0,\"p0_1\":0,\"p1\":0,\"p2_5\":0,\"p10\":0,\"p25\":0,\"p50\":0,\"p75\":0,\"p90\":0,\"p97_5\":0,\"p99\":0,\"p99_9\":0,\"p99_99\":0,\"p99_999\":0,\"sent\":90101},\"latency\":{\"average\":0,\"mean\":0,\"stddev\":0,\"min\":0,\"max\":0,\"p0_001\":0,\"p0_01\":0,\"p0_1\":0,\"p1\":0,\"p2_5\":0,\"p10\":0,\"p25\":0,\"p50\":0,\"p75\":0,\"p90\":0,\"p97_5\":0,\"p99\":0,\"p99_9\":0,\"p99_99\":0,\"p99_999\":0},\"throughput\":{\"average\":0,\"mean\":0,\"stddev\":0,\"min\":0,\"max\":0,\"total\":0,\"p0_001\":0,\"p0_01\":0,\"p0_1\":0,\"p1\":0,\"p2_5\":0,\"p10\":0,\"p25\":0,\"p50\":0,\"p75\":0,\"p90\":0,\"p97_5\":0,\"p99\":0,\"p99_9\":0,\"p99_99\":0,\"p99_999\":0},\"errors\":0,\"timeouts\":0,\"duration\":5.11,\"start\":\"2019-12-18T17:09:06.423Z\",\"finish\":\"2019-12-18T17:09:11.532Z\",\"connections\":50,\"pipelining\":1,\"non2xx\":0,\"1xx\":0,\"2xx\":0,\"3xx\":0,\"4xx\":0,\"5xx\":0}\r\n\r\n    at ChildProcess.child.once (/home/trivikr/workspace/node/benchmark/_http-benchmarkers.js:235:16)\r\n    at Object.onceWrapper (events.js:286:20)\r\n    at ChildProcess.emit (events.js:198:13)\r\n    at maybeClose (internal/child_process.js:982:16)\r\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:259:5)\r\n```\r\n\r\n**Expected behavior**\r\nThe `benchmark/http/headers.js` runs without any error\r\n\r\n**Additional context**\r\nI came across this issue as part of running benchmarks while moving to `for...of` loop in the initial commits of https://github.com/nodejs/node/pull/30958",
        "labels": "confirmed-bug",
        "id": 45073
    },
    {
        "title": "unhandledRejection fails to occur if `.catch()` is used on the last promise",
        "body": "* **Version**: 12.13.1 / 13.3.0\r\n* **Platform**: `Linux lt2.cfware.com 5.3.11-200.fc30.x86_64 #1 SMP Tue Nov 12 19:25:25 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\nTake the following script:\r\n```js\r\n'use strict';\r\n\r\nPromise.reject('rejection 1');\r\nPromise.reject('rejection 2').catch(() => {});\r\n```\r\n\r\nThe expected result is an unhandledRejection for `rejection 1`.  This script produces no warnings on node.js 12 or 13.",
        "labels": "confirmed-bug",
        "id": 45074
    },
    {
        "title": "fs callback functions return Errors without stack",
        "body": "* **Version**: 13.3.0\r\n* **Platform**: Windows 10 x64\r\n```js\r\nconst fs = require('fs')\r\nfs.readFile('nonexistentfile', (err) => console.log(err.stack))\r\n```\r\n**What is the expected output?**\r\nThe err.stack should contain error text and stack\r\nSame as readFileSync function:\r\n> Error: ENOENT: no such file or directory, open 'nonexistentfile'\r\n>     at Object.openSync (fs.js:446:3)\r\n>     at Object.readFileSync (fs.js:348:35)\r\n> ...\r\n\r\n**What do you see instead?**\r\nerr.stack only contains error text\r\n> Error: ENOENT: no such file or directory, open 'C:\\dev\\projects\\ntest\\nonexistentfile'\r\n\r\n\r\n`fs.writeFile` have same trouble\r\nÐnother strange thing is that the error text is also different (local/absolute path)\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45075
    },
    {
        "title": "better error message for wasi",
        "body": "when `preopens` directory not really exists, Node.js failed with \r\n\r\n```console\r\nnode[55811]: ../src/node_wasi.cc:88:node::wasi::WASI::WASI(node::Environment *, Local<v8::Object>, uvwasi_options_t *): Assertion `(uvwasi_init(&uvw_, options)) == (0)' failed.\r\n 1: 0x100081683 node::Abort() [/usr/local/bin/node]\r\n 2: 0x10008142b node::AppendExceptionLine(node::Environment*, v8::Local<v8::Value>, v8::Local<v8::Message>, node::ErrorHandlingMode) [/usr/local/bin/node]\r\n 3: 0x1000e58be node::wasi::WASI::WASI(node::Environment*, v8::Local<v8::Object>, uvwasi_options_s*) [/usr/local/bin/node]\r\n 4: 0x1000e5e5b node::wasi::WASI::New(v8::FunctionCallbackInfo<v8::Value> const&) [/usr/local/bin/node]\r\n 5: 0x1001ec8d0 v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo) [/usr/local/bin/node]\r\n 6: 0x1001ebb9d v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<true>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/usr/local/bin/node]\r\n 7: 0x1001eb557 v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/usr/local/bin/node]\r\n 8: 0x100951939 Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_BuiltinExit [/usr/local/bin/node]\r\nfish: 'node --experimental-wasi-unstabâ€¦' terminated by signal SIGABRT (Abort)\r\n```\r\n\r\nRepro code:\r\n```js\r\n\"use strict\";\r\nconst fs = require('fs');\r\nconst { WASI } = require('wasi');\r\nconst wasi = new WASI({\r\n    args: process.argv,\r\n    env: process.env,\r\n    preopens: {\r\n        '/sandbox': '/not/real/path'\r\n    }\r\n})\r\n```\r\n\r\nI think maybe we can add some pre-check here ? The current error message doesn't provide much information.\r\n\r\ncc @nodejs/wasi ",
        "labels": "confirmed-bug",
        "id": 45076
    },
    {
        "title": "Exception message for assert(0) depends on whitespace",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10, 12\r\n* **Platform**: macOS High Sierra 10.13.6\r\n* **Subsystem**: Assert\r\n\r\n<!-- Please provide more details below this comment. -->\r\nUnder Node 10 and Node 12, generating an exception from an assertion failure returns a different assertion failure message depending on differences in whitespace. It seems that with a certain whitespace configuration we see the Node 8 assertion failure message `0 == true`, other configurations will generate the Node 10 message `The expression evaluated to a falsy value`.  This issue only seems to affect the exception message, all other behaviour seems consistent.\r\n\r\nThis will affect anything that runs minified source.\r\n\r\nI have included a simple reproduction of the issue [here](https://github.com/AndrewFinlay/node_exception_example)\r\n",
        "labels": "confirmed-bug",
        "id": 45077
    },
    {
        "title": "net: `write(cb)` not called if `destroy()`:ed before `'connect'`",
        "body": "See https://github.com/nodejs/node/pull/30839\r\n\r\n`_writeGeneric` waits for `'connect'` https://github.com/nodejs/node/blob/cf5ce2c9e1aab5eadbae107c697fdd11c6fb93a9/lib/net.js#L759 which might never be emitted due to https://github.com/nodejs/node/blob/cf5ce2c9e1aab5eadbae107c697fdd11c6fb93a9/lib/net.js#L1106-L1108\r\n\r\nI believe this will fail:\r\n```js\r\nconst socket = createSocketBeforeConnect();\r\nsocket.write('asd', common.mustCall());\r\nsocket.destroy();\r\n```",
        "labels": "confirmed-bug",
        "id": 45078
    },
    {
        "title": "Surprising require('./file') behavior when ran from REPL",
        "body": "## Where?\r\n\r\n* **Version**: v10.15.3, v12.13.1, v13.3.0\r\n* **Platform**: x86_64 GNU/Linux\r\n* **Subsystem**: require\r\n\r\n## Repo Steps\r\n\r\nGiven the following tree:\r\n\r\n```bash\r\nmkdir testrequire\r\ncd testrequire\r\n\r\nmkdir node_modules\r\necho 'module.exports = `yes`' > node_modules/foo.js\r\n```\r\n\r\nThe following code will produce different behavior when executed as a main module, required module, or from the REPL\r\n\r\n```js\r\nrequire('./foo') // this should always throw an error, but works on the REPL\r\n```\r\n\r\n## Tests\r\n\r\n### 1. As main module:\r\n\r\n```\r\nâ†ª echo 'require(`./foo`)' > main.js; node main.js\r\ninternal/modules/cjs/loader.js:800\r\n    throw err;\r\n    ^\r\n\r\nError: Cannot find module './foo'\r\n```\r\n\r\n### 2. As stdin input:\r\n\r\n```\r\nâ†ª echo 'require(`./foo`)' | node\r\ninternal/modules/cjs/loader.js:800\r\n    throw err;\r\n    ^\r\n\r\nError: Cannot find module './foo'\r\n```\r\n\r\n### 3. As REPL commands:\r\n\r\nThis is the surprising behavior\r\n\r\n```\r\nâ†ª node\r\nWelcome to Node.js v12.13.1.\r\nType \".help\" for more information.\r\n> require('./foo')\r\n'yes'\r\n```\r\n\r\n#### 4. As REPL but indirectly loaded\r\n\r\n```\r\nâ†ª echo 'require(`./foo`)' > main.js\r\nâ†ª node\r\nWelcome to Node.js v12.13.1.\r\nType \".help\" for more information.\r\n> require('./main')\r\nThrown:\r\nError: Cannot find module './foo'\r\n```\r\n\r\n## Is this a bug?\r\n\r\nI'm not sure if this is a bug or not, but it is quite surprising to me.\r\n\r\nI'd expect `require` to behave the same no matter from where it is being executed. Why is that the REPL behaves differently?\r\n",
        "labels": "confirmed-bug",
        "id": 45079
    },
    {
        "title": "primordials break REPL autocomplete with useGlobal: false",
        "body": "Discovered in https://github.com/nodejs/node/pull/30740\r\n\r\nWhen the REPL is started with `useGlobal: false`, the autocomplete for globals doesn't include values that are present in the primordials object.\r\nExample with Node.js 13.3.0:\r\n\r\n![image](https://user-images.githubusercontent.com/2352663/70158731-03193a80-16b8-11ea-9b1c-dd2f9cce8377.png)\r\n\r\nI pressed \"N\", \"TAB\", \"TAB\". The output doesn't include `Number`.\r\n",
        "labels": "confirmed-bug",
        "id": 45080
    },
    {
        "title": "investigate flaky parallel/test-readline-async-iterators-destroy in CI",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: master \r\n* **Platform**: linux-containerized\r\n* **Subsystem**: readline\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n\r\n```\r\nnot ok 1632 parallel/test-readline-async-iterators-destroy\r\n  ---\r\n  duration_ms: 0.177\r\n  severity: fail\r\n  exitcode: 1\r\n  stack: |-\r\n    events.js:194\r\n          throw er; // Unhandled 'error' event\r\n          ^\r\n    \r\n    Error: EBADF: bad file descriptor, read\r\n    Emitted 'error' event on ReadStream instance at:\r\n        at internal/fs/streams.js:183:12\r\n        at FSReqCallback.wrapper [as oncomplete] (fs.js:480:5) {\r\n      errno: -9,\r\n      code: 'EBADF',\r\n      syscall: 'read'\r\n    }\r\n  ...\r\n\r\n```\r\n\r\nref: https://ci.nodejs.org/job/node-test-commit-linux-containered/nodes=ubuntu1804_sharedlibs_openssl111_x64/16239/consoleText",
        "labels": "confirmed-bug",
        "id": 45081
    },
    {
        "title": "child_process normalization logic can be bypassed",
        "body": "The `child_process` module allows to bypass the JavaScript validation logic and to pass a custom array into C++, which then crashes the process:\r\n\r\n```js\r\nconst { spawn } = require('child_process');\r\n\r\nspawn('ls', Object.assign([], {\r\n  slice() {\r\n    return this;\r\n  },\r\n  unshift(arg) {\r\n    [].unshift.call(this, arg);\r\n    Object.defineProperty(this, '0', {\r\n      get() { throw new Error(); }\r\n    });\r\n  }\r\n}));\r\n```\r\n\r\nThis should be virtually impossible to exploit, so I am not marking this as a security issue.",
        "labels": "confirmed-bug",
        "id": 45082
    },
    {
        "title": "--experimental-resolve-self and exports sugar",
        "body": "Currently when using the `--experimental-resolve-self` flag, with the following:\r\n\r\n```json\r\n{\r\n  \"name\": \"test\",\r\n  \"exports\": \"./test.js\"\r\n}\r\n```\r\n\r\nIf including a `require('test')` in the `test.js` file and running `node --experimental-resolve-self pkg/test.js` this will throw an error.\r\n\r\nIt works with \"main\" and exports subpaths though so may be a sugar-specific or main-specific error case for this flag.",
        "labels": "confirmed-bug",
        "id": 45083
    },
    {
        "title": "[13.2.0] Assertion `(new_handler_count) >= (0)' failed",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `v13.2.0`\r\n* **Platform**: `Linux nicolo-XPS-15-9570 5.3.0-23-generic #25-Ubuntu SMP Tue Nov 12 09:22:33 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: ?\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nAfter upgrading from node 13.1.0 to 13.2.0, after running `lerna` node doesn't exit normally but crashes:\r\n\r\n```\r\nlerna success Bootstrapped 155 packages\r\n/home/nicolo/n/bin/node[20139]: ../src/signal_wrap.cc:159:void node::DecreaseSignalHandlerCount(int): Assertion `(new_handler_count) >= (0)' failed.\r\n 1: 0x9f0390 node::Abort() [/home/nicolo/n/bin/node]\r\n 2: 0x9f0417  [/home/nicolo/n/bin/node]\r\n 3: 0xa91bdc node::DecreaseSignalHandlerCount(int) [/home/nicolo/n/bin/node]\r\n 4: 0xa91cb4  [/home/nicolo/n/bin/node]\r\n 5: 0x98fbd5 node::Environment::CleanupHandles() [/home/nicolo/n/bin/node]\r\n 6: 0x98fe6b node::Environment::RunCleanup() [/home/nicolo/n/bin/node]\r\n 7: 0xa2d2f0 node::NodeMainInstance::Run() [/home/nicolo/n/bin/node]\r\n 8: 0x9c1311 node::Start(int, char**) [/home/nicolo/n/bin/node]\r\n 9: 0x7f14c1fd71e3 __libc_start_main [/lib/x86_64-linux-gnu/libc.so.6]\r\n10: 0x95ed25  [/home/nicolo/n/bin/node]\r\nAborted (core dumped)\r\n```\r\n\r\nSteps to reproduce this bug: (you need `make` and `yarn`)\r\n```\r\ngit clone https://github.com/babel/babel.git\r\ncd babel\r\nmake bootstrap\r\n```\r\n\r\ncc @addaleax (author of 55f98df303939774639bb597c6392c1c85bae6dd, which introduced the assertion)",
        "labels": "confirmed-bug",
        "id": 45084
    },
    {
        "title": "Crash when error.name is not a string",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `v12.13.0`. \r\n* **Platform**: `Darwin will.local 18.7.0 Darwin Kernel Version 18.7.0: Sat Oct 12 00:02:19 PDT 2019; root:xnu-4903.278.12~1/RELEASE_X86_64 x86_64`\r\n* **Subsystem**: `internal/util/inspect.js`\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThe following program crashes on node `v12.13.0`:\r\n\r\n##### `error-12.js`\r\n```js\r\nconst err = new Error('bloop');\r\nerr.name = 404;\r\nconsole.log(err);\r\n```\r\n\r\nwith the following logged:\r\n\r\n```\r\n$ node error-12.js\r\ninternal/util/inspect.js:880\r\n      name.endsWith('Error') &&\r\n           ^\r\n\r\nTypeError: name.endsWith is not a function\r\n    at formatError (internal/util/inspect.js:880:12)\r\n    at formatRaw (internal/util/inspect.js:681:14)\r\n    at formatValue (internal/util/inspect.js:569:10)\r\n    at inspect (internal/util/inspect.js:223:10)\r\n    at formatWithOptions (internal/util/inspect.js:1651:40)\r\n    at Object.Console.<computed> (internal/console/constructor.js:272:10)\r\n    at Object.log (internal/console/constructor.js:282:61)\r\n    at Object.<anonymous> (/Users/williammyers/projects/js/error-12.js:3:9)\r\n    at Module._compile (internal/modules/cjs/loader.js:774:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:785:10)\r\n```\r\n\r\nOn node `v10.15.1`, the program doesn't crash and instead logs:\r\n\r\n```\r\n$ node error-12.js\r\n{ 404: bloop\r\n    at Object.<anonymous> (/Users/williammyers/projects/js/error-12.js:1:75)\r\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\r\n    at Module.load (internal/modules/cjs/loader.js:599:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\r\n    at startup (internal/bootstrap/node.js:283:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:743:3) name: 404 }\r\n```\r\n\r\nI appreciate that node might not consider this a bug that is theirs to fix (the `name` property being non-string could be viewed as a userland error), but wanted to file the issue in case it was concerning. \r\n\r\nI discovered this doing an upgrade to node 12--it turns out the official [aws-sdk](https://github.com/aws/aws-sdk-js/blob/master/lib/util.js#L597) will set the `name` property of HTTP response errors to the _numeric_ HTTP response code. \r\n\r\nI suspect this was introduced in https://github.com/nodejs/node/commit/e54f237afe53324ff6d6f1504a40f26b9fe7711c. ",
        "labels": "confirmed-bug",
        "id": 45085
    },
    {
        "title": "Assertion: node_crypto.cc:2015: Assertion `(1) == (X509V3_EXT_print(bio.get(), ext, 0, 0))' failed.",
        "body": "* **Version**: 13.1.0 and 10.17.0\r\n* **Platform**: windows 64-bit\r\n* **Subsystem**: crypto / tls\r\n\r\nclient.js  (run-of-the-mill TLS client):\r\n```javascript\r\nconst tls = require(\"tls\");\r\nconst fs = require(\"fs\");\r\nconst client = tls.connect({\r\n\thost: \"localhost\",\r\n\tport: 12345,\r\n\tca: fs.readFileSync(\"./server.crt\"),\r\n}, () => {\r\n\tconsole.log(\"secureConnect\");\r\n\tclient.write(\"foo\");\r\n\tclient.end();\r\n});\r\nclient.setEncoding('utf8');\r\nclient.on(\"data\", (data) => {\r\n\tconsole.log(\"client.data\", data);\r\n});\r\nclient.on(\"end\", () => {\r\n\tconsole.log(\"client.end\");\r\n});\r\n```\r\n\r\nserver.js (run-of-the-mill TLS server):\r\n```javascript\r\nconst tls = require(\"tls\");\r\nconst fs = require(\"fs\");\r\n\r\nlet server = tls.createServer({\r\n\tcert: fs.readFileSync(\"./server.crt\"),\r\n\tkey: fs.readFileSync(\"./server.key\"),\r\n}, (socket) => {\r\n\tconsole.log(\"server.secureConnection\");\r\n\tsocket.setEncoding(\"utf8\");\r\n\tsocket.on(\"data\", (data) => {\r\n\t\tconsole.log(\"server.socket.data\", data);\r\n\t\tsocket.write(data);\r\n\t});\r\n\tsocket.on(\"end\", () => {\r\n\t\tconsole.log(\"server.socket.end\");\r\n\t});\r\n\tsocket.on(\"error\", console.error);\r\n});\r\nserver.listen({ port: 12345 }, () => {\r\n\tconsole.log(\"listening!\")\r\n});\r\n```\r\n\r\nserver.crt:\r\n```\r\n-----BEGIN CERTIFICATE-----\r\nMIIEFTCCAv2gAwIBAgIBATANBgkqhkiG9w0BAQUFADBvMRIwEAYDVQQDEwlsb2Nh\r\nbGhvc3QxCzAJBgNVBAYTAk5MMRYwFAYDVQQIEw1Ob29yZC1CcmFiYW50MRIwEAYD\r\nVQQHEwlFaW5kaG92ZW4xDDAKBgNVBAoTA0FCQjESMBAGA1UECxMJU3Bpcml0IElU\r\nMB4XDTE5MTExODA4MjIzN1oXDTI5MTExODA4MjIzN1owbzESMBAGA1UEAxMJbG9j\r\nYWxob3N0MQswCQYDVQQGEwJOTDEWMBQGA1UECBMNTm9vcmQtQnJhYmFudDESMBAG\r\nA1UEBxMJRWluZGhvdmVuMQwwCgYDVQQKEwNBQkIxEjAQBgNVBAsTCVNwaXJpdCBJ\r\nVDCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBALJjXZnfBDFer7oGt9pP\r\nN68yLEnKOaYpy31Bw4rNdpX4KgqwqeENKDgbmdl0kL7vEkAXNG6i+vfnGRlfuFw3\r\noGcKW+xCaTf/T/CJqCCKJnBYKoR3Oxz3iu99/9+5U5Z3wErpKPc4Cc5dwwOyrkvi\r\nbbm2AsFXtd7VL3fjgP+V0+HT3rsfPXJVzwuW7GD/8ujBT2LFgYqQ7a5JNJUIaECa\r\nQ20158H8YSDh42NHvE6/68yd9OELnu1ene/OYeSdWzZ3ejc1l63IcJtHnqnODc3W\r\nti9K2UTZFVdmA5xpMFcU3ni91tUlwduPplcWDfLGi8uXwUzBdGPQl+/+Ke+DqrmC\r\nBo8CAwEAAaOBuzCBuDAMBgNVHRMEBTADAQH/MAsGA1UdDwQEAwIC9DA7BgNVHSUE\r\nNDAyBggrBgEFBQcDAQYIKwYBBQUHAwIGCCsGAQUFBwMDBggrBgEFBQcDBAYIKwYB\r\nBQUHAwgwEQYJYIZIAYb4QgEBBAQDAgD3MCwGA1UdEQQlMCOGEGh0dHA6Ly9sb2Nh\r\nbGhvc3STCWxvY2FsaG9zdIcEfwAAATAdBgNVHQ4EFgQUOc37CHYprVsgXM0RC+PA\r\nNXMS22owDQYJKoZIhvcNAQEFBQADggEBACcwRa4GiLmFrR34rOjR3fwLq6m9r9Rb\r\nLny4WzHKwRLEDfe2yPuNZjoOG4XT80KWpgLopiWViR7WPkfDcbAN+sXmpmdc3Oxa\r\nTR7RsxfqnDYMp6PSO+3qQfTuz5sAsKf292Qu9BEJMkU8rWFmwmwNjRGZGoT06yCs\r\nDFxRFuyS+w1x3jZNbkMtwZiPHGwEkbWd8WY8UQXZR8Y3YpwipJn9EzCOOXKRokrJ\r\nZ7UTUKSrjIl6oHgrrhxBdw3kOUMKWx9M26A8Ua8Lyjbtcq3huy9M/J6DaZ6X4/Hs\r\ndIgL/SLdnc3WFonsCmfMk4iaJD5NE4NAYCIBWwq8RpThLm3UlPm0RVg=\r\n-----END CERTIFICATE-----\r\n```\r\n\r\nserver.key:\r\n```\r\n-----BEGIN RSA PRIVATE KEY-----\r\nMIIEpQIBAAKCAQEAsmNdmd8EMV6vuga32k83rzIsSco5pinLfUHDis12lfgqCrCp\r\n4Q0oOBuZ2XSQvu8SQBc0bqL69+cZGV+4XDegZwpb7EJpN/9P8ImoIIomcFgqhHc7\r\nHPeK733/37lTlnfASuko9zgJzl3DA7KuS+JtubYCwVe13tUvd+OA/5XT4dPeux89\r\nclXPC5bsYP/y6MFPYsWBipDtrkk0lQhoQJpDbTXnwfxhIOHjY0e8Tr/rzJ304Que\r\n7V6d785h5J1bNnd6NzWXrchwm0eeqc4Nzda2L0rZRNkVV2YDnGkwVxTeeL3W1SXB\r\n24+mVxYN8saLy5fBTMF0Y9CX7/4p74OquYIGjwIDAQABAoIBAB8QFnh40S4Xotnt\r\n2Y32RWgIgJXI1QkONhT1oqtE4+VxdUCvSqWZuOssQzoOhjX5Q2BNqh+p2bHZWBGH\r\nDX9hYFkRALi/R7sshisIjXI9HDxr3dt7N5vvrw3NDwVSLDADYkSpHS0PYQXCZfb6\r\n4kbsgtbXztsD/vNyg/WIdCoNWPv1slAa9qIOA/MofJK9K4e6hX3jOOx5E2uL7SkC\r\nMM9Na0EOxBe/+pghyQVefCRDi1tG2X/nkKYo1ouawK0/f9Wom8tf5R1G2juMdYDk\r\n8m6VV9uE41aN5o1J1atUqp1mGyX/af+WuQ3IqLNbvCgPYnxMQuWJ3zKg9f494A8D\r\n7G3KVIECgYEA31PAZ5RWldIvdcRUFNO/STFmhDDyXRGDoWZkPRzr7dAVreIgmIzT\r\nxZKANkYYH9QUcVSA6CiqJrURLT8ZRpJuaSTMIPKfseWJnXSFBsQO/zFLG8BUUA+7\r\nSuQhpCaA/cj7azjkMiuhq9gB1RjNrRrUx3ev9eFpJrbK6PaFyMn49T8CgYEAzHyE\r\no91atAnWYDJkTTzNU0MIKFZvGZ3GAfpX22zwxF/5b9XlmeqL5GhBQOFFXxCgBMnN\r\nutt2iUFZmVLe3PtsL5SeCOAJ+oGMczmJjv1nBU6mThXahx18LM3xGAhcxWgB8wkV\r\nIWXGLB3kOjO2aZmMtQ8ESY6xi5857pSVifY0CrECgYEA0ZyCUrXgLu8ArMCBSqsU\r\nN1auqhRm5wOxUKQSIWor5yIPtw0vGv/TJPXEcSyJKBaeuWBfPYgta/c3EAjRaHO4\r\nPefT0Hjpese+ypK66QbMLKnPnVR/zkV1vW0yRif9mjYyBQl45b4eGHS+A40sPvWY\r\nEUA9X8MaNsQK323DVBp+GXECgYEArLEgB49iEZgZPsZv5LbLpFyA4CgWzahr17HH\r\nTt1S/FUdP/CBZhopqGzPZu6Yem985G5VW1AKbGIPPCg7ZJ7Ev+4gBNjINJIBvjHC\r\nVUr2HQpN8rYMBn3FJ8WIrcYqKuDqfIiYGstrsEhSPUD89XOi3CnhcgmbMZH4B9/d\r\n5lRRoRECgYEA1vK9QtIDaW5pnWYDNnyZ7EFUcOLteuIP/xEdjc0gowvIfXwvjMPB\r\n6IWZVifow2OwGs44EgZ7hjPaB/4qTWZXcBhTJCzBOU/m0qovyAwBucqJbZOxhV+x\r\nab7NKOxOYy1UB3JJJknTvDLV+f/sQwieofNwsa+eKqYkoUx4ALj5m6I=\r\n-----END RSA PRIVATE KEY-----\r\n```\r\n\r\n1. Start node ./server.js\r\n2. Start node ./client.js\r\n\r\nOutput of client.js using node v10.17.0:\r\n```shell\r\n$ node ./client.js\r\nMINGW64:/c/Source/modules/exlent-est-client[17368]: c:\\ws\\src\\node_crypto.cc:1619: Assertion `(1) == (X509V3_EXT_print(bio.get(), ext, 0, 0))' failed.\r\n 1: 00007FF63CD37DDA v8::internal::GCIdleTimeHandler::GCIdleTimeHandler+4506\r\n 2: 00007FF63CD12876 node::MakeCallback+4534\r\n 3: 00007FF63CD1292F node::MakeCallback+4719\r\n 4: 00007FF63CC0E523 X509_getm_notAfter+69619\r\n 5: 00007FF63CC20981 X509_getm_notAfter+144465\r\n 6: 00007FF63D23E1D2 std::vector<v8::internal::compiler::MoveOperands * __ptr64,v8::internal::ZoneAllocator<v8::internal::compiler::MoveOperands * __ptr64> >::_Umove+79442\r\n 7: 00007FF63D23F65D std::vector<v8::internal::compiler::MoveOperands * __ptr64,v8::internal::ZoneAllocator<v8::internal::compiler::MoveOperands * __ptr64> >::_Umove+84701\r\n 8: 00007FF63D23E6B6 std::vector<v8::internal::compiler::MoveOperands * __ptr64,v8::internal::ZoneAllocator<v8::internal::compiler::MoveOperands * __ptr64> >::_Umove+80694\r\n 9: 00007FF63D23E59B std::vector<v8::internal::compiler::MoveOperands * __ptr64,v8::internal::ZoneAllocator<v8::internal::compiler::MoveOperands * __ptr64> >::_Umove+80411\r\n10: 0000013E942DC5C1\r\n```\r\n\r\n\r\nOutput of client.js using node v13.1.0:\r\n```shell\r\n$ node ./client.js \r\nMINGW64:/c/Source/modules/exlent-est-client[16720]: c:\\ws\\src\\node_crypto.cc:2015: Assertion `(1) == (X509V3_EXT_print(bio.get(), ext, 0, 0))' failed.\r\n 1: 00007FF7E882F22F napi_wrap+125087\r\n 2: 00007FF7E87CFAA6 v8::base::CPU::has_sse+35302\r\n 3: 00007FF7E87CFDC3 v8::base::CPU::has_sse+36099\r\n 4: 00007FF7E8711C11 EVP_PKEY_meth_set_keygen+4913\r\n 5: 00007FF7E86FCC84 uv_loop_size+62996\r\n 6: 00007FF7E8F9BE30 v8::internal::Builtins::builtin_handle+324848\r\n 7: 00007FF7E8F9B370 v8::internal::Builtins::builtin_handle+322096\r\n 8: 00007FF7E8F9B6B8 v8::internal::Builtins::builtin_handle+322936\r\n 9: 00007FF7E8F9B4BE v8::internal::Builtins::builtin_handle+322430\r\n10: 00007FF7E942B2FD v8::internal::SetupIsolateDelegate::SetupHeap+545005\r\n11: 00007FF7E93B0869 v8::internal::SetupIsolateDelegate::SetupHeap+42585 \r\n12: 00007FF7E93B0869 v8::internal::SetupIsolateDelegate::SetupHeap+42585 \r\n13: 00007FF7E93B0869 v8::internal::SetupIsolateDelegate::SetupHeap+42585\r\n14: 00007FF7E93B0869 v8::internal::SetupIsolateDelegate::SetupHeap+42585\r\n15: 00007FF7E93B0869 v8::internal::SetupIsolateDelegate::SetupHeap+42585\r\n16: 00007FF7E93ADD7E v8::internal::SetupIsolateDelegate::SetupHeap+31598\r\n17: 00007FF7E93AD96C v8::internal::SetupIsolateDelegate::SetupHeap+30556\r\n18: 00007FF7E8EF57D2 v8::internal::Execution::CallWasm+1410\r\n19: 00007FF7E8EF5149 v8::internal::Execution::Call+185\r\n20: 00007FF7E8FC68C0 v8::Function::Call+608\r\n21: 00007FF7E884B798 node::CallbackScope::~CallbackScope+1608\r\n22: 00007FF7E88449E3 v8::internal::interpreter::BytecodeNode::operand_scale+179\r\n23: 00007FF7E86ED34C std::basic_ostream<char,std::char_traits<char> >::put+27324\r\n24: 00007FF7E89A4662 SSL_set_tlsext_max_fragment_length+56898\r\n25: 00007FF7E89ADA31 SSL_is_init_finished+2913\r\n26: 00007FF7E89AD829 SSL_is_init_finished+2393\r\n27: 00007FF7E89D5524 SSL_set_default_read_buffer_len+3716\r\n28: 00007FF7E89CE0A0 i2d_SSL_SESSION+9680\r\n29: 00007FF7E89CE011 i2d_SSL_SESSION+9537\r\n30: 00007FF7E89C4747 SSL_write_ex+5943\r\n31: 00007FF7E89C1A02 SSL_read+66\r\n32: 00007FF7E86EA495 std::basic_ostream<char,std::char_traits<char> >::put+15365\r\n33: 00007FF7E86EA958 std::basic_ostream<char,std::char_traits<char> >::put+16584\r\n34: 00007FF7E86ECDC3 std::basic_ostream<char,std::char_traits<char> >::put+25907\r\n35: 00007FF7E874B175 v8::internal::Debug::break_frame_id+1093\r\n36: 00007FF7E88630FB uv_tty_set_vterm_state+8299\r\n37: 00007FF7E8877F5C uv_loop_init+844\r\n38: 00007FF7E8878294 uv_run+244\r\n39: 00007FF7E879C312 v8::internal::AsmJsScanner::GetIdentifierString+30882\r\n40: 00007FF7E87F72D0 node::Start+288\r\n41: 00007FF7E86B666C RC4_options+339308\r\n42: 00007FF7E94E1B08 v8::internal::SetupIsolateDelegate::SetupHeap+1292536\r\n43: 00007FFBD2D57BD4 BaseThreadInitThunk+20\r\n44: 00007FFBD346CED1 RtlUserThreadStart+33\r\n```\r\n\r\n\r\nThere is almost certainly something wrong with the server certificate content. However I would expect BOTH the server and client to throw a proper error instead of the client asserting.\r\n\r\n\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45086
    },
    {
        "title": "Assertion failed in napi_get_last_error_info for experimental N-API",
        "body": "* **Version**: v10.16.3\r\n* **Platform**: Linux\r\n\r\nIf NODE_EXPERIMENTAL is defined then `napi_get_last_error_info()` asserts due to the fact that it ignores experimental error codes (e.g. `napi_bigint_expected`):\r\n\r\n```\r\n../src/node_api.cc:1412:napi_status napi_get_last_error_info(napi_env, const napi_extended_error_info**):\r\nAssertion `(env->last_error.error_code) <= (napi_callback_scope_mismatch)' failed.\r\n```\r\n\r\nDocumentation does not say clearly whether nodejs should be recompiled with NODE_EXPERIMENTAL or not.",
        "labels": "confirmed-bug",
        "id": 45087
    },
    {
        "title": "util.format('%s', o) fails to call String(o) in certain cases",
        "body": "* **Version**: v12.12.0\r\n* **Platform**: Darwin [redacted] 18.7.0 Darwin Kernel Version 18.7.0: Sat Oct 12 00:02:19 PDT 2019; root:xnu-4903.278.12~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: util\r\n\r\nI was very surprised to discover that in node v12, `util.format('%s', v)` does not consistently call `String(v)`.  Checking [the docs](https://nodejs.org/api/util.html#util_util_format_format_args), I read:\r\n\r\n> `%s`: `String` will be used to convert all values except `BigInt`, `Object` and `-0`. `BigInt` values will be represented with an `n` and Objects that have no user defined `toString` function are inspected using `util.inspect()` with options `{ depth: 0, colors: false, compact: 3 }`.\r\n\r\nThis is a surprising (and in my view undesirable) change from the previous behaviour, which was to consistently call `String` in response to `%s`.  It also appears to be a semantically breaking change introduced, via #27621 and #27799, in 12.3.0, despite that not being a new major version.  If so, it should be entirely reverted (and good riddance, in my opinion).\r\n\r\nIf there is some compelling argument for why the new behaviour is actually desirable, then at least the code should be made consistent with the documentation or vice versa.\r\n\r\nIn particular, whether a user defined toString function is called depends in non-documented and non-obvious ways on the value of the `.constructor` property of the object, which is otherwise normally of no significance:\r\n\r\n```JS\r\n// ES6 subclassing:\r\nclass A {\r\n  toString() { return 'custom A'; }\r\n}\r\nclass B extends A {}\r\n\r\n// ES5 subclassing:\r\nfunction C() {}\r\nC.prototype.toString = function() { return 'custom C'; };\r\n\r\nfunction D() { C.call(this); }\r\nD.prototype = Object.create(C.prototype);\r\n// What if we forget to set the .constructor?\r\n// D.prototype.constructor = D;\r\n\r\nconsole.log('%s', new A());\r\nconsole.log('%s', new B());\r\nconsole.log('%s', new C());\r\nconsole.log('%s', new D());\r\n\r\n// Fix forgotten .constructor:\r\nD.prototype.constructor = D;\r\nconsole.log('%s', new D());\r\n```\r\n\r\nActual output:\r\n\r\n```\r\ncustom A\r\nB {}\r\ncustom C\r\ncustom C\r\nD {}\r\n```\r\n\r\nExpected / documented output:\r\n\r\n```\r\ncustom A\r\ncustom A\r\ncustom C\r\ncustom C\r\ncustom C\r\n```\r\n\r\nConsistently applying the documented behaviour would go some way to remedying the breaking nature of this change, since at least user supplied `.toString` implementations would always be called, as was previously the case.\r\n",
        "labels": "confirmed-bug",
        "id": 45088
    },
    {
        "title": "A package.json lacking a \"type\" field is not treated as if it contained \"type\": \"commonjs\"",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 13.0.1\r\n* **Platform**: macOS Mojave\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n[ECMAScript modules Document](https://nodejs.org/api/esm.html#esm_package_scope_and_file_extensions) says:\r\n\r\n> A package.json lacking a `\"type\"` field is treated as if it contained `\"type\": \"commonjs\"`.\r\n\r\nTo confirm this, I have created folders and files as follows (file contents are written after colons).\r\n\r\n```\r\nroot/\r\n  package.json   : { \"type\": \"module\" }\r\n  sub1/\r\n    foo.js       : const fs = require('fs');\r\n    package.json : {}\r\n  sub2/\r\n    foo.js       : const fs = require('fs');\r\n    package.json : { \"repository\": { \"type\": \"git\" } }\r\n```\r\n\r\nWhen I execute `$ node --experimental-modules ./sub1/foo.js` in the `root` folder, it results in an error `Error [ERR_REQUIRE_ESM]: Must use import to load ES Module`, while `$ node --experimental-modules ./sub2/foo.js` does not throw any error.\r\nTherefore, the document is incorrect and it is likely non-top-level `\"type\"` fields in `package.json` file affects whether the JS files are treated as ES modules or CommonJS modules.",
        "labels": "confirmed-bug",
        "id": 45089
    },
    {
        "title": "Strange Ñlosure variable value in node 12 and 13 ",
        "body": "**Version:** v12.4.0 and v13.0.1\r\n**Platform:** Linux 5.3.7-arch1-2-ARCH\r\n\r\nMinimum code to reproduce:\r\n```js\r\nlet id = 0;\r\nconst genId = () => (id)++;\r\n\r\nfor (let i = 0; i < 10000; i++) {\r\n    console.log(genId());\r\n}\r\n```\r\nIn node 12 and 13 it doesn't output values 1..9999. It outputs values sequentially till some value, for example 6146 and then repeats this value.\r\nHowever this snippet works as expected in node 10 and 8 (that is where I checked).\r\nAlso it works correctly in node 12 and 13 if there is no parentheses around id variable:\r\n```js\r\nlet id = 0;\r\nconst genId = () => id++;\r\n\r\nfor (let i = 0; i < 10000; i++) {\r\n    console.log(genId());\r\n}\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45090
    },
    {
        "title": "EventEmitter memory leak with socket bind",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8.16.0 and greater\r\n* **Platform**: MacOS\r\n* **Subsystem**: dgram socket\r\n\r\n<!-- Please provide more details below this comment. -->\r\nWhen binding to a broadcast socket using-\r\n\r\n```\r\nconst doSocketBind = () => {\r\n    this.socket.bind(broadcastPort, undefined, () => {\r\n        console.log('Success');\r\n    });\r\n};\r\n```\r\n\r\nAnd retrying the bind after a failure-\r\n\r\n```\r\nthis.socket.on('error', (err: Error) => {\r\n    if (err['code'] === 'EADDRINUSE') {\r\n        setTimeout(() => {\r\n            doSocketBind();\r\n        }, 5000);\r\n    }\r\n});\r\n```\r\n\r\nAfter a few failures I receive this message-\r\n\r\n`(node:68039) MaxListenersExceededWarning: Possible EventEmitter memory leak detected. 11 listening listeners added. Use emitter.setMaxListeners() to increase limit`\r\n\r\nFor example, if something else has bound to the same broadcast port and has locked the port.\r\n\r\nThe issue is caused by-\r\n\r\nhttps://github.com/nodejs/node/blob/eac614332be7453633273cdd20aedd15295e551c/lib/dgram.js#L194\r\n\r\n`arguments[arguments.length - 1]` is intended to be the callback.  In the case of a failure, the callback doesn't execute and the callback remains in the event queue waiting to be executed.  If there are 10 bind failures the callback will execute 10 times after being able to successfully bind in the 11th retry.\r\n\r\nA workaround-\r\n\r\nDefine the callback as a named function and remove the callback if an error is encountered.\r\n\r\n```\r\nthis.socket.on('error', (err: Error) => {\r\n    this.socket.removeListener('listening', onSocketBind);\r\n\r\n    if (err['code'] === 'EADDRINUSE') {\r\n        setTimeout(() => {\r\n            doSocketBind();\r\n        }, 5000);\r\n    }\r\n});\r\n```",
        "labels": "confirmed-bug",
        "id": 45091
    },
    {
        "title": "errors with --experimental-loader trigger unhandled rejections in core",
        "body": "```\r\n$ node --experimental-modules --experimental-loader i-dont-exist test.mjs\r\n(node:480349) ExperimentalWarning: The ESM module loader is experimental.\r\n(node:480349) ExperimentalWarning: --experimental-loader is an experimental feature. This feature could change at any time\r\n(node:480349) UnhandledPromiseRejectionWarning: Error: Cannot find package 'i-dont-exist' imported from /home/mzasso/test/m/\r\n    at Loader.resolve [as _resolve] (internal/modules/esm/default_resolve.js:84:13)\r\n    at Loader.resolve (internal/modules/esm/loader.js:74:33)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:148:40)\r\n    at Loader.import (internal/modules/esm/loader.js:132:28)\r\n    at internal/process/esm_loader.js:60:31\r\n    at Object.initializeLoader (internal/process/esm_loader.js:64:5)\r\n    at runMainESM (internal/bootstrap/pre_execution.js:480:20)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:1049:5)\r\n    at internal/main/run_main_module.js:16:11\r\n(node:480349) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 2)\r\n(node:480349) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n```\r\n\r\n```\r\n$ node --experimental-modules --experimental-loader ./i-have-syntax-error.mjs test.mjs\r\n(node:480438) ExperimentalWarning: The ESM module loader is experimental.\r\n(node:480438) ExperimentalWarning: --experimental-loader is an experimental feature. This feature could change at any time\r\n(node:480438) UnhandledPromiseRejectionWarning: SyntaxError: Unexpected end of input\r\n    at Loader.moduleStrategy (internal/modules/esm/translators.js:84:18)\r\n    at async link (internal/modules/esm/module_job.js:36:21)\r\n(node:480438) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 1)\r\n(node:480438) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n```",
        "labels": "confirmed-bug",
        "id": 45092
    },
    {
        "title": "Cannot compile node",
        "body": "Cannot compile node 13.0.1 with flags `./configure --fully-static --with-intl=full-icu` inside docker image for node\r\n\r\nGetting this output\r\n\r\n```\r\n  LD_LIBRARY_PATH=/node/out/Release/lib.host:/node/out/Release/lib.target:$LD_LIBRARY_PATH; export LD_LIBRARY_PATH; cd ../tools/v8_gypfiles; mkdir -p /node/out/Release/obj/gen/src/regexp; python ../../deps/v8/tools/run.py \"/node/out/Release/gen-regexp-special-case\" \"/node/out/Release/obj/gen/src/regexp/special-case.cc\"\r\ntools/v8_gypfiles/run_gen-regexp-special-case.target.mk:13: recipe for target '/node/out/Release/obj/gen/src/regexp/special-case.cc' failed\r\nmake[1]: *** [/node/out/Release/obj/gen/src/regexp/special-case.cc] Error 245\r\nmake[1]: *** Waiting for unfinished jobs....\r\nrm 889aa6e08bf291915b2edfb5755eacba271e7d14.intermediate\r\nMakefile:101: recipe for target 'node' failed\r\nmake: *** [node] Error 2\r\n```\r\n\r\nSteps to reproduce: \r\n1) Install docker\r\n2) `docker run -it node bash`\r\n//inside docker shell\r\n3) `git clone https://github.com/nodejs/node.git`\r\n4) `cd node`\r\n5) `git checkout v13.0.1`\r\n6) `./configure --fully-static --with-intl=full-icu`\r\n7) `make -j8`\r\n\r\nAlso not working with flags `./configure --fully-static --enable-static --with-intl=full-icu` with the same error\r\n\r\nBut it compiles without errors with version 11.1.0 with flags `./configure --fully-static --with-intl=full-icu --download=all`",
        "labels": "confirmed-bug",
        "id": 45093
    },
    {
        "title": "Thrown an Error from queueMicrotask's callback aborted the process",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `v12.13.0`\r\n* **Subsystem**: `global`\r\n\r\n\r\n* **Platform**: `Linux rankong-wacai-env 4.9.125-linuxkit #1 SMP Fri Sep 7 08:20:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux`\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n![image](https://user-images.githubusercontent.com/3054411/67365445-3d18fc00-f5a4-11e9-8a2f-35e580c172d7.png)\r\n\r\n* **Platform**: `Darwin RanWithMeow-RMPB 18.7.0 Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64 x86_64`\r\n\r\n![image](https://user-images.githubusercontent.com/3054411/67365552-6b96d700-f5a4-11e9-94be-751376f48c28.png)\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45094
    },
    {
        "title": "--use-strict flag doesn't apply strict mode to script",
        "body": "* Node 12.*:\r\n* Windows 64bit, Debian 64bit:\r\n\r\nThe `--use-strict` flag doesn't apply strict mode to script.\r\nreproduction:\r\n```\r\necho a = 1 > test.js && node --use-strict test\r\n```\r\nexpected behavior:\r\n    `ReferenceError: a is not defined` is thrown.\r\nbehavior:\r\n    script executes without any issue.\r\n\r\nhowever it works as expected when node is started first and script is called from repl.\r\n<12 versions aren't affected. \r\n\r\n```\r\nnode --use-strict\r\nWelcome to Node.js v12.12.0.\r\nType \".help\" for more information.\r\n> a = 1\r\nThrown:\r\nReferenceError: a is not defined\r\n>\r\n```",
        "labels": "confirmed-bug",
        "id": 45095
    },
    {
        "title": "possible libuv issue with macos 10.15: empty udp message not registering",
        "body": "* **Version**:\r\nv12.12.0\r\n* **Platform**:\r\nmacos catalina/10.15 (19A602)\r\n* **Subsystem**:\r\nn/a\r\n<!-- Please provide more details below this comment. -->\r\nWhen sending an empty udp message, the message will not be received until another non-empty udp message is received.\r\n\r\nExample/Reproduce: (may only affect macos 10.15?)\r\n\r\n\r\nfile `server.js`\r\n```\r\nvar PORT = 33333;\r\nvar HOST = '127.0.0.1';\r\n\r\nvar dgram = require('dgram');\r\nvar server = dgram.createSocket('udp4');\r\n\r\nserver.on('listening', function() {\r\n  var address = server.address();\r\n console.log('UDP Server listening on ' + address.address + ':' + address.port);\r\n});\r\n\r\nserver.on('message', function(message, remote) {\r\n console.log(remote.address + ':' + remote.port +' - ' + message);\r\n});\r\n\r\nserver.bind(PORT, HOST);\r\n```\r\n\r\nfile `client_test.js`\r\n\r\n```\r\nvar PORT = 33333;\r\nvar HOST = '127.0.0.1';\r\n\r\nvar dgram = require('dgram');\r\n\r\n\r\nvar client = dgram.createSocket('udp4');\r\nvar message = Buffer.from('abc');\r\n\r\nclient.send(message, 0, message.length, PORT, HOST, function(err, bytes) {\r\n  if (err) throw err;\r\n  console.log('UDP message sent to ' + HOST +':'+ PORT);\r\n  client.close();\r\n});\r\n```\r\n\r\nfile `client_0.js`\r\n\r\n```\r\nvar PORT = 33333;\r\nvar HOST = '127.0.0.1';\r\n\r\nvar dgram = require('dgram');\r\n\r\n\r\nvar client = dgram.createSocket('udp4');\r\nvar message = Buffer.from('');\r\n\r\nclient.send(message, 0, message.length, PORT, HOST, function(err, bytes) {\r\n  if (err) throw err;\r\n  console.log('UDP message sent to ' + HOST +':'+ PORT);\r\n  client.close();\r\n});\r\n```\r\n\r\n\r\nrun the server code, then run the `client_0.js`: no response in server.\r\nfollowed by running client_test.js: server got empty and the \"abc\" message.",
        "labels": "confirmed-bug",
        "id": 45096
    },
    {
        "title": "attempting to use a readstream to read a specific size of bytes no longer works properly with Node 10",
        "body": "Here's my OS info:\r\nEdition: Windows 10\r\nVersion: 1903\r\nOS Build: 18362.356\r\n\r\nHere's the output from Node 10.16.3 x64\r\n```\r\nc:\\code\\temp>node -v\r\nv10.16.3\r\n\r\nc:\\code\\temp>node readBytes.js\r\nsize > bufferSize : true\r\nnull segment: true\r\nnull segment: true\r\n```\r\n\r\nHere's the output from Node 8.15.1 x64\r\n```\r\nc:\\code\\temp>node -v\r\nv8.15.1\r\n\r\nc:\\code\\temp>node readBytes.js\r\nsize > bufferSize : true\r\nnull segment: true\r\nnull segment: true\r\nnull segment: false\r\nnull segment: true\r\nnull segment: false\r\nnull segment: true\r\nnull segment: false\r\nnull segment: true\r\ndone! 3 chunks\r\n```\r\n\r\nhere's the contents of *readBytes.js* which illustrates the problem\r\n```\r\nconst fs = require('fs');\r\nconst filepath = 'C:/code/temp/21_MB_File';\r\nconst bufferSize = 10 * 1024 * 1024;\r\n\r\nconst chunks = [];\r\nconst stats = fs.statSync(filepath);\r\nconsole.log(`size > bufferSize : ${stats.size > bufferSize}`);\r\n\r\nconst readableStream = fs.createReadStream(filepath);\r\nlet segmentIndex = 1;\r\nreadableStream.on('readable', () => {\r\n\tlet segment = readableStream.read(bufferSize);\r\n\tconsole.log(`null segment: ${segment === null}`);\r\n\twhile (segment !== null) {\r\n\t\tchunks.push({ index: segmentIndex++, body: segment });\r\n\t\tsegment = readableStream.read(bufferSize);\r\n\t\tconsole.log(`null segment: ${segment === null}`);\r\n\t}\r\n});\r\nreadableStream.on('end', () => {\r\n\tconsole.log(`done! ${chunks.length} chunks`);\r\n});\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45097
    },
    {
        "title": "crypto: Assertation failed when createPrivateKey(PUBLIC)",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 12.11.1 and 12.7.0 (and more, i believe)\r\n* **Platform**: Linux dev 5.3.5-arch1-1-ARCH #1 SMP PREEMPT Mon Oct 7 19:03:08 UTC 2019 x86_64 GNU/Linux\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n`crypto.createPrivateKey` raise an assertation failure when trying to import a public key.\r\n\r\nOutput of v12.11.1:\r\n\r\n```\r\n> keyPair.publicKey.export({format:'der',type:'spki'}).toString('base64')\r\n'PUBLIC_KEY_IN_BASE64'\r\n> pubkey=require('crypto').createPrivateKey({key:Buffer.from('PUBLIC_KEY_IN_BASE64','base64'),format:'der',type:'spki'})\r\nnode[8267]: ../src/node_crypto.cc:3299:node::crypto::ParseKeyResult node::crypto::ParsePrivateKey(node::crypto::EVPKeyPointer*, const node::crypto::PrivateKeyEncodingConfig&, const char*, size_t): Assertion `(config.type_.ToChecked()) == (kKeyEncodingSEC1)' failed.\r\n 1: 0x9d33e0 node::Abort() [node]\r\n 2: 0x9d3467  [node]\r\n 3: 0xace6ea  [node]\r\n 4: 0xadf83e  [node]\r\n 5: 0xae03e7 node::crypto::KeyObject::Init(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 6: 0xb9ec19  [node]\r\n 7: 0xba0a07 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 8: 0x136d639  [node]\r\nAborted (core dumped)\r\n```\r\n\r\nI have tried `keyPair=require('crypto').generateKeyPairSync('rsa',{modulusLength:4096})` and `keyPair=require('crypto').generateKeyPairSync('ec',{namedCurve:'P-256'})`, the result are the same.",
        "labels": "confirmed-bug",
        "id": 45098
    },
    {
        "title": "ClientHttp2Session doesn't acknowledge new settings",
        "body": "Demo:\r\n\r\nhttps://runkit.com/szmarczak/5d90f849ecc28e001ac8f3e1\r\n\r\nCurrent output:\r\n```\r\nclient side - 4294967295\r\nclient side - 4294967295\r\nserver side - 4294967295\r\nserver side - 2\r\n```\r\n\r\nExpected output:\r\n```\r\nclient side - 4294967295\r\nclient side - 2\r\nserver side - 4294967295\r\nserver side - 2\r\n```\r\n\r\nAs per the spec:\r\n### [6.5. SETTINGS](https://httpwg.org/specs/rfc7540.html#SETTINGS)\r\n\r\n> SETTINGS parameters are not negotiated; they describe characteristics of the sending peer, which are used by the receiving peer. Different values for the same parameter can be advertised by each peer. For example, a client might set a high initial flow-control window, whereas **a server might set a lower value to conserve resources**.\r\n\r\n> A SETTINGS frame MUST be sent by both endpoints at the start of a connection and **MAY be sent at any other time by either endpoint over the lifetime of the connection**. Implementations MUST support all of the parameters defined by this specification.\r\n\r\n> **Each parameter in a SETTINGS frame replaces any existing value for that parameter**. Parameters are processed in the order in which they appear, and **a receiver of a SETTINGS frame does not need to maintain any state other than the current value of its parameters**. Therefore, **the value of a SETTINGS parameter is the last value that is seen by a receiver**.\r\n\r\nSounds like a bug.",
        "labels": "confirmed-bug",
        "id": 45099
    },
    {
        "title": "Possible regression in Node v12.11.0's Proxy",
        "body": "* **Version**: v12.11.0\r\n* **process.versions**: \r\n```js\r\nprocess.versions\r\n{\r\n  node: '12.11.0',\r\n  v8: '7.7.299.11-node.12',\r\n  uv: '1.32.0',\r\n  zlib: '1.2.11',\r\n  brotli: '1.0.7',\r\n  ares: '1.15.0',\r\n  modules: '72',\r\n  nghttp2: '1.39.2',\r\n  napi: '5',\r\n  llhttp: '1.1.4',\r\n  http_parser: '2.8.0',\r\n  openssl: '1.1.1c',\r\n  cldr: '35.1',\r\n  icu: '64.2',\r\n  tz: '2019a',\r\n  unicode: '12.1'\r\n}\r\n```\r\n* **Platform**: Darwin pmbp 18.7.0 Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**: V8\r\n\r\n\r\nRunning this in node v12.11.0 fails:\r\n\r\n```js\r\nObject.getPrototypeOf(new Proxy(Object.create(null), {\r\n  getPrototypeOf(target) {\r\n    return Reflect.getPrototypeOf(target)\r\n  }\r\n}))\r\n```\r\n\r\nPasting it in node's REPL gives this error:\r\n```\r\nThrown:\r\nTypeError: 'getPrototypeOf' on proxy: trap returned neither object nor null\r\n    at Function.getPrototypeOf (<anonymous>)\r\n```\r\n\r\nExpected behavior: it should just print `null`.",
        "labels": "confirmed-bug",
        "id": 45100
    },
    {
        "title": "fs,macos: fs.watch() behavior change in node >= 10.16.0",
        "body": "This is a container bug for issues caused by PR https://github.com/libuv/libuv/pull/2082. Disparate reports but the root cause is the linked PR.\r\n\r\n#25856 \r\n#27869\r\n#28512\r\n#28882\r\n#28917\r\n\r\nFixing it turned out to be not so easy (https://github.com/libuv/libuv/pull/2313) and simply reverting trades one regression for another.",
        "labels": "confirmed-bug",
        "id": 45101
    },
    {
        "title": "crypto: frozen on RSA key generation with public exponent 3",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10.16.3\r\n* **Platform**: Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\nNodeJS is frozen on RSA key generation with public exponent 3. It works fine in NodeJS v12\r\n```js\r\nconst crypto = require(\"crypto\");\r\n\r\nconst keys = crypto.generateKeyPairSync(\"rsa\", {\r\n  modulusLength: 2048,\r\n  publicExponent: 3,\r\n  publicKeyEncoding: {\r\n    format: \"der\",\r\n    type: \"spki\",\r\n  },\r\n  privateKeyEncoding: {\r\n    format: \"der\",\r\n    type: \"pkcs8\",\r\n  },\r\n});\r\n\r\nconsole.log(keys);\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45102
    },
    {
        "title": "repl: bug in fs module autocompletion",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: macOS X 10.14.4\r\n* **Subsystem**: repl\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nSmall bug on macOS (when, e.g., I have `node-core-utils` in `/Users/Projects`):\r\n\r\n```js\r\nfs.readFileSync('node-<tab>\r\n\r\nEXPECTED: fs.readFileSync('node-core-utils\r\nACTUAL:   fs.readFileSync('node-ode-core-utils\r\n```\r\n\r\nRefs: https://github.com/nodejs/node/pull/26648#issuecomment-493638851\r\n\r\ncc @antsmartian ",
        "labels": "confirmed-bug",
        "id": 45103
    },
    {
        "title": "Emission of secure events changed across versions of node",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8.16.1, v10.16.3, v12.8.1\r\n* **Platform**: Linux tufopad 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: tls\r\n\r\n<!-- Please provide more details below this comment. -->\r\nIt seems to be a bit of discordance in the emission of the `secure` event across versions of node and also if you use the deprecated `createSecurePair` vs `new tls.TLSSocket`.\r\n\r\n# Steps to reproduce\r\nFirst, you'll need to clone [this repo](https://github.com/tufosa/tls-secure-event) containing the sample code.\r\n\r\nThis program starts a `tls.Server`, and then two clients, one using the deprecated `createSecurePair` and the other using `tls.TLSSocket`. It just opens the connections and wait for the different events to trigger. Each event leaves a trace. It reproduces 2 cases per client (4 in total): one just opening the connection (`write: false`) and the other opening the connection and immediately writing an empty string to the socket (`write: true`). Therefore the 4 cases are:\r\n\r\n- SecurePair-write-false\r\n- SecurePair-write-true\r\n- TLSSocket-write-false\r\n- TLSSocket-write-true\r\n\r\nIn order to reproduce the bug, run `node main.js` using different versions of nodejs and observe the differences in behaviour through the traces left by the program. It seems like both the `secure` and `secureConnection` events are emitted with different criteria depending on the version of node used.\r\n\r\nI undestand that `createSecurePair` is deprecated and therefore should not be used, but I believe that the new way of doing things (`tls.TLSSocket`) should have the same behaviour as the old `createSecurePair` in order to make the transition easier. It seems reasonable to wait for the `secure` event before attempting to write anything. This is how the old `createSecurePair` behaved in node v8.16.1, but this behaviour has been changed in node 10 and node 12.\r\n\r\nAlso [the documented `secureConnect`](https://nodejs.org/docs/latest-v8.x/api/tls.html#tls_event_secureconnect) event is never emitted. An undocumented `secure` event is emitted instead. I see that this has been reported before (at least [here](https://github.com/nodejs/node/issues/10555) and [here](https://github.com/nodejs/node/issues/13368)), but the docs haven't been fixed.\r\n\r\n## node v8.16.1\r\n```\r\nCreating SecurePair write false client...\r\n(node:31271) [DEP0064] DeprecationWarning: tls.createSecurePair() is deprecated. Please use tls.TLSSocket instead.\r\nsecureConnection\r\nsecure\r\n\r\nCreating TLSSocket write false client...\r\nERROR:  TLSSocket with write false did NOT receive secure event\r\n\r\nCreating SecurePair write true client...\r\nsecureConnection\r\nsecure\r\n\r\nCreating TLSSocket write true client...\r\nsecureConnection\r\nsecure\r\n\r\nFinished\r\n```\r\nThe only case not emitting any event is TLSSocket-write-false.\r\n\r\n## node v10.16.3\r\n```\r\nCreating SecurePair write false client...\r\n(node:31533) [DEP0064] DeprecationWarning: tls.createSecurePair() is deprecated. Please use tls.TLSSocket instead.\r\nERROR:  SecurePair with write false did NOT receive secure event\r\n\r\nCreating TLSSocket write false client...\r\nERROR:  TLSSocket with write false did NOT receive secure event\r\n\r\nCreating SecurePair write true client...\r\nsecureConnection\r\nsecure\r\n\r\nCreating TLSSocket write true client...\r\nsecureConnection\r\nsecure\r\n\r\nFinished\r\n```\r\nAll write-false cases fail (as in do not emit events) and all write-true cases\r\npass.\r\n\r\n## node v12.8.1\r\n```\r\nCreating SecurePair write false client...\r\n(node:31828) [DEP0064] DeprecationWarning: tls.createSecurePair() is deprecated. Please use tls.TLSSocket instead.\r\nERROR:  SecurePair with write false did NOT receive secure event\r\n\r\nCreating TLSSocket write false client...\r\nERROR:  TLSSocket with write false did NOT receive secure event\r\n\r\nCreating SecurePair write true client...\r\nsecure\r\n\r\nCreating TLSSocket write true client...\r\nsecureConnection\r\nsecure\r\n\r\nFinished\r\n```\r\nAll write-false cases fail and the write-true cases behave slightly different,\r\nas one of them (SecurePair-write-true) never emit the `secureConnection` event.\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45104
    },
    {
        "title": "Looping async functions with Promise.race() allocates excessive memory",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.15.3, node 12.0.0-nightly20190331bb98f27181, node 12.0.0-v8-canary201903313c649ecee6, v13.0.0-nightly20190822775048d54c\r\n* **Platform**: Ubuntu 14.04.5 LTS, Trusty Tahr x64 / Win7x64, \r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n[Test case](https://gist.github.com/Slayer95/1aed510b091dbacacbb3d4e61704a1a8): https://gist.github.com/Slayer95/1aed510b091dbacacbb3d4e61704a1a8\r\n\r\n**What steps will reproduce the problem?**\r\n1. Run the test case.\r\n2. Watch the memory consumption. Increase total run time with the constant SUITE_SIZE\r\n\r\n**What is the expected output?**\r\nMemory consumption is kept constant.\r\n\r\n**What do you see instead?**\r\nAn increasingly high memory consumption over time, and the process crashes for OOM.\r\n\r\n**Supporting info:**\r\n- Memory consumption was constant under Node 8.15.1\r\n- Switching the deepCloneSync() function for any of its commented-out variants removes the leak.\r\n- Awaiting for a setImmediate() to resolve every nth \"game\" is run suppresses the leak.\r\n\r\nOriginally reported as https://bugs.chromium.org/p/v8/issues/detail?id=9069\r\n\r\n/cc @MayaLekova ",
        "labels": "confirmed-bug",
        "id": 45105
    },
    {
        "title": "12.9.0 is it a bug?",
        "body": "version: 12.9.0\r\ngcc: 8.2\r\n\r\nmessage:\r\n```\r\n#\r\n# Fatal error in , line 0\r\n# Check failed: (isolate_->embedded_blob()) != nullptr.\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 0x7fff837402c0  (core dumped)\r\n```\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45106
    },
    {
        "title": "tools: check-imports.py false negatives",
        "body": "Refs: #29222\r\n\r\nAs that PR shows, there are some unused imports that `tools/check-imports.py` doesn't catch because:\r\n\r\n1. They're used in comments.\r\n2. The tool doesn't match at word boundaries (e.g. `FromJust` is considered a use of `Just`.)",
        "labels": "confirmed-bug",
        "id": 45107
    },
    {
        "title": "Issues with net.Server when using a pipe",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: current master\r\n* **Platform**: Unix, at least Ubuntu 18.04. The callback issue also affects Windows.\r\n* **Subsystem**: net\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nDiscovered while working on https://github.com/nodejs/node/pull/28858. I investigated this for a while but wasn't able to solve the issue. Opening this to keep track, or to get an explanation if someone knows what's going on.\r\n\r\nThere seem to be two (possibly related) issues when using a pipe with net.Server:\r\n\r\n<details>\r\n<summary>The pipe file descriptor is not closed (or one of them? there seems to be more than one in some cases).</summary>\r\n\r\nPatch to reproduce:\r\n```diff\r\ndiff --git a/test/parallel/test-child-process-server-close.js b/test/parallel/test-child-process-server-close.js\r\nindex d70926f2e8..180f51499d 100644\r\n--- a/test/parallel/test-child-process-server-close.js\r\n+++ b/test/parallel/test-child-process-server-close.js\r\n@@ -7,6 +7,13 @@ const net = require('net');\r\n const tmpdir = require('../common/tmpdir');\r\n tmpdir.refresh();\r\n\r\n+const { execSync } = require('child_process');\r\n+const lsof = `lsof -p ${process.pid} | grep -e ^COMMAND -e tmp`;\r\n+process.on('exit', () => {\r\n+  const openFiles = execSync(lsof, { encoding: 'utf8' });\r\n+  console.error(`Open files (${lsof}):\\n${openFiles}`);\r\n+});\r\n+\r\n const server = net.createServer((conn) => {\r\n   spawn(process.execPath, ['-v'], {\r\n     stdio: ['ignore', conn, 'ignore']\r\ndiff --git a/test/parallel/test-tls-wrap-econnreset-pipe.js b/test/parallel/test-tls-wrap-econnreset-pipe.js\r\nindex b400e35d41..5d1070b63c 100644\r\n--- a/test/parallel/test-tls-wrap-econnreset-pipe.js\r\n+++ b/test/parallel/test-tls-wrap-econnreset-pipe.js\r\n@@ -11,6 +11,13 @@ const net = require('net');\r\n const tmpdir = require('../common/tmpdir');\r\n tmpdir.refresh();\r\n\r\n+const { execSync } = require('child_process');\r\n+const lsof = `lsof -p ${process.pid} | grep -e ^COMMAND -e tmp`;\r\n+process.on('exit', () => {\r\n+  const openFiles = execSync(lsof, { encoding: 'utf8' });\r\n+  console.error(`Open files (${lsof}):\\n${openFiles}`);\r\n+});\r\n+\r\n const server = net.createServer((c) => {\r\n   c.end();\r\n }).listen(common.PIPE, common.mustCall(() => {\r\n```\r\n\r\n</details>\r\n\r\n<details>\r\n<summary>The callback of `server.close()` is never called.</summary>\r\n\r\nPatch to reproduce:\r\n```diff\r\ndiff --git a/test/parallel/test-child-process-server-close.js b/test/parallel/test-child-process-server-close.js\r\nindex d70926f2e8..b63245b160 100644\r\n--- a/test/parallel/test-child-process-server-close.js\r\n+++ b/test/parallel/test-child-process-server-close.js\r\n@@ -7,6 +7,9 @@ const net = require('net');\r\n const tmpdir = require('../common/tmpdir');\r\n tmpdir.refresh();\r\n\r\n+const runsOk = common.mustCall(function runsOk() {});\r\n+const neverRuns = common.mustCall(function neverRuns() {});\r\n+\r\n const server = net.createServer((conn) => {\r\n   spawn(process.execPath, ['-v'], {\r\n     stdio: ['ignore', conn, 'ignore']\r\n@@ -17,7 +20,8 @@ const server = net.createServer((conn) => {\r\n   const client = net.connect(common.PIPE, common.mustCall());\r\n   client.on('data', () => {\r\n     client.end(() => {\r\n-      server.close();\r\n+      runsOk();\r\n+      server.close(neverRuns);\r\n     });\r\n   });\r\n });\r\ndiff --git a/test/parallel/test-tls-wrap-econnreset-pipe.js b/test/parallel/test-tls-wrap-econnreset-pipe.js\r\nindex b400e35d41..e02a2f08b6 100644\r\n--- a/test/parallel/test-tls-wrap-econnreset-pipe.js\r\n+++ b/test/parallel/test-tls-wrap-econnreset-pipe.js\r\n@@ -11,6 +11,9 @@ const net = require('net');\r\n const tmpdir = require('../common/tmpdir');\r\n tmpdir.refresh();\r\n\r\n+const runsOk = common.mustCall(function runsOk() {});\r\n+const neverRuns = common.mustCall(function neverRuns() {});\r\n+\r\n const server = net.createServer((c) => {\r\n   c.end();\r\n }).listen(common.PIPE, common.mustCall(() => {\r\n@@ -21,6 +24,7 @@ const server = net.createServer((c) => {\r\n       assert.strictEqual(e.port, undefined);\r\n       assert.strictEqual(e.host, undefined);\r\n       assert.strictEqual(e.localAddress, undefined);\r\n-      server.close();\r\n+      runsOk();\r\n+      server.close(neverRuns);\r\n     }));\r\n }));\r\n```\r\n\r\n</details><br>\r\n\r\nThis doesn't happen with all the tests that use pipes, but only with [`parallel/test-child-process-server-close`](https://github.com/nodejs/node/blob/61f3a5c60ad78506e9e0caae061a04ccab878ca1/test/parallel/test-child-process-server-close.js) and [`parallel/test-tls-wrap-econnreset-pipe`](https://github.com/nodejs/node/blob/61f3a5c60ad78506e9e0caae061a04ccab878ca1/test/parallel/test-tls-wrap-econnreset-pipe.js). The first one passes the pipe as the stdout of a child process and the second triggers an error in the server, so this issue may be related to that and actually expected.\r\n\r\ncc @bnoordhuis, @indutny, @nodejs/streams\r\n",
        "labels": "confirmed-bug",
        "id": 45108
    },
    {
        "title": "Abort/core dump in fs.closeSync upon fd of greater than 32 bit",
        "body": "* **Version**: `v12.7.0` installed with nvm\r\n* **Platform**: `Linux lt2.cfware.com 5.1.20-300.fc30.x86_64 #1 SMP Fri Jul 26 15:03:11 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: `fs`\r\n\r\nTested in REPL:\r\n```js\r\nconst fs = require('fs')\r\nfs.closeSync(4294967296)\r\nfs.closeSync(4294967295)\r\n```\r\n`fs.closeSync(4294967296)` produces a JS exception:\r\n```\r\nThrown:\r\nRangeError [ERR_OUT_OF_RANGE]: The value of \"fd\" is out of range. It must be >= 0 && < 4294967296. Received 4294967296\r\n    at Object.closeSync (fs.js:405:3)\r\n    at repl:1:4\r\n    at Script.runInThisContext (vm.js:126:20)\r\n    at REPLServer.defaultEval (repl.js:384:29)\r\n    at bound (domain.js:415:14)\r\n    at REPLServer.runBound [as eval] (domain.js:428:12)\r\n    at REPLServer.onLine (repl.js:700:10)\r\n    at REPLServer.emit (events.js:208:15)\r\n    at REPLServer.EventEmitter.emit (domain.js:471:20)\r\n    at REPLServer.Interface._onLine (readline.js:316:10)\r\n```\r\n`fs.closeSync(4294967295)` trips a C++ assertion:\r\n```\r\nnode[28006]: ../src/node_file.cc:802:void node::fs::Close(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `args[0]->IsInt32()' failed.\r\n 1: 0x9afed0 node::Abort() [node]\r\n 2: 0x9aff57  [node]\r\n 3: 0x9ba25a node::fs::Close(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 4: 0xb90726  [node]\r\n 5: 0xb92647 v8::internal::Builtin_HandleApiCall(int, unsigned long*, v8::internal::Isolate*) [node]\r\n 6: 0x1318979  [node]\r\nAborted (core dumped)\r\n```\r\n\r\nObviously this is not a reasonable thing to do but an invalid fd it should produce a JS exception and not core dump.",
        "labels": "confirmed-bug",
        "id": 45109
    },
    {
        "title": "process.title don't change process name",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.16.1\r\n* **Platform**: 18.7.0 Darwin Kernel Version 18.7.0: Thu Jun 20 18:42:21 PDT 2019; root:xnu-4903.270.47~4/RELEASE_X86_64 x86_64\r\n* **Subsystem**: `process`\r\n\r\n<!-- Please provide more details below this comment. -->\r\nHello\r\n\r\nIn `v10.16.1`\r\n```js\r\nprocess.title = \"test\";\r\n```\r\nstops changing process name\r\n\r\nIn `v10.15.3`\r\nAll works as expected",
        "labels": "confirmed-bug",
        "id": 45110
    },
    {
        "title": "Malicious getters can make scrypt crash",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: all\r\n* **Subsystem**: crypto\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nPassing getters for the scrypt parameters `N`, `r`, `p` (or their aliases) can cause the process to crash with an assertion error if the getters don't return the same value at all times:\r\n\r\n```\r\n> crypto.scryptSync('', '', 1, { count: 0, get N() { if (++this.count > 2) return undefined; return 1; } })\r\nnode[15812]: c:\\ws\\src\\node_crypto.cc:6070: Assertion `args[3]->IsUint32()' failed.\r\n```\r\n\r\nI'm not labeling this `security` since it is virtually impossible to exploit remotely.",
        "labels": "confirmed-bug",
        "id": 45111
    },
    {
        "title": "DNS SOA Serial bug",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 11.16.0 & 12.6.0\r\n* **Platform**: macOS 10.14.5 & Ubuntu 18.04.2 LTS (4.15.0-54-generic)\r\n* **Subsystem**: dns\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n## Bug description\r\n\r\ndns.resolveSoa may produce unexpected \"serial\" results, when the serial does not follow the YYYYMMDDHH format (or if the serial reaches a certain date ;)\r\n\r\n## Code sample\r\n```\r\nvar dns = require(\"dns\")\r\ndns.resolveSoa(\"some.host\", function(e,o) {console.log(o)})\r\n ```\r\n\r\n## Expected results\r\n\r\n{\r\n  nsname: 'ns1.some.host',\r\n  hostmaster: 'hostmaster.some.host',\r\n  serial: 4294867295,\r\n  refresh: 86400,\r\n  retry: 7200,\r\n  expire: 1209600,\r\n  minttl: 3000\r\n}\r\n\r\n## Actual results\r\n\r\n{\r\n  ...\r\n  serial: -100001,  // this is weird\r\n  ...\r\n}\r\n\r\n## Observations\r\n\r\nAfter some tests, it appears the lowest serial number under which this issue appears is 2147483648 (something to do with dates?)\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45112
    },
    {
        "title": "\"pure virtual method called\" when creating a heap snapshot",
        "body": "* **Version**: v11.15.0\r\n* **Platform**: Linux\r\n\r\nRun the following script with ``node --inspect script.js``, connect a debugger with Google Chrome and instruct it to do a heap snapshot.\r\n\r\n**Edit:** See my comment below for a better snippet.\r\n\r\n```js\r\nfunction memoryLeak() {\r\n    return new Promise(() => {});\r\n}\r\n\r\nfunction loop() {\r\n    for (let i = 0; i < 10000; i++) {\r\n        memoryLeak();\r\n    }\r\n\r\n    setTimeout(loop, 0);\r\n}\r\n\r\nloop();\r\n```\r\n\r\nRoughly half of the time node will crash with \"pure virtual method called\".\r\n\r\nThat code actually causes a [memory leak](https://github.com/nodejs/node/issues/28787), but it will likely be annoying to debug if this isn't fixed first.",
        "labels": "confirmed-bug",
        "id": 45113
    },
    {
        "title": "segfault when using SharedArrayBuffer from an unrefed worker thread",
        "body": "* **Version**: 12.6.0\r\n* **Platform**: macOS\r\n* **Subsystem**: worker_threads\r\n\r\nThe following code causes a segfault:\r\n\r\n```javascript\r\nconst {Worker} = require('worker_threads');\r\n\r\nconst w = new Worker(`\r\n  const { parentPort } = require('worker_threads');\r\n  parentPort.on('message', () => {\r\n    const sharedArrayBuffer = new SharedArrayBuffer(12);\r\n    parentPort.postMessage(sharedArrayBuffer);\r\n  });\r\n`, { eval: true });\r\nw.unref();\r\nw.once('message', () => {\r\n console.log('done');\r\n});\r\nw.postMessage('go');\r\n```\r\n\r\nThe segfault occurs due to usage of `unref()` on the worker. Without that call, the process exits as normal (when `process.exit()` is called from within the `message` handler, otherwise it keeps running).\r\n\r\nBacktrace from lldb:\r\n\r\n```\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x20)\r\n  * frame #0: 0x00000001001947dd node`v8::ArrayBufferDeleter(void*, unsigned long, void*) + 13\r\n    frame #1: 0x00000001000ed298 node`node::worker::SharedArrayBufferMetadata::~SharedArrayBufferMetadata() + 24\r\n    frame #2: 0x00000001000ed55d node`std::__1::__shared_ptr_pointer<node::worker::SharedArrayBufferMetadata*, std::__1::default_delete<node::worker::SharedArrayBufferMetadata>, std::__1::allocator<node::worker::SharedArrayBufferMetadata> >::__on_zero_shared() + 23\r\n    frame #3: 0x00007fff6cc7fd42 libc++.1.dylib`std::__1::__shared_weak_count::__release_shared() + 40\r\n    frame #4: 0x00000001000ed453 node`node::worker::(anonymous namespace)::SABLifetimePartner::~SABLifetimePartner() + 33\r\n    frame #5: 0x00000001000387d4 node`node::Environment::RunCleanup() + 164\r\n    frame #6: 0x00000001000ac686 node`node::NodeMainInstance::Run() + 658\r\n    frame #7: 0x0000000100056ccc node`node::Start(int, char**) + 237\r\n    frame #8: 0x00007fff6fa4a3d5 libdyld.dylib`start + 1\r\n    frame #9: 0x00007fff6fa4a3d5 libdyld.dylib`start + 1\r\n```\r\n\r\nThe cause (within node) appears to be in the destructor of `SharedArrayBufferMetadata`: https://github.com/nodejs/node/blob/b6bfc193788b1838bee73d584fe089e1104b9f88/src/sharedarraybuffer_metadata.cc#L120-L124\r\n\r\nPossibly this is a race between the main thread and worker thread, but I'm not familiar enough with node's internals to debug further.",
        "labels": "confirmed-bug",
        "id": 45114
    },
    {
        "title": "Access Violation",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v12.6.0\r\n* **Platform**: Windows 64-bit\r\n* **Subsystem**:\r\n\r\nIt is possible that I'm doing something wrong, but I believe the program should not crash.\r\n\r\nBy running the following code, the program crashes (most of the time) with C0000005.ACCESS_VIOLATION.\r\n\r\n```js\r\nconst { Worker } = require( \"worker_threads\" );\r\n\r\nconst workerCode = `\r\nconst v8 = require( \"v8\" );\r\nconst { parentPort } = require( \"worker_threads\" );\r\n\r\nfunction share( contents ) {\r\n  const shared = new SharedArrayBuffer( contents.length );\r\n  const buffer = Buffer.from( shared );\r\n  contents.copy( buffer );\r\n  return shared;\r\n}\r\n\r\nfunction serialize( value ) {\r\n  return share( v8.serialize( value ) );\r\n}\r\n\r\nparentPort.on( \"message\", () => {\r\n  parentPort.postMessage( serialize( {} ) );\r\n} );\r\n`;\r\n\r\nfunction createWorker( id ) {\r\n  const child = new Worker( workerCode, {\r\n    eval: true\r\n  } );\r\n  child.postMessage( {} );\r\n  child.on( \"message\", () => {\r\n    child.terminate();\r\n  } );\r\n  child.on( \"error\", err => console.error( \"error\", id, err ) );\r\n  child.once( \"exit\", () => {\r\n    console.log( \"exit\", id );\r\n  } );\r\n}\r\n\r\nconsole.log( \"5 secs...\" );\r\n\r\nsetTimeout( () => {\r\n  for ( let i = 0; i < 10; i++ ) {\r\n    createWorker( i );\r\n  }\r\n}, 5000 );\r\n```\r\n\r\nI've used `procdump64 -e node` to produce a dump file (available in the following zip file).\r\n[node.exe_190719_222025.zip](https://github.com/nodejs/node/files/3412780/node.exe_190719_222025.zip)\r\n\r\nOpening the dump file in Visual Studio, shows me this:\r\n\r\n![image](https://user-images.githubusercontent.com/18088420/61566821-49f1f500-aa75-11e9-8eab-04eb25067065.png)\r\n\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "confirmed-bug",
        "id": 45115
    },
    {
        "title": "backtrace truncated if msg contains null character `\\0`",
        "body": "backtrace truncated if msg contains null character `\\0`\r\n\r\n```\r\n$ node main.js\r\n\r\nabcdef\r\n/main/t02.js:6\r\n    throw new Error(a);\r\n    ^\r\n\r\nError: abc\r\n```\r\n\r\nwith this program\r\n\r\n```js\r\nfunction test(){\r\n  var a = \"abc\\0def\"\r\n  var a2 = \"abcdef\"\r\n  console.log(a); // not truncated\r\n  if(true) // change to false and backtrace works\r\n    throw new Error(a); // backtrace msg truncated at `\\0`, the whole stack frames are missing\r\n  else\r\n    throw new Error(a2); // backtrace shown correctly\r\n}\r\n\r\ntest()\r\n```\r\n\r\n##\r\n\r\nwithout the `\\0` the backtrace shows fine:\r\n```\r\nabcdef\r\n/main/t02.js:8\r\n    throw new Error(a2);\r\n    ^\r\n\r\nError: abcdef\r\n    at test (/main/t02.js:8:11)\r\n    at Object.<anonymous> (/main/t02.js:11:1)\r\n    at Module._compile (internal/modules/cjs/loader.js:774:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:785:10)\r\n    at Module.load (internal/modules/cjs/loader.js:641:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:556:12)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:837:10)\r\n    at internal/main/run_main_module.js:17:11\r\n```\r\n\r\n##\r\nnode -v\r\nv12.3.1\r\n\r\nuname -a\r\nDarwin  18.5.0 Darwin Kernel Version 18.5.0\r\n\r\n## note\r\naccording to https://stackoverflow.com/questions/13698677/null-character-in-strings \r\n\r\n>> a NUL byte should simply be \"yet another character value\" and have no special meaning, as opposed to other languages where it might end a SV (String value).\r\n\r\nconsole.log correctly shows the string (no truncation) but the backtrace doesn't work when running node on cmd line. \r\n\r\nnote that on a browser (eg chrome) it works: no truncation:\r\n```\r\nthrow new Error(\"abc\\0def\");\r\nVM9405:1 Uncaught Error: abc\u0000def\r\n    at <anonymous>:1:7\r\n```\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45116
    },
    {
        "title": "fs.mkdir/mkdirSync hang with {recursive: true} if name is invalid",
        "body": "* **Version**: 10.16.0, 11.14.0, 12.6.0\r\n* **Platform**: Windows 10\r\n* **Subsystem**: fs\r\n\r\nIf the name of the dir to be created is invalid, fs.mkdir never calls back and fs.mkdirSync blocks:\r\n\r\n```\r\nconst fs = require('fs')\r\n\r\nconsole.log(\"1\")\r\nfs.mkdir('invalid1:', {recursive: true}, (err) => {\r\n  console.log(\"is not called\")\r\n  if (err) throw err\r\n})\r\n\r\nconsole.log(\"2\")\r\nfs.mkdirSync('invalid2:', {recursive: true})\r\nconsole.log(\"is not reached\")\r\n```\r\n\r\nBTW, the error message that is reported with {recursive: false} appears a bit strange:\r\n\r\n> Error: ENOENT: no such file or directory, mkdir 'invalid2:'\r\n\r\nWouldn't it be more convenient to use EPERM, EACCES or ENOTDIR?\r\n",
        "labels": "confirmed-bug",
        "id": 45117
    },
    {
        "title": "stream performance regression 12.6.0 vs 10.16.0 ",
        "body": "Seeing major performance regression, ~50% drop in throughput, in one of our benchmarks. I will work on creating a minimal repro. In the meantime though, here are some snippets of the profile outputs - it is pretty strange that 12.6.0 is spending ~70% of the time in shared library land (maybe there's an issue with the profile too?) \r\n\r\n```\r\n#uname -a\r\nLinux ledion-vm 4.10.0-33-generic #37~16.04.1-Ubuntu SMP Fri Aug 11 14:07:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\n10.16.0\r\n```\r\n [Shared libraries]:\r\n   ticks  total  nonlib   name\r\n   1021    2.5%          /lib/x86_64-linux-gnu/libc-2.23.so\r\n    724    1.8%          /lib/x86_64-linux-gnu/libpthread-2.23.so\r\n     17    0.0%          [vdso]\r\n      6    0.0%          /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\r\n\r\n\r\n [Summary]:\r\n   ticks  total  nonlib   name\r\n  26260   63.9%   66.8%  JavaScript\r\n  11860   28.9%   30.2%  C++\r\n    947    2.3%    2.4%  GC\r\n   1768    4.3%          Shared libraries\r\n   1178    2.9%          Unaccounted\r\n\r\n\r\n [Bottom up (heavy) profile]:\r\n   ticks parent  name\r\n    3566    8.7%  Builtin: LoadIC\r\n     858   24.1%    LazyCompile: *onwrite _stream_writable.js:450:17\r\n     358   41.7%      LazyCompile: *afterTransform _stream_transform.js:78:24\r\n     349   97.5%        LazyCompile: *Transform._read _stream_transform.js:185:37\r\n     349  100.0%          LazyCompile: *Readable.read _stream_readable.js:377:35\r\n     348   99.7%            LazyCompile: *pipeOnDrainFunctionResult _stream_reada\r\n```\r\n\r\n\r\n12.6.0\r\n```\r\n [Shared libraries]:\r\n   ticks  total  nonlib   name\r\n  28413   64.4%          /usr/local/bin/node\r\n   1845    4.2%          /lib/x86_64-linux-gnu/libc-2.23.so\r\n    455    1.0%          /lib/x86_64-linux-gnu/libpthread-2.23.so\r\n      7    0.0%          [vdso]\r\n      6    0.0%          /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\r\n      4    0.0%          /lib/x86_64-linux-gnu/libm-2.23.so\r\n\r\n [Summary]:\r\n   ticks  total  nonlib   name\r\n   8697   19.7%   65.1%  JavaScript\r\n   4515   10.2%   33.8%  C++\r\n   1969    4.5%   14.7%  GC\r\n  30730   69.7%          Shared libraries\r\n    154    0.3%          Unaccounted\r\n\r\n\r\n   ticks parent  name\r\n  28413   64.4%  /usr/local/bin/node\r\n   6958   24.5%    LazyCompile: *Readable.read _stream_readable.js:394:35\r\n   6901   99.2%      LazyCompile: *pipeOnDrainFunctionResult _stream_readable.js\r\n   6901  100.0%        LazyCompile: *emit events.js:153:44\r\n   6901  100.0%          LazyCompile: *EventEmitter.emit domain.js:460:39\r\n   6901  100.0%            LazyCompile: *onwrite _stream_writable.js:445:17\r\n   3237   11.4%    LazyCompile: *ondata _stream_readable.js:711:18\r\n   3237  100.0%      LazyCompile: *emit events.js:153:44\r\n   3237  100.0%        LazyCompile: *Readable.read _stream_readable.js:394:35\r\n   3214   99.3%          LazyCompile: *pipeOnDrainFunctionResult _stream_readabl\r\n   3214  100.0%            LazyCompile: *emit events.js:153:44\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45118
    },
    {
        "title": "Worker_threads SharedArrayBuffer in multiple object properties cross-referenced randomly (object corruption?)",
        "body": "* **Version**: 12.6.0\r\n* **Platform**: *Linux* dc 4.4.62-1.el7.elrepo.x86_64 #1 SMP Tue Apr 18 11:02:11 EDT 2017 x86_64 x86_64 x86_64 GNU/Linux and 64-bit *Windows*\r\n* **Subsystem**: worker_threads\r\n\r\n**MainThread**\r\n```JavaScript\r\nconst { Worker, isMainThread, parentPort, workerData } = require('worker_threads');\r\n\r\nfunction allocateSharedMemory(objSharedBuffer, strBufferType, nBytesCount)\r\n{\r\n\tobjSharedBuffer[strBufferType] = new SharedArrayBuffer(nBytesCount);\r\n\tconst arrSharedMemoryView = new Uint32Array(objSharedBuffer[strBufferType]);\r\n\tarrSharedMemoryView[0] = nBytesCount;\r\n}\r\n\r\nconst arrFruit = [\r\n\t\"apples\",\r\n\t\"bananas\",\r\n\t\"oranges\",\r\n];\r\n\r\nconst objToShare = {};\r\n\r\nfor(let strFruit of arrFruit)\r\n{\t\r\n\tobjToShare[strFruit] = {};\r\n\tobjToShare[strFruit][\"type\"] = {};\r\n\t\r\n\tobjToShare[strFruit][\"type\"][\"sunlight\"] = {};\r\n\t\r\n\tallocateSharedMemory(objToShare[strFruit][\"type\"][\"sunlight\"], \"lastHour\", 100);\r\n\tallocateSharedMemory(objToShare[strFruit][\"type\"][\"sunlight\"], \"lastDay\", 104);\r\n\tallocateSharedMemory(objToShare[strFruit][\"type\"][\"sunlight\"], \"lastMonth\", 108);\r\n\tallocateSharedMemory(objToShare[strFruit][\"type\"][\"sunlight\"], \"lastYear\", 112);\r\n\r\n\tobjToShare[strFruit][\"type\"][\"water\"] = {};\r\n\r\n\tallocateSharedMemory(objToShare[strFruit][\"type\"][\"water\"], \"lastHour\", 116);\r\n\tallocateSharedMemory(objToShare[strFruit][\"type\"][\"water\"], \"lastDay\", 120);\r\n\tallocateSharedMemory(objToShare[strFruit][\"type\"][\"water\"], \"lastMonth\", 124);\r\n\tallocateSharedMemory(objToShare[strFruit][\"type\"][\"water\"], \"lastYear\", 128);\r\n}\t\r\n\r\nfor(let i = 0; i < 4; i++)\r\n{\r\n\tconst w = new Worker(\"./WorkerThread.js\");\r\n\t\r\n\tw.postMessage(objToShare);\r\n\t\r\n\t/*w.on('message', (msg) => {\r\n\t\tconst arrDataPoints = new Uint32Array(objToShare[\"bananas\"][\"type\"][\"sunlight\"][\"lastHour\"]);\r\n\t});*/\t\r\n}\r\n```\r\n\r\n**WorkerThread**\r\n\r\n```JavaScript\r\nconst {  parentPort, workerData } = require('worker_threads');\r\n\r\nparentPort.once('message', (value) => {\r\n\r\n\tconst objGranularities = {\r\n\t\t\"lastHour\": 100,\r\n\t\t\"lastDay\": 104,\r\n\t\t\"lastMonth\": 108,\r\n\t\t\"lastYear\": 112\r\n\t}\r\n\r\n\tfor(let strGranularity in objGranularities)\r\n\t{\r\n\t\tconst sharedBuffer = value[\"bananas\"][\"type\"][\"sunlight\"][strGranularity];\r\n\t\tconst sharedBufferView = new Uint32Array(sharedBuffer);\r\n\t\tconst nByteLengthReceived = sharedBuffer.byteLength;\r\n\t\tconst nByteLengthExpected = objGranularities[strGranularity]; \r\n\t\t\r\n\t\tif(nByteLengthExpected === nByteLengthReceived)\r\n\t\t{\r\n\t\t\tconsole.log(\"[Pass]\", \"receivedLength =\", nByteLengthReceived, \"expectedLength =\", nByteLengthExpected, \"firstValue =\", sharedBufferView[0], \"type =\", strGranularity);\r\n\t\t\t\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\tconsole.log(\"[Fail]\", \"receivedLength =\", nByteLengthReceived, \"expectedLength =\", nByteLengthExpected, \"firstValue =\", sharedBufferView[0],  \"type =\", strGranularity);\r\n\t\t}\r\n\t\t\r\n\t}\r\n\r\n\tparentPort.postMessage(\"finished\");\r\n\r\n});\r\n```\r\n\r\n***Output***\r\n```\r\n[Fail] receivedLength = 104 expectedLength = 100 firstValue = 104 type = lastHour\r\n[Fail] receivedLength = 108 expectedLength = 104 firstValue = 108 type = lastDay\r\n[Fail] receivedLength = 104 expectedLength = 100 firstValue = 104 type = lastHour\r\n[Fail] receivedLength = 112 expectedLength = 108 firstValue = 112 type = lastMonth\r\n[Fail] receivedLength = 108 expectedLength = 104 firstValue = 108 type = lastDay\r\n[Fail] receivedLength = 128 expectedLength = 112 firstValue = 128 type = lastYear\r\n[Fail] receivedLength = 112 expectedLength = 108 firstValue = 112 type = lastMonth\r\n[Fail] receivedLength = 128 expectedLength = 112 firstValue = 128 type = lastYear\r\n[Fail] receivedLength = 104 expectedLength = 100 firstValue = 104 type = lastHour\r\n[Fail] receivedLength = 108 expectedLength = 104 firstValue = 108 type = lastDay\r\n[Fail] receivedLength = 112 expectedLength = 108 firstValue = 112 type = lastMonth\r\n[Fail] receivedLength = 128 expectedLength = 112 firstValue = 128 type = lastYear\r\n[Fail] receivedLength = 104 expectedLength = 100 firstValue = 104 type = lastHour\r\n[Fail] receivedLength = 108 expectedLength = 104 firstValue = 108 type = lastDay\r\n[Fail] receivedLength = 112 expectedLength = 108 firstValue = 112 type = lastMonth\r\n[Fail] receivedLength = 128 expectedLength = 112 firstValue = 128 type = lastYear\r\n```\r\n\r\n**The order of creating the keys in the object matters.\r\nIt appears there's some optimization in V8 which is disabled partially (object keys reordering).**\r\n\r\nWhen ordered this way, everything works fine:\r\n```\r\nconst arrFruit = [\r\n\t\"bananas\",\r\n\t\"oranges\",\r\n\t\"apples\",\r\n];\r\n\r\n{\r\n  bananas: { type: { sunlight: [Object], water: [Object] } },\r\n  oranges: { type: { sunlight: [Object], water: [Object] } },\r\n  apples: { type: { sunlight: [Object], water: [Object] } }\r\n}\r\n```\r\n\r\nI get the following output: \r\n```\r\n[Pass] receivedLength = 100 expectedLength = 100 firstValue = 100 type = lastHour\r\n[Pass] receivedLength = 104 expectedLength = 104 firstValue = 104 type = lastDay\r\n[Pass] receivedLength = 108 expectedLength = 108 firstValue = 108 type = lastMonth\r\n[Pass] receivedLength = 112 expectedLength = 112 firstValue = 112 type = lastYear\r\n[Pass] receivedLength = 100 expectedLength = 100 firstValue = 100 type = lastHour\r\n[Pass] receivedLength = 104 expectedLength = 104 firstValue = 104 type = lastDay\r\n[Pass] receivedLength = 100 expectedLength = 100 firstValue = 100 type = lastHour\r\n[Pass] receivedLength = 108 expectedLength = 108 firstValue = 108 type = lastMonth\r\n[Pass] receivedLength = 104 expectedLength = 104 firstValue = 104 type = lastDay\r\n[Pass] receivedLength = 112 expectedLength = 112 firstValue = 112 type = lastYear\r\n[Pass] receivedLength = 108 expectedLength = 108 firstValue = 108 type = lastMonth\r\n[Pass] receivedLength = 112 expectedLength = 112 firstValue = 112 type = lastYear\r\n[Pass] receivedLength = 100 expectedLength = 100 firstValue = 100 type = lastHour\r\n[Pass] receivedLength = 104 expectedLength = 104 firstValue = 104 type = lastDay\r\n[Pass] receivedLength = 108 expectedLength = 108 firstValue = 108 type = lastMonth\r\n[Pass] receivedLength = 112 expectedLength = 112 firstValue = 112 type = lastYear\r\n```\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45119
    },
    {
        "title": "Stack trace gets lost in Node.js 12.6.0 when rethrowing from uncaught exception handler ",
        "body": "* **Version**:  v12.6.0\r\n* **Platform**: Darwin Bastians-MBP 18.6.0 Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019; root:xnu-4903.261.4~2/RELEASE_X86_64 x86_64\r\n\r\nUp to version 12.5.0, when rethrowing the error from an `uncaughtException` handler, the original stack trace would be preserved. In version 12.6.0, this is no longer the case. Instead, a stack trace with only one line is printed, showing the callsite where the error has been rethrown. \r\n\r\n`rethrow.js`:\r\n\r\n```\r\n'use strict';\r\n\r\nprocess.on('uncaughtException', err => {\r\n  throw err;\r\n});\r\n\r\nfunction throwUncaughtError() {\r\n  throw new Error('Boom');\r\n}\r\n\r\nthrowUncaughtError();\r\n```\r\n\r\nRunning the above in 12.5.0 and 12.6.0 shows the difference:\r\n\r\n```\r\n> nvm use 12.5.0 && node rethrow\r\n\r\nNow using node v12.5.0 (npm v6.9.0)\r\n/Users/bastian/instana/code/nodejs/packages/collector/test/uncaught/apps/rethrow.js:4\r\n  throw err;\r\n  ^\r\n\r\nError: Boom\r\n    at throwUncaughtError (/Users/bastian/instana/code/nodejs/packages/collector/test/uncaught/apps/rethrow.js:8:9)\r\n    at Object.<anonymous> (/Users/bastian/instana/code/nodejs/packages/collector/test/uncaught/apps/rethrow.js:11:1)\r\n    at Module._compile (internal/modules/cjs/loader.js:776:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:787:10)\r\n    at Module.load (internal/modules/cjs/loader.js:643:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:556:12)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:839:10)\r\n    at internal/main/run_main_module.js:17:11\r\n\r\n> nvm use 12.6.0 && node rethrow\r\n\r\nNow using node v12.6.0 (npm v6.9.0)\r\n/Users/bastian/instana/code/nodejs/packages/collector/test/uncaught/apps/rethrow.js:4\r\n  throw err;\r\n  ^\r\n\r\nError: Boom\r\n\r\n>\r\n\r\n```\r\n\r\nCommits 0fd652468003fcf00cadd04ff5bf7ee7fc07af84 and 5b92eb468663809f9075e930d10cf97bc1eb0762 might be related to this change in behaviour.",
        "labels": "confirmed-bug",
        "id": 45120
    },
    {
        "title": "`path.relative` adds trailing slash in node 12",
        "body": "## What happens in node < 12\r\n\r\n```js\r\nconst Path = require('path');\r\nPath.relative('/page1/page2/foo', '/');\r\n// '../../..'\r\nPath.relative('/page1/page2/foo', '/page1/');\r\n// '../..'\r\nPath.relative('/page1/page2/foo', '/page1/page2/');\r\n// '..'\r\n```\r\n\r\n## What happens in node => 12\r\n\r\n```js\r\nconst Path = require('path');\r\nPath.relative('/page1/page2/foo', '/');\r\n// '../../../'\r\n//          ^--- Note the trailing slash\r\nPath.relative('/page1/page2/foo', '/page1/');\r\n// '../..'\r\nPath.relative('/page1/page2/foo', '/page1/page2/');\r\n// '..'\r\n```\r\n\r\nNote the inconsistency when resolving a path against root. In node 12 we now get a trailing slash.\r\n\r\n## What I expect should happen\r\n\r\nWe either resolve all paths with or without trailing slashes but not mix both.\r\nNodes behavior prior to 12 was more consistent.\r\n\r\n* 12.6.0\r\n* OSX 10.14.5\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45121
    },
    {
        "title": "REPL complete function swallows errors",
        "body": "@estrada9166 recently brought up that `test/parallel/test-repl-save-load.js` is not working as it should. It should fail as is it but the errors are swallowed due to calling `complete`.\r\n\r\nIt seems like the domain does not propagate the error properly and it's silently swallowed. Adding an error listener to the active domain in the complete function that throws the error fixes the problem but it causes some side effects in other cases. We should only add the listener to the domains that do not handle the error properly at the moment.\r\n\r\nPing @Trott since you fixed some of these cases before.",
        "labels": "confirmed-bug",
        "id": 45122
    },
    {
        "title": "`cat <(node -v)` never exits after >= 12.5.0",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v12.5.0 and greater\r\n* **Platform**: Darwin MacBook-Pro.local 18.6.0 Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019; root:xnu-4903.261.4~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\nSimply run `cat <(node -v)`\r\nrelated: https://github.com/robbyrussell/oh-my-zsh/issues/7972",
        "labels": "confirmed-bug",
        "id": 45123
    },
    {
        "title": "crypto: DH prime for bits <= 15 is always 35963",
        "body": "With today's master:\r\n```js\r\nconst assert = require('assert');\r\nconst crypto = require('crypto');\r\nfor (let bits = 3; bits <= 15; bits++) {\r\n  const p = crypto.createDiffieHellman(bits).getPrime();\r\n  assert.strictEqual(p.length, 2);\r\n  assert.strictEqual(p.readUInt16BE(0), 35963);\r\n}\r\n```\r\nI'd expect the test case to fail (it should find different primes) but it returns the same prime for sizes 3 to 15. It's only at `bits >= 16` that it starts to find different primes.\r\n\r\nI'm not sure if this is a Node.js or an openssl bug. `log2(35963) > 15` though so it definitely seems wrong to return that prime (and only that prime) for `bits <= 15`.",
        "labels": "confirmed-bug",
        "id": 45124
    },
    {
        "title": "SIGTERM handler does not run if there are no tasks running and exit code is always 0",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.15.0\r\n* **Platform**: Linux tsundberg-dev 4.18.0-20-generic #21~18.04.1-Ubuntu SMP Wed May 8 08:43:37 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: process\r\n\r\n<!-- Please provide more details below this comment. -->\r\n---\r\nTo run the following tests paste them into `index.js` and run `node index.js; echo $?`\r\n\r\n---\r\n#### Case 1\r\nThe following results in an expected output:\r\n```node\r\nprocess.kill(process.pid, 'SIGTERM')\r\n```\r\nOutput:\r\n```\r\nTerminated\r\n143\r\n```\r\n---\r\n#### Case 2\r\nAdding a SIGTERM results in an exit code of 0, and the handler never runs:\r\n```node\r\nprocess.on('SIGTERM', () => {\r\n    console.error('Handle ran!')\r\n    process.exit(1)\r\n})\r\n\r\nprocess.kill(process.pid, 'SIGTERM')\r\n```\r\nOutput:\r\n```\r\n0\r\n```\r\n---\r\n#### Case 3\r\nAdding a timeout or some other task that keeps node alive results in the expected behavior:\r\n```node\r\nprocess.on('SIGTERM', () => {\r\n    console.error('Handle ran!')\r\n    process.exit(1)\r\n})\r\n\r\nprocess.kill(process.pid, 'SIGTERM')\r\n\r\nsetTimeout(() => {}, 100000)\r\n```\r\nOutput:\r\n```\r\nHandle ran!\r\n1\r\n```",
        "labels": "confirmed-bug",
        "id": 45125
    },
    {
        "title": "CHECK failure in ResetStdio on >=12.5.0",
        "body": "Check failure is this: `../src/node.cc:649:void node::ResetStdio(): Assertion `(err) != (-1)' failed.`\r\n\r\nhttps://github.com/nodejs/node/blob/dec5b2258a853b524e125542667b5b2dfc5afb74/src/node.cc#L646-L649\r\n\r\nReproduction:\r\n\r\n1. Make sure you are on >=12.5.0\r\n2. clone https://github.com/engine262/engine262\r\n3. `npm run build && npm run test`\r\n4. Tests start running, hit ctrl+c to kill it\r\n5. Check failure happens consistently here",
        "labels": "confirmed-bug",
        "id": 45126
    },
    {
        "title": "Time Zone Bug ('Antarctica/DumontDUrville')",
        "body": "There is a timezone bug in Node 10.16.0. It is the same bug that I reported to Chromium here:\r\nhttps://bugs.chromium.org/p/chromium/issues/detail?id=928068\r\n\r\nRun the code in comment 1, from there, to reproduce the bug in Node 10.16.0.\r\n\r\nI'm not sure if this is a V8 thing or if each environment has to fix the bug. If it is a V8 thing, perhaps this bug will go away by itself eventually. Otherwise, it needs to be addressed in Node.",
        "labels": "confirmed-bug",
        "id": 45127
    },
    {
        "title": "./configure --enable-vtune-profiling doesn't work.",
        "body": "latest node source code doesn't work well with \"--enable-vtune-profiling\", the log is below:\r\ngyp: /home/benchmark/Downloads/node/tools/v8_gypfiles/v8vtune.gyp not found (cwd: /home/benchmark/Downloads/node) while loading dependencies of /home/benchmark/Downloads/node/node.gyp while trying to load /home/benchmark/Downloads/node/node.gyp\r\nError running GYP\r\n",
        "labels": "confirmed-bug",
        "id": 45128
    },
    {
        "title": " parallel/test-domain-error-types can crash if GC timings get unlucky",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v13.0.0-pre\r\n* **Platform**: Linux (debian)\r\n* **Subsystem**: Domain\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nIt appears that the `TickObject` used for `process.nextTick` can die between the tick callback and the tick's `after` hook (possibly only in the case where the callback throws an exception), in which case there is no longer a strong reference to the tick's domain and the `WeakReference` to the domain can die (on an unlucky GC run). Then, the `exit()` call in `domain.js` will be called on undefined, and will crash.\r\n\r\nDepending on the desired semantics, either `current.get()` in the `after()` call should check the `WeakReference`, or the `TickObject` resource/domain should be kept strongly alive until after the `after` hook.\r\n\r\nReproducible by manually setting a tighter GC interval and stressing compaction on a debug node build:\r\n\r\n```\r\n$ node --gc-interval=100 --stress-compaction test/parallel/test-domain-error-types.js\r\nTypeError: Cannot read property 'exit' of undefined\r\n    at AsyncHook.after (domain.js:82:20)\r\n    at emitHook (internal/async_hooks.js:164:38)\r\n    at emitAfterScript (internal/async_hooks.js:363:5)\r\n    at process._fatalException (internal/process/execution.js:180:9)\r\n```",
        "labels": "confirmed-bug",
        "id": 45129
    },
    {
        "title": "Piping streams into SHA3 without end: false crashes",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 12.4.0\r\n* **Platform**: Windows 10 x64 and Linux 4.4.0-042stab138.1\r\n* **Subsystem**: crypto or deps\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThis code causes a segmentation fault in 12.4.0:\r\n\r\n```javascript\r\nconst crypto = require('crypto');\r\nconst fs = require('fs');\r\n\r\nconst myOwnCode = fs.createReadStream(__filename);\r\nconst copy = fs.createWriteStream(`${__filename}.copy`);\r\nconst hash = crypto.createHash('sha3-512');\r\nmyOwnCode.pipe(hash);\r\nmyOwnCode.pipe(copy).on('finish', () => {\r\n  hash.digest();\r\n});\r\n```\r\n\r\nThis seems to be caused by `pipe` calling `hash._flush` when `end` is not set to `false`. This code also causes a segmentation fault:\r\n\r\n```javascript\r\nconst crypto = require('crypto');\r\n\r\nconst hash = crypto.createHash('sha3-512');\r\nhash._flush(() => console.log('Flushed'));\r\nhash.digest();\r\n```\r\n\r\nThis seems to be at least partially caused by the implementation of `_flush`:\r\n\r\nhttps://github.com/nodejs/node/blob/908292cf1f551c614a733d858528ffb13fb3a524/lib/internal/crypto/hash.js#L54-L57\r\n\r\nIt bypasses the `this[kState][kFinalized]` safeguard:\r\n\r\nhttps://github.com/nodejs/node/blob/908292cf1f551c614a733d858528ffb13fb3a524/lib/internal/crypto/hash.js#L79-L91\r\n\r\nNote that this bug only happens when using SHA3, `sha256` seems to be working just fine, so there might also be some weirdness in OpenSSL.\r\n\r\ncc @mcollina @nodejs/crypto @nodejs/streams",
        "labels": "confirmed-bug",
        "id": 45130
    },
    {
        "title": "Experimental module resolution inconsistency between --eval and file",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `v12.3.1`\r\n* **Platform**: `Linux thinkpad-avaq 4.19.47 #1-NixOS SMP Fri May 31 13:46:35 UTC 2019 x86_64 GNU/Linux`\r\n\r\n----\r\n\r\n### Preparation\r\n\r\n1. Go to a temporary directory: `cd $(mktemp -d)`\r\n2. Install Fluture or any other module that has a \"main\" field without file extension, and contains a `.js` main file as well as a `.mjs` main file: `npm install fluture@11.0.1`\r\n\r\n### Reproducing\r\n\r\nRun the following two shell scripts:\r\n\r\n```sh\r\nnode --input-type=module \\\r\n     --experimental-modules \\\r\n     --eval 'import Future from \"fluture\"; console.log(Future)'\r\n```\r\n```sh\r\necho 'import Future from \"fluture\"; console.log(Future)' > index.mjs\r\nnode --experimental-modules index.mjs\r\n```\r\n\r\n### Expected result\r\n\r\nThe output of both shell scripts is the same.\r\n\r\n### Actual result\r\n\r\nThe first script errors with `Error: Cannot find package 'fluture' imported from`, and the output from the second shows that the module resolver loaded the CommonJS version of the package into the module.\r\n\r\n<sub>/cc @ljharb</sub>",
        "labels": "confirmed-bug",
        "id": 45131
    },
    {
        "title": "Worker threads get killed if they listen for data on stdin",
        "body": "Description\r\n-----------\r\n\r\nWhen a worker thread tries to listen for data on stdin, it gets killed.\r\nNot even finally blocks get called.\r\n\r\nEnvironment\r\n------------\r\n\r\n* **Version**: v12.0.0\r\n* **Platform**: Darwin Joshs-MacBook-Air.local 18.6.0 Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019; root:xnu-4903.261.4~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**: Probably `worker_thread`\r\n\r\nExample\r\n--------\r\n\r\nA worker is started, it prints \"processing\" 10 times:\r\n\r\n```node\r\nconst { Worker, isMainThread } = require('worker_threads')\r\nif(isMainThread) {\r\n  new Worker(__filename).on('exit', (exitStatus) => console.log({ exitStatus }))\r\n} else {\r\n  // process.stdin.on('data', console.log) // <-- this line is commented out\r\n  for(i=0; i < 10; ++i) console.log(`processing(${i})`)\r\n}\r\n// => processing(0)\r\n// => processing(1)\r\n// => processing(2)\r\n// => processing(3)\r\n// => processing(4)\r\n// => processing(5)\r\n// => processing(6)\r\n// => processing(7)\r\n// => processing(8)\r\n// => processing(9)\r\n// => { exitStatus: 0 }\r\n```\r\n\r\nNow we uncomment the line that listens for data, it gets killed after 2 or 3 iterations (on my machine, guessing quicker on faster machines):\r\n\r\n```node\r\nconst { Worker, isMainThread } = require('worker_threads')\r\nif(isMainThread) {\r\n  new Worker(__filename).on('exit', (exitStatus) => console.log({ exitStatus }))\r\n} else {\r\n  process.stdin.on('data', console.log) // <-- now this line runs\r\n  for(i=0; i < 10; ++i) console.log(`processing(${i})`)\r\n}\r\n// => processing(0)\r\n// => processing(1)\r\n// => processing(2)\r\n// => { exitStatus: 0 }\r\n```\r\n\r\nExpected Behaviour\r\n--------------------\r\n\r\n-  I expected the second example to behave the same as the first example. Which is to say that I expect my worker would be able to process my stdin.\r\n-  However, if this behaviour is intentional, then I'd expect\r\n   - The behaviour to be documented [here](https://nodejs.org/api/worker_threads.html)\r\n   - To respect `finally` blocks (omitted from my example to keep it short/focused)\r\n   - To exit with a nonzero status (docs say _\"If the worker was terminated, the exitCode parameter will be 1\"_)",
        "labels": "confirmed-bug",
        "id": 45132
    },
    {
        "title": "core dumped when takeHeapSnapshot for http2 server and memory leak",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n- **Version**: v12.3.1\r\n- **Platform**: Darwin Kernel Version 18.5.0: Mon Mar 11 20:40:32 PDT 2019; root:xnu-4903.251.3~3/RELEASE_X86_64 x86_64\r\n- **Subsystem**: http2\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nserver.js\r\n\r\n```javascript\r\n'use strict';\r\nconst http2 = require('http2');\r\n\r\nconst server = http2.createServer();\r\nserver.once('error', err => {\r\n  console.log(err);\r\n});\r\nserver.on('session', session => {\r\n  console.log(session);\r\n});\r\nserver.on('stream', (stream, headers) => {\r\n  console.log(stream, headers);\r\n});\r\nserver.listen(12200, () => {\r\n  console.log('server start on %s', 12200);\r\n});\r\n```\r\n\r\nclient.js\r\n\r\n```javascript\r\n'use strict';\r\nconst connect = async () => {\r\n  return new Promise(resolve => {\r\n    const client = http2.connect('http://localhost:12200', () => {\r\n      client.close();\r\n      resolve();\r\n    });\r\n  });\r\n};\r\n\r\n(async () => {\r\n  while (true) {\r\n    await connect();\r\n  }\r\n})();\r\n```\r\n\r\nexecute command:\r\n`node --gc-global --trace-gc --inspect server.js`\r\n`node client.js`\r\n\r\nthen take a snapshot in Chrome DevTools\r\nthe server process will take a core dumped.\r\n\r\n> [1]    49577 segmentation fault (core dumped)  node --gc-global --trace-gc --inspect server.js\r\n\r\nthe dump file bt:\r\n\r\n ```\r\n    thread #1, stop reason = signal SIGSTOP\r\n    \r\n    - frame #0: 0x00000001000a588b node`node::MemoryRetainerNode::MemoryRetainerNode(node::MemoryTracker*, node::MemoryRetainer const*) + 107\r\n      frame #1: 0x00000001000a551f node`node::MemoryTracker::AddNode(node::MemoryRetainer const*, char const*) + 87\r\n      frame #2: 0x000000010001a8e7 node`node::MemoryTracker::Track(node::MemoryRetainer const*, char const*) + 147\r\n      frame #3: 0x00000001000a450a node`node::http2::Http2Session::Http2Settings::MemoryInfo(node::MemoryTracker*) const + 134\r\n      frame #4: 0x000000010001a90b node`node::MemoryTracker::Track(node::MemoryRetainer const*, char const*) + 183\r\n      frame #5: 0x000000010003931b node`node::MemoryTracker::TrackField(char const*, node::CleanupHookCallback const&, char const*) + 193\r\n      frame #6: 0x000000010003a2ec node`void node::MemoryTracker::TrackField<std::__1::unordered_set<node::CleanupHookCallback, node::CleanupHookCallback::Hash, node::CleanupHookCallback::Equal, std::__1::allocator<node::CleanupHookCallback> >, std::__1::__hash_const_iterator<std::__1::__hash_node<node::CleanupHookCallback, void*>*> >(char const*, std::__1::unordered_set<node::CleanupHookCallback, node::CleanupHookCallback::Hash, node::CleanupHookCallback::Equal, std::__1::allocator<node::CleanupHookCallback> > const&, char const*, char const*, bool) + 146\r\n      frame #7: 0x0000000100039598 node`node::Environment::MemoryInfo(node::MemoryTracker*) const + 524\r\n      frame #8: 0x000000010001a90b node`node::MemoryTracker::Track(node::MemoryRetainer const*, char const*) + 183\r\n      frame #9: 0x000000010003660d node`node::Environment::BuildEmbedderGraph(v8::Isolate*, v8::EmbedderGraph*, void*) + 131\r\n      frame #10: 0x000000010074f57c node`v8::internal::HeapProfiler::BuildEmbedderGraph(v8::internal::Isolate*, v8::EmbedderGraph*) + 60\r\n      frame #11: 0x00000001007589dc node`v8::internal::NativeObjectsExplorer::IterateAndExtractReferences(v8::internal::HeapSnapshotGenerator*) + 172\r\n      frame #12: 0x0000000100759396 node`v8::internal::HeapSnapshotGenerator::GenerateSnapshot() + 230\r\n      frame #13: 0x000000010074f5f1 node`v8::internal::HeapProfiler::TakeSnapshot(v8::ActivityControl*, v8::HeapProfiler::ObjectNameResolver*) + 97\r\n      frame #14: 0x0000000100940d37 node`v8_inspector::V8HeapProfilerAgentImpl::takeHeapSnapshot(v8_inspector::protocol::Maybe<bool>) + 263\r\n      frame #15: 0x00000001009ff74e node`v8_inspector::protocol::HeapProfiler::DispatcherImpl::takeHeapSnapshot(int, v8_inspector::String16 const&, v8_inspector::protocol::ProtocolMessage const&, std::__1::unique_ptr<v8_inspector::protocol::DictionaryValue, std::__1::default_delete<v8_inspector::protocol::DictionaryValue> >, v8_inspector::protocol::ErrorSupport*) + 382\r\n      frame #16: 0x00000001009fdd94 node`v8_inspector::protocol::HeapProfiler::DispatcherImpl::dispatch(int, v8_inspector::String16 const&, v8_inspector::protocol::ProtocolMessage const&, std::__1::unique_ptr<v8_inspector::protocol::DictionaryValue, std::__1::default_delete<v8_inspector::protocol::DictionaryValue> >) + 116\r\n      frame #17: 0x00000001009db538 node`v8_inspector::protocol::UberDispatcher::dispatch(int, v8_inspector::String16 const&, std::__1::unique_ptr<v8_inspector::protocol::Value, std::__1::default_delete<v8_inspector::protocol::Value> >, v8_inspector::protocol::ProtocolMessage const&) + 584\r\n      frame #18: 0x0000000100948c3a node`v8_inspector::V8InspectorSessionImpl::dispatchProtocolMessage(v8_inspector::StringView const&) + 282\r\n      frame #19: 0x0000000100107001 node`node::inspector::NodeInspectorClient::dispatchMessageFromFrontend(int, v8_inspector::StringView const&) + 239\r\n      frame #20: 0x0000000100106d52 node`node::inspector::(anonymous namespace)::SameThreadInspectorSession::Dispatch(v8_inspector::StringView const&) + 58\r\n```\r\n\r\n    ",
        "labels": "confirmed-bug",
        "id": 45133
    },
    {
        "title": "Undefined variable icu_path during configure when system-icu is set",
        "body": "Version: node-git master branch\r\nPlatform: openSUSE Tumbleweed\r\n\r\n```\r\nnode-git.f585dca83d> ./configure --prefix=/usr --enable-lto --shared-zlib --shared-cares \r\n--with-intl=system-icu --shared-nghttp2 --gdb --without-dtrace --openssl-use-def-ca-store\r\n\r\ngyp: Undefined variable icu_path in\r\n/home/abuild/rpmbuild/BUILD/node-git.f585dca83d/tools/v8_gypfiles/v8.gyp \r\nwhile loading dependencies of /home/abuild/rpmbuild/BUILD/node-git.f585dca83d/node.gyp\r\nwhile trying to load /home/abuild/rpmbuild/BUILD/node-git.f585dca83d/node.gyp\r\nError running GYP\r\n```\r\n\r\nThere are no problems with Node 12.x branches.\r\n\r\n<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "confirmed-bug",
        "id": 45134
    },
    {
        "title": "Delayed setEncoding on Readable causes multibyte characters to break",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.15.3\r\n* **Platform**: `4.15.0-50-generic #54~16.04.1-Ubuntu x86_64 GNU/Linux`\r\n* **Subsystem**: stream/http\r\n\r\n### Server\r\n```javascript\r\nconst http = require('http');\r\n\r\nconst server = http.createServer(async (req, res) => {\r\n    const data = [];\r\n    // simulate some preprocessing - eg. authentication in middleware\r\n    // if setEncoding is called before async operation all works correctly\r\n    await sleep(2000);\r\n    req.setEncoding('utf8');\r\n    req.on('data', (d) => {\r\n        // already buffered chunks are read as buffer, although encoding is set to utf8\r\n        data.push(d);\r\n        console.log(d);\r\n    });\r\n    req.on('end', () => {\r\n        const body = data.join('');\r\n        // expected {\"Å™eÅ™icha\":\"hello ÄaÄa\"} but got {\"ï¿½ï¿½eÅ™icha\":\"hello ÄaÄa\"}\r\n        console.log(body);\r\n        console.log(body.toString());\r\n        res.statusCode = 204;\r\n        res.end();\r\n    });\r\n});\r\n\r\nserver.listen(3000, 'localhost', () => {\r\n    console.log('LISTENING');\r\n});\r\n\r\nasync function sleep(ms = 1000) {\r\n    return new Promise((res) => setTimeout(res, ms));\r\n}\r\n```\r\n### Client\r\n```javascript\r\nconst http = require('http');\r\n\r\nconst data = Buffer.from(JSON.stringify({ Å™eÅ™icha: 'hello ÄaÄa' }));\r\n\r\nasync function main() {\r\n    const req = http.request(\r\n        {\r\n            hostname: 'localhost',\r\n            port: 3000,\r\n            method: 'POST',\r\n            path: '/',\r\n            headers: {\r\n                'content-type': 'application/json',\r\n                'content-length': data.length\r\n            }\r\n        },\r\n        (res) => {\r\n            console.log(res.statusCode);\r\n            console.log(res.headers);\r\n        }\r\n    );\r\n\r\n    const offset = 3;\r\n    // write some bytes\r\n    req.write(data.slice(0, offset));\r\n    for (let i = offset; i < data.length; i++) {\r\n        // simulate very slow connection\r\n        await sleep();\r\n        req.write(data.slice(i, i + 1));\r\n    }\r\n    req.end();\r\n}\r\n\r\nmain();\r\n\r\nasync function sleep(ms = 1000) {\r\n    return new Promise((res) => setTimeout(res, ms));\r\n}\r\n```\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhen setEncoding('utf8') is used on Readable stream (eg. IncomingMessage) with some delay, although no data are read, then already buffered chunks are read as buffer which breaks multibyte characters.\r\n\r\nIf encoding is set immediately, eg. on http 'request' event, than it works properly, however http frameworks (Express, Fastify, Koa) allows including asynchronous middlewares in processing pipeline before body parsing occurs, which delays setEncoding call and thus breaks multibyte characters.\r\n\r\nIncluded code simulates this delay as two first emitted 'data' chunks are buffers which in standard body processing breaks characters if chunk contains only some bytes of unicode character. In case of http body parsing middlewares this also breaks content-length check.\r\n\r\n#### Example body processing middleware from Fastify v1.14.6\r\n```javascript\r\nfunction rawBody (request, reply, options, parser, done) {\r\n  var asString = parser.asString\r\n  var limit = options.limit === null ? parser.bodyLimit : options.limit\r\n  var contentLength = request.headers['content-length'] === undefined\r\n    ? NaN\r\n    : Number.parseInt(request.headers['content-length'], 10)\r\n\r\n  if (contentLength > limit) {\r\n    const err = new Error('Request body is too large')\r\n    err.statusCode = 413\r\n    reply.code(err.statusCode).send(err)\r\n    return\r\n  }\r\n\r\n  var receivedLength = 0\r\n  var body = asString === true ? '' : []\r\n  var req = request.raw\r\n\r\n  if (asString === true) {\r\n    req.setEncoding('utf8')\r\n  }\r\n\r\n  req.on('data', onData)\r\n  req.on('end', onEnd)\r\n  req.on('error', onEnd)\r\n\r\n  function onData (chunk) {\r\n    receivedLength += chunk.length\r\n\r\n    if (receivedLength > limit) {\r\n      req.removeListener('data', onData)\r\n      req.removeListener('end', onEnd)\r\n      req.removeListener('error', onEnd)\r\n      const err = new Error('Request body is too large')\r\n      err.statusCode = 413\r\n      reply.code(err.statusCode).send(err)\r\n      return\r\n    }\r\n\r\n    if (asString === true) {\r\n      // first chunks might be buffers automatically coerced to strings\r\n      // with broken multibytes characters\r\n      body += chunk\r\n    } else {\r\n      body.push(chunk)\r\n    }\r\n  }\r\n\r\n  function onEnd (err) {\r\n    req.removeListener('data', onData)\r\n    req.removeListener('end', onEnd)\r\n    req.removeListener('error', onEnd)\r\n\r\n    if (err !== undefined) {\r\n      err.statusCode = 400\r\n      reply.code(err.statusCode).send(err)\r\n      return\r\n    }\r\n\r\n    if (asString === true) {\r\n      receivedLength = Buffer.byteLength(body)\r\n    }\r\n    if (!Number.isNaN(contentLength) && receivedLength !== contentLength) {\r\n      const err = new Error('Request body size did not match Content-Length')\r\n      err.statusCode = 400\r\n      reply.code(err.statusCode).send(err)\r\n      return\r\n    }\r\n\r\n    if (asString === false) {\r\n      body = Buffer.concat(body)\r\n    }\r\n\r\n    var result = parser.fn(req, body, done)\r\n    if (result && typeof result.then === 'function') {\r\n      result.then(body => done(null, body), done)\r\n    }\r\n  }\r\n}\r\n```",
        "labels": "confirmed-bug",
        "id": 45135
    },
    {
        "title": "console.table splits long strings and breaks formatting in node v12",
        "body": "* **Version**: v12.0 and onwards (checked 12.3.1)\r\n* **Platform**: Darwin 18.6.0 Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019; root:xnu-4903.261.4~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**: console\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nStarting with node v12.0 `console.table` breaks table by splitting long strings with pluses and new lines.\r\n\r\nYou can easily reproduce it:\r\n```bash\r\nnvm install 12.0 # or nvm use 12.0\r\nnode -e \"console.table([{name:'very long long long long long long long long long long long long long long long'}])\" \r\n```\r\n<img width=\"977\" alt=\"Ð¡Ð½Ð¸Ð¼Ð¾Ðº ÑÐºÑ€Ð°Ð½Ð° 2019-05-26 Ð² 22 19 31\" src=\"https://user-images.githubusercontent.com/690135/58384666-36db1f80-8006-11e9-9794-46373a3cb1e2.png\">\r\n\r\n```bash\r\nnvm install 10.15.3 # or nvm use 10.15.3\r\nnode -e \"console.table([{name:'very long long long long long long long long long long long long long long long'}])\"\r\n```\r\n<img width=\"977\" alt=\"Ð¡Ð½Ð¸Ð¼Ð¾Ðº ÑÐºÑ€Ð°Ð½Ð° 2019-05-26 Ð² 22 19 58\" src=\"https://user-images.githubusercontent.com/690135/58384652-085d4480-8006-11e9-8e57-4672c4fe19f5.png\">\r\n\r\n```bash\r\nnvm install 11.15.0 # or nvm use 11.15.0\r\nnode -e \"console.table([{name:'very long long long long long long long long long long long long long long long'}])\"\r\n```\r\n<img width=\"977\" alt=\"Ð¡Ð½Ð¸Ð¼Ð¾Ðº ÑÐºÑ€Ð°Ð½Ð° 2019-05-26 Ð² 22 18 57\" src=\"https://user-images.githubusercontent.com/690135/58384687-81f53280-8006-11e9-95fe-9692c02b9fee.png\">\r\n\r\nUnfortunately i am not able to find a source of issue because code looks too complicated to me.\r\n",
        "labels": "confirmed-bug",
        "id": 45136
    },
    {
        "title": "fs.watch(): reports delete of file as change instead of rename",
        "body": "* **Version**: `12.0.0`\r\n* **Platform**: `Darwin Benjamins-MacBook-Pro.local 18.6.0 Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019; root:xnu-4903.261.4~2/RELEASE_X86_64 x86_64`\r\n\r\nGiven the following code:\r\n\r\n```js\r\nvar fs = require(\"fs\");\r\n\r\nfs.watch('./test.txt', (event, filename) => {\r\n    console.log(event, filename);\r\n})\r\n```\r\n\r\nRunning below in a directory where `test.txt` exists and gets deleted yields different results for `event` in `12.x` vs `10.x`:\r\n* `12.x`: `change`\r\n* `10.x`: `rename`\r\n\r\nThis basically renders `node.js 12` incapable of detecting a file delete vs change when watching it.\r\n",
        "labels": "confirmed-bug",
        "id": 45137
    },
    {
        "title": "REPL: `{} instanceof Object === false` with nodejs 11 and nodejs 12 ",
        "body": "With the given file:\r\n\r\nconsole.js\r\n```js\r\nconst repl = require('repl');\r\nrepl.start('> ');\r\n```\r\n\r\nThen running in nodejs 11 & 12:\r\n\r\n```shell\r\n$ node console.js\r\n\r\n> console.log({} instanceof Object)\r\nfalse\r\n```\r\n\r\nBut running with nodejs 10:\r\n\r\n```shell\r\n$ node console.js\r\n\r\n> console.log({} instanceof Object)\r\ntrue\r\n```\r\n\r\nI am expecting to be `true` in all cases, did I miss something?",
        "labels": "confirmed-bug",
        "id": 45138
    },
    {
        "title": "test-process-env-tz fails",
        "body": "* **Version**:\r\ncurrent master\r\n* **Platform**:\r\nDarwin iMac-Mikhail 17.7.0 Darwin Kernel Version 17.7.0: Wed Apr 24 21:17:24 PDT 2019; root:xnu-4570.71.45~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\nI'm running standard test suite using ```make test-only``` and got \r\n```\r\n=== release test-process-env-tz ===\r\nPath: parallel/test-process-env-tz\r\nassert.js:89\r\n  throw new AssertionError(obj);\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: Expected values to be strictly equal:\r\n+ actual - expected\r\n\r\n+ 'Sat Apr 14 2018 14:34:56 GMT+0200 (GMT+02:00)'\r\n- 'Sat Apr 14 2018 14:34:56 GMT+0200 (CEST)'\r\n    at Object.<anonymous> (/Users/mihan007/Projects/node/test/parallel/test-process-env-tz.js:29:8)\r\n    at Module._compile (internal/modules/cjs/loader.js:774:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:785:10)\r\n    at Module.load (internal/modules/cjs/loader.js:641:32)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:556:12)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:837:10)\r\n    at internal/main/run_main_module.js:17:11 {\r\n  generatedMessage: true,\r\n  code: 'ERR_ASSERTION',\r\n  actual: 'Sat Apr 14 2018 14:34:56 GMT+0200 (GMT+02:00)',\r\n  expected: 'Sat Apr 14 2018 14:34:56 GMT+0200 (CEST)',\r\n  operator: 'strictEqual'\r\n}\r\nCommand: out/Release/node /Users/mihan007/Projects/node/test/parallel/test-process-env-tz.js\r\n```\r\n\r\nMy best guess here that it happens because I'm using Russian locale at my mac.",
        "labels": "confirmed-bug",
        "id": 45139
    },
    {
        "title": "node -p process.verions display issue on Windows Cmd",
        "body": "{\r\n  node: \u001b[32m'12.3.0'\u001b[39m,\r\n  v8: \u001b[32m'7.4.288.27-node.17'\u001b[39m,\r\n  uv: \u001b[32m'1.28.0'\u001b[39m,\r\n  zlib: \u001b[32m'1.2.11'\u001b[39m,\r\n  brotli: \u001b[32m'1.0.7'\u001b[39m,\r\n  ares: \u001b[32m'1.15.0'\u001b[39m,\r\n  modules: \u001b[32m'72'\u001b[39m,\r\n  nghttp2: \u001b[32m'1.38.0'\u001b[39m,\r\n  napi: \u001b[32m'4'\u001b[39m,\r\n  llhttp: \u001b[32m'1.1.3'\u001b[39m,\r\n  http_parser: \u001b[32m'2.8.0'\u001b[39m,\r\n  openssl: \u001b[32m'1.1.1b'\u001b[39m,\r\n  cldr: \u001b[32m'35.1'\u001b[39m,\r\n  icu: \u001b[32m'64.2'\u001b[39m,\r\n  tz: \u001b[32m'2019a'\u001b[39m,\r\n  unicode: \u001b[32m'12.1'\u001b[39m\r\n}",
        "labels": "confirmed-bug",
        "id": 45140
    },
    {
        "title": "util-inl.h missing",
        "body": "* **Version**: v12.3.0\r\n* **Platform**: Darwin Kernel Version 18.6.0: Thu Apr 25 23:16:27 PDT 2019; root:xnu-4903.261.4~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\nnode.h:107 now includes util-inl.h. That file is not shipped by node-gyp though.\r\n\r\n12.2 did not include this file.",
        "labels": "confirmed-bug",
        "id": 45141
    },
    {
        "title": "symlink is - stateful?",
        "body": "Version: v11.6.0\r\nPlatform: Windows 10 (64bit)\r\nSubsystem: fs\r\n\r\nThis is easiest to describe with sample code:\r\n\r\n```\r\nlet shortPath = 'c:\\\\temp\\\\long pathname test';\r\nundefined\r\nlet longPath = 'c:\\\\temp\\\\long pathname test\\\\01234567890123456789012345678901234567890123456789\\\\01234567890123456789012345678901234567890123456789\\\\01234567890123456789012345678901234567890123456789\\\\01234567890123456789012345678901234567890123456789\\\\01234567890123456789012345678901234567890123456789';\r\nundefined\r\nfs.symlinkSync(path.join(shortPath, 'foobar1.jpg'), path.join(longPath, 'foobar1.jpg'));\r\nundefined\r\nfs.symlinkSync(path.join(longPath, 'foobar2.jpg'), path.join(shortPath, 'foobar2.jpg'));\r\n{ Error: EPERM: operation not permitted, symlink ...}\r\nfs.unlinkSync(path.join(longPath, 'foobar1.jpg'))\r\nundefined\r\nfs.symlinkSync(path.join(shortPath, 'foobar1.jpg'), path.join(longPath, 'foobar1.jpg'));\r\n{ Error: EPERM: operation not permitted, symlink ...}\r\n```\r\n\r\n\r\nNow there are a few oddities here\r\na) I can link from a short path to a long one (> MAX_PATH) but not the other way around\r\nb) The error reported is EPERM for some reason, not ENAMETOOLONG or EINVAL\r\nc) after that error has been reported, even the original call linking from short to long fails\r\n\r\nc is the most scary of them because it indicates there is some global internal state that gets flipped and breaks all further calls? How does that make sense?\r\n\r\nThis is independent of the unlink call btw., this problem also happens if I remove the link outside node or if I use a third file.",
        "labels": "confirmed-bug",
        "id": 45142
    },
    {
        "title": "Unable to reassign negative zero object property to positive zero",
        "body": "- **Version:** v12.2.0\r\n- **Platform:** Darwin Kernel Version 18.5.0: Mon Mar 11 20:40:32 PDT 2019; root:xnu-4903.251.3~3/RELEASE_X86_64 x86_64\r\n\r\nSome object properties cannot be assigned to `0` if they currently have a value of `-0`, without being first set to a non-zero value.\r\n\r\n```javascript\r\nconst duration = {\r\n\tyears: -0,\r\n\tmonths: -0,\r\n\tweeks: -0,\r\n\tdays: -0,\r\n\thours: -0,\r\n\tminutes: -0,\r\n\tseconds: -0,\r\n\tmilliseconds: -0\r\n};\r\n\r\nObject.keys(duration).forEach(key => {\r\n\tduration[key] = 0;\r\n});\r\n\r\nconsole.log(duration);\r\n/* âœ… For node v11.11.0, all values on `duration` are logged as positive 0.\r\n * âŒ For node v12.2.0, the logged output is consistently as follows:\r\n * {\r\n *   years: 0,\r\n *   months: 0,\r\n *   weeks: 0,\r\n *   days: -0,\r\n *   hours: -0,\r\n *   minutes: -0,\r\n *   seconds: -0,\r\n *   milliseconds: -0\r\n * }\r\n */\r\n\r\n// Expected behaviour can be achieved by changing the value to a non-zero value first:\r\nObject.keys(duration).forEach(key => {\r\n\tduration[key] = 1;\r\n\tduration[key] = 0;\r\n});\r\n\r\nconsole.log(duration);\r\n// âœ… Correct for both v11.11.0 and v12.2.0\r\n```",
        "labels": "confirmed-bug",
        "id": 45143
    },
    {
        "title": "`node -c` rejects BOM before #!, but `node` accepts it",
        "body": "Version: v12.1.0\r\n\r\n```shell\r\n$ node -e 'require(\"fs\").writeFileSync(\"test.js\", `\\u{FEFF}#!`, \"utf8\")'\r\n$ node -c test.js\r\n(function (exports, require, module, __filename, __dirname) { #!\r\n                                                              ^\r\nSyntaxError: Invalid or unexpected token\r\n$ echo $?\r\n1\r\n$ node test.js\r\n$ echo $?\r\n0\r\n```\r\n\r\nThe bug is that [`check_syntax.js` call `stripShebang` before `stripBOM`](https://github.com/nodejs/node/blob/bfbc035033e4cedbe039a9757da693c50ac44c5c/lib/internal/main/check_syntax.js#L52-L74), but the actual loader calls [stripBOM](https://github.com/nodejs/node/blob/bfbc035033e4cedbe039a9757da693c50ac44c5c/lib/internal/modules/cjs/loader.js#L785) before [stripShebag](https://github.com/nodejs/node/blob/bfbc035033e4cedbe039a9757da693c50ac44c5c/lib/internal/modules/cjs/loader.js#L703).\r\n\r\nIt's not totally clear which behavior is desired. The [original bug](https://github.com/nodejs/node-v0.x-archive/issues/1440) which lead to [the introduction of `stripBOM`](https://github.com/nodejs/node/commit/ac722bbed6ea846991904ed205a6dc5ece4748c9) actually had a script with a BOM preceding the `#!`, though the test included in that commit doesn't. But unix systems generally require the `#!` to be the first two bytes for it to be parsed as an interpreter directive, which means it cannot be preceded by a BOM.",
        "labels": "confirmed-bug",
        "id": 45144
    },
    {
        "title": "Event loop execution order changes based on code part that didn't executed",
        "body": "* **Node.js Version**: v10.14.1\r\n* **OS**: Windows10x64\r\n\r\nNo need to init new project. Only the built-in `fs` module used there.\r\n\r\nI have a code that works as designed in Unix based OS, but in windows, it gives the \"strange\" result.\r\nCode \r\n```js\r\nconst fs = require('fs');\r\n\r\nfunction someAsyncOperation(callback) {\r\n  fs.readFile('/path/to/file', callback);\r\n}\r\n\r\nconst timeoutScheduled = Date.now();\r\n\r\nsetTimeout(() => {\r\n  const delay = Date.now() - timeoutScheduled;\r\n\r\n  console.log(`${delay}ms have passed since I was scheduled`);\r\n}, 1000);\r\n\r\nsomeAsyncOperation(() => {\r\n  console.log('BEFORE WHILE');\r\n  const startCallback = Date.now();\r\n\r\n  while (Date.now() - startCallback < 1000) {\r\n    // do nothing\r\n  }\r\n\r\n  // setImmediate(() => { console.log('IMMEDIATE'); });\r\n\r\n  console.log('AFTER WHILE');\r\n});\r\n```\r\nThe output is\r\n```cmd\r\nBEFORE WHILE\r\nAFTER WHILE\r\n2007ms have passed since I was scheduled\r\n```\r\nThe output is the same independently of how many timers are present. ( it's always 2000+ )\r\n\r\nWhich is weird. I guess that such a result is possible if the `setTimeout` ( I mean the `setTimeout` itself, not the`setTimeout`'s callback ) registered AFTER `while` loop work. \r\n\r\nPay attention at `// setImmediate(() => { console.log('IMMEDIATE'); });` line.\r\nIf I uncomment it the output will be \r\n```cmd\r\nBEFORE WHILE\r\nAFTER WHILE\r\nIMMEDIATE\r\n1005ms have passed since I was scheduled\r\n```\r\nIn Unix based system the output always {1000+}ms, and doesn't depend on `setImmediate` existence.\r\n\r\nCan someone explain why it happens, and give event loop execution order?\r\n\r\nIt's maybe a BUG, but I'm not sure.\r\n\r\nThanks in advance.\r\n\r\n**Update:** This message is copied from https://github.com/nodejs/help/issues/1912 ",
        "labels": "confirmed-bug",
        "id": 45145
    },
    {
        "title": "Node fs.copyfileSync hangs when source and destination are identical",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.15.3\r\n* **Platform**: 4.15.0-46-generic #49~16.04.1-Ubuntu x86_64\r\n* **Subsystem**: fs\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nUnless the `fs.constants.COPYFILE_EXCL` flag is passed, when `source` and `destination` are the same, Node hangs forever.\r\n\r\n```\r\nconst fs = require('fs'); \r\n\r\nfs.writeFileSync('foo', 'Hello World!');\r\nfs.copyFileSync('foo', 'foo');\r\n\r\n//Never reach here\r\nconsole.log('Done');\r\n``` \r\n",
        "labels": "confirmed-bug",
        "id": 45146
    },
    {
        "title": "Performance issue in NodeJS >= 10.0.0",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10.0.0\r\n* **Platform**: Linux PC 5.0.10-arch1-1-ARCH #1 SMP PREEMPT Sat Apr 27 20:06:45 UTC 2019 x86_64 GNU/Linux\r\n* **Subsystem**: v8\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nNot sure if this is the right place but I may have found a possible performance issue in NodeJS JavaScript execution.\r\nWhile execution of [this example script](https://gist.github.com/hellivan/3331677eba2589b8cb32ef9177787dc4) on a NodeJS runtime <10.0.0 runs smoothly, it freezes on NodeJS runtimes >= 10.0.0 for an indefinite amount of time.\r\nI tested the script for all latest major releases of NodeJS and got the following results:\r\n* 8.16.0: Runs smoothly\r\n* 9.11.2: Runs smoothly\r\n* 10.0.0: Freeze\r\n* 10.15.3: Freeze\r\n* 11.15.0: Freeze\r\n* 12.2.0: Freeze\r\n\r\nI tested the script on different machines (including windows hosts), always getting the same result.\r\nDue to the facts that the example-script is a pure JavaScript file with no dependencies on any NodeJS or external modules, and that the issue occurred first in NodeJS version 10.0.0 I assume that it has to do something with the upgrade of V8 Runtime from 6.2 to 6.6, which was listed in the changelog ov NodeJS version 10.0.0.\r\n\r\n**NB**: I discovered this issue after upgrading a service to newest NodeJS runtime. The service is responsible for validating arbitrary Data against a defined JSONSchema. Validation is implemented using an external library called AJV. After the update, the service started to freeze sporadically during validation process. The provided example script therefore contains an example of a validation function generated by AJV library and some sample data (array of 1000 elements) for which validation will freeze after some time (on my machine, depending on NodeJs version at element no ~594 or  no ~610). ",
        "labels": "confirmed-bug",
        "id": 45147
    },
    {
        "title": "Node.js 12.0.0 changes how arrays with symbol properties are compared using deepEqual()",
        "body": "Hi, it looks like Node 12 changed how arrays are compared with `deepEqual()`, presumably due to https://github.com/nodejs/node/pull/25008/files . Here's an example of how `deepEqual()` handles arrays with symbol properties:\r\n\r\n```javascript\r\nconst assert = require('assert');\r\n\r\nconsole.log(process.version);\r\n\r\nconst s = Symbol('foo');\r\n\r\nconst arr = [];\r\narr[s] = 42;\r\n\r\nassert.deepEqual(arr, []);\r\n```\r\n\r\nRunning this script with Node.js 11.9.0 succeeds:\r\n\r\n```\r\n$ ~/Workspace/libs/node-v11.9.0-linux-x64/bin/node test.js \r\nv11.9.0\r\n$\r\n```\r\n\r\nRunning with Node.js 12 fails:\r\n\r\n```\r\n$ ~/Workspace/libs/node-v12.0.0-linux-x64/bin/node test.js \r\nv12.0.0\r\nassert.js:89\r\n  throw new AssertionError(obj);\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: Expected values to be loosely deep-equal:\r\n\r\n[\r\n  [Symbol(foo)]: 42\r\n]\r\n\r\nshould equal\r\n\r\n[]\r\n$ \r\n```\r\n\r\nIs this a bug or expected behavior? If so, you should update the [legacy mode `deepEqual()` docs](https://nodejs.org/api/assert.html#assert_assert_deepequal_actual_expected_message), which explicitly state that symbol properties are ignored.\r\n\r\nRelated to https://github.com/Automattic/mongoose/pull/7784.",
        "labels": "confirmed-bug",
        "id": 45148
    },
    {
        "title": "Inspector segmentation fault",
        "body": "* **Version**: 12.2.0\r\n* **Platform**: Windows 10, Linux Ubuntu 18.0, Mac HighSierra\r\n* **Subsystem**: inspector\r\n\r\nAccessing `this` in static class field initialization context in some conditions crashes the process. This seems to be related both to Node.js inspector and Chrome devtool inspector.\r\n\r\nHere is an automated repro:\r\n\r\n```js\r\n'use strict';\r\n\r\n~class{a(){}};\r\ndebugger;\r\nclass A{static a = this};\r\nif(process.argv.includes('test')) return;\r\n\r\nconst cp = require('child_process');\r\nconst proc1 = cp.spawn(process.execPath, ['--inspect-brk', __filename, 'test']);\r\nconst proc2 = cp.spawn(process.execPath, ['inspect', '-p', proc1.pid]);\r\n\r\nproc1.on('exit', (code, signal) => {\r\n  if(code) console.log('Exit code: ' + code.toString(16).toUpperCase());\r\n  if(signal) console.log('Exit signal: ' + signal);\r\n});\r\n\r\nsetTimeout(() => proc2.stdin.write('c\\n'), 1000);\r\nsetTimeout(() => proc2.stdin.write('s\\n'), 1100);\r\nsetTimeout(() => proc2.stdin.write('repl\\n'), 1200);\r\nsetTimeout(() => proc2.stdin.write('this\\n'), 1300);\r\n```\r\n\r\nSave as `main.js`, then run `node main.js`\r\nOutput:\r\n\r\n```\r\nExit code: C0000005   // On Windows\r\nExit signal: SIGSEGV  // On Linux and Mac\r\n```",
        "labels": "confirmed-bug",
        "id": 45149
    },
    {
        "title": "HTTP response corrupted with status 400 when URL includes pipe character (`|`)",
        "body": "* **Version**: v12.1.0 v12.0.0\r\n* **Platform**: MacOS 10.14.2 - Darwin Kernel Version 18.5.0: Mon Mar 11 20:40:32 PDT 2019; root:xnu-4903.251.3~3/RELEASE_X86_64 x8\r\n6_64\r\n\r\nMy code:\r\n\r\n`index.js`\r\n\r\n```\r\nvar http = require('http');\r\nvar url = require('url');\r\n\r\nhttp.createServer(function (req, res) {\r\n  res.writeHead(200, { 'Content-Type': 'text/html' });\r\n  var q = url.parse(req.url, true).query;\r\n  var search = q.search;\r\n  res.end(search);\r\n}).listen(8080);\r\n```\r\n\r\nStarting command: `node index.js`\r\n\r\nChrome: Version 74.0.3729.131 (Official Build) (64-bit)\r\n\r\nWhen I try to request to my http service, it is working fine with normal url like\r\n`http://localhost:8080/?search=example`\r\n\r\nBut, when the url come to `http://localhost:8080/?search=example|` or `http://localhost:8080/?sea|rch=example` . My browser gets back **This page isnâ€™t working** and `HTTP ERROR 400`  (the request did not appeared on Network tab of Chrome devtool) .\r\n\r\nTry again with `curl` or `Postman`, these urls are working fine ðŸ¤” \r\n\r\n=> When I use older node version like `v11.11.0` I don't get any errors.\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45150
    },
    {
        "title": "second pass phantom callback leads to infinite recursion",
        "body": "In my GN build, I'm observing this failure:\r\n\r\n* Run `./node test/parallel/test-repl-tab-complete.js`\r\n* Observe assertion failure.\r\n\r\n```\r\n#\r\n# Fatal error in ../../v8/src/execution.cc, line 224\r\n# Check failed: AllowJavascriptExecution::IsAllowed(isolate).\r\n#\r\n```\r\n\r\nThe stack trace I get is this\r\n\r\n```\r\n[0 ] v8::base::OS::Abort()                                        ../../v8/src/base/platform/platform-posix.cc:400\r\n[1 ] V8_Fatal(char const*, int, char const*, ...)                 ../../v8/src/base/logging.cc:171        \r\n[2 ] v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) ../../v8/src/execution.cc:224           \r\n[3 ] v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) ../../v8/src/execution.cc:358           \r\n[4 ] v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) ../../v8/src/api.cc:4992                \r\n[5 ] Emit                                                         ../../node/src/async_wrap.cc:122        \r\n[6 ] node::AsyncWrap::EmitBefore(node::Environment*, double)      ../../node/src/async_wrap.cc:149        \r\n[7 ] InternalCallbackScope                                        ../../node/src/api/callback.cc:65       \r\n[8 ] InternalMakeCallback                                         ../../node/src/api/callback.cc:145      \r\n[9 ] node::AsyncWrap::MakeCallback(v8::Local<v8::Function>, int, v8::Local<v8::Value>*) ../../node/src/async_wrap.cc:692        \r\n[10] OnMessage                                                    ../../node/src/inspector_js_api.cc:75   \r\n[11] SendMessageToFrontend                                        ../../node/src/inspector_js_api.cc:56   \r\n[12] node::inspector::(anonymous namespace)::ChannelImpl::sendMessageToFrontend(v8_inspector::StringView const&) ../../node/src/inspector_agent.cc:280   \r\n[13] node::inspector::(anonymous namespace)::ChannelImpl::sendNotification(std::__1::unique_ptr<v8_inspector::StringBuffer, std::__1::default_delete<v8_inspector::StringBuffer> >) ../../node/src/inspector_agent.cc:274   \r\n[14] v8_inspector::V8InspectorSessionImpl::sendProtocolNotification(std::__1::unique_ptr<v8_inspector::protocol::Serializable, std::__1::default_delete<v8_inspector::protocol::Serializable> >) ../../v8/src/inspector/v8-inspector-session-impl.cc:182\r\n[15] v8_inspector::protocol::Runtime::Frontend::executionContextDestroyed(int) gen/v8/src/inspector/protocol/Runtime.cpp:1337\r\n[16] v8_inspector::V8RuntimeAgentImpl::reportExecutionContextDestroyed(v8_inspector::InspectedContext*) ../../v8/src/inspector/v8-runtime-agent-impl.cc:820\r\n[17] v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1::operator()(v8_inspector::V8InspectorSessionImpl*) const ../../v8/src/inspector/v8-inspector-impl.cc:236\r\n[18] std::__1::__invoke<v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1&, v8_inspector::V8InspectorSessionImpl*> ../../buildtools/third_party/libc++/trunk/include/type_traits:4399\r\n[19] void std::__1::__invoke_void_return_wrapper<void>::__call<v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1&, v8_inspector::V8InspectorSessionImpl*>(v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1&, v8_inspector::V8InspectorSessionImpl*&&) ../../buildtools/third_party/libc++/trunk/include/__functional_base:348\r\n[20] std::__1::__function::__alloc_func<v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1, std::__1::allocator<v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1>, void (v8_inspector::V8InspectorSessionImpl*)>::operator()(v8_inspector::V8InspectorSessionImpl*&&) ../../buildtools/third_party/libc++/trunk/include/functional:1531\r\n[21] void std::__1::__function::__policy_invoker<void (v8_inspector::V8InspectorSessionImpl*)>::__call_impl<std::__1::__function::__alloc_func<v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1, std::__1::allocator<v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1>, void (v8_inspector::V8InspectorSessionImpl*)> >(std::__1::__function::__policy_storage const*, v8_inspector::V8InspectorSessionImpl*) ../../buildtools/third_party/libc++/trunk/include/functional:2014\r\n[22] std::__1::__function::__policy_func<void (v8_inspector::V8InspectorSessionImpl*)>::operator()(v8_inspector::V8InspectorSessionImpl*&&) const ../../buildtools/third_party/libc++/trunk/include/functional:2127\r\n[23] std::__1::function<void (v8_inspector::V8InspectorSessionImpl*)>::operator()(v8_inspector::V8InspectorSessionImpl*) const ../../buildtools/third_party/libc++/trunk/include/functional:2351\r\n[24] v8_inspector::V8InspectorImpl::forEachSession(int, std::__1::function<void (v8_inspector::V8InspectorSessionImpl*)> const&) ../../v8/src/inspector/v8-inspector-impl.cc:392\r\n[25] v8_inspector::V8InspectorImpl::contextCollected(int, int)    ../../v8/src/inspector/v8-inspector-impl.cc:235\r\n[26] v8_inspector::InspectedContext::WeakCallbackData::callContextCollected(v8::WeakCallbackInfo<v8_inspector::InspectedContext::WeakCallbackData> const&) ../../v8/src/inspector/inspected-context.cc:38\r\n[27] v8::internal::GlobalHandles::PendingPhantomCallback::Invoke(v8::internal::Isolate*, v8::internal::GlobalHandles::PendingPhantomCallback::InvocationType) ../../v8/src/global-handles.cc:1098     \r\n[28] v8::internal::GlobalHandles::InvokeSecondPassPhantomCallbacks() ../../v8/src/global-handles.cc:968      \r\n[29] v8::internal::Heap::CollectGarbage(v8::internal::AllocationSpace, v8::internal::GarbageCollectionReason, v8::GCCallbackFlags) ../../v8/src/heap/heap.cc:1337          \r\n[30] v8::internal::Heap::AllocateRawWithLightRetry(int, v8::internal::AllocationType, v8::internal::AllocationAlignment) ../../v8/src/heap/heap.cc:4514          \r\n[31] v8::internal::Heap::AllocateRawWithRetryOrFail(int, v8::internal::AllocationType, v8::internal::AllocationAlignment) ../../v8/src/heap/heap.cc:4528          \r\n[32] v8::internal::Factory::AllocateRawWithImmortalMap(int, v8::internal::AllocationType, v8::internal::Map, v8::internal::AllocationAlignment) ../../v8/src/heap/factory.cc:136        \r\n[33] v8::internal::Factory::NewRawOneByteString(int, v8::internal::AllocationType) ../../v8/src/heap/factory.cc:1000       \r\n[34] v8::internal::Factory::NewStringFromTwoByte(unsigned short const*, int, v8::internal::AllocationType) ../../v8/src/heap/factory.cc:779        \r\n[35] v8::internal::Factory::NewStringFromTwoByte(v8::internal::Vector<unsigned short const>, v8::internal::AllocationType) ../../v8/src/heap/factory.cc:796        \r\n[36] v8::(anonymous namespace)::NewString(v8::internal::Factory*, v8::NewStringType, v8::internal::Vector<unsigned short const>) ../../v8/src/api.cc:6363                \r\n[37] v8::String::NewFromTwoByte(v8::Isolate*, unsigned short const*, v8::NewStringType, int) ../../v8/src/api.cc:6428                \r\n[38] SendMessageToFrontend                                        ../../node/src/inspector_js_api.cc:53   \r\n[39] node::inspector::(anonymous namespace)::ChannelImpl::sendMessageToFrontend(v8_inspector::StringView const&) ../../node/src/inspector_agent.cc:280   \r\n[40] node::inspector::(anonymous namespace)::ChannelImpl::sendNotification(std::__1::unique_ptr<v8_inspector::StringBuffer, std::__1::default_delete<v8_inspector::StringBuffer> >) ../../node/src/inspector_agent.cc:274   \r\n[41] v8_inspector::V8InspectorSessionImpl::sendProtocolNotification(std::__1::unique_ptr<v8_inspector::protocol::Serializable, std::__1::default_delete<v8_inspector::protocol::Serializable> >) ../../v8/src/inspector/v8-inspector-session-impl.cc:182\r\n[42] v8_inspector::protocol::Runtime::Frontend::executionContextDestroyed(int) gen/v8/src/inspector/protocol/Runtime.cpp:1337\r\n[43] v8_inspector::V8RuntimeAgentImpl::reportExecutionContextDestroyed(v8_inspector::InspectedContext*) ../../v8/src/inspector/v8-runtime-agent-impl.cc:820\r\n[44] v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1::operator()(v8_inspector::V8InspectorSessionImpl*) const ../../v8/src/inspector/v8-inspector-impl.cc:236\r\n[45] std::__1::__invoke<v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1&, v8_inspector::V8InspectorSessionImpl*> ../../buildtools/third_party/libc++/trunk/include/type_traits:4399\r\n[46] void std::__1::__invoke_void_return_wrapper<void>::__call<v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1&, v8_inspector::V8InspectorSessionImpl*>(v8_inspector::V8InspectorImpl::contextCollected(int, int)::$_1&, v8_inspector::V8InspectorSessionImpl*&&) ../../buildtools/third_party/libc++/trunk/include/__functional_base:348\r\n```\r\n\r\nI think the assertion failure is actually a red herring.\r\n\r\nWhat actually happens is that during GC, we trigger a second-pass-phantom-callback. That sends a notification to the inspector, which in `inspector_js_api.cc` tries to allocate a string to pass that along. Only, allocating the string fails, because we are not done with GC yet. So we perform GC.\r\n\r\nThat triggers a recursion until we run out of stack, in which case things start to behave weirdly and we get this assertion failure. This weirdness does not reproduce on the regular Node build. The following patch helps with reproducing this on the regular Node build though:\r\n\r\n```\r\ndiff --git a/deps/v8/src/heap/heap.cc b/deps/v8/src/heap/heap.cc\r\nindex e72269d40a..9e02bab258 100644\r\n--- a/deps/v8/src/heap/heap.cc\r\n+++ b/deps/v8/src/heap/heap.cc\r\n@@ -1335,7 +1335,11 @@ bool Heap::CollectGarbage(AllocationSpace space,\r\n   }\r\n \r\n   // Ensure that all pending phantom callbacks are invoked.\r\n-  isolate()->global_handles()->InvokeSecondPassPhantomCallbacks();\r\n+  {\r\n+    DCHECK(AllowHeapAllocation::IsAllowed());\r\n+    DisallowHeapAllocation no_allocation_during_gc;\r\n+    isolate()->global_handles()->InvokeSecondPassPhantomCallbacks();\r\n+  }\r\n \r\n   // The VM is in the GC state until exiting this function.\r\n   VMState<GC> state(isolate());\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45151
    },
    {
        "title": "console.time measuring lot of time the first time that is being executed",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.15.0\r\n* **Platform**: Darwin MacBook-Pro.local 18.5.0 Darwin Kernel Version 18.5.0: Mon Mar 11 20:40:32 PDT 2019; root:xnu-4903.251.3~3/RELEASE_X86_64 x86_64\r\n* **Subsystem**: Not known\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThe first time that console.time function is used, it is measuring more time than the following calls. This is a minimum code to reproduce the issue:\r\n\r\n```javascript\r\nconsole.time('time1');\r\nconsole.timeEnd('time1');\r\n\r\nconsole.time('time2');\r\nconsole.timeEnd('time2');\r\n\r\n```\r\nIt results in:\r\n\r\n```\r\ntime1: 0.380ms\r\ntime2: 0.035ms\r\n```\r\n\r\nThis impact directly in time measurement for any function executed in node and can lead to false results.\r\n\r\n\r\nAny idea about?\r\n",
        "labels": "confirmed-bug",
        "id": 45152
    },
    {
        "title": "UTF Characters for relative path",
        "body": "Version: 10.15.3\r\nPlatform: Windows 64bit\r\nSubsystem: \"path\" module\r\n\r\n```\r\nconst path = require(\"path\");\r\n\r\nconst rootPath = \"Ä°\"; // Turkish character, char code 304\r\nconst absolute = \"c:\\\\Users\\\\root\\\\Documents\\\\Ä°\\\\test.txt\";\r\n\r\nconst relative = path.relative(rootPath, absolute); // est.txt\r\n```\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nExpected result: `test.txt`\r\nActual result: `est.txt`",
        "labels": "confirmed-bug",
        "id": 45153
    },
    {
        "title": "Segfaults with dynamic imports and mocha",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 12.1.0\r\n* **Platform**: Linux 5.0.9 64-bit\r\n* **Subsystem**: modules\r\n\r\n<!-- Please provide more details below this comment. -->\r\nI am testing the new ESM implementation on one of my projects. I am able to consistently get segfaults when using experimental modules and dynamic imports with mocha unit tests.\r\n\r\nI extracted a reproducible example to [demurgos/node-esm-sigsegv](https://github.com/demurgos/node-esm-sigsegv). I am working on reducing the example to be minimal.\r\n\r\nThe README.md has more details, here is a summary:\r\n\r\nYou can clone the repo, install the dependencies and run the following command:\r\n```\r\nnode --experimental-modules --es-module-specifier-resolution=node node_modules/mocha/bin/_mocha build/test/test.esm.js --delay --async --no-config --no-package --no-opts --diff --extension js --reporter spec --slow 75 --timeout 2000 --ui bdd\r\n```\r\n\r\nThe segfault occurs while evaluating the function in [test.esm.js](https://github.com/demurgos/node-esm-sigsegv/blob/master/build/test/test.esm.js).\r\nThis function sequentially dynamically imports ESM spec files.\r\n\r\nWhen importing a single file, the execution succeeds.\r\nWhen importing 2 or 3 files, the execution segfaults 25% of the time.\r\nWhen importing more files, the execution always segfaults.\r\n\r\nI don't know the exact cause of the segfault yet. I am working on isolating it to a minimal example.\r\nIt is worth noting that Mocha injects global variables (which may interact badly with ES modules). It may also be a mocha bug, at the moment I am suspecting an ESM issue because it is a C++ crash (and not a JS exception).",
        "labels": "confirmed-bug",
        "id": 45154
    },
    {
        "title": "REPL: Node 12.0.0 unable to parse class properties ",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v12.0.0\r\n* **Platform**: Darwin XX.z 18.5.0 Darwin Kernel Version 18.5.0: Mon Mar 11 20:40:32 PDT 2019; root:xnu-4903.251.3~3/RELEASE_X86_64 x86_64\r\n\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n<img width=\"363\" alt=\"Screenshot 2019-04-24 at 19 50 35\" src=\"https://user-images.githubusercontent.com/12004383/56685604-3e876b80-66ca-11e9-9963-287f522cd788.png\">\r\n<img width=\"325\" alt=\"Screenshot 2019-04-24 at 19 52 05\" src=\"https://user-images.githubusercontent.com/12004383/56685726-80b0ad00-66ca-11e9-802a-4fbb1472703a.png\">\r\n",
        "labels": "confirmed-bug",
        "id": 45155
    },
    {
        "title": "Node.js crash with a fatal error on Date#toLocaleString",
        "body": "* **Version**: 12.0.0\r\n* **Platform**: Windows (Japanese)\r\n* **Subsystem**:\r\n\r\nNode.js crash with a fatal error on a call of `Date#toLocaleString`.\r\nI know that Node.js doesn't contain full ICU, but I didn't expect it to crash with a fatal error.\r\n\r\n```\r\n> node -e \"new Date().toLocaleString()\"\r\n\r\n#\r\n# Fatal error in , line 0\r\n# Check failed: U_SUCCESS(status).\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 000000F1A52FD440\r\n```",
        "labels": "confirmed-bug",
        "id": 45156
    },
    {
        "title": "Latest Node.js crashes when ran with --interpreted-frames-native-stack",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `master` / v12.0.0\r\n* **Platform**: any\r\n* **Subsystem**: V8\r\n\r\nThis is an upstream bug and there's already an [issue in the V8 tracker](https://bugs.chromium.org/p/v8/issues/detail?id=9122) as well as a [PR](https://chromium-review.googlesource.com/c/v8/v8/+/1570582) to fix it, but since we're about to release v12.0.0 and the issue will be present there, I think it's a good idea to have this registered here in case users stumble upon that.\r\n\r\n---\r\n\r\nThe `--interpreted-frames-native-stack` flag - which is used to allow system profilers to understand V8 interpreted frames - is not compatible with code cache, which we introduced a while back in https://github.com/nodejs/node/pull/24950. If we try to run Node.js with this flag - regardless of the script being executed -, Node.js will crash:\r\n\r\n```\r\n$ ./node --interpreted-frames-native-stack\r\n#\r\n# Fatal error in , line 0\r\n# Check failed: !obj->IsCode().\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 0x7ffc8458e3a0[1]    16377 illegal hardware instruction (core dumped)  ./node --interpreted-frames-native-stack\r\n```\r\n\r\nWe need to backport https://chromium-review.googlesource.com/c/v8/v8/+/1570582 once it lands upstream, as well as re-enable the Linux perf tests on our V8 CI machines (https://github.com/nodejs/build/issues/1774) once the flag is fixed.",
        "labels": "confirmed-bug",
        "id": 45157
    },
    {
        "title": "--cpu-prof crashes in debug builds when code cache is enabled",
        "body": "This currently fails the debug build on master, the CPU profiler crashes when code cache is enabled (for some reason, `this` in `v8::internal::ProfilerListener::InferScriptName` turns into a nullptr in the middle of the profiling).\r\n\r\n```\r\n./configure --debug\r\nmake -C out\r\nout/Debug/node --cpu-prof test/fixtures/workload/fibonacci.js # or any script\r\n```\r\n\r\n<details>\r\n<summary>See stack trace </summary>\r\n\r\n```\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=EXC_I386_GPFLT)\r\n  * frame #0: 0x0000000100f738d1 node`v8::internal::ProfilerListener::InferScriptName(v8::internal::Name, v8::internal::SharedFunctionInfo) [inlined] v8::internal::Map::instance_type() const at map-inl.h:293 [opt]\r\n    frame #1: 0x0000000100f738d1 node`v8::internal::ProfilerListener::InferScriptName(v8::internal::Name, v8::internal::SharedFunctionInfo) [inlined] v8::internal::HeapObject::IsString() const at instance-type-inl.h:70 [opt]\r\n    frame #2: 0x0000000100f738c1 node`v8::internal::ProfilerListener::InferScriptName(this=0x0000000000000000, name=<unavailable>, info=SharedFunctionInfo @ 0x00007ffeefbfbb30) at profiler-listener.cc:265 [opt]\r\n    frame #3: 0x0000000100f74ba8 node`v8::internal::ProfilerListener::CodeCreateEvent(this=0x0000000103e1b9b0, tag=SCRIPT_TAG, abstract_code=<unavailable>, shared=SharedFunctionInfo @ 0x00007ffeefbfbd38, script_name=Name @ 0x00007ffeefbfbc28, line=1, column=1) at profiler-listener.cc:172 [opt]\r\n    frame #4: 0x00000001010dc732 node`v8::internal::CodeSerializer::Deserialize(v8::internal::Isolate*, v8::internal::ScriptData*, v8::internal::Handle<v8::internal::String>, v8::ScriptOriginOptions) [inlined] v8::internal::CodeEventDispatcher::CodeCreateEvent(this=<unavailable>, tag=SCRIPT_TAG, code=AbstractCode @ r12, shared=SharedFunctionInfo @ 0x00007ffeefbfbed0, source=Name @ 0x00007ffeefbfbe90, line=1, column=<unavailable>) at code-events.h:142 [opt]\r\n    frame #5: 0x00000001010dc6dc node`v8::internal::CodeSerializer::Deserialize(isolate=0x0000000106000000, cached_data=<unavailable>, source=Handle<v8::internal::String> @ 0x00007ffeefbfbed0, origin_options=<unavailable>) at code-serializer.cc:276 [opt]\r\n    frame #6: 0x00000001006edffe node`v8::internal::Compiler::GetWrappedFunction(source=<unavailable>, arguments=<unavailable>, context=<unavailable>, script_details=0x00007ffeefbfc1f0, origin_options=(flags_ = 1), cached_data=<unavailable>, compile_options=kConsumeCodeCache, no_cache_reason=kNoCacheNoReason) at compiler.cc:1936 [opt]\r\n    frame #7: 0x0000000100531b50 node`v8::ScriptCompiler::CompileFunctionInContext(v8_context=<unavailable>, source=<unavailable>, arguments_count=<unavailable>, arguments=0x00000001050311d0, context_extension_count=0, context_extensions=0x0000000000000000, options=kConsumeCodeCache, no_cache_reason=kNoCacheNoReason) at api.cc:2545 [opt]\r\n    frame #8: 0x000000010022bd19 node`node::native_module::NativeModuleLoader::LookupAndCompile(this=0x0000000102951e38, context=(val_ = 0x0000000107012720), id=\"path\", parameters=0x00007ffeefbfced0 size=6, result=0x00007ffeefbfd054) at node_native_module.cc:217\r\n    frame #9: 0x000000010022ad0e node`node::native_module::NativeModuleLoader::CompileAsModule(this=0x0000000102951e38, context=(val_ = 0x0000000107012720), id=\"path\", result=0x00007ffeefbfd054) at node_native_module.cc:173\r\n    frame #10: 0x00000001002373ae node`node::native_module::NativeModuleEnv::CompileFunction(args=0x00007ffeefbfd510) at node_native_module_env.cc:128\r\n    frame #11: 0x000000010063765e node`v8::internal::FunctionCallbackArguments::Call(this=0x00007ffeefbfd590, handler=<unavailable>) at api-arguments-inl.h:157 [opt]\r\n    frame #12: 0x00000001006358c4 node`v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(isolate=0x0000000106000000, function=<unavailable>, new_target=<unavailable>, fun_data=<unavailable>, receiver=<unavailable>, args=BuiltinArguments @ 0x00007ffeefbfd640) at builtins-api.cc:109 [opt]\r\n    frame #13: 0x0000000100633105 node`v8::internal::Builtin_Impl_HandleApiCall(args=BuiltinArguments @ 0x00007ffeefbfd680, isolate=0x0000000106000000) at builtins-api.cc:139 [opt]\r\n    frame #14: 0x0000000100632c79 node`v8::internal::Builtin_HandleApiCall(args_length=6, args_object=0x00007ffeefbfd7d8, isolate=0x0000000106000000) at builtins-api.cc:127 [opt]\r\n    frame #15: 0x0000000101d82c09 node`Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_NoBuiltinExit + 73\r\n    frame #16: 0x0000000101abfa35 node`Builtins_InterpreterEntryTrampoline + 981\r\n    frame #17: 0x0000000101abfa35 node`Builtins_InterpreterEntryTrampoline + 981\r\n    frame #18: 0x0000000101abfa35 node`Builtins_InterpreterEntryTrampoline + 981\r\n    frame #19: 0x0000000101abfa35 node`Builtins_InterpreterEntryTrampoline + 981\r\n    frame #20: 0x0000000101abfa35 node`Builtins_InterpreterEntryTrampoline + 981\r\n    frame #21: 0x0000000101abfa35 node`Builtins_InterpreterEntryTrampoline + 981\r\n    frame #22: 0x0000000101ab577d node`Builtins_JSEntryTrampoline + 93\r\n    frame #23: 0x0000000101ab54f8 node`Builtins_JSEntry + 120\r\n    frame #24: 0x0000000100afa3fc node`v8::internal::(anonymous namespace)::Invoke(v8::internal::Isolate*, v8::internal::(anonymous namespace)::InvokeParams const&) [inlined] v8::internal::GeneratedCode<unsigned long, unsigned long, unsigned long, unsigned long, unsigned long, long, unsigned long**>::Call(args=<unavailable>, args=<unavailable>, args=<unavailable>, args=<unavailable>, args=<unavailable>, args=<unavailable>) at simulator.h:138 [opt]\r\n    frame #25: 0x0000000100afa3f4 node`v8::internal::(anonymous namespace)::Invoke(isolate=0x0000000106000000, params=0x00007ffeefbfdea0)::InvokeParams const&) at execution.cc:274 [opt]\r\n    frame #26: 0x0000000100af9fb4 node`v8::internal::Execution::Call(isolate=0x0000000106000000, callable=<unavailable>, receiver=<unavailable>, argc=6, argv=0x0000000105109360) at execution.cc:366 [opt]\r\n    frame #27: 0x000000010055a6cd node`v8::Function::Call(this=<unavailable>, context=<unavailable>, recv=<unavailable>, argc=6, argv=<unavailable>) at api.cc:4984 [opt]\r\n    frame #28: 0x0000000100115096 node`node::ExecuteBootstrapper(env=0x0000000107016e00, id=\"internal/bootstrap/node\", parameters=0x00007ffeefbfe2e0 size=6, arguments=0x00007ffeefbfe2b8 size=6) at node.cc:204\r\n    frame #29: 0x00000001001164b4 node`node::RunBootstrapping(env=0x0000000107016e00) at node.cc:332\r\n    frame #30: 0x000000010020d64e node`node::NodeMainInstance::CreateMainEnvironment(this=0x00007ffeefbff1c0, exit_code=0x00007ffeefbfee74) at node_main_instance.cc:155\r\n    frame #31: 0x000000010020c545 node`node::NodeMainInstance::Run(this=0x00007ffeefbff1c0) at node_main_instance.cc:47\r\n    frame #32: 0x000000010011e2ed node`node::Start(argc=3, argv=0x0000000105108a50) at node.cc:863\r\n    frame #33: 0x000000010169615e node`main(argc=3, argv=0x00007ffeefbff630) at node_main.cc:126\r\n    frame #34: 0x00007fff7890c015 libdyld.dylib`start + 1\r\n```\r\n\r\n</details>\r\n\r\nIt does not crash if I build it with `code_cache_stub.cc`, or build it in release mode.\r\n\r\ncc @nodejs/v8 @nodejs/v8-inspector @psmarshall ",
        "labels": "confirmed-bug",
        "id": 45158
    },
    {
        "title": "vm.compileFunction is crashing the node process with unknown error",
        "body": "* **Version**: 10.15.3\r\n* **Platform**: Windows 10\r\n* **Subsystem**: vm\r\n\r\n<!-- Please provide more details below this comment. -->\r\nThe following simple script crashes the node process with no apparent reason:\r\n```js\r\nconst vm = require('vm');\r\nconsole.log(process.version);\r\nvm.compileFunction('return', ['ab'.replace('b', 'b'.repeat(12)).split('').join('')]);\r\nconsole.log('compiled ok 1');\r\nvm.compileFunction('return', ['ab'.replace('b', 'b'.repeat(11))]);\r\nconsole.log('compiled ok 2');\r\ntry {\r\n    vm.compileFunction('return', ['ab'.replace('b', 'b'.repeat(12))]); // crash here\r\n    console.log('compiled ok 3');\r\n} catch (e) { // no exception was caught\r\n    console.error(e);\r\n}\r\n```\r\nOutput:\r\n```\r\nv10.15.3\r\ncompiled ok 1\r\ncompiled ok 2\r\n```",
        "labels": "confirmed-bug",
        "id": 45159
    },
    {
        "title": "mkdir no ERROR when parent is a file with native recursive option",
        "body": "On windows Node.js v10.x hangs when trying to mkdir in a path where the parent is a file.\r\n(sorry tested only on appveyor and travis) \r\n\r\nNode8 on windows errors with EEXIST\r\nNode10 on non-windows errors ENOTDIR\r\nNode10 on windows hangs NO error ðŸ˜¿ \r\n\r\n* **Version**: v10.15.3\r\n* **Platform**: Windows\r\n* **Subsystem**: fs\r\n\r\n<!-- Please provide more details below this comment. -->\r\n```js\r\nconst fs = require('fs')\r\nfs.writeFileSync('./test2.txt', '')\r\nfs.mkdirSync('./test2.txt/sub/dir', {\r\n    recursive: true\r\n})\r\n```\r\n\r\nSee hanging test on travis https://travis-ci.org/sindresorhus/make-dir\r\nRelated PR that adds test to `make-dir` https://github.com/sindresorhus/make-dir/pull/15",
        "labels": "confirmed-bug",
        "id": 45160
    },
    {
        "title": "[8.x] assert.rejects fails with confusing error message",
        "body": "* **Version**: latest 8.* series\r\n* **Platform**: not relevant\r\n* **Subsystem**: assert\r\n\r\nThe API of `assert.rejects` is different between the 10.* series and the 8.* series, because the backported 8.* version does not accept a `Promise` as first argument, it requires a `Function` that returns a rejected promise.\r\nIf you misuse the API, though, you get a confusing error message:\r\n> TypeError: errors.ERR_INVALID_ARG_TYPE is not a constructor\r\n>    at waitForActual (assert.js:723:11)\r\n>    at Function.rejects (assert.js:799:31)\r\n>\r\n\r\nThis is because at https://github.com/nodejs/node/blob/045868db973a1dac3c2eb55cdcb7134a42b124cc/lib/assert.js#L723 the throw line is incorrect.\r\n",
        "labels": "confirmed-bug",
        "id": 45161
    },
    {
        "title": "Piping w/ spawn is broken in Node 11 / 12",
        "body": "* **Version**: 11.13\r\n* **Platform**: OSX\r\n* **Subsystem**: child_process\r\n\r\nRef #18016, ping @elibarzilay and @gireeshpunathil\r\n\r\nIt seems that Node 11's behavior changed compared to Node 10, and pipes are now automatically closed after being used as output stream from a process. I think this is a bug, because it makes it impossible to use the same pipe as output from two different processes (which would be the case if I was to implement `(foo; bar) | cat` - both `foo` and `bar` would write into the `cat` process).\r\n\r\nAdditionally, it causes previously working code to \"randomly\" throw internal exceptions. The random part is likely caused by a race condition, since `perl` throws consistently while `rev` doesn't cause problems. The exception is as such:\r\n\r\n```js\r\nconst {spawn} = require(`child_process`);\r\n\r\nconst p2 = spawn(`perl`, [`-ne`, `print uc`], {\r\n  stdio: [`pipe`, process.stdout, process.stderr],\r\n});\r\n\r\nconst p1 = spawn(`node`, [`-p`, `\"hello world\"`], {\r\n  stdio: [process.stdin, p2.stdin, process.stderr],\r\n});\r\n\r\np1.on(`exit`, code => {\r\n  p2.stdin.end();\r\n});\r\n```\r\n\r\n```\r\nâ¯ [mael-mbp?] /Users/mael â¯ node test\r\n\r\nHELLO WORLD\r\ninternal/validators.js:130\r\n    throw new ERR_INVALID_ARG_TYPE(name, 'number', value);\r\n    ^\r\n\r\nTypeError [ERR_INVALID_ARG_TYPE]: The \"err\" argument must be of type number. Received type undefined\r\n    at validateNumber (internal/validators.js:130:11)\r\n    at Object.getSystemErrorName (util.js:231:3)\r\n    at errnoException (internal/errors.js:383:21)\r\n    at Socket._final (net.js:371:25)\r\n    at callFinal (_stream_writable.js:617:10)\r\n    at processTicksAndRejections (internal/process/task_queues.js:81:17)\r\n```\r\n\r\nAs you can see the code executed fine (`HELLO WORLD` got printed), but during cleanup an internal assertion failed and Node crashed.",
        "labels": "confirmed-bug",
        "id": 45162
    },
    {
        "title": "certain exponents cause generateKeyPair to hang",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 11.13.0 and also tested 10.15.0\r\n* **Platform**: Darwin calvin 18.2.0 Darwin Kernel Version 18.2.0: Thu Dec 20 20:46:53 PST 2018; root:xnu-4903.241.1~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: crypto\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\ncertain exponents cause  crypto.generateKeyPair to hang\r\n\r\ntry running\r\n\r\n```js\r\nconst { publicKey, privateKey } = crypto.generateKeyPairSync('rsa', {\r\n  modulusLength: 1024,\r\n  publicExponent: 3,\r\n  publicKeyEncoding: {\r\n    type: 'spki',\r\n    format: 'pem'\r\n  },\r\n  privateKeyEncoding: {\r\n    type: 'pkcs8',\r\n    format: 'pem'\r\n  }\r\n});\r\n```\r\n\r\nyou'd expect it to eventually do something at least error, but it just hangs as do exponents 5 and 17, in fact the only one that seems to work is 0x10001.\r\n\r\nThis isn't a speed thing since I can generate a key like this in browser crypto and in pure javascript pretty easily.\r\n\r\nlooking at the tests it looks like 0x10001 is the only key being tested against",
        "labels": "confirmed-bug",
        "id": 45163
    },
    {
        "title": "meaning of the boolean return value of `send()` not documented",
        "body": "https://nodejs.org/api/child_process.html#child_process_subprocess_send_message_sendhandle_options_callback describes the meaning of the boolean return.\r\n\r\nIt should be described in https://nodejs.org/api/cluster.html#cluster_worker_send_message_sendhandle_callback and\r\nhttps://nodejs.org/api/process.html#process_process_send_message_sendhandle_options_callback but is not.\r\n\r\nreported in https://github.com/nodejs/node/issues/26937#issuecomment-478079356\r\n\r\n<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: all\r\n* **Platform**: n/a\r\n* **Subsystem**: process, cluster\r\n\r\n<!-- Please provide more details below this comment. -->\r\n",
        "labels": "confirmed-bug",
        "id": 45164
    },
    {
        "title": "async_hooks: destroy emitted more than once for an asyncId",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 12.0.0-pre (current master)\r\n* **Platform**: Darwin LIB-0F7FVH8-LT 18.2.0 Darwin Kernel Version 18.2.0: Thu Dec 20 20:46:53 PST 2018; root:xnu-4903.241.1~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: async_hooks\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThis code shows `destroy` emitting twice for a single `asyncId`. (You may need to run it more than once to see the error and/or increase the value of `N` in the code, but it repros most of the time for me.)\r\n\r\n```js\r\n'use strict';\r\n\r\nconst assert = require('assert');\r\nconst async_hooks = require('async_hooks');\r\nconst http = require('http');\r\n\r\nconst N = 50;\r\nconst KEEP_ALIVE = 100;\r\n\r\nconst destroyedIds = [];\r\nasync_hooks.createHook({\r\n  destroy: (asyncId) => {\r\n    assert(!destroyedIds.includes(asyncId), `${asyncId} already in ${destroyedIds.sort()}`);\r\n    destroyedIds.push(asyncId);\r\n  }\r\n}).enable();\r\n\r\nconst server = http.createServer(function(req, res) {\r\n  res.end('Hello');\r\n});\r\n\r\nconst keepAliveAgent = new http.Agent({\r\n  keepAlive: true,\r\n  keepAliveMsecs: KEEP_ALIVE,\r\n});\r\n\r\nlet M = 0;\r\nserver.listen(0, function() {\r\n  for (let i = 0; i < N; ++i) {\r\n    (function makeRequest() {\r\n      http.get({\r\n        port: server.address().port,\r\n        agent: keepAliveAgent\r\n      }, function(res) {\r\n        res.resume();\r\n        M++;\r\n        if (M === N)\r\n          server.close();\r\n        assert.ok(M <= N);\r\n      });\r\n    })();\r\n  }\r\n});\r\n```",
        "labels": "confirmed-bug",
        "id": 45165
    },
    {
        "title": "fs.copyFile on Mac OS does not respect permissions",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `v11.2.0`\r\n* **Platform**: `Darwin iMac.local 18.2.0 Darwin Kernel Version 18.2.0: Thu Dec 20 20:46:53 PST 2018; root:xnu-4903.241.1~1/RELEASE_X86_64 x86_64`\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhen setting a file mode to `444` using `chmodSync`, then trying to copy another file over it, on Windows and on Linux, `copyFile` will throw an error, but on a Mac it does not, and it will override the file\r\n\r\n```javascript\r\nfs.chmodSync(dest, '444');\r\n// then try to \r\nfs.copyFile(source, dest, function (err) {\r\n    // \ti do expect an err here, \r\n   // but there is no error on Mac\r\n});\r\n```\r\n\r\ni even check the `stat.mode` using `parseInt(fs.statSync(dest).mode.toString(8), 10)` and it does in fact say `100444`\r\n\r\nThis is a sample when everything is working well \r\nhttps://repl.it/repls/CylindricalGlisteningCondition\r\n\r\nHowever, when i run it on my mac, I get this\r\n\r\n```\r\nThis platform is darwin\r\nfs.stat.mode ./dest: 100444\r\n/Users/akhoury/rcloned/code/NodeBB/rrr.js:26\r\n                throw new Error(`This should've thrown an error!`);\r\n                ^\r\n\r\nError: This should've thrown an error!\r\n```\r\nThanks\r\n",
        "labels": "confirmed-bug",
        "id": 45166
    },
    {
        "title": "Path.js throws away one character paths.",
        "body": "* **Version**:\r\nMaster version in github\r\n* **Platform**:\r\nWindows\r\n* **Subsystem**:\r\n\r\nThe code to parse win32 paths, throws away paths that consist of one letter or character (unless its a forward or backward slash).  Line 833 in the excerpt below, returns empty strings.\r\n\r\nhttps://github.com/nodejs/node/blob/d989e207177f29fe277a010a1d087230aec40a8e/lib/path.js#L826-L833\r\n",
        "labels": "confirmed-bug",
        "id": 45167
    },
    {
        "title": "pummel/test-tls-session-timeout failing",
        "body": "https://ci.nodejs.org/job/node-test-commit-custom-suites-freestyle/5519/console\r\n\r\ntest-rackspace-ubuntu1604-x64-1\r\n\r\n```console\r\n00:06:39 not ok 101 pummel/test-tls-session-timeout\r\n00:06:39   ---\r\n00:06:39   duration_ms: 0.214\r\n00:06:39   severity: fail\r\n00:06:39   exitcode: 1\r\n00:06:39   stack: |-\r\n00:06:39     assert.js:85\r\n00:06:39       throw new AssertionError(obj);\r\n00:06:39       ^\r\n00:06:39     \r\n00:06:39     AssertionError [ERR_ASSERTION]: Expected values to be strictly equal:\r\n00:06:39     + actual - expected\r\n00:06:39     \r\n00:06:39     + 'New'\r\n00:06:39     - 'Reused'\r\n00:06:39         at /home/iojs/build/workspace/node-test-commit-custom-suites-freestyle/test/pummel/test-tls-session-timeout.js:121:16\r\n00:06:39         at ChildProcess.<anonymous> (/home/iojs/build/workspace/node-test-commit-custom-suites-freestyle/test/pummel/test-tls-session-timeout.js:105:7)\r\n00:06:39         at ChildProcess.emit (events.js:198:13)\r\n00:06:39         at Process.ChildProcess._handle.onexit (internal/child_process.js:254:12)\r\n00:06:39   ...\r\n```",
        "labels": "confirmed-bug",
        "id": 45168
    },
    {
        "title": "executionAsyncId doesn't return expected value in context of process.on('unhandledRejection')",
        "body": "Version: 12.0.0-pre (78162ad570bfb991e2416c7850be546848a6fcc0)\r\nPlatform: Darwin geegaw.local 18.2.0 Darwin Kernel Version 18.2.0: Thu Dec 20 20:46:53 PST 2018; root:xnu-4903.241.1~1/RELEASE_X86_64 x86_64\r\nSubsystem: async_hooks\r\n\r\nhttps://gist.github.com/isaacs/1f8c5092ba7d67d9a5f4e342ff7778b7\r\n\r\nI am building a domain-like implementation to catch errors using async_hooks.  However, the executionAsyncId is reset to 0 on an `unhandledRejection` event, making it impossible for me to know if I ought to handle the error or crash.\r\n\r\nThe weird thing is that it only fails in this way when the promise rejection is within an async hop, such as a setTimeout.  If the promise rejection happens at the top level, then I get the expected value of `1` as the executionAsyncId.\r\n\r\nThis is preventing me moving node-tap off of core domains.  Fewer modules using domains means that it could be deprecated sooner :)",
        "labels": "confirmed-bug",
        "id": 45169
    },
    {
        "title": "console.trace not printing stack",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**:\r\nv11.11.0\r\n\r\n* **Platform**:\r\nLinux zeratul 4.18.0-15-generic #16-Ubuntu SMP Thu Feb 7 10:56:39 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n* **Subsystem**:\r\nconsole\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThe following code seems to print a stack trace on v11.10.1 but not on v11.11.0 and v11.12.0\r\n```javascript\r\nconsole.trace('show me');\r\n```\r\n\r\nOutput on v11.10.1:\r\n```\r\nTrace: show me\r\n    at Object.<anonymous> (/tmp/console-trace-no-stack.js:1:71)\r\n    at Module._compile (internal/modules/cjs/loader.js:738:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:749:10)\r\n    at Module.load (internal/modules/cjs/loader.js:630:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:570:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:562:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:801:12)\r\n    at internal/main/run_main_module.js:21:11\r\n```\r\n\r\nOutput on v11.11.0 and v11.12.0\r\n```\r\nTrace: show me\r\n```",
        "labels": "confirmed-bug",
        "id": 45170
    },
    {
        "title": "node-api/test_exception fails in debug mode",
        "body": "* **Version**: master\r\n* **Platform**: Linux (presumably any)\r\n* **Subsystem**: n-api\r\n\r\n```c++\r\nStarting program: node_g --expose-gc test/node-api/test_exception/test.js\r\n[...]\r\n#\r\n# Fatal error in ../deps/v8/src/heap/heap-inl.h, line 164\r\n# Debug check failed: AllowHeapAllocation::IsAllowed().\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 0x7fffeb649850\r\nThread 1 \"node_g\" received signal SIGILL, Illegal instruction.\r\nv8::base::OS::Abort () at ../deps/v8/src/base/platform/platform-posix.cc:400\r\n400\t    V8_IMMEDIATE_CRASH();\r\n(gdb) bt\r\n#0  v8::base::OS::Abort () at ../deps/v8/src/base/platform/platform-posix.cc:400\r\n#1  0x000055592c258a2b in V8_Fatal (file=0x55592cb79048 \"../deps/v8/src/heap/heap-inl.h\", line=164, format=format@entry=0x55592cf8704a \"Debug check failed: %s.\") at ../deps/v8/src/base/logging.cc:171\r\n#2  0x000055592c258a45 in v8::base::(anonymous namespace)::DefaultDcheckHandler (file=<optimized out>, line=<optimized out>, message=<optimized out>) at ../deps/v8/src/base/logging.cc:56\r\n#3  0x000055592b69d1a8 in v8::internal::Heap::AllocateRaw (this=0x55592df7a780, size_in_bytes=24, space=v8::internal::NEW_SPACE, alignment=v8::internal::kWordAligned) at ../deps/v8/src/heap/heap-inl.h:164\r\n#4  0x000055592b6e031f in v8::internal::Heap::AllocateRawWithLightRetry (this=this@entry=0x55592df7a780, size=size@entry=24, space=space@entry=v8::internal::NEW_SPACE, alignment=alignment@entry=v8::internal::kWordAligned) at ../deps/v8/src/heap/heap.cc:4326\r\n#5  0x000055592b6e042e in v8::internal::Heap::AllocateRawWithRetryOrFail (this=this@entry=0x55592df7a780, size=24, space=space@entry=v8::internal::NEW_SPACE, alignment=alignment@entry=v8::internal::kWordAligned) at ../deps/v8/src/heap/heap.cc:4347\r\n#6  0x000055592b68e9e4 in v8::internal::Factory::AllocateRawWithAllocationSite (this=this@entry=0x55592df71960, map=map@entry=..., pretenure=pretenure@entry=v8::internal::NOT_TENURED, allocation_site=...) at ../deps/v8/src/heap/factory.cc:143\r\n#7  0x000055592b6a43b8 in v8::internal::Factory::NewJSObjectFromMap (this=this@entry=0x55592df71960, map=..., map@entry=..., pretenure=pretenure@entry=v8::internal::NOT_TENURED, allocation_site=..., allocation_site@entry=...) at ../deps/v8/src/heap/factory.cc:3059\r\n#8  0x000055592b8f5729 in v8::internal::JSObject::New (constructor=constructor@entry=..., new_target=..., site=site@entry=...) at ../deps/v8/src/objects.cc:1379\r\n#9  0x000055592b840d2f in v8::internal::ErrorUtils::Construct (isolate=isolate@entry=0x55592df71960, target=..., new_target=..., message=..., mode=mode@entry=v8::internal::SKIP_NONE, caller=..., caller@entry=..., suppress_detailed_trace=false) at ../deps/v8/src/messages.cc:1160\r\n#10 0x000055592b68d971 in v8::internal::Factory::NewError (this=this@entry=0x55592df71960, constructor=..., message=..., message@entry=...) at ../deps/v8/src/heap/factory.cc:2379\r\n#11 0x000055592b1020ba in v8::Exception::Error (raw_message=...) at ../deps/v8/src/api.cc:8988\r\n#12 0x000055592adde733 in napi_throw_error (env=0x55592e09ac40, code=0x0, msg=0x7fdfd2dfcb55 \"Error during Finalize\") at ../src/js_native_api_v8.cc:1803\r\n#13 0x00007fdfd2dfc8d5 in finalizer (env=0x55592e09ac40, data=0x7fdfd2ffd0d0 <buffer_data>, hint=0x0) at ../test_exception.c:5\r\n#14 0x000055592adfe1f3 in v8impl::(anonymous namespace)::BufferFinalizer::<lambda()>::operator()(void) const (__closure=0x7fffeb64a030) at ../src/node_api.cc:40\r\n#15 0x000055592ae0252a in NapiCallIntoModule<v8impl::(anonymous namespace)::BufferFinalizer::FinalizeBufferCallback(char*, void*)::<lambda()>&, NapiCallIntoModuleThrow(napi_env, T&&) [with T = v8impl::(anonymous namespace)::BufferFinalizer::FinalizeBufferCallback(char*, void*)::<lambda()>]::<lambda(v8::Local<v8::Value>)> >(napi_env, v8impl::(anonymous namespace)::BufferFinalizer::<lambda()> &, <lambda(v8::Local<v8::Value>)> &&) (env=0x55592e09ac40, call=..., handle_exception=...) at ../src/js_native_api_v8.h:121\r\n#16 0x000055592ae01e36 in NapiCallIntoModuleThrow<v8impl::(anonymous namespace)::BufferFinalizer::FinalizeBufferCallback(char*, void*)::<lambda()> >(napi_env, v8impl::(anonymous namespace)::BufferFinalizer::<lambda()> &&) (env=0x55592e09ac40, call=...) at ../src/js_native_api_v8.h:132\r\n#17 0x000055592adfe250 in v8impl::(anonymous namespace)::BufferFinalizer::FinalizeBufferCallback (data=0x7fdfd2ffd0d0 <buffer_data> \"\", hint=0x55592e0825b0) at ../src/node_api.cc:39\r\n#18 0x000055592ae0985a in node::Buffer::(anonymous namespace)::CallbackInfo::WeakCallback (this=0x55592e0bbb50, isolate=0x55592df71960) at ../src/node_buffer.cc:151\r\n#19 0x000055592ae09803 in node::Buffer::(anonymous namespace)::CallbackInfo::WeakCallback (data=...) at ../src/node_buffer.cc:145\r\n#20 0x000055592b66c7ec in v8::internal::GlobalHandles::PendingPhantomCallback::Invoke (this=this@entry=0x7fffeb64a120, isolate=0x55592df71960) at ../deps/v8/src/global-handles.cc:915\r\n#21 0x000055592b66f986 in v8::internal::GlobalHandles::InvokeFirstPassWeakCallbacks (this=0x55592df96b50) at ../deps/v8/src/global-handles.cc:877\r\n#22 0x000055592b6dc64c in v8::internal::Heap::PerformGarbageCollection (this=this@entry=0x55592df7a780, collector=collector@entry=v8::internal::MARK_COMPACTOR, gc_callback_flags=gc_callback_flags@entry=v8::kGCCallbackFlagForced) at ../deps/v8/src/heap/heap.cc:1739\r\n#23 0x000055592b6dd384 in v8::internal::Heap::CollectGarbage (this=this@entry=0x55592df7a780, space=space@entry=v8::internal::OLD_SPACE, gc_reason=<optimized out>, gc_callback_flags=v8::kGCCallbackFlagForced) at ../deps/v8/src/heap/heap.cc:1327\r\n#24 0x000055592b6dd764 in v8::internal::Heap::CollectAllGarbage (this=0x55592df7a780, flags=<optimized out>, gc_reason=<optimized out>, gc_callback_flags=<optimized out>) at ../deps/v8/src/heap/heap.cc:1070\r\n#25 0x000055592b1cc261 in v8::internal::FunctionCallbackArguments::Call (this=this@entry=0x7fffeb64a500, handler=..., handler@entry=...) at ../deps/v8/src/api-arguments-inl.h:146\r\n#26 0x000055592b1cee18 in v8::internal::(anonymous namespace)::HandleApiCallHelper<false> (isolate=isolate@entry=0x55592df71960, function=..., function@entry=..., new_target=..., new_target@entry=..., fun_data=..., receiver=..., receiver@entry=..., args=...) at ../deps/v8/src/builtins/builtins-api.cc:109\r\n#27 0x000055592b1d0319 in v8::internal::Builtin_Impl_HandleApiCall (args=..., isolate=isolate@entry=0x55592df71960) at ../deps/v8/src/builtins/builtins-api.cc:139\r\n#28 0x000055592b1d0bdd in v8::internal::Builtin_HandleApiCall (args_length=5, args_object=0x7fffeb64a740, isolate=0x55592df71960) at ../deps/v8/src/builtins/builtins-api.cc:127\r\n#29 0x000055592c669592 in Builtins_CEntry_Return1_DontSaveFPRegs_ArgvOnStack_NoBuiltinExit () at ../deps/v8/src/code-stub-assembler.cc:128\r\n#30 0x000055592c3753c8 in Builtins_InterpreterEntryTrampoline () at ../deps/v8/src/builtins/builtins-collections-gen.cc:1308\r\n[...]\r\n```\r\n\r\nThree questions:\r\n\r\n- Should we keep this test? At the moment seems to test something invalid, namely throwing an error during GC.\r\n- Alternatively, should we try to switch over to a second pass callback here as well, like we did in https://github.com/nodejs/node/pull/25992, but for all `Buffer`s?\r\n- **Why doesnâ€™t this fail in CI?** Looking at CI output, we donâ€™t seem to test addons in debug mode at all? That seems pretty bad, they are one of the test suites that need it the most.\r\n\r\n/cc @nodejs/n-api @nodejs/build ",
        "labels": "confirmed-bug",
        "id": 45171
    },
    {
        "title": "v11.11.0 `timeout.refresh()` does not seem to prevent event loop from exiting",
        "body": "* **Version**: `v11.11.0`\r\n* **Platform**: `Alpine Linux v3.9` run inside Docker on `Linux 03891e4323dc 5.0.0-arch1-1-ARCH #1 SMP PREEMPT Mon Mar 4 14:11:43 UTC 2019 x86_64 Linux`\r\n* **Subsystem**: `Timers`\r\n\r\nWhen using [`timeout.refresh`](https://nodejs.org/api/timers.html#timers_timeout_refresh) to keep re-running some code, Node.js v11.x exits process, even though timeout is supposed to be \"ref'ed\" by default (and it is: `timeout.hasRef()` returns `true` every time).\r\n\r\nI am not 100% sure, but i think it might be caused by this line:\r\nhttps://github.com/nodejs/node/blob/32853c0a136b0616844cdf5c276d2f1eb9a4fc50/lib/timers.js#L232\r\n\r\nShouldn't it look like this instead?\r\n```js\r\nif (refed !== item[kRefed]) {\r\n```\r\n\r\nProblem is 100% reproducible with following example (save it to file and run, e.g., `node test-timer.js` or `DEBUG=1 node test-timer.js`):\r\n\r\n```js\r\nprocess.on('exit', () => console.log('Bye!'));\r\n\r\nconst DEBUG = Number(process.env.DEBUG) || false;\r\nvar countdown = 2;\r\nvar timer = setTimeout(run, 0);\r\n\r\nfunction run () {\r\n\tconsole.log('run', countdown--);\r\n\tif (countdown < 1) {\r\n\t\tconsole.log('all done');\r\n\t\tclearTimeout(timer);\r\n\t\treturn;\r\n\t}\r\n\ttimer.refresh();\r\n\t// Uncomment next line to make this work on Node.js v11.x\r\n\t// timer = setTimeout(run, 0);\r\n\tif (DEBUG) {\r\n\t\tconsole.debug('has ref?', timer.hasRef ? timer.hasRef() : timer);\r\n\t}\r\n}\r\n```\r\n\r\nWhen run on v11.11.0, actual output is incorrect:\r\n```txt\r\nrun 2\r\nBye!\r\n```\r\n\r\nWhen run on v10.15.3, actual output is correct:\r\n```txt\r\nrun 2\r\nrun 1\r\nall done\r\nBye!\r\n```\r\n\r\nChanging amount of time, e.g., from 0 to 1000, does not change the output.\r\nNumber assigned to `countdown` does not matter either, as long as it's greater than 1 ;).",
        "labels": "confirmed-bug",
        "id": 45172
    },
    {
        "title": "Change in NODE_OPTIONS parsing behavior in Node 11",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.9.0\r\n* **Platform**: Darwin\r\n* **Subsystem**: \r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nIf `NODE_OPTIONS` starts with a leading space the `--require` option does not function (possibly other flags but I've only tested `--require`).\r\n\r\nSpecifically:\r\n\r\n```sh\r\nNODE_OPTIONS=\"--require ./some-file.js\" node ./other-file.js\r\n```\r\n\r\n^ will properly require `./some-file.js` prior to executing `./other-file.js`\r\n\r\nWhereas:\r\n\r\n```sh\r\nNODE_OPTIONS=\" --require ./some-file.js\" node ./other-file.js\r\n```\r\n\r\n^^ will **not** require `./some-file.js` at all\r\n\r\nSteps to reproduce:\r\n\r\n```sh\r\nmkdir test-node-options\r\ncd test-node-options\r\necho \"console.log('first!')\" > first.js\r\necho \"console.log('second!')\" > second.js\r\n```\r\n\r\nThen compare the output of these two commands:\r\n\r\n```\r\n# \"broken\"\r\nNODE_OPTIONS=\" --require ./first.js\" node ./second.js\r\n\r\n# \"working\"\r\nNODE_OPTIONS=\"--require ./first.js\" node ./second.js\r\n```\r\n\r\n---\r\n\r\nI stumbled across this while attempting to use Yarn's PnP system on Node 11 (see https://github.com/yarnpkg/yarn/issues/7092 for the original report there). Yarn 1.13.0 adds ` --require ${PATH_TO_PNP_FILE}` to `NODE_OPTIONS` which causes this issue.\r\n\r\n/cc @arcanis @turbo87 @stefanpenner",
        "labels": "confirmed-bug",
        "id": 45173
    },
    {
        "title": "buffer.indexOf is incorrect in utf16le encoding for odd byteOffset",
        "body": "Version: v11.10.1\r\nPlatform: Windows 10 (64-bits)\r\nSubsystem: buffer\r\nFile Encoding: UTF8\r\n\r\nPlease consider the following 2 lines of code:\r\nlet buf = Buffer.from('\\u6881\\u6882\\u6881', 'utf16le');\r\nconsole.log(buf.indexOf('\\u6881', 1, 'utf16le'));\r\n\r\nIn this example, the expected correct output should be 4.\r\nHowever, the result is 0.",
        "labels": "confirmed-bug",
        "id": 45174
    },
    {
        "title": "Buffer.alloc(): `A TypeError will be thrown if size is not a number.`",
        "body": "`Buffer.alloc(size)` and friends (`allocUnsafe()`, `allocUnsafeSlow()`) promise that:\r\n\r\n```\r\nA TypeError will be thrown if size is not a number.\r\n```\r\n\r\nHowever, this contract is broken when `size` is `NaN`:\r\n\r\n```javascript\r\n> Buffer.alloc(123+undefined)\r\n<Buffer >\r\n```\r\n\r\nThe reason is that `assertSize()`, which validates the `size` argument, does the check using `typeof size !== 'number'`, however:\r\n\r\n```javascript\r\n> typeof (123+undefined)\r\n'number'\r\n```\r\n\r\n`Number.isInteger()` would be better:\r\n\r\n```javascript\r\n> Number.isInteger(123+undefined)\r\nfalse\r\n```\r\n\r\nAlternatively, a faster test for `NaN` would be swapping the range check around to throw for anything not in range (as opposed to throw for anything before 0 or after `kMaxLength` which is what it currently does):\r\n\r\n```javascript\r\nif (!(size >= 0 && size <= kMaxLength)) {\r\n  err = new ERR_INVALID_OPT_VALUE.RangeError('size', size);\r\n}\r\n```\r\n\r\nThe above snippet catches `NaN`.",
        "labels": "confirmed-bug",
        "id": 45175
    },
    {
        "title": "First crypto ECDH sign() failes after convertKey() call.",
        "body": "* **Version**: v11.10.0\r\n* **Platform**: 64-bit Windows 10\r\n* **Subsystem**: crypto\r\n\r\nAfter calling ECDH.convertKey() (on an invalid public key) the next call to sign() fails, but subsequent calls succeed.\r\nExample:\r\n\r\n```\r\nconst crypto = require(\"crypto\");\r\n\r\nconst publicKey = Buffer.from(\"02ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff\", \"hex\");\r\ntry {\r\n\tcrypto.ECDH.convertKey(publicKey, \"secp256k1\", undefined, undefined, \"compressed\");\r\n} catch (error) {\r\n\t//Lies outside curve, so it should throw.\r\n}\r\n\r\nconst secp256k1 = crypto.createECDH(\"secp256k1\");\r\nsecp256k1.generateKeys();\r\n\r\n//Pem format private key\r\nlet privateKey = secp256k1.getPrivateKey();\r\nif (privateKey.length < 32) {\r\n\tprivateKey = Buffer.concat([Buffer.alloc(32 - privateKey.length, 0), privateKey]);\r\n}\r\nconst privateStart = Buffer.from(\"302e0201010420\", \"hex\");\r\nconst privateEnd = Buffer.from(\"a00706052b8104000a\", \"hex\");\r\nconst privateKeyPem = \"-----BEGIN EC PRIVATE KEY-----\\n\" +\r\n\tBuffer.concat([privateStart, privateKey, privateEnd]).toString(\"base64\") +\r\n\t\"\\n-----END EC PRIVATE KEY-----\";\r\n\r\nconst toSign = \"whatever\";\r\ntry {\r\n\tcrypto.createSign(\"SHA256\").update(toSign).sign(privateKeyPem);\r\n} catch (error) {\r\n\tconsole.log(error);\r\n\tconsole.log(\"That threw an error, lets try the same thing again.\");\r\n\tcrypto.createSign(\"SHA256\").update(toSign).sign(privateKeyPem);\r\n\tconsole.log(\"This time it threw no error.\");\r\n}\r\n```\r\n\r\nResulting error:\r\n```\r\nError: error:10067066:elliptic curve routines:ec_GFp_simple_oct2point:invalid encoding\r\n    at Sign.sign (internal/crypto/sig.js:84:29)\r\n```",
        "labels": "confirmed-bug",
        "id": 45176
    },
    {
        "title": "`readable` event not emitted after `net.Socket` reconnects",
        "body": "* **Version**: v10.15.1\r\n* **Platform**: Windows 10 Pro 64-bit\r\n* **Subsystem**: net\r\n\r\nIf `net.Socket` loses connection (`close` is emitted) and the same socket instance is used to reconnect to the same server, no more `readable` events are emitted (`data` events are still emitted).\r\n\r\nDoesn't work in v10.14/v10.15.1. Works in v8.15.0.\r\n\r\nRepro: https://gist.github.com/morkai/fa175bd0104443e6142f3d0e22805653\r\n1. Run `server.js`\r\n2. Run `client.js`\r\n3. Client prints `client#readable`\r\n4. Kill the server\r\n5. Run the server again\r\n6. Client reconnects\r\n7. **Client doesn't print any `client#readable` lines**\r\n8. Kill the client\r\n9. Uncomment the `data` event handler and comment the `readable` handler in `client.js`\r\n10. Run the client\r\n11. Client prints `client#data`\r\n12. Kill the server\r\n13. Run the server again\r\n14. Client reconnects\r\n15. Client resumes printing `client#data` lines",
        "labels": "confirmed-bug",
        "id": 45177
    },
    {
        "title": "Node 11.4.0+ fails to resolve index.js when combined with -r and --inspect-brk",
        "body": "#### index.js\r\n```js\r\nconsole.log(\"hi from index.js\")\r\n```\r\n#### preload.js\r\n```js\r\nconsole.log(\"hi from preload.js\")\r\n```\r\n\r\nIn Node 11.3.0 and below this works:\r\n```shell\r\nnode -r ./preload.js --inspect-brk index.js\r\n```\r\nand results in:\r\n```shell\r\nDebugger listening on ws://127.0.0.1:9229/3a4d89ae-03a7-45f0-b740-711ac3fb490e\r\nFor help, see: https://nodejs.org/en/docs/inspector\r\nDebugger attached.\r\nhi from preload.js\r\n```\r\n\r\nHowever, in Node 11.4.0+ it errors with:\r\n```\r\nDebugger listening on ws://127.0.0.1:9229/d9fa3f56-312d-4288-a61c-9eb221c0ad02\r\nFor help, see: https://nodejs.org/en/docs/inspector\r\nDebugger attached.\r\ninternal/modules/cjs/loader.js:605\r\n    throw err;\r\n    ^\r\n\r\nError: Cannot find module 'index.js'\r\n    at Function.Module._resolveFilename (internal/modules/cjs/loader.js:603:15)\r\n    at Module._compile (internal/modules/cjs/loader.js:702:31)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:734:10)\r\n    at Module.load (internal/modules/cjs/loader.js:620:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:560:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:552:3)\r\n    at Module.require (internal/modules/cjs/loader.js:659:17)\r\n    at Module._preloadModules (internal/modules/cjs/loader.js:844:12)\r\n    at prepareUserCodeExecution (internal/bootstrap/node.js:297:7)\r\n    at startExecution (internal/bootstrap/node.js:275:5)\r\nWaiting for the debugger to disconnect...\r\n```",
        "labels": "confirmed-bug",
        "id": 45178
    },
    {
        "title": "Workers affected by V8 aborting on virtual allocation failure",
        "body": "* **Version**: 4b6e4c1eb110\r\n* **Platform**: Linux 4.19.15 x86_64\r\n* **Subsystem**: `worker_threads`\r\n\r\nA process aborts when V8 fails to allocate virtual memory. This is detremental to using `Workers` because:\r\n\r\n1. If a `Worker` fails to allocate virtual memory during initialization the process aborts.\r\n2. V8's virtual memory allocator doesn't play nicely with `ulimit`.\r\n\r\nTo demonstrate this issue:\r\n\r\n1. Set `ulimit -v` to some value smaller than actual physically available memory (I've allocated 8GB out of 16GB).\r\n2. Run the following script that spawns a set number of `Worker`s (the number to spawn may need adjusting depending on the system):\r\n\r\n```js\r\nconst WORKER_COUNT = 60; // Value may need adjustment\r\n\r\nconst { Worker, parentPort, workerData, threadId } = require('worker_threads');\r\nconst worker_array = [];\r\n\r\nif (workerData) {\r\n  process._rawDebug(workerData, threadId, process.pid, process.ppid);\r\n  parentPort.postMessage(42);\r\n  setTimeout(() => {}, 1000000);\r\n  return;\r\n}\r\n\r\n(function runner(n) {\r\n  if (++n > WORKER_COUNT) return setTimeout(killAll, 10);\r\n  const w = new Worker(__filename, { workerData: n });\r\n  w.on('message', () => {\r\n    process._rawDebug(JSON.stringify(getMemUsage()));\r\n    runner(n);\r\n  });\r\n  w.on('exit', c => process._rawDebug(`${n} exited with ${c}`));\r\n  worker_array.push(w);\r\n})(0);\r\n\r\nfunction killAll() {\r\n  for (let w of worker_array)\r\n    w.terminate();\r\n}\r\n\r\nfunction getMemUsage() {\r\n  const o = process.memoryUsage();\r\n  for (let i in o) o[i] = o[i] / 1024;\r\n  return o;\r\n}\r\n```\r\n\r\nWhich results in a `Fatal process OOM in CodeRange setup: allocate virtual memory` error. With the stack trace of:\r\n\r\n```\r\n * thread #1: tid = 4094, 0x0000000003eab702 node_g`v8::base::OS::Abort() at platform-posix.cc:399, name = 'node_g', stop reason = signal SIGILL: illegal instruction operand\r\n  * frame #0: 0x0000000003eab702 node_g`v8::base::OS::Abort() at platform-posix.cc:399\r\n    frame #1: 0x0000000002954ac2 node_g`v8::Utils::ReportOOMFailure(isolate=0x0000000005c13170, location=\"CodeRange setup: allocate virtual memory\", is_heap_oom=false) at api.cc:460\r\n    frame #2: 0x000000000295492d node_g`v8::internal::V8::FatalProcessOutOfMemory(isolate=0x0000000005c13170, location=\"CodeRange setup: allocate virtual memory\", is_heap_oom=false) at api.cc:428\r\n    frame #3: 0x000000000322e4a6 node_g`v8::internal::MemoryAllocator::InitializeCodePageAllocator(this=0x0000000005c076d0, page_allocator=0x00000000045aa030, requested=134217728) a t spaces.cc:168\r\n    frame #4: 0x000000000322e083 node_g`v8::internal::MemoryAllocator::MemoryAllocator(this=0x0000000005c076d0, isolate=0x0000000005c13170, capacity=1526909922, code_range_size=0) at spaces.cc:132\r\n    frame #5: 0x000000000318d6da node_g`v8::internal::Heap::SetUp(this=0x0000000005c13190) at heap.cc:4349\r\n    frame #6: 0x000000000331aa77 node_g`v8::internal::Isolate::Init(this=0x0000000005c13170, des=0x00007fffffff6db8) at isolate.cc:3176\r\n    frame #7: 0x00000000036e558c node_g`v8::internal::Snapshot::Initialize(isolate=0x0000000005c13170) at snapshot-common.cc:55\r\n    frame #8: 0x0000000002994b0d node_g`v8::Isolate::Initialize(isolate=0x0000000005c13170, params=0x00007fffffff7170) at api.cc:8224\r\n    frame #9: 0x00000000025db63b node_g`node::NewIsolate(allocator=0x00007fff34002c80, event_loop=0x0000000005bf2530) at node.cc:1420\r\n    frame #10: 0x000000000270d9a6 node_g`node::worker::Worker::Worker(this=0x0000000005bf2500, env=0x00007fffffffcd08, wrap=(val_ = 0x00007fffffff84a0), url=\"\\xb0?\"..., per_isolate_ opts=nullptr) at node_worker.cc:106\r\n```\r\n\r\nExamination of the `strace` log shows:\r\n\r\n```\r\n31103 mmap(0x129b53343000, 134217728, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = -1 ENOMEM (Cannot allocate memory)\r\n31103 mmap(0x129b53343000, 134217728, PROT_NONE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = -1 ENOMEM (Cannot allocate memory)\r\n31103 write(2, \"\\n#\\n# Fatal process OOM in CodeRa\"..., 70) = 70\r\n```\r\n\r\nThough if I run the same script on a machine with 8GB physical memory and `ulimit -v unlimited` the script doesn't have a problem.\r\n\r\nIn the end, this is probably something that'd need to be resolved by V8. Both to allocate virtual memory more intelligently and allow the `Isolate` to notify when no more memory could be allocated. Then have that hooked into the `Worker`'s `'error'` event.\r\n",
        "labels": "confirmed-bug",
        "id": 45179
    },
    {
        "title": "investigate test/tick-processor/test-tick-processor-builtin failures",
        "body": "* **Version**: v12.0.0-pre (master branch at 28c0f84a6\r\n* **Platform**: macOS 10.14.2 (Mojave):  Darwin LIB-0F7FVH8-LT 18.2.0 Darwin Kernel Version 18.2.0: Mon Nov 12 20:24:46 PST 2018; root:xnu-4903.231.4~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**: test\r\n\r\n<!-- Please provide more details below this comment. -->\r\n test/tick-processor/test-tick-processor-builtin.js fails consistently for me. Since this test is not run in CI or typically locally (unless you run `make test-tick-processor`, which almost no one does, or the brand new `make test-all-suites`), it may be broken everywhere. Or maybe it's just me. Anyone?\r\n\r\n/ping @indutny who has the biggest `git blame` footprint on that file (sorry if that's a bad metric to use and I'm pinging the wrong person)",
        "labels": "confirmed-bug",
        "id": 45180
    },
    {
        "title": "When dns module resolve mx, core dumped, and process aborted",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**:10.14.2\r\n* **Platform**:Linux 10-9-70-48 2.6.32-279.19.27.el6.ucloud.x86_64 #1 SMP Fri Aug 14 16:10:19 CST 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:dns\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n```\r\n# uname -a\r\nLinux 10-9-70-48 2.6.32-279.19.27.el6.ucloud.x86_64 #1 SMP Fri Aug 14 16:10:19 CST 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n# cat /etc/redhat-release \r\nRed Hat Enterprise Linux Server release 6.3 (Santiago)\r\n\r\n# nvm --version\r\n0.33.2\r\n\r\n# nvm list\r\n->     v10.14.2\r\ndefault -> lts/* (-> v10.14.2)\r\nnode -> stable (-> v10.14.2) (default)\r\nstable -> 10.14 (-> v10.14.2) (default)\r\niojs -> N/A (default)\r\nlts/* -> lts/dubnium (-> v10.14.2)\r\nlts/argon -> v4.9.1 (-> N/A)\r\nlts/boron -> v6.15.1 (-> N/A)\r\nlts/carbon -> v8.14.0 (-> N/A)\r\nlts/dubnium -> v10.14.2\r\n\r\n# node -v\r\nv10.14.2\r\n\r\n# npm -v\r\n6.4.1\r\n\r\n# cat /tmp/test-dns.js \r\nconst dns = require('dns');\r\nconst mx = (domain) => {\r\n    dns.resolveMx(domain, function (err, addresses) {\r\n        console.log(err);\r\n        console.log(addresses);\r\n    })\r\n}\r\nmx('torbox3uiot6wchz.onion')\r\n\r\n# node /tmp/test-dns.js \r\nSegmentation fault (core dumped)\r\n```\r\n\r\n```\r\n(gdb) bt\r\n#0  0x0000003ebd27b95c in __libc_free (mem=0x1528816) at malloc.c:3731\r\n#1  0x00000000016a3816 in ares_query (channel=0x2571a10, name=Unhandled dwarf expression opcode 0xf3\r\n) at ../deps/cares/src/ares_query.c:124\r\n#2  0x00000000008af32a in node::cares_wrap::(anonymous namespace)::QueryWrap::AresQuery ()\r\n#3  0x00000000008b3193 in void node::cares_wrap::(anonymous namespace)::Query<node::cares_wrap::(anonymous namespace)::QueryMxWrap>(v8::FunctionCallbackInfo<v8::Value> const&) ()\r\n#4  0x0000000000b5eb3f in v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) ()\r\n#5  0x0000000000b5f6a9 in v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) ()\r\n#6  0x00003c779595be1d in ?? ()\r\n#7  0x0000000000000006 in ?? ()\r\n#8  0x00003c779595bd81 in ?? ()\r\n#9  0x00007fffffffce40 in ?? ()\r\n#10 0x0000000000000006 in ?? ()\r\n#11 0x00007fffffffcf08 in ?? ()\r\n#12 0x00003c77959118d5 in ?? ()\r\n#13 0x000012c7cdc026f1 in ?? ()\r\n#14 0x000039d35b65aa31 in ?? ()\r\n#15 0x0000000700000000 in ?? ()\r\n#16 0x000012c7cdc02801 in ?? ()\r\n#17 0x000039d35b654ba1 in ?? ()\r\n#18 0x000006ba26dcbd49 in ?? ()\r\n#19 0x000006ba26dc7701 in ?? ()\r\n#20 0x000012c7cdc026f1 in ?? ()\r\n#21 0x000012c7cdc06bd1 in ?? ()\r\n#22 0x000006ba26dc7701 in ?? ()\r\n#23 0x000039d35b65aa31 in ?? ()\r\n#24 0x000006ba26dcbce9 in ?? ()\r\n#25 0x000012c7cdc026f1 in ?? ()\r\n#26 0x000006ba26dcbd49 in ?? ()\r\n#27 0x000012c7cdc026f1 in ?? ()\r\n#28 0x000000c000000000 in ?? ()\r\n#29 0x000039d35b65dc21 in ?? ()\r\n#30 0x000006ba26dc81a1 in ?? ()\r\n#31 0x000006ba26dc8169 in ?? ()\r\n#32 0x00007fffffffcf70 in ?? ()\r\n#33 0x00003c77959118d5 in ?? ()\r\n#34 0x000006ba26dcbca9 in ?? ()\r\n#35 0x000039d35b654ba1 in ?? ()\r\n#36 0x000006ba26dc7681 in ?? ()\r\n#37 0x000006ba26dcbca9 in ?? ()\r\n#38 0x000012c7cdc026f1 in ?? ()\r\n#39 0x000006ba26dc9019 in ?? ()\r\n#40 0x000006ba26dcad91 in ?? ()\r\n#41 0x0000004c00000000 in ?? ()\r\n#42 0x000039d35b65d9d1 in ?? ()\r\n#43 0x000006ba26dcbc71 in ?? ()\r\n#44 0x000006ba26dc0f79 in ?? ()\r\n#45 0x00007fffffffcfd0 in ?? ()\r\n#46 0x00003c77959118d5 in ?? ()\r\n#47 0x000039d35b654ba1 in ?? ()\r\n#48 0x00002a5d1441ad11 in ?? ()\r\n#49 0x000039d35b654ba1 in ?? ()\r\n#50 0x000012c7cdc026f1 in ?? ()\r\n#51 0x0000088f16603dc1 in ?? ()\r\n#52 0x000006ba26dcbc71 in ?? ()\r\n#53 0x0000005600000000 in ?? ()\r\n#54 0x000039d35b654f09 in ?? ()\r\n#55 0x000006ba26dc0b89 in ?? ()\r\n#56 0x000006ba26dc0f79 in ?? ()\r\n#57 0x00007fffffffd0a8 in ?? ()\r\n---Type <return> to continue, or q <return> to quit---\r\n#58 0x00003c77959118d5 in ?? ()\r\n#59 0x000006ba26dc0bc9 in ?? ()\r\n#60 0x000006ba26dbf4a9 in ?? ()\r\n#61 0x000006ba26dbf871 in ?? ()\r\n#62 0x000006ba26dc0c29 in ?? ()\r\n#63 0x000006ba26dbf929 in ?? ()\r\n#64 0x000006ba26dbf929 in ?? ()\r\n#65 0x000006ba26dc0bc9 in ?? ()\r\n#66 0x000006ba26dbf4a9 in ?? ()\r\n#67 0x000006ba26dbf871 in ?? ()\r\n#68 0x000006ba26dc0c29 in ?? ()\r\n#69 0x000006ba26dbf929 in ?? ()\r\n#70 0x000006ba26dbf929 in ?? ()\r\n#71 0x000006ba26dc0b89 in ?? ()\r\n#72 0x0000088f16604ad1 in ?? ()\r\n#73 0x000012c7cdc026f1 in ?? ()\r\n#74 0x0000000000000000 in ?? ()\r\n(gdb) info threads\r\n  7 Thread 0x7ffff7ffc700 (LWP 8405)  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:183\r\n  6 Thread 0x7ffff57df700 (LWP 8404)  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:183\r\n  5 Thread 0x7ffff61e0700 (LWP 8403)  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:183\r\n  4 Thread 0x7ffff6be1700 (LWP 8402)  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:183\r\n  3 Thread 0x7ffff75e2700 (LWP 8401)  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:183\r\n  2 Thread 0x7ffff7fe3700 (LWP 8400)  0x0000003ebd2e8e8c in epoll_pwait (epfd=<value optimized out>, events=<value optimized out>, maxevents=<value optimized out>, timeout=<value optimized out>, set=<value optimized out>) at ../sysdeps/unix/sysv/linux/epoll_pwait.c:50\r\n* 1 Thread 0x7ffff7fe5720 (LWP 8397)  0x0000003ebd27b95c in __libc_free (mem=0x1528816) at malloc.c:3731\r\n(gdb) info frame\r\nStack level 0, frame at 0x7fffffffc750:\r\n rip = 0x3ebd27b95c in __libc_free (malloc.c:3731); saved rip 0x16a3816\r\n called by frame at 0x7fffffffc790\r\n source language c.\r\n Arglist at 0x7fffffffc740, args: mem=0x1528816\r\n Locals at 0x7fffffffc740, Previous frame's sp is 0x7fffffffc750\r\n Saved registers:\r\n  rip at 0x7fffffffc748\r\n```",
        "labels": "confirmed-bug",
        "id": 45181
    },
    {
        "title": "Erroneous errors for multiline statements that include BigInt literal suffix",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.15.0, v10.15.1, v11.8.0\r\n* **Platform**: Linux <name redacted> 4.15.0-43-generic  # 46~16.04.1-Ubuntu SMP Fri Dec 7 13:31:08 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: REPL\r\n\r\n<!-- Please provide more details below this comment. -->\r\n## Possibly related to the issues discussed in #24231\r\n\r\nWhen attempting to create a multiline statement that includes the BigInt literal suffix syntax (i.e. Number followed by `n` to denote a BigInt) causes an erroneous `SyntaxError: Invalid or unexpected token` to be thrown. This behavior appears to occur only when the end of the statement is not on the same line as the BigInt. For example, the following seems to be erroneous behavior:\r\n\r\n```\r\n> let a = [\r\n... 4,\r\n... 'hello',\r\n... 0xffn,\r\nThrown:\r\n0xffn,\r\n     ^\r\n\r\nSyntaxError: Unexpected end of input\r\n```\r\n\r\nWhereas if the statement ends on the same line, it seems to behave as expected:\r\n\r\n```\r\n> [\r\n... 4,\r\n... 'hello',\r\n... 0xffn]\r\n[ 4, 'hello', 255n ]\r\n```\r\n\r\nThe same behavior seems to extend to any multiline statements regardless of whether or not the BigNum is the last thing on the line:\r\n\r\nWith BigNum:\r\n```\r\n> function fun(){\r\n... let m = 0xffn; return m;\r\nThrown:\r\nlet m = 0xffn; return m;\r\n                       ^\r\n\r\nSyntaxError: Unexpected end of input\r\n```\r\nWithout BigNum:\r\n```\r\nfunction fun(){\r\n... let m = 0xff; return m;\r\n... }\r\nundefined\r\n```\r\nBigNum on same line as closing bracket:\r\n```\r\n> function fun(){\r\n... let m = 0xffn; return m;}\r\nundefined\r\n> fun()\r\n255n\r\n```\r\n\r\n### Edit (Not sure if helpful):\r\n\r\nBigInt suffix seems to be picked up as an identifier. Given the following input into REPL:\r\n```\r\n> [\r\n... 0xffn,\r\n\r\n<debugger paused on pressing return key>\r\n```\r\n\r\n`pp$4.raise()` at line 2753 in `internal/deps/acorn/dist/acorn.js` is receiving `pos = 6, message = \"Identifier directly after number (2:4)`\r\n\r\nThat in turn seems to be coming from `pp$8.readRadixNumber()` at line 4981 in `internal/deps/acorn/dist/acorn.js`\r\n\r\nThe issue seems to originate at `isIdentifierStart()` (internal/deps/acorn/dist/acorn.js:71), which does in fact pick up `n` as the start of an identifier.\r\n\r\n`isIdentifierStart()` is also called by `pp$8.readNumber()` when using a normal, non-radix-prefixed number, producing the same result.\r\n\r\n`isIdentifierStart()` is bypassed when the statement is terminated on the same line as the BigInt, which explains why this scenario does not trigger the error:\r\n```\r\n> [\r\n... 0xffn]\r\n[ 255n ]\r\n>\r\n```",
        "labels": "confirmed-bug",
        "id": 45182
    },
    {
        "title": "Transform stream misses final readable event for small inputs",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.8.0\r\n* **Platform**: Ubuntu 18.10\r\n* **Subsystem**: stream\r\n\r\n<!-- Please provide more details below this comment. -->\r\nA Transform stream that transforms the entire input in one shot will generate just one `readable` event, when it should be two (one for data and one for EOS).\r\n\r\n```js\r\nconst stream = require('stream')\r\nconst fs = require('fs');\r\n\r\nconst r = new stream.Readable();\r\nr._read = function(n) { this.push('content'); this.push(null); };\r\n// const r = fs.createReadStream('/boot/memtest86+.bin');\r\n\r\nvar t = new stream.Transform({\r\n  transform: function(chunk, encoding, callback) {\r\n    console.log('_transform');\r\n    this.push(chunk);\r\n    return void callback();\r\n  },\r\n  flush: function(callback) {\r\n    console.log('_flush');\r\n    return void callback();\r\n  }\r\n});\r\n\r\nr.pipe(t);\r\nt.on(\"readable\", function() {\r\n  console.log(\"on readable\");\r\n  while (true) {\r\n    var chunk = t.read();\r\n    console.log(\"chunk\", chunk);\r\n    if (!chunk)\r\n      break;\r\n  }\r\n});\r\n```\r\n\r\nThe output of this example is:\r\n\r\n> _transform\r\n_flush\r\non readable\r\nchunk <Buffer 63 6f 6e 74 65 6e 74>\r\nchunk null\r\n\r\n But it should be\r\n> _transform\r\n_flush\r\non readable\r\nchunk <Buffer 63 6f 6e 74 65 6e 74>\r\nchunk null\r\non readable\r\nchunk null\r\n\r\nUsing a larger input stream (like the commented out line) correctly produces the last `readable` event.",
        "labels": "confirmed-bug",
        "id": 45183
    },
    {
        "title": "Unhandled application error causes segmentation fault in OpenSSL internals",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: master\r\n* **Platform**: Linux 4.4.0-042stab134.8 #1 SMP Fri Dec 7 17:16:09 MSK 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nI came across some segmentation faults within OpenSSL internals while changing some things in our crypto module. I was able to reproduce the segmentation faults on master by changing `test/parallel/test-crypto-keygen.js` to throw an error:\r\n\r\n```diff\r\ndiff --git a/test/parallel/test-crypto-keygen.js b/test/parallel/test-crypto-keygen.js\r\nindex ebbac76..62475e7 100644\r\n--- a/test/parallel/test-crypto-keygen.js\r\n+++ b/test/parallel/test-crypto-keygen.js\r\n@@ -276,6 +276,7 @@ const sec1EncExp = (cipher) => getRegExpForPEM('EC PRIVATE KEY', cipher);\r\n     }, /bad decrypt|asn1 encoding routines/);\r\n\r\n     testSignVerify(publicKey, { key: privateKey, passphrase: 'secret' });\r\n+    throw new Error();\r\n   }));\r\n }\r\n\r\n```\r\n\r\nOutput:\r\n\r\n```\r\n~/node$ ./node_g test/parallel/test-crypto-keygen.js\r\n/home/tniessen/node/test/parallel/test-crypto-keygen.js:279\r\n    throw new Error();\r\n    ^\r\n\r\nError\r\n    at AsyncWrap.common.mustCall (/.../node/test/parallel/test-crypto-keygen.js:279:11)\r\n    at AsyncWrap.<anonymous> (/.../node/test/common/index.js:370:15)\r\n    at AsyncWrap.wrap.ondone (internal/crypto/keygen.js:52:14)\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nTrace in GDB:\r\n\r\n```\r\nCore was generated by `./node_g test/parallel/test-crypto-keygen.js'.\r\nProgram terminated with signal SIGSEGV, Segmentation fault.\r\n#0  __GI___pthread_rwlock_wrlock (rwlock=0x0) at pthread_rwlock_wrlock.c:100\r\n100     pthread_rwlock_wrlock.c: No such file or directory.\r\n[Current thread is 1 (Thread 0x7fd5e2bfd700 (LWP 25121))]\r\n(gdb) bt\r\n#0  __GI___pthread_rwlock_wrlock (rwlock=0x0) at pthread_rwlock_wrlock.c:100\r\n#1  0x0000000001dcc442 in CRYPTO_THREAD_write_lock (lock=0x0) at ../deps/openssl/openssl/crypto/threads_pthread.c:73\r\n#2  0x0000000001da12c6 in RAND_get_rand_method () at ../deps/openssl/openssl/crypto/rand/rand_lib.c:744\r\n#3  0x0000000001da14a7 in RAND_priv_bytes (buf=0x7fd5d0006710 \"\", num=64) at ../deps/openssl/openssl/crypto/rand/rand_lib.c:816\r\n#4  0x0000000001cd6224 in bnrand (flag=PRIVATE, rnd=0x7fd5d0006380, bits=512, top=-1, bottom=0) at ../deps/openssl/openssl/crypto/bn/bn_rand.c:46\r\n#5  0x0000000001cd6688 in bnrand_range (flag=PRIVATE, r=0x7fd5d0006380, range=0x7fd5d0006350) at ../deps/openssl/openssl/crypto/bn/bn_rand.c:162\r\n#6  0x0000000001cd672d in BN_priv_rand_range (r=0x7fd5d0006380, range=0x7fd5d0006350) at ../deps/openssl/openssl/crypto/bn/bn_rand.c:184\r\n#7  0x0000000001cd4cbf in BN_is_prime_fasttest_ex (a=0x7fd5d0005ab0, checks=5, ctx_passed=0x7fd5d0005a20, do_trial_division=0, cb=0x0) at ../deps/openssl/openssl/crypto/bn/bn_prime.c:220\r\n#8  0x0000000001cd47d5 in BN_generate_prime_ex (ret=0x7fd5d0005ab0, bits=512, safe=0, add=0x0, rem=0x0, cb=0x0) at ../deps/openssl/openssl/crypto/bn/bn_prime.c:103\r\n#9  0x0000000001daa85e in rsa_builtin_keygen (rsa=0x7fd5d00060b0, bits=1024, primes=2, e_value=0x7fd5d0000a10, cb=0x0) at ../deps/openssl/openssl/crypto/rsa/rsa_gen.c:164\r\n#10 0x0000000001daa2b7 in RSA_generate_multi_prime_key (rsa=0x7fd5d00060b0, bits=1024, primes=2, e_value=0x7fd5d0000a10, cb=0x0) at ../deps/openssl/openssl/crypto/rsa/rsa_gen.c:61\r\n#11 0x0000000001db2076 in pkey_rsa_keygen (ctx=0x7fd5d00008c0, pkey=0x7fd5d0000b50) at ../deps/openssl/openssl/crypto/rsa/rsa_pmeth.c:742\r\n#12 0x0000000001d6a0fd in EVP_PKEY_keygen (ctx=0x7fd5d00008c0, ppkey=0x7fd5e2bfce00) at ../deps/openssl/openssl/crypto/evp/pmeth_gn.c:108\r\n#13 0x0000000000fbe3df in node::crypto::GenerateKeyPairJob::GenerateKey (this=0x510a840) at ../src/node_crypto.cc:5793\r\n#14 0x0000000000fbe2de in node::crypto::GenerateKeyPairJob::DoThreadPoolWork (this=0x510a840) at ../src/node_crypto.cc:5770\r\n#15 0x0000000000e06a79 in node::ThreadPoolWork::ScheduleWork()::{lambda(uv_work_s*)#1}::operator()(uv_work_s*) const (__closure=0x0, req=0x510a850) at ../src/node_internals.h:233\r\n#16 0x0000000000e06afd in node::ThreadPoolWork::ScheduleWork()::{lambda(uv_work_s*)#1}::_FUN(uv_work_s*) () at ../src/node_internals.h:234\r\n#17 0x0000000001020edc in uv__queue_work (w=0x510a8a8) at ../deps/uv/src/threadpool.c:321\r\n#18 0x000000000102068f in worker (arg=0x0) at ../deps/uv/src/threadpool.c:122\r\n#19 0x00007fd5eaa206ba in start_thread (arg=0x7fd5e2bfd700) at pthread_create.c:333\r\n#20 0x00007fd5ea75641d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109\r\n```\r\n\r\nMy best guess is that we are shutting down OpenSSL after the error on the main thread occurs, causing background tasks such as key generation to run into problems when trying to use internal resources that have been cleaned up already.",
        "labels": "confirmed-bug",
        "id": 45184
    },
    {
        "title": "FatalException handler SIGABRT from throw with `.stack` getter error",
        "body": "```\r\nnode -e \"throw { get stack() { throw new Error('weird throw but ok') } }\"\r\n\r\nFATAL ERROR: v8::ToLocalChecked Empty MaybeLocal.\r\n...\r\n```\r\n\r\nAs discovered in https://github.com/nodejs/node/pull/25715 but not strictly related to.\r\n\r\nThis is the line in question from the abort:\r\nhttps://github.com/nodejs/node/blob/f40778e97a1a324a01e266ed82d91c272715a69a/src/node_errors.cc#L211\r\n\r\nBasically, `node::FatalException` doesn't handle deep errors from `.stack` getters.\r\n\r\nThis is a pretty messy problem to fully deal with. It is possible to have a situation of infinitely recursing `.stack` getter errors, theoretically at least.\r\n\r\nThat being said... I doubt that any significant number of people will ever actually run into the more problematic cases, or maybe even the simple case.",
        "labels": "confirmed-bug",
        "id": 45185
    },
    {
        "title": "worker_threads: worker.postMessage does not get executed without exiting synchronous call stack",
        "body": "* **Version**: 11.7.0\r\n* **Platform**: Linux threadripper 4.15.0-43-generic #46-Ubuntu SMP Thu Dec 6 14:45:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: worker_threads\r\n\r\nI am playing with node's worker_threads, running Emscripten-generated multi-threaded code in this way. From what I can see, the worker's\r\n\r\n```\r\nparentPort.on(\"message\", function(msg) {\r\n...\r\n});\r\n```\r\nwill not get triggered, if the main thread calls `worker.postMessage(...)` without \"unwinding the stack\" (ie., returning control to node's event loop). Unfortunately, this is exactly the kind of code that Emscripten generates: the main thread will use `Atomics.wait(...)` to wait for its child threads (workers) to complete, but it will not actually return control to node.\r\n\r\nNote that the `Worker.postMessage(...)` semantics is insofar different from how `postMessage` works in browsers, which gets executed _immediately_, ie., WITHOUT returning control to the browser.\r\n\r\nThis may be related to https://github.com/nodejs/node/issues/21417.",
        "labels": "confirmed-bug",
        "id": 45186
    },
    {
        "title": "DNS resolution fails for internationalized domain names",
        "body": "* **Version**: v10.14.2\r\n* **Platform**: Darwin november.local 18.2.0 Darwin Kernel Version 18.2.0: Mon Nov 12 20:24:46 PST 2018; root:xnu-4903.231.4~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**: dns, cares_wrap\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nCurrently the DNS module seems to utf-8 encode the names passed to c-ares for DNS resolution: https://github.com/nodejs/node/blob/2c0a75118cd6a2eaf6b45fe8c67336f44c86ab0f/src/cares_wrap.cc#L1803\r\n\r\nThat doesn't work for [internationalized domain names](https://en.wikipedia.org/wiki/Internationalized_domain_name), which need to be IDNA encoded.\r\n\r\nDNS is pretty much all ASCII, so IMHO Node shouldn't utf-8 encode on input.\r\n\r\n[Here](http://www.i18nguy.com/markup/idna-examples.html) is a list of international domain names to test.\r\n\r\nThis will produce an error:\r\n\r\n```\r\n> dns.resolve('espaÃ±a.icom.museum', function(r, e) { console.log(r, e) })`\r\n> { Error: queryA ENOTFOUND espaÃ±a.icom.museum\r\n    at QueryReqWrap.onresolve [as oncomplete] (dns.js:197:19)\r\n  errno: 'ENOTFOUND',\r\n  code: 'ENOTFOUND',\r\n  syscall: 'queryA',\r\n  hostname: 'espaÃ±a.icom.museum' } undefined\r\n```\r\nWhereas the proper IDNA encoded version works:\r\n\r\n```\r\n> dns.resolve('xn--espaa-rta.icom.museum', function(e, r) { console.log(e, r) })\r\n> null [ '91.194.60.138' ]\r\n```",
        "labels": "confirmed-bug",
        "id": 45187
    },
    {
        "title": "Windows CI failures: parallel/test-trace-events-fs-sync",
        "body": "Seeing 3221225477 (access violation) non-stop on win10 + vs2017 on CI in a trace_events test:\r\n\r\n```console\r\n00:19:43 not ok 494 parallel/test-trace-events-fs-sync\r\n00:19:43   ---\r\n00:19:43   duration_ms: 0.781\r\n00:19:43   severity: fail\r\n00:19:43   exitcode: 1\r\n00:19:43   stack: |-\r\n00:19:43     c:\\workspace\\node-test-binary-windows\\test\\parallel\\test-trace-events-fs-sync.js:140\r\n00:19:43         throw new Error(`${tr}:\\n${util.inspect(proc)}`);\r\n00:19:43         ^\r\n00:19:43     \r\n00:19:43     Error: fs.sync.fchmod:\r\n00:19:43     { status: 3221225477,\r\n00:19:43       signal: null,\r\n00:19:43       output: [ null, '', '' ],\r\n00:19:43       pid: 3272,\r\n00:19:43       stdout: '',\r\n00:19:43       stderr: '' }\r\n00:19:43         at Object.<anonymous> (c:\\workspace\\node-test-binary-windows\\test\\parallel\\test-trace-events-fs-sync.js:140:11)\r\n00:19:43         at Module._compile (internal/modules/cjs/loader.js:722:30)\r\n00:19:43         at Object.Module._extensions..js (internal/modules/cjs/loader.js:733:10)\r\n00:19:43         at Module.load (internal/modules/cjs/loader.js:621:32)\r\n00:19:43         at tryModuleLoad (internal/modules/cjs/loader.js:564:12)\r\n00:19:43         at Function.Module._load (internal/modules/cjs/loader.js:556:3)\r\n00:19:43         at Function.Module.runMain (internal/modules/cjs/loader.js:775:12)\r\n00:19:43         at executeUserCode (internal/bootstrap/node.js:433:15)\r\n00:19:43         at startExecution (internal/bootstrap/node.js:370:3)\r\n00:19:43   ...\r\n```\r\n\r\nExamples:\r\n\r\nhttps://ci.nodejs.org/job/node-test-binary-windows/23086/COMPILED_BY=vs2017,RUNNER=win10,RUN_SUBSET=0/console\r\nhttps://ci.nodejs.org/job/node-test-binary-windows/23085/COMPILED_BY=vs2017,RUNNER=win10,RUN_SUBSET=0/\r\nhttps://ci.nodejs.org/job/node-test-binary-windows/23084/COMPILED_BY=vs2017,RUNNER=win10,RUN_SUBSET=0/\r\n\r\n...and many others...started happening in the last 24 hours or so. Not sure if something changed in our code or if something changed on CI or what. First noted (to my knowledge) by @gireeshpunathil in https://github.com/nodejs/node/pull/22712#issuecomment-453897949 and https://github.com/nodejs/node/issues/22865#issuecomment-453914513.\r\n\r\nThat was rebased onto 7f913293c1ac50b01dfc775fe4861f362bcf624a. So if the problem *is* in our code (and not something that is only being surfaced now but has been there for a while or else something that is a problem with the CI host and not a problem with the test or code), then it would be either in that commit or one shortly before it.\r\n\r\n@nodejs/trace-events \r\n\r\n[refack]Added context - the above 3 fails are on 3 different workers. AFAICT all failures are similar and happen while testing `fchmod`\r\nTest call site: https://github.com/nodejs/node/blob/master/test/parallel/test-trace-events-fs-sync.js#L122\r\nand setup site: https://github.com/nodejs/node/blob/master/test/parallel/test-trace-events-fs-sync.js#L33-L36\r\nwhere this test case is six deep.",
        "labels": "confirmed-bug",
        "id": 45188
    },
    {
        "title": "crypto::Hash update method error output is missing `Buffer`",
        "body": "* **Version**: `10.10.0`\r\n* **Platform**: `Linux amit-ThinkPad-X1-Carbon-6th 4.15.0-43-generic #46-Ubuntu SMP Thu Dec 6 14:45:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: `crypto`\r\n\r\nThe `Hash` class in the `crypto` module has an `update` method which may receive `{string | Buffer | TypedArray | DataView}` in the `data` argument.\r\n(https://github.com/nodejs/node/blob/master/doc/api/crypto.md#hashupdatedata-inputencoding)\r\n\r\nThe error message output if an invalid argument type is passed is missing `Buffer`.\r\n(https://github.com/nodejs/node/blob/master/lib/internal/crypto/hash.js#L65)\r\n\r\nI believe this is a good first bug, and would like to fix it myself. AFAICT, a test should be added here:\r\nhttps://github.com/nodejs/node/blob/master/test/parallel/test-crypto-hash.js\r\n\r\nIf this issue is verified, I just need a pointer to how to run the tests in `test/parallel`.\r\n",
        "labels": "confirmed-bug",
        "id": 45189
    },
    {
        "title": "esm: Bug in dynamic modules refactoring",
        "body": "Reposted from https://github.com/nodejs/help/issues/1717.\r\n\r\n# Specs:\r\n- **Node.js Version**: \r\n  - Tested and working: \r\n    - v11.3.0 \r\n  - Tested and broken:\r\n    - v11.4.0\r\n    - v11.5.0\r\n- **OS**: Tested on Linux Mint 19.1 Cinnamon\r\n  - `Linux HOSTNAME 4.15.0-43-generic #46-Ubuntu SMP Thu Dec 6 14:45:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux`\r\n- **Scope (install, code, runtime, meta, other?)**: ES6 Module Import Regression from v11.3.0 to v11.4.0 using `--experimental-modules`\r\n- **Module (and version) (if relevant)**: `request-promise-native`, but stacktrace also points to `psl` and core node as suspect.\r\n\r\n# Problem Statement:\r\nImporting `request-promise-native` using ES6 module syntax on v11.4.0 or v11.5.0 causes a stacktrace which (I think) points to an error in core node:\r\n\r\n```\r\nkevin@rayquaza:~/tmp$ node --experimental-modules index.mjs \r\n(node:13310) ExperimentalWarning: The ESM module loader is experimental.\r\nTypeError: Cannot read property 'onReady' of undefined\r\n    at Module.load (internal/modules/cjs/loader.js:631:22)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:560:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:552:3)\r\n    at Module.require (internal/modules/cjs/loader.js:659:17)\r\n    at require (internal/modules/cjs/helpers.js:22:18)\r\n    at Object.<anonymous> (/home/kevin/tmp/node_modules/psl/index.js:14:19)\r\n    at Module._compile (internal/modules/cjs/loader.js:723:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:734:10)\r\n    at Module.load (internal/modules/cjs/loader.js:620:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:560:12)\r\n```\r\n\r\n# Steps To Reproduce:\r\n- Be on node version v11.4.0 or later:\r\n   - `nvm install v11.4.0`\r\n- Clone (or otherwise duplicate) the project from this gist: https://gist.github.com/kj800x/f08f44305429bbf8fdd65f9991cb2a71\r\n  - `git clone https://gist.github.com/kj800x/f08f44305429bbf8fdd65f9991cb2a71 && cd f08f44305429bbf8fdd65f9991cb2a71`\r\n  - It consists of an index file that imports `request-promise-native` and a package.json and a package-lock.json\r\n- Install dependencies:\r\n  - `npm i`\r\n- Run the code\r\n  - `npm start`\r\n    - **ACTUAL:** Observe the stacktrace and error\r\n- Switch to node version v11.3.0\r\n  - `nvm install v11.3.0`\r\n- Run the code\r\n  - `npm start`\r\n    - **EXPECTED:** Observe that you are able to successfully import the module without errors.\r\n\r\n# Related\r\nThe last three comments on this `request-promise-native` issue are related: https://github.com/request/request-promise-native/issues/1#issuecomment-450769515",
        "labels": "confirmed-bug",
        "id": 45190
    },
    {
        "title": "TypeError: clazz is not a constructor on â‰¥ v11.6.0",
        "body": "I'm experiencing an issue with a following piece of code\r\n\r\n<img width=\"1147\" alt=\"screen shot 2019-01-11 at 10 27 41 pm\" src=\"https://user-images.githubusercontent.com/14351638/51058947-27c57900-15f3-11e9-839d-33dd8fc4d49d.png\">\r\n\r\n```javascript\r\n'use strict';\r\n\r\nconst people = [\r\n  ['John', 19, 'm'],\r\n  ['Valentine', 28, 'f'],\r\n  ['Christina', 25, 'f']\r\n];\r\n\r\nclass Person {\r\n  get name() {\r\n    return this[0];\r\n  }\r\n  \r\n  get age() {\r\n    return this[1];\r\n  }\r\n  \r\n  get sex() {\r\n    return this[2];\r\n  }\r\n}\r\n\r\npeople.forEach(person => Object.setPrototypeOf(person, Person.prototype));\r\n\r\nconst query = person => person.age > 25;\r\n\r\npeople.filter(query);\r\n```\r\nYou can see a more detailed information about the stacktrace right below\r\n<img width=\"822\" alt=\"screen shot 2019-01-11 at 10 49 55 pm\" src=\"https://user-images.githubusercontent.com/14351638/51058973-40ce2a00-15f3-11e9-90d0-04b38c5012c5.png\">\r\n\r\n* **Node: v11.6.0**:\r\n* **Platform: macOS Mojave Version 10.14.2**:\r\n",
        "labels": "confirmed-bug",
        "id": 45191
    },
    {
        "title": "Syntax error message sometimes highlights the wrong token for reserved words",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: `v11.6.0`\r\n* **Platform**: Linux (`linux-4.20.arch1-1-ARCH`)\r\n\r\nWhen attempting to declare a variable with a reserved word as an identifier name, the `SyntaxError` message thrown will sometimes highlight the wrong token. For example:\r\n\r\n```js\r\n'use strict';\r\nlet public = 0;\r\n```\r\n\r\nThe above code throws the following error:\r\n\r\n```\r\nlet public = 0;\r\n^^^\r\n\r\nSyntaxError: Unexpected strict mode reserved word\r\n    at new Script (vm.js:84:7)\r\n    at createScript (vm.js:264:10)\r\n    at Object.runInThisContext (vm.js:312:10)\r\n    at Module._compile (internal/modules/cjs/loader.js:684:28)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:732:10)\r\n    at Module.load (internal/modules/cjs/loader.js:620:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:560:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:552:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:774:12)\r\n    at executeUserCode (internal/bootstrap/node.js:342:17)\r\n```\r\n\r\nHowever, changing the `let` to a `const` throws this error instead:\r\n\r\n```\r\nconst public = 0;\r\n      ^^^^^^\r\n\r\nSyntaxError: Unexpected strict mode reserved word\r\n    at new Script (vm.js:84:7)\r\n    at createScript (vm.js:264:10)\r\n    at Object.runInThisContext (vm.js:312:10)\r\n    at Module._compile (internal/modules/cjs/loader.js:684:28)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:732:10)\r\n    at Module.load (internal/modules/cjs/loader.js:620:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:560:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:552:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:774:12)\r\n    at executeUserCode (internal/bootstrap/node.js:342:17)\r\n```\r\n\r\nSome additional notes about when this happens, in case it helps:\r\n\r\n- It only occurs in strict mode; non-strict-mode code gets underlined correctly\r\n- It only occurs with `let` declarations, not `const` or `var`\r\n- It does *not* occur with identifier names of `let` or `strict`, presumably because they're treated differently according to the ECMA spec\r\n- For identifiers `true`, `false`, and `null`, the bug still occurs with a `let` declaration, but the error message thrown by `const` and `var` declarations becomes `SyntaxError: Unexpected token` instead of `SyntaxError: Unexpected strict mode reserved word`",
        "labels": "confirmed-bug",
        "id": 45192
    },
    {
        "title": "generateKeyPairSync doesn't return KeyObject",
        "body": "* **Version**: v11.6.0\r\n* **Platform**: macOS Mojave (10.14.2) Darwin C02TT3JQHTD6 18.2.0 Darwin Kernel Version 18.2.0: Mon Nov 12 20:24:46 PST 2018; root:xnu-4903.231.4~2/RELEASE_X86_64 x86_64\r\n\r\nFrom `crypto.generateKeyPair` documentation\r\n> If a `publicKeyEncoding` or `privateKeyEncoding` was specified, this function behaves as if `keyObject.export()` had been called on its result. **Otherwise, the respective part of the key is returned as a `KeyObject`.**\r\n\r\nThis documentation part is missing from `crypto.generateKeyPairSync` but you can still omit the encoding objects, then a simple empty object `{}` is returned instead of an expected `KeyObject`.\r\n\r\n/cc @tniessen\r\n\r\nExamples:\r\n```js\r\nconst { generateKeyPairSync } = require('crypto')\r\n\r\nconsole.log('generateKeyPairSync result', generateKeyPairSync('rsa', { modulusLength: 2048 }))\r\n// => generateKeyPairSync result { publicKey: {}, privateKey: {} }\r\n```",
        "labels": "confirmed-bug",
        "id": 45193
    },
    {
        "title": "TextDecoder should not output BOM",
        "body": "Found when porting encoding WPT into core.\r\n\r\nSpec: https://encoding.spec.whatwg.org/#concept-td-serialize\r\n\r\n> If encoding is UTF-8, UTF-16BE, or UTF-16LE, and ignore BOM flag and BOM seen flag are unset, then:\r\n>  - If token is U+FEFF, then set BOM seen flag.\r\n>  - Otherwise, if token is not end-of-stream, then set BOM seen flag and append token to output.\r\n>  - Otherwise, return output.\r\n\r\nFailing tests:\r\n\r\n- [wpt/encoding/textdecoder-byte-order-marks.any.js](https://github.com/web-platform-tests/wpt/blob/e44b8b3/encoding/textdecoder-byte-order-marks.any.js)\r\n- [wpt/encoding/textdecoder-copy.any.js](https://github.com/web-platform-tests/wpt/blob/e40affe/encoding/textdecoder-copy.any.js)\r\n",
        "labels": "confirmed-bug",
        "id": 45194
    },
    {
        "title": "fs.watch() reports removed directory as subdirectory of itself",
        "body": "* **Affected versions**: Latest release of Current and all LTSes - 11.6.0, 10.15.0, 8.15.0, and 6.16.0.\r\n* **Affected platform**: Linux (ok on macOS/Windows)\r\n* **Subsystem**: fs\r\n\r\n### Description\r\n\r\nWhen using `fs.watch()` to watch a directory, and removing that very directory itself, a change event is emitted with a filename matching the directory itself.\r\n\r\nTo my knowledge, the standard way to obtain an absolute path of the affected file, is to `path.join()` the filename with the directory being watched.\r\n\r\nAs such, the emitted event is interpreted as if a subdirectory changed, which is incorrect.\r\n\r\n### Test case\r\n\r\nCode at https://github.com/Krinkle/sandbox/blob/node-fs-watch-removedir/test.js.\r\n\r\nBuild output:\r\n* Linux / Node 11.6.0: <https://travis-ci.com/Krinkle/sandbox/jobs/167657972>\r\n* Linux / Node 10.15.0: <https://travis-ci.com/Krinkle/sandbox/jobs/167657973>\r\n* .. for Node 8, 6 and macOS/Windows, see <https://travis-ci.com/Krinkle/sandbox/builds/96013157>.\r\n\r\nIn brief:\r\n\r\n1. Given a directory structure as follows:\r\n\r\n```\r\n    - home/\r\n          - a/\r\n             - file1\r\n          - b/\r\n             - file1\r\n             - file2\r\n          - c/\r\n```\r\n\r\n2. And creating an fs.FSWatcher for `home/` and `home/c`, via `fs.watch(dir, { encoding: 'utf8', recursive: false })`.\r\n3. And removing `home/c/` via `fs.rmdirSync(dir)`.\r\n\r\n### Expected\r\n\r\nChange event for `home/` or `home/c/`. Specifically, one or more of:\r\n\r\n* An event on `home/` with a filename of `'c'`, `'/c'`, or no filename.\r\n* An event on `home/c/` with a filename of `''` (empty string),`'.'` (empty string), `'/'`, or no filename.\r\n\r\n### Actual\r\n\r\nOn macOS, gets a change event for `home/c/` as expected:\r\n\r\n1. FSWatcher for `home/` receives `change` event; eventType=`rename`, filename=`c`\r\n\r\nOn macOS, gets a change event for `home/c/` as expected:\r\n\r\n1. FSWatcher for `home/` receives `change` event; eventType=`rename`, filename=`c`\r\n\r\nOn Linux, gets change events for **`/home/c/c/`**: âŒ\r\n\r\n1. FSWatcher for **`home/c/`** receives `change` event; eventType=`rename`, filename=`c` âŒ\r\n2. FSWatcher for **`home/c/`** receives `change` event; eventType=`rename`, filename=`c` âŒ\r\n3. FSWatcher for `home/` receives `change` event; eventType=`rename`, filename=`c` âœ…\r\n",
        "labels": "confirmed-bug",
        "id": 45195
    },
    {
        "title": "Tabs in the repl cause display issues",
        "body": "Just copy something like `var\tabc\t=\t5;` in the repl and go back and forth and remove or add some characters. Push enter and go up and down in the history and further issues will resolve.\r\n\r\nThe marker is not correct and sometimes things are not visible that should be and the other way around.\r\n\r\n<s>I guess we could either just display tabs as space (that would likely resolve the problem easily) or</s>\r\n\r\nWe have to properly fix this and to teach the code to jump to the correct position if there's a tab.",
        "labels": "confirmed-bug",
        "id": 45196
    },
    {
        "title": "fileURLToPath returns forward slashes on Windows",
        "body": "* **Version**: v11.6.0\r\n* **Platform**: Win64\r\n* **Subsystem**: url\r\n\r\n`url.fileURLToPath` results in a path containing forward slashes instead of backslashes on Windows.\r\n\r\n```js\r\nurl.fileURLToPath('file:///C:/Users/zenparsing/Code');\r\n// 'C:/Users/zenparsing/Code'\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45197
    },
    {
        "title": "Zero-byte allocation causes assertion failure",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 11.6.0\r\n* **Platform**: Ubuntu, Windows\r\n* **Subsystem**: crypto\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nPassing an empty string to any function that parses a private key causes an assertion failure:\r\n\r\n```\r\n> crypto.createPrivateKey({ key: '' })\r\nC:\\WINDOWS\\system32\\cmd.exe - node[12104]: src\\node_crypto.cc:2675: Assertion `(mem) != nullptr' failed.\r\n```",
        "labels": "confirmed-bug",
        "id": 45198
    },
    {
        "title": "Makefile dependency tree is incomplete, makefiles do not build only as necessary",
        "body": "* Version: master\r\n* Platform:Linux samtu 4.18.0-12-generic #13-Ubuntu SMP Wed Nov 14 15:17:05 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n* Subsystem: gyp/make\r\n\r\nThe makefiles generated by gyp are not working for development (they work better for single-shot CI builds). Perhaps I'm missing something, please tell me if I am, but I've done some asking around to people who know the gyp system, and have some agreement on these points.\r\n\r\n- `make node; make node` Make should do *nothing* if no source code has been changed, but `make node` relinks both `node` *and* `cctest` (!?) every time it is run.\r\n\r\n- `make -C out node` is faster, ~but~ and builds just node, not cctest, but it does it even if no source has changed. However, its build/dependency tree is incomplete! It doesn't run js2c so if any js source files are changed they will not be built-in with js2c. Fast and wrong is worse than slow.\r\n\r\n- `make -C out/Release node` as above\r\n\r\n- ` make -j4 node; make -j1 test` often required. parallel make is not working for test. Various symptoms of brokenness occur (irc has some discussion). Sounds like this could be related to the dependency relationships not being correctly specified, causing build rules to run in parallel when they cannot, and thus be racy.\r\n\r\n- `./configure --shared-openssl-includes` will cause openssl include paths to be passed to dependencies that don't use openssl. This might appear harmless, but it (for example) causes ccache to rebuild icu, even though icu doesn't use openssl. Possible fix: https://github.com/nodejs/node/blob/eef6504cf7b95ada170ec9878089ce57fde551d8/common.gypi#L549-L560, add `OPENSSL_THREADS` to the else clause (I haven't tried yet).\r\n\r\n\r\nNinja notes:\r\n\r\nNinja (`./configure --ninja`) doesn't have the above problems for building, its dependency tree is correct (it builds nothing when nothing has changed, and it reruns js2c when js files have changed).\r\n\r\nHowever, it is either incomplete or not integrated with the rest of the build (I'm not sure how its intended to work). It doesn't make the top-level `node` symlink (at least `test-doc` relies on this), so a `ln -s out/Release/node node` is required for `make test-doc`. As for `make test`, it won't use the ninja build output, because it relies on .PHONY targets, so it always (effectively) does a `make -C out all`.",
        "labels": "confirmed-bug",
        "id": 45199
    },
    {
        "title": "regression: child_process stdin pipe close event not emitted",
        "body": "### Summary\r\n* **Version**: v8.12.0 and newer, all v10.x and all v11.x\r\n* **Platform**: Linux and macOS amd64\r\n* **Subsystem**: child_process\r\n\r\nSince #18701 Node.js doesn't emit a close event when a child process closes its stdin pipe. The close is only detected if the parent tries to write to the child's stdin and receives an EPIPE.\r\n\r\nThe original behaviour is preferable because it allows immediate detection of the close event, rather than waiting for a failed write.\r\n\r\n### Reproducer\r\n\r\nThis works as expected in v8.11.4 and fails in all newer versions of v8.x, as well as all v10.x and all v11.x.\r\n\r\n```js\r\nconst {spawn} = require('child_process');\r\n\r\nconst cp = spawn(\r\n    'node', [\r\n        '-e',\r\n        'fs.closeSync(0); setTimeout(() => {}, 2000)'\r\n    ],\r\n    {stdio: ['pipe', 'inherit', 'inherit']}\r\n)\r\n\r\nsetTimeout(() => {\r\n    console.log('BUGGY! stdin close event was not emitted')\r\n    process.exit(1);\r\n}, 1000);\r\n\r\ncp.stdin.on('close', () => {\r\n    console.log('Ok!')\r\n    process.exit(0);\r\n});\r\n```\r\n\r\n### Problem detail\r\n\r\nAs far as I can tell the only way the close event can be emitted is if the `Socket` constructor calls `this.read(0)`. This triggers `onStreamRead()` to be called, which does `stream.push(null)` and eventually results in the close event. This is a little weird because stdin isn't a readable stream :)\r\n\r\nIn Node 8.11.4 this worked because `child_process.js:createSocket()` called the `Socket` constructor with `options.readable === undefined`. So the `Socket` constructor sees that `options.readable !== false` and runs `this.read(0)`\r\n\r\nIn PR #18701 `createSocket()` was changed to call the `Socket` constructor with `options.readable === true`. This stops `this.read(0)` from being called and the close event is not emitted.\r\n\r\n### Hacky solution\r\n\r\n```diff\r\n--- a/lib/internal/child_process.js\r\n+++ b/lib/internal/child_process.js\r\n@@ -286,3 +286,3 @@ function flushStdio(subprocess) {\r\n function createSocket(pipe, readable) {\r\n-  return net.Socket({ handle: pipe, readable, writable: !readable });\r\n+  return net.Socket({ handle: pipe, readable, writable: !readable, childProcess: true });\r\n }\r\n--- a/lib/net.js\r\n+++ b/lib/net.js\r\n@@ -315,3 +315,5 @@ function Socket(options) {\r\n   // buffer.  if not, then this will happen when we connect\r\n-  if (this._handle && options.readable !== false) {\r\n+  if (options.childProcess) {\r\n+    this.read(0);\r\n+  } else if (this._handle && options.readable !== false) {\r\n     if (options.pauseOnCreate) {\r\n```\r\n\r\nThis passes the full test suite with a minor change to `test-pipewrap.js`. I haven't raised a PR because I'm sure somebody could think of a better solution. If someone can point me in the right direction I'm happy to try and implement it.\r\n\r\nThanks :)",
        "labels": "confirmed-bug",
        "id": 45200
    },
    {
        "title": "object spread operator mutates first argument",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: v11.4.0\r\nPlatform: Windows 10.0.17134, 64-bit\r\nSubsystem: don't know\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.4.0\r\n* **Platform**: Windows 10.0.17134, 64-bit\r\n* **Subsystem**: don't know\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nCode to reproduce the issue:\r\n\r\n```\r\nconst workspace = JSON.parse('{\"orgContentScore\":{\"41\":{\"id\":\"41\",\"contentId\":\"111\",\"competenceId\":\"40\",\"scoreTypeId\":\"6\",\"value\":0.25}}}');\r\nconst selectedObject = Object.values(workspace.orgContentScore).filter(ocs => ocs.contentId === '111').find(ocs => ocs.competenceId === '40');\r\nconsole.log(selectedObject.value, 0.25); // Note: not mutated (yet)\r\nconsole.log({...selectedObject, value: 0.9}.value, 0.9); // Note: This mutates selectedObject on node@11 but not on node@10\r\nconsole.log(selectedObject.value, 0.25); // Note: selected objects is now mutated!!\r\n```\r\n\r\nOn node@11 this outputs this unexpected result:\r\n\r\n```\r\n0.25 0.25\r\n0.9 0.9\r\n0.9 0.25\r\n```\r\n\r\nWhere on node@10, it outputs the expected result:\r\n\r\n```\r\n0.25 0.25\r\n0.9 0.9\r\n0.25 0.25\r\n```\r\n\r\naccording to my understanding of the description on MDN: \r\n\r\n* https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax#Spread_in_object_literals\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45201
    },
    {
        "title": "exit race between main and worker threads",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.0.0\r\n* **Platform**: all\r\n* **Subsystem**: ~~worker~~, process, src\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nSample test case to reproduce the issue:\r\n\r\n```js\r\n'use strict'\r\nconst { Worker, isMainThread, parentPort } = require('worker_threads')\r\n\r\nif (isMainThread) {\r\n  const count = process.argv[2] / 1\r\n  for(var i=0;i<count;i++)\r\n    new Worker(__filename)\r\n  process.exit(0)\r\n} else {\r\n  setInterval(() => {\r\n    parentPort.postMessage('Hello, world!')\r\n  }, 1)\r\n}\r\n```\r\n\r\nThe flakiness of the test is largely influenced by the thread scheduling order / number of CPUs / load on the system.\r\n\r\nFirst reported in AIX and Linux through `sequential/test-cli-syntax.js`. The more you run, the more variety of scenarios you get: SIGSEGV, SIGABRT, SIGILL... depends on at what point the main and the worker threads are.\r\n\r\nThe root cause is that there is no specified order / identified ownership of C++ global objects that being destructed between threads.\r\n\r\nRefs: https://github.com/nodejs/node/issues/24403\r\n",
        "labels": "confirmed-bug",
        "id": 45202
    },
    {
        "title": "close event emitted on net socket but not tls",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.4.0\r\n* **Platform**: Linux david-Latitude-E6440 4.18.0-12-generic #13-Ubuntu SMP Wed Nov 14 15:17:05 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: net, tls\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWhy does this emit a `close` event:\r\n\r\n```javascript\r\nconst fs = require('fs');\r\nconst path = require('path');\r\nconst net = require('net');\r\nconst server = net.createServer();\r\n\r\nserver.on('connection', function (conn) {\r\n    conn.on('close', function () {\r\n        console.log(\"CLOSE\");\r\n    });\r\n\r\n    conn.resume();\r\n    conn.end(Buffer.alloc(1024*1024));\r\n});\r\n\r\nserver.listen(7000, function () {\r\n    net.connect({\r\n        port: 7000\r\n    }, function () {\r\n        this.end();\r\n    });\r\n});\r\n```\r\n\r\nbut this does not emit a close event:\r\n\r\n```javascript\r\nconst fs = require('fs');\r\nconst path = require('path');\r\nconst tls = require('tls');\r\nconst server = tls.createServer({\r\n    key: fs.readFileSync(path.join(__dirname, 'server.key')),\r\n    cert: fs.readFileSync(path.join(__dirname, 'server.pem'))\r\n});\r\n\r\nserver.on('secureConnection', function (conn) {\r\n    conn.on('close', function () {\r\n        console.log(\"CLOSE\");\r\n    });\r\n\r\n    conn.resume();\r\n    conn.end(Buffer.alloc(1024*1024));\r\n});\r\n\r\nserver.listen(7000, function () {\r\n    tls.connect({\r\n        ca: fs.readFileSync(path.join(__dirname, 'ca.pem')),\r\n        port: 7000\r\n    }, function () {\r\n        this.end();\r\n    });\r\n});\r\n```\r\n\r\n?\r\n",
        "labels": "confirmed-bug",
        "id": 45203
    },
    {
        "title": "Node 10.14.x Regression in parsing of binary upgrade response body",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10.14.1\r\n* **Platform**: MacOS 10.13.2\r\n* **Subsystem**: _(Docker > ubuntu:xenial)_\r\n\r\nIt appears that the v10.14.x version range introduces a regression which was resolved by #17806. This gist can consistently reproduce the error: https://gist.github.com/shellscape/2020916f92be5d61f4d411fb6d2bce61\r\n\r\nNote that stepping back down to any 10.x version lower than 10.14.0 does not reproduce the error. We've spun up brand new containers to verify the issue was isolated to 10.14.x. The same containers (config) from scratch with 10.13.x are completely fine. And have verified this on three different machines (both Windows and Mac OS), in different geographic locations (U.S., Brazil, New Zealand).\r\n\r\nThis was noticed with use of the [websockets/ws](/websockets/ws) module. The immediate error stack produced:\r\n\r\n```\r\n  RangeError: Invalid WebSocket frame: RSV1 must be clear\r\n\r\n  Receiver.getInfo (node_modules/ws/lib/receiver.js:168:14)\r\n  Receiver.startLoop (node_modules/ws/lib/receiver.js:121:22)\r\n  Receiver._write (node_modules/ws/lib/receiver.js:69:10)\r\n  Socket.socketOnData (node_modules/ws/lib/websocket.js:816:35)\r\n```\r\n\r\nAnd the subsequent stack produced is:\r\n\r\n```\r\nError [ERR_STREAM_WRITE_AFTER_END]: write after end\r\n      at writeAfterEnd (_stream_writable.js:243:12)\r\n      at Socket.Writable.write (_stream_writable.js:291:5)\r\n      at Sender.sendFrame (/node_modules/ws/lib/sender.js:404:20)\r\n      at Sender.doClose (/node_modules/ws/lib/sender.js:141:10)\r\n      at Sender.close (/node_modules/ws/lib/sender.js:128:12)\r\n      at WebSocket.close (/node_modules/ws/lib/websocket.js:215:18)\r\n      at Receiver.receiverOnConclude (/node_modules/ws/lib/websocket.js:695:32)\r\n      at Receiver.emit (events.js:182:13)\r\n      at Receiver.controlMessage (/node_modules/ws/lib/receiver.js:436:14)\r\n      at Receiver.getData (/node_modules/ws/lib/receiver.js:330:42)\r\n```\r\n\r\nBoth, when traced to the best of my ability, point back to the same problem as described in #17806.",
        "labels": "confirmed-bug",
        "id": 45204
    },
    {
        "title": "(experimental) worker isolation",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 11.3.0\r\n* **Platform**:win 7 (64)\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nI just wondering if this lack of isolation is expected:\r\n\r\n```\r\nnew Worker(`process.env.FOO = 123`, { eval: true });\r\nnew Worker(`console.log(process.env.FOO)`, { eval: true }); // prints 123\r\n```\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45205
    },
    {
        "title": "Misleading error message",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.4.0\r\n* **Platform**: macOS\r\n* **Subsystem**: assert\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n```\r\n$ cat t.js \r\nconst assert = require('assert');\r\n\r\nfunction StorageObject() {}\r\nStorageObject.prototype = Object.create(null);\r\n\r\nassert.deepStrictEqual(new StorageObject(), {});\r\n```\r\n\r\n```\r\n$ node t.js \r\nassert.js:86\r\n  throw new AssertionError(obj);\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: Values identical but not reference-equal:\r\n\r\n{}\r\n\r\n    at Object.<anonymous> (/Users/luigi/t.js:6:8)\r\n    at Module._compile (internal/modules/cjs/loader.js:723:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:734:10)\r\n    at Module.load (internal/modules/cjs/loader.js:620:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:560:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:552:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:776:12)\r\n    at executeUserCode (internal/bootstrap/node.js:342:17)\r\n    at startExecution (internal/bootstrap/node.js:276:5)\r\n    at startup (internal/bootstrap/node.js:227:5)\r\n```\r\n\r\nThe assertion fails because the objects have a different prototype. The same assertion produces a different message in other cases, for example:\r\n\r\n```\r\n$ cat t.js \r\nconst assert = require('assert');\r\n\r\nassert.deepStrictEqual(Object.create(null), {});\r\n```\r\n\r\n```\r\n$ node t.js \r\nassert.js:86\r\n  throw new AssertionError(obj);\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: Expected values to be strictly deep-equal:\r\n+ actual - expected\r\n\r\n+ [Object: null prototype] {}\r\n- {}\r\n    at Object.<anonymous> (/Users/luigi/t.js:3:8)\r\n    at Module._compile (internal/modules/cjs/loader.js:723:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:734:10)\r\n    at Module.load (internal/modules/cjs/loader.js:620:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:560:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:552:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:776:12)\r\n    at executeUserCode (internal/bootstrap/node.js:342:17)\r\n    at startExecution (internal/bootstrap/node.js:276:5)\r\n    at startup (internal/bootstrap/node.js:227:5)\r\n```\r\n\r\ncc: @BridgeAR ",
        "labels": "confirmed-bug",
        "id": 45206
    },
    {
        "title": "tls ca: option doesn't support the same formats as openssl -CAfile",
        "body": "\r\n* **Version**: all\r\n* **Platform**: all\r\n* **Subsystem**: tls\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nOpenSSL supports \"BEGIN TRUSTED CERTIFICATE\", whereas Node.js silently ignores  them. When people fail to authenticate with a `ca:` file, they often try with other tools (`openssl s_client -CAfile ...`, `curl -cacert ...`, ...) to confirm where the CAs are valid. They find they are, but that they don't work with Node.js. Ouch.\r\n\r\nFixed in https://github.com/nodejs/node/pull/24733",
        "labels": "confirmed-bug",
        "id": 45207
    },
    {
        "title": "Incorrect inspection of Set iterator for set.entries()",
        "body": "* **Version**: 10, 11, master\r\n* **Platform**: Linux\r\n* **Subsystem**: util\r\n\r\n```js\r\nvar set = new Set([1, 2])\r\nconsole.log(set.entries())\r\n```\r\n\r\nIn Node 6 and 8, it outputs:\r\n\r\n```\r\nSetIterator { [ 1, 1 ], [ 2, 2 ] }\r\n```\r\n\r\nIn Node 10, 11 and master:\r\n\r\n```\r\n[Set Iterator] { 1, 2 }\r\n```",
        "labels": "confirmed-bug",
        "id": 45208
    },
    {
        "title": "HTTP/1 request parsing framing error event",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.13.0\r\n* **Platform**: Windows 10\r\n* **Subsystem**: http\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nIt seems that in Node.js 10+, it's no longer possible to know with a framing error happened during the request transfer to a server. This is evident in request parsing, for example. A framing error could be when the incoming request is coming in `Tranfer-Encoding: chunked` and a chunk header is no valid hex.\r\n\r\nHere is an example app that shows the error handing in previous Node.js versions working:\r\n```js\r\nvar http = require('http')\r\nvar net = require('net')\r\n\r\nvar server = http.createServer(function (req, res) {\r\n  var bufs = []\r\n\r\n  req.on('data', function (chunk) {\r\n    console.log('request recv %d bytes', chunk.length)\r\n    bufs.push(chunk)\r\n  })\r\n\r\n  req.on('end', function () {\r\n    var data = Buffer.concat(bufs)\r\n    console.log('request got %d bytes', data.length)\r\n    res.end('OK')\r\n    server.close()\r\n  })\r\n\r\n  req.socket.on('error', function (e) {\r\n    console.log('request error %s', e.toString())\r\n    req.destroy()\r\n    server.close()\r\n  })\r\n})\r\n\r\nserver.listen(0, function () {\r\n  var port = server.address().port\r\n  var sock = net.createConnection(port, '127.0.0.1')\r\n\r\n  sock.on('connect', function () {\r\n    sock.write('POST / HTTP/1.1\\r\\n')\r\n    sock.write('Host: localhost\\r\\n')\r\n    sock.write('Transfer-Encoding: chunked\\r\\n')\r\n    sock.write('\\r\\n')\r\n    sock.write('3\\r\\n')\r\n    sock.write('foo\\r\\n')\r\n    sock.write('3\\r\\n')\r\n    sock.write('bar\\r\\n')\r\n    sock.write('ff\\r\\n')\r\n    sock.end()\r\n  })\r\n})\r\n\r\nsetTimeout(function () {\r\n  console.log('timeout!')\r\n  process.exit(1)\r\n}, 10000).unref()\r\n```\r\n\r\nIn Node.js 8 and below it prints the following:\r\n```\r\nrequest recv 3 bytes\r\nrequest recv 3 bytes\r\nrequest error Error: Parse Error\r\n```\r\n\r\nIn Node.js 10+ is prints the following:\r\n```\r\nrequest recv 3 bytes\r\nrequest recv 3 bytes\r\ntimeout!\r\n```\r\n\r\nThe `req.on('close', ...)` fires in both, but I'm just asking about how to know if it closed from a socket error within the normal request / response transaction processing now in Node.js 10+. The best I can see is just if the `'close'` was before `'end'`, then it could have been due to an error. But of course there is no guarantee that `'close'` is actually emitted only after `'end'`: the `close` event is emitted whenever the socket is closed, even if the entire request was received without error and was just pased (which is the state that `req` starts out in).",
        "labels": "confirmed-bug",
        "id": 45209
    },
    {
        "title": "macOS binaries: UV_FS_COPYFILE_FICLONE not supported",
        "body": "Node binaries from the [official pkg distribution](https://nodejs.org/dist/latest/node-v11.2.0.pkg) do not support copy-on-write (`UV_FS_COPYFILE_FICLONE`) on apfs-formatted volumes.\r\n\r\n* **Version**: v11.2.0\r\n* **Platform**: Darwin iMac.local 17.7.0 Darwin Kernel Version 17.7.0: Wed Oct 10 23:06:14 PDT 2018; root:xnu-4570.71.13~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: fs\r\n\r\n## Steps to reproduce\r\nGenerate a file (3MB here, size is not important) to clone later\r\n```sh\r\nmkdir ~/apfs-cow-test && cd ~/apfs-cow-test\r\nhead -c 3000000 </dev/urandom >origfile\r\nnode\r\n```\r\n\r\nIn the node REPL, run:\r\n\r\n```js\r\nconst fs = require('fs')\r\nfs.copyFile('origfile', 'newfile', fs.constants.UV_FS_COPYFILE_FICLONE_FORCE, err => { if (err) { console.log(err) }})\r\n```\r\n\r\nIn the official node binary, this error is raised:\r\n\r\n```\r\n> { [Error: ENOSYS: function not implemented, copyfile 'origfile' -> 'newfile']\r\n  errno: -78,\r\n  code: 'ENOSYS',\r\n  syscall: 'copyfile',\r\n  path: 'origfile',\r\n  dest: 'newfile' }\r\n```\r\n\r\nWith a binary that supports this feature, the file is cloned normally. You can verify that the clone call works as intended by cloning a large file and checking the volume size on Disk Utility. It doesn't create a hardlink. Changes to the clone don't affect the original file.\r\n\r\n## Implications\r\n\r\nThis bug also affects users of [nvm](https://github.com/creationix/nvm) and [n](https://github.com/tj/n) who install prebuilt binaries (the default behavior). brew users are not impacted as the prebuilt binary ([bottle](https://github.com/Homebrew/homebrew-core/blob/5c6a6e41460e0ab0c563509c884767ac45cde53b/Formula/node.rb)) is built with support for this flag.\r\n\r\n[Yarn is directly affected by this.](https://github.com/yarnpkg/yarn/pull/6302) `UV_FS_COPYFILE_FICLONE` falls back to normal copying, negating the performance and disk space benefits of cloning.",
        "labels": "confirmed-bug",
        "id": 45210
    },
    {
        "title": "HTTP2 writehead header format can't use array of arrays for headers",
        "body": "node 10.13\r\nCentOs\r\nHTTP2\r\n\r\nWith http, you can send headers like this:\r\n[\r\n  [\r\n    \"Content-Type\",\r\n    \"text/html; charset=utf-8\"\r\n  ],\r\n  [\r\n    \"last-modified\",\r\n    \"Sun, 18 Nov 2018 17:49:47 GMT\"\r\n  ]\r\n]\r\n\r\nTo send multiple values for the same header, like cookies. But with http2 the returned headers looks like this when this format is used:\r\nhttps://i.imgur.com/QXZnu4v.png",
        "labels": "confirmed-bug",
        "id": 45211
    },
    {
        "title": "timers wrong behavior",
        "body": "* **Version**: 11.1\r\n* **Platform**: Debian 7\r\n* **Subsystem**: timers\r\n\r\nI have found another strange behavior of timers after refactor in v11. Example:\r\n\r\n```\r\nsetTimeout(() => {\r\n  console.log('firing', 11000)\r\n}, 11000)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 90000)\r\n}, 90000)\r\n\r\nsetInterval(() => {\r\n  console.log('firing', 1000)\r\n}, 1000)\r\n\r\nconst timer4000 = setTimeout(() => {\r\n  console.log('firing', 4000)\r\n}, 4000)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 60000)\r\n}, 60000)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 100)\r\n\r\n  const timer1500 = setTimeout(() => {\r\n    console.log('firing', 1500)\r\n  }, 1500)\r\n  clearTimeout(timer1500)\r\n\r\n}, 100)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 3000)\r\n}, 3000)\r\n\r\nclearTimeout(timer4000)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 16000)\r\n}, 16000)\r\n```\r\n\r\nIt is a bit complicated, but when i am removing any part, it works as expected. An output:\r\n\r\n```\r\nfiring 100\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 11000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 16000\r\nfiring 1000\r\nfiring 1000\r\n...\r\n```\r\nSo, 3000ms timeout is never fired. There is a way to make that example to working a little different:\r\n\r\n```\r\nsetTimeout(() => {\r\n  console.log('firing', 11000)\r\n}, 11000)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 90000)\r\n}, 90000)\r\n\r\nsetInterval(() => {\r\n  console.log('firing', 1000)\r\n}, 1000)\r\n\r\nconst timer4000 = setTimeout(() => {\r\n  console.log('firing', 4000)\r\n}, 4000)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 60000)\r\n}, 60000)\r\n\r\nsetTimeout(async () => {\r\n  console.log('firing', 100)\r\n\r\n  const timer1500 = setTimeout(() => {\r\n    console.log('firing', 1500)\r\n  }, 1500)\r\n  await Promise.resolve()\r\n  clearTimeout(timer1500)\r\n\r\n}, 100)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 3000)\r\n}, 3000)\r\n\r\nclearTimeout(timer4000)\r\n\r\nsetTimeout(() => {\r\n  console.log('firing', 16000)\r\n}, 16000)\r\n```\r\n\r\nThen, output is:\r\n\r\n```\r\nfiring 100\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 11000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 1000\r\nfiring 16000\r\nfiring 3000\r\nfiring 1000\r\n```\r\n\r\nSo, 3000ms timer is unlocked, but only after 16000ms timer is fired. O_O\r\n\r\nI suppose, it is related to [that one](https://github.com/nodejs/node/issues/24320), but works a little different, so i am making another issue. I am a bit angry, because i spend a few days to extract specific issue form whole, async app. :/\r\n",
        "labels": "confirmed-bug",
        "id": 45212
    },
    {
        "title": "timers: timer starvation",
        "body": "* **Version**: 11.1.0 and master. 10.x is not impacted\r\n* **Platform**: macOS\r\n* **Subsystem**: timers\r\n\r\nThe following code should exit once the 110ms timer fires. Unfortunately, that never happens. Note, I tried including https://github.com/nodejs/node/pull/24318, and that did not fix the issue either.\r\n\r\n```js\r\n'use strict';\r\nlet client = null;\r\n\r\nfunction serverBeat() {\r\n  setTimeout(() => {}, 45);\r\n  setTimeout(serverBeat, 50);\r\n  clientBeat();\r\n}\r\n\r\nfunction clientBeat() {\r\n  clearTimeout(client);\r\n  client = setTimeout(clientBeat, 95);\r\n}\r\n\r\nsetTimeout(() => {}, 10000);\r\nsetTimeout(serverBeat, 50);\r\nsetTimeout(() => {}, 120000);\r\nclientBeat();\r\n\r\nsetTimeout(() => {\r\n  console.log('finished!');\r\n  process.exit();\r\n}, 110);\r\n```\r\n\r\nRefs: https://github.com/hapijs/nes/issues/257\r\ncc: @nodejs/timers ",
        "labels": "confirmed-bug",
        "id": 45213
    },
    {
        "title": "stream.resume() doesn't make the stream flowing after removing readable listener",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.13.0\r\n* **Platform**: Darwin planata.local 17.7.0 Darwin Kernel Version 17.7.0: Wed Oct 10 23:06:14 PDT 2018; root:xnu-4570.71.13~1/RELEASE_X86_64 x86_64 i386 MacBookPro14,2 Darwin\r\n* **Subsystem**: stream\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nWith v10.13.0, stream.resume() doesn't make the stream flowing after removing `readable` listener. Here is a code to demonstrate the problem.\r\n\r\n```js\r\n'use strict';\r\n\r\nconst fs = require('fs');\r\n\r\nconst s = fs.createReadStream('s.js');\r\n\r\nconst readableListener = () => console.log('readable');\r\ns.on('readable', readableListener);\r\ns.on('end', () => console.log('end'));\r\ns.removeListener('readable', readableListener);\r\ns.resume();\r\n```\r\n\r\nNote that you need to name this script `s.js` to run this script without any changes.\r\n\r\nWith v10.13.0, this prints nothing. With v8.12.0, this prints `end`. This seems to be related to #18994, #21696 and #22209, but I'm not sure if this is an intentional change.\r\n\r\nNote that a stream starts flowing when I add `data` listener instead of calling `resume`.",
        "labels": "confirmed-bug",
        "id": 45214
    },
    {
        "title": "setTimeout is not working properly with non-integer in Node 11",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.1.0\r\n* **Platform**:Darwin suguru 17.7.0 Darwin Kernel Version 17.7.0: Fri Jul  6 19:54:51 PDT 2018; root:xnu-4570.71.3~2/RELEASE_X86_64 x86_64\r\n* **Subsystem**: timers\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nI have tested `setTimeout` and realized the function seems to have an issue when it is called with non-integer, such as `1.1 * 100 (110.00000000000001)`.\r\nThe function will stop calling a callback function randomly and eat up high CPU usage.\r\nThe code is as below,\r\n\r\n```js\r\nconst time = 1.1 * 100;\r\nconsole.log(`time: ${time}`);\r\n\r\nfunction exec(i) {\r\n  console.log(i);\r\n  setTimeout(exec, time, ++i);\r\n}\r\nexec(0);\r\n```\r\n\r\n```sh\r\n// output\r\ntime: 110.00000000000001\r\n0\r\n1\r\n2\r\n3 // process hangs and eats up all CPU\r\n```\r\n\r\nI also tested it in Node v10, but it seems fine. ",
        "labels": "confirmed-bug",
        "id": 45215
    },
    {
        "title": "Running a single test using --expose-internals throws an error [nodeconf code and learn]",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: current\r\n* **Platform**: macOS\r\n* **Subsystem**: internal\r\n\r\nSteps followed:\r\n* built node by following the instructions [here](https://github.com/nodejs/node/blob/master/BUILDING.md#building-nodejs-1)\r\n* ran single test `test/parallel/test-internal-errors.js` by following the instructions [here](https://github.com/nodejs/node/blob/master/BUILDING.md#running-tests) and got the error shown below\r\n\r\n```\r\n$ ./node --expose-internals ./test/parallel/test-internal-errors.js\r\n/Users/lufo/w/nodeconfeu/codenlearn/node/test/common/index.js:585\r\n        throw new assert.AssertionError({\r\n        ^\r\n\r\nAssertionError [ERR_ASSERTION]: Expected \"actual\" to be reference-equal to \"expected\":\r\n+ actual - expected\r\n\r\n  Comparison {\r\n    code: 'ERR_ASSERTION',\r\n+   message: `Expected \"actual\" to be reference-equal to \"expected\":\\n\\u001b[32m+ actual\\u001b[39m \\u001b[31m- expected\\u001b[39m\\n\\n  Comparison {\\n    code: 'TEST_ERROR_1',\\n\\u001b[32m+\\u001b[39m   type: [Function: TypeError]\\n\\u001b[31m-\\u001b[39m   type: [Function: RangeError]\\n  }`\r\n-   message: /\\+   type: \\[Function: TypeError]\\n-   type: \\[Function: RangeError]/\r\n  }\r\n    at new AssertionError (internal/assert.js:394:11)\r\n    at Object.innerFn (/Users/lufo/w/nodeconfeu/codenlearn/node/test/common/index.js:585:15)\r\n    at expectedException (assert.js:568:19)\r\n    at expectsError (assert.js:663:16)\r\n    at Function.throws (assert.js:694:3)\r\n    at Object.expectsError (/Users/lufo/w/nodeconfeu/codenlearn/node/test/common/index.js:597:12)\r\n    at Object.<anonymous> (/Users/lufo/w/nodeconfeu/codenlearn/node/test/parallel/test-internal-errors.js:79:8)\r\n    at Module._compile (internal/modules/cjs/loader.js:722:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:733:10)\r\n    at Module.load (internal/modules/cjs/loader.js:620:32)\r\n```\r\n\r\nI don't get this error when tests are run with the following command:\r\n```\r\n$ python tools/test.py -J --mode=release parallel/test-internal-errors\r\n[00:00|% 100|+   1|-   0]: Done\r\n```",
        "labels": "confirmed-bug",
        "id": 45216
    },
    {
        "title": "socket.write() emits error synchronously when socket was closed by peer",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: all\r\n* **Platform**: all\r\n* **Subsystem**: net\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\n```js\r\nvar net = require('net')\r\n\r\nvar s = net.createServer().listen(0).on('listening', function() {\r\n  var port = this.address().port;\r\n  var c = net.connect(port).on('connect', function() {\r\n    setTimeout(function() {\r\n      var er;\r\n      c.on('error', function(e) {\r\n        er = e;\r\n        console.log('on er', e);\r\n      });\r\n      c.write('helo');\r\n      console.log('after write', er);\r\n    }, 5);\r\n  });\r\n});\r\n\r\ns.on('connection', function(c) {\r\n  c.end();\r\n});\r\n```\r\n\r\nEDIT: forgot output:\r\n```\r\ncore/node (master % u=) % ./node ../sync-error.js\r\non er { Error: This socket has been ended by the other party\r\n    at Socket.writeAfterFIN [as write] (net.js:407:12)\r\n    at Timeout._onTimeout (/home/sam/w/core/sync-error.js:12:9)\r\n    at listOnTimeout (timers.js:324:15)\r\n    at processTimers (timers.js:268:5) code: 'EPIPE' }\r\nafter write { Error: This socket has been ended by the other party\r\n    at Socket.writeAfterFIN [as write] (net.js:407:12)\r\n    at Timeout._onTimeout (/home/sam/w/core/sync-error.js:12:9)\r\n    at listOnTimeout (timers.js:324:15)\r\n    at processTimers (timers.js:268:5) code: 'EPIPE' }\r\n```\r\n\r\nI would expect error to be emitted in the next tick, as it normally would for a runtime error. This matters because normally code like this would work:\r\n\r\n```js\r\nsock,write(...)\r\nsock.on('error', ...)\r\n```\r\n\r\nbut in the case of a TCP close by the peer, the error event will never be caught in the above.\r\n\r\nI think the TODO in the source is referring to this:\r\n\r\nhttps://github.com/nodejs/node/blob/5c2d555b29d99f9d1f484fd46eff33b42ee9c11f/lib/net.js#L409\r\n\r\n@mcollina what do you think? Is how net sockets are working here how a write stream is expected to work?",
        "labels": "confirmed-bug",
        "id": 45217
    },
    {
        "title": "Intl.DateTimeFormat doesn't respect the passed culture",
        "body": "* **Version**: 10.13\r\n* **Platform**: Windows Server v1607\r\n* **Subsystem**: unknown\r\n\r\ndate = new Date('6/15/2017 1:03 PM');\r\nIntl.DateTimeFormat('fr-FR', {year:'numeric', month:'numeric', day:'numeric', hour:'numeric', minute:'numeric'}).format(date)\r\n\r\nexpected: \r\n\"2017-6-15 13:03\"\r\n\r\nactual:  (I am in the US with en-US culture settings for language and locale)\r\n\"6/15/2017, 1:03 PM\"\r\n\r\nThis worked fine in Node v8.10.0.\r\n",
        "labels": "confirmed-bug",
        "id": 45218
    },
    {
        "title": "Profiling using --prof inside worker_threads does not work",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 11.0.0\r\n* **Platform**: macos \r\n* **Subsystem**: worker_threads\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nGenerating flame graphs with worker_thread produces isolate files that do not contain useful information.\r\n\r\nUsing my example repo https://github.com/slonka/nodejs-prof-worker-threads-not-working i generated the following flame graphs for:\r\n\r\nSingle threaded version:\r\n![image](https://user-images.githubusercontent.com/2753650/47855440-e9d2fa00-dde4-11e8-9697-45177903394f.png)\r\n\r\nAnd worker threads version:\r\n![image](https://user-images.githubusercontent.com/2753650/47855452-f35c6200-dde4-11e8-8bf2-9ceb71d1eee5.png)\r\n\r\n![image](https://user-images.githubusercontent.com/2753650/47855462-f9524300-dde4-11e8-80bb-22c347f9af7d.png)\r\n\r\nWhat makes me think that this is a bug inside `node` and not `0x` is that isolate files and processed files (generated by running `node --prof-process`) contain pretty much the same info that is on the flame graphs. I used flame graphs because they are easier to read for me.",
        "labels": "confirmed-bug",
        "id": 45219
    },
    {
        "title": "HeapProfiler.takeHeapSnapshot will cause Node.js crash",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8.9.3 & v10.12.0 & v11.0.0\r\n* **Platform**: macOS Mojave Version 10.14.1 Beta (18B67a)\r\n* **Subsystem**: \r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nI'm trying use `inspector` module to get the head snapshot, but the Node.js will crash after post `HeapProfiler.takeHeapSnapshot` command to the inspector.\r\n\r\nIt crash randomly, but easily reproduce it.\r\n\r\n```js\r\nconst inspector = require('inspector');\r\n\r\nfunction post(session, action, params) {\r\n  return new Promise((resolve, reject) => {\r\n    session.post(action, params, (err, data) => {\r\n      if (err) {\r\n        return reject(err);\r\n      }\r\n      resolve(data);\r\n    });\r\n  });\r\n}\r\n\r\nasync function main() {\r\n  const session = new inspector.Session();\r\n  session.connect();\r\n  await post(session, 'HeapProfiler.enable');\r\n  await post(session, 'HeapProfiler.startSampling', {\r\n    samplingInterval: 32768\r\n  });\r\n\r\n  // Take the snapshot\r\n  const chunks = [];\r\n\r\n  session.on('HeapProfiler.addHeapSnapshotChunk', data => {\r\n    chunks.push(data.params.chunk);\r\n  });\r\n  await post(session, 'HeapProfiler.takeHeapSnapshot', {\r\n    reportProgress: false\r\n  });\r\n\r\n  const snapshot = chunks.join('');\r\n  console.log(snapshot);\r\n}\r\n\r\nmain();\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45220
    },
    {
        "title": "Memory leak when a Promise is stored on an Express request that's added to a domain",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.12.0\r\n* **Platform**: Darwin zero-gravitas-lan.jetpants.com 18.0.0 Darwin Kernel Version 18.0.0: Wed Aug 22 20:13:40 PDT 2018; root:xnu-4903.201.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: domain\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThe following code, which is a reduced test case using functionality that's relied upon by the popular [Sentry](https://www.npmjs.com/package/@sentry/node) error reporting module, works fine in Node 8.12.0 but consistently leaks memory on each request in Node 10.12.0, 11.0.0, and 9.11.2:\r\n\r\n```js\r\n'use strict';\r\n\r\nconst domain = require('domain');\r\nconst app = require('express')();\r\n\r\napp.use((req, res, next) => {\r\n  let requestDomain = domain.create();\r\n\r\n  requestDomain.add(req);\r\n  requestDomain.on('error', next);\r\n\r\n  requestDomain.run(() => {\r\n    next();\r\n  });\r\n});\r\n\r\napp.get('/', (req, res) => {\r\n  req.cachedPromise = new Promise(resolve => {\r\n    let tenMebibyteString = 'a'.repeat(10 * 1024 * 1024);\r\n    resolve(tenMebibyteString);\r\n  });\r\n\r\n  res.send('hi');\r\n});\r\n\r\napp.listen(5000);\r\n```\r\n\r\nI would expect the `req` object and its `req.cachedPromise` property to be GCed once the response is finished, since no references to it are being held. This is what happens in Node 8. But in Nodes 9, 10, and 11, `req.cachedPromise` never seems to be GCed, causing a steady memory leak.\r\n\r\nI first noticed this issue when I tried to upgrade a production service using Sentry to Node 10. It likely affects anyone who uses Sentry with Express and caches promises on the request object (or on any descendant of the request object).\r\n\r\nThe relevant code in Sentry is here: https://github.com/getsentry/sentry-javascript/blob/839326fbb498c669bd8b9c38bd93d39ca15b6266/packages/node/src/handlers.ts#L220-L229",
        "labels": "confirmed-bug",
        "id": 45221
    },
    {
        "title": "clearTimeout blocks the process (100% CPU usage)",
        "body": "The following code should output TEST every 10s:\r\n```js\r\n'use strict';\r\n\r\nconst timers = [];\r\n\r\nfunction test()\r\n{\r\n  console.log(new Date().toISOString(), 'TEST');\r\n\r\n  for (let i = 0; i < 1000; ++i)\r\n  {\r\n    timers.push(setTimeout(clearTimeouts, Math.round(Math.random() * 9000)));\r\n  }\r\n\r\n  setTimeout(test, 10000);\r\n}\r\n\r\nfunction clearTimeouts()\r\n{\r\n  for (let i = 0; i < timers.length; ++i)\r\n  {\r\n    if (timers[i] && Math.random() > 0.8)\r\n    {\r\n      clearTimeout(timers[i]);\r\n      timers[i] = null;\r\n    }\r\n  }\r\n}\r\n\r\ntest();\r\n```\r\n\r\nVersion 11.0.0 hangs with 100% CPU usage (memory stays the same). v8.12.0 and v10.9.0 works. `test.js` was run for 60s in v8, v10 and v11:\r\n\r\n```\r\nÎ» node8 --version\r\nv8.12.0\r\nÎ» node8 test.js\r\n2018-10-24T21:59:34.334Z TEST\r\n2018-10-24T21:59:44.339Z TEST\r\n2018-10-24T21:59:54.356Z TEST\r\n2018-10-24T22:00:04.366Z TEST\r\n2018-10-24T22:00:14.387Z TEST\r\n2018-10-24T22:00:24.403Z TEST\r\n^C\r\n\r\nÎ» node10 --version\r\nv10.9.0\r\nÎ» node10 test.js\r\n2018-10-24T22:01:49.382Z TEST\r\n2018-10-24T22:01:59.388Z TEST\r\n2018-10-24T22:02:09.403Z TEST\r\n2018-10-24T22:02:19.419Z TEST\r\n2018-10-24T22:02:29.433Z TEST\r\n2018-10-24T22:02:39.442Z TEST\r\n^C\r\n\r\nÎ» node --version\r\nv11.0.0\r\nÎ» node test.js\r\n2018-10-24T22:03:45.987Z TEST\r\n^C\r\n```\r\n\r\nEDIT 1:\r\nThe following code hangs node v11 if `N > 6` (sometimes TEST is printed twice):\r\n```js\r\n'use strict';\r\n\r\nconst N = 10;\r\n\r\nfunction noop() {}\r\n\r\nfunction test()\r\n{\r\n  console.log(new Date().toISOString(), 'TEST');\r\n\r\n  const timers = [];\r\n\r\n  for (let i = 1; i <= N; ++i)\r\n  {\r\n    timers.push(setTimeout(noop, i * 1000));\r\n  }\r\n\r\n  setTimeout(() => timers.forEach(t => clearTimeout(t)), 5000);\r\n\r\n  setTimeout(test, 10000);\r\n}\r\n\r\ntest();\r\n```\r\n\r\nEDIT 2:\r\nJust found out about `NODE_DEBUG=timer`:\r\n```\r\nÎ» node test.js\r\n2018-10-24T22:39:02.837Z TEST\r\nTIMER 13840: no 1000 list was found in insert, creating a new one\r\nTIMER 13840: no 2000 list was found in insert, creating a new one\r\nTIMER 13840: no 3000 list was found in insert, creating a new one\r\nTIMER 13840: no 4000 list was found in insert, creating a new one\r\nTIMER 13840: no 5000 list was found in insert, creating a new one\r\nTIMER 13840: no 6000 list was found in insert, creating a new one\r\nTIMER 13840: no 7000 list was found in insert, creating a new one\r\nTIMER 13840: no 8000 list was found in insert, creating a new one\r\nTIMER 13840: no 9000 list was found in insert, creating a new one\r\nTIMER 13840: no 10000 list was found in insert, creating a new one\r\nTIMER 13840: process timer lists 1055\r\nTIMER 13840: timeout callback 1000\r\nTIMER 13840: 1000 list empty\r\nTIMER 13840: process timer lists 2060\r\nTIMER 13840: timeout callback 2000\r\nTIMER 13840: 2000 list empty\r\nTIMER 13840: process timer lists 3059\r\nTIMER 13840: timeout callback 3000\r\nTIMER 13840: 3000 list empty\r\nTIMER 13840: process timer lists 4058\r\nTIMER 13840: timeout callback 4000\r\nTIMER 13840: 4000 list empty\r\nTIMER 13840: process timer lists 5059\r\nTIMER 13840: timeout callback 5000\r\nTIMER 13840: unenroll: list empty\r\nTIMER 13840: unenroll: list empty\r\nTIMER 13840: unenroll: list empty\r\nTIMER 13840: unenroll: list empty\r\nTIMER 13840: 5000 list empty\r\nTIMER 13840: process timer lists 10060\r\nTIMER 13840: timeout callback 10000\r\n2018-10-24T22:39:12.846Z TEST\r\nTIMER 13840: no 1000 list was found in insert, creating a new one\r\nTIMER 13840: no 2000 list was found in insert, creating a new one\r\nTIMER 13840: no 3000 list was found in insert, creating a new one\r\nTIMER 13840: no 4000 list was found in insert, creating a new one\r\nTIMER 13840: no 5000 list was found in insert, creating a new one\r\nTIMER 13840: no 6000 list was found in insert, creating a new one\r\nTIMER 13840: no 7000 list was found in insert, creating a new one\r\nTIMER 13840: no 8000 list was found in insert, creating a new one\r\nTIMER 13840: no 9000 list was found in insert, creating a new one\r\nTIMER 13840: 10000 list wait because diff is -3\r\nTIMER 13840: process timer lists 11063\r\nTIMER 13840: timeout callback 1000\r\nTIMER 13840: 1000 list empty\r\nTIMER 13840: process timer lists 12065\r\nTIMER 13840: timeout callback 2000\r\nTIMER 13840: 2000 list empty\r\nTIMER 13840: process timer lists 13064\r\nTIMER 13840: timeout callback 3000\r\nTIMER 13840: 3000 list empty\r\nTIMER 13840: process timer lists 14064\r\nTIMER 13840: timeout callback 4000\r\nTIMER 13840: 4000 list empty\r\nTIMER 13840: process timer lists 15064\r\nTIMER 13840: timeout callback 5000\r\nTIMER 13840: unenroll: list empty\r\nTIMER 13840: unenroll: list empty\r\nTIMER 13840: unenroll: list empty\r\nTIMER 13840: unenroll: list empty\r\nTIMER 13840: 5000 list empty\r\nTIMER 13840: process timer lists 18065\r\nTIMER 13840: timeout callback 8000\r\nTIMER 13840: 8000 list empty\r\nTIMER 13840: timeout callback 8000\r\nTIMER 13840: 8000 list empty\r\nTIMER 13840: timeout callback 8000\r\nTIMER 13840: 8000 list empty\r\nTIMER 13840: timeout callback 8000\r\nTIMER 13840: 8000 list empty\r\nTIMER 13840: timeout callback 8000\r\nTIMER 13840: 8000 list empty\r\nTIMER 13840: timeout callback 8000\r\nTIMER 13840: 8000 list empty\r\n...\r\nTIMER 13840: 8000 list empty\r\nTIMER 13840: timeout callback 8000\r\n...\r\n```",
        "labels": "confirmed-bug",
        "id": 45222
    },
    {
        "title": "Stream destruction breaks async-iteration and ends nodejs event loop",
        "body": "* **Version**: v10.12.0\r\n* **Platform**: Windows 10 64-bits\r\n* **Subsystem**: streams\r\n\r\nAsync iteration over a readable stream breaks horribly if for any reason the stream is destroyed while the iteration is still running (or even if it is destroyed before starting the iteration). I would expect that the iteration runs normally or throws an exception. What happens instead is that the whole event loop is shut down.\r\n\r\nMost notably this makes async iteration useless with `pipeline`.\r\n\r\nTest code:\r\n```js\r\nconst {createReadStream} = require('fs');\r\nconst {pipeline} = require('stream');\r\nconst {createDeflate} = require('zlib');\r\n\r\nasync function iterate(name, stream, destroy = false) {\r\n    try {\r\n        console.log(`${name}: Starting loop`);\r\n        for await (const chunk of stream) {\r\n            console.log(`${name}: Got a chunk`);\r\n            if (destroy) {\r\n                console.log(`${name}: destroying stream`);\r\n                stream.destroy();\r\n            }\r\n        }\r\n        console.log(`${name}: loop ended`);\r\n    } catch (err) {\r\n        console.log(`${name}: loop ended with error: ${err}`);\r\n    }\r\n}\r\n\r\nasync function main() {\r\n    // These work fine\r\n    await iterate('oneStream', createReadStream('test.js'));\r\n    await iterate('oneStreamError', createReadStream('doesnotexist'));\r\n\r\n    // Any of these just shuts down the node event loop...\r\n    await iterate('oneStreamDestroy', createReadStream('test.js'), true);\r\n    await iterate('pipeline', pipeline(createReadStream('doesnotexist'), createDeflate(), err => console.log(`pipeline ended: ${err}`)));\r\n    const stream = createReadStream('test.js');\r\n    stream.destroy();\r\n    await iterate('destroyedStream', stream);\r\n}\r\n\r\nmain().catch(console.error);\r\n```\r\n\r\nOutput:\r\n```\r\n> node test.js\r\noneStream: Starting loop\r\n(node:21664) ExperimentalWarning: Readable[Symbol.asyncIterator] is an experimental feature. This feature could change at any time\r\noneStream: Got a chunk\r\noneStream: loop ended\r\noneStreamError: Starting loop\r\noneStreamError: loop ended with error: Error: ENOENT: no such file or directory, open 'C:\\Users\\mfischer\\src\\tests\\node-stream-async-iteration\\doesnotexist'\r\noneStreamDestroy: Starting loop\r\noneStreamDestroy: Got a chunk\r\noneStreamDestroy: destroying stream\r\n```",
        "labels": "confirmed-bug",
        "id": 45223
    },
    {
        "title": "url: Cannot load ESM module with newline in file name",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 10.12.0\r\n* **Platform**: Linux 64 bit\r\n* **Subsystem**: Modules\r\n\r\n<!-- Please provide more details below this comment. -->\r\nNode fails to load ESM entry points if their filename contains a newline character. This is a regression compared to the current commonjs modules.\r\n\r\nThe following code fails:\r\n```\r\nfs.writeFileSync(\"foo\\nbar.mjs\", \"console.log('Hello, World!');\\n\");\r\nconst spawnRes = cp.spawnSync(process.execPath, [\"--experimental-modules\", \"foo\\nbar.mjs\"]);\r\nassert(spawnRes.status === 0);\r\nconsole.error(spawnRew.stderr.toString(\"UTF-8\"));\r\n```\r\n\r\nExpected: no failed assertion, nothing in stderr (appart from the warning that ESM is experimental).\r\nActual: Failed assertion. Stderr contains:\r\n```\r\nError: Cannot find module /tmp/tmp-59206v9LQ3sEjvCA/foobar.mjs\r\n    at search (internal/modules/esm/default_resolve.js:28:12)\r\n    at Loader.resolve [as _resolve] (internal/modules/esm/default_resolve.js:64:11)\r\n    at Loader.resolve (internal/modules/esm/loader.js:58:33)\r\n    at Loader.getModuleJob (internal/modules/esm/loader.js:113:40)\r\n    at Loader.import (internal/modules/esm/loader.js:99:28)\r\n    at asyncESM.loaderPromise.then (internal/modules/cjs/loader.js:734:27)\r\n    at process._tickCallback (internal/process/next_tick.js:68:7)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:745:11)\r\n    at startup (internal/bootstrap/node.js:279:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:752:3) code: 'MODULE_NOT_FOUND'\r\n```\r\nNote that the error message does not even contain the newline in the file name.\r\n\r\nFor comparison, the following code using commonJS works fine: \r\n\r\n```\r\nfs.writeFileSync(\"foo\\nbar.js\", \"console.log('Hello, World!');\\n\");\r\nconst spawnRes = cp.spawnSync(process.execPath, [\"foo\\nbar.js\"]);\r\nassert(spawnRes.status === 0);\r\nconsole.error(spawnRew.stderr.toString(\"UTF-8\"));\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45224
    },
    {
        "title": "Breakpoints not working inside Chrome devtools since `v10.12.0` ",
        "body": "* **Version**: `v10.12.0`\r\n* **Platform**: `Linux my-laptop 4.15.0-36-generic #39-Ubuntu SMP Mon Sep 24 16:19:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Chrome version**: `69.0.3497.100` (V8 `6.9.427.23`)\r\n\r\nThis might be related to #23688 but I believe this might contain more detailed information.\r\n\r\nBreakpoints set inside Chrome devtools do not stop code execution anymore since `v10.12.0`. It works with `v10.11.0` though. `debugger` statements work (only breakpoints set in the Chrome devtools UI do not work).\r\n\r\nExample file `index.js`:\r\n```js\r\nconsole.log('start');\r\ndebugger;\r\nconsole.log('breakpoint');\r\n```\r\n\r\nSteps to reproduce:\r\n  - Inside Chrome, go to `chrome://inspect/#devices` then click on `Open dedicated DevTools for Node`\r\n  - Using Node `v10.11.0`:\r\n     - Run `node --inspect-brk index.js`. The code stops at the first line.\r\n     - Add a breakpoint to `console.log()` line by clicking on the left margin\r\n     - Click on `Resume script execution` (F8): the code stops at `debugger` statement.\r\n     - Click on `Resume script execution` (F8): the code stops at `console.log()` statement.\r\n     - Click on `Resume script execution` (F8): the code execution ends.\r\n  - Using Node `v10.12.0`:\r\n     - Run `node --inspect-brk index.js`. The code stops at the first line.\r\n     - Add a breakpoint to `console.log()` line by clicking on the left margin\r\n     - Click on `Resume script execution` (F8): the code stops at `debugger` statement.\r\n     - Click on `Resume script execution` (F8): the code does not stop at `console.log()` statement. Instead the code execution ends.\r\n\r\nScreencast:\r\n\r\n![screencast](https://user-images.githubusercontent.com/8136211/47030826-d2eaa180-d16e-11e8-83bb-349ff899fd03.gif)\r\n",
        "labels": "confirmed-bug",
        "id": 45225
    },
    {
        "title": "src\\node_buffer.cc:173: Assertion `arg->IsNumber()' failed.",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v11.0.0-nightly20181007061e09891c\r\n* **Platform**: \r\n![image](https://user-images.githubusercontent.com/3070987/46949745-6bc0e480-d0bd-11e8-9de0-053ffc26e8c9.png)\r\n\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n![image](https://user-images.githubusercontent.com/3070987/46949866-d07c3f00-d0bd-11e8-9115-a0b82a4255ba.png)\r\n```PS D:\\Data\\github\\nosuelazer2> node server\r\nLazerBancho server listening on port 443\r\nLazerBancho NonSecure server listening on port 80\r\nDNS service has started\r\nConnected to MySQL, BeatmapHelper will work now\r\nvortex.data.microsoft.com\r\nops.dgsrz.com\r\nsending49.165.223.140\r\nWindows PowerShell[23292]: src\\node_buffer.cc:173: Assertion `arg->IsNumber()' failed.\r\n 1: 00007FF78D76B1C5\r\n 2: 00007FF78D7443C6\r\n 3: 00007FF78D744491\r\n 4: 00007FF78D72DEE1\r\n 5: 00007FF78D72F069\r\n 6: 00007FF78DB6945E\r\n 7: 00007FF78DB6A980\r\n 8: 00007FF78DB69959\r\n 9: 00007FF78DB6983B\r\n10: 000000B88F550861\r\nPS D:\\Data\\github\\nosuelazer2> node -v\r\nv11.0.0-nightly20181007061e09891c\r\nPS D:\\Data\\github\\nosuelazer2> winver\r\nPS D:\\Data\\github\\nosuelazer2>\r\n```\r\n\r\n\r\nI tried to use updns npm module, but this error happens.\r\nBut It isn't module bugs, because It works correctly on Node v8.\r\nAlso It's native error, so I don't have any idea other than bugs.\r\nIf It isn't bug, tell me how to fix it. Thanks!\r\n",
        "labels": "confirmed-bug",
        "id": 45226
    },
    {
        "title": "Segmentation fault building 10.12.0",
        "body": "\r\n\r\n* **Version**: 10.12.0\r\n* **Platform**: \r\nUbuntu 17.10\r\nLinux version 4.13.0-46-generic (buildd@lcy01-amd64-002) (gcc version 7.2.0 (Ubuntu 7.2.0-8ubuntu3.2)) #51-Ubuntu SMP Tue Jun 12 12:36:29 UTC 2018\r\n* **Subsystem**:\r\nGNU Make 4.1\r\ngcc (Ubuntu 7.2.0-8ubuntu3.2) 7.2.0\r\nPython 2.7.14\r\n<!-- Please provide more details below this comment. -->\r\n```\r\nwget -qO- https://github.com/nodejs/node/archive/v10.12.0.tar.gz | tar -xz\r\ncd node-10.12.0/\r\n./configure --prefix=/opt/nodejs --download=all --fully-static\r\nmake -j8\r\n```\r\n\r\nwhich fails with:\r\n ```\r\n g++ -o /tmp/node-10.12.0/out/Release/genccode -pthread -rdynamic -m64  -Wl,--start-group /tmp/node-10.12.0/out/Release/obj.host/genccode/deps/icu-small/source/tools/genccode/genccode.o /tmp/node-10.12.0/out/Release/obj.host/genccode/tools/icu/no-op.o /tmp/node-10.12.0/out/Release/obj.host/tools/icu/libicutools.a -static -Wl,--end-group\r\nSegmentation fault (core dumped)\r\ndeps/v8/gypfiles/v8_torque.host.mk:16: recipe for target 'cbaa0277bb5f5796abc8de7022f625e0be4aa200.intermediate' failed\r\nmake[1]: *** [cbaa0277bb5f5796abc8de7022f625e0be4aa200.intermediate] Error 139\r\nmake[1]: *** Waiting for unfinished jobs....\r\nrm bfa79deccc09f1b7eb1e1c81a4d3b823493cc2f6.intermediate cbaa0277bb5f5796abc8de7022f625e0be4aa200.intermediate\r\nMakefile:99: recipe for target 'node' failed\r\nmake: *** [node] Error 2\r\n```",
        "labels": "confirmed-bug",
        "id": 45227
    },
    {
        "title": "Console.log bug?",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.6.0\r\n* **Platform**: Mac OS 10.13.6\r\n* **Subsystem**: console\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nSuppose we used console.log as follows:\r\n\r\n```\r\nconsole.log('I\\'m trying to escape', false);\r\nconsole.log(false, 'I\\'m trying to escape');\r\n```\r\nThis will then output the following:\r\n\r\n```\r\nI'm trying to escape false\r\nfalse 'I\\'m trying to escape'\r\n```\r\n\r\nAs can be seen the backslash is treated differently between lines.\r\n\r\nAlso in the actual shell, the colouring is not present in the first line, but is present in the second line.\r\n(boolean is yellow and string is green)\r\n\r\nIs this by design or a bug?\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45228
    },
    {
        "title": "`'open'` can be emitted after `'close'`",
        "body": "`'open'` can be emitted after `'close'` for file streams which can cause some unexpected behaviours.\r\n\r\nEDIT: Updated to after `'close'` instead of after `destroy()`.",
        "labels": "confirmed-bug",
        "id": 45229
    },
    {
        "title": "Memory Leak in V8 CpuProfiler",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 8.12.0, 10.11.0, Master\r\n* **Platform**: Windows, Linux\r\n* **Subsystem**: V8\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nIt seems there is a memory leak in V8 CPU Profiler. If have seen that RSS steadily increases but V8 heap stays constant. I did a fast heap profiling with MSVC and got following stack frames which seem to point to the leak:\r\n```\r\nv8::internal::Runtime_StackGuard\r\nv8::internal::StackGuard::HandleInterrupts\r\nv8::internal::OptimizingCompileDispatcher::InstallOptimizedFunctions\r\nv8::internal::Compiler::FinalizeCompilationJob\r\nv8::internal::`anonymous namespace'::FinalizeOptimizedCompilationJob\r\nv8::internal::`anonymous namespace'::RecordFunctionCompilation\r\nv8::internal::CodeEventDispatcher::CodeCreateEvent\r\n\tv8::internal::ProfilerListener::RecordDeoptInlinedFrames\r\n\tv8::internal::ProfilerListener::RecordInliningInfo\r\n\tv8::internal::JITLineInfoTable::SetPosition\r\n\tv8::internal::ProfilerListener::NewCodeEntry\r\n```\r\nStopping profiling doesn't release the memory.\r\nI did also a fast test with NodeJS 10.11.0 and it seems the issue is not present there.\r\n\r\nI will continue my investigations but any hint which fix in V8 would be needed to be backported to get this fixed is welcome.\r\n",
        "labels": "confirmed-bug",
        "id": 45230
    },
    {
        "title": "fs.createReadStream(...)[Symbol.asyncIterator]() is not async iterable",
        "body": "* **Version**: v10.10.0\r\n* **Platform**: n/a\r\n* **Subsystem**: ?\r\n\r\n```js\r\nconst fs = require('fs')\r\n\r\nasync function main () {\r\n  const iterator = fs.createReadStream(__filename)[Symbol.asyncIterator]()\r\n  for await (const chunk of iterator) {\r\n    console.log('got a chunk', chunk.toString())\r\n  }\r\n}\r\n\r\nmain()\r\n```\r\n\r\nI get the error:\r\n\r\n```\r\n(node:13875) UnhandledPromiseRejectionWarning: TypeError: iterator is not async iterable\r\n```\r\n\r\nThis isn't exactly a bug, but I think the iterator returned by `fs.createReadStream(__filename)[Symbol.asyncIterator]()` doesn't implement the iterable protocol which is why this is happening.\r\n\r\n> It is not possible to know reflectively whether a particular object implements the iterator protocol, however it is easy to create an object that satisfies both the iterator and iterable protocols (as shown in the example below). Doing so allows an iterator to be consumed by the various syntaxes expecting iterables. Thus it is rarely desireable to implement the iterator protocol without also implementing iterable. \r\n> https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#The_iterator_protocol\r\n\r\nThis might be useful if you wanted to consume the first X chunks of a stream using `await iterator.next()` and then conditionally consume the rest with `for await of`.\r\n",
        "labels": "confirmed-bug",
        "id": 45231
    },
    {
        "title": "HTTP2 Push Stream always results in aborted event being fired",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v10.9.0\r\n* **Platform**: Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST 2017; root:xnu-4570.41.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: HTTP2\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nCode sample:\r\n\r\n```js\r\nconst http2 = require('http2')\r\nconst server = http2.createServer()\r\nserver.on('stream', (stream, headers) => {\r\n  stream.pushStream({ ':path': '/test' }, (err, pushStream) => {\r\n    if (err) throw err\r\n    pushStream.end('pushed some data')\r\n  })\r\n  stream.end('some data')\r\n})\r\nserver.listen(8080, () => {\r\n  let client = http2.connect('http://localhost:8080')\r\n  let req = client.request({ ':path': '/' })\r\n  req.on('data', (data) => {\r\n    console.log(data.toString('utf8'))\r\n  })\r\n  client.on('stream', (pushedStream) => {\r\n    console.log('on stream')\r\n    pushedStream.on('aborted', () => {\r\n      console.log('aborted')\r\n    })\r\n    pushedStream.on('end', () => {\r\n      console.log('end')\r\n    })\r\n    pushedStream.on('data', (data) => {\r\n      console.log(data.toString('utf8'))\r\n    })\r\n  })\r\n})\r\n```\r\n\r\nOutput:\r\n```\r\non stream\r\nsome data\r\npushed some data\r\nend\r\naborted\r\n```\r\n\r\nExpectation:\r\n\r\naborted event is not fired",
        "labels": "confirmed-bug",
        "id": 45232
    },
    {
        "title": "Error: PEM_read_bio_PUBKEY after upgrade to Node 10.10",
        "body": "* **Version**: v10.10.0\r\n* **Platform**: Linux 4.9.0-8-amd64 #1 SMP Debian 4.9.110-3+deb9u4 (2018-08-21) x86_64 GNU/Linux (actually, both Ubuntu and Debian, I have bunch of servers running the service)\r\n* **Subsystem**: Crypto (I guess)\r\n\r\nMy code is like\r\n``` JavaScript\r\nconst FS = require('fs');\r\nconst JWT = require('jsonwebtoken');\r\nconst certPem = FS.readFileSync('./public.pem');\r\nconst token = 'xxxx';\r\nJWT.verify(token, certPem, {}, (error, payload) => { ... });\r\n```\r\nand runs without problem with Node 8 and Node 10.8/10.9 (Ubuntu and Debian, NodeJS offical APT source)\r\n\r\nAfter I upgrade to Node 10.10 yesterday, on `JWT.verify` throws\r\n```\r\nError: PEM_read_bio_PUBKEY failed\r\n    at Verify.verify (internal/crypto/sig.js:122:23)\r\n    at Object.verify (/my/project/path/node_modules/jwa/index.js:89:21)\r\n    at Object.jwsVerify [as verify] (/my/project/path/node_modules/jws/lib/verify-stream.js:54:15)\r\n    at /my/project/path/node_modules/jsonwebtoken/verify.js:116:19\r\n    at getSecret (/my/project/path/node_modules/jsonwebtoken/verify.js:76:14)\r\n    at Object.module.exports [as verify] (/my/project/path/node_modules/jsonwebtoken/verify.js:80:10)\r\n```",
        "labels": "confirmed-bug",
        "id": 45233
    },
    {
        "title": "Potentially critical bug: Unexpected, reproducible calculation error",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: 8.x\r\n* **Platform**: docker ( official node as well as mhart/alpine-node)\r\n* **Subsystem**: core\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nThe following minimal sample code results in reproducible, unexpected behavior:\r\n\r\n```\r\nconst one = 150\r\nconst two = 2\r\nlet counter = 0\r\n\r\nsetInterval(() => {\r\n  const res = Math.max(5, Math.floor(one / two))\r\n  if (res > 100) {\r\n    console.log(counter, res)\r\n  } else {\r\n    counter++\r\n  }\r\n}, 1)\r\n```\r\n\r\n*Expected behavior*\r\nThis code should never output anything, because the calculation result is always 75\r\n\r\n*Actual behavior*\r\nAfter a while, the code starts to output the value of the variable `one`. This happens reliably once at counter value 5.398 and at each iteration starting from 10.794. The behavior is identical (even more or less the counter values) when changing the values of the variables or making the timer slower. The actual bug seems to happen within the `Math.max`, the result of `Math.floor` looks good.\r\n\r\n*Side notes*\r\n- reliably happens when using `node:8`, `node:8.9`, `node:8.11`, `mhart/alpine-node:8.9` (and more) docker images, both on Mac and Linux host systems\r\n- doesn't happen when changing the `setInterval` to a `while loop`\r\n- doesn't happen when using `node:6` or `node:10` docker images\r\n- bug first occured within a big software project and was easily reproducible in this minimal sample\r\n- the counter isn't needed for showing the bug, it's just to demonstrate how deterministic the problem seems to be\r\n- even when splitting the calculation into \r\n\r\n```\r\nconst floored = Math.floor(one / two)\r\nconst res = Math.max(5, floored)\r\n```\r\n\r\n`res` will carry the value of `one` after around 10.000 iterations\r\n\r\nI don't get what happens under the hood, but I assume this is critical.",
        "labels": "confirmed-bug",
        "id": 45234
    },
    {
        "title": "Large strings decoded from latin1 and then encoded to utf8 has wrong size",
        "body": "<!--\r\nThank you for reporting a possible bug in Node.js.\r\n\r\nPlease fill in as much of the template below as you can.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify the affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you can.\r\n-->\r\n\r\n* **Version**: v8.11.4\r\n* **Platform**: Linux xyz 4.17.5-200.fc28.x86_64 #1 SMP Tue Jul 10 13:39:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n<!-- Please provide more details below this comment. -->\r\n\r\nDecoding a latin1 buffer larger than about 1MB to a string and encoding that string into utf-8 gives a buffer with the same number of bytes as the latin1 input even though more are required for characters that use more space in utf-8.\r\n\r\nThis seems to work properly on v10.x but not v8.x or v9.x.\r\n\r\nCode that demonstrates the problem:\r\n```js\r\nconst fs = require('fs');\r\nconst s = 'RÃ¤ksmÃ¶rgÃ¥s';\r\nlet ss = '';\r\n\r\nconst SIZE = (1024 * 1024);\r\n// works:\r\n//const SIZE = (1024 * 512);\r\n\r\nwhile (ss.length < SIZE) {\r\n    ss = ss + ss.length + ' ' + s + '\\n';\r\n}\r\n\r\n// create latin1 buffer we can decode\r\nlet l1Buffer = Buffer.from(ss, 'latin1');\r\nlet l1String = l1Buffer.toString('latin1')\r\n// also fixes it:\r\n// l1String = ('x' + l1String).substring(1, l1String.length + 1);\r\n// create utf8 buffer from decoded latin1 string\r\nlet u8Buffer = Buffer.from(l1String, 'utf8')\r\n\r\nconsole.log(l1Buffer.length);\r\nconsole.log(u8Buffer.length);\r\n\r\nif (l1Buffer.length === u8Buffer.length) {\r\n    console.log('failed, should be different size');\r\n} else {\r\n    console.log('works');\r\n}\r\n```",
        "labels": "confirmed-bug",
        "id": 45235
    },
    {
        "title": "Abort during Object.keys after vm.runInContext",
        "body": "This occurs in both master and v10.x-staging but didn't repro in 10.9.0\r\n\r\n```\r\n./node -e 'let test = { not: \"empty\" }; vm.createContext(test); Object.keys(vm.runInContext(\"this\", test))'\r\n\r\n\r\n#\r\n# Fatal error in , line 0\r\n# Check failed: element->ToUint32(&number).\r\n#\r\n#\r\n#\r\n#FailureMessage Object: 0x7ffdaccc1b20Illegal instruction\r\n```\r\n\r\nHere's the llnode backtrace:\r\n\r\n```\r\n * thread #1: tid = 15265, 0x00007fffef24ce49 node`v8::base::OS::Abort() + 9, name = 'node', stop reason = signal SIGILL: illegal instruction operand\r\n  * frame #0: 0x00007fffef24ce49 node`v8::base::OS::Abort() + 9\r\n    frame #1: 0x00007fffef24901a node`V8_Fatal(char const*, int, char const*, ...) + 362\r\n    frame #2: 0x00007fffeeb45ce3 node`v8::internal::(anonymous namespace)::CollectInterceptorKeysInternal(v8::internal::Handle<v8::internal::JSReceiver>, v8::internal::Handle<v8::internal::JSObject>, v8::internal::Handle<v8::internal::InterceptorInfo>, v8::internal::KeyAccumulator*, v8::internal::(anonymous namespace)::IndexedOrNamed) + 1507\r\n    frame #3: 0x00007fffeeb475f1 node`v8::internal::KeyAccumulator::CollectOwnElementIndices(v8::internal::Handle<v8::internal::JSReceiver>, v8::internal::Handle<v8::internal::JSObject>) + 305\r\n    frame #4: 0x00007fffeeb489b2 node`v8::internal::KeyAccumulator::CollectOwnKeys(v8::internal::Handle<v8::internal::JSReceiver>, v8::internal::Handle<v8::internal::JSObject>) + 274\r\n    frame #5: 0x00007fffeeb496b5 node`v8::internal::KeyAccumulator::CollectKeys(v8::internal::Handle<v8::internal::JSReceiver>, v8::internal::Handle<v8::internal::JSReceiver>) + 69\r\n    frame #6: 0x00007fffeeb499e6 node`v8::internal::KeyAccumulator::GetKeys(v8::internal::Handle<v8::internal::JSReceiver>, v8::internal::KeyCollectionMode, v8::internal::PropertyFilter, v8::internal::GetKeysConversion, bool, bool) + 166\r\n    frame #7: 0x00007fffeed14d1f node`v8::internal::Runtime_ObjectKeys(int, v8::internal::Object**, v8::internal::Isolate*) + 143\r\n    frame #8: 0x000006d8132dc01d <exit>\r\n    frame #9: 0x000006d81331f255 keys(this=0x00002de71e2045d1:<function: Object at (no script)>, 0x00002a3391b027d9:<Global proxy>) at (no script) fn=0x00002de71e205139\r\n    frame #10: 0x000006d8132918b5 (anonymous)(this=0x00000be72f61a8f1:<Global proxy>) at repl:1:0 fn=0x0000047a28af6aa1\r\n    frame #11: 0x000006d81328ee55 <internal>\r\n    frame #12: 0x000006d813289521 <entry>\r\n    frame #13: 0x00007fffeea0e540 node`v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) + 272\r\n    frame #14: 0x00007fffee681d28 node`v8::Script::Run(v8::Local<v8::Context>) + 536\r\n    frame #15: 0x00007fffee466ddc node`node::contextify::ContextifyScript::EvalMachine(node::Environment*, long, bool, bool, v8::FunctionCallbackInfo<v8::Value> const&) + 1036\r\n    frame #16: 0x00007fffee467127 node`node::contextify::ContextifyScript::RunInThisContext(v8::FunctionCallbackInfo<v8::Value> const&) + 343\r\n    frame #17: 0x00007fffee6ea4c2 node`v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) + 530\r\n    frame #18: 0x00007fffee6eb069 node`v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) + 185\r\n    frame #19: 0x000006d8132dc01d <exit>\r\n    frame #20: 0x000006d8132918b5 runInThisContext(this=0x00002a3391b022e1:<Object: ContextifyScript>, 0x00002a3391b02399:<Object: Object>) at vm.js:91:19 fn=0x0000083ade3c0761\r\n    frame #21: 0x000006d8132918b5 defaultEval(this=0x00001241ac282201:<Object: REPLServer>, 0x00002a3391b02409:<String: \"let test = { not...\">, 0x00000be72f61a8f1:<Global proxy>, 0x00002de71e231309:<String: \"repl\">, 0x00002a3391b02481:<function: finish at repl.js:629:20>) at repl.js:227:23 fn=0x00001241ac282309\r\n    frame #22: 0x000006d8132918b5 bound(this=0x00003a32c6b826f1:<undefined>, 0x00001241ac282201:<Object: REPLServer>, 0x00001241ac282461:<Object: EventEmitter>, 0x00001241ac282309:<function: defaultEval at repl.js:227:23>, 0x00002a3391b024c1:<unknown>) at domain.js:391:15 fn=0x00001241ac282349\r\n    frame #23: 0x000006d8132918b5 runBound(this=0x00001241ac282201:<Object: REPLServer>) at domain.js:408:20 fn=0x00001241ac282511\r\n    frame #24: 0x000006d81328a5a3 <adaptor>\r\n    frame #25: 0x000006d8132918b5 onLine(this=0x00001241ac282201:<Object: REPLServer>, 0x00002a3391b024e1:<String: \"let test = { not...\">) at repl.js:582:34 fn=0x00001241ac282591\r\n    frame #26: 0x000006d8132918b5 emit(this=0x00001241ac282201:<Object: REPLServer>, 0x00003a32c6b86a51:<String: \"line\">) at events.js:140:44 fn=0x00002de71e2433a9\r\n    frame #27: 0x000006d81328a5a3 <adaptor>\r\n    frame #28: 0x000006d8132918b5 EventEmitter.emit(this=0x00001241ac282201:<Object: REPLServer>) at domain.js:431:39 fn=0x0000047a28aa74e9\r\n    frame #29: 0x000006d81328a5a3 <adaptor>\r\n    frame #30: 0x000006d8132918b5 Interface._onLine(this=0x00001241ac282201:<Object: REPLServer>, 0x00002a3391b024e1:<String: \"let test = { not...\">) at readline.js:283:39 fn=0x000016f9f5553e81\r\n    frame #31: 0x000006d8132918b5 Interface._line(this=0x00001241ac282201:<Object: REPLServer>) at readline.js:635:37 fn=0x000016f9f5554381\r\n    frame #32: 0x000006d8132918b5 Interface._ttyWrite(this=0x00001241ac282201:<Object: REPLServer>, 0x00000f3a729af9e1:<String: \"\r\n\">, 0x00002a3391b02631:<Object: Object>) at readline.js:756:41 fn=0x000016f9f5554501\r\n    frame #33: 0x000006d8132918b5 REPLServer.self._ttyWrite(this=0x00001241ac282201:<Object: REPLServer>, 0x00000f3a729af9e1:<String: \"\r\n\">, 0x00002a3391b02631:<Object: Object>) at repl.js:693:20 fn=0x0000047a28ad4f59\r\n    frame #34: 0x000006d8132918b5 onkeypress(this=0x00001241ac2826f1:<Object: ReadStream>, 0x00000f3a729af9e1:<String: \"\r\n\">, 0x00002a3391b02631:<Object: Object>) at readline.js:167:22 fn=0x00001241ac282639\r\n    frame #35: 0x000006d8132918b5 emit(this=0x00001241ac2826f1:<Object: ReadStream>, 0x0000047a28ac8cc9:<String: \"keypress\">) at events.js:140:44 fn=0x00002de71e2433a9\r\n    frame #36: 0x000006d81328a5a3 <adaptor>\r\n    frame #37: 0x000006d8132918b5 EventEmitter.emit(this=0x00001241ac2826f1:<Object: ReadStream>) at domain.js:431:39 fn=0x0000047a28aa74e9\r\n    frame #38: 0x000006d81328a5a3 <adaptor>\r\n    frame #39: 0x000006d8132918b5 emitKeys(this=0x00003a32c6b826f1:<undefined>, 0x00003a32c6b82801:<hole>) at (external).js:166:19 fn=0x000012bdb5259ed1\r\n    frame #40: 0x000006d813332c3b\r\n    frame #41: 0x000006d8132918b5 onData(this=0x00001241ac2826f1:<Object: ReadStream>, 0x00002a3391b026b1:<ArrayBufferView: backingStore=0x0000555557806e80, byteOffset=0, byteLength=1>) at readline.js:1006:18 fn=0x00001241ac282859\r\n    frame #42: 0x000006d8132918b5 emit(this=0x00001241ac2826f1:<Object: ReadStream>, 0x00002de71e23c291:<String: \"data\">) at events.js:140:44 fn=0x00002de71e2433a9\r\n    frame #43: 0x000006d81328a5a3 <adaptor>\r\n    frame #44: 0x000006d8132918b5 EventEmitter.emit(this=0x00001241ac2826f1:<Object: ReadStream>) at domain.js:431:39 fn=0x0000047a28aa74e9\r\n    frame #45: 0x000006d81328a5a3 <adaptor>\r\n    frame #46: 0x000006d8132918b5 addChunk(this=0x00003a32c6b826f1:<undefined>, 0x00001241ac2826f1:<Object: ReadStream>, 0x00001241ac282899:<Object: ReadableState>, 0x00002a3391b026b1:<ArrayBufferView: backingStore=0x0000555557806e80, byteOffset=0, byteLength=1>, 0x00003a32c6b829a1:<false>) at (external).js:280:18 fn=0x000012bdb5237531\r\n    frame #47: 0x000006d8132918b5 readableAddChunk(this=0x00003a32c6b826f1:<undefined>, 0x00001241ac2826f1:<Object: ReadStream>, 0x00002a3391b026b1:<ArrayBufferView: backingStore=0x0000555557806e80, byteOffset=0, byteLength=1>, 0x00003a32c6b826f1:<undefined>, 0x00003a32c6b829a1:<false>, 0x00003a32c6b826f1:<undefined>) at (external).js:227:26 fn=0x000012bdb52374f1\r\n    frame #48: 0x000006d8132918b5 Readable.push(this=0x00001241ac2826f1:<Object: ReadStream>, 0x00002a3391b026b1:<ArrayBufferView: backingStore=0x0000555557806e80, byteOffset=0, byteLength=1>, 0x00003a32c6b826f1:<undefined>) at (external).js:202:35 fn=0x00000f3a729c5149\r\n    frame #49: 0x000006d81328a5a3 <adaptor>\r\n    frame #50: 0x000006d8132918b5 onStreamRead(this=0x00001241ac2829b9:<Object: TTY>, <Smi: 1>, 0x00002a3391b026b1:<ArrayBufferView: backingStore=0x0000555557806e80, byteOffset=0, byteLength=1>) at (external).js:87:22 fn=0x000012bdb525c879\r\n    frame #51: 0x000006d81328ee55 <internal>\r\n    frame #52: 0x000006d813289521 <entry>\r\n    frame #53: 0x00007fffeea0e540 node`v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) + 272\r\n    frame #54: 0x00007fffee68602f node`v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) + 415\r\n    frame #55: 0x00007fffee433cf9 node`node::InternalMakeCallback(node::Environment*, v8::Local<v8::Object>, v8::Local<v8::Function>, int, v8::Local<v8::Value>*, node::async_context) + 441\r\n    frame #56: 0x00007fffee3fddd6 node`node::AsyncWrap::MakeCallback(v8::Local<v8::Function>, int, v8::Local<v8::Value>*) + 134\r\n    frame #57: 0x00007fffee4fe3f4 node`node::StreamBase::CallJSOnreadMethod(long, v8::Local<v8::Object>) + 196\r\n    frame #58: 0x00007fffee4fe4cc node`node::EmitToJSStreamListener::OnStreamRead(long, uv_buf_t const&) + 156\r\n    frame #59: 0x00007fffee504eb1 node`node::LibuvStreamWrap::ReadStart()::{lambda(uv_stream_s*, long, uv_buf_t const*)#2}::_FUN(uv_stream_s*, long, uv_buf_t const*) + 161\r\n    frame #60: 0x00007fffee5a2242 node`uv__read(stream=<unavailable>) + 674 at stream.c:1257\r\n    frame #61: 0x00007fffee5a2880 node`uv__stream_io(loop=<unavailable>, w=<unavailable>, events=<unavailable>) + 624 at stream.c:1324\r\n    frame #62: 0x00007fffee5a8260 node`uv__io_poll(loop=<unavailable>, timeout=<unavailable>) + 976 at linux-core.c:401\r\n    frame #63: 0x00007fffee59761b node`uv_run(loop=<unavailable>, mode=<unavailable>) + 331 at core.c:370\r\n    frame #64: 0x00007fffee43d425 node`node::Start(v8::Isolate*, node::IsolateData*, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 1909\r\n    frame #65: 0x00007fffee43b08a node`node::Start(int, char**) + 1386\r\n    frame #66: 0x00007ffff6b942b1 libc.so.6`__libc_start_main + 241\r\n    frame #67: 0x00007fffee3f4b2a node`_start + 42\r\n```",
        "labels": "confirmed-bug",
        "id": 45236
    },
    {
        "title": "Memory leak when using zlib.inflate to inflate invalid data v10.9.0",
        "body": "Version: 10.9.0\r\nPlatform: Linux Ubuntu 3.13.0-36-generic\r\nSubsystem: zlib\r\n\r\nI've recently updated a large project from Node 8.11.3 to 10.9.0 but the service crashes after a few minutes because of memory exhaustion (4GB RAM). I've narrowed down the issue to the use of the asynchronous zlib.inflate method if the input isn't a valid input. \r\n\r\nI've been able to create a small script which shows the issue\r\n\r\n    const crypto = require('crypto'), zlib = require('zlib');\r\n\r\n    const LOOPS = 10 * 1000;\r\n    let body = process.argv[2] === \"valid\" ? zlib.deflateSync(crypto.randomBytes(1024)) : \r\n    crypto.randomBytes(1024);\r\n\r\n    let totalRuns = 0;\r\n    let initialRSS = process.memoryUsage().rss;\r\n    setInterval(() => {\r\n\r\n    for (let i = 0; i < LOOPS; i++) {\r\n        zlib.inflate(body, (error, result) => { });\r\n    }\r\n\r\n    totalRuns += LOOPS\r\n\r\n    let currentRSS = process.memoryUsage().rss;\r\n\r\n    console.log(totalRuns, currentRSS, currentRSS - initialRSS);\r\n\r\n    }, 100);\r\n\r\nWhen using Node 8.11.3 I get the following output from that script, you can see memory usage levels out around 280MiB.\r\n> Loops ** Current RSS** RSS Increase\r\n> 10000 **150556672** 132362240\r\n> 100000 **281853952** 263659520\r\n> 200000 **294563840** 276369408\r\n> 1000000 **297381888** 279158784\r\n\r\nSwitching to Node 10.9.0 I get the following output\r\n> Loops ** Current RSS** RSS Increase\r\n> 10000 **149655552** 130969600\r\n> 100000 **790159360** 771473408\r\n> 200000 **1477070848** 1458384896\r\n\r\nAfter 200k iterations the 8.11.3 version uses 280MiB but the 10.9.0 version is using 1400MiB of memory.  After about 300k iterations using 10.9.0 the process crashes because it runs out of RAM. \r\n\r\nRunning the script with the \"valid\" parameter to send zlib a valid stream shows an increase in memory but it's small and eventually levels out and doesn't run out of memory.\r\n> node memoryleak.js valid\r\n> 10000 **156794880** 137863168\r\n> 100000 **505155584** 486223872\r\n> 200000 **546017280** 527085568\r\n\r\nI've corrected our service so that we check for invalid streams before trying to inflate them but I thought that there is potential for a denial of service against any service which uses zlib.inflate to decompress user input. ",
        "labels": "confirmed-bug",
        "id": 45237
    },
    {
        "title": "deepStrictEqual comparison output is unhelpful on prototype-only differences",
        "body": "```\r\n$ node -v\r\nv10.8.0\r\n$ node test.js\r\n```\r\n\r\n```\r\n//test.js\r\nconst assert = require('assert').strict;\r\n\r\nconst DEBUG = process.env.DEBUG_ROUTER;\r\n\r\nconst pathnameToMatches = (pathname, template) => {\r\n    DEBUG && console.log(pathname, '~', template);\r\n\r\n    const regexp = templateToRegexp(template);\r\n    const matches = pathname.match(regexp);\r\n\r\n    DEBUG && console.log(pathname, '~', regexp, '=>', !matches ? false : (matches.groups || {}));\r\n\r\n    if (!matches)\r\n        return false;\r\n\r\n    const result = matches.groups || {};\r\n    for (const key in result)\r\n        result[key] = result[key] || null;\r\n    return result;\r\n};\r\n\r\nconst templateToRegexp = template => {\r\n    let pattern = template;\r\n    DEBUG && console.log('processing =>', template);\r\n    pattern = pattern.replace(/\\/:(?<param>[\\w\\d]+?)(?=\\/|$)/gi, '\\\\/(?<$<param>>[\\\\w\\\\d]+?)(?=\\\\/|$)');\r\n    DEBUG && console.log('after required =>', pattern);\r\n    pattern = pattern.replace(/\\/:(?<param>[\\w\\d]+?)\\?/gi, '(\\\\/(?<=\\\\/)(?<$<param>>[\\\\w\\\\d]+?)(?=\\\\/|$))?');\r\n    DEBUG && console.log('after optional =>', pattern);\r\n    pattern = '^' + pattern + '$';\r\n    DEBUG && console.log('after boundaries =>', pattern);\r\n    const regexp = new RegExp(pattern, 'i');\r\n    DEBUG && console.log(template, '=>', pattern, '=>', regexp);\r\n    return regexp;\r\n};\r\n\r\ntry {\r\n    assert.deepStrictEqual(pathnameToMatches('/user', '/user'), {});\r\n    assert.deepStrictEqual(pathnameToMatches('/not-user', '/user'), false);\r\n    assert.deepStrictEqual(pathnameToMatches('/user/123', '/user/:id'), { id: '123' });\r\n    assert.deepStrictEqual(pathnameToMatches('/user/123/456', '/user/:id'), false);\r\n    assert.deepStrictEqual(pathnameToMatches('/user', '/user/:id'), false);\r\n    assert.deepStrictEqual(pathnameToMatches('/user', '/user/:id?'), { id: null });\r\n    assert.deepStrictEqual(pathnameToMatches('/user/123', '/user/:id?'), { id: '123' });\r\n    assert.deepStrictEqual(pathnameToMatches('/user/123/male', '/user/:id/:sex'), { id: '123', sex: 'male' });\r\n    assert.deepStrictEqual(pathnameToMatches('/user/123', '/user/:id/:sex?'), { id: '123', sex: null });\r\n    assert.deepStrictEqual(pathnameToMatches('/user/123', '/user/:id/:sex'), false);\r\n    assert.deepStrictEqual(pathnameToMatches('/user/123', '/user/:id?/:sex?'), { id: '123', sex: null });\r\n    assert.deepStrictEqual(pathnameToMatches('/user/123/female', '/user/:id?/:sex?'), { id: '123', sex: 'female' });\r\n    assert.deepStrictEqual(pathnameToMatches('/user', '/user/:id?/:sex?'), { id: null, sex: null });\r\n\r\n    console.log('ðŸŽ‰ðŸŽ‰ðŸŽ‰');\r\n}\r\ncatch (error) {\r\n    console.error(error);//.message, { actual: error.actual, expected: error.expected });\r\n}\r\n```\r\n\r\nThrows a misterious:\r\n```\r\n{ AssertionError [ERR_ASSERTION]: Input objects not identical:\r\n\r\n{\r\n  id: '123'\r\n}\r\n\r\n    at Object.<anonymous> (/Users/damz/Desktop/react-router-xs/specs/pathnameToMatches.spec.js:41:12)\r\n    at Module._compile (internal/modules/cjs/loader.js:689:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:700:10)\r\n    at Module.load (internal/modules/cjs/loader.js:599:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:538:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:530:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:742:12)\r\n    at startup (internal/bootstrap/node.js:266:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:596:3)\r\n  generatedMessage: true,\r\n  name: 'AssertionError [ERR_ASSERTION]',\r\n  code: 'ERR_ASSERTION',\r\n  actual: { id: '123' },\r\n  expected: { id: '123' },\r\n  operator: 'deepStrictEqual' }\r\n```\r\n\r\nWhat does this mean? Where's the difference? ðŸ¤¨\r\n```\r\n  actual: { id: '123' },\r\n  expected: { id: '123' },\r\n```",
        "labels": "confirmed-bug",
        "id": 45238
    },
    {
        "title": "Segfault when spawning child with trace events enabled",
        "body": "Introduced in version 10.2.0 (found in versions 10.2.0..10.7.0)\r\n\r\nTiny snippet:\r\n```\r\n'use strict'\r\n\r\nconst { spawn } = require('child_process')\r\n\r\n// Spawning a child with trace events enabled\r\n// Segfaults when:\r\n// - Destination file is missing OR\r\n// - On any error thrown inside the file, like `throw new Error('foo')` or `require('module-not-found')`\r\nconst proc = spawn('node', ['non-existent.js'], {\r\n  env: Object.assign({}, process.env, {\r\n    NODE_OPTIONS: '--trace-events-enabled'\r\n  })\r\n})\r\n\r\nproc.once('exit', function (code, signal) {\r\n  console.log({ code, signal })\r\n})\r\n```\r\n\r\nExecution:\r\n```\r\nkm-mac:n-tmp km$ nvm use 10.7\r\nNow using node v10.7.0 (npm v6.1.0)\r\nkm-mac:n-tmp km$ node segfault-issue.js\r\n{ code: null, signal: 'SIGSEGV' }\r\n# BROKEN\r\n\r\nkm-mac:n-tmp km$ nvm use 10.2\r\nNow using node v10.2.0 (npm v5.6.0)\r\nkm-mac:n-tmp km$ node segfault-issue.js\r\n{ code: null, signal: 'SIGSEGV' }\r\n# BROKEN\r\n\r\nkm-mac:n-tmp km$ nvm use 10.1\r\nNow using node v10.1.0 (npm v5.6.0)\r\nkm-mac:n-tmp km$ node segfault-issue.js\r\n{ code: 1, signal: null }\r\n# OK\r\n\r\nkm-mac:n-tmp km$ nvm use 10.2\r\nNow using node v10.2.0 (npm v5.6.0)\r\n\r\nkm-mac:n-tmp km$ echo \"throw new Error('foo')\" > non-existent.js\r\nkm-mac:n-tmp km$ node segfault-issue.js\r\n{ code: null, signal: 'SIGSEGV' }\r\n# On error throw\r\n\r\nkm-mac:n-tmp km$ echo \"require('foo')\" > non-existent.js\r\nkm-mac:n-tmp km$ node segfault-issue.js\r\n{ code: null, signal: 'SIGSEGV' }\r\n# On ENOENT require\r\n\r\nkm-mac:n-tmp km$ echo \"require('http')\" > non-existent.js\r\nkm-mac:n-tmp km$ node segfault-issue.js\r\n{ code: 0, signal: null }\r\n# When contents are valid\r\n\r\nkm-mac:n-tmp km$ ls\r\nnode_trace.1.log\tnon-existent.js\t\tsegfault-issue.js\r\n# Trace log was produced during one of these executions\r\n```\r\n\r\nTrace log file:\r\n[node_trace.1.log](https://github.com/nodejs/node/files/2244838/node_trace.1.log)\r\n\r\nOSX El Capitan 10.11.6\r\n```\r\nkm-mac:n-tmp km$ uname -a\r\nDarwin km-mac.local 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 21 20:07:40 PDT 2018; root:xnu-3248.73.11~1/RELEASE_X86_64 x86_64\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45239
    },
    {
        "title": "Invalid `--experimental-modules` CLI flag parsing (core dumped)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\n  ```\r\n  $ node -v\r\n  v10.6.0\r\n  ```\r\n\r\n* **Platform**:\r\n  ```\r\n  $ uname -a\r\n  Linux red 4.17.4-1-ARCH #1 SMP PREEMPT Tue Jul 3 15:45:09 UTC 2018 x86_64 GNU/Linux\r\n  ```\r\n* **Subsystem**: cli\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhile experimenting with building `NODE_OPTIONS` by concatenating additional options, I found the following two combinations causing a core dump (exit code `134`):\r\n\r\n```\r\n$ NODE_OPTIONS=\"--abort-on-uncaught-exception --experimental-modules\" node\r\nmunmap_chunk(): invalid pointer\r\nAborted (core dumped)\r\n```\r\n\r\n```\r\n$ NODE_OPTIONS=\"--experimental-modules --experimental-modules\" node\r\nfree(): invalid size\r\nAborted (core dumped)\r\n```\r\n\r\n**Node should either run successfully or gracefully terminate.** The current behavior seems to indicate some unreliable handling of the memory.\r\nThe crashes above happen every time I executed the command with these options. It's maybe not just related to `experimental-module`, the following command runs successfully: `NODE_OPTIONS=\"--trace-sync-io --experimental-modules\" node`.",
        "labels": "confirmed-bug",
        "id": 45240
    },
    {
        "title": "Pasting code into node repl makes it exit on Windows",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\nNode v8.11.2\r\nWin10 Pro\r\n\r\nI run node from cmd.exe, and simply paste this code using r-click:\r\n\r\n```\r\nvar crypto = require('crypto');\r\nfunction hmacN(N)\r\n{\r\n    console.log(N);\r\n}\r\n```\r\nThe moment I paste it, node exists and I get this output:\r\n\r\n```\r\nMicrosoft Windows [Version 10.0.17134.81]\r\n(c) 2018 Microsoft Corporation. All rights reserved.\r\n\r\nC:\\Users\\username>node\r\n> var crypto = require('crypto');\r\nundefined\r\n> function hmacN(N)\r\n... {\r\n...     console.log(N);\r\n... }\r\nundefined\r\n>\r\nC:\\Users\\username>\r\n```\r\n\r\nThis used to work properly (e.g. it shouldn't exit), that's how I always test snippets by pasting them into node-repl console.\r\n\r\nInteresting observation: if I paste incomplete code (without last `}`) then it won't exit and I need to manually complete it with the last brace and can continue. Or, if pasted block doesn't end with a new line character, then it will also won't exist and will wait for manual `[ENTER]` key press. Also, to confirm, the problem happens on `8.11.3` as well\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45241
    },
    {
        "title": "repl completion for large buffers fails to display named properties",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.5.0\r\n* **Platform**: macOS\r\n* **Subsystem**:REPL\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen alloc a large buffer, and input `a.` then press tab. It's a warning.\r\n\r\n```\r\n> a = Buffer.alloc(1024*1024)\r\n<Buffer 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ... >\r\n> a.\r\n(node:7432) REPLWarning: The current array, Buffer or TypedArray has too many entries. Certain properties may be missing from completion output.\r\n```\r\n\r\nBut it works well, when alloc a small buffer.\r\n\r\n```\r\n> a = Buffer.alloc(1024)\r\n<Buffer 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ... >\r\n> a.\r\na.__defineGetter__      a.__defineSetter__      a.__lookupGetter__      a.__lookupSetter__      a.__proto__             a.constructor           a.hasOwnProperty        a.isPrototypeOf         a.propertyIsEnumerable\r\na.toLocaleString        a.toString              a.valueOf               \r\n\r\na.buffer                a.byteLength            a.byteOffset            a.copyWithin            a.entries               a.every                 a.fill                  a.filter                a.find\r\na.findIndex             a.forEach               a.includes              a.indexOf               a.join                  a.keys                  a.lastIndexOf           a.length                a.map\r\na.reduce                a.reduceRight           a.reverse               a.set                   a.slice                 a.some                  a.sort                  a.subarray              a.values\r\n\r\na.BYTES_PER_ELEMENT     \r\n\r\na.asciiSlice            a.asciiWrite            a.base64Slice           a.base64Write           a.compare               a.copy                  a.equals                a.hexSlice              a.hexWrite\r\na.inspect               a.latin1Slice           a.latin1Write           a.offset                a.parent                a.readDoubleBE          a.readDoubleLE          a.readFloatBE           a.readFloatLE\r\na.readInt16BE           a.readInt16LE           a.readInt32BE           a.readInt32LE           a.readInt8              a.readIntBE             a.readIntLE             a.readUInt16BE          a.readUInt16LE\r\na.readUInt32BE          a.readUInt32LE          a.readUInt8             a.readUIntBE            a.readUIntLE            a.swap16                a.swap32                a.swap64                a.toJSON\r\na.ucs2Slice             a.ucs2Write             a.utf8Slice             a.utf8Write             a.write                 a.writeDoubleBE         a.writeDoubleLE         a.writeFloatBE          a.writeFloatLE\r\na.writeInt16BE          a.writeInt16LE          a.writeInt32BE          a.writeInt32LE          a.writeInt8             a.writeIntBE            a.writeIntLE            a.writeUInt16BE         a.writeUInt16LE\r\na.writeUInt32BE         a.writeUInt32LE         a.writeUInt8            a.writeUIntBE           a.writeUIntLE           \r\n```",
        "labels": "confirmed-bug",
        "id": 45242
    },
    {
        "title": "fs.promises.readFile cannot read /proc/stat, produces empty result",
        "body": "* **Version**: 10.4.1\r\n* **Platform**: Amazon Linux 2, kernel 4.14 x64\r\n* **Subsystem**: fs, experimental promises api\r\n\r\n```js\r\nconst fs = require('fs')\r\nfs.promises.readFile('/proc/stat', { encoding: 'utf8' }).then(r => console.log(r.length)) // => 0\r\nfs.readFile('/proc/stat', { encoding: 'utf8' }, (e, r) => console.log(r.length)) // => 2347\r\nconsole.log(fs.readFileSync('/proc/stat', { encoding: 'utf8' }).length) // => 2347\r\n```\r\n\r\nI'm not sure how promises API differs from classic one, but this behaviour is surprising, and I can't find anything in the docs that would explain what I am doing wrongâ€¦",
        "labels": "confirmed-bug",
        "id": 45243
    },
    {
        "title": "Sockets in Node 10.0.0 and up are not destroyed if ended before connect",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.0.0 and up\r\n* **Platform**: Darwin CLI-4992 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: net\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nBeginning with commit 9b7a6914a7f0bd754e78b42b48c75851cfd6b3c4, calling `.end` a Node.js socket before it is connected will fail to call `.destroy` on the socket, so the socket will never emit a `close` event.\r\n\r\nHere is a minimal repro, provided by @lpinca in dicussion on https://github.com/nodejs/node/pull/19241#issuecomment-396143740:\r\n\r\n```\r\nconst net = require('net');\r\n\r\nconst server = net.createServer();\r\n\r\nserver.listen(() => {\r\n  const socket = net.createConnection(server.address().port);\r\n\r\n  socket.on('connect', () => console.log('connect'));\r\n  socket.on('end', () => console.log('end'));\r\n  socket.on('close', () => console.log('close'));\r\n  socket.end();\r\n});\r\n```\r\n\r\nA test run illustrating the problem:\r\n\r\n```\r\n$ nvm use 9.11.1\r\nNow using node v9.11.1 (npm v5.6.0)\r\n$ node testSocketEnd.js\r\nconnect\r\nend\r\nclose\r\n^C\r\n$ nvm use 10.0.0\r\nNow using node v10.0.0 (npm v5.6.0)\r\n$ node testSocketEnd.js\r\nconnect\r\nend\r\n^C\r\n$ nvm use 10.4.0\r\nNow using node v10.4.0 (npm v6.1.0)\r\n$ node testSocketEnd.js\r\nconnect\r\nend\r\n^C\r\n```\r\n\r\nThis occurs because when we fire end before the connect completes (a real-world example is a timeout that fires off an `end` on the connecting socket if it is slow) we get the ordering:\r\n\r\n  * `Socket.end` from client code on timeout (calls down to `stream.Duplex.prototype.end`, setting `this.writable` to false and `this._writableState.ending` to true)\r\n\r\n  * `Socket.afterConnect`(sets `this.writable` to true when we connect without error)\r\n\r\n  * `Socket.onReadableStreamEnd` (calls `this.end`)\r\n\r\n  * `Socket.end` (calls `stream.Duplex.prototype.end`)\r\n\r\n  * `Writable.prototype.end` (does NOT call `endWritable` because `this._writableState.ending` is already true from the previous call to `socket.end`, so `this.writable` stays true)\r\n\r\n  * `socket.maybeDestroy` (does not call `socket.destroy` because `socket.writable` is `true`, so `this.destroy` is never called and  `close` is never emitted)\r\n\r\nWhile this is not really a problem with 9b7a6914a7f0bd754e78b42b48c75851cfd6b3c4, but rather an issue with afterConnect setting `writable` without any state checks, commit 9b7a6914a7f0bd754e78b42b48c75851cfd6b3c4 removes the behavior that was masking the issue -- previous to that change we were calling `destroySoon`, which would call down to `destroy` even with `.writable` set to true.\r\n\r\nThis is causing a problem for at least the fairly popular IORedis (https://github.com/luin/ioredis/issues/633), both in theory and in practice, and it seems as though it warrants a look, I'd be surprised if that was the only thing that was depending on those sockets being destroyed and emitting `close`.\r\n\r\nI'm not sure what to propose as a good fix: I don't immediately see any internal state on the socket that looks appropriate for switching behavior in `afterConnect`, although I guess it peeks at the _writableState in a couple of places.",
        "labels": "confirmed-bug",
        "id": 45244
    },
    {
        "title": "`source <(npm completion)` doesn't end in Node v10.4.0",
        "body": "* **Version**: v10.4.0\r\n* **Platform**: Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: \r\n\r\nIn bash or zsh, following command doesn't end in Node v10.4.0.\r\n\r\n```\r\n$ cat <(node -v)\r\nv10.4.0\r\n\r\n```\r\n\r\nBecause of this change, [source <(npm completion)](https://docs.npmjs.com/cli/completion) in my `.zshrc` stops initializing a new shell.\r\n\r\nIn Node v10.3.0, the command ends normally.",
        "labels": "confirmed-bug",
        "id": 45245
    },
    {
        "title": "Setting callback for on 'data' event of stderr causes error on v10.0.0",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.0.0\r\n* **Platform**: OS X 10.13.2\r\n* **Subsystem**: Process\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI am unable to set a callback on the 'data' event (since `process.stderr` [is a](https://nodejs.org/api/process.html#process_process_stdin) `net.Socket` stream, [it should](https://nodejs.org/api/stream.html#stream_event_data) emit the `data` event).\r\n\r\nThe following snippet works on v8.0.0 but throws an error on v10.0.0:\r\n\r\n```javascript\r\nprocess.stderr.on('data', function(data) {\r\n    // not relevant, error is threw anyway\r\n});\r\n```\r\n\r\nError threw:\r\n\r\n```\r\nError: read ENOTCONN\r\n    at WriteStream.Socket._read (net.js:530:20)\r\n    at WriteStream.Readable.read (_stream_readable.js:458:10)\r\n    at resume_ (_stream_readable.js:897:12)\r\n    at process._tickCallback (internal/process/next_tick.js:174:19)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:721:11)\r\n    at startup (internal/bootstrap/node.js:228:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:575:3)\r\nEmitted 'error' event at:\r\n    at emitErrorNT (internal/streams/destroy.js:92:8)\r\n    at emitErrorAndCloseNT (internal/streams/destroy.js:59:3)\r\n    at process._tickCallback (internal/process/next_tick.js:174:19)\r\n    [... lines matching original stack trace ...]\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:575:3)\r\n````\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45246
    },
    {
        "title": "Bad tab completion for object properties with special characters",
        "body": "* **Version**: `v8.11.0`\r\n* **Platform**: `Linux fedora-thinkpad 4.13.9-300.fc27.x86_64 #1 SMP Mon Oct 23 13:41:58 UTC`\r\n* **Subsystem**: n/a\r\n\r\n```node\r\n> d = {'hello, world!': 'some string'}\r\n{ 'hello, world!': 'some string' }\r\n> d.hello<tab>\r\n> d.hello, world!<enter>\r\n... \r\n... \r\n> <keyboard interrupt> \r\n```\r\n\r\nWhen an object has special characters as one of it's properties, node will autocomplete that property, but continue waiting for input (as the completed property is invalid syntax). This is not desired behaviour.\r\n\r\nThis issue is also present in Firefox, but not in Chrome.",
        "labels": "confirmed-bug",
        "id": 45247
    },
    {
        "title": "v8.deserialize triggers Buffer constructor deprecation warning",
        "body": "* **Version**: Observed on 10.4.0, presumably occurs on all 10+\r\n* **Platform**: All\r\n\r\nDeserializing a representation of an expression that contained a `Buffer` displays`(node:15176) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.`\r\n\r\nReproduce with`v8.deserialize(v8.serialize(Buffer.alloc(0)))`.\r\n\r\nIt looks like `DefaultDeserializer ._readHostObject()` needs a special case for buffers.",
        "labels": "confirmed-bug",
        "id": 45248
    },
    {
        "title": "configure: clang version is misdetected for double-digit clang versions",
        "body": "* **Version**: v10.3.0\r\n* **Platform**: \r\n* **Subsystem**: \r\n\r\nConfigure performs a check to see if clang is newer than 3.4.2. However, this check is done against the string parsed out of the clang output in `try_check_compiler`: https://github.com/nodejs/node/blob/master/configure#L710 This results in miscomparisons for double-digit clang versions. For example, if `clang_version` is `'10.0.0'`, then `clang_version < '3.4.2'` is false even though clang 10 is definitely newer than 3.",
        "labels": "confirmed-bug",
        "id": 45249
    },
    {
        "title": "require.main is undefined when using --experimental-modules",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: node v10.3.0\r\n* **Platform**: linux, windows, wsl\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nWhen running node with --experimental-modules flag, the global ```require``` object has a ```main``` property but its value is always ```undefined```. Is this by design?\r\n\r\n```js\r\n// index.js\r\nconsole.log(require.main === undefined)\r\n```\r\n```console\r\n$ node index.js\r\nfalse\r\n```\r\n```\r\n$ node --experimental-modules index.js\r\ntrue\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45250
    },
    {
        "title": "node 10.2.0+ turning off stty echo when using process.stdin.setRawMode()",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.2.0\r\n* **Platform**: MacOS\r\n* **Subsystem**: Unsure right now\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nStarting with node 10.2.0 it is behaving as if I'm running `stty -echo` and hides the echo output when using `heroku run` and typing characters in. Node 10.3.0 and 10.3.1 also have the issue, but 10.1.0 and lower does not.\r\n\r\nRight now I'm working on providing a simpler example that does not involve the Heroku CLI. I'm assuming this is something related to using `.setRawMode()` but will update when I have more information.\r\n\r\n**Update:** Here is a simpler example: `node -e \"process.stdin.setRawMode(true)\"` in bash. It sets `stty -echo`.\r\n\r\nIf you run this in node 10.1.0, nothing happens. If you run it in 10.2.0 in bash, it will turn echo off.",
        "labels": "confirmed-bug",
        "id": 45251
    },
    {
        "title": "http2: assertion failed",
        "body": "Node 10.2.1, OSX\r\n\r\n```\r\n/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node[47055]: ../src/node_http2.cc:1819:void node::http2::Http2Stream::OnTrailers(): Assertion `!this->IsDestroyed()' failed.\r\n 1: node::Abort() [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n 2: node::MakeCallback(v8::Isolate*, v8::Local<v8::Object>, char const*, int, v8::Local<v8::Value>*, node::async_context) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n 3: node::http2::Http2Stream::OnTrailers() [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n 4: node::http2::Http2Stream::Provider::Stream::OnRead(nghttp2_session*, int, unsigned char*, unsigned long, unsigned int*, nghttp2_data_source*, void*) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n 5: nghttp2_session_pack_data [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n 6: nghttp2_session_mem_send_internal [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n 7: nghttp2_session_mem_send [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n 8: node::http2::Http2Session::SendPendingData() [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n 9: node::http2::Http2Session::ClearOutgoing(int) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n10: node::http2::Http2Session::OnStreamAfterWrite(node::WriteWrap*, int) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n11: node::WriteWrap::OnDone(int) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n12: node::Environment::RunAndClearNativeImmediates() [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n13: node::Environment::CheckImmediate(uv_check_s*) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n14: uv__run_check [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n15: uv_run [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n16: node::Start(v8::Isolate*, node::IsolateData*, int, char const* const*, int, char const* const*) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n17: node::Start(uv_loop_s*, int, char const* const*, int, char const* const*) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n18: node::Start(int, char**) [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n19: start [/Users/ronagy/.nvm/versions/node/v10.2.1/bin/node]\r\n```",
        "labels": "confirmed-bug",
        "id": 45252
    },
    {
        "title": "http2 pushPromise in 10.2.0+",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.2.0 and 10.2.1\r\n* **Platform**: OS X\r\n* **Subsystem**: http2\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIâ€™m afraid I may not be able to describe this well; a lot of HTTP2 stuff goes over my head. Iâ€™m aware this module is experimental, so itâ€™s possible that there is an intentional but undocumented API or behavior change in play, but my gut says this is _probably_ a bug.\r\n\r\nWhen running the same code using HTTP2 without the compatibility API in 10.1.0 and 10.2.0 (or 10.2.1), I observe very different results (using chrome://net-internals to observe the back-and-forth) with an end result of no push promise adoption. No errors are thrown â€” Iâ€™ve found nothing observably different in the application â€” and Iâ€™m not at all sure what specifically accounts for the difference in behavior, but it was replicable across two different applications using the HTTP2 module and was consistent in Chrome and Firefox.\r\n\r\ntl;dr: since 10.2.0, it _seems_ like push promises stopped working\r\n\r\nIâ€™ve tried to put together the most minimal reproduction I could since I donâ€™t have much else to offer for debugging this, though I donâ€™t know of any way to test this that doesnâ€™t involve certs:\r\n\r\n```js\r\nconst fs = require('fs');\r\nconst http2 = require('http2');\r\nconst path = require('path');\r\n\r\nconst SSL_CERT_PATH = path.resolve(__dirname, 'XXXXXXXXX.crt');\r\nconst SSL_KEY_PATH  = path.resolve(__dirname, 'XXXXXXXXX.key');\r\nconst HTTPS_PORT = XXXX;\r\n\r\nconst DEPENDENCY = {\r\n  data: Buffer.from(`body { background: red; }`),\r\n  path: '/dep',\r\n  type: 'text/css',\r\n  pushAssets: []\r\n};\r\n\r\nconst DOCUMENT = {\r\n  data: Buffer.from(`<!DOCTYPE html><link rel=\"stylesheet\" href=\"/dep\">`),\r\n  path: '/',\r\n  type: 'text/html',\r\n  pushAssets: [ DEPENDENCY ]\r\n};\r\n\r\nconst server = http2.createSecureServer({\r\n  key: fs.readFileSync(SSL_KEY_PATH),\r\n  cert: fs.readFileSync(SSL_CERT_PATH)\r\n});\r\n\r\nconst serveAsset = (stream, asset) => {\r\n  stream.respond({\r\n    [http2.constants.HTTP2_HEADER_STATUS]: http2.constants.HTTP_STATUS_OK,\r\n    [http2.constants.HTTP2_HEADER_CONTENT_LENGTH]: asset.data.length,\r\n    [http2.constants.HTTP2_HEADER_CONTENT_TYPE]: asset.type\r\n  });\r\n\r\n  for (const pushAsset of asset.pushAssets) {\r\n    stream.pushStream({\r\n      [http2.constants.HTTP2_HEADER_PATH]: pushAsset.path\r\n    }, (err, stream, h) => {\r\n      if (err) return console.log(err);\r\n\r\n      stream.respond({\r\n        [http2.constants.HTTP2_HEADER_STATUS]: http2.constants.HTTP_STATUS_OK,\r\n        [http2.constants.HTTP2_HEADER_CONTENT_LENGTH]: pushAsset.data.length,\r\n        [http2.constants.HTTP2_HEADER_CONTENT_TYPE]: pushAsset.type\r\n      });\r\n\r\n      stream.end(pushAsset.data);\r\n    });\r\n  }\r\n\r\n  stream.end(asset.data);\r\n};\r\n\r\nserver.on('stream', (stream, reqHeaders) => {\r\n  switch (reqHeaders[http2.constants.HTTP2_HEADER_PATH]) {\r\n    case '/': return serveAsset(stream, DOCUMENT);\r\n    case '/dep': return serveAsset(stream, DEPENDENCY);\r\n  }\r\n});\r\n\r\nserver.listen(HTTPS_PORT);\r\n```\r\n\r\nIf we run this in Node 10.1.0, the dependencyâ€™s push promise is adopted.\r\n\r\n<img width=\"564\" alt=\"screen shot 2018-05-27 at 10 23 58 pm\" src=\"https://user-images.githubusercontent.com/6257356/40594476-6319fd64-61fd-11e8-953c-41a4e1a30ee3.png\">\r\n\r\n<details>\r\n<summary>Transcript (Node 10.1.0)</summary>\r\n<pre>\r\n25756: HTTP2_SESSION\r\nStart Time: 2018-05-27 22:24:12.292\r\n\r\nt=4420 [st= 0]  HTTP2_SESSION_PING\r\n                --> is_ack = false\r\n                --> type = \"sent\"\r\n                --> unique_id = 1\r\nt=4420 [st= 0]  HTTP2_SESSION_SEND_HEADERS\r\n                --> exclusive = true\r\n                --> fin = true\r\n                --> has_priority = true\r\n                --> :method: GET\r\n                    :authority: snek.city:9443\r\n                    :scheme: https\r\n                    :path: /\r\n                    pragma: no-cache\r\n                    cache-control: no-cache\r\n                    upgrade-insecure-requests: 1\r\n                    user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\r\n                    accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\r\n                    accept-encoding: gzip, deflate, br\r\n                    accept-language: en-US,en;q=0.9\r\n                --> parent_stream_id = 0\r\n                --> source_dependency = 25807 (HTTP_STREAM_JOB)\r\n                --> stream_id = 5\r\n                --> weight = 256\r\nt=4420 [st= 0]  HTTP2_SESSION_RECV_HEADERS\r\n                --> fin = false\r\n                --> :status: 200\r\n                    content-length: 50\r\n                    content-type: text/html\r\n                    date: Mon, 28 May 2018 02:24:12 GMT\r\n                --> stream_id = 5\r\nt=4421 [st= 1]  HTTP2_SESSION_RECV_PUSH_PROMISE\r\n                --> :scheme: https\r\n                    :authority: snek.city:9443\r\n                    :method: GET\r\n                    :path: /dep\r\n                --> id = 5\r\n                --> promised_stream_id = 6\r\nt=4421 [st= 1]  HTTP2_STREAM_SEND_PRIORITY\r\n                --> exclusive = true\r\n                --> parent_stream_id = 5\r\n                --> stream_id = 6\r\n                --> weight = 110\r\nt=4421 [st= 1]  HTTP2_SESSION_RECV_HEADERS\r\n                --> fin = false\r\n                --> :status: 200\r\n                    content-length: 25\r\n                    content-type: text/css\r\n                    date: Mon, 28 May 2018 02:24:12 GMT\r\n                --> stream_id = 6\r\nt=4421 [st= 1]  HTTP2_SESSION_RECV_DATA\r\n                --> fin = false\r\n                --> size = 50\r\n                --> stream_id = 5\r\nt=4421 [st= 1]  HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                --> delta = -50\r\n                --> window_size = 15728590\r\nt=4421 [st= 1]  HTTP2_SESSION_RECV_DATA\r\n                --> fin = false\r\n                --> size = 25\r\n                --> stream_id = 6\r\nt=4421 [st= 1]  HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                --> delta = -25\r\n                --> window_size = 15728565\r\nt=4421 [st= 1]  HTTP2_SESSION_PING\r\n                --> is_ack = true\r\n                --> type = \"received\"\r\n                --> unique_id = 1\r\nt=4421 [st= 1]  HTTP2_SESSION_RECV_DATA\r\n                --> fin = true\r\n                --> size = 0\r\n                --> stream_id = 5\r\nt=4421 [st= 1]  HTTP2_SESSION_RECV_DATA\r\n                --> fin = true\r\n                --> size = 0\r\n                --> stream_id = 6\r\nt=4427 [st= 7]  HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                --> delta = 50\r\n                --> window_size = 15728615\r\nt=4433 [st=13]  HTTP2_STREAM_ADOPTED_PUSH_STREAM\r\n                --> stream_id = 6\r\n                --> url = \"https://snek.city:9443/dep\"\r\nt=4434 [st=14]  HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                --> delta = 25\r\n                --> window_size = 15728640\r\n</pre>\r\n</details>\r\n\r\n---\r\n\r\nIf we run this in either Node 10.2.0 or 10.2.1, instead the promise (which is seemingly received) is not adopted and the browser requests the dependency:\r\n\r\n<img width=\"529\" alt=\"screen shot 2018-05-27 at 10 31 24 pm\" src=\"https://user-images.githubusercontent.com/6257356/40594531-bd953308-61fd-11e8-9f58-91015da78695.png\">\r\n\r\n<details>\r\n<summary>Transcript (Node 10.2.1)</summary>\r\n<pre>\r\n26175: HTTP2_SESSION\r\nsnek.city:9443 (DIRECT)\r\nStart Time: 2018-05-27 22:31:22.364\r\n\r\nt=2704 [st= 0] +HTTP2_SESSION  [dt=?]\r\n                --> host = \"snek.city:9443\"\r\n                --> proxy = \"DIRECT\"\r\nt=2704 [st= 0]    HTTP2_SESSION_INITIALIZED\r\n                  --> protocol = \"h2\"\r\n                  --> source_dependency = 26174 (SOCKET)\r\nt=2704 [st= 0]    HTTP2_SESSION_SEND_SETTINGS\r\n                  --> settings = [\"[id:1 (SETTINGS_HEADER_TABLE_SIZE) value:65536]\",\"[id:3 (SETTINGS_MAX_CONCURRENT_STREAMS) value:1000]\",\"[id:4 (SETTINGS_INITIAL_WINDOW_SIZE) value:6291456]\"]\r\nt=2704 [st= 0]    HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                  --> delta = 15663105\r\n                  --> window_size = 15728640\r\nt=2704 [st= 0]    HTTP2_SESSION_SEND_WINDOW_UPDATE\r\n                  --> delta = 15663105\r\n                  --> stream_id = 0\r\nt=2704 [st= 0]    HTTP2_SESSION_SEND_HEADERS\r\n                  --> exclusive = true\r\n                  --> fin = true\r\n                  --> has_priority = true\r\n                  --> :method: GET\r\n                      :authority: snek.city:9443\r\n                      :scheme: https\r\n                      :path: /\r\n                      pragma: no-cache\r\n                      cache-control: no-cache\r\n                      upgrade-insecure-requests: 1\r\n                      user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\r\n                      accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\r\n                      accept-encoding: gzip, deflate, br\r\n                      accept-language: en-US,en;q=0.9\r\n                  --> parent_stream_id = 0\r\n                  --> source_dependency = 26170 (HTTP_STREAM_JOB)\r\n                  --> stream_id = 1\r\n                  --> weight = 256\r\nt=2706 [st= 2]    HTTP2_SESSION_RECV_SETTINGS\r\nt=2706 [st= 2]    HTTP2_SESSION_SEND_SETTINGS_ACK\r\nt=2709 [st= 5]    HTTP2_SESSION_RECV_SETTINGS_ACK\r\nt=2709 [st= 5]    HTTP2_SESSION_RECV_HEADERS\r\n                  --> fin = false\r\n                  --> :status: 200\r\n                      content-length: 50\r\n                      content-type: text/html\r\n                      date: Mon, 28 May 2018 02:31:22 GMT\r\n                  --> stream_id = 1\r\nt=2709 [st= 5]    HTTP2_SESSION_RECV_PUSH_PROMISE\r\n                  --> :scheme: https\r\n                      :authority: snek.city:9443\r\n                      :method: GET\r\n                      :path: /dep\r\n                  --> id = 1\r\n                  --> promised_stream_id = 2\r\nt=2709 [st= 5]    HTTP2_STREAM_SEND_PRIORITY\r\n                  --> exclusive = true\r\n                  --> parent_stream_id = 1\r\n                  --> stream_id = 2\r\n                  --> weight = 110\r\nt=2709 [st= 5]    HTTP2_SESSION_RECV_HEADERS\r\n                  --> fin = false\r\n                  --> :status: 200\r\n                      content-length: 25\r\n                      content-type: text/css\r\n                      date: Mon, 28 May 2018 02:31:22 GMT\r\n                  --> stream_id = 2\r\nt=2709 [st= 5]    HTTP2_SESSION_RECV_DATA\r\n                  --> fin = false\r\n                  --> size = 50\r\n                  --> stream_id = 1\r\nt=2709 [st= 5]    HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                  --> delta = -50\r\n                  --> window_size = 15728590\r\nt=2709 [st= 5]    HTTP2_SESSION_RECV_DATA\r\n                  --> fin = false\r\n                  --> size = 25\r\n                  --> stream_id = 2\r\nt=2709 [st= 5]    HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                  --> delta = -25\r\n                  --> window_size = 15728565\r\nt=2710 [st= 6]    HTTP2_SESSION_RECV_DATA\r\n                  --> fin = true\r\n                  --> size = 0\r\n                  --> stream_id = 1\r\nt=2711 [st= 7]    HTTP2_SESSION_RECV_RST_STREAM\r\n                  --> error_code = \"0 (NO_ERROR)\"\r\n                  --> stream_id = 2\r\nt=2711 [st= 7]    HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                  --> delta = 25\r\n                  --> window_size = 15728590\r\nt=2714 [st=10]    HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                  --> delta = 50\r\n                  --> window_size = 15728640\r\nt=2722 [st=18]    HTTP2_SESSION_SEND_HEADERS\r\n                  --> exclusive = true\r\n                  --> fin = true\r\n                  --> has_priority = true\r\n                  --> :method: GET\r\n                      :authority: snek.city:9443\r\n                      :scheme: https\r\n                      :path: /dep\r\n                      pragma: no-cache\r\n                      cache-control: no-cache\r\n                      user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36\r\n                      accept: text/css,*/*;q=0.1\r\n                      referer: https://snek.city:9443/\r\n                      accept-encoding: gzip, deflate, br\r\n                      accept-language: en-US,en;q=0.9\r\n                  --> parent_stream_id = 0\r\n                  --> source_dependency = 26180 (HTTP_STREAM_JOB)\r\n                  --> stream_id = 3\r\n                  --> weight = 256\r\nt=2723 [st=19]    HTTP2_SESSION_RECV_HEADERS\r\n                  --> fin = false\r\n                  --> :status: 200\r\n                      content-length: 25\r\n                      content-type: text/css\r\n                      date: Mon, 28 May 2018 02:31:22 GMT\r\n                  --> stream_id = 3\r\nt=2723 [st=19]    HTTP2_SESSION_RECV_DATA\r\n                  --> fin = false\r\n                  --> size = 25\r\n                  --> stream_id = 3\r\nt=2723 [st=19]    HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                  --> delta = -25\r\n                  --> window_size = 15728615\r\nt=2723 [st=19]    HTTP2_SESSION_RECV_DATA\r\n                  --> fin = true\r\n                  --> size = 0\r\n                  --> stream_id = 3\r\nt=2724 [st=20]    HTTP2_SESSION_UPDATE_RECV_WINDOW\r\n                  --> delta = 25\r\n                  --> window_size = 15728640\r\n</pre>\r\n</details>\r\n\r\n---\r\n\r\nComparing the transcripts the first stand-out difference is `(DIRECT)`. I donâ€™t know what this means. But theyâ€™re so different altogether that Iâ€™m not sure what factors might be significant.\r\n\r\nApologies if Iâ€™m missing something painfully obvious.",
        "labels": "confirmed-bug",
        "id": 45253
    },
    {
        "title": "stream: Readable().removeAllListeners() not work",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.1.0, 10.2.0, 11.0.0-pre\r\n* **Platform**: Darwin (), maybe all platforms\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n```js\r\nconst {Socket} = require('net')\r\nconst s = new Socket\r\ns.on('data', () => {\r\n})\r\n\r\ns.removeAllListeners()\r\ns.listenerCount('data') // 0 expected, but got 1\r\n```\r\n\r\nIf there is no arguments for `stream::removeAllListeners()`, the argument to be passed into `Stream.prototype.removeAllListeners` will be `undefined`, see [here](https://github.com/nodejs/node/blob/master/lib/_stream_readable.js#L849)\r\n\r\nThe `undefined` value causes that the `events::removeAllListeners(undefined)` will do nothing. see [here](https://github.com/nodejs/node/blob/master/lib/events.js#L374)\r\n",
        "labels": "confirmed-bug",
        "id": 45254
    },
    {
        "title": "http2: Edge and IE broken response",
        "body": "* **Version**: v10.1.0\r\n* **Platform**: Linux develop 4.9.0-6-amd64 #1 SMP Debian 4.9.88-1+deb9u1 (2018-05-07) x86_64 GNU/Linux\r\n* **Subsystem**: http2\r\n\r\nAfter upgrade nodejs from v9.11.1 to v10.1.0 Edge and IE not handle properly response from server or response is somehow broken.\r\n\r\nSimple server:\r\n\r\n```js\r\nconst http2 = require('http2');\r\n\r\nconst server = http2.createSecureServer({\r\n        allowHTTP1: true,\r\n        cert: \"some cert\",\r\n        key: \"some key\"\r\n}, (req, res) => {\r\n   console.log(\"message\");\r\n   res.writeHead(200);\r\n   res.end(\"ok\");\r\n   // or \"hack\" setTimeout(()=>res.end(\"ok\"), 100); // to make Edge get valid response more offen\r\n}).listen(443);\r\n\r\nserver.on(\"session\", () => {\r\n  console.log(\"session\");\r\n})\r\n```\r\n\r\n* session is created\r\n* request come\r\n* browser not handle response\r\n\r\nEdge sometimes display response, IE never.\r\nOn Edge bigger responses are truncated randomly.\r\nI see same behavior in plain mode - via haproxy.\r\n\r\nIE and Edge version:\r\n![sample](https://media.cyclosport.pl/f/7629dfa1e7c2e00c09424b4d11cb0aff/Screenshot_20180520_171523.png)",
        "labels": "confirmed-bug",
        "id": 45255
    },
    {
        "title": "assert: filename may be undefined in `filename.endsWith('.js')`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.1.0\r\n* **Platform**: Linux arch-seckinger 4.16.9-1-ARCH #1 SMP PREEMPT Thu May 17 02:10:09 UTC 2018 x86_64 GNU/Linux\r\n* **Subsystem**: assert\r\n\r\nApparently introduced by #18322.\r\nI'm working on a PR to fix this.\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n## code\r\n```javascript\r\nnew Function(\"assert\", \"assert(1 === 2);\")(require(\"assert\"));\r\n```\r\n\r\n## expected behavior\r\n(this is what happens with node 6, 7, 8 and 9)\r\nthrows an `AssertionError: false == true`\r\n\r\n## actual behavior\r\n(with node 10)\r\nthrows\r\n```\r\nassert.js:163\r\n  if (filename.endsWith('.js') && NativeModule.exists(filename.slice(0, -3))) {\r\n               ^\r\n\r\nTypeError: Cannot read property 'endsWith' of undefined\r\n```",
        "labels": "confirmed-bug",
        "id": 45256
    },
    {
        "title": "fs.ftruncate cannot truncate to lengths > 2GB",
        "body": "* **Version**: 10.x\r\n* **Platform**: all\r\n* **Subsystem**: fs\r\n\r\n`fs.ftruncate`, in Node 10, [attempts to do some length checking](https://github.com/nodejs/node/blob/df511c619557d5cf1af27c674a41c0fb7a741f67/lib/fs.js#L787-L802), which I don't recall being present in earlier versions of Node (v6 I think?). As somewhat alluded to in the comment there, this breaks any attempt to truncate (or allocate, in my particular case) a file to more than 2GB.",
        "labels": "confirmed-bug",
        "id": 45257
    },
    {
        "title": "the Stream is closed if app pushes unused assets",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.1.0\r\n* **Platform**: Windows Server 2008R2 64\r\n* **Subsystem**: any browser any OS\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIf push some assets which will not be used with browser - stream closes on the second request\r\nPage requires only ```<script src=\"script.js\"></script>```, but if to push something that is not using on the page - the next page refresh will close the http2 stream\r\n\r\n```js\r\n        const pushAsset = (stream, file) => {\r\n            const filePath = path.resolve(file.filePath);\r\n        \r\n            stream.pushStream({ [HTTP2_HEADER_PATH]: file.path }, (err, pushStream) => {\r\n                pushStream.respondWithFile(filePath, file.headers, {\r\n                    onError: (err) => {\r\n                        respondToStreamError(err, stream);\r\n                    }\r\n                });\r\n            });\r\n        };\r\n\r\n        const cssFile = {\r\n            path: '/style.css',\r\n            filePath: './style.css',\r\n            headers: {\r\n                'content-type': 'text/css'\r\n            }\r\n        };\r\n        const cssFile1 = {\r\n            path: '/style1.css',\r\n            filePath: './style1.css',\r\n            headers: {\r\n                'content-type': 'text/css'\r\n            }\r\n        };\r\n        const jsFile = {\r\n            path: '/script.js',\r\n            filePath: './script.js',\r\n            headers: {\r\n                'content-type': 'application/javascript'\r\n            }\r\n        };\r\n\r\n        pushAsset(stream, jsFile);\r\n        pushAsset(stream, cssFile);   //<-- unused\r\n        pushAsset(stream, cssFile1);   //<-- unused\r\n```\r\nThe error:\r\n```\r\nevents.js:167\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError [ERR_HTTP2_STREAM_ERROR]: Stream closed with error code NGHTTP2_REFUSED_STREAM\r\n    at ServerHttp2Stream._destroy (internal/http2/core.js:1871:13)\r\n    at ServerHttp2Stream.destroy (internal/streams/destroy.js:32:8)\r\n    at ServerHttp2Stream.[maybe-destroy] (internal/http2/core.js:1887:12)\r\n    at Http2Stream.onStreamClose [as onstreamclose] (internal/http2/core.js:346:26)\r\nEmitted 'error' event at:\r\n    at emitErrorNT (internal/streams/destroy.js:82:8)\r\n    at emitErrorAndCloseNT (internal/streams/destroy.js:50:3)\r\n    at process._tickCallback (internal/process/next_tick.js:63:19)\r\n\r\n```\r\nDeclaration of extra assets should not crush the tream",
        "labels": "confirmed-bug",
        "id": 45258
    },
    {
        "title": "Cannot read property 'emit' of null in _http_client.js",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.14.2\r\n* **Platform**: Linux clearnet 4.9.56-21.pvops.qubes.x86_64 #1 SMP Tue Oct 17 23:58:50 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: http\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI'm getting the following error on every run of [registry-static](https://www.npmjs.com/package/registry-static):\r\n```\r\n_http_client.js:277\r\n  req.emit('close');\r\n     ^\r\n\r\nTypeError: Cannot read property 'emit' of null\r\n    at TLSSocket.socketCloseListener (_http_client.js:277:6)\r\n    at emitOne (events.js:101:20)\r\n    at TLSSocket.emit (events.js:188:7)\r\n    at _handle.close (net.js:509:12)\r\n    at TCP.done [as _onclose] (_tls_wrap.js:332:7)\r\n```\r\n\r\nIt's happening reliably for me at 317673 while processing [ng2-comps](https://skimdb.npmjs.com/registry/ng2-comps).  I haven't tried with an empty output folder yet because it takes me a few days to get that far into the database.",
        "labels": "confirmed-bug",
        "id": 45259
    },
    {
        "title": "http2: server.close not behaving like http1 or net",
        "body": "* **Version**: 8, 9, 10, master\r\n* **Platform**: Mac OS X\r\n* **Subsystem**: http2\r\n\r\nAn http2 server inherits from `net.Server`, so a user might expect that the behavior of `close()` is the same (and we document it as being the same). However, the following will __never__ call the `close(cb)`Â  callback.\r\n\r\n```js\r\n'use strict';\r\n\r\nconst http2 = require('http2');\r\nconst assert = require('assert');\r\n\r\nconst server = http2.createServer();\r\nlet client;\r\n\r\nserver.listen(0, function() {\r\n  client = http2.connect(`http://localhost:${server.address().port}`);\r\n  client.on('connect', function() {\r\n    console.log('connect');\r\n\r\n    server.close(function() {\r\n      console.log('the close callback');\r\n    });\r\n  });\r\n});\r\n\r\nserver.on('session', (s) => {\r\n  s.setTimeout(10, function () {\r\n    console.log('timeout');\r\n    s.destroy();\r\n  });\r\n});\r\n```\r\n\r\nThis is the same code for `net` that works as expected:\r\n\r\n```js\r\n'use strict';\r\n\r\nconst net = require('net');\r\nconst assert = require('assert');\r\n\r\nconst server = net.createServer();\r\nlet client;\r\n\r\nserver.listen(0, function() {\r\n  client = net.connect(server.address().port);\r\n  client.on('connect', function() {\r\n    console.log('connect');\r\n\r\n    server.close(function() {\r\n      console.log('the close callback');\r\n    });\r\n  });\r\n});\r\n\r\nserver.on('connection', (s) => {\r\n  s.setTimeout(10, function () {\r\n    console.log('timeout');\r\n    s.destroy();\r\n  });\r\n});\r\n```",
        "labels": "confirmed-bug",
        "id": 45260
    },
    {
        "title": "process.stdin example from docs no longer works in node 10",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 10.0.0 (using nvm)\r\n* **Platform**: 4.13.0-39-generic #44~16.04.1-Ubuntu\r\n* **Subsystem**: \r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI am running `process.stdin` [example](https://nodejs.org/api/process.html#process_process_stdin) from docs:\r\n\r\n```js\r\nprocess.stdin.setEncoding('utf8');\r\n\r\nprocess.stdin.on('readable', () => {\r\n  const chunk = process.stdin.read();\r\n  if (chunk !== null) {\r\n    process.stdout.write(`data: ${chunk}`);\r\n  }\r\n});\r\n\r\nprocess.stdin.on('end', () => {\r\n  process.stdout.write('end');\r\n});\r\n```\r\nI expect the same results as in node v9 and below: command line should wait for my input and return it prefixed with `data: `. Instead, process is closed right away. I believe this is regression as example works fine in node v9 and v8.\r\n\r\n<sub>(edited by @addaleax: syntax highlighting)</sub>",
        "labels": "confirmed-bug",
        "id": 45261
    },
    {
        "title": "fs: too strict range check on 'mode' parameter",
        "body": "* **Version**: 10.0.0\r\n* **Platform**: MacOS 10.12.6 (Sierra)\r\n* **Subsystem**: fs\r\n\r\nSince version 10, function like `fs.chmod()` or `fs.mkdir()` check if their `mode` parameter is below `o777` [throwing a RangeError exception if the condition isn't satisfied](https://github.com/nodejs/node/blob/master/lib/fs.js#L1024).\r\nThis requirement is too strict as the mode parameter can often be above `o777` if it need to set the `S_ISUID` or `S_ISGID` bits.\r\n\r\nFurthermore this range check break several node packages (e.g. `graceful-fs` used by over 1400 other packages) in a very common scenario:\r\nA program wants to create a new file/directory with the same rights that a reference file/directory. Often the `mode` attribute of `fs.Stats` object is directly passed to `fs.chmod()` or `fs.mkdir()`. However the `fs.Stats.mode` is always above `o777` (e.g. `o100644`) since it also contains the file type bits.\r\n\r\nClassic POSIX version of `chmod` or `mkdir` seems to handle those kind a values without complaining by discarding the irrelevant bits instead of throwing an error. Why do Node need to be so brutal about it?",
        "labels": "confirmed-bug",
        "id": 45262
    },
    {
        "title": "assigning a hostname with port 80 to URL.host will not override the existing port ",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.8.1, but also occurs in 10.0.0\r\n* **Platform**: MacOS\r\n* **Subsystem**: url\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nOverriding the host property with a host that has port 80, will not override the port.\r\nExample:\r\n\r\n```js\r\nconst {URL} = require('url')\r\n\r\nconst u = new URL('http://localhost:3000/foo')\r\nu.host = 'some-domain:80'\r\nconsole.log(u.href) // expected http://some-domain:80/foo, actual: http://some-domain:3000/foo \r\n\r\n// note that any other port besides 80 works correctly:\r\n\r\nconst u2 = new URL('http://localhost:3000/foo')\r\nu2.host = 'some-domain:801'\r\nconsole.log(u2.href) // http://some-domain:801/foo\r\n```\r\n\r\nThe same bug applies to `https` with port 443.",
        "labels": "confirmed-bug",
        "id": 45263
    },
    {
        "title": "console.time() should output warning if timer exists",
        "body": "* **Version**: v.10.0.0\r\n* **Platform**: 16.7.0 Darwin Kernel Version 16.7.0: Tue Jan 30 11:27:06 PST 2018; root:xnu-3789.73.11~1/RELEASE_X86_64 x86_64\r\n\r\nThe WHATWG Console Standard specifies [`console.time()`](https://console.spec.whatwg.org/#time) as printing a warning to the screen if an associated timer exists. Currently in Node, no warning is printed and the associated existing timer is reset.",
        "labels": "confirmed-bug",
        "id": 45264
    },
    {
        "title": "process.domain is undefined after using \"await\" in node10",
        "body": "Version: found at v10.0.0\r\nPlatform: 64-bit Windows 7\r\nSubsystem:domain\r\n\r\nWhen I upgrade to node v10.0.0, I found a problem with domain\r\n\r\nHere is the code:\r\n\r\n```js\r\nlet d = require('domain').create();\r\n\r\nd.run(async function(){\r\n    console.log(d === process.domain);\r\n    // true\r\n    console.log(1, process.domain);\r\n    // process.domain exists\r\n\r\n    let result = await (async() => {\r\n        return new Promise((resolve) => {\r\n            resolve(\"ok\");\r\n        });\r\n    })();\r\n\r\n    console.log(result, process.domain, d);\r\n    /**\r\n     * result: ok\r\n     * process.domain: undefined\r\n     * d: no change\r\n     */\r\n});\r\n```\r\n\r\nAs shown by the comments, process.domain is undefined after using await. However, If I remove await, the result will be a Promise and process.domain is the same with d.\r\n\r\n\r\nJust like the problem mentioned at https://github.com/nodejs/node/issues/10724. It happened again at node v10.0.0. Please take a look. ",
        "labels": "confirmed-bug",
        "id": 45265
    },
    {
        "title": "REPL on Windows doesn't display console cursor after moving",
        "body": "* **Version**: v10.0.0\r\n* **Platform**: Windows 10\r\n* **Subsystem**: repl?\r\n\r\n### Steps to reproduce the problem:\r\n\r\n1. Open command prompt or powershell\r\n2. Type `node` and then press enter\r\n3. Write some code\r\n4. Press left arrow on the keyboard <kbd>â†</kbd>\r\n5. The console cursor becomes invisible for a second\r\n\r\n### What is the expected behavior?\r\n\r\nThe cursor should be visible immediatelly after moving (to the left or to the right). For example, command prompt automatically displays the cursor after it has been moved. The cursor has blink rate, but after user moves it, it should be visible no matter if at the given moment the blink rate timeout suggest that it should be visible or invisible.\r\n\r\n### What went wrong?\r\n\r\nAfter moving, the cursor becomes hidden. It makes navigating through the code very hard. Users need to wait one second after moving in order to find out where the cursor currently is. Using <kbd>CTRL</kbd>+<kbd>â†</kbd> helps a bit skipping whole words, but it is still very hard to navigate if the code is large.\r\n\r\n### Is it a problem with Node.js itself?\r\n\r\nI am pretty sure it is. The reason I think it is Node.js issue and not issue with command prompt is because other programs which provide REPL functionalities properly display the cursor after moving (reset the cursor blink rate to visible state). For example, Python 3.6 properly handles it.\r\n\r\n### Did this work before?\r\n\r\nI think no.",
        "labels": "confirmed-bug",
        "id": 45266
    },
    {
        "title": "[fs.watch] src\\fs_event_wrap.cc:90: Assertion `wrap != nullptr' failed.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.0.0\r\n* **Platform**: windows 10 (x64) & linux 4.13.0-38-generic (x86_64)\r\n* **Subsystem**: fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nCalling `close()` from `fs.watch` may crash node process. \r\nFrom my test:\r\n\r\n- on Windows 10 will crash every time\r\n- on Linux may crash 20% of the time\r\n\r\nThe minimal reproducible code: (will not crash on node 8 or 9)\r\n\r\n```js\r\nconst { watch, mkdirSync, rmdirSync, existsSync } = require('fs')\r\nconst { join } = require('path')\r\n\r\nconst TEST_ROOT = join(__dirname, 'test-watch-gitignore/')\r\n\r\nexistsSync(TEST_ROOT) || mkdirSync(TEST_ROOT)\r\n\r\nconst watcher = watch(TEST_ROOT, { persistent: false, recursive: false })\r\n\r\nwatcher.addListener('error', () => { // TODO: NOTE: crash on windows node 10, every time\r\n  console.log('error ===============')\r\n  setTimeout(() => { // TODO: NOTE: remove this will stop the crash\r\n    console.log('error setTimeout ===============')\r\n    watcher.close()\r\n    console.log('error done ===============')\r\n  }, 10)\r\n})\r\n\r\nwatcher.addListener('change', () => { // TODO: NOTE: crash on linux node 10, 20% of the time\r\n  console.log('change ===============')\r\n  setTimeout(() => { // TODO: NOTE: remove this will stop the crash\r\n    console.log('change setTimeout ===============')\r\n    watcher.close()\r\n    console.log('change done ===============')\r\n  }, 10)\r\n})\r\n\r\nconsole.log('111 ===============')\r\nrmdirSync(TEST_ROOT)\r\nconsole.log('222 ===============')\r\nsetTimeout(() => {}, 100) // TODO: NOTE: wait for listener to hit\r\nconsole.log('333 ===============')\r\n```\r\n\r\nThe error on Windows:\r\n\r\n    > node .\\test-bug.js\r\n    111 ===============\r\n    222 ===============\r\n    333 ===============\r\n    error ===============\r\n    error setTimeout ===============\r\n    Windows PowerShell[22248]: src\\fs_event_wrap.cc:90: Assertion `wrap != nullptr' failed.\r\n     1: node::DecodeWrite\r\n     2: node::DecodeWrite\r\n     3: node::Start\r\n     4: v8::internal::interpreter::BytecodeDecoder::Decode\r\n     5: v8::internal::RegExpImpl::Exec\r\n     6: v8::internal::RegExpImpl::Exec\r\n     7: v8::internal::Object::ToInt32\r\n     8: v8::internal::Object::GetProperty\r\n     9: v8::internal::NativesCollection<0>::GetScriptsSource\r\n    10: v8::internal::NativesCollection<0>::GetScriptsSource\r\n    11: 00000383BE284281\r\n\r\n\r\nThe error on Linux:\r\n\r\n    $ node test-bug.js \r\n    111 ===============\r\n    222 ===============\r\n    333 ===============\r\n    change ===============\r\n    change ===============\r\n    change setTimeout ===============\r\n    change done ===============\r\n    change setTimeout ===============\r\n    node[14950]: ../src/fs_event_wrap.cc:90:static void node::{anonymous}::FSEventWrap::GetInitialized(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `wrap != nullptr' failed.\r\n     1: node::Abort() [node]\r\n     2: 0x87b6c5 [node]\r\n     3: 0x86a60a [node]\r\n     4: v8::internal::FunctionCallbackArguments::Call(v8::internal::CallHandlerInfo*) [node]\r\n     5: 0xad62fa [node]\r\n     6: v8::internal::Builtins::InvokeApiFunction(v8::internal::Isolate*, bool, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*, v8::internal::Handle<v8::internal::HeapObject>) [node]\r\n     7: v8::internal::Object::GetPropertyWithAccessor(v8::internal::LookupIterator*) [node]\r\n     8: v8::internal::Object::GetProperty(v8::internal::LookupIterator*) [node]\r\n     9: v8::internal::LoadIC::Load(v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Name>) [node]\r\n    10: v8::internal::Runtime_LoadIC_Miss(int, v8::internal::Object**, v8::internal::Isolate*) [node]\r\n    11: 0x12b965e0427d\r\n    Aborted (core dumped)\r\n",
        "labels": "confirmed-bug",
        "id": 45267
    },
    {
        "title": "Node 10.0.0 Object.values() returns incorrect array",
        "body": "* **Version**: v10.0.0\r\n* **Platform**: Darwin Kernel Version 17.5.0: Mon Mar  5 22:24:32 PST 2018; root:xnu-4570.51.1~1/RELEASE_X86_64 x86_64\r\n\r\nTo reproduce the problem, create the following js files:\r\n1. values.js\r\n```js\r\n\"use strict\";\r\nObject.defineProperty(exports, \"__esModule\", { value: true });\r\nclass X {\r\n}\r\nexports.X = X;\r\n```\r\n\r\n2. test.js\r\n```js\r\nconst x = require('./values.js');\r\nconsole.log(x);\r\nconsole.log(Object.values(x));\r\n```\r\n\r\n3. test1.js\r\n```js\r\nconst x = require('./values.js');\r\nconsole.log(Object.values(x));\r\n```\r\n\r\nNow `node test` prints:\r\n```\r\n{ X: [Function: X] }\r\n[]\r\n```\r\n\r\nInterestingly, `node test1` prints:\r\n```\r\n[ [Function: X] ]\r\n```\r\n\r\nPlease note `Object.values(x)` in `test.js` returns `[]`. I expect it to print:\r\n```\r\n{ X: [Function: X] }\r\n[ [Function: X] ]\r\n```\r\n\r\nI tried Node 8.x, both `test` and `test1` work as expected.",
        "labels": "confirmed-bug",
        "id": 45268
    },
    {
        "title": "Different async_hooks behavior in Node 10",
        "body": "* **Version**: v10.0.0\r\n* **Platform**: Linux, Windows 10 WSL\r\n\r\nRunning the following code\r\n\r\n```javascript\r\nconst async_hooks = require(\"async_hooks\");\r\nconst fs = require(\"fs\");\r\n\r\nasync_hooks\r\n  .createHook({\r\n    init: (asyncId, type, triggerAsyncId, resource) => {\r\n      fs.writeSync(1, `${triggerAsyncId} => ${asyncId}\\n`);\r\n    }\r\n  })\r\n  .enable();\r\n\r\nasync function main() {\r\n  console.log(\"hello\");\r\n  await null;\r\n  console.log(\"hello\");\r\n}\r\n\r\nmain();\r\n```\r\n\r\non Node 9 gives the output\r\n\r\n```\r\n1 => 6\r\nhello\r\n1 => 7\r\n6 => 8\r\n8 => 9\r\nhello\r\n9 => 10\r\n```\r\n\r\nwhile on Node 10 it gives\r\n\r\n```\r\n1 => 6\r\nhello\r\n1 => 7\r\n1 => 8\r\nhello\r\n1 => 9\r\n```\r\n\r\nThat is, on Node 10, the `triggerAsyncId` is always 1, and I am unable to track which contexts follow from which other contexts.\r\n\r\nIs one of these unexpected behavior? If the change is a known (undocumented?) new behavior, is there any way with Node 10 to achieve what I was doing under previous versions?",
        "labels": "confirmed-bug",
        "id": 45269
    },
    {
        "title": "node 10.0.0 with ts-node throws a TypeError in isInsideNodeModules when an error is thrown by user code",
        "body": "* **Version**: v10.0.0\r\n* **Platform**:  Darwin bigbird.local 17.5.0 Darwin Kernel Version 17.5.0: Mon Mar  5 22:24:32 PST 2018; root:xnu-4570.51.1~1/RELEASE_X86_64 x86_64\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nAttached sample project (which is a single ts file with just `throw new Error()`) when run via `npm start` fails with:\r\n\r\n```\r\nmdouglass$ npm start\r\n\r\n> temp@1.0.0 start /Users/mdouglass/kixeye/km/server/temp\r\n> ts-node index.ts\r\n\r\ninternal/util.js:360\r\n    const filename = frame.getFileName();\r\n                           ^\r\n\r\nTypeError: frame.getFileName is not a function\r\n    at isInsideNodeModules (internal/util.js:360:28)\r\n    at showFlaggedDeprecation (buffer.js:149:8)\r\n    at new Buffer (buffer.js:174:3)\r\n    at Array.<anonymous> (/Users/mdouglass/kixeye/km/server/temp/node_modules/source-map-support/source-map-support.js:163:21)\r\n    at /Users/mdouglass/kixeye/km/server/temp/node_modules/source-map-support/source-map-support.js:53:24\r\n    at mapSourcePosition (/Users/mdouglass/kixeye/km/server/temp/node_modules/source-map-support/source-map-support.js:185:21)\r\n    at wrapCallSite (/Users/mdouglass/kixeye/km/server/temp/node_modules/source-map-support/source-map-support.js:357:20)\r\n    at /Users/mdouglass/kixeye/km/server/temp/node_modules/source-map-support/source-map-support.js:392:26\r\n    at Array.map (<anonymous>)\r\n    at Function.prepareStackTrace (/Users/mdouglass/kixeye/km/server/temp/node_modules/source-map-support/source-map-support.js:391:24)\r\n```\r\n\r\n[repro-nodejs-10-throw.zip](https://github.com/nodejs/node/files/1944442/repro-nodejs-10-throw.zip)\r\n",
        "labels": "confirmed-bug",
        "id": 45270
    },
    {
        "title": "streamError never emitted",
        "body": "Reading the http/2 compat code it mentions a `streamError` on the server object.\r\n\r\n```js\r\nfunction onStreamError(error) {\r\n  // this is purposefully left blank\r\n  //\r\n  // errors in compatibility mode are\r\n  // not forwarded to the request\r\n  // and response objects. However,\r\n  // they are forwarded to 'streamError'\r\n  // on the server by Http2Stream\r\n}\r\n```\r\n\r\nHowever, this doesn't seem to be emitted anywhere in the code? Is this something that has been removed from core http/2 and has a leftovers in compat and docs?",
        "labels": "confirmed-bug",
        "id": 45271
    },
    {
        "title": "v10.0.0-rc.0 + npm emitting Buffer deprecation warnings",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.0.0-rc.0\r\n* **Platform**: macOS\r\n* **Subsystem**: buffer\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n```console\r\n$ uname -a\r\nREDACTED-HOSTNAME 16.7.0 Darwin Kernel Version 16.7.0: Tue Jan 30 11:27:06 PST 2018; root:xnu-3789.73.11~1/RELEASE_X86_64 x86_64\r\n$ NVM_NODEJS_ORG_MIRROR=https://nodejs.org/download/rc nvm install 10\r\nv10.0.0-rc.0 is already installed.\r\nNow using node v10.0.0-rc.0 (npm v5.6.0)\r\n$ node -v\r\nv10.0.0-rc.0\r\n$ npm -v\r\n5.6.0\r\n$ npm install left-pad\r\n(node:39380) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.\r\nnpm WARN saveError ENOENT: no such file or directory, open '/Users/trott/temp/package.json'\r\nnpm notice created a lockfile as package-lock.json. You should commit this file.\r\nnpm WARN enoent ENOENT: no such file or directory, open '/Users/trott/temp/package.json'\r\nnpm WARN temp No description\r\nnpm WARN temp No repository field.\r\nnpm WARN temp No README data\r\nnpm WARN temp No license field.\r\nnpm WARN You are using a pre-release version of node and things may not work as expected\r\n\r\n+ left-pad@1.3.0\r\nadded 1 package in 0.653s\r\n$ env | grep NODE\r\n$ env  | grep NVM\r\nNVM_CD_FLAGS=\r\nNVM_DIR=/Users/trott/.nvm\r\nNVM_BIN=/Users/trott/.nvm/versions/node/v10.0.0-rc.0/bin\r\n$ which node\r\n/Users/trott/.nvm/versions/node/v10.0.0-rc.0/bin/node\r\n$ which npm\r\n/Users/trott/.nvm/versions/node/v10.0.0-rc.0/bin/npm\r\n$\r\n```\r\n\r\nTurning on trace warnings so we can see what's causing the warning to be emitted:\r\n\r\n```console\r\n$ NODE_OPTIONS='--trace-warnings' npm install left-pad \r\n(node:39545) [DEP0005] DeprecationWarning: Buffer() is deprecated due to security and usability issues. Please use the Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() methods instead.\r\n    at showFlaggedDeprecation (buffer.js:159:11)\r\n    at new Buffer (buffer.js:174:3)\r\n    at Object.<anonymous> (/Users/trott/.nvm/versions/node/v10.0.0-rc.0/lib/node_modules/npm/node_modules/tar/lib/parse.js:33:20)\r\n    at Module._compile (internal/modules/cjs/loader.js:678:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:689:10)\r\n    at Module.load (internal/modules/cjs/loader.js:589:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:528:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:520:3)\r\n    at Module.require (internal/modules/cjs/loader.js:626:17)\r\n    at require (internal/modules/cjs/helpers.js:20:18)\r\n    at Object.<anonymous> (/Users/trott/.nvm/versions/node/v10.0.0-rc.0/lib/node_modules/npm/node_modules/tar/lib/list.js:8:16)\r\n    at Module._compile (internal/modules/cjs/loader.js:678:30)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:689:10)\r\n    at Module.load (internal/modules/cjs/loader.js:589:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:528:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:520:3)\r\nnpm WARN saveError ENOENT: no such file or directory, open '/Users/trott/temp/package.json'\r\nnpm WARN enoent ENOENT: no such file or directory, open '/Users/trott/temp/package.json'\r\nnpm WARN temp No description\r\nnpm WARN temp No repository field.\r\nnpm WARN temp No README data\r\nnpm WARN temp No license field.\r\nnpm WARN You are using a pre-release version of node and things may not work as expected\r\n\r\n+ left-pad@1.3.0\r\nupdated 1 package in 0.64s\r\n$\r\n```\r\n\r\nIt seems to be `/Users/trott/.nvm/versions/node/v10.0.0-rc.0/lib/node_modules/npm/node_modules/tar/lib/parse.js` which should not trigger a warning because it is inside of a `node_modules` directory. The offending line is:\r\n\r\n```js\r\nconst gzipHeader = new Buffer([0x1f, 0x8b])\r\n```\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45272
    },
    {
        "title": "Node 10,  npm gives an EPERM on every operation",
        "body": "Version: v10.0.0-nightly201804175eb9f3c91c\r\nPlatform: Windows 10 64-bit and 32-bit\r\nSubsystem: npm\r\n\r\nBoth node and npm are installed in default location, and on the path.\r\n\r\nThis works as expected in Node 9, which is why I filed an issue here. \r\n\r\nAny npm command results in the following error on several machines:\r\n```\r\nfs.js:111\r\n    throw err;\r\n    ^\r\n\r\nError: EPERM: operation not permitted, open 'C:\\Program Files (x86)\\nodejs\\node_modules\\npm\\bin\\npm-cli.js'\r\n    at Object.fs.openSync (fs.js:545:3)\r\n    at Object.fs.readFileSync (fs.js:451:33)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:688:20)\r\n    at Module.load (internal/modules/cjs/loader.js:589:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:528:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:520:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:719:10)\r\n    at startup (internal/bootstrap/node.js:229:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:576:3)\r\nfs.js:111\r\n    throw err;\r\n    ^\r\n\r\nError: EPERM: operation not permitted, open 'C:\\Program Files (x86)\\nodejs\\node_modules\\npm\\bin\\npm-cli.js'\r\n    at Object.fs.openSync (fs.js:545:3)\r\n    at Object.fs.readFileSync (fs.js:451:33)\r\n    at Object.Module._extensions..js (internal/modules/cjs/loader.js:688:20)\r\n    at Module.load (internal/modules/cjs/loader.js:589:32)\r\n    at tryModuleLoad (internal/modules/cjs/loader.js:528:12)\r\n    at Function.Module._load (internal/modules/cjs/loader.js:520:3)\r\n    at Function.Module.runMain (internal/modules/cjs/loader.js:719:10)\r\n    at startup (internal/bootstrap/node.js:229:19)\r\n    at bootstrapNodeJSCore (internal/bootstrap/node.js:576:3)\r\n```\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45273
    },
    {
        "title": "http2 compat does not emit 'timeout' event on request object",
        "body": "http2 compat does not emit 'timeout' event on request object. It only invokes the `setTimeout` callback argument.",
        "labels": "confirmed-bug",
        "id": 45274
    },
    {
        "title": "difference between http2 Compatibility API and http",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.11.1\r\n* **Platform**: macos\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n```javascript\r\nlet http2 = require('http2');\r\nlet http = require('http');\r\nhttp2.createSecureServer({\r\n\tallowHTTP1: true,\r\n\tcert: `-----BEGIN CERTIFICATE-----\r\nMIICpDCCAYwCCQDchnaEFAYYfzANBgkqhkiG9w0BAQsFADAUMRIwEAYDVQQDDAls\r\nb2NhbGhvc3QwHhcNMTcxMTExMjA1NjQ2WhcNMTcxMjExMjA1NjQ2WjAUMRIwEAYD\r\nVQQDDAlsb2NhbGhvc3QwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDP\r\nCdzfoRXMW4rHYSXqR+exh9PfHkGFe7wF0yT5gPVgt6FdSMsYxbDjE6R3zfKSNSAq\r\nmJfsiN1GRfMmO+tv6Ddvy5J/q9tAJmUxqsWcpe7aOAnWnwXNJSFoawjU2HPmKHzb\r\n+vAYECKwWB9WJvztQrBN6WJnJCo1ffVq6qTEb1NiP0CXW/J8DgymmzP7gKTiSnFy\r\ndTnE2OOSx98ZG/YORGTX1w58mzFRkeIG1BAm3NB6jN4RGNaQoIyAPfInutlUbBSs\r\n2dDrclBdw1gjIFGmPtEL15zEqhxuckCSkM1cJWCnm805ZoqNB7/PxpXrPVOVttiL\r\nuj3B31JYCCpr/fFWpuJ9AgMBAAEwDQYJKoZIhvcNAQELBQADggEBAExF+pAYc0Kq\r\nejSiNxu4Ae5T5XLXOCFSGHRjHwE/Wpud0SqJIrLAAm6VfyU/MDvEIUlwfnHaHpyL\r\n/j+1JNCLlMPcCY81k3CM3FrgnYit9ImU9ni3DU+c23zdMrkiF1bgQZBdbg2gzqgy\r\n8yq2Ws72a6i0S8odCQ4/inCall3D9c64sefE9LocLTEBrTQDYp+bg6+RX7QKdmE6\r\n6dkYm4oQOeB1lb0IdV+YSKz/bkypFPA0KY5dtpsoPK8TpwwUzg9cbnvXo0gKMbR3\r\nqY8JmgsajfMbbynqR88kFHbtHOISC/XtmlObxSA+CqCKrI+f9ljc+wADPkF+rqxX\r\nGs1T2qkuJ6g=\r\n-----END CERTIFICATE-----`,\r\n\tkey: `-----BEGIN PRIVATE KEY-----\r\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDPCdzfoRXMW4rH\r\nYSXqR+exh9PfHkGFe7wF0yT5gPVgt6FdSMsYxbDjE6R3zfKSNSAqmJfsiN1GRfMm\r\nO+tv6Ddvy5J/q9tAJmUxqsWcpe7aOAnWnwXNJSFoawjU2HPmKHzb+vAYECKwWB9W\r\nJvztQrBN6WJnJCo1ffVq6qTEb1NiP0CXW/J8DgymmzP7gKTiSnFydTnE2OOSx98Z\r\nG/YORGTX1w58mzFRkeIG1BAm3NB6jN4RGNaQoIyAPfInutlUbBSs2dDrclBdw1gj\r\nIFGmPtEL15zEqhxuckCSkM1cJWCnm805ZoqNB7/PxpXrPVOVttiLuj3B31JYCCpr\r\n/fFWpuJ9AgMBAAECggEABZxO0ACdhpw0dpK7ZE3uiXEU3McFH4jq332JUvmbrLNN\r\nPCns1w8EbCLsIhMCr9Ogu4bHFzHeTTk4DaEyECZK2ky5+5u8pVBlDaODF2unvWIn\r\nYhmNHrIS5bGA28PB4ErYl12FhCFrzzuUHdGQqR1Vicb5U7I3MpvnOq6BKJGbwN3J\r\nZyEhlZ9MirbAQa12yv5h3827RkLeFXqzmxMHzKgT8VXbQwenZ3HzhwZ5jNd65g6M\r\nyhBQw9tJvwjapm/gj66DpVdV9gJhzi5TBdRsIe5yu+QVInN0FKPCH7mpIfy3I+j4\r\n0uYIXr/DLjv6sok6zQqvICQrhRwCQ557qsmGc5V8AQKBgQD/H/+iKzpqNgHYrgmF\r\nROPlb8bAVFslqKjKWiH7q6wUV2htQ6+S9giWxbmUXb5j2qG26YaEtPIcm+g5LEXm\r\nOx9MQjhNEeQIhb6KH5ghHrIDxqQNT2+sR49VbR3Y+OL6oBxFOv00nwg/h8KBK9NN\r\n/asR15NmCka36OMwVinlr1xujQKBgQDPv6TcBuXF5b77h3OYoURnXv2ZJvULIDTV\r\npKaJa9Z/k8bCiTiHbKNjVGsfDijXEd82Dp6YwJMbYIAlexewR48vpQMOnGOkA9Hk\r\nemMBfMy0t4i+8tZTT0UdYgVICsbZQSO/8L0LcEkGVfmRgJPrUhDw9o9AeD2YLnXM\r\n7d9mBCD/sQKBgQDxhf6BLQFpKWXIFsLGmrhRLedvjqyXUzswDfIcCqKmwzUGM8zU\r\niP0Kl3cfwTuL1p+/xQZnPdHzSZmn/oTR9+iiThJ0y9ogQ1Vl95ES0bdfIb+PJkOn\r\nSjukeN+H198xuz/oPncVSPULB+AYXz/0lpBMHNTbBiF63AuwZ/HUEpajxQKBgH8f\r\nz1rQYbQaZSZ3eVXxgPEcYGRiQVpgh9Qf38SBl40TuXF7FHtSEB0NIEutl3IbvpHO\r\nml/wn1QGVgQZcaJt94F5IQjEy/gmWj7MYV8cpgsDsArggCQUgr97Jq4x4gI5aQ3f\r\n215vhE/7Ni9CFcHOww0gYwJZUZ+Y9n7DJIvBhQvRAoGBAP68uVfOB7oVV3z9K6G+\r\noJHntre6Za8deemnksM/5H4/k4Kedl+RIMExhLsAypaP0aIZPW29Mwv3eT19ciUm\r\ng6KrdhUNWvbNhryyg//VYnDLQi0FnGr+oZDQNhGxNdWXjxOBBTVxe4Z16CEDgIXI\r\nPwz9a9ZgvBd2si5/cMwM6aOe\r\n-----END PRIVATE KEY-----`\r\n}, onmessage).listen(1234);\r\nhttp.createServer(onmessage).listen(5678);\r\n\r\nfunction onmessage(req, res){\r\n\tif (req.method === 'GET') {\r\n\t\tres.writeHead(200, {\r\n\t\t\t'content-type': 'text/html'\r\n\t\t});\r\n\t\tres.end(`<!DOCTYPE html>\r\n<html>\r\n\t<head>\r\n\t\t<meta charset=\"utf-8\"/>\r\n\t\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"/>\r\n\t\t<meta name=\"format-detection\" content=\"telephone=no\"/>\r\n\t\t<title>fusion-backend</title>\r\n\t</head>\r\n\t<body>welcome\r\n\t\t<input type=\"file\"/>\r\n\t\t<script>\r\n\t\t\tdocument.querySelector('input').addEventListener('change', function() {\r\n\t\t\t\tif (this.files.length) {\r\n\t\t\t\t\tlet x = new XMLHttpRequest();\r\n\t\t\t\t\tx.open('put', '/images/' + this.files[0].name, true);\r\n\t\t\t\t\tx.onreadystatechange = function() {\r\n\t\t\t\t\t\tif (this.readyState === 4 && this.status === 200) {\r\n\t\t\t\t\t\t\talert(this.responseText);\r\n\t\t\t\t\t\t}\r\n\t\t\t\t\t};\r\n\t\t\t\t\tx.send(this.files[0]);\r\n\t\t\t\t\tthis.value = '';\r\n\t\t\t\t}\r\n\t\t\t});\r\n\t\t</script>\r\n\t</body>\r\n</html>`);\r\n\t} else {\r\n\t\tres.writeHead(405);\r\n\t\tres.end();\r\n\t}\r\n}\r\n```\r\nchoose a file bigger then 100k you'll see http1 returns 405 immediately, but http2 never return any thing.",
        "labels": "confirmed-bug",
        "id": 45275
    },
    {
        "title": "Investigate flaky parallel/test-http-server-keep-alive-timeout",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.0.0-pre (master)\r\n* **Platform**: freebsd10-64\r\n* **Subsystem**: test http\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nhttps://ci.nodejs.org/job/node-test-commit-freebsd/16985/nodes=freebsd10-64/console\r\n\r\n```console\r\nnot ok 783 parallel/test-http-server-keep-alive-timeout\r\n  ---\r\n  duration_ms: 2.29\r\n  severity: fail\r\n  exitcode: 1\r\n  stack: |-\r\n    Mismatched <anonymous> function calls. Expected exactly 3, actual 1.\r\n        at Object.exports.mustCall (/usr/home/iojs/build/workspace/node-test-commit-freebsd/nodes/freebsd10-64/test/common/index.js:427:10)\r\n        at serverEndKeepAliveTimeoutWithPipeline (/usr/home/iojs/build/workspace/node-test-commit-freebsd/nodes/freebsd10-64/test/parallel/test-http-server-keep-alive-timeout.js:22:43)\r\n        at run (/usr/home/iojs/build/workspace/node-test-commit-freebsd/nodes/freebsd10-64/test/parallel/test-http-server-keep-alive-timeout.js:18:11)\r\n        at process._tickCallback (internal/process/next_tick.js:172:11)\r\n        at Function.Module.runMain (internal/modules/cjs/loader.js:721:11)\r\n        at startup (internal/bootstrap/node.js:228:19)\r\n        at bootstrapNodeJSCore (internal/bootstrap/node.js:575:3)\r\n  ...\r\n```",
        "labels": "confirmed-bug",
        "id": 45276
    },
    {
        "title": "Node read stream hangs on specific file, base64 encoding",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 7.9.0/8.9.3/9.7.1\r\n* **Platform**: Windows/Linux/MacOS\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI have following code working for every file except the one that keeps hanging without emitting `end` or `error` events (I tried other stream events too).\r\n\r\n```javascript\r\nconst fs = require('fs');\r\n\r\nconst rs = fs.createReadStream(filePath, {\r\n    encoding: 'base64',\r\n});\r\n\r\nrs.on('data', () => {\r\n    console.log('data');\r\n});\r\nrs.on('end', () => {\r\n    console.log('end');\r\n});\r\nrs.on('error', e => {\r\n    console.log('error', e);\r\n});\r\n```\r\n\r\nIf I move read point with `start` option to 1 instead of 0 it works properly. Same if `highWaterMark` is set to value other than default. It doesn't really help as it seems it can fail with other \"corrupted\" file.\r\n\r\nIt seems like Node bug, but maybe there's something I'm missing here.\r\n\r\nHere's file to recreate the issue:\r\nhttp://s3.eu-west-1.amazonaws.com/jjapitest/file\r\n\r\nHere's interactive demo of the issue:\r\nhttps://repl.it/repls/AnimatedDisguisedNumerator\r\n",
        "labels": "confirmed-bug",
        "id": 45277
    },
    {
        "title": "Missing useful debug information for Dynamic Import errors",
        "body": "Hello there, \r\n\r\nNode: v9.10.1\r\nPlatform: Darwin MACLTUS44977 15.6.0 Darwin Kernel Version 15.6.0\r\n\r\n```\r\n// problem.mjs\r\nconst foo = () => {\r\n  await bar()\r\n}\r\n```\r\nSo \"problem.mjs\" has an issue, which is that it is using the \"await\" keyword inside a non \"async\" function.\r\n\r\nIf you try to run this file as an entry in node or regular import, a very helpful error is thrown as expected:\r\n```\r\n// \"node --experimental-modules problem.mjs\" or \"import problem from './problem.mjs'\"\r\nfile:///Users/ctsuser1/Desktop/projects/problem.mjs:2\r\n  await bar()\r\n  ^^^^^\r\nSyntaxError: Unexpected reserved word\r\n    at translators.set (internal/loader/Translators.js:27:13)\r\n    at <anonymous>\r\n```\r\n\r\nBut... if you try to \"dynamically\" import \"problem.mjs\", it throws a completely useless error:\r\n```\r\nSyntaxError: Unexpected reserved word\r\n    at translators.set (internal/loader/Translators.js:27:13)\r\n    at <anonymous>\r\n```\r\n\r\nIs this a bug? How can this be resolved? It's impossible to debug this way. Thanks in advance!\r\n",
        "labels": "confirmed-bug",
        "id": 45278
    },
    {
        "title": "assert.rejects passes if the given function throws synchronously",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: Built from source off of latest master, df62e69de73f4fb199f3b88727d13f6c52de332a. (This API has not appeared in a release yet.)\r\n* **Platform**: macOS\r\n* **Subsystem**: assert\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe following code prints `assertion passed`:\r\n\r\n```js\r\nconst assert = require('assert');\r\n\r\nfunction functionThatThrows() {\r\n  throw new Error();\r\n}\r\n\r\nassert.rejects(functionThatThrows).then(\r\n  () => console.log('assertion passed'),\r\n  () => console.log('assertion failed')\r\n);\r\n```\r\n\r\nThis is unexpected because I would expect `assert.rejects` to check that the given function returns a Promise which eventually rejects. In this case, no Promise is returned at all, so there is nothing that \"rejects\".\r\n\r\nFrom an ergonomics perspective, if I were writing a function which could return a rejected Promise, I would want to always return a Promise to indicate errors, rather than sometimes throwing synchronously. If my function did throw synchronously rather than rejecting, this would be incorrect behavior and I would expect `assert.rejects` to report the error.",
        "labels": "confirmed-bug",
        "id": 45279
    },
    {
        "title": "streams: backpressure is broken in multi push cases on master",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master (eeb57022e6)\r\n* **Platform**: Linux\r\n* **Subsystem**: streams\r\n\r\nTry out the following test case with a fast readable stream, and a slow writable one that are piped together. There seems to be a bug in master where the readable one is not backpressured properly when multiple pushes are done in the read fn.\r\n\r\n``` js\r\nvar stream = require('stream')\r\n\r\nvar rs = stream.Readable({\r\n  read: function () {\r\n    this.push(Buffer.alloc(65500))\r\n    for (var i = 0; i < 40; i++) {\r\n      this.push(Buffer.alloc(1024))\r\n    }\r\n  }\r\n})\r\n\r\nvar ws = stream.Writable({\r\n  write: function (data, enc, cb) {\r\n    setTimeout(cb, 10)\r\n  }\r\n})\r\n\r\nsetInterval(function () {\r\n  const state = rs._readableState\r\n  console.log('state.length %d, state.buffer.length %d, state.hwm %d', state.length, state.buffer.length, state.highWaterMark)\r\n}, 1000)\r\n\r\nrs.pipe(ws)\r\n```\r\n\r\nNotice how the internal buffer just keeps growing\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "confirmed-bug",
        "id": 45280
    },
    {
        "title": "url library behaves unexpectedly when attempting to set a url's port to a large number",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.8.0\r\n* **Platform**: Linux 4.4.0-31-generic #50~14.04.1-Ubuntu SMP Wed Jul 13 01:07:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: url\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n`const {URL} = require('url');`\r\n`let url = new URL('http://127.0.0.1');`\r\n`url.port // -> ''`\r\n`url.port = 2.12323232e88;`\r\n`url.port // -> '2'`",
        "labels": "confirmed-bug",
        "id": 45281
    },
    {
        "title": "`url.format` does not have same behavior for pathnames with and without slashes",
        "body": "Using Node@9.9 on OSX.\r\n\r\n## Problem\r\n\r\n`url.format` returns an usable result when `pathname` is not slash prefixed:\r\n\r\n```\r\n> const url = require('url')\r\n> url.format({hostname: 'dougbeck.me', pathname: 'womp.html'})\r\n'dougbeck.mewomp.html'\r\n```\r\n\r\n## Expectation\r\n\r\n`pathname` is treated the same with or without the leading / (slash)\r\n\r\nConversation started here: https://github.com/nodejs/help/issues/1176",
        "labels": "confirmed-bug",
        "id": 45282
    },
    {
        "title": "Breaking change in path normalizeString in node 9.9.0",
        "body": "I believe #19237 to be the culprit of this change.\r\n\r\nI believe that PR unintentionally changed the behaviour of at least `path.resolve` which was not documented in the changelog.\r\n\r\nWe have a specific test around `path.resolve` and it started failing after 9.9.0 was released. See https://travis-ci.org/thelounge/thelounge/jobs/356475798#L582\r\n\r\nhttps://github.com/thelounge/thelounge/blob/844ca1fbe602aa291b54085a6cf69198ea4a5390/test/src/helperTest.js#L14-L16\r\n\r\nOn 9.8.0 this happens:\r\n```\r\n> require(\"path\").resolve(\"a\\\\b\")\r\n'/home/xpaw/a\\\\b'\r\n```\r\n\r\nBut on 9.9.0 it seems that separator is changed to the OS specific one.\r\n```\r\n> require(\"path\").resolve(\"a\\\\b\")\r\n'/home/xpaw/a/b'\r\n```",
        "labels": "confirmed-bug",
        "id": 45283
    },
    {
        "title": "Unnecessary TypeError from util.inspect(Object.setPrototypeOf(function() {}, null))",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v8.9.4\r\n* **Platform**: Linux stola-ThinkPad 3.16.0-38-generic #52~14.04.1-Ubuntu SMP Fri May 8 09:43:57 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: util\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`util.inspect(Object.setPrototypeOf(function() {}, null))` results in\r\n```\r\nTypeError: Cannot read property 'name' of null\r\n    at formatValue (util.js:523:35)\r\n    at Object.inspect (util.js:324:10)\r\n```\r\nNote that this is the code that is used by REPL to print the result of `Object.setPrototypeOf(function() {}, null)` expression.\r\n\r\nThis `TypeError` is confusing and unnecessary. It comes from `constructor.name` in `util.js:523`. Few lines above (line 457) there is `const ctorName = ...` code that attempts to avoid problems like this, i.e., it would be sufficient to use `ctorName` instead of `constructor.name` on line 523.",
        "labels": "confirmed-bug",
        "id": 45284
    },
    {
        "title": "internal check macros don't work",
        "body": "This code:\r\n```js\r\nCHECK_NE(addressType, undefined);\r\n```\r\n\r\nIs transformed to:\r\n```js\r\nCHECK((addressType) !== (undefined));\r\n```\r\n\r\nThis results in a runtime `ReferenceError: CHECK is not defined`. Macros should be expanded recursively.\r\n\r\n/cc @devsnek",
        "labels": "confirmed-bug",
        "id": 45285
    },
    {
        "title": "Write EPROTO error on Node 8 and above",
        "body": "I'm getting EPROTO errors on Node 8 and above\r\n\r\n## Test code `test.js`\r\n\r\n```js\r\nvar https = require('https');\r\nvar fs = require('fs');\r\n\r\nconsole.log('Node', process.version);\r\n\r\nvar writeStream = fs.createWriteStream('test.html');\r\nwriteStream.on('finish', function () {\r\n  console.log('Finish');\r\n})\r\n\r\nhttps.get('https://handbrake.fr/nightly.php', function (res) {\r\n  res.pipe(writeStream);\r\n});\r\n```\r\n\r\n## Test by version\r\n\r\n### v4\r\n```\r\n$ node test.js\r\nNode v4.8.7\r\nFinish\r\n```\r\n\r\n### v5\r\n```\r\n$ node test.js\r\nNode v5.12.0\r\nFinish\r\n```\r\n\r\n### v6\r\n```\r\n$ node test.js\r\nNode v6.13.1\r\nFinish\r\n```\r\n\r\n### v7\r\n```\r\n$ node test.js\r\nNode v7.10.1\r\nFinish\r\n```\r\n\r\n### v8\r\n```\r\n$ node test.js\r\nNode v8.10.0\r\nevents.js:183\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: write EPROTO 101057795:error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake failure:openssl\\ssl\\s23_clnt.c:802:\r\n\r\n    at _errnoException (util.js:1022:11)\r\n    at WriteWrap.afterWrite [as oncomplete] (net.js:880:14)\r\n```\r\n\r\n### v9\r\n```\r\n$ node test.js\r\nNode v9.8.0\r\nevents.js:165\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: write EPROTO 101057795:error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert handshake failure:openssl\\ssl\\s23_clnt.c:802:\r\n\r\n    at WriteWrap.afterWrite [as oncomplete] (net.js:841:14)\r\nEmitted 'error' event at:\r\n    at TLSSocket.socketErrorListener (_http_client.js:394:9)\r\n    at TLSSocket.emit (events.js:180:13)\r\n    at onwriteError (_stream_writable.js:427:12)\r\n    at onwrite (_stream_writable.js:449:5)\r\n    at _destroy (internal/streams/destroy.js:39:7)\r\n    at TLSSocket.Socket._destroy (net.js:545:3)\r\n    at TLSSocket.destroy (internal/streams/destroy.js:32:8)\r\n    at WriteWrap.afterWrite [as oncomplete] (net.js:843:10)\r\n```\r\n\r\n---\r\n\r\n**Version**: 4-9 (arch. 64-bit) (listed in console log above)\r\n**Platform**: Windows 10 (64-bit)\r\n",
        "labels": "confirmed-bug",
        "id": 45286
    },
    {
        "title": "Potential memory leak in fs::WriteString",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master\r\n* **Subsystem**: fs\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI have not verified it yet, just discovered this when I went through the comments in node_file.cc to see if there is anything to update.\r\n\r\nhttps://github.com/nodejs/node/blob/040dd244de14f51b4757c25311164e36f72238c3/src/node_file.cc#L1389-L1391\r\n\r\nLooks like in the async case, if the buffer was copied instead of being moved (in the external string cases up there), then the `buf` will not get deleted after the request is done. This seems to be introduced when the `FSReqWrap:: Ownership` was removed in https://github.com/nodejs/node/commit/4b9ba9b83390f351d4a9f32ffef7730f87b17d2b\r\n, and `ReleaseEarly` was no longer called upon destruction of `FSReqWrap`.\r\n\r\nI am trying to come up with a fix, opening an issue in case this gets lost.",
        "labels": "confirmed-bug",
        "id": 45287
    },
    {
        "title": "Array.concat breaks when extending the Array to custom class using ES6 classes",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.9.3\r\n* **Platform**: Ubuntu 16.04 64-bit\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n``` js\r\nclass MyArray extends Array {};\r\n\r\nlet myArray = new MyArray(6);\r\nmyArray = myArray.concat(new MyArray(5));\r\n\r\nlet array = new Array(6);\r\narray = array.concat(new Array(5));\r\n\r\nconsole.log('myArray length: ', myArray.length);\r\nconsole.log('array length: ', array.length);\r\n```\r\n\r\nActual output:\r\n\r\n```\r\nmyArray length:  0\r\narray length:  11\r\n```\r\n\r\nExpected output:\r\n```\r\nmyArray length:  11\r\narray length:  11\r\n```\r\n\r\n**FEW NOTES:**\r\n\r\n- Actual and expected output match when run with `node v10.0.0-pre`\r\n-  Actual and expected output match when run in the chrome V8 console",
        "labels": "confirmed-bug",
        "id": 45288
    },
    {
        "title": "fsPromises.readFile ignores encoding option",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.0.0-nightly20180309099e621648\r\n* **Platform**: Win10 x64\r\n* **Subsystem**: ?\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n```\r\nvar fs = require('fs/promises'); \r\nfs.readFile(path,\"utf8\").then((data)=>...\r\n```\r\n\r\n**data** will be of type string, when specifying the encoding in the method call, but with the latest version (**v10.0.0-nightly20180309099e621648**) I have to `data.toString(\"utf8\")` **again**, to get the result as string.\r\n\r\nBy design?",
        "labels": "confirmed-bug",
        "id": 45289
    },
    {
        "title": "tools: strange linting issue",
        "body": "* **Version**: master\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: tools\r\n\r\nThe case of drive letter (i.e. `j:` vs `J:`) causes different behavior. Moreover, this difference is opposite in various shells.\r\n\r\n`cmd.exe`:\r\n```console\r\nj:\\temp\\_git\\node-fork> node j:/temp/_git/node-fork/tools/node_modules/eslint/bin/eslint.js .eslintrc.js\r\n\r\n[no errors]\r\n\r\nj:\\temp\\_git\\node-fork> node J:/temp/_git/node-fork/tools/node_modules/eslint/bin/eslint.js .eslintrc.js\r\n\r\nj:\\temp\\_git\\node-fork\\.eslintrc.js\r\n  1:1  error  Definition for rule 'node-core/no-unescaped-regexp-dot' was not found  node-core/no-unescaped-regexp-dot\r\n\r\nâœ– 1 problem (1 error, 0 warnings)\r\n```\r\n\r\nGit Bash:\r\n```console\r\nvmb@vmb-nb MINGW64 /j/temp/_git/node-fork (master)\r\n$ node j:/temp/_git/node-fork/tools/node_modules/eslint/bin/eslint.js .eslintrc.js\r\n\r\nJ:\\temp\\_git\\node-fork\\.eslintrc.js\r\n  1:1  error  Definition for rule 'node-core/no-unescaped-regexp-dot' was not found  node-core/no-unescaped-regexp-dot\r\n\r\nâœ– 1 problem (1 error, 0 warnings)\r\n\r\nvmb@vmb-nb MINGW64 /j/temp/_git/node-fork (master)\r\n$ node J:/temp/_git/node-fork/tools/node_modules/eslint/bin/eslint.js .eslintrc.js\r\n\r\n[no errors]\r\n```\r\n\r\ncc @nodejs/linting @nodejs/platform-windows ",
        "labels": "confirmed-bug",
        "id": 45290
    },
    {
        "title": "kIncomingMessage undefined for socket.server",
        "body": "after upgrading to node 9.7 some existing code started crashing when calling socket.emit('data', data)\r\n\r\nthe socket was created by net/Server, and later added to an httpServer through httpServer.emit('connection', socket)\r\n\r\nI understand that the usage may be a bit hacky, but this was how some third party library implemented a hybrid server (one that takes both tcp & ws connections)",
        "labels": "confirmed-bug",
        "id": 45291
    },
    {
        "title": "'close' event called before 'end' in paused stream",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **v8.9.4**:\r\n* **Linux tufopad 4.13.0-32-generic #35~16.04.1-Ubuntu SMP Thu Jan 25 10:13:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux**:\r\n* **stream**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI believe I've found an akward behaviour of a **stream in paused mode** using the `net` module. In some specific cases, when the source socket ends, the `close` event is called before the `end` event in the destination socket. I've been able to reproduce it simulating the callback queue with nested setImmediates.\r\n\r\n**Server**\r\n```\r\n'use strict';\r\n                               \r\nconst net = require('net');    \r\n\r\nlet n=0;                       \r\n\r\nconst opts = {                 \r\n  host: '127.0.0.1',\r\n  port: 1100\r\n};\r\n  \r\nconst server = net.createServer(s => {\r\n  let id = n++;                \r\n  s.setEncoding('utf8');       \r\n  s.on('readable', () => {\r\n    setImmediate(() => \r\n      setImmediate(() => \r\n        setImmediate(() =>\r\n          setImmediate(() => s.read()))));\r\n  });\r\n  s.on('end', () => console.trace(`Socket ${id} END`));\r\n  s.on('close', () => console.trace(`Socket ${id} CLOSE`));\r\n});\r\n\r\nserver.listen(opts, console.info.bind(null, 'server listening', opts));\r\n```\r\nI've tried with two clients.\r\n\r\n**Client 1** (bash)\r\n`$ echo EVENT | nc localhost 1100`\r\n\r\n**Client 2** (node)\r\n```\r\n'use strict';\r\n\r\nconst net = require('net');\r\n\r\nlet n=0;\r\n\r\nfunction runOnce() { \r\n  const s = net.connect(1100, () => { \r\n    console.info('Connected', n++);\r\n    s.write('EVENT', () => { \r\n      s.end();\r\n    });\r\n  });\r\n  return new Promise(ok => { \r\n    s.on('close', ok)\r\n  })\r\n}\r\n\r\nasync function run(times) {\r\n  for (let i=0; i<times; i++) { \r\n    await runOnce();\r\n  }\r\n}\r\n\r\nrun(10);\r\n```\r\nIt consistently \"fails\" with both, \"fail\" meaning that the `close` event is called before the `end` event. According to the documentation this should never happen.\r\n\r\n> The 'close' event is emitted when the stream and any of its underlying resources (a file descriptor, for example) have been closed. The event indicates that **no more events** will be emitted, and no further computation will occur.\r\n\r\n**NOTE:** The number of `setImmediate`s that you need to nest in order to make it \"fail\" may vary depending on your environment.",
        "labels": "confirmed-bug",
        "id": 45292
    },
    {
        "title": "Error: couldn't open node-v9.7.0.pkg",
        "body": "\r\n\r\n9.7.0:\r\nmacOS:\r\nhttps://nodejs.org/dist/v9.7.0/node-v9.7.0.pkg\r\n\r\nI am receiving the following error when I try to run the macOS installer for Node.js 9.7.0.\r\n\r\n```\r\nThe operation couldnâ€™t be completed. (com.apple.installer.pagecontroller error -1.)\r\n\r\ncouldn't open node-v9.7.0.pkg\r\n```",
        "labels": "confirmed-bug",
        "id": 45293
    },
    {
        "title": "Segmentation fault in http2 module when cancelling download in Chrome",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.5.0, v9.6.1, and v10.0.0-pre commit 743f890\r\n* **Platform**: linux 64-bit (kernel 4.4.0-116-generic from Ubuntu)\r\n* **Subsystem**: http2\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nSteps to reproduce:\r\n1. Serve a file from Node.js to Chrome using the `http2` module\r\n2. Cancel the download from Chrome\r\n\r\nI have not been able to reproduce this problem locally, however.\r\n\r\nThis was the stacktrace which was generated by node-segfault-handler (Node.js v9.5.0):\r\n```\r\nPID 1371 received SIGSEGV for address: 0x0\r\n/home/iczero/prj/buildserver/node_modules/segfault-handler/build/Release/segfault-handler.node(+0x1acd)[0x7fccc33beacd]\r\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x11390)[0x7fccc59a0390]\r\nnode(_ZN4node5http212Http2Session22OnStreamAfterWriteImplEPNS_9WriteWrapEiPv+0x55)[0x90f4b5]\r\nnode(_ZN4node10StreamBase10AfterWriteEPNS_9WriteWrapEi+0xa0)[0x94c330]\r\nnode(_ZN4node7TLSWrap6EncOutEv+0xc5)[0x999075]\r\nnode(_ZN4node10StreamBase10AfterWriteEPNS_9WriteWrapEi+0xa0)[0x94c330]\r\nnode(_ZN4node15LibuvStreamWrap10AfterWriteEPNS_9WriteWrapEi+0x1b)[0x9502cb]\r\nnode(_ZN4node15LibuvStreamWrap12AfterUvWriteEP10uv_write_si+0x54)[0x950f14]\r\nnode[0x14240b9]\r\nnode[0x1424d74]\r\nnode[0x142ac58]\r\nnode(uv_run+0x156)[0x1419676]\r\nnode(_ZN4node5StartEP9uv_loop_siPKPKciS5_+0x4bd)[0x8d49ed]\r\nnode(_ZN4node5StartEiPPc+0x153)[0x8d12d3]\r\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7fccc55e5830]\r\nnode[0x89d7e1]\r\n```\r\nRelevant symbols demangled:\r\n```\r\nnode::http2::Http2Session::OnStreamAfterWriteImpl(node::WriteWrap*, int, void*)\r\nnode::StreamBase::AfterWrite(node::WriteWrap*, int)\r\nnode::TLSWrap::EncOut()\r\nnode::StreamBase::AfterWrite(node::WriteWrap*, int)\r\nnode::LibuvStreamWrap::AfterWrite(node::WriteWrap*, int)\r\nnode::LibuvStreamWrap::AfterUvWrite(uv_write_s*, int)\r\n```\r\n\r\nA small script that causes the segfault:\r\n```js\r\nconst http2 = require('http2');\r\nconst fs = require('fs');\r\n\r\nconst FILE = '/usr/bin/node';\r\n\r\n// generate a self-signed cert first:\r\n// $ openssl req -newkey rsa:2048 -nodes -keyout key.pem -x509 -days 365 -out cert.pem\r\n\r\nlet server = http2.createSecureServer({\r\n  key: fs.readFileSync('./key.pem'),\r\n  cert: fs.readFileSync('./cert.pem')\r\n}, async (request, response) => {\r\n  console.log('a request!');\r\n  fs.createReadStream(FILE).pipe(response);\r\n});\r\nserver.listen(9998);\r\n```",
        "labels": "confirmed-bug",
        "id": 45294
    },
    {
        "title": "parallel/test-http-connect broken on master",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master (2b7f920e26171f05fac437d867a30209f57c6bad)\r\n* **Platform**: all\r\n* **Subsystem**: http, test\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n```\r\n=== release test-http-connect ===\r\nPath: parallel/test-http-connect\r\nassert.js:74\r\n  throw new AssertionError(obj);\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: 2 strictEqual 1\r\n    at Server.server.on.common.mustCall (/Users/Jeremiah/Documents/node/test/parallel/test-http-connect.js:37:10)\r\n    at Server.<anonymous> (/Users/Jeremiah/Documents/node/test/common/index.js:476:15)\r\n    at Server.emit (events.js:129:13)\r\n    at onParserExecuteCommon (_http_server.js:536:14)\r\n    at onParserExecute (_http_server.js:483:3)\r\n```\r\n\r\ncc @BridgeAR who says he's on it.",
        "labels": "confirmed-bug",
        "id": 45295
    },
    {
        "title": "Coverage broken",
        "body": "https://coverage.nodejs.org/ displays nothing new since nine days. I feel something has gone wrong here?\r\n\r\n/cc @mhdawson ",
        "labels": "confirmed-bug",
        "id": 45296
    },
    {
        "title": "HTTP Client 'aborted' event fires even when request was ok",
        "body": "* **Version**: all versions from 4.x - > 9.x\r\n* **Platform**: Linux/Ubuntu 16.04 x64\r\n* **Subsystem**: http/https\r\n\r\nWe have been having issues with http/https downloads failing silently and the file being downloaded having an incorrect size for some time now. We are using axios library to do download and after some research and testing the only way we could get alerted about an incomplete download (connection is forcibly closed by server in middle of downloading body) was to handle the http response \"aborted\" event.\r\n\r\nHowever, when we handled this we noticed we were having good downloads, where file contents were completely received, reported as \"aborted\".\r\n\r\nMaybe this is intended behaviour but it makes more sense to me to only receive aborted event on a client response if the socket close happened before the active http response has been received completely. Currently, there is [no check](https://github.com/nodejs/node/blob/v8.9.4/lib/_http_client.js#L351) for the current active response having completed or not before firing the aborted event.\r\n\r\nYou can see the behaviour in this [gist](https://gist.github.com/billywhizz/b500a0d4708f89625ddbb313601b5363) - the firing of the aborted event seems completely random and is likely due to timing of when the server closes the socket.\r\n\r\nOur workaround is to use the commented code [here](https://gist.github.com/billywhizz/b500a0d4708f89625ddbb313601b5363#file-abort-stream-js-L22) to check if the current response is complete and ignore the aborted event if so.\r\n\r\nShould the same logic be used in node.js core? Appreciate this could cause issues for existing libraries depending on current behaviour.",
        "labels": "confirmed-bug",
        "id": 45297
    },
    {
        "title": "require does not work as described in the documentation",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **v9.5.0**:\r\n* **Windows 10 Pro 64-bit**:\r\n* **modules**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nI have this file structure:\r\n![image](https://user-images.githubusercontent.com/21264991/36063143-538ff8bc-0e92-11e8-91a3-9a8a083e8fb7.png)\r\n\r\n- app.js\r\n`console.log( require.resolve('./hello') );`\r\n\r\n- package.json\r\n`{\r\n  \"main\": \"test\"\r\n}`\r\n\r\nother files are empty.\r\n\r\nrun: `node app.js`\r\n\r\nif rely on the documentation **require** should find file underlined in the picture below:\r\n![image](https://user-images.githubusercontent.com/21264991/36063243-a417a356-0e93-11e8-83a6-ac63dfd59bf0.png)\r\n**hello.js**\r\n\r\nbut it finds this:\r\n![image](https://user-images.githubusercontent.com/21264991/36063237-9640bdc6-0e93-11e8-981e-474835a5ab59.png)\r\n**test.js**\r\n\r\nIt should find file in step **3.a** but it finds in step **3.b**\r\n![image](https://user-images.githubusercontent.com/21264991/36063327-023ddab2-0e95-11e8-8309-47b3d3c02cd5.png)\r\n",
        "labels": "confirmed-bug",
        "id": 45298
    },
    {
        "title": "Stack overflow in fs.readdirSync causes fatal error",
        "body": "* **Version**: v9.5.0\r\n* **Platform**: Linux sujin 4.4.0-101-generic # 124-Ubuntu SMP Fri Nov 10 18:29:59 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\nThe following code causes node to abort with `FATAL ERROR` on my system, when I would expect it to throw a \"RangeError: Maximum call stack size exceeded\" instead.\r\n\r\n```js\r\nlet fs = require(\"fs\");\r\nfunction f() {\r\n  fs.readdirSync(\".\");\r\n  f();\r\n}\r\nf();\r\n```\r\n\r\n```\r\n$ node readdir-sync-bug.js\r\nFATAL ERROR: v8::ToLocalChecked Empty MaybeLocal.\r\n 1: node::Abort() [node]\r\n 2: 0x8c807c [node]\r\n 3: v8::Utils::ReportApiFailure(char const*, char const*) [node]\r\n 4: 0x8fe7b6 [node]\r\n 5: 0xf835c887147\r\nAborted (core dumped)\r\n```\r\n\r\nRunning Node with GDB suggests that the problem is happening here:\r\n\r\n```\r\n#5  0x00000000008fe7b6 in node::ReadDir(v8::FunctionCallbackInfo<v8::Value> const&) ()\r\n```\r\n\r\n<details><summary>GDB output</summary>\r\n\r\n```\r\n$ gdb --args node readdir-sync-bug.js\r\nGNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1\r\n...\r\nReading symbols from node...done.\r\n(gdb) run\r\nStarting program: /home/ubuntu/.nvm/versions/node/v9.5.0/bin/node readdir-sync-bug.js\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\n[New Thread 0x7ffff6b42700 (LWP 123862)]\r\n[New Thread 0x7ffff6341700 (LWP 123863)]\r\n[New Thread 0x7ffff5b40700 (LWP 123864)]\r\n[New Thread 0x7ffff533f700 (LWP 123865)]\r\n[New Thread 0x7ffff7ff5700 (LWP 123869)]\r\nFATAL ERROR: v8::ToLocalChecked Empty MaybeLocal.\r\n 1: node::Abort() [/home/ubuntu/.nvm/versions/node/v9.5.0/bin/node]\r\n 2: 0x8c807c [/home/ubuntu/.nvm/versions/node/v9.5.0/bin/node]\r\n 3: v8::Utils::ReportApiFailure(char const*, char const*) [/home/ubuntu/.nvm/versions/node/v9.5.0/bin/node]\r\n 4: 0x8fe7b6 [/home/ubuntu/.nvm/versions/node/v9.5.0/bin/node]\r\n 5: 0x2e361c207147\r\n\r\nThread 1 \"node\" received signal SIGABRT, Aborted.\r\n0x00007ffff6b78428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n54\t../sysdeps/unix/sysv/linux/raise.c: No such file or directory.\r\n(gdb) bt\r\n#0  0x00007ffff6b78428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n#1  0x00007ffff6b7a02a in __GI_abort () at abort.c:89\r\n#2  0x00000000008c8041 in node::Abort() ()\r\n#3  0x00000000008c807c in node::OnFatalError(char const*, char const*) ()\r\n#4  0x0000000000a36085 in v8::Utils::ReportApiFailure(char const*, char const*) ()\r\n#5  0x00000000008fe7b6 in node::ReadDir(v8::FunctionCallbackInfo<v8::Value> const&) ()\r\n#6  0x00002e361c207147 in ?? ()\r\n#7  0x00007ffffff07818 in ?? ()\r\n#8  0x00007ffffff07860 in ?? ()\r\n#9  0x0000000000000002 in ?? ()\r\n#10 0x0000000002233b50 in ?? ()\r\n#11 0x00002e361c207021 in ?? ()\r\n#12 0x00007ffffff077d0 in ?? ()\r\n#13 0x0000000000000006 in ?? ()\r\n#14 0x00007ffffff078a0 in ?? ()\r\n#15 0x00002e361c2075c1 in ?? ()\r\n#16 0x0000020b35d02201 in ?? ()\r\n#17 0x00000000021cd8e0 in ?? ()\r\n#18 0x00001263620822d1 in ?? ()\r\n#19 0x00001263620822d1 in ?? ()\r\n#20 0x00000adadb40c5d1 in ?? ()\r\n#21 0x00002e00b2d5e111 in ?? ()\r\n#22 0x0000020b35d02239 in ?? ()\r\n#23 0x00001263620822d1 in ?? ()\r\n#24 0x00001263620822d1 in ?? ()\r\n#25 0x00001263620834b1 in ?? ()\r\n#26 0x0000020b35d02201 in ?? ()\r\n#27 0x0000020b35d02201 in ?? ()\r\n#28 0x00001263620822d1 in ?? ()\r\n#29 0x0000000000000000 in ?? ()\r\n(gdb)\r\n```\r\n</details>",
        "labels": "confirmed-bug",
        "id": 45299
    },
    {
        "title": "stream: another missing end event",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: master https://github.com/nodejs/node/commit/312414662b678d95bee2904348e053728993b97a\r\n* **Platform**: all\r\n* **Subsystem**: stream\r\n\r\nhttps://github.com/nodejs/node/commit/1e0f3315c77033ef0e01bb37c3d41c8e1d65e686 introduced another issue where `end` isn't emitted. Note that this is a different issue than https://github.com/nodejs/node/issues/18294 although they seem related.\r\n\r\nHere is a test case. After some poking around it seems to be back pressure related.\r\n\r\n``` js\r\nvar stream = require('stream')\r\n\r\nvar ended = false\r\nvar missing = 50\r\n\r\nvar rs = new stream.Readable({\r\n  objectMode: true,\r\n  read: () => {\r\n    if (missing--) rs.push({})\r\n    else rs.push(null)\r\n  }\r\n})\r\n\r\nvar a = rs.pipe(new stream.PassThrough({objectMode: true}))\r\n  .pipe(new stream.PassThrough({objectMode: true}))\r\n\r\na.on('end', function () {\r\n  wrap.push(null)\r\n})\r\n\r\nvar wrap = new stream.Readable({\r\n  objectMode: true,\r\n  read: () => {\r\n    process.nextTick(function () {\r\n      var data = a.read()\r\n      if (data === null) {\r\n        a.once('readable', function () {\r\n          data = a.read()\r\n          if (data !== null) wrap.push(data)\r\n        })\r\n      } else {\r\n        wrap.push(data)\r\n      }\r\n    })\r\n  }\r\n})\r\n\r\nwrap.resume()\r\nwrap.on('end', function () {\r\n  ended = true\r\n})\r\n\r\nprocess.on('exit', function () {\r\n  if (!ended) throw new Error('stream should end')\r\n})\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45300
    },
    {
        "title": "`readDoubleLE` broken on 9.4.0",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.4.0\r\n* **Platform**: Darwin\r\n* **Subsystem**: Buffer\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIt looks like https://github.com/nodejs/node/pull/17775 might have seriously broken `Buffer.prototype.readDoubleLE`.\r\n\r\nOn v9.3.0:\r\n\r\n```\r\nBuffer.from([0xeb, 0x97, 0x3a, 0x98, 0x20, 0xdb, 0xc2, 0x40]).readDoubleLE();\r\n// => 9654.254645656756\r\n```\r\n\r\nOn v9.4.0:\r\n\r\n```\r\nBuffer.from([0xeb, 0x97, 0x3a, 0x98, 0x20, 0xdb, 0xc2, 0x40]).readDoubleLE();\r\n// => -5.828774743119337e-192\r\n```",
        "labels": "confirmed-bug",
        "id": 45301
    },
    {
        "title": "SIGILL (Illegal Instruction / Failed DCHECK) in Debug build and SIGSEGV in Release when heapdumping",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: Node 8.9.4 Debug Build\r\n* **Platform**: OSX Sierra\r\n* **Subsystem**: None/V8?\r\n\r\nI have an application I've been unable to heapdump for some time without segfaulting. Tracking it down has been extremely frustrating as the segfault was not consistent; tests would need to be run 10+ times per configuration to confirm the segfault was removed. Switching to the Debug build (tag `v8.9.4`) gives me a consistent SIGILL when heapdumping:\r\n\r\n```\r\n$ ../../forks/node/out/Debug/node --inspect index.js                                                                                                                                                           23:16:49\r\nDebugger listening on ws://127.0.0.1:9229/cfe57000-94ad-4f71-a00c-831b592f1f34\r\nFor help see https://nodejs.org/en/docs/inspector\r\nDebugger attached.\r\n\r\n#\r\n# Fatal error in ../deps/v8/src/profiler/heap-snapshot-generator.cc, line 1306\r\n# Debug check failed: constructor_or_backpointer->IsJSFunction() || constructor_or_backpointer->IsNull(map->GetIsolate()).\r\n#\r\n'../../forks/node/out/Debug/nodeâ€¦' terminated by signal SIGILL (Illegal instruction)\r\n```\r\n\r\nI eventually narrowed it down to Lodash 3.10.1 and started deleting lines to get to a minimum possible reproduction. This is as small as I could get it:\r\n\r\n```js\r\nfunction baseLodash() {}\r\n\r\nvar baseCreate = (function() {\r\n  function object() {}\r\n  return function(prototype) {\r\n    var result = new object;\r\n    object.prototype = undefined;\r\n  };\r\n}());\r\n\r\nfunction createCtorWrapper(Ctor) {\r\n  return function() {\r\n    return baseCreate(Ctor.prototype);\r\n  };\r\n}\r\n\r\nbaseCreate(baseLodash.prototype);\r\n\r\nsetInterval(() => {}, 1000);\r\n```\r\n\r\nRunning this then heapdumping it will consistently fail the `DCHECK` on my machine.\r\n\r\nTo more quickly debug, install `heapdump` and append:\r\n\r\n```js\r\nvar heapdump = require('heapdump');\r\nheapdump.writeSnapshot('./' + Date.now() + '.heapsnapshot');\r\n```\r\n\r\nwhich will trigger the SIGILL / DCHECK failure almost immediately.\r\n\r\nReproduction repository at https://github.com/STRML/lodash-heapdump-sigill.\r\n\r\nV8 Bug at https://bugs.chromium.org/p/v8/issues/detail?id=7328\r\n",
        "labels": "confirmed-bug",
        "id": 45302
    },
    {
        "title": "Floating point value decoded incorrectly by buf.readDoubleBE()",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.4.0\r\n* **Platform**: Windows 10 Pro x64 Version 1709 (OS Build 16299.192)\r\n* **Subsystem**: Buffer\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n[example_js.txt](https://github.com/nodejs/node/files/1639663/example_js.txt)\r\n\r\nThe attached example produces the output: \r\n\r\n`246800 encodes to 410e208000000000`\r\n`410e208000000000 decodes to 246800.03176522627`\r\n\r\nThe expected result is: \r\n\r\n`246800 encodes to 410e208000000000`\r\n`410e208000000000 decodes to 246800`",
        "labels": "confirmed-bug",
        "id": 45303
    },
    {
        "title": "Memory leak with http2 write()",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.4.0\r\n* **Platform**: Windows 10 64-bit\r\n* **Subsystem**: `http2`\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIf you use `req.write(\"\")` in `http2`, with an empty string, the memory gets higher and higher without end. Memory leak?\r\n\r\n```typescript\r\n        req.write(\"\", () => {\r\n            console.log(\"dun knoe\");\r\n        });\r\n```\r\n![image](https://user-images.githubusercontent.com/2917613/34968663-7784c674-fa62-11e7-83ac-58e15a95d34c.png)\r\n\r\n**Note:** Re-creation script is a few posts down this one",
        "labels": "confirmed-bug",
        "id": 45304
    },
    {
        "title": "Pass an empty buffer to Buffer.alloc filling will cause not responding and high CPU usage",
        "body": "* **Version**: 9.4.0\r\n* **Platform**: Arch Linux\r\n\r\n```javascript\r\nBuffer.alloc(1, Buffer.alloc(0));\r\n```",
        "labels": "confirmed-bug",
        "id": 45305
    },
    {
        "title": "assert.throws works incorrectly for functions that throw `undefined`",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.3.0\r\n* **Platform**: macOS\r\n* **Subsystem**: assert\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`assert.throws` and `assert.doesNotThrow` seem to treat functions that throw `undefined` the same way as functions that do not throw a value.\r\n\r\n```js\r\n'use strict';\r\n\r\nconst assert = require('assert');\r\n\r\nfunction foo() {\r\n  throw undefined;\r\n}\r\n\r\nassert.throws(foo);\r\n```\r\n\r\nExpected behavior: assertion succeeds\r\n\r\nActual behavior: assertion fails",
        "labels": "confirmed-bug",
        "id": 45306
    },
    {
        "title": "win32 path.normalize() not correctly normalizing relative paths containing ../ that advance above root",
        "body": "* **Version**: 9.3.0\r\n* **Platform**: Windows 10 64bit\r\n* **Subsystem**: path\r\n\r\nedit: See below comment for correct replication code\r\n\r\n```\r\nconst path = require( 'path' );\r\nconst n = path.normalize( '../dir1/../../dir2' );\r\nconsole.log( n );\r\n```\r\n\r\nShould output ```../../dir2``` but outputs ```dir2```.\r\n\r\nAfter some investigation it appears to have been introduced via commit [b98e8d995efb426bbdee56ce503017bdcbbc6332](https://github.com/nodejs/node/commit/b98e8d995efb426bbdee56ce503017bdcbbc6332) (path: fix normalize on directories with two dots)\r\n",
        "labels": "confirmed-bug",
        "id": 45307
    },
    {
        "title": "`process.throwDeprecation` hides original error stack",
        "body": "Node v9.3.0 on Linux (I would expect other versions since the introduction of the deprecation warning stuff - and other platforms - to behave the same way)\r\n\r\n## Current behavior\r\n\r\nIt doesn't matter whether you use `process.throwDeprecation = true` or `node --throw-deprecation` here, the behavior is the same.\r\n\r\n```js\r\nasync function x() {\r\n    throw new Error( 'aaaa' );\r\n}\r\n\r\nprocess.throwDeprecation = true;\r\n\r\nx().then( r => console.log( r ) );\r\n```\r\n\r\n```sh\r\n$ node test1.js\r\ninternal/process/warning.js:143\r\n        throw warning;\r\n        ^\r\n\r\nDeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\r\n    at emitWarning (internal/process/promises.js:92:15)\r\n    at emitPendingUnhandledRejections (internal/process/promises.js:109:11)\r\n    at runMicrotasksCallback (internal/process/next_tick.js:118:9)\r\n    at process._tickCallback (internal/process/next_tick.js:150:11)\r\n    at Function.Module.runMain (module.js:703:11)\r\n    at startup (bootstrap_node.js:194:16)\r\n    at bootstrap_node.js:618:3\r\n```\r\n\r\n## Expected behavior\r\n\r\nNote concise output that preserves the original error stack without adding irrelevant stuff.\r\n\r\n```js\r\nasync function x() {\r\n        throw new Error( 'aaaa' );\r\n}\r\n\r\nprocess.on( 'unhandledRejection', err => {\r\n        console.error( 'Unhandled promise rejection:', err );\r\n        process.exit( 1 );\r\n} );\r\n\r\nx().then( r => console.log( r ) );\r\n```\r\n\r\n```sh\r\n$ node test2.js \r\nUnhandled promise rejection: Error: aaaa\r\n    at x (../test2.js:2:8)\r\n    at Object.<anonymous> (.../test2.js:10:1)\r\n    at Module._compile (module.js:660:30)\r\n    at Object.Module._extensions..js (module.js:671:10)\r\n    at Module.load (module.js:573:32)\r\n    at tryModuleLoad (module.js:513:12)\r\n    at Function.Module._load (module.js:505:3)\r\n    at Function.Module.runMain (module.js:701:10)\r\n    at startup (bootstrap_node.js:194:16)\r\n    at bootstrap_node.js:618:3\r\n```",
        "labels": "confirmed-bug",
        "id": 45308
    },
    {
        "title": "Specify which module was requested in \"SyntaxError: The requested module does not provide an export named '...'\"",
        "body": "I'm using `--experimental-modules` and find that when a module down the dependency chain doesn't export a symbol, it's hard to tell which module that was:\r\n\r\n> SyntaxError: The requested module does not provide an export named '...'\r\n\r\nIt would really help if Node included the name of the module that didn't provide that export.",
        "labels": "confirmed-bug",
        "id": 45309
    },
    {
        "title": "doc: many erroneous linkifications",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 9.3.0\r\n* **Platform**: N/A\r\n* **Subsystem**: N/A\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe NodeJS v9.x API docs for stream have [a heading](https://nodejs.org/docs/latest-v9.x/api/stream.html#stream_a_href_http_man7_org_linux_man_pages_man0_readable_read_0_html_readable_read_0_a) that is literally `<a href=\"http://man7.org/linux/man-pages/man0/readable.read.0.html\">readable.read(0)</a>` instead of the `readable.read(0)` from [previous versions](https://nodejs.org/docs/latest-v8.x/api/stream.html#stream_readable_read_0).\r\nI'd have opened a PR but I don't know where the extra characters are coming from: the source code in both the [master](https://github.com/nodejs/node/blame/master/doc/api/stream.md#L2207) and [v9.3.0](https://github.com/nodejs/node/blame/v9.3.0/doc/api/stream.md#L2207) branches show the line unchanged for two years.\r\nApologies if this has already been corrected, github searches yielded no results for either code or issues relating to man7.",
        "labels": "confirmed-bug",
        "id": 45310
    },
    {
        "title": "Crash on windows when passing child process' stdin as other childs stdout",
        "body": "* **Version**: v8.9.2\r\n* **Platform**: Windows 10 64bits\r\n\r\nThe following simple test crashes the node process on Windows. It works fine on Linux.\r\n\r\n```js\r\nconst {spawn} = require('child_process');\r\n\r\nif (process.argv.length <= 2) {\r\n    // parent\r\n    const child2 = spawn(process.argv0, [process.argv[1], '.'], {\r\n        stdio: ['pipe', 'ignore', 'ignore'],\r\n    });\r\n    const child1 = spawn(process.argv0, [process.argv[1], '.'], {\r\n        stdio: ['pipe', child2.stdin, 'ignore'],\r\n    });\r\n    setInterval(() => child1.stdin.write(`.`), 1);\r\n} else {\r\n    // children\r\n    process.stdin.pipe(process.stdout);\r\n}\r\n```\r\n\r\nThe error is:\r\n```\r\nException thrown: write access violation.\r\nreq was 0x2275CA37430.\r\n```\r\n\r\nIt occurs in [deps/uv/src/win/core.c:439](https://github.com/nodejs/node/blob/v8.9.2/deps/uv/src/win/core.c#L439).\r\n\r\nCall stack:\r\n![callstack](https://user-images.githubusercontent.com/426158/33665422-2dd61ebe-da97-11e7-8da2-e68f56bec2c6.png)\r\n\r\nLocals:\r\n![locals](https://user-images.githubusercontent.com/426158/33665425-3257f778-da97-11e7-9f3d-8ccaae78fb16.png)\r\n\r\nI got the stack traces from a self-compiled build, but it also crashes with the official binary.\r\n",
        "labels": "confirmed-bug",
        "id": 45311
    },
    {
        "title": "Heavy use of TLSSocket + tls.connect crashes with SIGSEGV/SIGABRT",
        "body": "* **Version**: v8.9.1\r\n* **Platform**:  Linux zapp 4.10.0-40-generic #44-Ubuntu SMP Thu Nov 9 14:49:09 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: `tls`\r\n\r\nI've filed a repo with a full repro and details here: https://github.com/pimterry/node-tls-crash.\r\n\r\nThe specific code that's crashing is https://github.com/pimterry/node-tls-crash/blob/master/proxy.js\r\n\r\nTo summarize:\r\n* The repro is a minimal HTTPS-intercepting proxy: it uses `new TLSSocket` to handle incoming HTTP CONNECT sockets, uses `tls.connect` to create upstream connections, and pipes between the two.\r\n* Node aborts in under a minute with any serious web use (e.g. opening `https://cnn.com` in a browser a few times), with one of a variety of pointer errors, seemingly always in `CRYPTO_free`.\r\n* I can reproduce this in `v8.9.1`, `v6.12.0` and `v9.2.0`\r\n* There's no native modules used here at all\r\n* I've attached two example core dumps as releases on the repro repo: https://github.com/pimterry/node-tls-crash/releases\r\n\r\nI've pulled this out of a larger project, and tried to shrink the repro down as much as possible. It's pretty small and standalone, but still not tiny tiny, as I haven't found a way to reproduce this without a real working browser session. Happy to shrink it further if you have any suggestions for doing so.",
        "labels": "confirmed-bug",
        "id": 45312
    },
    {
        "title": "node --experimental-modules don't give the code where to find the error, just Invalid or unexpected token. Eg v.8.9.1",
        "body": "\r\nI'm testing projects renaming js to .mjs in order to execute them with --experimental-modules\r\nthey are proyects running ok with babel.\r\n\r\nBut I keep guessing where the error can be found on my code. I get always an error that it's hard to find:\r\n\r\n(node:16709) ExperimentalWarning: The ESM module loader is experimental.\r\nSyntaxError: Invalid or unexpected token\r\n    at ModuleJob.loaders.set [as moduleProvider] (internal/loader/ModuleRequest.js:32:13)\r\n    at <anonymous>\r\n\r\nby example I can copy this example code where the error is produced, but it's not only with this situation but in anothers too. Why Node don't give me the line and the code that produces the error ? maybe it's better I try with node 9 ? that version is more compatible with  --experimental-modules ?\r\n\r\n\r\nExample code:\r\n\r\ntest.js\r\n\r\n```\r\nimport { pgClient } from '../connection.mjs';\r\n//or \r\n//import { pgClient } from '../connection';\r\n\r\nconst pool = pgClient();\r\n\r\n(async function(){\r\n  const client = await pool.connect();\r\n  const res = await client.query('\r\n  SELECT table_name\r\n  FROM information_schema.tables\r\n  WHERE table_schema = 'public');\r\n  console.log( JSON.stringify(res.rows[0]));\r\n\r\n  client.release();\r\n})();\r\n\r\nawait pool.end();\r\n\r\n```\r\n\r\n\r\nconnection.jms     (this file have errors , by example using require()  or anothers, but the idea is to get display errors that help you to find errors  )\r\n\r\n```\r\nimport dotenv from 'dotenv';\r\ndotenv.config();\r\nimport Sequelize from 'sequelize';\r\n//import { Pool, Client } from 'pg';\r\n\r\nexport const db = new Sequelize(process.env.DB_NAME, process.env.DB_USER, process.env.DB_PASS, {\r\n  host: 'localhost',\r\n  port: '5432',\r\n  dialect: 'postgres',\r\n  timezone: '+00:00',\r\n  pool: {\r\n    max: 5,\r\n    min: 0,\r\n    idle: 10000\r\n  },\r\n});\r\n\r\n\r\n// conection segurisÃ© direct verst postresql without graphl, example dont' expose password for users\r\nexport const pgClient = () => {\r\n  \r\n  const { Pool, Client } =  require('pg');\r\n  const pool = new Pool()\r\n  \r\n  return pool;\r\n};\r\n\r\n```\r\n\r\nI execute with:\r\n\r\n`node  --experimental-modules  ./src/test.mjs\r\n`\r\n\r\nagain I repeat the error message:\r\n\r\n```\r\n\r\n(node:17571) ExperimentalWarning: The ESM module loader is experimental.\r\nSyntaxError: Invalid or unexpected token\r\n    at ModuleJob.loaders.set [as moduleProvider] (internal/loader/ModuleRequest.js:32:13)\r\n    at <anonymous>\r\n\r\n```\r\n\r\n\r\n\r\n\r\nVersion: 8.9.1\r\nPlatform: Mac ElCapitan\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45313
    },
    {
        "title": "sequential/test-inspector-port-zero segfaults on macOS 10.10 and below",
        "body": "* **Version**: 8.9.0.0\r\n* **Platform**: macOS <= 10.10.1\r\n* **Subsystem**: libuv, getaddrinfo\r\n\r\nThis test fails consistently on earlier versions of macOS (used code in https://github.com/nodejs/node/pull/16685 to work out that it was a segfault).\r\n\r\n#### Original test case failure:\r\n\r\n```js\r\n$ tools/test.py sequential/test-inspector-port-zero\r\n=== release test-inspector-port-zero ===                    \r\nPath: sequential/test-inspector-port-zero\r\nassert.js:42\r\n  throw new errors.AssertionError({\r\n  ^\r\n\r\nAssertionError [ERR_ASSERTION]: exitCode: null, signal: SIGSEGV\r\n    at ChildProcess.proc.on.mustCall (/build/jenkins/n8-test/ab673161/node/test/sequential/test-inspector-port-zero.js:37:59)\r\n    at ChildProcess.<anonymous> (/build/jenkins/n8-test/ab673161/node/test/common/index.js:533:15)\r\n    at emitTwo (events.js:126:13)\r\n    at ChildProcess.emit (events.js:214:7)\r\n    at Process.ChildProcess._handle.onexit (internal/child_process.js:198:12)\r\nCommand: out/Release/node /build/jenkins/n8-test/ab673161/node/test/sequential/test-inspector-port-zero.js\r\n[00:00|% 100|+   0|-   1]: Done \r\n```\r\n\r\n#### Minimal reproduction:\r\n\r\nOnly one line of the test is failling:\r\n\r\nhttps://github.com/nodejs/node/blob/5df0b9e0bf16e0103cf371d34c7a2eb37bbb3739/test/sequential/test-inspector-port-zero.js#L46\r\n\r\nWhich means you can reproduce with:\r\n\r\n```bash\r\nnode --inspect=localhost:0\r\n# Outputs: Segmentation fault: 11 (core dumped)\r\n```\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45314
    },
    {
        "title": "Split output wrong for Node version 6.12.0 when trapping calls to RegExp.prototype.exec",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.12.0\r\n* **Platform**: 4.10.0-38-generic #42~16.04.1-Ubuntu SMP Tue Oct 10 16:32:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe following code snippet produces the output `[ '.hover-yellow:hover' ]` using Node version 6.12.0. The expected output is `[ '.hover-yellow', ':hover' ]` which is also the output produced by for example Node 7.10.0.\r\n\r\n```javascript\r\nvar orig = RegExp.prototype.exec;\r\n\r\nRegExp.prototype.exec = function() {\r\n    return Reflect.apply(orig, this, arguments);\r\n};\r\n\r\nvar selector = \".hover-yellow:hover\";\r\nvar r = /(?!^)(?=[.:])/g\r\nconsole.log(selector.split(r));\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45315
    },
    {
        "title": "repl: strange regression in output colors",
        "body": "* **Version**: 8x-9x\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: util\r\n\r\nCompare the outputs of various versions in `cmd.exe`, pay attention to the string value  color:\r\n\r\n![04 8](https://user-images.githubusercontent.com/10393198/32921188-3fbcf97a-cb35-11e7-8efa-03371a7f175b.png)\r\n\r\n![06 12](https://user-images.githubusercontent.com/10393198/32921189-3fd944cc-cb35-11e7-895c-b4bd6dfd396a.png)\r\n\r\n![08 9](https://user-images.githubusercontent.com/10393198/32921190-3ffa013a-cb35-11e7-9577-7532c6902367.png)\r\n\r\n![09 2](https://user-images.githubusercontent.com/10393198/32921191-401ba006-cb35-11e7-9771-44a2223396b4.png)\r\n\r\n![10 0](https://user-images.githubusercontent.com/10393198/32921192-40391c9e-cb35-11e7-9f30-71246d7305a3.png)\r\n",
        "labels": "confirmed-bug",
        "id": 45316
    },
    {
        "title": "zlib fails when uncompressing a previously compressed empty buffer",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **v9.1.0**:\r\n* **Linux 4.10.0-38-generic #42~16.04.1-Ubuntu SMP x86_64 GNU/Linux**:\r\n* **zlib**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nZlib throws an exception when trying to decompress a previously compressed empty buffer. The code below does not enter any `catch` block in node 8.x.x, but enters all of them in node 9.1.0. It seems like the compression part behaves exactly the same in 8.x.x and 9.1.0, but the decompression part definitely not.\r\n\r\n```js\r\n'use strict';\r\n\r\nconst assert = require('assert');\r\nconst zlib = require('zlib');\r\nconst emptyBuffer = new Buffer(0);\r\nlet compressed, decompressed\r\n\r\n//deflateRawSync\r\ncompressed = zlib.deflateRawSync(emptyBuffer);\r\nconsole.log(compressed);\r\ntry {\r\n  decompressed = zlib.inflateRawSync(compressed);\r\n  assert(decompressed.compare(emptyBuffer) === 0);\r\n} catch (e) { console.log('deflateRawSync', e);}\r\n\r\n//deflateSync\r\ncompressed = zlib.deflateSync(emptyBuffer);\r\nconsole.log(compressed);\r\ntry {\r\n  decompressed = zlib.inflateSync(compressed);\r\n  assert(decompressed.compare(emptyBuffer) === 0);\r\n} catch (e) { console.log('deflateSync', e);}\r\n\r\n//gzipSync\r\ncompressed = zlib.gzipSync(emptyBuffer);\r\nconsole.log(compressed);\r\ntry {\r\n  decompressed = zlib.gunzipSync(compressed);\r\n  assert(decompressed.compare(emptyBuffer) === 0);\r\n} catch (e) { console.log('gzipSync', e);}\r\n```\r\n\r\n<sub>(edited by @addaleax: syntax highlighting)</sub>",
        "labels": "confirmed-bug",
        "id": 45317
    },
    {
        "title": "new Map(wrong_iterable) swallow TypeError in file scripts",
        "body": "* **Version**:  8â€“10\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: ?\r\n\r\n```js\r\n'use strict';\r\n\r\nnew Map('a');\r\n```\r\n\r\n```console\r\n// Node.js 4.8.5\r\nnew Map('a');\r\n^\r\nTypeError: Iterator value a is not an entry object\r\n\r\n// Node.js 6.11.5\r\nnew Map('a');\r\n^\r\nTypeError: Iterator value a is not an entry object\r\n\r\n// Node.js 8.9.0\r\n<no output>\r\n\r\n// Node.js 9.0.0\r\n<no output>\r\n\r\n// Node.js 10.0.0 nightly 2017.11.06\r\n<no output>\r\n```\r\n\r\nThis only happens with a file script. In the REPL, `new Map('a')` throws `TypeError` in all these versions.",
        "labels": "confirmed-bug",
        "id": 45318
    },
    {
        "title": "inspector can increment to port out of range",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v10.0.0-pre\r\n* **Platform**: win2016 vs2017\r\n* **Subsystem**: inspector\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nhttps://ci.nodejs.org/job/node-test-binary-windows/12499/COMPILED_BY=vs2017,RUNNER=win2016,RUN_SUBSET=1/console\r\n\r\n```console\r\nnot ok 505 sequential/test-inspector-port-zero-cluster\r\n  ---\r\n  duration_ms: 0.337\r\n  severity: fail\r\n  stack: |-\r\n    Debugger listening on ws://127.0.0.1:65534/cedd265a-c18b-43a5-ad22-556b3839ccad\r\n    For help see https://nodejs.org/en/docs/inspector\r\n    Debug port must be 0 or in range 1024 to 65535.\r\n    Debug port must be 0 or in range 1024 to 65535.\r\n    Debugger listening on ws://127.0.0.1:65535/64fabeeb-8512-4797-958b-6ede1b27ff5f\r\n    For help see https://nodejs.org/en/docs/inspector\r\n    { AssertionError [ERR_ASSERTION]: false == true\r\n        at Promise.all.then.common.mustCall (c:\\workspace\\node-test-binary-windows\\test\\sequential\\test-inspector-port-zero-cluster.js:38:7)\r\n        at c:\\workspace\\node-test-binary-windows\\test\\common\\index.js:522:15\r\n        at <anonymous>\r\n        at process._tickCallback (internal/process/next_tick.js:188:7)\r\n      generatedMessage: true,\r\n      name: 'AssertionError [ERR_ASSERTION]',\r\n      code: 'ERR_ASSERTION',\r\n      actual: false,\r\n      expected: true,\r\n      operator: '==' }\r\n```\r\n\r\n@nodejs/v8-inspector @nodejs/platform-windows @nodejs/testing @nodejs/build ",
        "labels": "confirmed-bug",
        "id": 45319
    },
    {
        "title": "Missing accuracy while getting ino (èŽ·å–ino ç²¾åº¦ä¸¢å¤±)",
        "body": "\r\n![lalpbbcc1rf0dinnarznawe_353_284 png_620x10000q90g](https://user-images.githubusercontent.com/18753430/32310250-010ce9d4-bfcc-11e7-9320-5567e0b09c1c.jpg)\r\n<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:1-9.0\r\n* **Platform**:win\r\n* **Subsystem**:\r\nnode fs.stat èŽ·å–æ–‡ä»¶ ino ç²¾åº¦ä¸¢å¤±\r\n\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "confirmed-bug",
        "id": 45320
    },
    {
        "title": "http2 client stops sending after stream has reached 16KiB",
        "body": "* **Version**: 8.8.0\r\n* **Platform**: macOS High Sierra\r\n* **Subsystem**: http2\r\n\r\nWhen piping a readable stream to an http2 request, it sends up to 16KiB of data, then sends no more. This can be reproduced by:\r\n\r\nThe following test server will write a file when anyone connects and sends data, using `readable.pipe(writable)`. **Usage:** `node server.js /tmp/foo` to write `/tmp/foo`\r\n\r\n```js\r\nconst http2 = require('http2');\r\nconst fs = require('fs');\r\n\r\nconst server = http2.createServer();\r\n\r\nconst filename = process.argv[2];\r\n\r\nserver.on('stream', (stream, headers) => {\r\n\tconsole.log(headers);\r\n\tstream.pipe(fs.createWriteStream(filename));\r\n\r\n\tsetTimeout(() => {\r\n\t\tstream.respond({\r\n\t\t\t'content-type': 'text/plain',\r\n\t\t\t':status': 200\r\n\t\t});\r\n\t\tstream.end(\"1 second has elapsed\");\r\n\t}, 1000);\r\n});\r\n\r\nconst port = 54321;\r\nserver.listen(port, err => {\r\n\tconsole.log('started server on port' + port);\r\n});\r\n```\r\n\r\nThe following test program reads a file and connects to an http2 server and streams the file content, also using `readable.pipe(writable)`. **Usage** `node client.js file-to-read`.\r\n\r\n**This will succeed** (small file): `node client.js /etc/hosts`\r\n**This will fail** (large file): `node client.js /usr/bin/ssh`\r\n\r\n```js\r\nconst http2 = require('http2');\r\nconst {createReadStream} = require('fs');\r\n\r\nconst session = http2.connect(\"http://localhost:54321\");\r\nconst req = session.request({\r\n\t':path': '/',\r\n\t':method': 'POST',\r\n}, {\r\n\tendStream: false,\r\n});\r\n\r\nconst filename = process.argv[process.argv.length-1];\r\ncreateReadStream(filename).pipe(req);\r\nreq.pipe(process.stdout);\r\n```\r\n\r\n* **Expected behaviour**: Stream handling should *just work* with the rest of Node.\r\n\r\n#16213 might be related",
        "labels": "confirmed-bug",
        "id": 45321
    },
    {
        "title": "net.js broken in node 8.8",
        "body": "\r\n* **Version**: `v8.8.0`\r\n* **Platform**: `Linux staging 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: `net.js`\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI do not really have simple code, i noticed the problem while running [storjshare-daemon](https://github.com/Storj/storjshare-daemon), it happend about every 1-5 minutes:\r\n\r\n```\r\nnet.js:401\r\n  const prevWriteQueueSize = this._handle.writeQueueSize;\r\n                                          ^\r\n\r\nTypeError: Cannot read property 'writeQueueSize' of null\r\n    at Socket._onTimeout (net.js:401:43)\r\n    at ontimeout (timers.js:471:11)\r\n    at tryOnTimeout (timers.js:306:5)\r\n    at Timer.listOnTimeout (timers.js:266:5)\r\n```\r\n\r\nThis error seems to be introduced with the recent commit: https://github.com/nodejs/node/commit/a627c5fc136b3233959e8e1bff90ae4b2d0ec322",
        "labels": "confirmed-bug",
        "id": 45322
    },
    {
        "title": "resize event not firing",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v8.5.0 through v8.7.0\r\n* **Platform**: Darwin\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIn versions `v8.5.0` and higher, the `resize` event does not seem to fire on terminal window resize.\r\n\r\nTest code:\r\n```js\r\nprocess.stdout.on('resize', function () {\r\n  console.log('resized')\r\n})\r\n\r\nsetInterval(function () {\r\n}, 0)\r\n```\r\n\r\nI was able to have success when trying `v8.4.0`, but `v8.5.0` does not work.\r\n\r\nPossibly related recent closed issue:\r\nhttps://github.com/nodejs/node/issues/13197\r\n",
        "labels": "confirmed-bug",
        "id": 45323
    },
    {
        "title": "Memory leak due to process.fork()?",
        "body": "* **Version**: v8.5.0\r\n* **Platform**: Linux\r\n\r\nI am experiencing memory leakage in an app that uses`process.fork()` a lot. These child processes get sent messages via `process.send()` with a `sendHandle` and are terminated later on.\r\n\r\nI did run into issues with memory management here. Some heap dumps show that even after the child-processes exited, the `ChildProcess`-instances are retained in the master process. I learned that using `subprocess.disconnect()` partly fixes that issue, but one more retainer can be found here:\r\n\r\nhttps://github.com/nodejs/node/blob/20259f90927a8b2923a0ad3210f6400d3a29966b/lib/net.js#L1665\r\n\r\nHow, where and when should this `socketList` be removed from the `_workers`-array?",
        "labels": "confirmed-bug",
        "id": 45324
    },
    {
        "title": "Closing zlib stream may throw uncaught exception",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.11.3\r\n* **Platform**: Linux bono 4.12.0-2-amd64 #1 SMP Debian 4.12.13-1 (2017-09-19) x86_64 GNU/Linux\r\n* **Subsystem**: zlib\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen calling `.close()` on a `zlib.createGunzip()` stream while the engine is still working on decompressing some stuff, sometimes this exception is thrown:\r\n\r\n```\r\nzlib.js:633\r\nâ€‚â€‚â€‚â€‚â€‚â€‚var newReq = self._handle.write(flushFlag,\r\nâ€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚â€‚ ^\r\n\r\nTypeError: Cannot read property 'write' of null\r\nâ€‚â€‚â€‚â€‚at Zlib.callback (zlib.js:633:32)\r\n```\r\n\r\nLooking at the code, it seems that when `_processChunk` sets a callback, it does not sufficiently check that `this._handle` has not been unset in the meantime. The earlier code has `assert(this._handle, 'zlib binding closed');` check, but the callback code does not.\r\n\r\nBut even the assert is wrong, as calling `.close()` on a stream, even when there's unprocessed data, should not throw any exceptions. I guess the function should check for `this._closed` similarily as it checks for `this._hadError` currently.\r\n\r\nUnfortunately this bug is triggered very rarely on a production system, so I haven't been able to write short code to reproduce the issue.",
        "labels": "confirmed-bug",
        "id": 45325
    },
    {
        "title": "fatal error: 'node_internals.h' file not found",
        "body": "* **Version**: 01c680b92aed62e128aa2abd4ad923f9a6a0331a\r\n* **Platform**: MacOS X\r\n* **Subsystem**: addon\r\n\r\nRunning `npm --nodedir=$NODE_BUILD_PATH install native-hdr-histogram` causes the error:\r\n\r\n```\r\n/Users/Andreas/node/include/node/node_buffer.h:25:10: fatal error: 'node_internals.h' file not found\r\n#include \"node_internals.h\"\r\n```\r\n\r\nI think we did something wrong in how we export or setup the headers. It appears to be caused by https://github.com/nodejs/node/commit/290315ace7eed6eeeb300754dd68fc1af4d80c9b",
        "labels": "confirmed-bug",
        "id": 45326
    },
    {
        "title": "http2 - compat not working as http",
        "body": "I've got a weird case where `http` & `https` works without problem. However, `http2` compat does not.\r\n\r\nIn the case where I'm trying to do a `PATCH`, `PUT` or `POST` the request doesn't finish with `http2`.  `GET`, `HEAD` and other \"safe\" methods work without problem.\r\n\r\nGiven that `http2` compat should be mostly an in place replacement for `http` I believe this is a bug somewhere?\r\n\r\nI'm basically using [http2-proxy](https://www.npmjs.com/package/http2-proxy) something like:\r\n\r\n```js\r\nconst http2 = require('http2')\r\nconst proxy = require('http2-proxy')\r\nconst http = require('http')\r\nconst fs = require('fs')\r\n\r\nconst proxyServer = http2\r\n   .createSecureServer({\r\n     cert: fs.readFileSync('./server.crt'),\r\n     key: fs.readFileSync('./server.key'),\r\n     allowHTTP1: true\r\n   })\r\n  .on('request', (req, res) => {\r\n    proxy.web(req, res, {\r\n      hostname: 'localhost',\r\n      port: 7000\r\n    }, err => {\r\n      if (err) {\r\n        console.error('proxy error', err)\r\n      }\r\n    })\r\n  })\r\n  .listen(6000)\r\n\r\nconst server = http\r\n  .createServer()\r\n  .on('request', (req, res) => {\r\n    req\r\n      .pipe(fs.createWriteStream(Math.random().toString()))\r\n      .on('finish', () => {\r\n        res.statusCode = 200\r\n        res.end()\r\n     })\r\n  })\r\n  .listen(7000)\r\n```\r\n\r\nCan't create a full repo since I don't know how to do http2 requests in node.",
        "labels": "confirmed-bug",
        "id": 45327
    },
    {
        "title": "Debugging v8.5 - always pauses in async_hooks.js on promise rejection",
        "body": "Have this code:\r\n\r\n```js\r\nconsole.log('before');\r\nPromise.reject(new Error('error'))\r\n```\r\n\r\nWhen I debug it in Chrome Devtools or VS Code, even when it's set to not break on exceptions, it pauses on `function emitDestroyScript(asyncId) {...` in async_hook.js after the promise is rejected.\r\n\r\nThe stack where it pauses is\r\n\r\n```\r\nemitDestroyScript (async_hooks.js:436)\r\n_tickCallback (next_tick.js:175)\r\nModule.runMain (module.js:667)\r\nstartup (bootstrap_node.js:201)\r\n(anonymous function) (bootstrap_node.js:626)\r\n```\r\n\r\nThe reason on the Debugger.paused message is \"other\".",
        "labels": "confirmed-bug",
        "id": 45328
    },
    {
        "title": " async_hooks: async hook stack assertion shadows \"Maximum call stack size exceeded\"",
        "body": "* **Node Version**: `v8.2.1`\r\n* **Platform**: `Linux 4.10.0-33-generic #37~16.04.1-Ubuntu SMP Fri Aug 11 14:07:24 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`\r\n* node-fetch@1.7.3\r\n\r\nMy product is not affected by this bug, but I report it anyway because it's still a bug and may affect someone else.\r\n\r\n```js\r\n'use strict';\r\n\r\nconst fetch = require('node-fetch');\r\n\r\n// Function name `fetch` clashes with required `fetch`!\r\nconst FooBar = async function fetch(url, encoding) {\r\n\r\n  const res = fetch(url); // Programmer forgot `await` here!\r\n  const text = await res.text();\r\n\r\n};\r\n\r\n(async function () {\r\n  return await FooBar('https://github.com');\r\n})();\r\n```\r\n\r\n```console\r\n$ node foobar.js \r\nError: async hook stack has become corrupted (actual: 0, expected: 1)\r\n 1: node::Start(uv_loop_s*, int, char const* const*, int, char const* const*) [node]\r\n 2: node::Start(int, char**) [node]\r\n 3: __libc_start_main [/lib/x86_64-linux-gnu/libc.so.6]\r\n 4: 0x8ec861 [node]\r\n```\r\n\r\n# Expected\r\n\r\nUser-friendly error message is expected, not this stack error.",
        "labels": "confirmed-bug",
        "id": 45329
    },
    {
        "title": "Intl.NumberFormat changed behavior (possibly after ICU 58 -> 59 bump)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: v8.4.0\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nv8.4.0\r\n* **Platform**:\r\nLinux 8a6b069d5b19 4.10.0-22-generic #24~16.04.1-Ubuntu SMP Tue May 23 17:03:51 UTC 2017 x86_64 GNU/Linux\r\n* **Subsystem**:\r\nUbuntu\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWe're using Jest on Travis for testing and discovered that after Node upgraded from v7.9.0 to v8.4.0 some tests failed. That's okay I thought, but. Finally, I found this odd behavior:\r\n```\r\n$ node -v\r\nv7.9.0\r\n$ node\r\n> Intl.NumberFormat('en', {style: 'currency', currency: 'USD', minimumFractionDigits: 0}).format(9);            \r\n'$9'\r\n> Intl.NumberFormat('ru', {style: 'currency', currency: 'USD', minimumFractionDigits: 0}).format(9);            \r\n'$9' \r\n\r\n----\r\n\r\n$ node -v\r\nv8.4.0\r\n$ node\r\n> Intl.NumberFormat('en', {style: 'currency', currency: 'USD', minimumFractionDigits: 0}).format(9);            \r\n'$9'\r\n> Intl.NumberFormat('ru', {style: 'currency', currency: 'USD', minimumFractionDigits: 0}).format(9);            \r\n'US$ 9'  \r\n```\r\n\r\nMaybe I missed some breaking changes, so I'll appreciate any help with that.\r\nOtherwise, I think it's a regression and we should reflect on the proper solution.",
        "labels": "confirmed-bug",
        "id": 45330
    },
    {
        "title": "tcp socket localPort option does not work",
        "body": "Version: v6.11.2\r\nPlatform: Linux workstation 4.4.0-92-generic #115-Ubuntu SMP Thu Aug 10 09:04:33 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nSubsystem: net\r\n\r\n```\r\nconst net = require('net');\r\n\r\nfunction createServer(port) {\r\n    var server = net.createServer();\r\n\r\n    server.on('connection', (socket) => {\r\n        console.log('Server '+port+': socket connected',  socket.remotePort);\r\n    });\r\n\r\n    server.listen(port);\r\n}\r\n\r\ncreateServer(6001);\r\ncreateServer(6002);\r\n\r\nvar client =  new net.Socket();\r\n\r\nclient.connect({\r\n    port: 6001,\r\n    address: '::ffff:127.0.0.1',\r\n    localPort: 6002\r\n});\r\n\r\n```\r\n**Output**: Server 6001: socket connected 35372\r\n**Expected**: Server 6001: socket connected 6002 (or EADDRINUSE error)",
        "labels": "confirmed-bug",
        "id": 45331
    },
    {
        "title": "http keepAliveTimeout triggers while writing large http responses",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nv8.4.0. Also 8.0.0, and git branch 8.X\r\n* **Platform**:\r\nLinux london 4.4.0-78-generic #99-Ubuntu SMP Thu Apr 27 15:29:09 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\nhttp\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhile writing a large response, the http keepalive timeout closes the socket after 5 seconds of writing. I can reproduce with 8.0.0 and 8.4.0 on both OSX and Linux.\r\n\r\nThe [documented](https://nodejs.org/dist/latest-v8.x/docs/api/http.html) behavior of http.server.keepAliveTimeout is\r\n> The number of milliseconds of inactivity a server needs to wait for additional incoming data, after it has finished writing the last response, before a socket will be destroyed\r\n\r\nThe script below writes 30 MB of data, but when you use curl to fetch it times out after 5 seconds, having written about 5 MB.\r\n\r\nIt seems to start the 5 second timer from when the uv_write call happened, not from when uv_write calls the callback.\r\n\r\nHere's a server, bigreq.js\r\n```javascript\r\nconst http = require('http');\r\n\r\nconst server = http.createServer((req, res) => {\r\n\r\n  var content = Buffer.alloc(30000000, 0x44);\r\n\r\n  res.writeHead(200, {\r\n    'Content-Type': 'application/octet-stream',\r\n    'Content-Length': content.length.toString(),\r\n    'Vary': 'Accept-Encoding'\r\n  });\r\n\r\n  var endRc = res.end(content, function() {\r\n    console.log(`bigreq: wrote ${content.length}`);\r\n  });\r\n  console.log(`bigreq: res.end returns ${endRc}`);\r\n\r\n  res.end();\r\n});\r\n\r\nserver.listen(8000);\r\n```\r\n\r\nStart with `node bigreq.js`. Then run this curl command. The `dd bs=1` slows it down to about a MB/sec. After 5 seconds Node closes the connection despite it blasting out data.\r\n\r\n```sh\r\ncurl -v http://london:8000/ | dd bs=1 of=/dev/null\r\n*   Trying 172.17.1.20...\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0* Connected to london (172.17.1.20) port 8000 (#0)\r\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0> GET / HTTP/1.1\r\n> Host: london:8000\r\n> User-Agent: curl/7.49.0\r\n> Accept: */*\r\n>\r\n< HTTP/1.1 200 OK\r\n< Content-Type: application/octet-stream\r\n< Content-Length: 36000000\r\n< Vary: Accept-Encoding\r\n< Date: Wed, 30 Aug 2017 00:02:03 GMT\r\n< Connection: keep-alive\r\n<\r\n{ [1279 bytes data]\r\n 14 34.3M   14 5152k    0     0  1026k      0  0:00:34  0:00:05  0:00:29 1029k* transfer closed with 30254505 bytes remaining to read\r\n 15 34.3M   15 5610k    0     0  1022k      0  0:00:34  0:00:05  0:00:29 1024k\r\n* Closing connection 0\r\ncurl: (18) transfer closed with 30254505 bytes remaining to read\r\n5745495+0 records in\r\n5745495+0 records out\r\n5745495 bytes transferred in 5.540233 secs (1037049 bytes/sec)\r\n```\r\n\r\nPutting a breakpoint on uv__stream_close, I can see it getting called in the socketOnTimeout logic:\r\n```\r\n(lldb) v8 bt\r\n * thread #1: tid = 26063, 0x00000000015fdad1 node`uv__stream_close [inlined] fprintf(__fmt=\"uv__stream_close(fd=%d)\\n\", __stream=<unavailable>) at stdio2.h:97, name = 'node', stop reason = breakpoint 1.1\r\n  * frame #0: 0x00000000015fdad1 node`uv__stream_close [inlined] fprintf(__fmt=\"uv__stream_close(fd=%d)\\n\", __stream=<unavailable>) at stdio2.h:97\r\n    frame #1: 0x00000000015fdad1 node`uv__stream_close(handle=0x000000000241c488) + 1 at stream.c:1628\r\n    frame #2: 0x00000000015f17c5 node`uv_close(handle=0x000000000241c488, close_cb=<unavailable>) + 261 at core.c:116\r\n    frame #3: 0x00000000013c8dde node`node::HandleWrap::Close(v8::FunctionCallbackInfo<v8::Value> const&) + 158\r\n    frame #4: 0x0000000000a4be02 node`v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) + 274\r\n    frame #5: 0x0000000000acf607 node`v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) + 407\r\n    frame #6: 0x0000000000acff5e node`v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) + 206\r\n    frame #7: 0x000032b88e30437d <exit>\r\n    frame #8: 0x000032b88e70eaf0 Socket._destroy(this=0x00000a4e7433ba59:<Object: Socket>, 0x0000392901c02201:<null>, 0x000000d2b3c8bf09:<function: _destroy at internal/streams/destroy.js:32:30>) at net.js:526:37 fn=0x00003dbb38dde0a1\r\n    frame #9: 0x000032b88e70e581 destroy(this=0x00000a4e7433ba59:<Object: Socket>, 0x0000392901c02311:<undefined>, 0x0000392901c02311:<undefined>) at internal/streams/destroy.js:4:17 fn=0x00000328eb47d931\r\n    frame #10: 0x000032b88e30579b <adaptor>\r\n    frame #11: 0x000032b88e726753 socketOnTimeout(this=0x00000a4e7433ba59:<Object: Socket>) at _http_server.js:381:25 fn=0x00002430d86aff31\r\n    frame #12: 0x000032b88e5466dd emitNone(this=0x0000392901c02311:<undefined>, 0x00002430d86aff31:<function: socketOnTimeout at _http_server.js:381:25>, 0x0000392901c023b1:<true>, 0x00000a4e7433ba59:<Object: Socket>) at events.js:103:18 fn=0x00003dbb38d90571\r\n    frame #13: 0x000032b88e56f679 emit(this=0x00000a4e7433ba59:<Object: Socket>, 0x00003321f1d036e1:<String: \"timeout\">) at events.js:155:44 fn=0x00003321f1d426c1\r\n    frame #14: 0x000032b88e726389 Socket._onTimeout(this=0x00000a4e7433ba59:<Object: Socket>) at net.js:399:39 fn=0x00003dbb38dddcf9\r\n    frame #15: 0x000032b88e725259 ontimeout(this=0x0000392901c02311:<undefined>, 0x00000a4e7433ba59:<Object: Socket>) at timers.js:89:18 fn=0x00003dbb38d93299\r\n    frame #16: 0x000032b88e3e82ab <stub>\r\n    frame #17: 0x000032b88e3baffc tryOnTimeout(this=0x0000392901c02311:<undefined>, 0x00000a4e7433ba59:<Object: Socket>, 0x00000a4e7432a9a1:<Object: TimersList>) at timers.js:89:18 fn=0x00003dbb38d93179\r\n    frame #18: 0x000032b88e724ae8 listOnTimeout(this=0x00000a4e7432a9e9:<Object: Timer>) at timers.js:89:18 fn=0x00003dbb38d93131\r\n    frame #19: 0x000032b88e3b9ed9 <internal>\r\n    frame #20: 0x000032b88e326c2d <entry>\r\n    frame #21: 0x0000000000e650ff node`v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) + 319\r\n    frame #22: 0x0000000000a2bd21 node`v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) + 417\r\n    frame #23: 0x00000000013bb5bf node`node::AsyncWrap::MakeCallback(v8::Local<v8::Function>, int, v8::Local<v8::Value>*) + 447\r\n    frame #24: 0x000000000143f69b node`node::(anonymous namespace)::TimerWrap::OnTimeout(uv_timer_s*) + 139\r\n    frame #25: 0x00000000015ff305 node`uv__run_timers(loop=0x000000000230b400) + 53 at timer.c:165\r\n    frame #26: 0x00000000015f1d8a node`uv_run(loop=0x000000000230b400, mode=UV_RUN_ONCE) + 826 at core.c:366\r\n    frame #27: 0x00000000013de8f7 node`node::Start(uv_loop_s*, int, char const* const*, int, char const* const*) + 2295\r\n    frame #28: 0x00000000013d8ed3 node`node::Start(int, char**) + 275\r\n    frame #29: 0x00007ffff6b64830 libc.so.6`__libc_start_main(main=(node`main), argc=8, argv=0x00007fffffffe158, init=<unavailable>, fini=<unavailable>, rtld_fini=<unavailable>, stack_end=0x00007fffffffe148) + 240 at libc-start.c:291\r\n    frame #30: 0x0000000000866319 node`_start + 41\r\n```\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45332
    },
    {
        "title": "Stepping into function crashes debugger",
        "body": "* **Version**: 6.11.2\r\n* **Platform**: Windows x64\r\n* **Subsystem**: Debugger\r\n\r\nGiven is the following code:\r\n```js\r\n\"use strict\"\r\n\r\nfunction main(input) {\r\n  const a = arg => {\r\n    const b = input.find(e => e === arg);\r\n  }\r\n}\r\n\r\nmain([]);\r\n```\r\n\r\nAssume a setup like this (example uses VS Code):\r\n\r\n![image](https://user-images.githubusercontent.com/1658949/29828066-081bbf02-8cdc-11e7-8ba0-73ebfbaa9b4b.png)\r\n\r\nWhen I hit the breakpoint on line 9 and *step into*, the debugger crashes 100% of the time.\r\n\r\nFrom what I observe, the issue is specific to the instruction pointer resting on the fat-arrow expression. If a different expression is placed on line 4, the debugger will exit as soon as I step over it.",
        "labels": "confirmed-bug",
        "id": 45333
    },
    {
        "title": "AES Key Wrap Segfault",
        "body": "CC @thelunararmy\r\n\r\n* **Version**: 6.11.2\r\n* **Platform**: Linux PCName 4.8.0-56-generic # 61~16.04.1-Ubuntu SMP Wed Jun 14 11:58:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: crypto -> ciphers -> id-aesXXX-wrap\r\n\r\nWe're trying to do aes key wrapping for our [nodejs webcrypto implementation](https://github.com/anvilresearch/webcrypto). We were having some trouble so we made the following test script (using data from [RFC3394](https://tools.ietf.org/html/rfc3394#section-4.6)):\r\n\r\n```js\r\n'use strict'\r\n\r\nconst crypto = require('crypto')\r\n\r\nlet cipherName = 'id-aes128-wrap'\r\n\r\n// Ripped from RFC3394\r\nlet kekHex = '000102030405060708090A0B0C0D0E0F' // for 256: '000102030405060708090A0B0C0D0E0F101112131415161718191A1B1C1D1E1F'\r\nlet keyHex = '00112233445566778899AABBCCDDEEFF' // for 256: '00112233445566778899AABBCCDDEEFF000102030405060708090A0B0C0D0E0F'\r\nlet ivHex = 'A6A6A6A6A6A6A6A6'\r\n\r\nlet iv = Buffer.from(ivHex, 'hex')\r\nlet kek = Buffer.from(kekHex, 'hex')\r\nlet key = Buffer.from(keyHex, 'hex')\r\n\r\ntry {\r\n  let cipher = crypto.createCipheriv(cipherName, kek, iv)\r\n  let result = cipher.update(key)\r\n  let final = cipher.final()\r\n\r\n  // TODO process result\r\n\r\n  console.log('RESULT', result, final)\r\n} catch (error) {\r\n  console.error('ERROR', error)\r\n}\r\n```\r\n\r\nRunning this script causes node to segfault. Any ideas?",
        "labels": "confirmed-bug",
        "id": 45334
    },
    {
        "title": "buffer.kMaxLength returning different value than buffer.constants.MAX_LENGTH",
        "body": "* **Version**:\r\nv8.2.1\r\n\r\n* **Platform**:\r\nwin32 (10.0.14393)\r\n\r\n* **Subsystem**:\r\nBuffer \r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe documentation says... \r\n\r\nFor buffer.kMaxLength\r\nThe largest size allowed for a single Buffer instance\r\nAn alias for buffer.constants.MAX_LENGTH\r\n\r\nFor buffer.constants.MAX_LENGTH:\r\nThe largest size allowed for a single Buffer instance\r\nOn 32-bit architectures, this value is (2^30)-1 (~1GB). On 64-bit architectures, this value is (2^31)-1 (~2GB).\r\nThis value is also available as buffer.kMaxLength.\r\n\r\nBut when you call the functions, they return different values...\r\n\r\n> buffer.kMaxLength\r\n2147483647\r\n> buffer.constants.MAX_LENGTH\r\n268435440\r\n>\r\n\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45335
    },
    {
        "title": "_ZNKSt9type_infoeqERKS_ not found with gcc 6.3.0.1 on AIX 7.1",
        "body": "Hi - Is there any document or reference to install npm on AIX system ?\r\nPlease help to provide any reference on How to  install and configure Node on AIX . \r\n\r\n---\r\n\r\n#### _**EDIT(gibfahn):**_ \r\n\r\nThe help issue () uncovered an issue with our builds, namely that they don't work with the `libstdc++` from gcc 6.3.0.1 (reproduced by @shellberg). I'm reopening this, and adding the relevant information from that issue.\r\n\r\n```bash\r\n$ node - v\r\nexec(): 0509-036 Cannot load program node because of the following errors:\r\n        0509-130 Symbol resolution failed for node because:\r\n        0509-136   Symbol _ZNKSt9type_infoeqERKS_ (number 345) is not exported from\r\n                   dependent module /opt/freeware/lib/pthread/ppc64/libstdc++.a[libstdc++.so.6].\r\n        0509-192 Examine .loader section symbols with the\r\n                 'dump -Tv' command.\r\n```\r\n\r\n```bash\r\n$ g++ --version \r\ngcc version 6.3.0 (GCC)\r\n``` \r\n\r\n```bash\r\n$ rpm -qa | grep c++ \r\nlibstdc++-devel-6.3.0-1.ppc\r\nlibstdc++-6.3.0-1.ppc\r\ngcc-c++-6.3.0-1.ppc\r\n```",
        "labels": "confirmed-bug",
        "id": 45336
    },
    {
        "title": "util.inspect not checking for loops in {,Weak}Map data",
        "body": "* **Version**: v8.2.1\r\n* **Platform**: Darwin a0999b0cf96f.ant.amazon.com 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\n* **Subsystem**: util\r\n\r\nExpected behavior:\r\n\r\n```\r\ncoffee> m = new Map\r\nMap {}\r\ncoffee> m.set m, m\r\nref1 = Map {\r\n  ref1 => ref1\r\n}\r\ncoffee>\r\n```\r\n\r\nActual behavior:\r\n```\r\ncoffee> m = new Map\r\nMap {}\r\ncoffee> m.set m, m\r\nMap {\r\n  Map {\r\n  Map { [Object] => [Object] } => Map { [Object] => [Object] } } => Map {\r\n  Map { [Object] => [Object] } => Map { [Object] => [Object] } } }\r\ncoffee>\r\n```\r\n\r\nI know this is a non-trivial problem to solve but it seems worth at least documenting if not solving.",
        "labels": "confirmed-bug",
        "id": 45337
    },
    {
        "title": "dns: occasionally crashing in resolve4 and setServers",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: v9.0.0-pre (master)\r\nPlatform: Darwin zanarpro 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64 i386 MacBookPro11,3 Darwin\r\nSubsystem: c-ares\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.0.0-pre (master)\r\n* **Platform**: Darwin zanarpro 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64 i386 MacBookPro11,3 Darwin\r\n* **Subsystem**: c-ares\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nHere's the code:\r\n\r\n```js\r\n// under test folder\r\nconst common = require('../common');\r\nconst dns = require('dns');\r\n\r\ndns.resolve4('google.com', common.mustCall(function(/* err, nameServers */) {\r\n  dns.setServers([ '8.8.8.8' ]);\r\n}));\r\n\r\ndns.resolve4('google.com', common.mustCall(function() {\r\n  // do nothing...\r\n}));\r\n```\r\n\r\nAnd the Node.js will occasionally crash with:\r\n\r\n```sh\r\nAssertion failed: (ares__is_list_empty(&server->queries_to_server)), function ares__destroy_servers_state, file ../deps/cares/src/ares_destroy.c, line 102.\r\n```",
        "labels": "confirmed-bug",
        "id": 45338
    },
    {
        "title": "require() autocompletion in repl incorrectly removes file extensions from folders",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.3.0\r\n* **Platform**: macOS\r\n* **Subsystem**: repl\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIf a folder name ends in `.js`, the autocomplete suggestion in the repl will incorrectly remove the extension from the folder name.\r\n\r\nTo reproduce:\r\n\r\n1. `mkdir foo_bar.js`\r\n1. `touch foo_bar.js/index.js`\r\n1. `node`\r\n1. In the repl, enter `require('./foo_` and press Tab\r\n\r\nThe autocomplete suggestion is `require('./foo_bar')` rather than `require('./foo_bar.js')`. Since `foo_bar` is a folder, removing the `.js` extension results in an error when calling `require`.\r\n\r\n(I originally noticed this because I have a local clone of [Inquirer.js](https://github.com/SBoudrias/Inquirer.js/), which was cloned into a folder with a `.js` extension.)",
        "labels": "confirmed-bug",
        "id": 45339
    },
    {
        "title": "Passing empty environment variables to child processes convert to 'undefined' using ConEmu + Node ",
        "body": "* **Version**:  Since Node 8.0.0. (tested in Node 7.9, Node 8.0.0 and Node 8.2.1)\r\n* **Platform**: Windows 10 version 1703 x64 using a shell (cmd.exe or git-bash) in [ConEmu](https://conemu.github.io/en)\r\n\r\n## Problem description\r\n\r\nWhen executing a process which spawns a child process, which in turn creates another child process, the empty environment variables are passed through as 'undefined' (the string literal, *NOT* an absent value). If you than for example do an `npm install` command from that child process, bad things happen:\r\n\r\n```\r\nnpm WARN invalid config access=undefined\r\nnpm WARN invalid config also=undefined\r\nnpm WARN invalid config https-proxy=undefined\r\nnpm WARN invalid config Must be a full url with \\'http://\\'\r\nnpm WARN onload-script     at Function.Module._resolveFilename (module.js:485:15)\r\nnpm WARN onload-script  { Error: Cannot find module \\'undefined\\'\r\n```\r\n\r\nTo my knowledge: this only happens in ConEmu, a popular console emulator on Windows. When i downgrade to node 7.9, this problem does not occur.\r\n\r\n## Steps to reproduce\r\n\r\nI created a small github repo to reproduce the problem.\r\n\r\n1. On windows 10: install ConEmu: https://conemu.github.io/\r\n1. Clone this repo `git clone git@github.com:nicojs/reproduce-conemu-child-process-environment-bug.git`\r\n1. run `npm install`.\r\n1. run `npm test`\r\n\r\nThis test spawns a child process, which in turn starts a new child process which logs the `process.env` to console. The tests verifies that `npm_config_onload_script` (one of the env variables) is set to `''`. \r\n\r\n## Actual results\r\n\r\nWhen ran from within ConEmu: the test failes\r\n\r\n1) the env should contain \"npm_config_onload_script\":\r\n     Error: \"npm_config_onload_script\": \"undefined\"!\"\r\n\r\nThe test also prints the environment variables to screen. You can see a lot of \"undefined\" values (the string literal, not an absent value).\r\n\r\nFor example: \"npm_config_onload_script\": \"undefined\",\r\n\r\n## Expected results\r\n\r\nIf ran from cmd or git-bash using mintty directly (or on a POSIX environment): the test passes\r\n\r\nâˆš should contain \"npm_config_onload_script\"\r\n\r\nIf you now look at the environment variables on screen, you don't see the \"undefined\" values. Just empty strings.\r\n\r\nFor example: \"npm_config_onload_script\": \"\",\r\n\r\nI reported this issue to ConEmu first, but the developer pointed out to me that this seems to be regression in node. See the discussion with [Maximus5](https://github.com/Maximus5) here: https://github.com/Maximus5/ConEmu/issues/1209\r\n\r\n## Screenshots:\r\n\r\n### ConEmu with cmd.exe shell\r\n\r\n![using-con-emu-cmd](https://user-images.githubusercontent.com/1828233/28861135-d8f04f2c-775f-11e7-8a60-2a065520c31f.png)\r\n\r\n### Command prompt with cmd.exe shell\r\n\r\n![using-command-promt-cmd](https://user-images.githubusercontent.com/1828233/28861176-059c4058-7760-11e7-8340-cce3c08ef658.png)\r\n",
        "labels": "confirmed-bug",
        "id": 45340
    },
    {
        "title": "zlib flush() fails to flush all data when callback is not provided and needDrain == true",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.2.1 and prior (any version ~4.x.x and above, due to 1543c78c12658ee57fc3677a1cb0297696f94ad4)\r\n* **Platform**: Any\r\n* **Subsystem**: Zlib\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen using the `flush()` method on a zlib stream, the stream will not be flushed fully if a callback is not provided and `ws.needDrain` is true. This appears to have been introduced all the way back in #3534, in an attempt to prevent flush listeners piling up. However, the solution prevents the requested flush from actually occurring if you don't provide a callback function, due to [line 317](https://github.com/nodejs/node/blob/master/lib/zlib.js#L317). When there is not data waiting to be drained, the code follows the path at [line 321](https://github.com/nodejs/node/blob/master/lib/zlib.js#L321) and works as expected. Therefore, this problem appears when you've just written more than 16384 bytes (1 default chunk) to the stream and then try to flush, with the result being that you get no/partial flushes.\r\n\r\nBelow is an example that demonstrates the point:\r\n\r\n    const zlib = require('zlib');\r\n\r\n    /// Test with small write (< chunk size -> needDrain == false), works as expected\r\n    // Create streams\r\n    const zipper1 = zlib.createGzip();\r\n    const unzipper1 = zlib.createGunzip();\r\n    zipper1.pipe(unzipper1);\r\n\r\n    // Write to stream\r\n    zipper1.write('some small data');\r\n\r\n    // Attempt to flush stream\r\n    zipper1.flush();\r\n\r\n    // Check output\r\n    unzipper1.on('data', (d) => {\r\n    \tconsole.log('zipper1: Short data flush received ' + d.length + ' bytes');\r\n    });\r\n\r\n\r\n    /// Test with large write\r\n    // Create streams\r\n    const zipper2 = zlib.createGzip();\r\n    const unzipper2 = zlib.createGunzip();\r\n    zipper2.pipe(unzipper2);\r\n\r\n    // Write to stream\r\n    zipper2.write('A'.repeat(17000));\r\n\r\n    // Attempt to flush stream\r\n    zipper2.flush();\r\n\r\n    // Check output\r\n    unzipper2.on('data', (d) => {\r\n    \tconsole.log('zipper2: Long data flush received ' + d.length + ' bytes');\r\n    });\r\n\r\n\r\n    /// Test with large write and callback on flush, works as expected\r\n    // Create streams\r\n    const zipper3 = zlib.createGzip();\r\n    const unzipper3 = zlib.createGunzip();\r\n    zipper3.pipe(unzipper3);\r\n\r\n    // Write to stream\r\n    zipper3.write('A'.repeat(17000));\r\n\r\n    // Attempt to flush stream\r\n    zipper3.flush(() => {});\r\n\r\n    // Check output\r\n    unzipper3.on('data', (d) => {\r\n    \tconsole.log('zipper3: Long data flush with callback received ' + d.length + ' bytes');\r\n    });\r\n\r\nWhich produces the output:\r\n\r\n    zipper1: Short data flush received 15 bytes\r\n    zipper3: Long data flush with callback received 16384 bytes\r\n    zipper3: Long data flush with callback received 616 bytes\r\n\r\nWhat this tells us:\r\n- The short messages are flushing as expected on zipper1, great!\r\n- The long messages are not flushing at all when no-arg `flush()` is used (no bytes are received on zipper2)\r\n- Adding a callback causes the long messages to flush as expected (all 17000 bytes received in two chunks on zipper3)\r\n\r\nThis issue bubbles up to higher libraries that use zlib: I came across this whilst trying to compress and flush messages in an SSE event-stream using [compression](https://www.npmjs.com/package/compression) (see their SSE example and try sending large messages or see this https://github.com/expressjs/compression/issues/86). Once the messages hit a certain size, they would fail to flush properly due to this issue and would be delayed.\r\n\r\nPossible solutions:\r\n- Bind the `drain` handler (as on [line 319](https://github.com/nodejs/node/blob/master/lib/zlib.js#L319)) regardless of whether there is a callback provided (using a no-op handler for the nested flush or none at all). This effectively reverts #3534 and would mean the listeners could pile up.\r\n- Bind the drain handler the first time no-args flush() is called and whenever a callback is provided. This requires tracking the `needDrain` state, as when it transitions to true again we need to re-allow a new listener to be bound by flush(). This follows more of the intention of #3534, without this broken flush issue.\r\n\r\n@MylesBorins: Your input here would be appreciated, to understand the motivation of the original change",
        "labels": "confirmed-bug",
        "id": 45341
    },
    {
        "title": "repl: '...' should not be detected  as REPL keyword",
        "body": "```js\r\n$ node\r\n> ...[]\r\nInvalid REPL keyword\r\n```\r\n\r\nShould instead throw this error:\r\n\r\n```shell\r\n$ node -p '...[]'\r\n[eval]:1\r\n...[]\r\n^^^\r\nSyntaxError: Unexpected token ...\r\n```",
        "labels": "confirmed-bug",
        "id": 45342
    },
    {
        "title": "HTTP: Cannot read property 'Symbol(asyncId)' of null",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.0.0 - latest\r\n* **Platform**: Darwin 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\n* **Subsystem**: http\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nIt appears like the addition of async_hooks API into the http module (commit 4a7233c1788334c171d2280026333242df7d37af) causes an edge case to occur with 'write after end'. Here is a stack trace:\r\n```\r\nTypeError: Cannot read property 'Symbol(asyncId)' of null\r\n    at write_ (_http_outgoing.js:636:24)\r\n    at ServerResponse.write (_http_outgoing.js:630:10)\r\n    at Immediate.setImmediate [as _onImmediate] (/test.js:10:7)\r\n    at runCallback (timers.js:800:20)\r\n    at tryOnImmediate (timers.js:762:5)\r\n    at processImmediate [as _immediateCallback] (timers.js:733:5)\r\n```\r\nThis is an unhandled exception, thrown all the way up to OutgoingMessage.prototype.write, causing crashes when used with streams in some cases. It appears like `msg.socket[async_id_symbol]` is causing the error due to `msg.socket` being null. I have slimmed down the code into as bare as I could. Here is my code:\r\n```javascript\r\nvar http = require('http');\r\n\r\n// This code crashes the process\r\nhttp.createServer((req, res) => {\r\n    res.on(\"error\", (err) => console.error(\"res had error:\", err));\r\n    \r\n    res.write('hello');\r\n    res.end();\r\n    setImmediate(() => {\r\n        res.write('world')\r\n    })\r\n}).listen(9000);\r\n\r\n// This code works as expected\r\nhttp.createServer((req, res) => {\r\n    res.on(\"error\", (err) => console.error(\"res had error:\", err));\r\n    \r\n    res.write('hello');\r\n    res.end();\r\n    res.write('world')\r\n}).listen(9001);\r\n``` \r\nThe second block works as intended (emits the *error* event). It appears like this bug occurs in all versions after v8.0.0.",
        "labels": "confirmed-bug",
        "id": 45343
    },
    {
        "title": "undefined port should trigger a RangeError when launching a server",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: `7.9.0`\r\n* **Platform**: `Darwin MacBook-Air-de-paul-7.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64`\r\n* **Subsystem**: ?\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nHi guys,\r\n\r\n\r\nOn my version/platform it is possible to launch a server with an undefined port. This is misleading given that there's no error message and you believe the server is working but in fact it does not listen at all. On other versions it throws a RangeError.\r\n\r\nA complete history can be found here: https://github.com/expressjs/express/issues/3364 but Doug (https://github.com/dougwilson) gave me this one liner which makes it easy to test:\r\n\r\nThanks,\r\nPaul\r\n\r\n```\r\nnode -pe 'require(\"http\").createServer(function(){}).listen(undefined, function(){})'\r\nServer {\r\n  domain: null,\r\n  _events:\r\n   { request: [Function],\r\n     connection: [Function: connectionListener],\r\n     listening: { [Function: bound onceWrapper] listener: [Function] } },\r\n  _eventsCount: 3,\r\n  _maxListeners: undefined,\r\n  _connections: 0,\r\n  _handle:\r\n   TCP {\r\n     bytesRead: 0,\r\n     _externalStream: {},\r\n     fd: 11,\r\n     reading: false,\r\n     owner: [Circular],\r\n     onread: null,\r\n     onconnection: [Function: onconnection],\r\n     writeQueueSize: 0 },\r\n  _usingSlaves: false,\r\n  _slaves: [],\r\n  _unref: false,\r\n  allowHalfOpen: true,\r\n  pauseOnConnect: false,\r\n  httpAllowHalfOpen: false,\r\n  timeout: 120000,\r\n  _pendingResponseData: 0,\r\n  maxHeadersCount: null,\r\n  _connectionKey: '6::::0' }\r\n```\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45344
    },
    {
        "title": "V8: from zzo38 via IRC - \"external\" value internalized",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.1.3\r\n* **Platform**: *\r\n* **Subsystem**: V8,n-api\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nOriginal report\r\n```\r\nif an external value (created using napi_create_external()) is used as a key in a WeakMap, the system forgets that it is an external value.\r\n```\r\n\r\n@addaleax points out this is a more general V8 issue\r\n```js\r\nvar a = new tls.TLSSocket().ssl._externalStream;\r\nutil.inspect(a);\r\n// outputs '[External]'\r\nvar b = new WeakMap();\r\nb.set(a,0);\r\nutil.inspect(a);\r\n// outputs '{}'\r\n```",
        "labels": "confirmed-bug",
        "id": 45345
    },
    {
        "title": "path.normalize does not work correctly in case of a folder that contains .. as part of its name",
        "body": "* **8.0.0**:\r\n* **mac**:\r\n* **Subsystem**:\r\n\r\nWhen using path.normalize with a folder that has '..' at the end of it, it fails to continue parsing the input correctly.\r\n\r\npath.normalize('bar/foo../../')\r\ncurrent output: bar/foo../../\r\ndesired output: bar\r\n",
        "labels": "confirmed-bug",
        "id": 45346
    },
    {
        "title": "URL#searchParams#delete removes \"?\"",
        "body": "```js\r\nconst {URL} = require(\"url\");\r\n\r\nconst url = new URL(\"http://host/?param\");\r\nurl.searchParams.delete(\"param\");\r\nurl.href;\r\n//-> http://host/\r\n```\r\nIt should produce `http://host/?` [according to @TimothyGu](https://github.com/jsdom/whatwg-url/issues/97#issuecomment-312401510).",
        "labels": "confirmed-bug",
        "id": 45347
    },
    {
        "title": "Breaking chage with writable stream events",
        "body": "In some cases writable streams emit an error event after having already emitted a finish event.\r\nThis is inconsistent with older versions, and also breaks code that removes all event listeners on the finish event.\r\n\r\n\r\nConsider the js code below. In version v8.1.1 the output is:\r\nfinish\r\nerror\r\n\r\nIn node version v6.9.5 and v4.2.6 the output is:\r\nerror\r\n\r\nuname -a\r\nLinux xxxx 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/Linux\r\n\r\n\r\n```js\r\nvar stream = require('stream');\r\n\r\nvar rs = new stream.Readable();\r\nrs.push('ok');\r\nrs.push(null);\r\nrs._read = () => { };\r\n\r\nvar ws = new stream.Writable();\r\n\r\nws.on('finish', () => { console.log('finish'); });\r\nws.on('error', () => { console.log('error'); });\r\n\r\nws._write = (chunk, encoding, done) => {\r\n    setImmediate(() => { done(new Error()); });\r\n};\r\nrs.pipe(ws);\r\n```",
        "labels": "confirmed-bug",
        "id": 45348
    },
    {
        "title": "Cluster losts handle when data size is large",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 4, 5, 6, (7, 8 maybe?)\r\n* **Platform**: linux\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nwhen master to worker with some data with socket\r\nand worker sends the received data to the master back with socket,\r\nif the data size is above 10KB the socket disappeared.\r\nhere is the sample code\r\n\r\n```javascript\r\nconst cluster = require('cluster');\r\nconst net = require('net');\r\n\r\nvar doWork = function(worker) {\r\n   var sock = new net.Socket();\r\n   // available port and host\r\n    sock.connect(443, 'google.com', function() {\r\n\r\n        var data = [];\r\n        for(var i=0; i<30000; i++) {\r\n            data[i] = '1';\r\n        };\r\n       // 1. send to worker data with socket\r\n        console.log('master to worker with socket %s', sock);\r\n        worker.send({cmd:'syn', data:data}, sock);\r\n    });\r\n};\r\n\r\nif ( cluster.isMaster ) {\r\n    var num = 5;\r\n    var workers = [];\r\n    for(var i=0; i<num; i++) {\r\n        workers[i] = cluster.fork();\r\n        workers[i].on('message', function(m, h) {\r\n            // 3. received from worker, socket is undefined.\r\n            console.log('admin recv m %s, h %s, isNS', m.cmd, h, h? h instanceof net.Socket : 'na');\r\n        });\r\n    }\r\n    for(var i=0; i<num; i++) {\r\n        doWork(workers[i]);\r\n    }\r\n} else {\r\n    process.on('message', function(m, h) {\r\n       // 2. worker send data to master with socket\r\n        console.log('worker m %s, h %s, isNS', m.cmd, h, h ? h instanceof net.Socket : 'na');\r\n        process.send({cmd:'ack', data:m.data}, h);\r\n    });\r\n}\r\n\r\n```",
        "labels": "confirmed-bug",
        "id": 45349
    },
    {
        "title": "`querystring.parse` decodes incorrect in a specific case",
        "body": "* **Version**: 8.0.0/8.1.2\r\n* **Platform**: Windows 10 x64/Linux x64\r\n\r\nAt Node 7.* or before, the result of `require('querystring').parse('a=%20+&')` is `{ a: '  ' }`. However, at Node 8.0.0 or 8.1.2, the result of `require('querystring').parse('a=%20+&')` is `{ a: '%20 ' }`. `%20` doesn't decode when it is before `+`.\r\n",
        "labels": "confirmed-bug",
        "id": 45350
    },
    {
        "title": "node crashes if `undefined` passed to an objectMode readable stream",
        "body": "* **Version**: v8.1.2\r\n* **Platform**: Darwin mbp.local 16.6.0 Darwin Kernel Version 16.6.0: Fri Apr 14 16:21:16 PDT 2017; root:xnu-3789.60.24~6/RELEASE_X86_64 x86_64\r\n* **Subsystem**: Stream\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThe following code works on node v7 but crashes on v8: \r\n\r\n```js\r\nconst Transform = require('stream').Transform\r\nconst stream = new Transform({ objectMode: true })\r\n\r\nfunction processChunk (chunk) { return undefined }\r\n\r\nstream._transform = function (chunk, enc, done) {\r\n  if (chunk) {\r\n    this.push(processChunk(chunk))\r\n  }\r\n  done()\r\n}\r\n\r\nstream.end({ something: 'whatever' })\r\n```\r\n\r\nNode crashes if my `processChunk` function returns `undefined` (which it always does for the purpose of this test case), any other value works fine. However, [the docs](https://nodejs.org/dist/latest-v8.x/docs/api/stream.html#stream_readable_push_chunk_encoding) say that \"For object mode streams, chunk may be any JavaScript value.\" If this is true, `undefined` should work fine, no? ",
        "labels": "confirmed-bug",
        "id": 45351
    },
    {
        "title": "path.posix.relative returns different results for *nix and Windows versions of node",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.1.1\r\n* **Platform**: Windows Server\r\n* **Subsystem**: path.js\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis code returns different values depending on whether run on *nix or windows:\r\n```\r\npath.posix.relative('a/b/c', '../../x');\r\n'../../../..../x' // on windows\r\n'../../../../../x' // on *nix\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45352
    },
    {
        "title": "vcbuild does not always generate field <TargetMachine> in project files.",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v9.0.0-pre\r\n* **Platform**: Windows 10 x64\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nWhen generating project files for node, gyp does not include <TargetMachine> for librarian but does so for linker. As a result the linking fails as MSBuild will default unknown machine to x64 (on x64 platforms).\r\nThe result is as follows:\r\n\r\n```\r\nvcbuild.bat debug static vs2017 x86\r\n\r\n...\r\nLINK : warning LNK4068: /MACHINE not specified; defaulting to X64 [c:\\Users\\tamaroth\\Downloads\\node\\node.vcxproj]\r\nDebug\\obj\\node\\async-wrap.obj : fatal error LNK1112: module machine type 'X86' conflicts with target machine type 'x64' [c:\\Users\\tamaroth\\Downloads\\node\\node.vcxproj]\r\n```\r\n\r\nThis is manually easily fixed by modyfying .vcxproj file to include proper <TargetMachine> inside <Lib>. \r\n\r\nFor instance, from the above command, the node.vcxproj file in Debug|Win32 configuration has this entry:\r\n\r\n```\r\n    <Lib>\r\n      <OutputFile>$(OutDir)lib\\$(ProjectName)$(TargetExt)</OutputFile>\r\n    </Lib>\r\n```\r\n \r\nIf I modify it to \r\n\r\n```\r\n    <Lib>\r\n      <OutputFile>$(OutDir)lib\\$(ProjectName)$(TargetExt)</OutputFile>\r\n      <TargetMachine>MachineX86</TargetMachine>\r\n    </Lib>\r\n```\r\n\r\nEverything works great.\r\n\r\nInside \r\n\r\nnode\\tools\\gyp\\pylib\\gyp\\msvs_emulation.py\r\n\r\nin function GetLibFlags (line: 515) it says to add specific machine, but for some reason it's not added later on to the project file.",
        "labels": "confirmed-bug",
        "id": 45353
    },
    {
        "title": "All versions of `npm init` hang on Node 8.1.0",
        "body": "* **Version**: 8.1.0\r\n* **Platform**: Darwin\r\n* **Subsystem**: Unsure\r\n\r\nTo reproduce, with Node 8.1.0 and any version of npm (we've explicitly tested w/ 2, 3, 4 & 5):\r\n\r\n```\r\n$ npm init\r\nThis utility will walk you through creating a package.json file.\r\nIt only covers the most common items, and tries to guess sensible defaults.\r\n\r\nSee `npm help json` for definitive documentation on these fields\r\nand exactly what they do.\r\n\r\nUse `npm install <pkg> --save` afterwards to install a package and\r\nsave it as a dependency in the package.json file.\r\n\r\nPress ^C at any time to quit.\r\nname: (x) \r\nversion: (1.2.0) \r\n```\r\nAt the prompt for version Node stops accepting input and doesn't respond to ^Z or ^C. (It _does_ respond to `kill -STOP` and `kill -INT`. Continuing the process after a STOP results in keyboard input being echoed but the process still does not run.)\r\n",
        "labels": "confirmed-bug",
        "id": 45354
    },
    {
        "title": "Haraka test suite crashes with ",
        "body": "\r\n* **Version**: v8.1.0\r\n* **Platform**: Debian (Travis)\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nThis looks similar to #13325\r\n\r\nFull logs can be found here: https://travis-ci.org/haraka/Haraka/jobs/239765834\r\n\r\nTest suite exits with:\r\n```\r\n/home/travis/.nvm/versions/node/v8.1.0/bin/node[3346]: ../src/env-inl.h:131:void node::Environment::AsyncHooks::push_ids(double, double): Assertion `(trigger_id) >= (0)' failed.\r\n 1: node::Abort() [node]\r\n 2: node::Assert(char const* const (*) [4]) [node]\r\n 3: node::AsyncWrap::PushAsyncIds(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 4: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [node]\r\n 5: 0xb43f48 [node]\r\n 6: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) [node]\r\n 7: 0x26285a08437d\r\nAborted (core dumped)\r\n```\r\n\r\nTest being run is here: https://github.com/haraka/Haraka/blob/master/tests/server.js#L93\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45355
    },
    {
        "title": "inspector-port=0 edge case crash",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 8.1.0\r\n* **Platform**: *\r\n* **Subsystem**: cli\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nafter 399cb25f6266a17f0e5ed838b37b9c8299a87224 there's an edge case that crashes `node`\r\n```console\r\nD:\\code\\node$ Release\\node.exe --inspect-port=0\r\n> process.debugPort\r\n\r\nD:\\code\\node$ echo %ERRORLEVEL%\r\n-1073741819\r\n\r\nD:\\code\\node$\r\n```",
        "labels": "confirmed-bug",
        "id": 45356
    },
    {
        "title": "Node 8: Compiler warning about invalid format passed to fprintf when building in VS 2015",
        "body": "* **Version**: 8.0.0\r\n* **Platform**: Visual Studio 2015 (Update 3) on Windows 10\r\n* **Subsystem**: Win32 (x86)\r\n* Using the sln and vcxproj files generated by running \"vcbuild.bat x86 release\".\r\n\r\nHi\r\nWhile compiling node v8 (using sources downloaded yesterday) on VS 2015 (Update 3), I've noticed I'm receiving the following compiler warnings:\r\n```\r\nwarning C4476: 'fprintf' : unknown type field character ''' in format specifier\r\nwarning C4474: 'fprintf' : too many arguments passed for format string\r\n```\r\n\r\nabout the following line in env-inl.h (got the warnings repeatedly, for each cpp which includes env-inl.h):\r\n```\r\ninline bool Environment::AsyncHooks::pop_ids(double async_id) {\r\n...\r\n    fprintf(stderr,\r\n              \"Error: async hook stack has become corrupted (\"\r\n              \"actual: %'.f, expected: %'.f)\\n\",\r\n               uid_fields_[kCurrentAsyncId],\r\n               async_id);\r\n..,\r\n```\r\n\r\nThe \"%'.f\" format doesn't seem right (or I'm missing something).\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45357
    },
    {
        "title": "passing socket from master to worker causes a timeout issue where socket is null.",
        "body": "node: 8\r\nnpm: 5.0.2\r\nlinux Ubuntu 1604 -> 4.8.0-51\r\n\r\nSetup:\r\nWhen using node with the cluster module while using socket.io, connections are passed from the master to the children by emitting. This is needed for \"sticky-sessions\" to work. This worked with node v7.10. \r\n\r\nSince node8, I am getting following error;\r\n\r\n```\r\nworker process 3583 got 'uncaughtException', shutdown gracefully! TypeError: Cannot read property 'emit' of null\r\n    at Socket.socketOnTimeout (_http_server.js:386:34)\r\n    at emitNone (events.js:105:13)\r\n    at Socket.emit (events.js:207:7)\r\n    at Socket._onTimeout (net.js:401:8)\r\n    at ontimeout (timers.js:488:11)\r\n    at tryOnTimeout (timers.js:323:5)\r\n    at Timer.listOnTimeout (timers.js:283:5) 'TypeError: Cannot read property \\'emit\\' of null\\n    at Socket.socketOnTimeout (_http_server.js:386:34)\\n    at emitNone (events.js:105:13)\\n    at Socket.emit (events.js:207:7)\\n\r\n    at Socket._onTimeout (net.js:401:8)\\n    at ontimeout (timers.js:488:11)\\n    at tryOnTimeout (timers.js:323:5)\\n    at Timer.listOnTimeout (timers.js:283:5)'\r\n```\r\n\r\nThis is particularly strange as I have a domain wrapping the worker code which should prevent an uncaughtException.\r\n\r\nI have my suspicion, this is related to [#13348](https://github.com/nodejs/node/pull/13348)\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45358
    },
    {
        "title": "assert: deepEqual of two Sets with different content passes",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v8.0.0\r\n* **Platform**: Linux 3.16.0-4-amd64 SMP Debian 3.16.39-1 (2016-12-30) x86_64 GNU/Linux\r\n* **Subsystem**: assert\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n```\r\nassert.deepEqual(new Set([{a: 1}, {a: 1}]), new Set([{a: 1}, {a: 2}]))\r\nassert.deepStrictEqual(new Set([{a: 1}, {a: 1}]), new Set([{a: 1}, {a: 2}]))\r\n```\r\n\r\nBoth of these checks passes, while I would expect them to fail.\r\n",
        "labels": "confirmed-bug",
        "id": 45359
    },
    {
        "title": "Strange exit after updated to node 8.0.0",
        "body": "* **Version**: 8.0.0\r\n* **Platform**: Darwin Raianos-MacBook-Pro.local 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nRight now I don't know exactly what is causing the problem.... (I guess posting a http request to some endpoints)\r\n\r\nThe process exits with this:\r\n\r\n```\r\n/usr/local/bin/node[27084]: ../src/env-inl.h:131:void node::Environment::AsyncHooks::push_ids(double, double): Assertion `(trigger_id) >= (0)' failed.\r\n 1: node::Abort() [/usr/local/bin/node]\r\n 2: node::MakeCallback(v8::Isolate*, v8::Local<v8::Object>, char const*, int, v8::Local<v8::Value>*, double, double) [/usr/local/bin/node]\r\n 3: node::AsyncWrap::PopAsyncIds(v8::FunctionCallbackInfo<v8::Value> const&) [/usr/local/bin/node]\r\n 4: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [/usr/local/bin/node]\r\n 5: v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::HeapObject>, v8::internal::Handle<v8::internal::FunctionTemplateInfo>, v8::internal::Handle<v8::internal::Object>, v8::internal::BuiltinArguments) [/usr/local/bin/node]\r\n 6: v8::internal::Builtin_Impl_HandleApiCall(v8::internal::BuiltinArguments, v8::internal::Isolate*) [/usr/local/bin/node]\r\n 7: 0x528d1b8437d\r\n[1]    27084 abort      node server.js\r\n```\r\n\r\nAny guess?\r\n",
        "labels": "confirmed-bug",
        "id": 45360
    },
    {
        "title": "assert: RangeError: Maximum call stack size exceeded is still present",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: tested on `v6.9.1` and `v8.0.0-pre`, but it seems like all versions are affected.\r\n* **Platform**: Linux 3.16.0-4-amd64 SMP Debian 3.16.39-1 (2016-12-30) x86_64 GNU/Linux\r\n* **Subsystem**: assert\r\n\r\nThe following code\r\n\r\n```javascript\r\nconst a = {}\r\na.ref = a\r\n\r\nconst b = {}\r\nb.ref = b\r\n\r\nconst c = { ref: b }\r\n\r\nassert.deepEqual(a, c)\r\n```\r\n\r\nends up with `RangeError: Maximum call stack size exceeded` and it seems like changes for #6416 didn't fixed that error entirely.\r\n\r\nI'm going to provide the fix in a PR soon.",
        "labels": "confirmed-bug",
        "id": 45361
    },
    {
        "title": "Questions: async_hooks destroy callback vs setImmediate",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**:\r\nv8.0.0-nightly20170527f84666f923\r\n\r\n* **Platform**:\r\nMac OS \r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI just tried the new `async_hooks` callback API, I want to confirm the behaviors below is correct or not?\r\n\r\n```javascript\r\nconst async_hooks = require('async_hooks');\r\n\r\nfunction init(id, provider, parentId, parentHandle) {\r\n    process._rawDebug('init ', id, provider);\r\n}\r\n\r\nfunction before(id) { \r\n    process._rawDebug('before', id);\r\n }\r\nfunction after(id) { \r\n    process._rawDebug('after', id);\r\n }\r\nfunction destroy(id) {\r\n    process._rawDebug('destroy', id);\r\n}\r\n\r\nasync_hooks.createHook({init, before, after, destroy}).enable();\r\n\r\nconst timerId1 = setImmediate(() => {\r\n    process._rawDebug('setImmediate');\r\n});\r\nclearImmediate(timerId1);\r\n```\r\n\r\nIt is just a simple `setImmediate` and it was clear by `clearImmediate`.\r\nI expect the result will be \r\n\r\n```\r\n init  2 Immediate\r\ndestroy 2\r\n```\r\n\r\nbut the result is \r\n\r\n```\r\n init  2 Immediate\r\n```\r\n\r\nonly.\r\n\r\nIf I add some other `setTimeout` logic in the test program, the `destroy` will be called.\r\n\r\n```\r\nconst async_hooks = require('async_hooks');\r\n\r\nfunction init(id, provider, parentId, parentHandle) {\r\n    process._rawDebug('init ', id, provider, parentId, parentHandle);\r\n}\r\n\r\nfunction before(id) { \r\n    process._rawDebug('before', id);\r\n }\r\nfunction after(id) { \r\n    process._rawDebug('after', id);\r\n }\r\nfunction destroy(id) {\r\n    process._rawDebug('destroy', id);\r\n}\r\n\r\nasync_hooks.createHook({init, before, after, destroy}).enable();\r\n\r\nconst timerId1 = setImmediate(() => {\r\n    process._rawDebug('setImmediate');\r\n});\r\nclearImmediate(timerId1);\r\n\r\nconst timerId = setTimeout(() => {\r\n    process._rawDebug('settimeout');\r\n}, 100);\r\nclearTimeout(timerId);\r\n```\r\n\r\nthe result will look like\r\n\r\n```\r\ninit  2 Immediate\r\ninit  3 Timeout\r\ninit  4 TIMERWRAP\r\ndestroy 2\r\ndestroy 3\r\n```\r\n\r\nIs this the correct behaviors? And how to ensure the `destroy` callback is called ? \r\n\r\nThanks a lot!",
        "labels": "confirmed-bug",
        "id": 45362
    },
    {
        "title": "Late enabling of async_hooks after promise creation causes process abort",
        "body": "* **Version**: master\r\n* **Platform**: all\r\n* **Subsystem**: async_hooks\r\n\r\nHaving thought some more about #13177, I don't think there is much difference between that approach and checking if async_hooks is enabled by:\r\n\r\n```c++\r\nuint32_t* fields_ptr = async_hooks->fields();\r\nif (fields_ptr[AsyncHooks::kInit] +\r\n    fields_ptr[AsyncHooks::kBefore] +\r\n    fields_ptr[AsyncHooks::kAfter] +\r\n    fields_ptr[AsyncHooks::kDestroy] > 0) {\r\n\r\n}\r\n```\r\n\r\nBut the above solution is more consistent when `.disable()` is called after `.enable()`. Perhaps, more importantly, it highlights an issue where the promise is created just before the hooks are setup. In which case the node process will currently abort because of `CHECK_NE(wrap, nullptr);`.\r\n\r\n```js\r\nconst async_hooks = require('async_hooks');\r\n\r\nconst p = new Promise((resolve) => resolve(1));\r\np.then();\r\n\r\nconst hooks = async_hooks.createHook({\r\n  before(id) {\r\n    process._rawDebug(id);\r\n  }\r\n}).enable();\r\n```\r\n\r\ncauses the following error:\r\n\r\n```\r\n./out/Release/node[21762]: ../src/async-wrap.cc:310:void node::PromiseHook(v8::PromiseHookType, Local<v8::Promise>, Local<v8::Value>, void *): Assertion `(wrap) != (nullptr)' failed.\r\n 1: node::Abort() [./node]\r\n 2: node::FatalError(char const*, char const*) [./node]\r\n 3: node::PromiseHook(v8::PromiseHookType, v8::Local<v8::Promise>, v8::Local<v8::Value>, void*) [./node]\r\n 4: node::Environment::EnvPromiseHook(v8::PromiseHookType, v8::Local<v8::Promise>, v8::Local<v8::Value>) [./node]\r\n 5: v8::internal::Runtime_PromiseHookBefore(int, v8::internal::Object**, v8::internal::Isolate*) [./node]\r\n 6: 0x16a920f0437d\r\n[1]    21762 abort      ./node test.js\r\n```\r\n\r\nI don't think there is a good solution to this problem. But I would like to another opinion on that.\r\n\r\nOtherwise, we will just have to check for the `env->promise_wrap()` property and not emit before, after and destroy in this case. This is a difference behavior than that for all other `*Wrap` types, which is why it is not a good solution.\r\n\r\n/cc @addaleax @matthewloring ",
        "labels": "confirmed-bug",
        "id": 45363
    },
    {
        "title": "zlib assertion error",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 6.10.2\r\n* **Platform**: Linux\r\n* **Subsystem**: zlib\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nNode.js crashes while running the [Autobahn Testsuite](https://github.com/crossbario/autobahn-testsuite) against [ws](https://github.com/websockets/ws).\r\n\r\n```\r\n/home/luigi/.nvm/versions/node/v6.10.2/bin/node[12612]: ../src/node_zlib.cc:86:void node::ZCtx::Close(): Assertion `init_done_ && \"close before init\"' failed.\r\n 1: node::Abort() [node]\r\n 2: node::Assert(char const* const (*) [4]) [node]\r\n 3: node::ZCtx::Close(v8::FunctionCallbackInfo<v8::Value> const&) [node]\r\n 4: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [node]\r\n 5: 0x9ec20e [node]\r\n 6: 0x9ecaae [node]\r\n 7: 0xba4e8092a7\r\nAborted (core dumped)\r\n```\r\n\r\nThe issue is not reproducible with Node.js 6.10.1 (zlib 1.2.8). In Node.js 6.10.2, zlib has been upgraded to version 1.2.11.\r\n\r\nHere is a back trace:\r\n\r\n```\r\n(lldb) v8 bt\r\n * thread #1: tid = 12612, 0x00007f625684191f libc.so.6`__GI_raise + 159, name = 'node', stop reason = signal SIGABRT\r\n  * frame #0: 0x00007f625684191f libc.so.6`__GI_raise + 159\r\n    frame #1: 0x00007f625684351a libc.so.6`__GI_abort + 362\r\n    frame #2: 0x000000000109b771 node`node::Abort() + 33\r\n    frame #3: 0x000000000109b8a3 node`node::Assert(char const* const (*) [4]) + 211\r\n    frame #4: 0x00000000010d448a node`node::ZCtx::Close(v8::FunctionCallbackInfo<v8::Value> const&) + 298\r\n    frame #5: 0x000000000098d212 node`v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) + 290\r\n    frame #6: 0x00000000009ec20e node`v8::internal::(anonymous namespace)::HandleApiCallHelper(v8::internal::Isolate*, v8::internal::(anonymous namespace)::BuiltinArguments<(v8::internal::BuiltinExtraArguments)3>) + 574\r\n    frame #7: 0x00000000009ecaae node`v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) + 398\r\n    frame #8: 0x000000ba4e8092a7 <exit>\r\n    frame #9: 0x000000ba4e9d7953 _close(this=0x000023d5b6a04381:<undefined>, 0x0000024ce82c2c79:<Object: DeflateRaw>, 0x000023d5b6a04381:<undefined>) at zlib.js:473:16 fn=0x0000024ce8251951\r\n    frame #10: 0x000000ba4e809895 <adaptor>\r\n    frame #11: 0x000000ba4e9dd580 Zlib._handle.onerror(this=0x0000024ce82c48c1:<Object: Zlib>, 0x0000024ce82c4c11:<String: \"Init error\">, <Smi: -2>) at zlib.js:364:34 fn=0x00000884a5a28e61\r\n    frame #12: 0x000000ba4e83b7a3 <internal>\r\n    frame #13: 0x000000ba4e82508f <entry>\r\n    frame #14: 0x0000000000c53b54 node`v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) + 196\r\n    frame #15: 0x0000000000974d59 node`v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) + 313\r\n    frame #16: 0x0000000000982ee1 node`v8::Function::Call(v8::Local<v8::Value>, int, v8::Local<v8::Value>*) + 65\r\n    frame #17: 0x000000000108b479 node`node::AsyncWrap::MakeCallback(v8::Local<v8::Function>, int, v8::Local<v8::Value>*) + 329\r\n    frame #18: 0x00000000010d6202 node`node::ZCtx::Init(v8::FunctionCallbackInfo<v8::Value> const&) + 1122\r\n    frame #19: 0x000000000098d212 node`v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) + 290\r\n    frame #20: 0x00000000009ec20e node`v8::internal::(anonymous namespace)::HandleApiCallHelper(v8::internal::Isolate*, v8::internal::(anonymous namespace)::BuiltinArguments<(v8::internal::BuiltinExtraArguments)3>) + 574\r\n    frame #21: 0x00000000009ecaae node`v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) + 398\r\n    frame #22: 0x000000ba4e8092a7 <exit>\r\n    frame #23: 0x000000ba4e9d046b Zlib(this=0x0000024ce82c2c79:<Object: DeflateRaw>, 0x0000024ce82c2c39:<Object: Object>, <Smi: 5>) at zlib.js:299:14 fn=0x0000024ce8239391\r\n    frame #24: 0x000000ba4e9db606 DeflateRaw(this=0x0000024ce82c2c79:<Object: DeflateRaw>, 0x0000024ce82c2c39:<Object: Object>) at zlib.js:268:20 fn=0x0000024ce82394f9\r\n    frame #25: 0x000000ba4e83445b <constructor>\r\n    frame #26: 0x000000ba4e9db265 exports.createDeflateRaw(this=0x0000024ce8251819:<Object: Object>, 0x0000024ce82c2c39:<Object: Object>) at zlib.js:83:36 fn=0x000021655bb90cf1\r\n    frame #27: 0x000000ba4e9dacd4 compress(this=0x0000024ce82b49e1:<Object: PerMessageDeflate>, 0x0000024ce82c24d1:<ArrayBufferView 0x00000000034f7250+6816:16>, 0x000023d5b6a043c1:<true>, 0x0000024ce82c2871:<function: perMessageDeflate.compress at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/Sender.js:334:51>) at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/PerMessageDeflate.js:329:12 fn=0x0000024ce8252b61\r\n    frame #28: 0x000000ba4e9da760 dispatch(this=0x0000024ce82baad9:<Object: Sender>, 0x0000024ce82c24d1:<ArrayBufferView 0x00000000034f7250+6816:16>, 0x000023d5b6a043c1:<true>, 0x0000024ce82c2789:<Object: Object>, 0x000023d5b6a04381:<undefined>) at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/Sender.js:325:12 fn=0x0000024ce8253399\r\n    frame #29: 0x000000ba4e9d9d92 send(this=0x0000024ce82baad9:<Object: Sender>, 0x0000024ce82c24d1:<ArrayBufferView 0x00000000034f7250+6816:16>, 0x0000024ce82c2331:<Object: Object>, 0x000023d5b6a04381:<undefined>) at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/Sender.js:255:8 fn=0x0000024ce8253351\r\n    frame #30: 0x000000ba4e9d935b send(this=0x0000024ce82b8769:<Object: EventEmitter>, 0x0000024ce82c2101:<String: \"{\r\n   \"AutobahnPy\">, 0x000023d5b6a04381:<undefined>, 0x000023d5b6a04381:<undefined>) at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/WebSocket.js:350:8 fn=0x0000024ce8204e69\r\n    frame #31: 0x000000ba4e809895 <adaptor>\r\n    frame #32: 0x000000ba4e9d8d16 ws.on(this=0x0000024ce82b8769:<Object: EventEmitter>, 0x0000024ce82c2101:<String: \"{\r\n   \"AutobahnPy\">) at /home/luigi/Desktop/autobahn/server/index.js:12:20 fn=0x0000024ce82bbd71\r\n    frame #33: 0x000000ba4e9adf50 emitOne(this=0x000023d5b6a04381:<undefined>, 0x0000024ce82bbd71:<function: ws.on at /home/luigi/Desktop/autobahn/server/index.js:12:20>, 0x000023d5b6a043c1:<true>, 0x0000024ce82b8769:<Object: EventEmitter>, 0x0000024ce82c2101:<String: \"{\r\n   \"AutobahnPy\">) at events.js:94:17 fn=0x000021655bb464b1\r\n    frame #34: 0x000000ba4e921780 emit(this=0x0000024ce82b8769:<Object: EventEmitter>, 0x000023d5b6a8be39:<String: \"message\">) at events.js:136:44 fn=0x000023d5b6ae8571\r\n    frame #35: 0x000000ba4e809895 <adaptor>\r\n    frame #36: 0x000000ba4e9d8c02 _receiver.onmessage(this=0x0000024ce82b9a19:<Object: Receiver>, 0x0000024ce82c2101:<String: \"{\r\n   \"AutobahnPy\">) at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/WebSocket.js:146:32 fn=0x00000884a5a1b1f9\r\n    frame #37: 0x000000ba4e9d87a3 dataMessage(this=0x0000024ce82b9a19:<Object: Receiver>) at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/Receiver.js:359:15 fn=0x0000024ce8252ff1\r\n    frame #38: 0x000000ba4e9d7e8f perMessageDeflate.decompress(this=0x000023d5b6a04381:<undefined>, 0x000023d5b6a04201:<null>, 0x0000024ce82c1f49:<ArrayBufferView 0x00000000034f7250+6800:16>) at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/Receiver.js:343:51 fn=0x0000024ce82bce49\r\n    frame #39: 0x000000ba4e9d70d7 _inflate.flush(this=0x000023d5b6a04381:<undefined>) at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/PerMessageDeflate.js:314:25 fn=0x0000024ce82c0521\r\n    frame #40: 0x000000ba4e9a8f83 afterWrite(this=0x000023d5b6a04381:<undefined>, 0x0000024ce82bd059:<Object: InflateRaw>, 0x0000024ce82bdbe9:<Object: WritableState>, 0x000023d5b6a04271:<false>, 0x0000024ce82c0521:<function: _inflate.flush at /home/luigi/Desktop/autobahn/server/node_modules/ws/lib/PerMessageDeflate.js:314:25>) at _stream_writable.js:384:20 fn=0x000021655bb4af19\r\n    frame #41: 0x000000ba4e9a88e0 onwrite(this=0x000023d5b6a04381:<undefined>, 0x0000024ce82bd059:<Object: InflateRaw>, 0x000023d5b6a04381:<undefined>) at _stream_writable.js:356:17 fn=0x000021655bb4aed1\r\n    frame #42: 0x000000ba4e9a855f WritableState.onwrite(this=0x000023d5b6a04381:<undefined>, 0x000023d5b6a04381:<undefined>) at _stream_writable.js:89:26 fn=0x00000884a5a20f39\r\n    frame #43: 0x000000ba4e9d5fc9 afterTransform(this=0x000023d5b6a04381:<undefined>, 0x0000024ce82bd059:<Object: InflateRaw>, 0x000023d5b6a04381:<undefined>, 0x000023d5b6a04381:<undefined>) at _stream_transform.js:64:24 fn=0x000021655bb4b3a1\r\n    frame #44: 0x000000ba4e9d5c9f TransformState.afterTransform(this=0x000023d5b6a04381:<undefined>, 0x000023d5b6a04381:<undefined>, 0x000023d5b6a04381:<undefined>) at _stream_transform.js:53:33 fn=0x00000884a5a21481\r\n    frame #45: 0x000000ba4e809895 <adaptor>\r\n    frame #46: 0x000000ba4e9d5638 callback(this=0x0000024ce82bf139:<Object: Zlib>, <Smi: 0>, <Smi: 16368>) at zlib.js:576:20 fn=0x0000024ce82c1af1\r\n    frame #47: 0x000000ba4e83b7a3 <internal>\r\n    frame #48: 0x000000ba4e82508f <entry>\r\n    frame #49: 0x0000000000c53b54 node`v8::internal::Execution::Call(v8::internal::Isolate*, v8::internal::Handle<v8::internal::Object>, v8::internal::Handle<v8::internal::Object>, int, v8::internal::Handle<v8::internal::Object>*) + 196\r\n    frame #50: 0x0000000000974d59 node`v8::Function::Call(v8::Local<v8::Context>, v8::Local<v8::Value>, int, v8::Local<v8::Value>*) + 313\r\n    frame #51: 0x0000000000982ee1 node`v8::Function::Call(v8::Local<v8::Value>, int, v8::Local<v8::Value>*) + 65\r\n    frame #52: 0x000000000108b479 node`node::AsyncWrap::MakeCallback(v8::Local<v8::Function>, int, v8::Local<v8::Value>*) + 329\r\n    frame #53: 0x00000000010d827b node`node::ZCtx::After(uv_work_s*, int) + 635\r\n    frame #54: 0x000000000131a825 node`uv__work_done(handle=0x0000000001e1dfb0) + 165 at threadpool.c:236\r\n    frame #55: 0x000000000131c83b node`uv__async_event(loop=0x0000000001e1df00, w=<unavailable>, nevents=<unavailable>) + 171 at async.c:98\r\n    frame #56: 0x000000000131c913 node`uv__async_io(loop=0x0000000001e1df00, w=0x0000000001e1e0c8, events=<unavailable>) + 163 at async.c:138\r\n    frame #57: 0x000000000132cee0 node`uv__io_poll(loop=0x0000000001e1df00, timeout=119985) + 928 at linux-core.c:380\r\n    frame #58: 0x000000000131d3f6 node`uv_run(loop=0x0000000001e1df00, mode=UV_RUN_ONCE) + 342 at core.c:354\r\n    frame #59: 0x00000000010a60b0 node`node::Start(int, char**) + 1360\r\n    frame #60: 0x00007f625682c401 libc.so.6`__libc_start_main + 241\r\n    frame #61: 0x00000000007b8a0d node`_start + 41\r\n    frame #62: 0x00007f6257ccaf80 ld-linux-x86-64.so.2`_rtld_local + 3968\r\n    frame #63: 0x00007f6257ccaf80 ld-linux-x86-64.so.2`_rtld_local + 3968\r\n```\r\n\r\nThe test that makes the process crash has the following description:\r\n\r\n```\r\nSend 1000 compressed messages each of payload size 16, auto-fragment to 0 octets. Use permessage-deflate client offers (requestNoContextTakeover, requestMaxWindowBits): [(False, 8)]\r\n```",
        "labels": "confirmed-bug",
        "id": 45364
    },
    {
        "title": "test-npm failing on master after introduction of initial async hooks implementation",
        "body": "* **Version**: master\r\n* **Platform**: n/a\r\n* **Subsystem**: async_hooks\r\n\r\n`make test-npm` is failing since https://github.com/nodejs/node/pull/12892 (https://github.com/nodejs/node/commit/4a7233c1788334c171d2280026333242df7d37af) landed it seems. In particular, it appears that it's possible for a socket handle to not have an `asyncReset` function attached (perhaps something in npm or one of its dependencies are unsetting it?), causing a `TypeError` on [this line](https://github.com/nodejs/node/blob/4a7233c1788334c171d2280026333242df7d37af/lib/_http_agent.js#L170).\r\n\r\nAfter running across that issue, I spotted just a few lines below that that there is a bug waiting to happen on [this line](https://github.com/nodejs/node/blob/4a7233c1788334c171d2280026333242df7d37af/lib/_http_agent.js#L185) and [this line](https://github.com/nodejs/node/blob/4a7233c1788334c171d2280026333242df7d37af/lib/_http_agent.js#L298) because `newSocket` should be `undefined` if an error occurred.\r\n\r\nI have not checked for other similar potential issues yet.\r\n\r\n/cc @AndreasMadsen @addaleax @trevnorris",
        "labels": "confirmed-bug",
        "id": 45365
    },
    {
        "title": "OpenSSL have collisions in node.dll",
        "body": "* **Version**: v7.7.1 (on PC)\r\n* **Platform**: Windows 10 64-bit\r\n\r\nNodeJS latest (7.10.0) source (downloaded source as tar.gz), Visual Studio 2015, Python 2.7.13 32-bit, Launch:\r\n`.\\vcbuild.bat dll debug x64 vc2015`\r\n\r\n![image](https://cloud.githubusercontent.com/assets/1665373/25917991/25a4a78c-35ca-11e7-908a-64cf7983616f.png)\r\n(sorry, I closed terminal already)",
        "labels": "confirmed-bug",
        "id": 45366
    },
    {
        "title": "`ENETUNREACH` not handled for `http.request` in 7.10.0",
        "body": "* **Version**: 7.10.0\r\n* **Platform**: Linux\r\n* **Subsystem**: http\r\n\r\nAs the title says that error is not delivered via the returned event emitter, an exception is thrown instead. Other errors are properly handled, e.g., using `{port: 0}` which causes `ECONNREFUSED`. Also the net subsystem doesn't seem to be affected when I try with `net.connect` using the same options.\r\n\r\nHere is the snippet to reproduce it:\r\n\r\n```js\r\nconst http = require('http');\r\nconst request = http.request({host: '255.255.255.255'});\r\nrequest.on('error', console.error);\r\n```\r\n\r\n### Incorrect behavior\r\n\r\n```console\r\n$ nvm use 7.10.0\r\nNow using node v7.10.0\r\n$ node issue.js\r\nevents.js:163\r\n      throw er; // Unhandled 'error' event\r\n      ^\r\n\r\nError: connect ENETUNREACH 255.255.255.255:80 - Local (0.0.0.0:0)\r\n    at Object.exports._errnoException (util.js:1050:11)\r\n    at exports._exceptionWithHostPort (util.js:1073:20)\r\n    at internalConnect (net.js:889:16)\r\n    at lookupAndConnect (net.js:977:5)\r\n    at Socket.realConnect (net.js:945:5)\r\n    at Agent.connect [as createConnection] (net.js:77:22)\r\n    at Agent.createSocket (_http_agent.js:195:26)\r\n    at Agent.addRequest (_http_agent.js:157:10)\r\n    at new ClientRequest (_http_client.js:212:16)\r\n    at Object.request (http.js:26:10)\r\n```\r\n\r\n### Expected behavior\r\n\r\n```console\r\n$ nvm use 7.9.0\r\nNow using node v7.9.0\r\n$ node issue.js\r\n{ Error: connect ENETUNREACH 255.255.255.255:80 - Local (0.0.0.0:0)\r\n    at Object.exports._errnoException (util.js:1050:11)\r\n    at exports._exceptionWithHostPort (util.js:1073:20)\r\n    at internalConnect (net.js:894:16)\r\n    at net.js:980:9\r\n    at _combinedTickCallback (internal/process/next_tick.js:73:7)\r\n    at process._tickCallback (internal/process/next_tick.js:104:9)\r\n    at Module.runMain (module.js:607:11)\r\n    at run (bootstrap_node.js:423:7)\r\n    at startup (bootstrap_node.js:147:9)\r\n    at bootstrap_node.js:538:3\r\n  code: 'ENETUNREACH',\r\n  errno: 'ENETUNREACH',\r\n  syscall: 'connect',\r\n  address: '255.255.255.255',\r\n  port: 80 }\r\n```",
        "labels": "confirmed-bug",
        "id": 45367
    },
    {
        "title": "fs, test: one set of file attributes in Windows prevents fs.fchmod() from changing mode to RW and breaks incomplete test",
        "body": "* **Version**: 8.0.0 nightly 2017 05 01\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: fs, libuv?, test\r\n\r\nThis is a confusing story here, so I am sorry for possibly clumsy wording.\r\n\r\n### Prehistory\r\n\r\nI was launching tests with own test runner, each test with various context several times, and I've found out that [`parallel/test-fs-chmod.js`](https://github.com/nodejs/node/blob/master/test/parallel/test-fs-chmod.js) was OK on the first run and failed on all the next ones. Moreover, this happened not on all the machines.\r\n\r\nThis turned up to be caused by some combination of a fixture file attributes.\r\n\r\n### Excursus\r\n\r\nSee this small [attrib doc](https://technet.microsoft.com/en-us/library/5e763ca5-21a2-45d2-b26d-a9c44c99091a) for context.\r\n\r\nThe test fails if both `-a` and `-i` flags are unset for a fixture file used in the test. This unsetting combination, strangely enough, correlates with this GUI setting:\r\n<details>\r\n<summary>Screenshot:</summary>\r\n\r\n![a](https://cloud.githubusercontent.com/assets/10393198/25642829/f113138a-2fa4-11e7-9d5f-d5b10df75cc7.png)\r\n\r\n</details><br>\r\n\r\n### How to reproduce\r\n\r\nTry to run these commands with repo root as cwd (firstly, we set a combination of the `-a` and `-i` flags; then we check the current attributes; then we run the test twice; then we check if the attributes are the same.; `--no-deprecation` key there is due to cause of https://github.com/nodejs/node/pull/12795).\r\n<details>\r\n<summary>Commands :</summary>\r\n\r\n```console\r\nattrib +a +i test/fixtures/a1.js\r\nattrib test/fixtures/a1.js\r\nnode --no-deprecation test/parallel/test-fs-chmod.js\r\nnode --no-deprecation test/parallel/test-fs-chmod.js\r\nattrib test/fixtures/a1.js\r\n\r\nattrib +a -i test/fixtures/a1.js\r\nattrib test/fixtures/a1.js\r\nnode --no-deprecation test/parallel/test-fs-chmod.js\r\nnode --no-deprecation test/parallel/test-fs-chmod.js\r\nattrib test/fixtures/a1.js\r\n\r\nattrib -a +i test/fixtures/a1.js\r\nattrib test/fixtures/a1.js\r\nnode --no-deprecation test/parallel/test-fs-chmod.js\r\nnode --no-deprecation test/parallel/test-fs-chmod.js\r\nattrib test/fixtures/a1.js\r\n\r\nattrib -a -i test/fixtures/a1.js\r\nattrib test/fixtures/a1.js\r\nnode --no-deprecation test/parallel/test-fs-chmod.js\r\nnode --no-deprecation test/parallel/test-fs-chmod.js\r\nattrib test/fixtures/a1.js\r\n```\r\n\r\n</details><br>\r\n\r\nI see this output (some path details stripped, borders added after each iteration):\r\n<details>\r\n<summary>Output:</summary>\r\n\r\n```console\r\n/******************************************************************************/\r\n> attrib +a +i test/fixtures/a1.js\r\n\r\n> attrib test/fixtures/a1.js\r\nA       I    fixtures/a1.js\r\n\r\n> node --no-deprecation test/parallel/test-fs-chmod.js\r\n33060\r\n33060\r\n\r\n> node --no-deprecation test/parallel/test-fs-chmod.js\r\n33060\r\n33060\r\n\r\n> attrib test/fixtures/a1.js\r\nA       I    fixtures/a1.js\r\n/******************************************************************************/\r\n> attrib +a -i test/fixtures/a1.js\r\n\r\n> attrib test/fixtures/a1.js\r\nA            fixtures/a1.js\r\n\r\n> node --no-deprecation test/parallel/test-fs-chmod.js\r\n33060\r\n33060\r\n\r\n> node --no-deprecation test/parallel/test-fs-chmod.js\r\n33060\r\n33060\r\n\r\n> attrib test/fixtures/a1.js\r\nA            fixtures/a1.js\r\n/******************************************************************************/\r\n> attrib -a +i test/fixtures/a1.js\r\n\r\n> attrib test/fixtures/a1.js\r\n        I    fixtures/a1.js\r\n\r\n> node --no-deprecation test/parallel/test-fs-chmod.js\r\n33060\r\n33060\r\n\r\n> node --no-deprecation test/parallel/test-fs-chmod.js\r\n33060\r\n33060\r\n\r\n> attrib test/fixtures/a1.js\r\n        I    fixtures/a1.js\r\n/******************************************************************************/\r\n> attrib -a -i test/fixtures/a1.js\r\n\r\n> attrib test/fixtures/a1.js\r\n             fixtures/a1.js\r\n\r\n> node --no-deprecation test/parallel/test-fs-chmod.js\r\n33060\r\n33060\r\n\r\n> node --no-deprecation test/parallel/test-fs-chmod.js\r\n33060\r\nassert.js:557\r\nassert.ifError = function ifError(err) { if (err) throw err; };\r\n                                                  ^\r\n\r\nError: EPERM: operation not permitted, open 'fixtures/a1.js'\r\n\r\n> attrib test/fixtures/a1.js\r\n     R       fixtures/a1.js\r\n/******************************************************************************/\r\n```\r\n</details><br>\r\nAs you can see, in the last case the second test fails and the file mode is changed.\r\n\r\n### What is going on here?\r\n\r\n`test/parallel/test-fs-chmod.js` changes the mode of [`fixtures/a.js`](https://github.com/nodejs/node/blob/master/test/fixtures/a.js) with `fs.chmod()` and the mode of [`fixtures/a1.js`](https://github.com/nodejs/node/blob/master/test/fixtures/a1.js) with `fs.fchmod()` twice on Windows: to read-only and back to read-write. In case of `fixtures/a.js` and `fs.chmod()`, all is OK even with `-a` and `-i` attributes unset (I've checked this). But with `fixtures/a1.js` and `fs.fchmod()`, the beforementioned edge case prevents `fs.fchmod()` from the second change [here](https://github.com/nodejs/node/blob/98e54b0bd4854bdb3e2949d1b6b20d6777fb7cde/test/parallel/test-fs-chmod.js#L110): the `fixtures/a1.js` remains read-only after the first test run and `fs.open()` in append mode fails [here](https://github.com/nodejs/node/blob/98e54b0bd4854bdb3e2949d1b6b20d6777fb7cde/test/parallel/test-fs-chmod.js#L96) on the second test run.\r\n\r\n### Why the test does not detect this?\r\n\r\n[This assertion](https://github.com/nodejs/node/blob/98e54b0bd4854bdb3e2949d1b6b20d6777fb7cde/test/parallel/test-fs-chmod.js#L105) before failed `fs.fchmod()` call and [this assertion](https://github.com/nodejs/node/blob/98e54b0bd4854bdb3e2949d1b6b20d6777fb7cde/test/parallel/test-fs-chmod.js#L112) after the failed call check the same mode number in the failed case, but as long as this number is not falsy, the second assertion does not throw. On Windows, this number is not falsy in all the cases: it just differs in normal cases and remains the same in the edge case.\r\n\r\n### What possibly should be done?\r\n\r\n1. `fs.fchmod()` binding should be checked for this edge case. Maybe the bug should be reported upstream for `libuv` or even for Windows.\r\n2. The assertions in the test should be made stricter.\r\n\r\nUnfortunately, I cannot be any more help in this case, as I am not good in this realm. Sorry.",
        "labels": "confirmed-bug",
        "id": 45368
    },
    {
        "title": "readline: prompt opt-out behavior",
        "body": "* **Version**: v8.0.0-rc.0\r\n* **Platform**: Windows 4 x64\r\n* **Subsystem**: readline\r\n\r\nI am not sure if this is a bug or a feature.\r\n\r\nConsider this simple echo interface:\r\n```js\r\n'use strict';\r\n\r\nconst readline = require('readline');\r\n\r\nconst rl = readline.createInterface({\r\n  input: process.stdin,\r\n  output: process.stdout,\r\n});\r\n\r\nrl.on('line', (line) => {\r\n  console.log(line);\r\n});\r\n```\r\nIt does not use `rl.prompt()` anywhere and with a common input there will be no default prompt:\r\n<details>\r\n<summary>GIF 1:</summary>\r\n\r\n![1](https://cloud.githubusercontent.com/assets/10393198/25309441/020b938c-27d6-11e7-806e-a7a5f650e4d1.gif)\r\n\r\n</details><br>\r\n\r\nHowever, if a user press DELETE, BACKSPACE or UP button, default prompt immediately and somehow unexpectedly appears shifting the whole line:\r\n\r\n<details>\r\n<summary>GIF 2:</summary>\r\n\r\n![2](https://cloud.githubusercontent.com/assets/10393198/25309481/24a945d2-27d7-11e7-80ab-2fa1b7c2a24e.gif)\r\n\r\n</details><br>\r\n\r\nThis can be prevented by setting the `prompt` option into the empty line. However, I am not sure if this opt-out rule is an intended behavior.",
        "labels": "confirmed-bug",
        "id": 45369
    },
    {
        "title": "Int32 overflow when creating a buffer",
        "body": "- **Version**:  v7.9.0\r\n- **Platform**: Linux ***** 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\n- **Subsystem**: stream\r\n\r\nI noticed that there's an unhandled overflow error in `stream.Readable` in work earlier today; when large values are supplied as `highWaterMark` the value used by the created object wraps around to a negative number. This didn't cause us massive problems, but it is a little difficult to debug (given that most people won't read the contents of ` _readableState`)\r\n\r\n```\r\nconsole.log(\r\n\trequire('stream').Readable({\r\n\t\thighWaterMark: 2147483647\r\n\t})._readableState.highWaterMark\r\n)\r\n\r\nconsole.log(\r\n\trequire('stream').Readable({\r\n\t\thighWaterMark: 2147483647 + 1\r\n\t})._readableState.highWaterMark\r\n)\r\n```\r\nwhich outputs:\r\n```\r\n2147483647\r\n-2147483648\r\n```\r\n\r\nThis should ideally throw an error, or support larger numeric values.\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45370
    },
    {
        "title": "process:Why http_parser version do not display?",
        "body": "* **Version**:8.0.0-pre\r\n* **Platform**:Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64\r\n* **Subsystem**:http_parser\r\n\r\nWhen I type `node -p process.versions.http_parser` in Terminal,it display below:\r\n`HTTP_PARSER_VERSION_MAJOR.HTTP_PARSER_VERSION_MINOR.HTTP_PARSER_VERSION_PATCH`\r\n\r\nIt is never happen in  previous version,just nearest master branch.Windows and macOS be affected,and I do not test in Linux.",
        "labels": "confirmed-bug",
        "id": 45371
    },
    {
        "title": "ninja build failure on master",
        "body": "* **Version**: `master` \r\n* **Platform**: macOS Sierra, ninja\r\n* **Subsystem**: build\r\n\r\n### Repro:\r\n\r\n```bash\r\nalias bn='export CPPFLAGS=-fdiagnostics-color && ./configure && tools/gyp_node.py -f ninja && ninja -C out/Release && ln -fs out/Release/node node'\r\nmake clean\r\nbn\r\n```\r\n\r\n### Error:\r\n\r\n```cc\r\n[2284/2284] LINK cctest, POSTBUILDS\r\nFAILED: cctest \r\nc++ -Wl,-force_load,libopenssl.a -Wl,-force_load,libv8_base.a -Wl,-no_pie -Wl,-search_paths_first -mmacosx-version-min=10.7 -arch x86_64 -L. -stdlib=libc++ -o cctest obj/test/cctest/cctest.test_base64.o obj/test/cctest/cctest.test_environment.o obj/test/cctest/cctest.test_util.o obj/test/cctest/cctest.test_url.o obj/test/cctest/cctest.test_inspector_socket.o obj/test/cctest/cctest.test_inspector_socket_server.o obj/src/cctest.inspector_agent.o obj/src/cctest.inspector_io.o obj/src/cctest.inspector_socket.o obj/src/cctest.inspector_socket_server.o obj/src/cctest.node_crypto.o obj/src/cctest.node_crypto_bio.o obj/src/cctest.node_crypto_clienthello.o obj/src/cctest.tls_wrap.o obj/src/cctest.node_dtrace.o obj/src/cctest.backtrace_posix.o libgtest.a libzlib.a libopenssl.a libhttp_parser.a libuv.a libv8_libplatform.a libicui18n.a libcares.a libv8_libbase.a libv8_base.a libv8_libsampler.a libicuucx.a libicudata.a libicustubdata.a libv8_snapshot.a  obj.target/node/gen/node_javascript.o obj.target/node/src/node_debug_options.o obj.target/node/src/async-wrap.o obj.target/node/src/env.o obj.target/node/src/node.o obj.target/node/src/node_buffer.o obj.target/node/src/node_i18n.o obj.target/node/src/node_url.o obj.target/node/src/debug-agent.o obj.target/node/src/util.o obj.target/node/src/string_bytes.o obj.target/node/src/string_search.o obj.target/node/src/stream_base.o obj.target/node/src/node_constants.o obj.target/node/src/node_revert.o obj.target/node/src/tracing/agent.o obj.target/node/src/tracing/node_trace_buffer.o obj.target/node/src/tracing/node_trace_writer.o obj.target/node/src/tracing/trace_event.o -framework CoreFoundation -lm\r\nclang: error: no such file or directory: 'obj.target/node/gen/node_javascript.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/node_debug_options.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/async-wrap.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/env.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/node.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/node_buffer.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/node_i18n.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/node_url.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/debug-agent.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/util.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/string_bytes.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/string_search.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/stream_base.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/node_constants.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/node_revert.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/tracing/agent.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/tracing/node_trace_buffer.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/tracing/node_trace_writer.o'\r\nclang: error: no such file or directory: 'obj.target/node/src/tracing/trace_event.o'\r\nninja: build stopped: subcommand failed.\r\n```\r\n\r\nI originally got a longer error:\r\n\r\n<details><summary>On a dirty directory:</summary>\r\n```cc\r\nninja: Entering directory `out/Release'\r\n[7/7] LINK cctest, POSTBUILDS\r\nFAILED: cctest \r\nc++ -Wl,-force_load,libopenssl.a -Wl,-force_load,libv8_base.a -Wl,-no_pie -Wl,-search_paths_first -mmacosx-version-min=10.7 -arch x86_64 -L. -stdlib=libc++ -o cctest obj/test/cctest/cctest.test_base64.o obj/test/cctest/cctest.test_environment.o obj/test/cctest/cctest.test_util.o obj/test/cctest/cctest.test_url.o obj/test/cctest/cctest.test_inspector_socket.o obj/test/cctest/cctest.test_inspector_socket_server.o obj/src/cctest.inspector_agent.o obj/src/cctest.inspector_io.o obj/src/cctest.inspector_socket.o obj/src/cctest.inspector_socket_server.o obj/src/cctest.node_crypto.o obj/src/cctest.node_crypto_bio.o obj/src/cctest.node_crypto_clienthello.o obj/src/cctest.tls_wrap.o obj/src/cctest.node_dtrace.o obj/src/cctest.backtrace_posix.o libgtest.a libzlib.a libopenssl.a libhttp_parser.a libuv.a libv8_libplatform.a libicui18n.a libcares.a libv8_libbase.a libv8_base.a libv8_libsampler.a libicuucx.a libicudata.a libicustubdata.a libv8_snapshot.a  obj.target/node/gen/node_javascript.o obj.target/node/src/node_debug_options.o obj.target/node/src/async-wrap.o obj.target/node/src/env.o obj.target/node/src/node.o obj.target/node/src/node_buffer.o obj.target/node/src/node_i18n.o obj.target/node/src/node_url.o obj.target/node/src/debug-agent.o obj.target/node/src/util.o obj.target/node/src/string_bytes.o obj.target/node/src/string_search.o obj.target/node/src/stream_base.o obj.target/node/src/node_constants.o obj.target/node/src/node_revert.o obj.target/node/src/tracing/agent.o obj.target/node/src/tracing/node_trace_buffer.o obj.target/node/src/tracing/node_trace_writer.o obj.target/node/src/tracing/trace_event.o -framework CoreFoundation -lm\r\nUndefined symbols for architecture x86_64:\r\n  \"v8::FunctionTemplate::New(v8::Isolate*, void (*)(v8::FunctionCallbackInfo<v8::Value> const&), v8::Local<v8::Value>, v8::Local<v8::Signature>, int)\", referenced from:\r\n      node::AsyncWrap::Initialize(v8::Local<v8::Object>, v8::Local<v8::Value>, v8::Local<v8::Context>) in async-wrap.o\r\n      node::SetupNextTick(v8::FunctionCallbackInfo<v8::Value> const&) in node.o\r\n      node::SetupProcessObject(node::Environment*, int, char const* const*, int, char const* const*) in node.o\r\n      node::LoadEnvironment(node::Environment*) in node.o\r\n      node::CreateEnvironment(v8::Isolate*, uv_loop_s*, v8::Local<v8::Context>, int, char const* const*, int, char const* const*) in node.o\r\n      node::Environment::Environment(v8::Local<v8::Context>, uv_loop_s*) in node.o\r\n      node::Buffer::SetupBufferJS(v8::FunctionCallbackInfo<v8::Value> const&) in node_buffer.o\r\n      ...\r\n     (maybe you meant: __ZN2v816FunctionTemplate3NewEPNS_7IsolateEPFvRKNS_20FunctionCallbackInfoINS_5ValueEEEENS_5LocalIS4_EENSA_INS_9SignatureEEEiNS_19ConstructorBehaviorE)\r\n  \"v8::Context::New(v8::Isolate*, v8::ExtensionConfiguration*, v8::Local<v8::ObjectTemplate>, v8::Local<v8::Value>)\", referenced from:\r\n      node::Start(int, char**) in node.o\r\n      node::debugger::Agent::WorkerRun() in debug-agent.o\r\n  \"node::FreeIsolateData(node::IsolateData*)\", referenced from:\r\n      EnvironmentTest_AtExitWithEnvironment_Test::TestBody() in cctest.test_environment.o\r\n      EnvironmentTest_AtExitWithArgument_Test::TestBody() in cctest.test_environment.o\r\n      EnvironmentTest_MultipleEnvironmentsPerIsolate_Test::TestBody() in cctest.test_environment.o\r\n  \"node::CreateEnvironment(node::IsolateData*, v8::Local<v8::Context>, int, char const* const*, int, char const* const*)\", referenced from:\r\n      EnvironmentTest::Env::Env(v8::HandleScope const&, v8::Isolate*, Argv const&) in cctest.test_environment.o\r\n  \"node::CreateIsolateData(v8::Isolate*, uv_loop_s*)\", referenced from:\r\n      EnvironmentTest::Env::Env(v8::HandleScope const&, v8::Isolate*, Argv const&) in cctest.test_environment.o\r\n  \"node::LowMemoryNotification()\", referenced from:\r\n      char* node::UncheckedRealloc<char>(char*, unsigned long) in cctest.test_util.o\r\n      unsigned char* node::UncheckedRealloc<unsigned char>(unsigned char*, unsigned long) in cctest.test_util.o\r\n      unsigned short* node::UncheckedRealloc<unsigned short>(unsigned short*, unsigned long) in cctest.test_util.o\r\n      char* node::UncheckedRealloc<char>(char*, unsigned long) in cctest.node_crypto.o\r\n      unsigned char* node::UncheckedRealloc<unsigned char>(unsigned char*, unsigned long) in cctest.node_crypto.o\r\n      EC_builtin_curve* node::UncheckedRealloc<EC_builtin_curve>(EC_builtin_curve*, unsigned long) in cctest.node_crypto.o\r\n      char* node::UncheckedRealloc<char>(char*, unsigned long) in cctest.tls_wrap.o\r\n      ...\r\n  \"node::ssl_openssl_cert_store\", referenced from:\r\n      node::crypto::NewRootCertStore() in cctest.node_crypto.o\r\n  \"node::i18n::InitializeICUDirectory(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)\", referenced from:\r\n      URLTest::SetUp() in cctest.test_url.o\r\n  \"node::i18n::ToASCII(node::MaybeStackBuffer<char, 1024ul>*, char const*, unsigned long, bool)\", referenced from:\r\n      node::url::ParseHost(node::url::url_host*, char const*, unsigned long, bool) in node_url.o\r\n  \"node::i18n::ToUnicode(node::MaybeStackBuffer<char, 1024ul>*, char const*, unsigned long, bool)\", referenced from:\r\n      node::url::ParseHost(node::url::url_host*, char const*, unsigned long, bool) in node_url.o\r\n  \"node::AtExit(node::Environment*, void (*)(void*), void*)\", referenced from:\r\n      EnvironmentTest_AtExitWithEnvironment_Test::TestBody() in cctest.test_environment.o\r\n      EnvironmentTest_AtExitWithArgument_Test::TestBody() in cctest.test_environment.o\r\n      EnvironmentTest_MultipleEnvironmentsPerIsolate_Test::TestBody() in cctest.test_environment.o\r\n  \"node::crypto::UseExtraCaCerts(std::string const&)\", referenced from:\r\n      node::Start(int, char**) in node.o\r\n  \"node::inspector::Agent::Start(v8::Platform*, char const*, int, bool)\", referenced from:\r\n      node::StartDebug(node::Environment*, char const*, bool) in node.o\r\n  \"std::string::_Rep::_M_destroy(std::allocator<char> const&)\", referenced from:\r\n      node::Start(int, char**) in node.o\r\n      node::debugger::Agent::~Agent() in debug-agent.o\r\n  \"std::string::_Rep::_S_empty_rep_storage\", referenced from:\r\n      node::Start(int, char**) in node.o\r\n      __GLOBAL__sub_I_node.cc in node.o\r\n      node::debugger::Agent::Agent(node::Environment*) in debug-agent.o\r\n      node::debugger::Agent::~Agent() in debug-agent.o\r\n  \"std::string::assign(char const*, unsigned long)\", referenced from:\r\n      node::Init(int*, char const**, int*, char const***) in node.o\r\n  \"std::string::assign(std::string const&)\", referenced from:\r\n      node::debugger::Agent::Start(std::string const&, int, bool) in debug-agent.o\r\n  \"std::string::replace(unsigned long, unsigned long, char const*, unsigned long)\", referenced from:\r\n      node::Init(int*, char const**, int*, char const***) in node.o\r\n  \"std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, std::allocator<char> const&)\", referenced from:\r\n      node::Start(int, char**) in node.o\r\n  \"std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()\", referenced from:\r\n      __GLOBAL__sub_I_node.cc in node.o\r\n  \"std::__throw_length_error(char const*)\", referenced from:\r\n      std::vector<long long, std::allocator<long long> >::reserve(unsigned long) in node.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nninja: build stopped: subcommand failed.\r\n```\r\n</details>",
        "labels": "confirmed-bug",
        "id": 45372
    },
    {
        "title": "`setTimeout(function(){throw null},0)` crashes toplevel",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.10.0\r\n* **Platform**: `Linux localhost.hsd1.tn.comcast.net 4.10.8-200.fc25.x86_64 #1 SMP Fri Mar 31 13:20:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux`\r\n* **Subsystem**: `timer`\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nIf I run\r\n\r\n```js\r\nsetTimeout(function() { throw null }, 0)\r\n```\r\nthe REPL crashes with\r\n\r\n```\r\nTypeError: Cannot read property 'stack' of null\r\n    at Domain.<anonymous> (repl.js:392:17)\r\n    at emitOne (events.js:96:13)\r\n    at Domain.emit (events.js:188:7)\r\n    at Domain._errorHandler (domain.js:97:23)\r\n    at process._fatalException (bootstrap_node.js:293:33)\r\n```\r\n\r\nObviously such code is buggy (and would normally cause a crash).  However, I donâ€™t think that it should crash the toplevel, hence this report.",
        "labels": "confirmed-bug",
        "id": 45373
    },
    {
        "title": "regression: 3rd party debuggers are incompatible with node8 nighlies",
        "body": "In https://github.com/nodejs/node/pull/12197, support for `--inspect --debug-brk` was removed, and `--inspect-brk` should now be used instead, but `--inspect-brk` is only supported after 7.6.0. \r\nSince there is no common way to start the inspector across all Node versions that support it, this is an issue for VS Code and other debug clients which now have to determine which version of Node they are launching and select the right arguments, or detect when using one set fails, and try the other set. It's also annoying for anyone who switches node versions often and uses these arguments from the command line.\r\n\r\nWould it be possible to retain support for `--inspect --debug-brk` so that there's one command which can start Node in debug mode across all versions that support the inspector protocol? If it simplifies things, it could be undocumented.\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45374
    },
    {
        "title": "process: flaky behavior of 'exit' event handler",
        "body": "* **Version**: '8.0.0-rc.0'\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: process\r\n\r\n`process.md` [states](https://github.com/nodejs/node/blob/master/doc/api/process.md#event-exit):\r\n\r\n> Listener functions **must** only perform **synchronous** operations. The Node.js\r\n> process will exit immediately after calling the `'exit'` event listeners\r\n> causing any additional work still queued in the event loop to be abandoned.\r\n> In the following example, for instance, the timeout will never occur:\r\n> \r\n> ```js\r\n> process.on('exit', (code) => {\r\n>   setTimeout(() => {\r\n>     console.log('This will not run');\r\n>   }, 0);\r\n> });\r\n> ```\r\n\r\nHowever, the behavior of the code is flaky:\r\n```\r\n> test.js\r\n\r\n> test.js\r\nThis will not run\r\n\r\n> test.js\r\nThis will not run\r\n\r\n> test.js\r\n\r\n> test.js\r\n\r\n> test.js\r\n\r\n> test.js\r\nThis will not run\r\n\r\n...\r\n```\r\nIf this flakiness is not a bug, what would be better?\r\n\r\n1. Increase the timeout up to `1000` or something and save the categorical 'the timeout will never occur'.\r\n2. State flakiness. If so, what would be preferable wordings for the description and the logged string?\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45375
    },
    {
        "title": "Fatal V8 Compiler Error",
        "body": "* **Version**: 6.10.2\r\n* **Platform**: 64-bit Windows (also tested on Linux, not sure which arch)\r\n* **Subsystem**: V8 Compiler\r\n\r\n<!-- Enter your issue details below this comment. -->\r\nThe third line in the following script causes an error in the [v8 compiler](https://github.com/nodejs/node/blob/v6.x/deps/v8/src/compiler.cc#L786):\r\n```js\r\nconst sphincs = require('sphincs') // npm install sphincs@1.0.2\r\nconsole.log('blah')\r\nconst keyPair = sphincs.keyPair()\r\n```\r\n```\r\nblah\r\n\r\n\r\n#\r\n# Fatal error in ..\\..\\src\\compiler.cc, line 786\r\n# Check failed: !info->shared_info()->feedback_vector()->metadata()->SpecDiffersFrom( info->literal()->feedback_vector_spec()).\r\n#\r\n```\r\n\r\n**Node 7.8.0 (V8 5.5.372) is not affected.**\r\n\r\nThis module is an emscripten transpile, and the issue specifically affects the optimised emcc -O3 build. The compiled, minified source is 107KB so I've made no attempts to debug any further.\r\n\r\n[An option suggested to the module author](https://github.com/cyph/sphincs.js/issues/1) is to create a legacy build with less optimisations - so there's certainly workarounds in this case, but could this be a symptom of a deeper issue?\r\n\r\nAre there any plans to upgrade V8 for 6.x?",
        "labels": "confirmed-bug",
        "id": 45376
    },
    {
        "title": "node aborts with --debug when it self-exits",
        "body": "* **Version**: 7.x, 6.x, 4.x (there is no `--debug` in master)\r\n* **Platform**: Linux (at least)\r\n* **Subsystem**: debugger\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`node --debug test/fixtures/printA.js` (node's test/fixtures), `node --debug -p process.features`, `node --debug -e \"console.log('hi')\", all abort on https://github.com/nodejs/node/blob/610ac7d8581012e627a4f4b67450b423ddbda415/src/debug-agent.cc#L147 with UV_EBUSY, because there is still work.\r\n\r\nThe check seems invalid to me, `uv_run()` runs with `NOWAIT`, so its not guaranteed to run til the loop is empty, just until there is nothing that would involve blocking, IIRC.\r\n\r\nI tried adding `setTimeout()` and `setImmediate()` into `printA.js`, same thing. I think the debugger just doesn't expect to be used to debug a node process which is not long-lived.\r\n\r\n```\r\ncore/node (v8.x *$% u=) % ./node --debug test/fixtures/printA.js\r\n(node:27775) [DEP0062] DeprecationWarning: node --debug is deprecated. Please use node --inspect instead.\r\nDebugger listening on 127.0.0.1:5858\r\nA\r\nerr -16/home/sam/w/core/node/out/Release/node[27775]: ../src/debug-agent.cc:148:void node::debugger::Agent::Stop(): Assertion `(err) == (0)' failed.\r\n 1: node::Abort() [./node]\r\n 2: node::Assert(char const* const (*) [4]) [./node]\r\n 3: 0x5645e6a64394 [./node]\r\n 4: node::debugger::Agent::~Agent() [./node]\r\n 5: node::Environment::~Environment() [./node]\r\n 6: node::Start(uv_loop_s*, int, char const* const*, int, char const* const*) [./node]\r\n 7: node::Start(int, char**) [./node]\r\n 8: __libc_start_main [/lib/x86_64-linux-gnu/libc.so.6]\r\n 9: _start [./node]\r\nzsh: abort (core dumped)  ./node --debug test/fixtures/printA.js\r\n```",
        "labels": "confirmed-bug",
        "id": 45377
    },
    {
        "title": "V6.x crash with holes following spreads in array literals",
        "body": "* **Version**: 6.10.1\r\n* **Platform**: Linux\r\n* **Subsystem**: V8\r\n\r\nRepro: `node -e \"var arr = [...[],,]; arr[0][0];\"`\r\n\r\nFix: https://github.com/v8/v8/commit/e4273007b613950845e92d479485ec737eb61185\r\nI found this while investigating https://github.com/nodejs/node/issues/11977",
        "labels": "confirmed-bug",
        "id": 45378
    },
    {
        "title": "V6.x crash with illegal spread as single arrow parameter",
        "body": "\r\n* **Version**: 6.10.1\r\n* **Platform**: Linux\r\n* **Subsystem**: V8\r\n\r\nRepro: `node -e \"(...[42]) => 42\"`\r\n\r\nFix: https://github.com/v8/v8/commit/b9f682baafb8fee8cca154d6dd66359facc06a69\r\nI found this while investigating https://github.com/nodejs/node/issues/11977",
        "labels": "confirmed-bug",
        "id": 45379
    },
    {
        "title": "Buffer.from('base64') decodes some white space as data",
        "body": "I am writing a native addon to decode a buffer containing base64 directly into another buffer, without requiring the allocation of an interim string (see https://github.com/nodejs/node/issues/11866 for why Node cannot decode base64 buffers directly).\r\n\r\nI wrote a fuzz test to test my own decoder, and then decided to try it out on Node's base64 decoder.\r\n\r\nThere are a few cases where Node's decoder treats whitespace as actual data, rather than ignoring it. This happens when the \"=\" is left out:\r\n\r\n```\r\n// Fails:\r\n> Buffer.from(\"3v6YpUFyK0/hitA2tCDIfdYKw0 g \", 'base64').toString('binary')\r\n'ÃžÃ¾Â˜Â¥Ar+OÃ¡ÂŠÃ6Â´ Ãˆ}Ã–\\nÃƒH>'\r\n> Buffer.from(\"3v6YpUFyK0/hitA2tCDIfdYKw0g \", 'base64').toString('binary')\r\n'ÃžÃ¾Â˜Â¥Ar+OÃ¡ÂŠÃ6Â´ Ãˆ}Ã–\\nÃƒH>'\r\n> Buffer.from(\"3v6YpUFyK0/hitA2tCDIfdYKw0g\\n\", 'base64').toString('binary')\r\n'ÃžÃ¾Â˜Â¥Ar+OÃ¡ÂŠÃ6Â´ Ãˆ}Ã–\\nÃƒH>'\r\n\r\n// Passes:\r\n> Buffer.from(\"3v6YpUFyK0/hitA2tCDIfdYKw0g=\", 'base64').toString('binary')\r\n'ÃžÃ¾Â˜Â¥Ar+OÃ¡ÂŠÃ6Â´ Ãˆ}Ã–\\nÃƒH'\r\n> Buffer.from(\"3v6YpUFyK0/hitA2tCDIfdYKw0g\", 'base64').toString('binary')\r\n'ÃžÃ¾Â˜Â¥Ar+OÃ¡ÂŠÃ6Â´ Ãˆ}Ã–\\nÃƒH'\r\n```\r\n\r\nIn the failing cases, Node's decoder has interpolated a \">\".",
        "labels": "confirmed-bug",
        "id": 45380
    },
    {
        "title": "In async function, returns a value in try block will before await statement in finally block",
        "body": "* **Version**: 7.7.3\r\n* **Platform**: Arch Linux\r\n\r\nTestcase:\r\n```javascript\r\nasync function test() {\r\n    try {\r\n        console.log(\"1\");\r\n        return await Promise.resolve();\r\n    } finally {\r\n        console.log(\"2\");\r\n        await Promise.resolve();\r\n        console.log(\"3\");\r\n    }\r\n}\r\n\r\ntest().then(() => {\r\n    console.log(\"4\");\r\n});\r\n```\r\n\r\nExpected: \r\n```\r\n1\r\n2\r\n3\r\n4\r\n```\r\n\r\nActual:\r\n```\r\n1\r\n2\r\n4\r\n3\r\n```\r\n\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45381
    },
    {
        "title": "Buffer::Length hard crashes",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 6.9.2 -> 7.2.0\r\n* **Platform**: Linux\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n[Buffer::Length ](https://github.com/PLSysSec/node/blob/master/src/node_buffer.cc#L263) hard crashes.\r\n\r\nI know that there are other issues where what to do about crashing bugs is being discussed, but I think most of the other examples are code directly accessible to JavaScript via process.binding. Here is an example that is something more subtle, but nevertheless can be triggered.\r\n\r\n```javascript\r\nconst dgram = require('dgram');\r\nconst util = require('util');\r\n// Create object that passes instanceof Buffer check\r\nfunction FakeBuffer() { }\r\nutil.inherits(FakeBuffer, Buffer);\r\nconst message = new FakeBuffer();\r\n// Pass object to code that eventually calls Length\r\ndgram.createSocket('udp4'). send(message, 41234, 'localhost', _ => {});\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45382
    },
    {
        "title": "vm: known issue with CopyProperties throw on empty code",
        "body": "CopyProperties() causes sandboxed Proxy to throw error\r\ndespite no code being run. The CopyProperties() function\r\nwill be removed shortly with the updates to the V8 API.\r\n\r\nRefs: https://github.com/nodejs/node/pull/11671\r\n\r\n```js\r\n'use strict';\r\n\r\n//Sandbox throws in CopyProperties() despite no code being run\r\n\r\nrequire('../common');\r\nconst assert = require('assert');\r\nconst vm = require('vm');\r\n\r\nconst handler = {\r\n    getOwnPropertyDescriptor: (target, prop) => {\r\n      throw new Error('whoops');\r\n    }\r\n};\r\nconst sandbox = new Proxy({foo: 'bar'}, handler);\r\nconst context = vm.createContext(sandbox);\r\n\r\n\r\nassert.doesNotThrow(() => vm.runInContext('', context));\r\n```",
        "labels": "confirmed-bug",
        "id": 45383
    },
    {
        "title": "npm delete itself after I make \"npm update -g\"",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.10.0\r\n* **Platform**: Darwin alaambp.local 16.4.0 Darwin Kernel Version 16.4.0: Thu Dec 22 22:53:21 PST 2016; root:xnu-3789.41.3~3/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nAfter upgrading to v7.7.3, every sometime I make `npm update -g` to update my installed npm packages, this time it throw a lot of errors and stop working. when I make `npm -v` => \"zsh: command not found: npm\" .. \r\nThen I thought something wrong with v7.7.3. I removed all install packages and the whole directory of node_modules, and actually I removed whole node from my system and reinstalled it again but this time I went with v6.10.0 the more stable one. Also did the same and throw error and then when I check for npm existence I don't find it.. \r\n[npm-debug.txt](https://github.com/nodejs/node/files/847150/npm-debug.txt)\r\n",
        "labels": "confirmed-bug",
        "id": 45384
    },
    {
        "title": "net.Socket.prototype.connect is having TypeError when called without connectionListener",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 7.7.2\r\n* **Platform**: Linux ip-172-31-25-224 4.4.0-53-generic #74-Ubuntu SMP Fri Dec 2 15:59:10 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**:\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`net.Socket.prototype.connect` should work fine without callback (connectionListener) according to [doc](https://nodejs.org/dist/latest-v7.x/docs/api/net.html#net_socket_connect_options_connectlistener)\r\n\r\nbut it's working like this\r\n\r\n```\r\n> (new net.Socket()).connect({ host:'google.com', port:80 })\r\nTypeError: \"listener\" argument must be a function\r\n    at Socket.once (events.js:307:11)\r\n    at Socket.connect (net.js:943:10)\r\n    at repl:1:20\r\n    at ContextifyScript.Script.runInThisContext (vm.js:23:33)\r\n    at REPLServer.defaultEval (repl.js:336:29)\r\n    at bound (domain.js:280:14)\r\n    at REPLServer.runBound [as eval] (domain.js:293:12)\r\n    at REPLServer.onLine (repl.js:533:10)\r\n    at emitOne (events.js:101:20)\r\n    at REPLServer.emit (events.js:191:7)\r\n```\r\n\r\nrelated PR: https://github.com/nodejs/node/pull/11667",
        "labels": "confirmed-bug",
        "id": 45385
    },
    {
        "title": "Use of variables + for loop + switch in a generator function causes inspector to crash",
        "body": "* **Version**: 7.6.0\r\n* **Platform**: Darwin Matthews-MBP-2.lan 16.3.0 Darwin Kernel Version 16.3.0: Thu Nov 17 20:23:58 \r\n* **Subsystem**: Unknown\r\n\r\nI was able to reduce it down to this code:\r\n\r\n**tcase.js**\r\n\r\n```js\r\nfunction* serialize() {\r\n  for(let i = 0; i < 10; i++) {\r\n    let value;\r\n    let section = {};\r\n\r\n    debugger;\r\n\r\n    switch('foo') {\r\n      case 'bar':\r\n        let items = [];\r\n        break;\r\n    }\r\n  }\r\n}\r\n\r\nlet gen = serialize();\r\ngen.next();\r\n```\r\n\r\nRun with `node --debug-brk --inspect tcase.js`. Stop on the `debugger` and then click to step over. It will crash with `1]    50320 illegal hardware instruction  node --debug-brk --inspect tcase.js`.\r\n\r\nI dumped the output into [this gist](https://gist.github.com/matthewp/ebc9c30c2e5f0a45afb3ec8bdc1bc109).\r\n",
        "labels": "confirmed-bug",
        "id": 45386
    },
    {
        "title": "--check flag doesn't always prevent execution",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: all\r\n* **Platform**: all\r\n* **Subsystem**: internal/bootstrap_node.js\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n```\r\n-c, --check\r\n       Syntax check the script without executing.\r\n```\r\n\r\nThe node `--check` flag is supposed to check syntax and then **stop**. However, [as currently implemented](https://github.com/nodejs/node/blob/f385f77f1d011786cb1c5e80f257fa043f4c608b/lib/internal/bootstrap_node.js#L129-L143) the `--check` flag is ignored if the script to be checked is given via stdin or via `-e` flag; and the script is executed regardless.\r\n\r\nFor instance:\r\n\r\n    $ echo 'console.log(\"hello\")' | node --check\r\n    \r\n    $ node --check -e 'console.log(\"hello\")'\r\n\r\n* **Expected behaviour**: nothing prints (but any syntax errors are reported)\r\n* **Actual behaviour**: \"hello\" is printed to stdout in both cases\r\n",
        "labels": "confirmed-bug",
        "id": 45387
    },
    {
        "title": "Some possible bugs concerning fs.appendFile() and fs.writeFile()",
        "body": "* **Version**: 7.6.0\r\n* **Platform**: Windows 7 x64\r\n* **Subsystem**: fs, test\r\n\r\n1\\. `fs.appendFile()` and `fs.writeFile()` can be called without mandatory `data` parameter, while not throwing any error messages. Thus, the only second parameter serves as `data` and `callback` (mandatory as well) parameters at the same time.\r\n```js\r\nconst fs = require('fs');\r\n\r\nconst cb = (err) => { if(err) console.error(err); }\r\n\r\nfs.appendFile('append-file.txt', cb);\r\nfs.writeFile('write-file.txt', cb);\r\n```\r\nThis code runs without any errors and produces 2 files with the same content:\r\n```\r\n> cat append-file.txt\r\n(err) => { if(err) console.error(err); }\r\n> cat write-file.txt\r\n(err) => { if(err) console.error(err); }\r\n```\r\nIt seems this is hardly an expected behavior.\r\n\r\n2\\.  [`test/parallel/test-fs-null-bytes.js`](https://github.com/nodejs/node/blob/master/test/parallel/test-fs-null-bytes.js) tests these functions with wrong parameters scheme, i.e. without mandatory `data` parameter. This may be not very important for the test aim, but it makes it somehow compromised.",
        "labels": "confirmed-bug",
        "id": 45388
    },
    {
        "title": "Destructuring Assignment Parse Error - works in Chrome & Safari but not Node",
        "body": "* **Version**: v6.9.5\r\n* **Platform**: Darwin Honor.local 16.4.0 Darwin Kernel Version 16.4.0: Thu Dec 22 22:53:21 PST 2016; root:xnu-3789.41.3~3/RELEASE_X86_64 x86_64\r\n* **Subsystem**: parser\r\n\r\nThis source: `a=b=1;((a + 1), {c} = b)`\r\n\r\n* Works in Chrome 56.0.2924.87\r\n* Works in Safari 10.0.3 (12602.4.8)\r\n* Fails to parse in Node\r\n\r\nQuick command-line test:\r\n* `echo \"a=b=1;((a + 1), {c} = b)\" | node`\r\n\r\nThese slight variations DO work in node:\r\n* `a=b=1;((a), {c} = b)`\r\n* `a=b=1;((a + 1), ({c} = b))`\r\n",
        "labels": "confirmed-bug",
        "id": 45389
    },
    {
        "title": "stderr redirection breaks require",
        "body": "* **Version**: 7.5.0\r\n* **Platform**: Darwin Kernel Version 16.5.0 (mac os sierra)\r\n\r\nrelated workaround: https://github.com/rtfeldman/node-test-runner/pull/106, https://github.com/rtfeldman/node-test-runner/pull/106/commits/959fda06c99a19a0cc72d4a7b5568a405c11373a\r\n\r\nWe noticed that when redirecting stderr AND receiving input script via pipe, `require` doesn't work with packages in package.json.\r\n\r\n\r\nMinimal test case: (given a `package.json` that includes ajv).\r\n\r\n```bash\r\necho \"require('ajv')\" | node &> js.out || cat js.out\r\n```\r\n\r\nexpected output: nothing, it's just a require\r\n\r\nactual output: \r\n```\r\nfs.js:56\r\n    assertEncoding(options.encoding);\r\n    ^\r\n\r\nTypeError: assertEncoding is not a function\r\n    at getOptions (fs.js:56:5)\r\n    at Object.realpathSync (fs.js:1468:13)\r\n    at toRealPath (module.js:130:13)\r\n    at tryFile (module.js:126:22)\r\n    at tryPackage (module.js:107:10)\r\n    at Function.Module._findPath (module.js:183:20)\r\n    at Function.Module._resolveFilename (module.js:468:25)\r\n    at Function.Module._load (module.js:418:25)\r\n    at Module.require (module.js:498:17)\r\n    at require (internal/module.js:20:19)\r\n```\r\n\r\nalso tested on another Ubuntu 14.04 server. Was not a problem using node 6.9.5",
        "labels": "confirmed-bug",
        "id": 45390
    },
    {
        "title": "this[searchParams].push is not a function",
        "body": "```js\r\nconst url = new (require(\"url\").URL)(\"http://domain/?var=\");\r\nconsole.log(url.searchParams);\r\nurl.search = \"\";  // critical step\r\nconsole.log(url.searchParams);\r\nurl.searchParams.append(\"asdf\", \"asdf\");\r\nconsole.log(url.searchParams);\r\n```\r\n```\r\nTypeError: this[searchParams].push is not a function\r\n    at URLSearchParams.append (internal/url.js:737:24)\r\n    at repl:1:148\r\n    at ContextifyScript.Script.runInThisContext (vm.js:23:33)\r\n    at REPLServer.defaultEval (repl.js:340:29)\r\n    at bound (domain.js:280:14)\r\n    at REPLServer.runBound [as eval] (domain.js:293:12)\r\n    at REPLServer.onLine (repl.js:537:10)\r\n    at emitOne (events.js:101:20)\r\n    at REPLServer.emit (events.js:189:7)\r\n    at REPLServer.Interface._onLine (readline.js:238:10)\r\n```\r\n\r\nThis is a regression introduced in Node v7.5, as v7.4 doesn't have this issue.",
        "labels": "confirmed-bug",
        "id": 45391
    },
    {
        "title": "Swapping two arrays seems to behave asynchronous outside function",
        "body": "**Version:** v7.1.0\r\n**Platform**: Windows 8.1; 64-bit\r\n\r\n**Issue details:** Swapping two variables from a function sometimes behaves like it is asynchronous as seen from outside that function, but synchronous from inside. It only happens when variables are swapped using the following short syntax:\r\n\r\n    [a, b] = [b, a];\r\n\r\nHowever, it doesn't hapen every time. This is an example\r\n\r\n\t'use strict';\r\n\r\n\tvar a = [];\r\n\tvar b = [];\r\n\tvar c = () => a;\r\n\tvar d = () => [a, b] = [b, a];\r\n\r\n\td();\r\n\r\n\tconsole.log(a === c()); // Sometimes it prints `false`, which should be impossible\r\n\r\nHowever, it doesn't work always. But, after a few hours of testing, I came up with the following code, which **always** prints wrong output:\r\n\r\n\t'use strict';\r\n\r\n\t// Here if I change `const` to `var` it prints 111\r\n\tconst w = 100;\r\n\tconst h = 100;\r\n\r\n\tvar first = new Array(100).fill(0).map(() => new Uint8Array(100));\r\n\tvar second = new Array(100).fill(0).map(() => new Uint8Array(100));\r\n\tvar getFirst = () => first;\r\n\r\n\tvar x, y;\r\n\tvar beginning = true;\r\n\tvar i = 0;\r\n\r\n\tvar func = () => {\r\n\t\tif(beginning){\r\n\t\t\tbeginning = false;\r\n\r\n\t\t\t// If I remove bitwise `or` operator from here, it prints 111\r\n\t\t\tfor(y = 0; (y | 0) < (h | 0); y++) for(x = 0; (x | 0) < (w | 0); x++){}\r\n\t\t}else{\r\n\t\t\tfor(y = 0; y < h; y++) for(x = 0; x < w; x++){\r\n\r\n\t\t\t\t// If I change the number 1 to 0 from this line, it prints 111\r\n\t\t\t\tif((first[x | 0][y | 0] | 0) + 1);\r\n\t\t\t}\r\n\r\n\t\t\t[first, second] = [second, first];\r\n\t\t}\r\n\r\n\t\tconsole.log(first === getFirst() ? 1 : 0); // It should always print 1, but third time it prints 0\r\n\t};\r\n\r\n\tfunc(); // Prints 1, that is ok\r\n\tfunc(); // Prints 1 too, its  ok\r\n\tfunc(); // This one always prints 0\r\n\r\nHere is how output looks like. I cannot find any possible explanations why is zero here:\r\n\r\n![1][1]\r\n\r\n[1]: http://i.imgur.com/N3RXOi7.png",
        "labels": "confirmed-bug",
        "id": 45392
    },
    {
        "title": "Documentation: conflicting \"Added in\" for Buffer methods",
        "body": "There as some new Buffer methods introduced to replace the now deprecated `new Buffer()` invocation. But there is conflicting information in the docs as to when these became available.\r\n\r\nFor example, according to v4 API docs:\r\n```\r\nClass Method: Buffer.allocUnsafe(size)\r\nAdded in: v4.5.0\r\n```\r\n\r\nBut according to latest API docs:\r\n```\r\nClass Method: Buffer.allocUnsafe(size)\r\nAdded in: v5.10.0\r\n```\r\n\r\nWhy the difference and which one is right? (Need to know to set the minimum supported Node version for my app.)",
        "labels": "confirmed-bug",
        "id": 45393
    },
    {
        "title": "Crash using SNICallback over a netSocket",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: 6.9.3\r\n* **Platform**: Linux 4.4.0-28-generic #47~14.04.1-Ubuntu SMP Fri Jun 24 16:30:35 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\r\n* **Subsystem**: 'tls'\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nMy node app is crashing often when using `SNICallback` with `netSocket` and `netServer`, can't reproduce it yet.\r\n\r\nBacktrace:\r\n```\r\n _tls_wrap.js:117\r\n   if (ctx.context)\r\n          ^\r\n  TypeError: Cannot read property 'context' of undefined\r\n     at requestOCSP (_tls_wrap.js:117:10)\r\n     at _tls_wrap.js:167:5\r\n     at loadSNI (_tls_wrap.js:88:12)\r\n     at TLSSocket.oncertcb (_tls_wrap.js:164:3)\r\n     at TLSWrap.ssl.oncertcb (_tls_wrap.js:418:39)\r\n```\r\nHere is a small piece of code just to show what is done:\r\n```\r\n//options object to use with tls.TLSSocket()\r\nvar sslOptions = {\r\n\tisServer : true,\r\n\r\n\tSNICallback : function(hostname, callback){\r\n\t\tcallback(null, tls.createSecureContext(fetchDomainCertificate()));\r\n\t},\r\n\r\n\tkey : fetchDefaultKey(),\r\n\tcert : fetchDefaultCert(),\r\n\tca : fetchDefaultCa(),\r\n\r\n\trequestCert : false,\r\n\trejectUnauthorized : false,\r\n\trequestOCSP : false\r\n}\r\n\r\n//create a server using 'net' package\r\nvar server = net.createServer(function(_socket){\r\n\tvar socket = new tlswrapper.tlsWrapper(_socket);\r\n\tvar lineStream = readline.createInterface(socket, socket);\r\n\r\n\tlineStream.on('line', function(line){\r\n\t\tif(line == \"STARTTLS\"){\r\n\t\t\t//issue the encryption mechanism\r\n\t\t\tsocket.startTLS(sslOptions);\r\n\t\t}\r\n\t});\r\n\r\n\t[...]\r\n\r\n}).listen(anyPort);\r\n\r\n//see here that I'm using a netServer, not a tlsServer.\r\nsslOptions.server = server;\r\n```\r\nThe [tlswrapper](https://github.com/nodejs/node/files/693370/tlswrapper.zip) attached here is what invokes `new tls.TLSSocket(socket, sslOptions)`, you should take a look at it.\r\n\r\nThe code above is what is used in production and works for dozens or hundreds of requests (which means a few minutes) until it crashes, but I wasn't able to reproduce it on a test case. I'll keep working on that.\r\n\r\nAlso, I would like to point that it seems to call that `requestOSCP()` function even though I set it to `false`.\r\n\r\nIt works fine if I use any `tlsServer` instead of the `netServer`, by just changing the last line to this:\r\n```\r\nsslOptions.server = tls.createServer(sslOptions);\r\n```",
        "labels": "confirmed-bug",
        "id": 45394
    },
    {
        "title": "Node v4 not respect const scope in while block",
        "body": "* Version: 4.7.0\r\n* Platform: Linux, Mac, Windows\r\n\r\nDemo code: https://github.com/lijunle/bug-node-v4-while-const/blob/master/index.js\r\n\r\nThe build output: [Travis](https://github.com/lijunle/bug-node-v4-while-const), [AppVeyor](https://ci.appveyor.com/project/lijunle/bug-node-v4-while-const). It is causing a dead loop in the `while` block.\r\n\r\nThis bug only happens in v4 and not v6 or v7. I understand that, v4 is in maintain status, but I think this is a critical bug.",
        "labels": "confirmed-bug",
        "id": 45395
    },
    {
        "title": "Invalid Url when domain contains between 4 and 9 digits",
        "body": "* **Version**: v7.2.1\r\n* **Platform**: Darwin Jans-MacBook-Pro-2.local 16.3.0 Darwin Kernel Version 16.3.0: Thu Nov 17 20:23:58 PST 2016; root:xnu-3789.31.2~1/RELEASE_X86_64 x86_64\r\n* **Subsystem**: url\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nExecuting:\r\n\r\n```js\r\nconst { URL } = require('url');\r\nnew URL('http://1234.com');\r\nnew URL('http://123456789.com');\r\n```\r\n\r\nall throw\r\n\r\n```\r\nTypeError: Invalid URL\r\n    at Object.URL.binding.parse (internal/url.js:85:17)\r\n    at new URL (internal/url.js:81:13)\r\n    at repl:1:1\r\n    at realRunInThisContextScript (vm.js:22:35)\r\n    at sigintHandlersWrap (vm.js:98:12)\r\n    at ContextifyScript.Script.runInThisContext (vm.js:24:12)\r\n    at REPLServer.defaultEval (repl.js:346:29)\r\n    at bound (domain.js:280:14)\r\n    at REPLServer.runBound [as eval] (domain.js:293:12)\r\n    at REPLServer.onLine (repl.js:545:10)\r\n```\r\n\r\nall following work without a problem:\r\n\r\n```js\r\nconst { URL } = require('url');\r\nnew URL('http://123.com');\r\nnew URL('http://1234567890.com');\r\n```\r\n\r\nThe bug doesn't happen in the browser. It looks like it tries to parse an IP address or something?",
        "labels": "confirmed-bug",
        "id": 45396
    },
    {
        "title": "Build failures with ninja",
        "body": "* **Version**: master\r\n* **Platform**: Linux\r\n* **Subsystem**: build, ninja\r\n\r\n### Versions\r\n - ccache 3.3.3\r\n - ninja 1.7.2\r\n\r\nWorth raising an issue to cover ninja build issues in [these comments](https://github.com/nodejs/node/commit/65c0feb5fe246c4f5a40b0caeaee0168fbd73a03), reported by @sam-github and @KenanY.\r\n\r\n### Info: \r\n(copied from above thread)\r\n\r\nGit bisect shows breaking commit as: https://github.com/nodejs/node/commit/e03a7b2a2b3f092338004a28d07971f4104e9da9\r\n\r\n``` bash\r\n$ ./configure && tools/gyp_node.py -f ninja && ninja -C out/Release\r\n\r\n...\r\n\r\n[2248/2248] LINK node\r\nFAILED: node \r\nccache g++ -pthread -rdynamic -m64 -Wl,--whole-archive,obj.target/deps/openssl/libopenssl.a -Wl,--no-whole-archive -Wl,-z,noexecstack -Wl,--whole-archive libv8_base.a -Wl,--no-whole-archive -pthread -o node -Wl,--start-group obj/src/node.debug-agent.o obj/src/node.async-wrap.o obj/src/node.env.o obj/src/node.fs_event_wrap.o obj/src/node.cares_wrap.o obj/src/node.connection_wrap.o obj/src/node.connect_wrap.o obj/src/node.handle_wrap.o obj/src/node.js_stream.o obj/src/node.node.o obj/src/node.node_buffer.o obj/src/node.node_config.o obj/src/node.node_constants.o obj/src/node.node_contextify.o obj/src/node.node_file.o obj/src/node.node_http_parser.o obj/src/node.node_javascript.o obj/src/node.node_main.o obj/src/node.node_os.o obj/src/node.node_revert.o obj/src/node.node_url.o obj/src/node.node_util.o obj/src/node.node_v8.o obj/src/node.node_stat_watcher.o obj/src/node.node_watchdog.o obj/src/node.node_zlib.o obj/src/node.node_i18n.o obj/src/node.pipe_wrap.o obj/src/node.signal_wrap.o obj/src/node.spawn_sync.o obj/src/node.string_bytes.o obj/src/node.stream_base.o obj/src/node.stream_wrap.o obj/src/node.tcp_wrap.o obj/src/node.timer_wrap.o obj/src/node.tty_wrap.o obj/src/node.process_wrap.o obj/src/node.udp_wrap.o obj/src/node.uv.o obj/src/node.util.o obj/src/node.string_search.o obj/src/node.inspector_agent.o obj/src/node.inspector_socket.o obj/src/node.node_crypto.o obj/src/node.node_crypto_bio.o obj/src/node.node_crypto_clienthello.o obj/src/node.tls_wrap.o obj/src/node.backtrace_posix.o obj/deps/v8/src/libv8_libplatform.a obj/tools/icu/libicui18n.a obj/deps/v8_inspector/src/inspector/libstandalone_inspector.a obj/deps/openssl/libopenssl.a obj/deps/zlib/libzlib.a obj/deps/http_parser/libhttp_parser.a obj/deps/cares/libcares.a obj/deps/uv/libuv.a obj/deps/v8/src/libv8_base.a obj/deps/v8/src/libv8_libbase.a obj/deps/v8/src/libv8_libsampler.a obj/tools/icu/libicuucx.a obj/tools/icu/libicudata.a obj/tools/icu/libicustubdata.a obj/deps/v8/src/libv8_snapshot.a -Wl,--end-group  -ldl -lrt -lm\r\ng++: error: libv8_base.a: No such file or directory\r\nninja: build stopped: subcommand failed.\r\n```",
        "labels": "confirmed-bug",
        "id": 45397
    },
    {
        "title": "Generators in REPL can't be specified using function *gen() {}",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v7.2.0\r\n* **Platform**: Linux gwg-nb01 4.8.0-1-amd64 #1 SMP Debian 4.8.7-1 (2016-11-13) x86_64 GNU/Linux\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n![image](https://cloud.githubusercontent.com/assets/4404683/20734396/f0a9eb04-b677-11e6-972d-f17f941cbbaa.png)\r\n\r\nAs you can see in the attached image, generators can only be specified with the star placed right next to the function keyword, as if it is placed in another place (right before the function name for example), it enters in multi-line edition mode.",
        "labels": "confirmed-bug",
        "id": 45398
    },
    {
        "title": "Infinite loop in timers.js",
        "body": "* **Version**: 6.8.1 and later\r\n* **Platform**: tested on OSX & Linux, probably all platforms\r\n* **Subsystem**: timers\r\n\r\nv6.8.1 and above will all hang when the following code is run:\r\n\r\n```javascript\r\nvar i1 = setImmediate(function() {\r\n  console.log('i1 cb');\r\n  clearImmediate(i2);\r\n  clearImmediate(i3);\r\n});\r\n\r\nvar i2 = setImmediate(function() {\r\n  console.log('i2 cb');\r\n});\r\n\r\nvar i3 = setImmediate(function() {\r\n  console.log('i3 cb');\r\n});\r\n\r\nconsole.log('All set');\r\n```\r\n\r\nAn example run of the code above:\r\n\r\n```\r\nhassy@mdb $ node -v\r\nv4.3.2\r\nhassy@mdb $ node isolated.js\r\n\r\nAll set\r\ni1 cb\r\n#\r\n# The process exits immediately.\r\n#\r\nhassy@mdb  $ nvm use 6.8.1\r\nhassy@mdb  $ node -v\r\nv6.8.1\r\nhassy@mdb $ node isolated.js\r\n\r\nAll set\r\ni1 cb\r\n#\r\n# The process won't exit. top shows it using 98%+ CPU.\r\n#\r\n```\r\n\r\nThe cause is Node entering into an infinite loop here when immediate._onImmediate is `null`:\r\n(source: https://github.com/nodejs/node/blob/master/lib/timers.js#L580-L587)\r\n\r\n```javascript\r\n  while (immediate) {\r\n    domain = immediate.domain;\r\n\r\n    if (!immediate._onImmediate)\r\n      continue;\r\n```\r\n\r\nThis happens when the immediate referred to by `next` gets cleared.\r\n\r\nThe issue first manifests itself in this commit: https://github.com/nodejs/node/commit/42158a03132568ce28cf94e73ba6b8039b208d5d\r\n\r\nThe `if` branch that causes an infinite loop was first introduced in https://github.com/nodejs/node/blob/6f75b6672ca08c2bc3bf5fe14abb1a9648601e28/lib/timers.js#L514-L519 but is obsolete now since the value of `immediate` will not change once the condition is hit.\r\n\r\nI'll send a PR to go along with this with a proposed fix.\r\n\r\n**EDIT 1:** Simplified the test case.\r\n\r\n",
        "labels": "confirmed-bug",
        "id": 45399
    },
    {
        "title": "Process crashes when trying to log a large object",
        "body": "* **Version**: 7.1.0\r\n* **Platform**: 64-bit Windows 10\r\n\r\nThe process consistently crashes (I assume, it simply doesn't log anything at all after running) when trying to run this:\r\n\r\n```\r\nconst obj = {};\r\nArray(607).fill('x').forEach((_, i) => obj[i] = i);\r\nconsole.log(obj);\r\n```\r\n\r\nChanging the array's length to 606 or lower shows the correct output, anything higher produces the crash. Anything after the log doesn't run. Omitting just the `console.log` call makes the program run correctly.\r\n",
        "labels": "confirmed-bug",
        "id": 45400
    },
    {
        "title": "invalid floating point uid or gid for spawn/execSync causes uv to assert and abort node",
        "body": "* **Version**: 0.12 to v8.0.0-pre\r\n\r\n```\r\n> child_process.spawnSync(\"cat\", {uid: 3.5})\r\nnode: ../deps/uv/src/unix/core.c:166: uv_close: Assertion `0' failed.\r\nzsh: abort (core dumped)  ./node\r\n```\r\n\r\nAlso\r\n```\r\n> child_process.execSync(\"date\", {uid: 3.5})\r\nnode: ../deps/uv/src/unix/core.c:161: uv_close: Assertion `0' failed.\r\nzsh: abort (core dumped)\r\n% ./node --version\r\nv8.0.0-pre\r\n```\r\n\r\nEDIT: git aborts, too",
        "labels": "confirmed-bug",
        "id": 45401
    },
    {
        "title": "readFile(fd) does not read the whole file (at least on Windows, possibly other platforms)",
        "body": "* **Version**: v7.1.0\r\n* **Platform**: Windows 10 64-bit\r\n* **Subsystem**: fs\r\n\r\nI wrote a small test that passes on Mac and Linux but throws on Windows:\r\n\r\n```js\r\nvar fs = require('fs');\r\nvar buffer = Buffer.alloc(8192);\r\nvar path = 'test-sparse-read-file';\r\nvar fd = fs.openSync(path, 'w+');\r\nconsole.log('created or truncated, sparse file size is now: ' + fs.fstatSync(fd).size);\r\n\r\nconsole.log('writing 1 byte at offset ' + (8192 - 1));\r\nfs.writeSync(fd, Buffer.alloc(1, 1), 0, 1, 8192 - 1);\r\nconsole.log('sparse file size is now: ' + fs.fstatSync(fd).size + '\\r\\n');\r\n\r\nconsole.log('reading 8192 bytes using readSync()...');\r\nvar bytesRead = fs.readSync(fd, buffer, 0, 8192, 0);\r\nif (bytesRead !== 8192) {\r\n  throw new Error('readSync() read ' + bytesRead + ' bytes');\r\n} else {\r\n  console.log('readSync() read ' + bytesRead + ' bytes');\r\n}\r\n\r\nconsole.log('\\r\\nreading entire file using readFileSync()...');\r\nvar result = fs.readFileSync(fd);\r\nif (result.length !== buffer.length) {\r\n  throw new Error('readFileSync returned a buffer with length ' + result.length);\r\n} else {\r\n  console.log('readFileSync returned a buffer with length ' + result.length);\r\n}\r\n\r\nfs.closeSync(fd);\r\nfs.unlinkSync(path);\r\nconsole.log('\\r\\nPASSED');\r\n```\r\n\r\nLinux:\r\n```\r\ncreated or truncated, sparse file size is now: 0\r\nwriting 1 byte at offset 8191\r\nsparse file size is now: 8192\r\n\r\nreading 8192 bytes using readSync()...\r\nreadSync() read 8192 bytes\r\n\r\nreading entire file using readFileSync()...\r\nreadFileSync returned a buffer with length 8192\r\n\r\nPASSED\r\n```\r\n\r\nWindows:\r\n```\r\ncreated or truncated, sparse file size is now: 0\r\nwriting 1 byte at offset 8191\r\nsparse file size is now: 8192\r\n\r\nreading 8192 bytes using readSync()...\r\nreadSync() read 8192 bytes\r\n\r\nreading entire file using readFileSync()...\r\nC:\\Users\\Joran\\test-sparse.js:22\r\n  throw new Error('readFileSync returned a buffer with length ' + result.length);\r\n  ^\r\n\r\nError: readFileSync returned a buffer with length 0\r\n    at Object.<anonymous> (C:\\Users\\Joran\\test-sparse.js:22:9)\r\n    at Module._compile (module.js:573:32)\r\n    at Object.Module._extensions..js (module.js:582:10)\r\n    at Module.load (module.js:490:32)\r\n    at tryModuleLoad (module.js:449:12)\r\n    at Function.Module._load (module.js:441:3)\r\n    at Module.runMain (module.js:607:10)\r\n    at run (bootstrap_node.js:420:7)\r\n    at startup (bootstrap_node.js:139:9)\r\n    at bootstrap_node.js:535:3\r\n```\r\n\r\nThe test shows that the problem does not appear to be with read() but only with readFileSync().\r\n\r\nreadFile() has the same issue.\r\n",
        "labels": "confirmed-bug",
        "id": 45402
    },
    {
        "title": "segfault if clearTimeout(interval)",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: v6.9.1\r\n* **Platform**: Darwin watson-3.local 16.1.0 Darwin Kernel Version 16.1.0: Thu Oct 13 21:26:57 PDT 2016; root:xnu-3789.21.3~60/RELEASE_X86_64 x86_64\r\n* **Subsystem**:\r\n\r\nIf using `clearTimeout` to clear an unreffed `Timeout` object returned by `setInterval(...).unref()` you'll get a segfault the next time the interval would normally have fired.\r\n\r\nThe following example program will segfault after 4 seconds:\r\n\r\n```js\r\n// keep the event loop busy while we wait for segfault\r\nsetTimeout(function () {}, 100000)\r\n\r\nconsole.log('setInterval')\r\nvar timer = setInterval(clear, 2000).unref()\r\n\r\nfunction clear () {\r\n  console.log('clear - start')\r\n\r\n  // Use clearTimeout instead of clearInterval\r\n  clearTimeout(timer)\r\n\r\n  console.log('clear - end')\r\n}\r\n```\r\n\r\nThe segfault doesn't happen if the `Timeout` object isn't unreffed.\r\n\r\nEven though the user should just use `clearInterval` instead, this at least shouldn't segfault.\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n",
        "labels": "confirmed-bug",
        "id": 45403
    },
    {
        "title": "The max length of console.log output is 8275",
        "body": "* **Version**: 7.1.0\r\n* **Platform**: Windows 10 1607 (Redstone) 14393.447 x64\r\n* **Subsystem**: console\r\n\r\nUsing the following codes, the second `console.log` will be failed without any error message and the program exits; but it worked on 7.0.0.\r\n\r\n```javascript\r\n\"use strict\";\r\n\r\n// length = 8275, Array(8276) is max.\r\nvar testString = Array(8277).join('a');\r\nconsole.log('length = ' + testString.length);\r\nconsole.log(testString);\r\n```\r\n\r\nReduce the array size to **8276**, the program works as expected.\r\n",
        "labels": "confirmed-bug",
        "id": 45404
    },
    {
        "title": "dtrace for node not work",
        "body": "* **v4.2.4**:\r\n* **MacOS Sierra**:\r\n* **10.12**\r\n\r\nuse Node core provider dtrace probe found error\r\n\r\n```dtrace script\r\nnode*:::http-server-request {\r\n    printf(\"%s of %s from %s\\n\", args[0]->method,\r\n            args[0]->url, args[1]->remoteAddress)\r\n}\r\n```\r\n```error\r\ndtrace: failed to compile script node_http_latency.d: line 2: operator -> cannot be applied to pointer to type \"int\"; must be applied to a struct or union pointer\r\n```\r\n",
        "labels": "confirmed-bug",
        "id": 45405
    },
    {
        "title": "Strange errors, segfaults when upgrading from v6.9.1 to v7.0.0",
        "body": "* **Version**: v7.0.0\r\n* **Platform**: (Arch Linux) Linux alpha 4.8.6-1-ARCH #1 SMP PREEMPT Mon Oct 31 18:51:30 CET 2016 x86_64 GNU/Linux\r\n* **Subsystem**: v8 (?)\r\n\r\nI'm not completely sure yet whether this is a v8 issue or a packaging issue w/ Arch Linux yet, but all I know is that when I install and use v7.0.0, I start getting weird errors, bugs and segfaults that I've never seen before with v6.9.1.\r\n\r\nFor example, one of the programs that I run had an impossible bug: It randomly left out some information that it's guaranteed to include when generating a feed. This bug has never happened before, and when I run it again, that time it just throws an error that it never threw before, something to do with accessing a missing property. When I switched back to v6.9.1, it starts working again just fine.\r\n\r\nOne consistent case I was able to find was cloning the yarn repo, and running tests on it. It gives me a segfault almost consistently at pretty much the same place, with the difference of npm sometimes segfaulting along with node in the journalctl logs: https://gist.github.com/SEAPUNK/652768e792f6f32bc8777230bc740a92\r\nAgain, switching back to v6.9.1 makes it work just fine.\r\n\r\nI can't pinpoint the issue, but I'm pretty sure it's something to do with v8, or how nodejs was packaged for Arch Linux.\r\n",
        "labels": "confirmed-bug",
        "id": 45406
    },
    {
        "title": "\"write after end\" error when stdout was end()-ed",
        "body": "<!--\r\nThank you for reporting an issue.\r\n\r\nThis issue tracker is for bugs and issues found within Node.js core.\r\nIf you require more general support please file an issue on our help\r\nrepo. https://github.com/nodejs/help\r\n\r\n\r\nPlease fill in as much of the template below as you're able.\r\n\r\nVersion: output of `node -v`\r\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\r\nSubsystem: if known, please specify affected core module name\r\n\r\nIf possible, please provide code that demonstrates the problem, keeping it as\r\nsimple and free of external dependencies as you are able.\r\n-->\r\n\r\n* **Version**: `master`, presumably all recent node major versions\r\n* **Platform**: OS X 10.10.5\r\n* **Subsystem**: process/console\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\n`stdout`/`stderr` unexpectedly throw a `write after end` error when `end()` has been called on them, even though `end()` throws it's own error in `destroy()`/`destroySoon()` overriding the usual destroy code which is in `net.Socket`. Since it overrides the destroy code, I don't think it should ever actually destroy the stream, which the error seems to indicate, but it appears to destroy it nonetheless.\r\n\r\nTry in the REPL:\r\n\r\n```js\r\nprocess.stderr.end('foo')\r\n// throws error, REPL catches it\r\n\r\nconsole.error('hello?')\r\n// Unexpectedly throws \"write after end\"\r\n```\r\n\r\ncc @nodejs/streams ",
        "labels": "confirmed-bug",
        "id": 45407
    },
    {
        "title": "readdirSync of drive letter lists items of cwd",
        "body": "* **Version**: v6.9.1\r\n* **Platform**: Windows 8.1 x64\r\n\r\nReaddirSync behavior depends on the current working directory (cwd/pwd) if we pass a drive letter with or without a trailing \"\\\".\r\n\r\nIt's very easy to reproduce. Here, I am on \"d:\" drive, and I have a \"d:\\Temp\" folder, containing \"A\" and \"B\" sub-folders.\r\n\r\n```\r\nD:\\Temp>  gci | % { $_.Name }\r\nA\r\nB\r\n\r\nD:\\Temp> node\r\n> var fs = require('fs');\r\nundefined\r\n> fs.readdirSync('d:')\r\n[ 'A', 'B' ]\r\n> fs.readdirSync('d:\\\\')\r\n[ '$RECYCLE.BIN',\r\n  'Cache',\r\n  'DEV',\r\n  'Installers',\r\n  'log',\r\n  'pagefile.sys',\r\n  'System Volume Information',\r\n  'Temp',\r\n  'VM' ]\r\n> .exit\r\nD:\\Temp>\r\n```\r\n\r\nIt's a very suprising behavior, and more importantly, it's not documented if expected.",
        "labels": "confirmed-bug",
        "id": 45408
    },
    {
        "title": "`node-crc` failing on node 6.x only",
        "body": "Friends,\n\nI'm the author of the [crc](https://www.npmjs.com/package/crc) module on which over 200 packages depend including express.js.\n\nI test the module on 0.10, 0.12, 4, 5, 6 and 7. One of the tests oddly fails on 6 only. Please see the [travis build](https://travis-ci.org/alexgorbatchev/node-crc/builds/171443310). Basically, one test out of 255 fails with a consistently unexpected checksum.\n\nI don't have experience debugging node specific issues, I'm wondering if anyone could have any pointers for me what it is that might be going on here?\n\nThe file in question is [here](https://github.com/alexgorbatchev/node-crc/blob/master/src/crc16.js). I'll also paste it here for the record. \n\n``` js\nimport {Buffer} from 'buffer';\nimport defineCrc from './define_crc';\n\n// Generated by `./pycrc.py --algorithm=table-driven --model=crc-16 --generate=c`\nlet TABLE = [\n  0x0000, 0xc0c1, 0xc181, 0x0140, 0xc301, 0x03c0, 0x0280, 0xc241,\n  0xc601, 0x06c0, 0x0780, 0xc741, 0x0500, 0xc5c1, 0xc481, 0x0440,\n  0xcc01, 0x0cc0, 0x0d80, 0xcd41, 0x0f00, 0xcfc1, 0xce81, 0x0e40,\n  0x0a00, 0xcac1, 0xcb81, 0x0b40, 0xc901, 0x09c0, 0x0880, 0xc841,\n  0xd801, 0x18c0, 0x1980, 0xd941, 0x1b00, 0xdbc1, 0xda81, 0x1a40,\n  0x1e00, 0xdec1, 0xdf81, 0x1f40, 0xdd01, 0x1dc0, 0x1c80, 0xdc41,\n  0x1400, 0xd4c1, 0xd581, 0x1540, 0xd701, 0x17c0, 0x1680, 0xd641,\n  0xd201, 0x12c0, 0x1380, 0xd341, 0x1100, 0xd1c1, 0xd081, 0x1040,\n  0xf001, 0x30c0, 0x3180, 0xf141, 0x3300, 0xf3c1, 0xf281, 0x3240,\n  0x3600, 0xf6c1, 0xf781, 0x3740, 0xf501, 0x35c0, 0x3480, 0xf441,\n  0x3c00, 0xfcc1, 0xfd81, 0x3d40, 0xff01, 0x3fc0, 0x3e80, 0xfe41,\n  0xfa01, 0x3ac0, 0x3b80, 0xfb41, 0x3900, 0xf9c1, 0xf881, 0x3840,\n  0x2800, 0xe8c1, 0xe981, 0x2940, 0xeb01, 0x2bc0, 0x2a80, 0xea41,\n  0xee01, 0x2ec0, 0x2f80, 0xef41, 0x2d00, 0xedc1, 0xec81, 0x2c40,\n  0xe401, 0x24c0, 0x2580, 0xe541, 0x2700, 0xe7c1, 0xe681, 0x2640,\n  0x2200, 0xe2c1, 0xe381, 0x2340, 0xe101, 0x21c0, 0x2080, 0xe041,\n  0xa001, 0x60c0, 0x6180, 0xa141, 0x6300, 0xa3c1, 0xa281, 0x6240,\n  0x6600, 0xa6c1, 0xa781, 0x6740, 0xa501, 0x65c0, 0x6480, 0xa441,\n  0x6c00, 0xacc1, 0xad81, 0x6d40, 0xaf01, 0x6fc0, 0x6e80, 0xae41,\n  0xaa01, 0x6ac0, 0x6b80, 0xab41, 0x6900, 0xa9c1, 0xa881, 0x6840,\n  0x7800, 0xb8c1, 0xb981, 0x7940, 0xbb01, 0x7bc0, 0x7a80, 0xba41,\n  0xbe01, 0x7ec0, 0x7f80, 0xbf41, 0x7d00, 0xbdc1, 0xbc81, 0x7c40,\n  0xb401, 0x74c0, 0x7580, 0xb541, 0x7700, 0xb7c1, 0xb681, 0x7640,\n  0x7200, 0xb2c1, 0xb381, 0x7340, 0xb101, 0x71c0, 0x7080, 0xb041,\n  0x5000, 0x90c1, 0x9181, 0x5140, 0x9301, 0x53c0, 0x5280, 0x9241,\n  0x9601, 0x56c0, 0x5780, 0x9741, 0x5500, 0x95c1, 0x9481, 0x5440,\n  0x9c01, 0x5cc0, 0x5d80, 0x9d41, 0x5f00, 0x9fc1, 0x9e81, 0x5e40,\n  0x5a00, 0x9ac1, 0x9b81, 0x5b40, 0x9901, 0x59c0, 0x5880, 0x9841,\n  0x8801, 0x48c0, 0x4980, 0x8941, 0x4b00, 0x8bc1, 0x8a81, 0x4a40,\n  0x4e00, 0x8ec1, 0x8f81, 0x4f40, 0x8d01, 0x4dc0, 0x4c80, 0x8c41,\n  0x4400, 0x84c1, 0x8581, 0x4540, 0x8701, 0x47c0, 0x4680, 0x8641,\n  0x8201, 0x42c0, 0x4380, 0x8341, 0x4100, 0x81c1, 0x8081, 0x4040\n]\n\nif (typeof(Int32Array) !== 'undefined') TABLE = new Int32Array(TABLE);\n\nmodule.exports = defineCrc('crc-16', function (buf, previous) {\n  if (!Buffer.isBuffer(buf)) buf = new Buffer(buf);\n\n  let crc = ~~previous;\n\n  for (let index = 0; index < buf.length; index++) {\n    const byte = buf[index];\n    crc = ((TABLE[(crc ^ byte) & 0xff] ^ (crc >> 8)) & 0xffff);\n  }\n\n  return crc;\n});\n```\n",
        "labels": "confirmed-bug",
        "id": 45409
    },
    {
        "title": "Some regexps hang and eating 100%",
        "body": "- **Version**: v7.0.0\n- **Platform**: Darwin josser-mbp 16.1.0 Darwin Kernel Version 16.1.0: Thu Oct 13 21:26:57 PDT 2016; root:xnu-3789.21.3~60/RELEASE_X86_64 x86_64\n- **Subsystem**: don't know, regexp? \n\nHi! \nNot sure that this is correct place for such issue, because it looks more like v8 bug. \nHowever, here is code which is stuck and never finished:\n\n``` javascript\nvar r = new RegExp(\"^(http|https|ftp)\\://([a-zA-Z0-9\\.\\-]+(\\:[a-zA-Z0-9\\.&amp;%\\$\\-]+)*@)*((25[0-5]|2[0-4][0-9]|[0-1]{1}[0-9]{2}|[1-9]{1}[0-9]{1}|[1-9])\\.(25[0-5]|2[0-4][0-9]|[0-1]{1}[0-9]{2}|[1-9]{1}[0-9]{1}|[1-9]|0)\\.(25[0-5]|2[0-4][0-9]|[0-1]{1}[0-9]{2}|[1-9]{1}[0-9]{1}|[1-9]|0)\\.(25[0-5]|2[0-4][0-9]|[0-1]{1}[0-9]{2}|[1-9]{1}[0-9]{1}|[0-9])|([a-zA-Z0-9\\-]+\\.)*[a-zA-Z0-9\\-]+\\.(com|edu|gov|int|mil|net|org|biz|arpa|info|name|pro|aero|coop|museum|[a-zA-Z]{2}))(\\:[0-9]+)*(/($|[a-zA-Z0-9\\.\\,\\?\\'\\\\\\+&amp;%\\$#\\=~_\\-]+))*$\");\nvar url = \"http://www.something.com/bookstore/making-process-improvement-work-a-concise-action-guide-0132929554\";\nr.test(url);\n```\n\nSame code in chrome also eating 100% CPU and hang but not reproducible in safari or firefox. \nThat's why I think it's v8 issue.\n\nThank you and sorry for bad english :)\n",
        "labels": "confirmed-bug",
        "id": 45410
    },
    {
        "title": "Division with comment containing '/' - SyntaxError",
        "body": "<!--\nThank you for reporting an issue.\n\nThis issue tracker is for bugs and issues found within Node.js core.\nIf you require more general support please file an issue on our help\nrepo. https://github.com/nodejs/help\n\n\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n\n<!-- Enter your issue details below this comment. -->\n- **Version**: 6.9.1, 7.0.0\n- **Platform**: Linux\n- **Subsystem**: Mint 17, Ubuntu 16\n\nFollowing function fails parsing:\n\n```\nfunction foo(){\n    var bar = 1 / 1; // '/'\n}\n```\n\nSyntaxError: Unexpected end of input\n\ntested with:\n- docker run -it node:6.9.1,\n- docker run -it node:7.0.0,\n- local installation\n\nThis code parses correctly in some node versions 5.X\n",
        "labels": "confirmed-bug",
        "id": 45411
    },
    {
        "title": "Buffer.alloc v4: Incorrectly returns zero-filled buffer when encoding is passed",
        "body": "- **v4.6.1, 4.5.0, 4.6.0**:\n- **Darwin Kernel Version 16.0.0; root:xnu-3789.1.32~3/RELEASE_X86_64 x86_64**:\n- **`Buffer.alloc(size, data, enc)`**:\n\n``` js\n$ node\n> let s = 'YQ=='\nundefined\n> Buffer.alloc(s.length, s, 'base64')\n<Buffer 00 00 00 00>\n> Buffer(s, 'base64')\n<Buffer 61>\n> Buffer.alloc(1, s, 'base64')\n<Buffer 00>\n> Buffer(s, 'base64').toString('base64')\n'YQ=='\n> let b = Buffer(s.length); b.write(s, 'base64'); b\n<Buffer 61 00 00 00>\n> b.toString('base64')\n'YQAAAA=='\n```\n\nAlso, the [`Buffer.alloc(size, data, enc)` docs example](https://nodejs.org/dist/latest-v4.x/docs/api/buffer.html#buffer_class_method_buffer_alloc_size_fill_encoding) fails:\n\n``` js\n> Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64');\n<Buffer 00 00 00 00 00 00 00 00 00 00 00>\n```\n",
        "labels": "confirmed-bug",
        "id": 45412
    },
    {
        "title": "Step out/Shift F11/Out debug command does not stop when exception is thrown inside a function",
        "body": "Version: v6.8.1\nPlatform: Windows 10 64 bit\n\n``` javascript\nfunction exception_function() {\n    try {\n        throw 'error';\n    } catch (err) {\n        console.log(err);\n    }\n}\nconsole.log('Starting script.');\nexception_function();\nconsole.log('Stopping script.');\n```\n\nWhen i am inside the exception_function in the debugger and execute the out function, it does not stop any more. If i do single step or step over all the way then it works fine.\n\n```\n< Debugger listening on [::]:5858\nconnecting to 127.0.0.1:5858 ... ok\nbreak in C:\\Users\\xxxx\\Desktop\\exception.js:10\n  8 }\n  9\n>10 console.log('Starting script.');\n 11 exception_function();\n 12 console.log('Stopping script.');\ndebug> next\n< Starting script.\nbreak in C:\\Users\\xxxx\\Desktop\\exception.js:11\n  9\n 10 console.log('Starting script.');\n>11 exception_function();\n 12 console.log('Stopping script.');\n 13\ndebug> step\nbreak in C:\\Users\\xxxx\\Desktop\\exception.js:4\n  2 function exception_function() {\n  3     try {\n> 4         throw 'error';\n  5     } catch (err) {\n  6         console.log(err);\ndebug> out\n< error\n< Stopping script.\ndebug> quit\n```\n",
        "labels": "confirmed-bug",
        "id": 45413
    },
    {
        "title": "stream.Readable unpipes the wrong stream when piped into multiple streams",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 6.8.0 and later\n- **Platform**: all\n- **Subsystem**: stream.Readable\n\n<!-- Enter your issue details below this comment. -->\n\nSince node 6.8.0 there is a bug where unpiping a stream from a readable stream that has a _readableState.pipesCount > 1 will cause it to remove the first stream in the _.readableState.pipes array no matter where in the list the dest stream was.\n\nExample test case:\n\n``` javascript\n\"use strict\"\nconst PassThrough = require('stream').PassThrough\n\nconst source = PassThrough()\nconst dest1 = PassThrough()\nconst dest2 = PassThrough()\n\nsource.pipe(dest1)\nsource.pipe(dest2)\n\nsource.unpipe(dest2)\n\nconsole.log(source._readableState.pipes === dest1) //false\nconsole.log(source._readableState.pipes === dest2) //true\n```\n\nAs you can see, the wrong stream was unpiped\n\nIt looks like this is the commit that broke things (https://github.com/nodejs/node/commit/2e568d95bdd689494b163f1cfe8bbc38f32e45ed#diff-ba6a0df0f5212f5cba5ca5179e209a17R670)\nThe variable used to splice was renamed to `index` on line 670, however the splice call on line 674 is still using the incorrect variable `i`.\n",
        "labels": "confirmed-bug",
        "id": 45414
    },
    {
        "title": "setImmediate regression in v6.8.0",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.8.0\n- **Platform**: ?\n- **Subsystem**: timers\n\n<!-- Enter your issue details below this comment. -->\n\nSee: https://github.com/TryGhost/Ghost/issues/7555\nMoving from: https://github.com/nodejs/node/pull/8655#issuecomment-253453520\n\nRegression from [`timers: improve setImmediate() performance`](https://github.com/nodejs/node/commit/0ed8839a279ba2597ae9fc54517030b16116207d) (https://github.com/nodejs/node/pull/8655)\n\n> Hey there!\n> \n> We started having test failures due to this change. There's more information on the issue & PR linked just above this comment. To pull some of that here:\n> \n> > The last job never get's executed, because setImmediate does not get triggered!\n> \n> We have a temporary fix in place in the PR, that reduces the timeout and this appears to work (the tests pass). Would love a little bit of input into how this change has impacted the functionality and whether we've found a bug or are doing something wrong :)\n## \n\n``` js\nvar jobs = [Date.now() + 1000, Date.now() + 2000, Date.now() + 3000];\n\njobs.forEach(function(timestamp) {\n    var timeout = setTimeout(function() {\n        clearTimeout(timeout);\n\n        (function retry() {\n            var immediate = setImmediate(function() {\n                clearImmediate(immediate);\n\n                if (Date.now() < timestamp) {\n                    return retry();\n                }\n\n                console.log(\"FINISHED JOB\");\n            });\n        }());\n    }, timestamp - 200);\n});\n```\n\n> `v6.8.0` - does not work, you will see 1 x FINISHED JOB\n> `v4.4.7 && v6.7.0` - works as expected, you will see 3 x FINISHED JOB\n\ncc @erisds, @TheAlphaNerd, @mscdex, @trott, @kirrg001\n",
        "labels": "confirmed-bug",
        "id": 45415
    },
    {
        "title": "Problematic process.argv with \"node -e\"",
        "body": "- **Version**: v6.7.0\n- **Platform**: Tested on Linux and Windows\n\nWhen running a script via \"node -e\", there doesn't seem to be a clean way to use `process.argv` when \"flag\" arguments are expected (or more accurately, any argument that begin with the '-' character). What happens is that the argument is silently dropped.\n\nThe following all work as expected:\n\n```\n$ node -e 'console.log(process.argv)'\n[ '/usr/bin/node' ]\n$ node -e 'console.log(process.argv)' arg1\n[ '/usr/bin/node', 'arg1' ]\n$ node -p -e 'console.log(process.argv)' arg1\n[ '/usr/bin/node', 'arg1' ]\nundefined\n$ node -e 'console.log(process.argv)' arg1 arg2\n[ '/usr/bin/node', 'arg1', 'arg2' ]\n$ node -p -e 'console.log(process.argv)' arg1 arg2\n[ '/usr/bin/node', 'arg1', 'arg2' ]\nundefined\n$ node --require fs -e 'console.log(process.argv)' -- arg1 arg2\n[ '/usr/bin/node', 'arg1', 'arg2' ]\n$ node -e 'console.log(process.argv)' arg1 -x\n[ '/usr/bin/node', 'arg1', '-x' ]\n$ node -e 'console.log(process.argv)' arg1 -x -e\n[ '/usr/bin/node', 'arg1', '-x', '-e' ]\n$ node -e 'console.log(process.argv)' -- arg1 -x -e\n[ '/usr/bin/node', 'arg1', '-x', '-e' ]\n$ node -e 'console.log(process.argv)' -- arg1 -- -x\n[ '/usr/bin/node', 'arg1', '--', '-x' ]\n```\n\nBut it seems impossible to have a '-' character at the beginning of the first argument. The following are unexpected and undesirable results:\n\n```\n$ node -e 'console.log(process.argv)' -- -x\n[ '/usr/bin/node' ]\n$ node -e 'console.log(process.argv)' -- -x arg2\n[ '/usr/bin/node', 'arg2' ]\n```\n\nNote above that \"flag-type\" arguments are successfully passed to the script as long as they are preceded by at least one \"non-flag\" argument.\n\n**The expected and desirable behavior is that all arguments after (the first encountered) \"--\" are passed into the script.**\n\nThank you\n",
        "labels": "confirmed-bug",
        "id": 45416
    },
    {
        "title": "zlib deflate results in a memory leak",
        "body": "- **Version**:6.7.0\r\n- **Platform**:Darwin ITs-MacBook-Pro.local 15.6.0 Darwin Kernel Version 15.6.0: Thu Jun 23 18:25:34 PDT 2016; root:xnu-3248.60.10~1/RELEASE_X86_64 x86_64\r\n- **Subsystem**:zlib\r\n\r\n<!-- Enter your issue details below this comment. -->\r\n\r\nI'm using the graylog2 package for logging, and we ran into significant memory leak issues.\r\nAfter tracking it down, I found zlib.deflate is the source of the issue.\r\nThe issue is magnified when running code inside of docker with the latest node distribution.\r\n\r\nRunning the below code on my macbook pro results in the memory spiking to ~3GB, then released down to 600MB.\r\nRunning the code in the latest node docker distro results in memory spiking to ~3GB, and it is never released.\r\n\r\n```js\r\nlet zlib = require('zlib');\r\n\r\nlet message = {\r\n  some:\"data\"\r\n};\r\nlet payload = new Buffer(JSON.stringify(message));\r\n\r\nfor(var i =0; i < 30000; ++i){\r\n  zlib.deflate(payload, function (err, buffer) {\r\n  });\r\n}\r\n\r\nsetTimeout(()=>{}, 2000000);\r\n```\r\n\r\nThis has resulted in our docker containers crashing due to memory exhaustion.\r\n",
        "labels": "confirmed-bug",
        "id": 45417
    },
    {
        "title": "fs: make process.stdout and stderr descend from Writable.",
        "body": "- **Version**: since dec 2011, https://github.com/nodejs/node/commit/a936768890db2e4b14f8994a84edb7121e6c82d0#diff-9a205ef7ee967ee32efee02e58b3482dR1342\n- **Platform**: all\n- **Subsystem**: fs, stream\n\n`process.stdout` and `process.stderr` are not implementing Stream 2 or 3 if they are redirected to a file. TheyÂ are a `SyncWriteStream`: https://github.com/nodejs/node/blob/dc7277909b0d842ea3f559628d6d7c7887bfd05b/lib/internal/process/stdio.js#L149.\nThis is were the choice is made.:https://github.com/nodejs/node/blob/dc7277909b0d842ea3f559628d6d7c7887bfd05b/lib/internal/process/stdio.js#L147-L151\n\nI know too little of the stdio sync/async situation to identify what should be preferred change. Ideally `process.stdout` and `process.stderr` should come from the streams implementations, but I might be wrong.\nWhat are the implications of doing so? Why is this needed in the first place?\nAs an example, can we use `net.Socket` instead https://github.com/nodejs/node/blob/dc7277909b0d842ea3f559628d6d7c7887bfd05b/lib/internal/process/stdio.js#L156-L160?\n\nIssues related:\nhttps://github.com/sindresorhus/is-stream/issues/5\nhttps://github.com/mcollina/pino/issues/85\nhttps://github.com/mcollina/pino/pull/86\n\ncc @jasnell @Fishrock123 @jsumners @catdad @sindresorhus @nodejs/streams \n",
        "labels": "confirmed-bug",
        "id": 45418
    },
    {
        "title": "Memory leak for https.request() on ECONNRESET",
        "body": "- **Version**: 6.8.0, 7.0.0\r\n- **Platform**: Ubuntu 16.04 (Linux patrickd 4.4.0-38-generic #57-Ubuntu SMP Tue Sep 6 15:42:33 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux)\r\n- **Subsystem**: https\r\n\r\nI experience a memory leak when doing https requests to a host that resets the connection.\r\n\r\n**Reproduce by**\r\n1) starting `node econnreset.js`\r\n[econnreset.js.txt](https://github.com/nodejs/node/files/498002/econnreset.js.txt)\r\n2) start `node leak.js`\r\n[leak.js.txt](https://github.com/nodejs/node/files/498004/leak.js.txt)\r\n3) Observe process memory\r\nFor me it goes up to 600MB with 10000 requests - and stays that way.\r\n\r\n**Heapdump is small**\r\n1) install node-heapdump (`npm install heapdump`)\r\n2) comment in the `require('heapdump')`\r\n3) run `node econnreset.js` and `node leak.js`\r\n4) when it's done with the requests (no more CPU usage) execute `kill -USR2 $pid`.\r\nThe resulting heapdump from a process with 600MB is only 100MB large.\r\n\r\n**Manual GC call has no effect**\r\n1) comment in `global.gc();`\r\n2) start `node econnreset.js` and `node leak.js --expose-gc`\r\n3) when it's done with the requests (no more CPU usage) it will execute the GC every second but the memory usage doesn't change.\r\n\r\nAm I using https.request() wrong or is this an internal problem?\r\n",
        "labels": "confirmed-bug",
        "id": 45419
    },
    {
        "title": "v6.6.0 node::PBKDF2() Out of Memory",
        "body": "The following code crashes in v6.6.0 on OSX 10.11.6. v6.5.0 does not crash.\n\nrunning\n\n``` javascript\nvar crypto = require('crypto');\nvar salt = new Buffer('McWpw6FL29zJ6E97Le3hKQ==', 'base64');\ncrypto.pbkdf2('', salt, 1, 32, \"sha256\", function(error, saltedPassword) {\n  console.log(error);\n  console.log(saltedPassword);\n});\n```\n\nresults in \n\n```\nFATAL ERROR: node::PBKDF2() Out of Memory\n 1: node::Abort() [/Users/scoope7/.nvm/versions/node/v6.6.0/bin/node]\n 2: node::FatalException(v8::Isolate*, v8::Local<v8::Value>, v8::Local<v8::Message>) [/Users/scoope7/.nvm/versions/node/v6.6.0/bin/node]\n 3: node::ClearFatalExceptionHandlers(node::Environment*) [/Users/scoope7/.nvm/versions/node/v6.6.0/bin/node]\n 4: node::crypto::RandomBytesWork(uv_work_s*) [/Users/scoope7/.nvm/versions/node/v6.6.0/bin/node]\n 5: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) [/Users/scoope7/.nvm/versions/node/v6.6.0/bin/node]\n 6: v8::internal::MaybeHandle<v8::internal::Object> v8::internal::(anonymous namespace)::HandleApiCallHelper<false>(v8::internal::Isolate*, v8::internal::(anonymous namespace)::BuiltinArguments<(v8::internal::BuiltinExtraArguments)1>) [/Users/scoope7/.nvm/versions/node/v6.6.0/bin/node]\n 7: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) [/Users/scoope7/.nvm/versions/node/v6.6.0/bin/node]\n 8: 0xe4335f092a7\n[1]    45139 abort      node crash.js\n```\n\nThis was code extracted out of https://github.com/neumino/rethinkdbdash that was crashing a project.\n",
        "labels": "confirmed-bug",
        "id": 45420
    },
    {
        "title": "Impossible to listen to beforeExit in single-tick --eval",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v2.2.0+ (?)\n- **Platform**: all\n- **Subsystem**: process\n\n<!-- Enter your issue details below this comment. -->\n\nThe following exits **without** printing:\n\n`node -e \"process.on('beforeExit', () => process._rawDebug('hi'))\"` \n\nHowever, this **does** print:\n\nnode -e \"process.on('beforeExit', () => process._rawDebug('hi')); setImmediate(()=>{})\"\n## \n\nI did some debugging and using this patch I get the following output:\n\n``` diff\ndiff --git a/lib/events.js b/lib/events.js\nindex d676580..16ee82c 100644\n--- a/lib/events.js\n+++ b/lib/events.js\n@@ -138,6 +138,8 @@ EventEmitter.prototype.emit = function emit(type) {\n   var needDomainExit = false;\n   var doError = (type === 'error');\n\n+  // process._rawDebug((new Error()).stack)\n+\n   events = this._events;\n   if (events)\n     doError = (doError && events.error == null);\n@@ -169,6 +171,9 @@ EventEmitter.prototype.emit = function emit(type) {\n\n   handler = events[type];\n\n+  process._rawDebug('01.5:' + type)\n+  process._rawDebug(typeof handler)\n+\n   if (!handler)\n     return false;\n\n@@ -234,6 +239,9 @@ function _addListener(target, type, listener, prepend) {\n   }\n\n   if (!existing) {\n+    process._rawDebug('@@@@')\n+    // process._rawDebug((new Error()).stack)\n+    // process._rawDebug(listener.toString())\n     // Optimize the case of one listener. Don't need the extra array object.\n     existing = events[type] = listener;\n     ++target._eventsCount;\ndiff --git a/lib/internal/process/next_tick.js b/lib/internal/process/next_tick.js\nindex 529645a..5f43ba0 100644\n--- a/lib/internal/process/next_tick.js\n+++ b/lib/internal/process/next_tick.js\n@@ -138,6 +138,8 @@ function setupNextTick() {\n   }\n\n   function nextTick(callback) {\n+    process._rawDebug('#####')\n+    process._rawDebug((new Error()).stack)\n     if (typeof callback !== 'function')\n       throw new TypeError('callback is not a function');\n     // on the way out, don't bother. it won't get fired anyway.\n```\n\n```\n./node -e \"process.on('beforeExit', () => process._rawDebug('hi'))\"\n@@@@\n@@@@\n01.5:newListener\nfunction\n@@@@\n#####\nError\n    at process.nextTick (internal/process/next_tick.js:142:24)\n    at evalScript (bootstrap_node.js:344:13)\n    at run (bootstrap_node.js:110:11)\n    at run (bootstrap_node.js:382:7)\n    at startup (bootstrap_node.js:109:9)\n    at bootstrap_node.js:497:3\n01.5:beforeExit\nundefined\n01.5:newListener\nfunction\n@@@@\n01.5:exit\nundefined\n```\n\nThat is, **`beforeExit` fires before the listener is attached**.\n## \n\nTurns out that `at evalScript (bootstrap_node.js:344:13)` leads to [this code and comment in `evalScript()`](https://github.com/nodejs/node/blob/2804518174b806da345f0924642c3f04fc39c30e/lib/internal/bootstrap_node.js#L341-L347):\n\n``` js\n    // Defer evaluation for a tick.  This is a workaround for deferred\n    // events not firing when evaluating scripts from the command line,\n    // see https://github.com/nodejs/node/issues/1600.\n    process.nextTick(function() {\n      const result = module._compile(script, `${name}-wrapper`);\n      if (process._print_eval) console.log(result);\n    });\n```\n\nThat comment leads back to https://github.com/nodejs/node/issues/1600 - `net.listen does not emit 'listening' event when in --eval mode`.\n\nThat was fixed in https://github.com/nodejs/node/commit/93a44d5228b2e1a885f6279f06c4175c174246be by @bnoordhuis and reviewed by @trevnorris resulting in this code in `evalScript()`.\n## \n\nNot sure how to fix this right now, but it seems like a deeper bug somewhere relating to startup and nextTick.\n\nRefs: https://github.com/nodejs/node/pull/1793 & https://github.com/nodejs/node/issues/1600 & also the older https://github.com/nodejs/node-v0.x-archive/issues/14168\n\nEdit: found by @cxreg \n",
        "labels": "confirmed-bug",
        "id": 45421
    },
    {
        "title": "Test failures on macOS Sierra 10.12 (GM) with Xcode 8.0 (GM)",
        "body": "- **Version**: master (latest)\n- **Platform**: macOS Sierra 10.12 (GM), Xcode 8.0 (GM)\n- **Subsystem**: -\n\nI don't know who is responsible for the failures, macOS, Xcode or a combination.\n\n```\n./configure\nmake test\n\n[==========] Running 22 tests from 2 test cases.\n[----------] Global test environment set-up.\n[----------] 4 tests from UtilTest\n[ RUN      ] UtilTest.ListHead\n[       OK ] UtilTest.ListHead (0 ms)\n[ RUN      ] UtilTest.StringEqualNoCase\n[       OK ] UtilTest.StringEqualNoCase (0 ms)\n[ RUN      ] UtilTest.StringEqualNoCaseN\n[       OK ] UtilTest.StringEqualNoCaseN (0 ms)\n[ RUN      ] UtilTest.ToLower\n[       OK ] UtilTest.ToLower (0 ms)\n[----------] 4 tests from UtilTest (0 ms total)\n\n[----------] 18 tests from InspectorSocketTest\n[ RUN      ] InspectorSocketTest.ReadsAndWritesInspectorMessage\n[       OK ] InspectorSocketTest.ReadsAndWritesInspectorMessage (0 ms)\n[ RUN      ] InspectorSocketTest.BufferEdgeCases\n[       OK ] InspectorSocketTest.BufferEdgeCases (1 ms)\n[ RUN      ] InspectorSocketTest.AcceptsRequestInSeveralWrites\n[       OK ] InspectorSocketTest.AcceptsRequestInSeveralWrites (0 ms)\n[ RUN      ] InspectorSocketTest.ExtraTextBeforeRequest\n../test/cctest/test_inspector_socket.cc:485: Failure\nValue of: 0\nExpected: uv_is_active(reinterpret_cast<uv_handle_t*>(&socket))\nWhich is: 1\n[  FAILED  ] InspectorSocketTest.ExtraTextBeforeRequest (0 ms)\n[ RUN      ] InspectorSocketTest.ExtraLettersBeforeRequest\n../test/cctest/test_inspector_socket.cc:497: Failure\nValue of: 0\nExpected: uv_is_active(reinterpret_cast<uv_handle_t*>(&socket))\nWhich is: 1\n[  FAILED  ] InspectorSocketTest.ExtraLettersBeforeRequest (1 ms)\n[ RUN      ] InspectorSocketTest.RequestWithoutKey\n../test/cctest/test_inspector_socket.cc:512: Failure\nValue of: 0\nExpected: uv_is_active(reinterpret_cast<uv_handle_t*>(&socket))\nWhich is: 1\n[  FAILED  ] InspectorSocketTest.RequestWithoutKey (0 ms)\n[ RUN      ] InspectorSocketTest.KillsConnectionOnProtocolViolation\n[       OK ] InspectorSocketTest.KillsConnectionOnProtocolViolation (0 ms)\n[ RUN      ] InspectorSocketTest.CanStopReadingFromInspector\n[       OK ] InspectorSocketTest.CanStopReadingFromInspector (0 ms)\n[ RUN      ] InspectorSocketTest.CloseDoesNotNotifyReadCallback\n[       OK ] InspectorSocketTest.CloseDoesNotNotifyReadCallback (1 ms)\n[ RUN      ] InspectorSocketTest.CloseWorksWithoutReadEnabled\n[       OK ] InspectorSocketTest.CloseWorksWithoutReadEnabled (0 ms)\n[ RUN      ] InspectorSocketTest.ReportsHttpGet\n[       OK ] InspectorSocketTest.ReportsHttpGet (4 ms)\n[ RUN      ] InspectorSocketTest.HandshakeCanBeCanceled\n[       OK ] InspectorSocketTest.HandshakeCanBeCanceled (1 ms)\n[ RUN      ] InspectorSocketTest.GetThenHandshake\n[       OK ] InspectorSocketTest.GetThenHandshake (0 ms)\n[ RUN      ] InspectorSocketTest.WriteBeforeHandshake\n[       OK ] InspectorSocketTest.WriteBeforeHandshake (0 ms)\n[ RUN      ] InspectorSocketTest.CleanupSocketAfterEOF\n[       OK ] InspectorSocketTest.CleanupSocketAfterEOF (4 ms)\n[ RUN      ] InspectorSocketTest.EOFBeforeHandshake\n[       OK ] InspectorSocketTest.EOFBeforeHandshake (1 ms)\n[ RUN      ] InspectorSocketTest.Send1Mb\n[       OK ] InspectorSocketTest.Send1Mb (15 ms)\n[ RUN      ] InspectorSocketTest.ErrorCleansUpTheSocket\n[       OK ] InspectorSocketTest.ErrorCleansUpTheSocket (1 ms)\n[----------] 18 tests from InspectorSocketTest (29 ms total)\n\n[----------] Global test environment tear-down\n[==========] 22 tests from 2 test cases ran. (29 ms total)\n[  PASSED  ] 19 tests.\n[  FAILED  ] 3 tests, listed below:\n[  FAILED  ] InspectorSocketTest.ExtraTextBeforeRequest\n[  FAILED  ] InspectorSocketTest.ExtraLettersBeforeRequest\n[  FAILED  ] InspectorSocketTest.RequestWithoutKey\n\n 3 FAILED TESTS\nmake[1]: *** [cctest] Error 1\nmake: *** [test] Error 2\n```\n",
        "labels": "confirmed-bug",
        "id": 45422
    },
    {
        "title": "dns.lookup blocks filesystem I/O",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v4.5.0\n- **Platform**: Linux jessie 3.16.0-4-amd64 # 1 SMP Debian 3.16.7-ckt25-2+deb8u3 (2016-07-02) x86_64 GNU/Linux\n- **Subsystem**: dns\n\n<!-- Enter your issue details below this comment. -->\n\nHi all,\n\nI'm posting this issue as a continuation of an issue originally opened against node-serialport: https://github.com/EmergingTechnologyAdvisors/node-serialport/issues/797\n\nOn networks with slow DNS response, or where DNS requests time out and fail, we observe that the blocking calls to `getaddrinfo` issued by `dns.lookup` saturate Node's `libuv` threadpool and delay our serialport or filesystem IO.\n\nIt looks like this issue has come up many times before. The most pertinent example I could find is https://github.com/nodejs/node-v0.x-archive/issues/2868, which outlines exactly this issue. However, it was closed in favor of https://github.com/nodejs/node-v0.x-archive/issues/8475, in which the API of `net.connect` was changed to allow a user-specified DNS resolution handler.\n\nThe original proposal of issue 2868, which included a change to `dns.lookup`, seems to have been lost in the consolidation to issue 8475. In our case, we'd like to be able to use the OS-level DNS facilities like a local DNS cache, so using `dns.resolve` does not seem to be an equivalent substitute to using `dns.lookup`. Furthermore, our application uses multiple high-level modules that wrap REST APIs with their own request modules, so changing every call to `net.connect` to use a custom DNS function is not feasible.\n\nThere seems to be a relevant open issue against `libuv` on the matter at https://github.com/libuv/libuv/issues/203. Through various issue reports, I've seen proposals in `libuv` to use `getaddrinfo_a`, to segregate the threadpools, or to cap the number of threads DNS requests could use, to avoid DNS requests starving all other IO.\n\nUnfortunately, although the synchronicity of `dns.lookup` is documented at https://nodejs.org/api/dns.html#dns_implementation_considerations, its behavior is not intuitive given that other network requests are truly asynchronous, and it has resulted in many downstream issues, including our seeming issue with serialport.\n",
        "labels": "confirmed-bug",
        "id": 45423
    },
    {
        "title": "Memory leak in DiffieHellman.set{Privat,Public}Key() and some suggestions",
        "body": "```js\r\nvar dh=require('crypto').createDiffieHellman(512);\r\nvar pubkey=dh.generateKeys();\r\nwhile (true) {\r\n  for (var i=0; i<100000; i++) {\r\n    dh.setPublicKey(pubkey);\r\n  }\r\n  console.log(process.memoryUsage());\r\n}\r\n```\r\n\r\nIn https://github.com/nodejs/node/blob/master/src/node_crypto.cc#L4757 (void DiffieHellman::SetPublicKey):\r\n\r\n```cc\r\n    diffieHellman->dh->pub_key = BN_bin2bn(\r\n        reinterpret_cast<unsigned char*>(Buffer::Data(args[0])),\r\n        Buffer::Length(args[0]),\r\n        0);\r\n```\r\n\r\nbut `...->pub_key` might already point to allocated memory, which is never freed.\r\n\r\nman OpenSSL says:\r\n\r\n> ```\r\n>   BIGNUM *BN_bin2bn(const unsigned char *s, int len, BIGNUM *ret);\r\n> ```\r\n> \r\n>  BN_bin2bn() converts the positive integer in big-endian form of length len at s\r\n>  into a BIGNUM and places it in ret. If ret is NULL, a new  BIGNUM is created.\r\n\r\nSo it should be enough to pass diffieHellman->dh->pub_key as third parameter, instead of 0.\r\n\r\nDiffieHellman::SetPrivateKey, a few lines later, has the same issue.\r\n\r\n**Alternatively**, we could forbid calling set{Public,Private}Key after a key exists, because the DH api does not seem to encourage reuse of DiffieHellman classes: `generateKeys()` always returns the same key after the first call. According to OpenSSL documentation, this is caused by `dh->priv_key` being non-null.\r\nChanging `generateKeys()` to return a new key on every call would be breaking API change; OTOH `setPrivateKey()` can (currently) not be used to reset `dh->priv_key` to null (while freeing possibly allocated memory).\r\n\r\nAll in all this suggests that the user should create a new DiffieHellman class for each key exchange, but the nodejs binding again thwarts such efforts:\r\n\r\n```\r\nvar dh=crypto.getDiffieHellman('modp18');\r\n// Clone DiffieHellman class\r\nconsole.time(); \r\nvar dh2=crypto.createDiffieHellman(dh.getPrime(),dh.getGenerator());\r\nconsole.timeEnd();    // --> 1451ms, because of DH_check in DiffieHellman::VerifyContext()\r\n```\r\n\r\nTherefore I'd **also suggest** to add another \"overload\" to `createDiffieHellman` which takes an existing `DiffieHellman` class and creates a new one with the same Prime and Generator, with empty keys, but _without_ calling (slow) `DH_check` (the parameters have already been checked earlier!) by just _copying_ the `.verifyError` result.\r\n\r\nA side note: Given the trivial conversion (via `.getPrime`, as shown above) of a `DiffieHellmanGroup` class to a `DiffieHellman` class and the same C++ class under the hood, the non-existence of `.set{Public,Private}Key` on the `DiffieHellmanGroup` class obtained by `.getDiffieHellman` is **completely arbitrary** and unnecessary.\r\n\r\nBTW, why not add some way to directly use PEM-encoded `----BEGIN DH PARAMETERS-----` ... `END` parameters via `PEM_read_bio_DHparams` and a memory BIO, e.g. by overloading `getDiffieHellman()`? E.g. RSA already reads keys in PEM format (via OpenSSL), and the natural format of new DiffieHellman Paramaters  generated by (time-consuming!) `openssl dhparams [bits]` is PEM, which currently has be converted _manually_ to a format readable by nodejs...\r\n",
        "labels": "confirmed-bug",
        "id": 45424
    },
    {
        "title": "v6.5.0 fails to build using clang-3.4.",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.5.0\n- **Platform**: Debian, Ubuntu ... using clang-3.4\n- **Subsystem**: build\n\n<!-- Enter your issue details below this comment. -->\n\nOur package builds for Debian Wheezy, Ubuntu Precise, and perhaps others, are failing on v6.5.0 using `clang-3.4`.\n\nThis seems to be a regression possibly introduced by V8 5.1.\n\nSee also: https://github.com/nodejs/node/pull/8054#issuecomment-243153991\n\ncc @nodejs/v8 @nodejs/ctc\n",
        "labels": "confirmed-bug",
        "id": 45425
    },
    {
        "title": "EFAULT error in process.stdout.write(data, 'hex')",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**:6.4.0 (or lower versions)\n- **Platform**: macosx (or any other unix/linux) \n- **Subsystem**: none\n\n<!-- Enter your issue details below this comment. -->\n# summary\n\nThis test program stops with EFAULT error\nwhen it is executed with piped stdout.\n\nEFAULT error must not occur in writing to stdout.\nIt seems a bug in Node.js.\n\ntest.js:\n\n``` javascript\nvar data = new Buffer(1000000).toString('hex');\n\nfunction write_loop() {\n    while (process.stdout.write(data, 'hex'));\n}\n\nprocess.stdout.on('drain', write_loop);\n\nwrite_loop();\n\nfunction memory_pressure() {\n    var val = [];\n    for (var i = 0; i < 1000000; i++) {\n        val[i] = i;\n    }\n    return val;\n}\n\nsetInterval(memory_pressure, 100);\n```\n# detail\n\n``` sh\n% node test.js | cat >/dev/null\n\nevents.js:160\n      throw er; // Unhandled 'error' event\n      ^\n\nError: write EFAULT\n    at exports._errnoException (util.js:1026:11)\n    at WriteWrap.afterWrite (net.js:794:14)\n```\n- The stdout of 'node test.js' must be piped in order to result EFAULT error.\n- 'hex' encoding is also needed.\n- EFAULT error seldom occurs without memory_pressure.\n# possible cause\n\nI found that error does not occur with this workaround code added.\n\n``` javascript\nvar orig_writeBuffer = process.stdout._handle.writeBuffer;\nprocess.stdout._handle.writeBuffer = function(req, b) {\n    req.keepReferenceForWorkaround = b;\n    orig_writeBuffer.call(this, req, b);\n}\n```\n\nprocess.stdout._handle.writeBuffer actually is native-code\nand it seems it assumes a reference of passed buffer is kept alive until write-completion.\n\nIn case of 'hex' encoding, passed buffer was created in \ncreateWriteReq() in node/lib/net.js as follows:\n\n``` javascript\ndefault:\n      return handle.writeBuffer(req, Buffer.from(data, encoding));\n```\n\nSo, this buffer can be garbage-collected if handler.writeBuffer does not keep the reference alive.\n# other information\n\nhandle.writeBuffer is used also in case of 'buffer' encoding,\nbut the passed buffer is stored in the request object\nin Socket.prototype._writeGeneric() (node/lib/net.js) as follows:\n\n``` javascript\n   if (data instanceof Buffer) {\n      req.buffer = data;  // Keep reference alive.\n      enc = 'buffer';\n    } else {\n      enc = encoding;\n    }\n    err = createWriteReq(req, this._handle, data, enc);\n```\n\nSo, in this case, EFALT error does not occur.\n",
        "labels": "confirmed-bug",
        "id": 45426
    },
    {
        "title": "--inspect: chrome-devtools - nullptr ",
        "body": "- **Version**:6.4.0\n- **Platform**:Windows 10 Pro version 1607\n\nnode running on Windows crashes when attaching the debugger.\nIt works on MacOS and on Windows with version 6.3.1\n\n```\nDebugger listening on port 9229.\nWarning: This is an experimental feature and could change at any time.\nTo start debugging, open the following URL in Chrome:\n    chrome-devtools://devtools/remote/serve_file/@62cd277117e6f8ec53e31b1be58290a6f7ab42ef/inspector.html?experiments=true&v8only=true&ws=localhost:9229/node\nServer running at http://127.0.0.1:80/\n**C:\\Program Files\\nodejs\\node.exe: src\\inspector_socket.cc:569: Assertion `(inspector->http_parsing_state) == (nullptr)' failed.**\n```\n",
        "labels": "confirmed-bug",
        "id": 45427
    },
    {
        "title": "assertion when attaching the Chrome dev tools",
        "body": "**Version**: v.6.4.0\n**Platform**: Windows10 64 bit\n**Repro**:\n- Run (script can be moved to the separate file, repro uses inline version only for brevity):\n\n```\nnode --inspect -e \"while(1);\"\n```\n- Open url that will be printed to start debugging.\n\n**Expected**:\n- Chrome dev tools are opened without any errors\n\n**Actual**:\nnode process shuts down the message:\n\n```\nC:\\Program Files\\nodejs\\node.EXE: src\\inspector_socket.cc:569: Assertion `(inspector->http_parsing_state) == (nullptr)' failed.\n```\n",
        "labels": "confirmed-bug",
        "id": 45428
    },
    {
        "title": "Change between Node 6.3.1 and 6.4 regarding writing strings of length 0 to a Buffer",
        "body": "In Node 6.3.1, you could do this:\n\n```\nvar buff = Buffer.alloc(1);\nbuff.write('', 1, 0);\nconsole.log(buff);\n```\n\nThat is, writing empty strings out of the buffer bounds would not cause a crash. However, with 6.4, that code above causes a crash with this error message:\n\n```\nbuffer.js:761\n     return this.utf8Write(string, offset, length);\n\nRange Error: Offset is out of bounds\n```\n\nThis change causes my library [to break](https://github.com/phretaddin/schemapack/issues/18). I'm wondering if this was an intentional change. If so, just let me know, and I'll patch my library to check for empty strings before writing.\n",
        "labels": "confirmed-bug",
        "id": 45429
    },
    {
        "title": "uv_close: Assertion `0' failed on child_process.execSync w/ Infinite maxBuffer",
        "body": "- **Version**: tested on 4.4.7 and 5.10.0\n- **Platform**:  `Linux 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt25-2 (2016-04-08) x86_64 GNU/Linux`\n- **Subsystem**:  child_process and deps/uv/src/unix/core.c\n\nReproduce:\n\n``` js\nvar cp = require('child_process')\n\ncp.execSync('', { maxBuffer: Infinity })\n```\n\n```\nnode: ../deps/uv/src/unix/core.c:165: uv_close: Assertion `0' failed.\n[1]    31628 abort      node index.js\n```\n\nNot that the async `exec` does not exert the same behaviour\n\n``` js\nvar cp = require('child_process')\n\ncp.exec('', { maxBuffer: Infinity })\n```\n\n```\n```\n",
        "labels": "confirmed-bug",
        "id": 45430
    },
    {
        "title": "segfault on node v6.3.1 on Ubuntu 14.04.4",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.3.1\n- **Platform**: Ubuntu 14.04.4 LTS (Heroku)\n- **Subsystem**: ?\n\n<!-- Enter your issue details below this comment. -->\n\nHello,\n\nI seem to be able to fairly reliably (maybe 50% of the time) reproduce a segfault with node v6.3.1 in my express application. I'm not using any native modules (except for `segfault-handler` to get the trace output below, and the error of course also occurs without `segfault-handler`).\n\nThis is the output I get:\n\n```\nPID 17 received SIGSEGV for address: 0x753760f\n/app/node_modules/segfault-handler/build/Release/segfault-handler.node(+0x1b04)[0x7f1fd8283b04]\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x10330)[0x7f1fdce8b330]\nnode(_ZN4node7TLSWrap7IsAliveEv+0x16)[0x1026586]\nnode(_ZN4node10StreamBase5GetFDINS_7TLSWrapEEEvN2v85LocalINS3_6StringEEERKNS3_20PropertyCallbackInfoINS3_5ValueEEE+0x92)[0x102b192]\nnode(_ZN2v88internal25PropertyCallbackArguments4CallEPFvNS_5LocalINS_4NameEEERKNS_20PropertyCallbackInfoINS_5ValueEEEES4_+0xd2)[0x981c12]\nnode(_ZN2v88internal6Object23GetPropertyWithAccessorEPNS0_14LookupIteratorE+0x1bd)[0xd16c1d]\nnode(_ZN2v88internal6Object11GetPropertyEPNS0_14LookupIteratorE+0x13b)[0xd51c2b]\nnode(_ZN2v88internal6LoadIC4LoadENS0_6HandleINS0_6ObjectEEENS2_INS0_4NameEEE+0x145)[0xcbc1c5]\nnode[0xcbcfdc]\nnode(_ZN2v88internal24Runtime_KeyedLoadIC_MissEiPPNS0_6ObjectEPNS0_7IsolateE+0x112)[0xcbfef2]\n[0x1367f3c0961b]\n```\n\nThe error seems to happen right after I send a message to a client via socket.io, but the message itself seems to send correctly (that is, I see a log line after the `.emit`).\n\nI looked at the other open issues mentioning segfaults, but I did not see anything relevant.\n\nAny ideas?\n",
        "labels": "confirmed-bug",
        "id": 45431
    },
    {
        "title": "Array and Object have different values in REPL and in files",
        "body": "- **Version**: `v6.3.0`\n- **Platform**: `4.4.0-31-generic #50-Ubuntu SMP Wed Jul 13 00:07:12 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux`\n\nI have one file, say `is.js`, that contains the following:\n\n``` javascript\nexports.isObject = (obj) => obj.constructor === Object\nexports.isNumber = (obj) => obj.constructor === Number\n```\n\nIn the console, `require('./is.js').isObject({})` returns `false`. However, `({}).constructor === Object` returns `true`. Strangely, `isNumber(2)` works as expected. When `require`d from another file, everything works as expected.\n\nAffected classes:\n- `Object`\n- `Array`\n- `Date`\n- `Error`\n- `RegExp`\n\nUnaffected classes:\n- `Number`\n- `String`\n- `Boolean`\n- `Map`\n- `Set`\n- `Symbol`\n- Typed arrays\n",
        "labels": "confirmed-bug",
        "id": 45432
    },
    {
        "title": "clearTimeout with invalid handle cause program runs longer",
        "body": "<!--\nThank you for reporting an issue.\nPlease fill in as much of the template below as you're able.\n\nVersion: output of `node -v`\nPlatform: output of `uname -a` (UNIX), or version and 32 or 64-bit (Windows)\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: Tested on 6.0.0\n- **Platform**: Tested on Windows & MacOS\n- **Subsystem**: Timer\n\n<!-- Enter your issue details below this comment. -->\n\nThis program cost 20 seconds, but 10.5 seconds was expected:\n\n``` javascript\nvar handle = setTimeout(function(){\n    clearTimeout(handle);\n    handle = setTimeout( function() {\n    }, 10000 );\n    setTimeout( function() {\n        clearTimeout( handle );\n    }, 500 );\n}, 10000);\n```\n\nBut all below codes work as expected:\n\n``` javascript\nvar handle = setTimeout(function(){\n    clearTimeout(handle);\n    handle = setTimeout( function() {\n    }, 10000 );\n    setTimeout( function() {\n        clearTimeout( handle );\n    }, 500 );\n}, 2000);  // <-- different delay \n```\n\n``` javascript\nvar handle = setTimeout(function(){\n        //clearTimeout(handle);  <-- comment this line.\n    handle = setTimeout( function() {\n    }, 10000 );\n    setTimeout( function() {\n        clearTimeout( handle );\n    }, 500 );\n}, 10000);\n```\n\nDoes clearTimeout with a invalid handle causes this problem?\n",
        "labels": "confirmed-bug",
        "id": 45433
    },
    {
        "title": "[repl] Tab completion crashes when invoked on in multiline mode after line with error",
        "body": "- **Version**: tested on node v6.2.2 & v6.3.0\n- **Platform**: OS X 10.11.5 on a Mac Mini late 2014, if relevant\n- **Subsystem**: repl\n\nWhen in the repl in multiline node, specifically when typing a function body, tab completion crashes the repl when invoked on a new line if the previous line would produce an error on evaluating.\n\nMinimal example: (`<tab>` indicates pressing the actual tab key)\n\n```\n> function(){\n... some_undefined_thing;\n... <tab>\nrepl.js:306\n    top.outputStream.write((e.stack || e) + '\\n');\n       ^\n\nTypeError: Cannot read property 'outputStream' of undefined\n    at Domain.<anonymous> (repl.js:306:8)\n    at emitOne (events.js:96:13)\n    at Domain.emit (events.js:188:7)\n    at Domain.errorHandler [as _errorHandler] (domain.js:97:23)\n    at process._fatalException (node.js:247:33)\n```\n\n(Actually, `repl.js:306` comes right after the `...` on the line on which tab was pressed.)\n\nInterestingly, this seems to be highly dependent on the exact conditions:\n\n```\n> function(){\n... k;\n... <tab>\nrepl.js:306 ...etc (CRASH)...\n```\n\ncrashes, just like\n\n```\n> k;\nReferenceError: k is not defined ...etc...\n> function(){\n... k;\n... <tab>\nrepl.js:306 ...etc (CRASH)...\n```\n\nand\n\n```\n> {k;}\nReferenceError: k is not defined ...etc...\n> function(){\n... k;\n... <tab>\nrepl.js:306 ...etc (CRASH)...\n```\n\nwhile\n\n```\n> {\n... k;\n... }\nReferenceError: k is not defined ...etc...\n> function(){\n... k;\n... <tab>\n(opens completions normally)\n```\n\nAnother example indicating this isn't something specific to ReferenceErrors:\n\n```\n> function(){\n... new Error(\"\");\n... <tab>\n(opens completions normally)\n```\n\nwhile\n\n```\n> function(){\n... throw new Error(\"\");\n... <tab>\nrepl.js:306 ...etc (CRASH)...\n```\n\nSomething else to make things potentially even more mysterious: having the erroring line on the same line as where the block started, doesn't crash.\n\n```\n> function(){ throw new Error(\"\");\n... <tab>\n(opens completions normally)\n```\n\nwhile having an extra line in between still crashes:\n\n```\n> function(){\n... console.log(\"hoi\");\n... throw new Error(\"\");\n... <tab>\nrepl.js:306 ...etc (CRASH)...\n```\n\nI have no idea what might be causing this. Any ideas?\n",
        "labels": "confirmed-bug",
        "id": 45434
    },
    {
        "title": "node --inspect connecting with url in localhost:<port>/json gives malloc error with nightlies",
        "body": "- **Version**: v7.0.0-nightly20160621ecc48a154d (21st Jun)\n- **Platform**: Mac OS\n- **Subsystem**: 10.9.5\n\n<!-- Enter your issue details below this comment. -->\n\nStarting node as \n`node --debug-brk --inspect=9999`\n\nThen navigating to `http://localhost:9999/json`\nGives\n\n```\n[\n{\ndescription: \"node.js instance\",\ndevtoolsFrontendUrl: \"https://chrome-devtools-frontend.appspot.com/serve_file/@521e5b7e2b7cc66b4006a8a54cb9c4e57494a5ef/inspector.html?experiments=true&v8only=true&ws=localhost:9999/node\",\nfaviconUrl: \"https://nodejs.org/static/favicon.ico\",\nid: \"8622\",\ntitle: \"node\",\ntype: \"node\",\nwebSocketDebuggerUrl: \"ws://localhost:9999/node\"\n}\n]\n```\n\nWhen connecting to devtoolsFrontendUrl: https://chrome-devtools-frontend.appspot.com/serve_file/@521e5b7e2b7cc66b4006a8a54cb9c4e57494a5ef/inspector.html\n\n```\nDebugger listening on port 9999.\nTo start debugging, open the following URL in Chrome:\n    chrome-devtools://devtools/remote/serve_file/@521e5b7e2b7cc66b4006a8a54cb9c4e57494a5ef/inspector.html?experiments=true&v8only=true&ws=localhost:9999/node\nnode(8622,0x104801000) malloc: *** error for object 0x15: pointer being freed was not allocated\n*** set a breakpoint in malloc_error_break to debug\n[1]    8622 abort      node --debug-brk --inspect=9999\n```\n\n/cc @ofrobots @pavelfeldman @paulirish\n",
        "labels": "confirmed-bug",
        "id": 45435
    },
    {
        "title": "Error ONLY when running babel task on arm64 node v4.4.6",
        "body": "Hi, I have reported an error on the babel issue tracker at https://phabricator.babeljs.io/T7457\n\nbut it might also be, that this is an issue on node v4?\n\nThe issue described does ONLY occur an the arm64 architecture (I am also using the linoaro dev cluster).\n\nIn a short:\n\nrunning:\n\n```\nmkdir -p /tmp/babel-test\n\ncd /tmp/babel-test\n\nnpm install babel-cli babel-preset-es2015 --save-dev\n\n./node_modules/.bin/babel ./node_modules/babel-polyfill/dist/polyfill.js -d lib --presets es2015 --no-babelrc\n```\n\nwill return\n\n<pre>\n[BABEL] Note: The code generator has deoptimised the styling of \"./node_modules/babel-polyfill/dist/polyfill.js\" as it exceeds the max of \"100KB\".\nTypeError: ./node_modules/babel-polyfill/dist/polyfill.js: Cannot read property 'compact' of undefined\nat Function.space (/tmp/babel-test/node_modules/babel-generator/lib/buffer.js:139:20)\nat Function.ObjectExpression (/tmp/babel-test/node_modules/babel-generator/lib/generators/types.js:62:10)\nat /tmp/babel-test/node_modules/babel-generator/lib/printer.js:113:24\nat Generator.withSource (/tmp/babel-test/node_modules/babel-generator/lib/buffer.js:293:39)\nat Generator.print (/tmp/babel-test/node_modules/babel-generator/lib/printer.js:112:10)\nat Generator.printJoin (/tmp/babel-test/node_modules/babel-generator/lib/printer.js:197:12)\nat Generator.printList (/tmp/babel-test/node_modules/babel-generator/lib/printer.js:261:17)\nat Generator.CallExpression (/tmp/babel-test/node_modules/babel-generator/lib/generators/expressions.js:144:8)\nat /tmp/babel-test/node_modules/babel-generator/lib/printer.js:113:24\nat Generator.withSource (/tmp/babel-test/node_modules/babel-generator/lib/buffer.js:293:39)\n</pre>\n\n\nIf I use node v6.2.2 arm64 and run the same command, the result is:\n\n<pre>\n[BABEL] Note: The code generator has deoptimised the styling of \"./node_modules/babel-polyfill/dist/polyfill.js\" as it exceeds the max of \"100KB\".\n./node_modules/babel-polyfill/dist/polyfill.js -> lib/node_modules/babel-polyfill/dist/polyfill.js\n</pre>\n\n\nSeems to be a kind of memory leak ?\n",
        "labels": "confirmed-bug",
        "id": 45436
    },
    {
        "title": "Readline keypress event is triggered only after pressing Esc key 3 times",
        "body": "- **Version**: 6.2.2 and 4.4.5\n- **Platform**: macOS 10.11.5\n- **Subsystem**: readline\n### Test case\n\n``` js\nconst readline = require('readline');\nreadline.emitKeypressEvents(process.stdin);\nprocess.stdin.setRawMode(true);\nprocess.stdin.on('keypress', console.log);\n```\n### Expected\n\nAfter pressing <kbd>Esc</kbd> once, I would get this output:\n\n```\nundefined { sequence: '\\u001b',\n  name: 'escape',\n  ctrl: false,\n  meta: true,\n  shift: false }\n```\n## Actual\n\nAfter pressing <kbd>Esc</kbd> three times, I get this output:\n\n```\nundefined { sequence: '\\u001b\\u001b\\u001b',\n  name: 'escape',\n  ctrl: false,\n  meta: true,\n  shift: false }\n```\n## \n\nIt works fine on 0.10.44 and 0.12.13. After pressing <kbd>Esc</kbd> once:\n\n```\n{ name: 'escape',\n  ctrl: false,\n  meta: false,\n  shift: false,\n  sequence: '\\u001b' }\n```\n\nAlso notice that `meta` is `false` here.\n",
        "labels": "confirmed-bug",
        "id": 45437
    },
    {
        "title": "replServer defineCommand",
        "body": "- **Version**: v4.4.5\n- **Platform**: Linux lts 4.4.0-24-generic #43-Ubuntu SMP Wed Jun 8 19:27:37 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**:\n\n<!-- Enter your issue details below this comment. -->\n\nWhen I try this demo\n\n```\n// repl_test.js\nconst repl = require('repl');\n\nvar replServer = repl.start({});\nreplServer.defineCommand('sayhello', {\n  help: 'Say hello',\n  action: function(name) {\n    this.write(`Hello, ${name}!\\n`);\n    this.displayPrompt();\n  }\n});\n```\n\nthen run this in my command line with node repl_test.js\n// and got the output with\n\n> .sayhello Node.js User\n> Hello, Node.js User!\n> SyntaxError: Unexpected identifier\n>     at Object.exports.createScript (vm.js:24:10)\n>     at REPLServer.defaultEval (repl.js:235:25)\n>     at bound (domain.js:287:14)\n>     at REPLServer.runBound [as eval](domain.js:300:12)\n>     at REPLServer.<anonymous> (repl.js:431:12)\n>     at emitOne (events.js:77:13)\n>     at REPLServer.emit (events.js:169:7)\n>     at REPLServer.Interface._onLine (readline.js:211:10)\n>     at REPLServer.Interface._line (readline.js:550:8)\n>     at REPLServer.Interface._ttyWrite (readline.js:885:20)\n\nIt got the synatax error, and I don't know why?\n",
        "labels": "confirmed-bug",
        "id": 45438
    },
    {
        "title": "Encoding of child_process.exec.stdout changed from String to Buffer in v6.2.1",
        "body": "<!--\nThank you for reporting an issue. Please fill in the template below. If unsure\nabout something, just do as best as you're able.\n\nVersion: usually output of `node -v`\nPlatform: either `uname -a` output, or if Windows, version and 32 or 64-bit\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: v6.2.1\n- **Platform**: Darwin Kernel Version 15.5.0\n- **Subsystem**: child_process\n\n<!-- Enter your issue details below this comment. -->\n\nSomewhere between node v6.2.0 and v6.2.1 the encoding of the data passed to the 'on data' callback for the child_process.exec.stdout stream seems to have changed from String to Buffer.\n\nWas this an intentional change, and what is the recommended way of setting the encoding for the exec stdout/stdio stream?\n\nThanks\n\nCode example:\n\n```\nvar exec = require('child_process').exec;\nvar keepAlive = setInterval(() => {}, 1000000000);\nvar e = exec('ls');\ne.stdout.on('data', function(data) {\n  console.log('data: ', typeof data, data instanceof Buffer);\n  clearInterval(keepAlive);\n});\n```\n\nwith v6.2.0, output is `data:  string false`\nwith v6.2.1, output is `data: object true`\n",
        "labels": "confirmed-bug",
        "id": 45439
    },
    {
        "title": "Failed to compile from source for armv7l (busybox) on ",
        "body": "<!--\nThank you for reporting an issue. Please fill in the template below. If unsure\nabout something, just do as best as you're able.\n\nVersion: usually output of `node -v`\nPlatform: either `uname -a` output, or if Windows, version and 32 or 64-bit\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: 6.2.1\n- **Platform**: busybox (Linux dm3730_zoom_torpedo 3.0.0-ts-armv7l #23 Thu Feb 18 13:29:10 PST 2016 armv7l GNU/Linux) \n- **Subsystem**: \n\n<!-- Enter your issue details below this comment. -->\n\nI am trying to compile node version 6.2.1 for armv7l (tried using out of the box one before, it would not run for me at all). While I was successfully able to compile all versions prior 6.2.0 (i.e. from 4.x -6.1), 6.2.0 and 6.2.1 start giving me a problem with **icu** and throws the  following error\n\n``` bash\nOptions: {'verbose': 1, 'filterfile': 'icu_small.json', 'toolpath': '/var/jenkins_home/jobs/Node/workspace/out/Release', 'deltmpdir': 1, 'outfile': 'icudt57l.dat', 'datfile': '../../deps/icu-small/source/data/in/icudt57l.dat', 'locales': 'en,root', 'endian': 'little', 'tmpdir': '/var/jenkins_home/jobs/Node/workspace/out/Release/obj/gen/icutmp'}\nicu_small.json: icutrim.py config: Trim down ICU to just a certain locale set, needed for node.js use.\n\nFAILED: /var/jenkins_home/jobs/Node/workspace/out/Release/icupkg -tl ../../deps/icu-small/source/data/in/icudt57l.dat \n\n/var/jenkins_home/jobs/Node/workspace/out/Release/obj/gen/icutmp/icudt57l.dat\ntools/icu/icudata.target.mk:13: recipe for target '/var/jenkins_home/jobs/Node/workspace/out/Release/obj/gen/icutmp/icudt57l.dat' failed\nmake[1]: *** [/var/jenkins_home/jobs/Node/workspace/out/Release/obj/gen/icutmp/icudt57l.dat] Error 1\n\n```\n\nThe script that i am using to build it is the following:\n\n``` bash\n#!/bin/sh\nexport AR=~/timesys/bin/armv7l-timesys-linux-gnueabi-ar\nexport CC=~/timesys/bin/armv7l-timesys-linux-gnueabi-gcc\nexport CXX=~/timesys/toolchain/bin/armv7l-timesys-linux-gnueabi-g++\nexport LINK=~/timesys/bin/armv7l-timesys-linux-gnueabi-g++\n\nexport TARGET_ARCH=\"-march=armv7l\"\nexport TARGET_TUNE=\"-mtune=cortex-a8 -mfpu=neon -mfloat-abi=softfp -mthumb-interwork -mno-thumb\"\n\n#DEFINE FLAGS\nexport CXX_TARGET_ARCH=\"-march-armv7l\"\nexport V8_TARGET_ARCH=\"-march-armv7l\"\n\nmake clean\n./configure with --without-snapshot;\nexport DESTDIR=\"~/dist/node-6.2.1\"\nmake -j4 install\n\n```\n\nAm I missing some kind of dependencies? Please advise if \n",
        "labels": "confirmed-bug",
        "id": 45440
    },
    {
        "title": "observed setImmediate and setTimeout execution order contradicts documentation",
        "body": "<!--\nThank you for reporting an issue. Please fill in the template below. If unsure\nabout something, just do as best as you're able.\n\nVersion: usually output of `node -v`\nPlatform: either `uname -a` output, or if Windows, version and 32 or 64-bit\nSubsystem: if known, please specify affected core module name\n\nIf possible, please provide code that demonstrates the problem, keeping it as\nsimple and free of external dependencies as you are able.\n-->\n- **Version**: `v6.2.1`\n- **Platform**: `Darwin`\n- **Subsystem**: `timers`\n\n<!-- Enter your issue details below this comment. -->\n\nDocumentation for `setImmediate`:\n\n> Schedules \"immediate\" execution of callback after I/O events' callbacks and **before timers set by setTimeout and setInterval** are triggered. \n\nDemonstration:\n\n``` javascript\nconsole.log(\"nodejs version\", process.versions.node);\nconsole.log(\"start\");\nsetTimeout(() =>\n{\n    console.log(\"setTimeout 0 callback\");\n}, 0);\nsetTimeout(() =>\n{\n    console.log(\"setTimeout 1 callback\");\n}, 1);\nsetImmediate(() =>\n{\n    console.log(\"setImmediate callback\");\n});\nsetTimeout(() =>\n{\n    console.log(\"setTimeout 0 after setImmediate callback\");\n}, 0);\nsetTimeout(() =>\n{\n    console.log(\"setTimeout 1 after setImmediate callback\");\n}, 1);\nprocess.nextTick(() => {\n  console.log(\"nextTick callback\");\n});\nconsole.log(\"scheduled\");\n```\n\nObserved outputs:\n\n```\n$ node test.js \nnodejs version 6.2.1\nstart\nscheduled\nnextTick callback\nsetTimeout 0 callback\nsetTimeout 1 callback\nsetImmediate callback\nsetTimeout 0 after setImmediate callback\nsetTimeout 1 after setImmediate callback\n```\n\n```\n$ node test.js \nnodejs version 6.2.1\nstart\nscheduled\nnextTick callback\nsetTimeout 0 callback\nsetTimeout 1 callback\nsetTimeout 0 after setImmediate callback\nsetTimeout 1 after setImmediate callback\nsetImmediate callback\n```\n\nExpected output:\n\n```\n$ node test.js \nnodejs version 6.2.1\nstart\nscheduled\nnextTick callback\nsetImmediate callback\nsetTimeout 0 callback\nsetTimeout 1 callback\nsetTimeout 0 after setImmediate callback\nsetTimeout 1 after setImmediate callback\n```\n",
        "labels": "confirmed-bug",
        "id": 45441
    },
    {
        "title": "Crashes when UDP/dgram socket is closed during listening event handler",
        "body": "- **Version**: 4.3, master\n- **Platform**: Linux 4.4\n- **Subsystem**: dgram\n\nNode.js crashes when a UDP/dgram socket is closed in the `listening` event handler.\n\nOutput / Stack trace using node.js 4.3:\n\n```\ndgram.js:460\n    throw new Error('Not running'); // error message from dgram_legacy.js\n    ^\n\nError: Not running\nat Socket._healthCheck (dgram.js:460:11)\nat Socket.send (dgram.js:284:8)\nat Socket.<anonymous> (dgram.js:299:21)\nat Socket.g (events.js:260:16)\nat emitNone (events.js:72:20)\nat Socket.emit (events.js:166:7)\nat startListening (dgram.js:121:10)\nat dgram.js:220:7\nat nextTickCallbackWith3Args (node.js:452:9)\nat process._tickCallback (node.js:358:17)\n```\n\nThis seems to happen because node.js attaches an own eventhandler to the `listening` event which will try to send messages that were enqueued before, but have not been sent (https://github.com/nodejs/node/blob/master/lib/dgram.js#L288-L293).  This closure might run after a user event handler which might close the socket (like mine does if it fails to join a multicast group). When it runs and tries to send messages on the already closed socket an exception is thrown which can not be captured by the user, because it's not on his callstack.\n\nWhat should be done to avoid that:\n- The `listening` handler should check if the socket is still open before starting to send enqueued messages and should simply return if it's no longer open.\n- The `close()` function should flush the sendQueue, which would also avoid that the handler does attempt to send anything.\n\nActually the second part is more part, because it seems that currently the callbacks for those queued sends are also never called if the socket is closed before connecting and because it would already solve the issue. However another sanity check in the `listening` handler would still be ok.\n\nWorkarounds: \n- Don't send anything before listening is emitted\n- Don't close the socket or do any complex logic in the `listening` handler, but defer the custom logic in a new eventloop tick.\n\nMy code for reproduction:\n\n```\nclass MulticastSocket {\n// ...\n\nopen() {\n  this._socket = dgram.createSocket(<any>{\n    type: 'udp4',\n    reuseAddr: true,\n  });\n\n  this._socket.once('listening', () => {\n    console.log('Multicast socket is listening')     \n\n    try {\n      // Try to join a multicast group\n      // This might fail depending on the network interfaces of the device\n      this._socket.addMembership(this._multicastAddress);\n      this._state = 'CONNECTED';\n    } catch (e) {\n      console.error('Adding multicast group membership failed')        \n      this._closeSocket(); // The socket is closed here inside the event listener\n    }\n  });\n}\n\n_closeSocket() {\n  if (this._state === 'CLOSED') return false;\n  this._state = 'CLOSED';\n\n  if (this._socket) {\n  this._socket.removeAllListeners();\n  this._socket.close();\n  this._socket = null;\n}\n```\n",
        "labels": "confirmed-bug",
        "id": 45442
    },
    {
        "title": "FATAL ERROR: v8::FromJust Maybe value is Nothing",
        "body": "- **Version**: 4.2.2, 4.4.0, 6.2.0\n- **Platform**: 4.2.0-35-generic #40-Ubuntu SMP  x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**: ubuntu 15.10\n\nsegmentation fault when simple mqtt client tries to send 40kb data to broker.\n4.x versions of node crash with \"console.log is not a function\"\nProgram does not crash when i remove the // before the first console.log.\nSeems to work under 32 bit.\n\nsteps to reproduce:\n\n```\n$ npm install mqtt mosca\n$ node_modules/.bin/mosca &\n...\n$ node crash.js \nFATAL ERROR: v8::FromJust Maybe value is Nothing.\nAborted (core dumped)\n\n$ cat crash.js\nvar mqtt    = require('mqtt');\nvar client  = mqtt.connect('mqtt://localhost');\nvar todo=5000;\n\nclient.on('connect', function () {\n//  console.log(\"WTF\");\n  client.subscribe('config/#');\n  pubs();\n});\n\nfunction pubs()\n{\n  if(todo>0)\n{\n  todo-=1;\n client.publish('c/'+todo, '' ,pubs);\n} else\n{\n  console.log(\"END\");\n  client.end();\n}\n}\n```\n",
        "labels": "confirmed-bug",
        "id": 45443
    },
    {
        "title": "streams: synchronous unpipe() causes data stalls",
        "body": "Continuation of https://github.com/nodejs/node-v0.x-archive/issues/7451.  Test case:\n\n``` js\nvar assert = require('assert');\nvar stream = require('stream');\n\nvar a = new stream.Duplex;\nvar b = new stream.Writable;\nvar chunks = [];\n\na._read = function() {};\na._write = a.push.bind(a);\nb._write = chunks.push.bind(chunks);\n\na.pipe(b);\na.write('ping');\na.unpipe(b);\n\nprocess.on('exit', function() {\n  assert(chunks.length > 0);\n});\n```\n\nFrom the original issue:\n\n> The unpipe() stops the data from propagating down the chain. That's problematic because I, as a streams2 user that gets slotted somewhere in the chain of handlers, don't know if or when unpipe() gets called.\n> \n> The observable behavior is that sometimes your pipeline stalls without a clue why. It took me long enough to debug so I strongly doubt that an average user could figure it out.\n\nIn the other issue I mentioned that it works with v0.10 but it fails with v0.10.41 and v0.10.45 so it seems there's been a regression somewhere.  I think I originally tested with v0.10.26 or v0.10.27-pre.\n\n/cc @nodejs/streams\n",
        "labels": "confirmed-bug",
        "id": 45444
    },
    {
        "title": "Loop with computed name crash node 6.2.0 without message",
        "body": "- **Version**: 6.2.0\n- **Platform**: Windows 10\n\nThis code crash node without notice:\n\n```\n\"use strict\";\n\nvar test = function () {\n    var random = 0 | Math.random()*1000;\n    var today = Date.now();\n    var o = {\n        ['prop_' + random] : today,\n        random,\n        today\n    };\n};\nconsole.time('test');\nfor (var n = 0; n < 100000; n++) {\n    test();\n}\nconsole.timeEnd('test');\n```\n\nWhen run this simple code, node 6.2.0 end without message. If I reduce the loop from 100.000 to 10.000, the code run perfectly and show\n\n```\ntest: 14.188ms\n```\n",
        "labels": "confirmed-bug",
        "id": 45445
    },
    {
        "title": "Missing or truncated error message",
        "body": "This looks close to #6456, and I thought it was just another case of that issue, but @indutny mentioned that the errors are printed from c++, so #6456 alone shouldn't have caused this, this is why I'm opening a separate issue.\n\nA harder to reproduce example where the error is missing (it reproduces with about 10% chance for me):\n\n``` js\nfor (var i = 0; i < 10000; i++) {\n  console.log('HelloHelloHelloHelloHelloHelelloHelloHelloHelloHelloHelloHello ' + i);\n}\na();\n```\n\nA simplier to reproduce example (the error gets truncated here most of the times, and sometimes is missing as in the previous example):\n\n``` js\nfor (var i = 0; i < 10000; i++) {\n  console.log('HelloHelloHelloHelloHelloHelelloHelloHelloHelloHelloHelloHello ' + i);\n}\nthrow new Error(Array(100000 + 1).join('x') + '!');\n```\n",
        "labels": "confirmed-bug",
        "id": 45446
    },
    {
        "title": "REPL crashes after let process;",
        "body": "- **Version**: v6.0.0\n- **Platform**: Windows 10 64bit\n- **Subsystem**: REPL\n\n<!-- Enter your issue details below this comment. -->\n\nSteps to replicate:\n1. Open REPL\n2. Type \"let process;\"\n\nNode crashes instead of displaying something like TypeError: Identifier 'process' has already been declared.\n",
        "labels": "confirmed-bug",
        "id": 45447
    },
    {
        "title": "Stream.Writable reports wrong number in _writableState.bufferedRequestCount",
        "body": "- **Version**: v6.1.0\n- **Platform**: Windows 10 64-bit\n- **Subsystem**: Stream\n\nWas casually reading _stream_writable.js and noticed that `clearBuffer()` mistakenly zeroes `state.bufferedRequestCount` at the end of the function in case when `_writev` is not implemented and `_write` is not synchronous. The `while (entry)` loop is breaken from, leaving data in the buffer, but the request counter is zeroed out anyway.\n\nHere's the testing code\n\n``` javascript\n'use strict';\n\nconst Stream = require('stream');\n\nclass testWritable extends Stream.Writable {\n  constructor() {\n    super({objectMode: true});\n  }\n\n  _write(chunk, encoding, cb) {\n    console.log(`_writing chunk ${chunk}`);\n    setTimeout(cb, 1000);\n  }\n}\n\nconst testStream = new testWritable();\n\ntestStream.cork();\nfor (let i = 1; i <= 5; ++i) {\n  testStream.write(i, () => { \n    console.log(`chunk ${i} cb called`);\n    console.log(`_writableState.bufferedRequestCount = ${testStream._writableState.bufferedRequestCount}`);\n    console.log(`real buffered request count = ${testStream._writableState.getBuffer().length}`);\n  });\n}\ntestStream.end();\nconsole.log('main program ends here');\n```\n\nAnd the output:\n\n```\n_writing chunk 1\nmain program ends here\n_writing chunk 2\nchunk 1 cb called\n_writableState.bufferedRequestCount = 0\nreal buffered request count = 3\n_writing chunk 3\nchunk 2 cb called\n_writableState.bufferedRequestCount = 0\nreal buffered request count = 2\n_writing chunk 4\nchunk 3 cb called\n_writableState.bufferedRequestCount = 0\nreal buffered request count = 1\n_writing chunk 5\nchunk 4 cb called\n_writableState.bufferedRequestCount = 0\nreal buffered request count = 0\nchunk 5 cb called\n_writableState.bufferedRequestCount = 0\nreal buffered request count = 0\n```\n\nThe implications of this are super low, I understand, but you know, just in case.\n",
        "labels": "confirmed-bug",
        "id": 45448
    },
    {
        "title": "https.request(): Agent name inconsistency when servername not supplied",
        "body": "- **Version**: v4.4.4\n- **Platform**: Linux XXXXXXXXXXX 3.13.0-62-generic #102~precise1-Ubuntu SMP Wed Aug 12 14:09:54 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n\nThe PR https://github.com/nodejs/node/pull/4389 introduced `servername` in the computation of the agent name.\n\nIf the caller of `https.request()` does not supply `servername`, _http_agent may introduce it in its method `createSocket()` if the header `host` is supplied. See [here](https://github.com/nodejs/node/blob/572e28efa2e3cde78b5e7984b7760fd4c270f619/lib/_http_agent.js#L168-L174).\n\nThat introduced an inconsistency issue in the method `addRequest()`, because `getName()` is called before `createSocket()` is called, which means on first call, it will not contain `servername`, while it will on subsequent calls, in particular when handling destruction.\n- Call to `getName()`: https://github.com/nodejs/node/blob/572e28efa2e3cde78b5e7984b7760fd4c270f619/lib/_http_agent.js#L121\n- Call to `createSocket()` in the same method: https://github.com/nodejs/node/blob/572e28efa2e3cde78b5e7984b7760fd4c270f619/lib/_http_agent.js#L144\n\nThat created an issue for us. We are a high traffic site, and node was leaving a lot of sockets in TIME_WAIT state behind. \n#### Expected\n\nagent name computation and management in `sockets` and `freeSockets` should be consistent.\n#### App-level workaround:\n\nAlways supply `servername` in the options of `https.request()`\n\n(Apologies, I haven't come up with a minimal test to highlight the problem, I figure it was more important to report the problem first, and I'll try to come up with a test after that.)\n",
        "labels": "confirmed-bug",
        "id": 45449
    },
    {
        "title": "require has issues when run from /",
        "body": "- **Version**: 6.1.0\n- **Platform**: `Darwin ReBuke-Pro.local 15.4.0 Darwin Kernel Version 15.4.0: Fri Feb 26 22:08:05 PST 2016; root:xnu-3248.40.184~3/RELEASE_X86_64 x86_64` and `Linux f50a089ff63e 4.4.8-boot2docker #1 SMP Mon Apr 25 21:57:27 UTC 2016 x86_64 Linux`\n- **Subsystem**: require/modules\n\nThe following command works in v5/v4/v0.12/v0.10 with npm@2.15.5 or npm@3.8.9, works in v6 with npm@2.15.5, but fails in v6 with npm@3.8.9:\n\n``` console\n$ cd /\n$ sudo npm install express\n$ sudo node -p \"require('express')\"\n...\nmodule.js:440\n    throw err;\n    ^\nError: Cannot find module 'merge-descriptors'\n    at Function.Module._resolveFilename (module.js:438:15)\n    at Function.Module._load (module.js:386:25)\n    at Module.require (module.js:466:17)\n    at require (internal/module.js:20:19)\n    at Object.<anonymous> (/node_modules/express/lib/express.js:16:13)\n    at Module._compile (module.js:541:32)\n    at Object.Module._extensions..js (module.js:550:10)\n    at Module.load (module.js:456:32)\n    at tryModuleLoad (module.js:415:12)\n    at Function.Module._load (module.js:407:3)\n```\n\nThe following command works in v6 (and below):\n\n``` console\n$ sudo mkdir /app && cd /app && sudo npm install express && sudo node -p \"require('express')\"\n```\n\nYou can reproduce this fairly easily without messing up your filesystem if you have docker (can use `mhart/alpine-node` instead of `node` below if you want a smaller download):\n\n``` console\n$ docker run node:5 sh -c 'npm install express && node -p \"require(\\\"express\\\")\"'\n```\n\n(^works)\n\n``` console\n$ docker run node:6 sh -c 'npm install express && node -p \"require(\\\"express\\\")\"'\n```\n\n(^doesn't work)\n\n``` console\n$ docker run node:6 sh -c 'mkdir app && cd app && npm install express && node -p \"require(\\\"express\\\")\"'\n```\n\n(^works)\n\nIt's unclear to me whether it's the fact that it's being run from the root directory specifically that's causing it to fail â€“ or whether it's the presence of one of the other directories (eg, `bin`) that's getting in the way\n",
        "labels": "confirmed-bug",
        "id": 45450
    },
    {
        "title": "dgram: socket.send() crash when input array is modified",
        "body": "#4374 introduces a bug: it makes `socket.send()` accept an array but it's not resilient against that array getting modified afterwards:\n\n```\n$ node -e '\n  var a = [\"boom!\"], s = dgram.createSocket(\"udp4\");\n  s.send(a, 1234);\n  a.splice(0);\n'\nnode: ../deps/uv/src/unix/udp.c:390: uv__udp_send: Assertion `nbufs > 0' failed.\nAborted (core dumped)\n```\n\nA secondary issue with #4374 is that it penalizes the common case of passing in a buffer by always wrapping it in an array.\n\n/cc @mcollina @jasnell\n",
        "labels": "confirmed-bug",
        "id": 45451
    },
    {
        "title": "funky behavior inside Proxy handler function",
        "body": "- **Version**: 6.0.0\n- **Platform**: darwin\n- **Subsystem**: 10.11\n\n<img width=\"569\" alt=\"screen shot 2016-04-29 at 14 53 46\" src=\"https://cloud.githubusercontent.com/assets/415586/14909852/8b151a8a-0e1a-11e6-9b84-e54f88f69f93.png\">\n",
        "labels": "confirmed-bug",
        "id": 45452
    },
    {
        "title": "stdio buffered writes (chunked) issues & process.exit() truncation",
        "body": "If this is currently breaking your program, please use this **temporary fix**:\r\n\r\n``` js\r\n[process.stdout, process.stderr].forEach((s) => {\r\n  s && s.isTTY && s._handle && s._handle.setBlocking &&\r\n    s._handle.setBlocking(true)\r\n})\r\n```\r\n\r\n---\r\n\r\n<!--\r\nThanks for wanting to report an issue you've found in Node.js. Please fill in\r\nthe template below by replacing the html comments with an appropriate answer.\r\nIf unsure about something, just do as best as you're able.\r\n\r\nversion: usually output of `node -v`\r\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\r\nsubsystem:  optional -- if known please specify affected core module name.\r\n\r\nIt will be much easier for us to fix the issue if a test case that reproduces\r\nthe problem is provided. Ideally this test case should not have any external\r\ndependencies. We understand that it is not always possible to reduce your code\r\nto a small test case, but we would appreciate to have as\r\nmuch data as possible.\r\n\r\nThank you!\r\n-->\r\n- **Version**: v6, (likely all and backportable)\r\n- **Platform**: all\r\n- **Subsystem**: `process`\r\n\r\nAs noted in #6297 async stdio will not be flushed upon immediate `process.exit()`. This may lay open general deficiencies around C `exit()` from C++ functions not being properly unwound and is probably not just introduced by latest `libuv` updates. It should be considered to add flushing, providing graceful exit and/or improving unwinding C++ stacks.\r\n\r\ncc @jasnell, @kzc, @Qix-, @bnoordhuis  \r\n#### Issues\r\n\r\nDiscussion has been already taking place at several places, e.g. #6297, #6456, #6379\r\n#### Summaries of Proposals\r\n\r\n> proposals are not exclusive and could lead to semantically unrelated contributions.\r\n- aid with `process.stdout.flush()`\r\n- `process.setBlocking(true)`\r\n- `node --blocking-stdio`\r\n- `longjmp()` towards main at exit in C++\r\n- move parts of `process.exit()` / `process.reallyExit()` to new method `os.exit()`\r\n- golang `panic()`\\- or c++ `throw`-like stack unwinding\r\n#### Discussions by Author (with content)\r\n\r\n---\r\n\r\n@ChALkeR \r\n_I tried to discuss this some time ago at IRC, but postponed it for quite a long time. Also I started the discussion of this in #1741, but I would like to extract the more specific discussion to a separate issue._\r\n\r\nI could miss some details, but will try to give a quick overview here.\r\n\r\nSeveral issues here:\r\n1. Many calls to `console.log` (e.g. calling it in a loop) could chew up all the memory and die â€” #1741, #2970,Â #3171.\r\n2. `console.log` has different behavior while printing to a terminal and being redirected to a file. â€” https://github.com/nodejs/node/issues/1741#issuecomment-105333932.\r\n3. Output is sometimes truncated â€” #6297, there were other ones as far as I remember.\r\n4. The behaviour seems to differ across platforms.\r\n\r\nAs I understand it â€” the output has an implicit write buffer (as it's non-blocking) of unlimited size.\r\n\r\nOne approach to fixing this would be to:\r\n1. Introduce an explicit cyclic write buffer.\r\n2. Make writes to that cyclic buffer blocking.\r\n3. Make writes from the buffer to the actual output non blocking.\r\n4. When the cyclic buffer reaches it's maximum size (e.g. 10 MiB) â€” block further writes to the buffer until a corresponding part of it is freed.\r\n5. On (normal) exit, make sure the buffer is flushed.\r\n\r\nFor almost all cases, except for the ones that are currently broken, this would behave as a non-blocking buffer (because writes to the buffer are considerably faster than writes from the buffer to file/terminal).\r\n\r\nFor cases when the data is being piped to the output too quickly and when the output file/terminal does not manage to output it at the same rate â€” the write would turn into a blocking operation. It would also be blocking at the exit until all the data is written.\r\n## \r\n\r\nAnother approach would be to monitor (and limit) the size of data that is contained in the implicit buffer coming from the async queue, and make the operations block when that limit is reached.\r\n",
        "labels": "confirmed-bug",
        "id": 45453
    },
    {
        "title": "http.request option \"family: 6\" doesn't enable request over IPv6",
        "body": "- **Version**: 5.5\n- **Platform**: Ubuntu 14.04.1\n- **Subsystem**: http(s)\n\n<!-- Enter your issue details below this comment. -->\n\nSeems like `family` option does nothing with actual DNS resolve to ipv6.\nProblem is internal server should only use ipv6. So, instead of \n\n``` js\nhttps.get({\n    hostname: 'cloud-api.yandex.net',\n    path: '/v1/disk/resources?path=/',\n    family: 6,\n    port: 443,\n    protocol: 'https:'\n}, (res) => {\n    console.log(res);\n}).on('error', (e) => {\n  console.log(`Got error: ${e.message}`);    // Got error: connect EHOSTUNREACH 213.180.204.127:443\n});\n```\n\ni should write\n\n``` js\ndns.lookup('cloud-api.yandex.net', { family: 6 }, (err, addr, family) => {\n    https.get({\n        hostname: addr,\n        path: '/v1/disk/resources?path=/',\n        port: 443,\n        protocol: 'https:',\n        headers: { host: 'cloud-api.yandex.net' }\n    }, (res) => {\n        console.log(res);\n    }).on('error', (e) => {\n      console.log(`Got error: ${e.message}`);\n    });\n});\n```\n",
        "labels": "confirmed-bug",
        "id": 45454
    },
    {
        "title": "`assert.deepEqual` loops forever with circular refs",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n\n**Version**: `v4.4.3`\n\n**Platform**: `Linux 3.13.0-24-generic #47-Ubuntu SMP Fri May 2 23:30:00 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux`\n\n<!-- Enter your issue details below this comment. -->\n\n**Code**:\n\n``` js\nvar assert = require('assert');\n\nvar b = {};\nb.b = b;\n\nvar c = {};\nc.b = c;\n\nassert.deepEqual(b, c);\n```\n\n**Expected**: no exceptions.\n\n**Actual**: `RangeError: Maximum call stack size exceeded`\n\n**See also**:\n- https://github.com/nodejs/node-v0.x-archive/issues/207\n- https://github.com/nodejs/node/blob/v4.4.3/test/parallel/test-assert.js#L369-L381\n- https://github.com/nodejs/node/blob/v4.4.3/test/parallel/test-assert.js#L387\n",
        "labels": "confirmed-bug",
        "id": 45455
    },
    {
        "title": "os.cpus() failing on lxc containers setting cpuset.cpus to less than the host cpu count",
        "body": "- **Version**: 4.4.3 and 5.10.1\n- **Platform**: Linux 3.19.0-42-generic #48~14.04.1-Ubuntu SMP Fri Dec 18 10:24:49 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux (inside an LXC container)\n- **Subsystem**: os\n\nWhen running inside an LXC container with cgroups setup to restrict cpuset.cpus to something less than the number of CPUs in the host machine (very common with cloud providers), accessing os.cpus() will give the following:\n\n```\nnode: ../deps/uv/src/unix/linux-core.c:746: read_times: Assertion `num == numcpus' failed.\nAborted\n```\n\nTo reproduce you will need to run node inside an LXC container with the appropriate cpuset.cpus setting. You can then reproduce with this command:\n\n```\nnode -e \"var cpuCount = require('os').cpus().length;\"\n```\n\nBecause it triggers an assertion failure with an an abort it can't be caught in a try/catch in JavaScript and there really isn't a way to know if it will fail prior to calling it. A common use case for this would be getting the CPU count to use with the _cluster_ module to determine how many instances to run.\n\nWhile it may not be possible to address the underlying issue it would be helpful it if failed in a way that could be caught in a try/catch so code could be written to use sensible defaults or an alternative method in the event of failure.\n",
        "labels": "confirmed-bug",
        "id": 45456
    },
    {
        "title": "path (extname, parse) cannot handle extension correctly for directory",
        "body": "- **Version**: v5.10.1\n- **Platform**: Darwin Kernel Version 15.3.0\n- **Subsystem**: path\n\nOn OS X and Linux its perfectly legal to use dot '.' in directory name.\nCurrently path.extname and path.parse handle `.` in directory name as a file extension.\n\ne.g.\n\n```\next.extname('/Users/Bob.Dev')\n> '.Dev'\n```\n\n```\next.parse('/Users/John.Smith')\n> { root: '/',\n  dir: '/Users',\n  base: 'Bob.Dev',\n  ext: '.Dev',\n  name: 'Bob' }\n```\n\nI understand that `path` don't do any validation. But this behavior is confusing an error prone.\n",
        "labels": "confirmed-bug",
        "id": 45457
    },
    {
        "title": "module resolution can fail with trailing slash",
        "body": "<!--\nThanks for wanting to report an issue you've found in Node.js. Please fill in\nthe template below by replacing the html comments with an appropriate answer.\nIf unsure about something, just do as best as you're able.\n\nversion: usually output of `node -v`\nplatform:  either `uname -a` output, or if Windows, version and 32 or 64-bit.\nsubsystem:  optional -- if known please specify affected core module name.\n\nIt will be much easier for us to fix the issue if a test case that reproduces\nthe problem is provided. Ideally this test case should not have any external\ndependencies. We understand that it is not always possible to reduce your code\nto a small test case, but we would appreciate to have as\nmuch data as possible.\n\nThank you!\n-->\n- **Version**: 6.0.0-rc.2 / master\n- **Platform**: Linux 4.5.0-302.fc24.x86_64 #1 SMP Wed Mar 30 15:41:34 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**: module\n\n<!-- Enter your issue details below this comment. -->\n\nI discovered this bug while trying to run [pm2](https://github.com/Unitech/pm2) with v6.0.0-rc.2.\n\nTo repro, create the following directory structure:\n\n```\ntest\ntest/test.js\ntest/node_modules/a/package.json\n```\n\ntest/test.js:\n\n``` js\nrequire('a/');\n```\n\ntest/node_modules/a/package.json:\n\n``` json\n{\n  \"main\": \"doesnotexist\"\n}\n```\n\nThen execute `test/test.js`.\n\nResult with v5.10.1:\n\n```\nmodule.js:341\n    throw err;\n    ^\n\nError: Cannot find module 'a/'\n    at Function.Module._resolveFilename (module.js:339:15)\n    at Function.Module._load (module.js:290:25)\n    at Module.require (module.js:367:17)\n    at require (internal/module.js:16:19)\n    at Object.<anonymous> (/home/mzasso/test/test.js:1:63)\n```\n\nResult with v6.0.0-rc.2 / master:\n\n```\nmodule.js:128\n  for (var i = 0; i < exts.length; i++) {\n                          ^\n\nTypeError: Cannot read property 'length' of undefined\n    at tryExtensions (module.js:128:27)\n    at tryPackage (module.js:107:10)\n    at Function.Module._findPath (module.js:182:18)\n    at Function.Module._resolveFilename (module.js:434:25)\n    at Function.Module._load (module.js:384:25)\n    at Module.require (module.js:464:17)\n    at require (internal/module.js:16:19)\n    at Object.<anonymous> (/home/mzasso/test/test.js:1:63)\n```\n\nI'm working on a fix right now.\n",
        "labels": "confirmed-bug",
        "id": 45458
    },
    {
        "title": "Thrown readable stream error while uncorking",
        "body": "- **Version**: 4.4.1 (currently upgrading to 4.4.2 to see what's good)\n- **Platform**: Linux ip-10-90-38-23 3.10.0-123.8.1.el7.x86_64 #1 SMP Mon Sep 22 19:06:58 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n- **Subsystem**: _stream_writable.js\n\nI have some production services that are throwing a pretty crazy error:\n\n```\nTypeError: Cannot set property 'entry' of null\n    at clearBuffer (_stream_writable.js:379:18)\n    at Socket.Writable.uncork (_stream_writable.js:238:7)\n    at RedisClient.uncork (/cn/runtime/epi-services/nodejs/releases/current/node_modules/@condenast/tsugu-service/node_modules/redis/index.js:361:25)\n    at Multi.exec_transaction (/cn/runtime/epi-services/nodejs/releases/current/node_modules/@condenast/tsugu-service/node_modules/redis/index.js:1171:18)\n```\n\nFor some background: We're using redis as a caching layer, and this code is getting triggered while writing to redis with its 'multi' helper. We're using v2.4.2 of the redis module but I'm gonna upgrade to 2.5.3 just in case it helps.\n\nAs far as I can tell, what's happening here is that the redis client [creates a net stream](https://github.com/NodeRedis/node_redis/blob/v.2.4.2/index.js#L108-L112) and at various points in time [might call uncork on it, including inside the multi exec handler](https://github.com/NodeRedis/node_redis/blob/v.2.4.2/index.js#L1280). For some reason, only sometimes, when this happens, [trying to clear the buffer throws because state.corkedRequestsFree is null](https://github.com/nodejs/node/blob/5368455fdafc097880a8b7269187255a0bcd9801/lib/_stream_writable.js#L394).\n\nI did look at net and Duplex code paths, as well as the redis code, and didn't see anything touching internal stream state, but maybe I missed something?\n\nUnfortunately, I don't have a reproducing case beyond the production code. I tried triggering this with a naive fuzzer on a writable stream, no dice.\n\n@mcollina tagging you because we talked about this on irc a little bit, and because [you have the git blame for CorkedRequest](https://github.com/nodejs/node/commit/89aeab901ac9e34c79be3854f1aa41f2a4fb6888).\n\nThanks!\n\n**EDIT:** Also created [an issue on the redis project](https://github.com/NodeRedis/node_redis/issues/1033) just in case\n",
        "labels": "confirmed-bug",
        "id": 45459
    },
    {
        "title": "TCP socket emitted 'end' event after 'error' event",
        "body": "- **Version**: observed on v0.12, v4, and v5.  Did not observe on v0.10. (details below)\n- **Platform**: observed on both illumos and OS X Mountain Lion, both 32-bit and 64-bit (details below)\n- **Subsystem**: net\n\nAlthough it's not technically documented, a lot of code assumes that once a stream emits an 'error' event, it will not subsequently emit 'data' or 'end' events.  This is pretty much necessary, because otherwise it's impossible for a stream consumer to know when a stream has come to rest and will emit no more events.  I've reproduced a case where Node reliably emits an 'end' event after an 'error' event, which violates the expectations of code that assumes a stream has come to rest after 'error'.\n\nTo be really precise about where I tested it:\n\nWorks as expected on v0.10 (perhaps only because the 'end' event is emitted first):\n- illumos: v0.10.43 (both 32-bit and 64-bit)\n- OS X Mountain Lion: v0.10.28 (64-bit)\n\nDoes not work as expected on v0.12 and later:\n- illumos: v0.12.12, v4.4.0, v5.9.0 (both 32-bit and 64-bit)\n- OS X Mountain Lion: v0.12.2, v4.4.2, v5.10.0 (64-bit)\n\nHere's a test case that's commented with what it's doing.  I've tried to simplify it as much as possible, but since it's a race condition, it's tricky to get the timing just right.\n\n``` javascript\n/*\n * test-stream.js: demonstrates a case where a Node stream can see an 'end'\n * event after an 'error' event.\n *\n * This test case works as follows:\n *\n *      (1) Set up a TCP server socket and connect to it using a TCP client.\n *          Server: set up listeners for 'end' and 'error'.\n *          Client: set up listener for 'error'.\n *\n *      (2) Client: write 65536 bytes of data.\n *\n *      (3) Pause one second.  Behind the scenes, Node will detect that the\n *          server's socket has become readable and read all 65536 bytes.  These\n *          will be buffered in JavaScript.\n *\n *      (4) Server: read 65535 bytes of data from the Socket.  There will be\n *          one byte left buffered on the Socket in JavaScript.\n *          Client: destroy the socket.  This will send a FIN to the server.\n *\n *      (5) Asynchronously (via setImmediate):\n *          Server: read 1 byte of data from the Socket.  This will trigger Node\n *          to read from the underlying socket again, where it will read 0\n *          bytes, signifying the end of the stream.\n *\n *          Server: write data to the socket.  Since the socket is now\n *          disconnected, eventually these writes will report EPIPE/SIGPIPE.\n *          This generally happens synchronously with respect to the write()\n *          call, but the error will be emitted asynchronously.\n *\n *      (6) Asynchronously (via setImmediate):\n *          Server: read another byte from the socket.  At this point, we're\n *          reading past end-of-stream, and Node will schedule an 'end' event to\n *          be emitted, but an 'error' event has already been scheduled as well,\n *          so we'll see 'error' and then 'end', which should be invalid.\n */\n\nvar mod_net = require('net');\nvar mod_os = require('os');\n\n/* IP address and port used for this test case. */\nvar ip = '127.0.0.1';\nvar port = 16404;\n\n/* We'll use this buffer as a chunk of data. */\nvar bufsz = 64 * 1024;\nvar buf;\n\n/* State for this test */\nvar server;     /* server's listening socket */\nvar ssock;      /* server's connection socket */\nvar csock;      /* client socket */\nvar end = false;    /* server has seen \"end\" on its connection socket */\nvar error = false;  /* server has seen \"error\" on its connection socket */\n\nfunction main()\n{\n    console.log('versions:',\n        process.version, process.arch, mod_os.platform());\n\n    buf = new Buffer(bufsz);\n    buf.fill(0);\n\n    /*\n     * (1) Set up client and server.\n     */\n    server = mod_net.createServer({ 'allowHalfOpen': true });\n    server.on('connection', function (s) {\n        console.log('server: client connected');\n        ssock = s;\n\n        ssock.on('end', function () {\n            console.log('server: saw \"end\" on client socket');\n            if (error) {\n                console.log('reproduced issue!');\n                process.abort();\n            }\n\n            end = true;\n        });\n\n        ssock.on('error', function (err) {\n            console.log('server: saw \"error\" on client socket', err);\n            if (error || end) {\n                console.log('bailing out after server error');\n                process.exit(0);\n            }\n\n            // ssock.read(1);\n            error = true;\n        });\n\n        /*\n         * (2) Client writes data.\n         */\n        csock.write(buf);\n\n        /*\n         * (3) Pause until the server sees that data.\n         */\n        ssock.once('readable', triggerIssue);\n    });\n\n    server.listen(port, function () {\n        console.log('server: listening');\n\n        csock = mod_net.createConnection(port, ip);\n        csock.on('connect', function () {\n            console.log('client: connected');\n        });\n\n        csock.on('end', function () {\n            console.log('client: saw \"end\" on server socket');\n        });\n    });\n}\n\nfunction triggerIssue()\n{\n    console.log('triggering issue by destroying client socket');\n\n    /*\n     * (4) Read _most_ of the data from the socket and have the client\n     * destroy the socket.\n     */\n    ssock.read(bufsz - 1);\n    csock.destroy();\n    setImmediate(function () {\n        /*\n         * (5) Read 1 byte of data from the socket and write data to it.\n         */\n        ssock.read(1);\n        ssock.write(buf);\n        ssock.write(buf);\n        setImmediate(function () {\n            /*\n             * (6) Read one more byte.\n             */\n            ssock.read(1);\n        });\n    });\n}\n\nmain();\n```\n\nThe detailed output for each test I ran is here:\nhttps://gist.github.com/davepacheco/84d450d2c25f6212a99a984a8f089b4c\n",
        "labels": "confirmed-bug",
        "id": 45460
    },
    {
        "title": "pasting tab-indented code into the repl wrongly triggers autocomplete",
        "body": "If you run node and then paste some script that contains tabs for indentation then node will exit with an exception:\n\n```\nfunction test(){\n    a();\n    a();\n}\n```\n\nmake sure that this piece contains tabs for indentation and paste it into node interactive shell. On tab char it will print lots of bs suggestions and then at the end:\n\n```\n> function test(){\n...\n...TONNES OF POINTLESS HINTS...\n... a();\n... repl.js:282\n    top.outputStream.write((e.stack || e) + '\\n');\n       ^\n\nTypeError: Cannot read property 'outputStream' of undefined\n    at Domain.<anonymous> (repl.js:282:8)\n    at emitOne (events.js:77:13)\n    at Domain.emit (events.js:169:7)\n    at emitError (domain.js:66:24)\n    at Domain.errorHandler [as _errorHandler] (domain.js:110:18)\n    at process._fatalException (node.js:216:33)\n```\n\nSurprisingly, if you have only one line inside test function above, then it doesn't throw. Also, on each tab node will print huge pile of suggestions. It would be nice if it could detect that extra chars follow the tab immediately and avoid showing suggestions. I get identical behavior with nodev4 on win, and nodev5 on ubuntu.\n- **Version**: v4.3.1 on win, or v5.9.1 on ubuntu\n- **Platform**: win32, ubuntu-64\n",
        "labels": "confirmed-bug",
        "id": 45461
    },
    {
        "title": "assert.deepEqual is broken?",
        "body": "- Node: v5.9.1\n- Platform: Darwin 15.4.0 Darwin Kernel Version 15.4.0: Fri Feb 26 22:08:05 PST 2016; root:xnu-3248.40.184~3/RELEASE_X86_64 x86_64\n\n**Problem:**\nDoes not throw an exception, when comparing two Float32Array which have the small different values.\n\n``` js\nassert.deepEqual(new Float32Array([ 0 ]), new Float32Array([ 0.1 ]));\n// undefined (This does not throw an AssertionError?)\n```\n\nThis works as expected.\n\n``` js\nassert.deepEqual(new Float32Array([ 0 ]), new Float32Array([ 1 ]));\n// AssertionError: Float32Array { '0': 0 } deepEqual Float32Array { '0': 1 }\n//    at repl:1:8\n//    at REPLServer.defaultEval (repl.js:260:27)\n//    at bound (domain.js:287:14)\n//    at REPLServer.runBound [as eval] (domain.js:300:12)\n//    at REPLServer.<anonymous> (repl.js:429:12)\n//    at emitOne (events.js:95:20)\n//    at REPLServer.emit (events.js:182:7)\n//    at REPLServer.Interface._onLine (readline.js:211:10)\n//    at REPLServer.Interface._line (readline.js:550:8)\n//    at REPLServer.Interface._ttyWrite (readline.js:827:14)\n```\n",
        "labels": "confirmed-bug",
        "id": 45462
    },
    {
        "title": "Segmentation fault in node v5.*",
        "body": "Hello\nwhile fiddling with the toy js parser I have made, i came across weird 139 (that is, Segmentation fault) errors which are driving me nuts. I've pruned every unnecessary part of the parser and looks like i have been able to isolate the error-causing case. i have very little experience using debugging tools to delve in this issue all by myself; i would hence be glad if someone could help me find out what is going on . \n\nthe faulty case: https://github.com/icefapper/lubejs\nmeminfo: https://gist.github.com/icefapper/3081ce0e4f1e8bb17314\nmy sys is : Linux 3.13.0-37-generic #64-Ubuntu SMP Mon Sep 22 21:28:38 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux (specifically it is LM 17.1)\ncpuinfo: https://gist.github.com/icefapper/5dc357ab7d751a7ceb86\n\ni have been experiencing it on 5.6.0 and up (i.e, even with the latest stable 5.9.\\* which i even built from source)\n\nThanks a lot reading this far, and I hope you could reproduce the error case. Simply run the \"run.sh\" thing 40-times or so, and the read the \"lubelean.log\"; please note, though, that the \"lubelean.log\" already contains the logs I received by running 'run.sh' which means if you need your own logs, you must delete it and _then_ run 'run.sh'. \n",
        "labels": "confirmed-bug",
        "id": 45463
    },
    {
        "title": "Memory leaks in loops with Promises and generators",
        "body": "Sample code in babel:\n\n``` js\n\"use strict\"\n\nfunction y(ms) {\n  return new Promise((res, rej) => {\n      res();\n  })\n}\n\nasync function x() {\n  while (true) {\n    await y();\n  }\n}\n\n\nx().catch ((err) => {\n  console.log(err);\n})\n```\n\nCompiled code for nodejs:\n\n``` js\nlet y = (() => {\n  var ref = _asyncToGenerator(function* () {\n    //nope\n  });\n\n  return function y() {\n    return ref.apply(this, arguments);\n  };\n})();\n\nlet x = (() => {\n  var ref = _asyncToGenerator(function* () {\n    while (true) {\n      yield y();\n    }\n  });\n\n  return function x() {\n    return ref.apply(this, arguments);\n  };\n})();\n\nfunction _asyncToGenerator(fn) { return function () { var gen = fn.apply(this, arguments); return new Promise(function (resolve, reject) { function step(key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { return Promise.resolve(value).then(function (value) { return step(\"next\", value); }, function (err) { return step(\"throw\", err); }); } } return step(\"next\"); }); }; }\n\nx().catch(err => {\n  console.log(err);\n});\n```\n\nThat's work perfect in browser Chromium 48, but work with memory leaks in nodejs (tested in 4.4.0 lts, 5.3.0, 5.9.0).\nIf I insert `gc()` after `yield y();` and run nodejs with `--expose-gc` -- that works without memory leaks.\n- **Version**: 4.4.0, 5.3.0, 5.9.0\n- **Platform**:\n  Linux unassigned 3.16.0-4-amd64 #1 SMP Debian 3.16.7-ckt20-1+deb8u2 (2016-01-02) x86_64 GNU/Linux\n  and \n  Linux work 3.13.0-24-generic #47-Ubuntu SMP Fri May 2 23:30:00 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\n  64-bit_\n",
        "labels": "confirmed-bug",
        "id": 45464
    },
    {
        "title": "setInterval where callback \"work\" time is more then interval, will sleep for work time, not zero ",
        "body": "- **Version**: v5.9.0 (but any version of lib/timers.js) I have seen so far\n- **Platform**:Darwin imac15.local 15.3.0 Darwin Kernel Version 15.3.0\n- **Subsystem**: timer\n\nWhen setting `setInterval` with a relatively short interval, and a callback that (sometimes) takes longer on cpu then that short interval, will delay the next callback by time it was on cpu, not 0 or interval.\n\nBelow is a testcase from what could be a gameloop that tries to do work every 100 millis exactly. When the simulated work is more then 1 millis, it will run into the problem above.\n\nThe scope of the bug is slightly more broad: any setInterval or setTimer with a certain timeout T, if we are currently processing timers of that T, and total processing of all timers of time T takes more time then T, the system will go into this state, where it will postpone for exactly CPU time. Resulting in a system that when under load uses _exactly_ 50% cpu. Moreover, newly scheduled timers might get processed in the same loop, which violates the (perhaps implicit) contract that newly scheduled timers are only processed in the next io loop.\n\nRelated, this way of handling repeated timers means the actual interval is T + average cpu time of all timers of T.\n\n```\nvar MILLIS = 100\n\nvar list = []\nvar last = +new Date\nvar sleepStart = +new Date\n\nfunction work() {\n    var start = +new Date\n    if (start - last < MILLIS) return\n    last = start - ((start - last) - MILLIS)\n\n    list.length = 0\n    for (var i = 0; i < 800000; i++) {\n        list.push(String(i))\n    }\n    var end = +new Date\n    var sleeptime = start - sleepStart\n    var worktime = end - start\n    var total = sleeptime + worktime\n    console.log(\"worked for:\", worktime, \"millis\", \"slept for:\", sleeptime, \"total:\", total, (total > MILLIS && sleeptime > MILLIS - worktime + 5? \"oeps\":\"\"))\n    sleepStart = end\n}\n\nsetInterval(work, 1)\n```\n\na preliminary fix, but still a problem, the `this.start(0, 0)`, or `this.start(msec - diff, 0)` have no relation with the actual current time, and `TimerWrap.now()` returns loop time, not wallclock time.\n\n```\ndiff --git a/lib/timers.js b/lib/timers.js\nindex 478a054..3b28aab 100644\n--- a/lib/timers.js\n+++ b/lib/timers.js\n@@ -166,6 +166,13 @@ function listOnTimeout() {\n   while (timer = L.peek(list)) {\n     diff = now - timer._idleStart;\n\n+    // Check if any new timers are sheduled after we started processing this list\n+    if (diff <= 0) {\n+      this.start(0, 0);\n+      debug('%d list break because next timer is from the future %d', msecs, diff);\n+      return;\n+    }\n+\n     // Check if this loop iteration is too early for the next timer.\n     // This happens if there are more timers scheduled for later in the list.\n     if (diff < msecs) {\n```\n",
        "labels": "confirmed-bug",
        "id": 45465
    },
    {
        "title": "vm: recent contextify changes cause segmentation fault in node v5.9",
        "body": "A recent change made to node_contextify.cc that was released in node 5.9.0 causes node to segfault.\n\nThe offending commit is this: https://github.com/nodejs/node/commit/bfff07b4dd4ccfdb652e29e94e89bebdb23141c7\n\nThe problem can be reproduced using the following test script:\n\n``` js\nvar vm = require('vm');\n\nfunction f() {\n  var sandbox = {};\n  vm.createContext(sandbox);\n\n  return function(script, ctx) {\n    var s = new vm.Script(script);\n    for(var p in ctx) { sandbox[p] = ctx[p]; };\n    var result = s.runInContext(sandbox);\n    console.log(result, sandbox);\n    for(var p in sandbox) { delete sandbox[p]; };\n  }\n}\n\nfor(var i=0; i<10000; i++) {\n  f()('x = 3', {x : 1});\n  f()('x = 4', {x : 2});\n}\n```\n\n``` sh\n$ node -v\nv5.9.0\n$ uname -a\nDarwin raymond-117.local 15.3.0 Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64\n```\n\ncc @ofrobots and @bnoordhuis \n",
        "labels": "confirmed-bug",
        "id": 45466
    },
    {
        "title": "SSL sockets may leak when keepalive is enabled",
        "body": "issue is in: lib/_http_agent.js\nThe issue is reproducible whenever the `ca` property is set globally in the agent and an https request is made with `https.request(ops)` where `ops` does not have the property `ca`\n\n_http_agent.js @ `Agent.prototype.createSocket`\nthe `options` are extended with the global `options` object which contains `ca`. In `getName` `ca` is used in the name generation of the hash.\n\nhowever _http_agent.js @ `Agent.prototype.addRequest`\nThe `options` (passed from the call `https.request(ops)` which don't have the property `ca`) are used to get a hashtag which is now different. The socket leaks and is closed when the timeout hits. Meanwhile a new socket is created for the request.\n",
        "labels": "confirmed-bug",
        "id": 45467
    },
    {
        "title": "Microtask queue is not flushed when promises are fulfilled in C++",
        "body": "Reproduction:\n\n``` C++\n#include <node.h>\n#include <uv.h>\n#include <unistd.h>\n\nstatic v8::Persistent<v8::Promise::Resolver> persistent;\n\nvoid run(uv_work_t* req) {\n  sleep(1);\n}\n\nvoid callback(uv_work_t* req, int i) {\n  v8::Isolate* isolate = v8::Isolate::GetCurrent();\n  v8::HandleScope scope(isolate);\n\n  v8::Local<v8::Promise::Resolver> local = v8::Local<v8::Promise::Resolver>::New(isolate, persistent);\n  local->Resolve(v8::Undefined(isolate));\n}\n\nvoid test(const v8::FunctionCallbackInfo<v8::Value>& args) {\n  v8::Isolate* isolate = args.GetIsolate();\n\n  if (persistent.IsEmpty()) {\n    persistent.Reset(isolate, v8::Promise::Resolver::New(isolate));\n\n    uv_work_t * req = (uv_work_t*) malloc(sizeof(uv_work_t));\n\n    uv_queue_work(uv_default_loop(), req, run, callback);\n  }\n\n  v8::Local<v8::Promise::Resolver> local = v8::Local<v8::Promise::Resolver>::New(isolate, persistent);\n\n  args.GetReturnValue().Set(local->GetPromise());\n}\n\nvoid init(v8::Local<v8::Object> exports) {\n  NODE_SET_METHOD(exports, \"test\", test);\n}\n\nNODE_MODULE(addon, init)\n```\n\n``` js\nvar r = require('./build/Release/addon.node');\n\nr.test().then(function() {\n  console.log('done');\n});\n\n\nsetTimeout(() => {}, 5000);\n```\n\n`done` should be printed after 1 seconds, but is printed after 5 seconds instead.\n",
        "labels": "confirmed-bug",
        "id": 45468
    },
    {
        "title": "relative module paths resolve differently in REPL.",
        "body": "- **Version**: v5.5.0\n- **Platform**: Darwin jdalton.local 15.3.0 Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64\n\n``` bash\nnpm init\n# <init a package>\nnpm i lodash --save\ntouch lodash.js\n```\n\nIn lodash.js\n\n``` js\nmodule.exports = {\n  'VERSION': 'should be me'\n};\n```\n\nNow in the REPL\n\n``` js\nconsole.log(require('./lodash').VERSION);\n// => 4.6.1 instead of 'should be me'\n```\n\nPut the same code in a file\n\n``` bash\ntouch foo.js\n```\n\nIn foo.js\n\n``` js\nconsole.log(require('./lodash').VERSION);\n```\n\nThen\n\n``` bash\nnode foo\n# logs 'should be me'\n```\n\nIt would work in the REPL if I changed the path from `'./lodash'` to `'./lodash.js'`.\n",
        "labels": "confirmed-bug",
        "id": 45469
    },
    {
        "title": "degrading performance after using child_process",
        "body": "After running a child process ( using exec or spawn ) I have found that the performance of my node.js application decreases by a factor of 10. Below is a contrived example and output.\n\n```\nvar exec = require('child_process').exec;\n\nfunction runExpensiveOperation(times) {\n  while(times > 0) {\n    console.time('expensiveOperation');\n    var str = 'lorem';\n    for ( var i=0;i< 10000000; i++) {\n      // string concatenation\n      str = str.length < 1000 ? str + str : '';\n      // math operation\n      i * i * i;\n    }\n    console.timeEnd('expensiveOperation');\n    times--;\n  }\n}\n\nconsole.log('PRE EXEC');\nrunExpensiveOperation(10);\nexec('echo \"hello\"');\nconsole.log('POST EXEC');\nrunExpensiveOperation(10);\n```\n\nOutput:\n\n```\nPRE EXEC\nexpensiveOperation: 66.458ms\nexpensiveOperation: 65.735ms\nexpensiveOperation: 69.237ms\nexpensiveOperation: 65.269ms\nexpensiveOperation: 69.133ms\nexpensiveOperation: 65.639ms\nexpensiveOperation: 67.944ms\nexpensiveOperation: 63.595ms\nexpensiveOperation: 64.153ms\nexpensiveOperation: 65.093ms\nPOST EXEC\nexpensiveOperation: 715.861ms\nexpensiveOperation: 739.671ms\nexpensiveOperation: 714.546ms\nexpensiveOperation: 714.845ms\nexpensiveOperation: 745.719ms\nexpensiveOperation: 743.240ms\nexpensiveOperation: 716.481ms\nexpensiveOperation: 732.916ms\nexpensiveOperation: 736.576ms\nexpensiveOperation: 742.416ms\n```\n\nIn addition, this problem only occurs if the string concatenation AND math operation are run in the expensiveOperation - if either are commented out then there is no issue.\n- **Version**: 5.8.0\n- **Platform**: Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64 ( Macbook Air OS X El Capitan )\n- **Subsystem**: child_process\n",
        "labels": "confirmed-bug",
        "id": 45470
    },
    {
        "title": "writeFloat* and writeDouble* do no longer throw range error when out of bounds",
        "body": "I'l let the code speak for itself.\n\n``` javascript\n\"use strict\";\n\nlet buffer;\n\nbuffer = new Buffer(8);\nbuffer.fill(1);\nconsole.log(buffer.writeFloatLE(0, 4), buffer, buffer.length);\n// Node.js v4.3.1: \"8 <Buffer 01 01 01 01 00 00 00 00> 8\"\n// Node.js v5.7.1: \"8 <Buffer 01 01 01 01 00 00 00 00> 8\"\n\nbuffer = new Buffer(8);\nbuffer.fill(1);\ntry {\n    console.log(buffer.writeFloatLE(0, 5), buffer, buffer.length);\n    // Node.js v5.7.1: \"9 <Buffer 01 01 01 01 01 00 00 00> 8\"\n} catch (error) {\n    console.log(error);\n    // Node.js v4.3.1: \"[RangeError: index out of range]\"\n}\n\nbuffer = new Buffer(16);\nbuffer.fill(1);\nconsole.log(buffer.writeDoubleLE(0, 8), buffer, buffer.length);\n// Node.js v4.3.1: \"16 <Buffer 01 01 01 01 01 01 01 01 00 00 00 00 00 00 00 00> 16\"\n// Node.js v5.7.1: \"16 <Buffer 01 01 01 01 01 01 01 01 00 00 00 00 00 00 00 00> 16\"\n\nbuffer = new Buffer(16);\nbuffer.fill(1);\ntry {\n    console.log(buffer.writeDoubleLE(0, 9), buffer, buffer.length);\n    // Node.js v5.7.1: \"17 <Buffer 01 01 01 01 01 01 01 01 01 00 00 00 00 00 00 00> 16\"\n} catch (error) {\n    console.log(error);\n    // Node.js v4.3.1: \"[RangeError: index out of range]\"\n}\n```\n\nSystem 1\n- **Version**: v4.3.1\n- **Platform**: Windows Server 2012 R2 64-bit\n- **Subsystem**: Buffer\n\nSystem 2\n- **Version**: v5.7.1\n- **Platform**: Windows 7 Pro SP1 64-bit\n- **Subsystem**: Buffer\n",
        "labels": "confirmed-bug",
        "id": 45471
    },
    {
        "title": "Node 5.7.1 path.normalize broken",
        "body": "The following sample works fine in **node v5.1.0** but is broken in **node v5.7.1**:\n\n**`path.normalize(\"/a/b/c/../../../x/y/z\")`**\n\nCorrect (node v5.1.0): `/x/y/z`\n**Broken (node v5.7.1): `/a/x/y/z`**\n\nNote this works fine if the first path contains more than 1 character (e.g. `\"/aa/b/c/../../../x/y/z\"`)\n",
        "labels": "confirmed-bug",
        "id": 45472
    },
    {
        "title": "Standalone blocks don't work in node REPL console ",
        "body": "Standalone blocks don't play well with the node console.\n\n``` javascript\n{ var x = 4; console.log(x); }\n```\n\nworks fine when put in a file and run, but when run in the console,\n\n```\nSyntaxError: Unexpected identifier\n    at Object.exports.createScript (vm.js:24:10)\n    at REPLServer.defaultEval (repl.js:137:25)\n    at bound (domain.js:250:14)\n    at REPLServer.runBound [as eval] (domain.js:263:12)\n    at REPLServer.<anonymous> (repl.js:393:12)\n    at emitOne (events.js:82:20)\n    at REPLServer.emit (events.js:169:7)\n    at REPLServer.Interface._onLine (readline.js:210:10)\n    at REPLServer.Interface._line (readline.js:549:8)\n    at REPLServer.Interface._ttyWrite (readline.js:826:14)\n```\n- **Version**: v4.1.1\n- **Platform**: `Linux matrix 3.13.0-79-generic #123-Ubuntu SMP Fri Feb 19 14:27:58 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux`\n",
        "labels": "confirmed-bug",
        "id": 45473
    },
    {
        "title": "path.relative parse wrong in windows",
        "body": "Node Version: 5.7.0\n\n``` js\nvar path = require('path');\nvar a = 'E:/WORKSPACE/GitHub/file-send/test/fixtures/name.d/';\nvar b = 'E:/WORKSPACE/GitHub/file-send/test/fixtures/name.dir/name.txt';\n\nconsole.log(path.relative(a, b));\n```\n\nresult:\n![qq 20160229181842](https://cloud.githubusercontent.com/assets/1730277/13391727/f5a6e2d6-df10-11e5-9d5a-2efce5bb3bdb.png)\n",
        "labels": "confirmed-bug",
        "id": 45474
    },
    {
        "title": "path.relative() wrong result in v5.7.0 Windows",
        "body": "Version: <= 5.6.0:\n\n```\n$ node\n> process.version\n'v5.6.0'\n> path.relative('C:\\\\git\\\\foo\\\\bootstrap-loader','C:\\\\git\\\\foo\\\\bootstrap')\n'..\\\\bootstrap'\n```\n\nVersion: 5.7.0\n\n```\n\n$ node\n> process.version\nprocess.version\n'v5.7.0'\n> path.relative('C:\\\\git\\\\foo\\\\bootstrap-loader','C:\\\\git\\\\foo\\\\bootstrap')\n'..'\n```\n\n'..' needs to be '..\\bootstrap'\n",
        "labels": "confirmed-bug",
        "id": 45475
    },
    {
        "title": "setTimeout() introduces artificial delay between ticks when doing synchronous work",
        "body": "_Affected Versions_: 0.11+\n\nThe issue came up during testing of [node-toobusy](https://github.com/STRML/node-toobusy/issues/13). I found that in newer Node versions, there seemed to be an artificial delay introduced _between_ setTimeout() calls if there is a significant amount of synchronous work in them. The delay seems to always equal the amount of work done, as if Node is measuring the time taken by the function and delaying it by that amount of time to keep the loop free.\n\nReproduction script:\n\n``` js\nfunction tightWork(duration) {\n  var start = Date.now();\n  while ((Date.now() - start) < duration) {\n    for (var i = 0; i < 1e5;) i++;\n  }\n}\n\nvar count = 0;\nvar last = Date.now();\n\nfunction load() {\n  if (count++ > 10) return;\n  // This measures the amount of time between setTimeout() being called,\n  // and it actually firing.\n  console.log('tick delta:', (Date.now() - last));\n  tightWork(100);\n  last = Date.now();\n  setTimeout(load, 0);\n}\n\nload();\n```\n\nOutput (similar on 0.11.x and above):\n\n``` bash\n$ node -v\nv5.6.0\n$ node index\ntick delta: 13\ntick delta: 1\ntick delta: 105\ntick delta: 104\ntick delta: 105\ntick delta: 105\ntick delta: 105\ntick delta: 104\ntick delta: 105\ntick delta: 105\ntick delta: 105\n```\n\nYet this doesn't happen on 0.10:\n\n``` bash\n$ node -v\nv0.10.41\n$ node index\ntick delta: 8\ntick delta: 2\ntick delta: 1\ntick delta: 1\ntick delta: 1\ntick delta: 1\ntick delta: 1\ntick delta: 1\ntick delta: 1\ntick delta: 1\ntick delta: 1\n```\n",
        "labels": "confirmed-bug",
        "id": 45476
    },
    {
        "title": "dgram: socket.send without address fails with weird error on 5.7",
        "body": "On node 4.x and node <5.7 this worked\n\n``` js\nvar dgram = require('dgram')\nvar socket = dgram.createSocket('udp4')\n\nsocket.send(Buffer('hi'), 0, 2, 10000) // works on 4.x <5.7\n```\n\nWith node 5.7 this fails with\n\n```\nRangeError: Port should be > 0 and < 65536\n```\n\nThe dgram docs on both 4.x and 5.x say\n\n```\n If the address is not specified or is an empty string, '0.0.0.0' or '::0' will be used instead\n```\n- **Version**: v5.7.0\n- **Platform**: Darwin brunhilde.local 15.2.0 Darwin Kernel Version 15.2.0: Fri Nov 13 19:56:56 PST 2015; root:xnu-3248.20.55~2/RELEASE_X86_64 x86_64\n",
        "labels": "confirmed-bug",
        "id": 45477
    },
    {
        "title": "url.parse result differences in 5.7.x to 5.6.x",
        "body": "- **Version**: `v5.7.0`\n- **Platform**: Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64\n\nI updated to Node 5.7.0 today, which results in my Cordova build breaking due to a change in the output of `url.parse`.\n\nIn Node 5.5.0 the output of parsing `https://*` was the following:\n\n```\n{ protocol: 'https:',\nÂ Â slashes: true,\nÂ Â auth: null,\nÂ Â host: '',\nÂ Â port: null,\nÂ Â hostname: '',\nÂ Â hash: null,\nÂ Â search: null,\nÂ Â query: null,\nÂ Â pathname: '/*',\nÂ Â path: '/*',\nÂ Â href: 'https:///*' }\n```\n\nHowever this changed when updating to 5.7.0:\n\n```\nUrl {\n  protocol: 'https:',\n  slashes: true,\n  auth: null,\n  host: '',\n  port: null,\n  hostname: '',\n  hash: null,\n  search: null,\n  query: null,\n  pathname: null,\n  path: null,\n  href: 'https://' }\n```\n\nThe `pathname` being `null` now broke the Cordova CLI library. Was this change intended to be breaking?\n",
        "labels": "confirmed-bug",
        "id": 45478
    },
    {
        "title": "keypress events not working in windows cmd.exe & powershell",
        "body": "- **Version**: 5.7.0\n- **Platform**: windows 10 x64\n- **Subsystem**: streams?\n\nI make commits using [cz-cli](https://github.com/commitizen/cz-cli) (it uses arrow keys for selection). Just updated node to 5.7.0 (from 5.6.0) on windows 10 and now arrow keys (**upd** also Ctrl+C and maybe something other) not working in command line. Pressing arrow keys does nothing (like keypress event doesn't happen).\n\nGuess it related https://github.com/nodejs/node/issues/2996.\n",
        "labels": "confirmed-bug",
        "id": 45479
    },
    {
        "title": "path.relative() result changed in v5.7.0",
        "body": "- **Version**: v5.7.0\n- **Platform**: Darwin pitti.local 15.3.0 Darwin Kernel Version 15.3.0: Thu Dec 10 18:40:58 PST 2015; root:xnu-3248.30.4~1/RELEASE_X86_64 x86_64\n- **Subsystem**: path\n\nHere is the output:\n\n```\npitti:~ master$ node -v\nv5.6.0\npitti:~ master$ node\n> path.relative('/Users/a/web/b/test/mails', '/Users/a/web/b')\n'../..'\n> \n(To exit, press ^C again or type .exit)\n> \npitti:~ master$ node -v\nv5.7.0\npitti:~ master$ node\n> path.relative('/Users/a/web/b/test/mails', '/Users/a/web/b')\n'../../../b'\n> \n```\n",
        "labels": "confirmed-bug",
        "id": 45480
    },
    {
        "title": "Error: EPERM: operation not permitted, open 'C:\\Users\\username\\.node_repl_history'",
        "body": "On Windows 7 for node 5.5.0 if \".node_repl_history\" has hidden attribute, node fails to open.\n",
        "labels": "confirmed-bug",
        "id": 45481
    },
    {
        "title": "stream: why use string_decoder in Readable?",
        "body": "I'm a little confused about the use of `string_decoder` in Readable [(Line 140).](https://github.com/nodejs/node/blob/master/lib/_stream_readable.js#L140)\n\nI thought it was meant to support `push`ing incomplete UTF-8 character sequence, but the following example failed:\n\n``` js\nconst stream = require('stream')\nconst euro = new Buffer([0xE2, 0x82, 0xAC])\nconst cent = new Buffer([0xC2, 0xA2])\nconst source = Buffer.concat([euro, cent])\n\nconst readable = stream.Readable({ encoding: 'utf8' })\nreadable.push(source.slice(0, 2))\nreadable.push(source.slice(2, 4))\nreadable.push(source.slice(4, 6))\nreadable.push(null)\n\nreadable.on('data', data => console.log(data))\n\n```\n\nNo output.\n\nI was expecting the output to be the same with\n\n``` js\nconst stream = require('stream')\nconst euro = new Buffer([0xE2, 0x82, 0xAC])\nconst cent = new Buffer([0xC2, 0xA2])\nconst source = Buffer.concat([euro, cent])\n\nconst readable = stream.Readable({ encoding: 'utf8' })\nreadable.push(source.slice(0, 3))\nreadable.push(source.slice(3, 5))\nreadable.push(null)\n\nreadable.on('data', data => console.log(data))\n// â‚¬\n// Â¢\n\n```\n\nIt seems that I have to `push` complete character sequence, or else `chunk` returned by the decoder in [Line 140](https://github.com/nodejs/node/blob/master/lib/_stream_readable.js#L140) will be empty (`''`).\nIf the stream is working in the flowing mode, every time `read()` try to get that empty string out, `howMuchToRead` will return `0` and `fromList` is not called, and data stops flowing.\n\nDid I misunderstand the purpose of using `string_decoder` here?\n",
        "labels": "confirmed-bug",
        "id": 45482
    },
    {
        "title": "repl cannot handle single quote in regex, when within a function",
        "body": "I'm getting a 'SyntaxError: Unexpected end of input' when I try to enter the following in the repl\n\n```\nvar someFunction = function(s) {\n    s = s.replace(/'/g, '');\n}\n```\n\nHowever, `s = s.replace(/'/g, '')` by itself on a new line is OK. Am I doing something wrong?\n",
        "labels": "confirmed-bug",
        "id": 45483
    },
    {
        "title": "TLS fails reading self-signed certificate on node 4.2.5+",
        "body": "I'm having an issue with ssl certificate validation using the `tls` module. The server is started with:\n\n```\ntls.createServer({\n        pfx: fs.readFileSync(config.certFile),\n        passphrase: config.keyPass,\n        requestCert: true, \n        rejectUnauthorized: false \n    }, ...);\n```\n\nThe client:\n\n```\ntls.connect({\n    port: config.port,\n    host:config.host,\n    pfx: fs.readFileSync(config.cert),\n    passphrase: config.pass,\n    rejectUnauthorized: false\n});\n```\n\nMy issue is that I get `tlsSocket.authorizationError` SELF_SIGNED_CERT_IN_CHAIN on v4.2.5+ but not on older versions. Here's my output on a Windows machine, but the same happens on an Ubuntu server.\n\n```\n>nodist 4.2.5\n>node --version\nv4.2.5\n\n>node server.js\nserver started:\nauth->SELF_SIGNED_CERT_IN_CHAIN\n\n>nodist 4.2.4\nnodev4.2.4\n\n>node server.js\nserver started:\nauth->null\n```\n\nThe `auth->` line is printed to console with the `tlsSocket.authorizationError` parameter when a client connects. In the case of a successful connect this field is `null`. \nTested down to 0.12.9, all versions read the certificate without issues.\n",
        "labels": "confirmed-bug",
        "id": 45484
    },
    {
        "title": "Node crashes when a big sparse array is given to console.log (might cause DoS)",
        "body": "```\nvar a=[] \na[1000000000]=1 \nconsole.log(a) \n```\n\nThis ends up with a `FATAL ERROR: process out of memory`. Wouldn't expect this...\n\nNote that many applications use `console.log` for logging their stuff, and this can lead to a DoS attack: for example, when an user-specified JSON `{\"1000000000\":\"a\"}` is merged with some pre-existing array and then printed on console. Having an upper bound on printed `Array` items in `console.log` seems like an easy fix for this.\n\nI originally reported this to `security@nodejs.org`, but I got this response:\n\n> I don't think we consider this a security issue (it's known and documented) but it's arguably a quality-of-implementation issue. If you'd like to pursue this further, can you file an issue (...)?\n\nSo I'm opening an issue :smiley: \n\nBtw, I can't see this documented anywhere in the [console docs](https://nodejs.org/api/console.html), but maybe I'm missing something?\n",
        "labels": "confirmed-bug",
        "id": 45485
    },
    {
        "title": "crypto: State not recovered after an exception is thrown",
        "body": "While upgrading one of our applications to Node.js 4.2.6 (from 4.2.3) I bumped into an issue with the crypto module. In the tests, we supply an invalid key into the `createCipheriv` function and it barks as expected.\n\nHowever, when running the same code again later in the tests, this time with a correct key, it still doesn't work and an exception is thrown. It weird thing is that the error comes from a different crypto function (`createHash`). I assume some internal state is not being cleared.\n\nThe code works on Node.js 4.2.3 and fails on 4.2.4-6. It's still entirely possible that we're doing something wrong. Any suggestions are welcomed.\n\nhttps://gist.github.com/jiripospisil/70450ba715a004a11623\n",
        "labels": "confirmed-bug",
        "id": 45486
    },
    {
        "title": "SNICallback doesn't appear to work with `tls.createSecurePair()`",
        "body": "Test case: https://gist.github.com/adammw/cf4327506d4293e69014\n\nTesting hitting the server with cURL:\n\n```\ncurl -v --resolve www.example.com:4443:127.0.0.1 https://www.example.com:4443/\n```\n\nDocs say that there should be two arguments passed to SNICallback, the servername and the callback to call with the secure context. The second argument doesn't appear to be passed through when the TLS connection is created as a stream with tls.createSecurePair().\n\nI get the error:\n\n```\nTypeError: cb is not a function\n    at Object.tls.createSecurePair.SNICallback [as onselect]\n```\n\nI note that when removing the callback argument I get an OpenSSL error in my terminal:\n\n```\nError: 140735169483536:error:1408A0C1:SSL routines:ssl3_get_client_hello:no shared cipher:../deps/openssl/openssl/ssl/s3_srvr.c:1411:\n```\n\nPotentially related PR: https://github.com/nodejs/node/pull/2441 /cc @socketpair\n",
        "labels": "confirmed-bug",
        "id": 45487
    },
    {
        "title": "DNS lookupService fails with internal C error when given a string port number.",
        "body": "The DNS module's `lookupService` method throws an unwrapped C error when given a string for a port number. This isn't ideal; preferably a TypeError would be thrown instead, or the function would just parse the string to an integer.\n\nThe following error messages is given for the failing test cases shown below.\n\n```\nnode: ../src/cares_wrap.cc:1098: void node::cares_wrap::GetNameInfo(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `args[2]->IsUint32()' failed.\nAborted\n```\n\nIf I'm missing any important information, please tell me and I'll update this issue.\n### Environment:\n- Node v5.4.1\n- Npm 3.5.3\n- Linux 4.2.0-23-generic (Ubuntu)\n### Test-Case:\n#### Failing Test Cases:\n\n```\nrequire('dns').lookupService('0.0.0.0', '0', (err, hostname, service) => {\n\n})\n\nrequire('dns').lookupService('127.0.0.1', '443', (err, hostname, service) => {\n\n})\n\n```\n#### Control Test Cases:\n\nBoth these cases behave normally; they don't throw a C error.\n\n```\nrequire('dns').lookupService('0.0.0.0', 0, (err, hostname, service) => {\n\n})\n\nrequire('dns').lookupService('127.0.0.1', 443, (err, hostname, service) => {\n\n})\n```\n",
        "labels": "confirmed-bug",
        "id": 45488
    },
    {
        "title": "displayErrors option of the vm module seems not to work well",
        "body": "I'm stuck for the behavior of the `displayErrors` option of the vm module.\n\nFirst I wrote the code like below and this works well.\n\n``` javascript\nvar vm = require(\"vm\");\nvar sandbox = Object.create(null);\nvar context = vm.createContext(sandbox);\nvar script  = new vm.Script(\"?\", { filename: \"foobar\", displayErrors: false });\nscript.runInContext(context, { filename: \"foobar\", displayErrors: false });\n```\n\n```\nfoobar:1\n?\n^\n\nSyntaxError: Unexpected token ?\n    at Object.<anonymous> (/path/to/file.js:4:15)\n    at Module._compile (module.js:413:34)\n    at Object.Module._extensions..js (module.js:422:10)\n    at Module.load (module.js:357:32)\n    at Function.Module._load (module.js:314:12)\n    at Function.Module.runMain (module.js:447:10)\n    at startup (node.js:139:18)\n    at node.js:999:3\n```\n\nWhen `displayErrors` are set to `true`, however, the behavior seems to be not consistent with the document \"print any errors to stderr before throwing an exception\" since this code does not output anything to stderr.\n\n``` javascript\nvar vm = require(\"vm\");\nvar sandbox = Object.create(null);\nvar context = vm.createContext(sandbox);\nvar script  = new vm.Script(\"?\", { filename: \"foobar\", displayErrors: true });\nscript.runInContext(context, { filename: \"foobar\", displayErrors: true });\n```\n\n```\nfoobar:1\n?\n^\n\nSyntaxError: Unexpected token ?\n    at Object.<anonymous> (/Users/Susisu/root/projects/est/dev/vmtest.js:4:15)\n    at Module._compile (module.js:413:34)\n    at Object.Module._extensions..js (module.js:422:10)\n    at Module.load (module.js:357:32)\n    at Function.Module._load (module.js:314:12)\n    at Function.Module.runMain (module.js:447:10)\n    at startup (node.js:139:18)\n    at node.js:999:3\n```\n\nNext, I tried to catch the error and get the information where the error has occurred but I couldn't.\n\nI also re-threw the error and found that the information about the script is discarded when the error is re-thrown if `displayErrors: false`, while the `displayErrors: true` version retains it.\n\n``` javascript\nvar vm = require(\"vm\");\nvar sandbox = Object.create(null);\nvar context = vm.createContext(sandbox);\ntry {\n    var script  = new vm.Script(\"?\", { filename: \"foobar\", displayErrors: false });\n    script.runInContext(context, { filename: \"foobar\", displayErrors: false });\n}\ncatch (err) {\n    throw err;\n}\n```\n\n```\n/path/to/file.js:9\n    throw err;\n    ^\n\nSyntaxError: Unexpected token ?\n    at Object.<anonymous> (/path/to/file.js:5:19)\n    at Module._compile (module.js:413:34)\n    at Object.Module._extensions..js (module.js:422:10)\n    at Module.load (module.js:357:32)\n    at Function.Module._load (module.js:314:12)\n    at Function.Module.runMain (module.js:447:10)\n    at startup (node.js:139:18)\n    at node.js:999:3\n```\n\n``` javascript\nvar vm = require(\"vm\");\nvar sandbox = Object.create(null);\nvar context = vm.createContext(sandbox);\ntry {\n    var script  = new vm.Script(\"?\", { filename: \"foobar\", displayErrors: true });\n    script.runInContext(context, { filename: \"foobar\", displayErrors: true });\n}\ncatch (err) {\n    throw err;\n}\n```\n\n```\nfoobar:1\n?\n^\n\nSyntaxError: Unexpected token ?\n    at Object.<anonymous> (/path/to/file.js:5:19)\n    at Module._compile (module.js:413:34)\n    at Object.Module._extensions..js (module.js:422:10)\n    at Module.load (module.js:357:32)\n    at Function.Module._load (module.js:314:12)\n    at Function.Module.runMain (module.js:447:10)\n    at startup (node.js:139:18)\n    at node.js:999:3\n```\n\nThe problem is more serious when combined with `Promise`.\nThis code actually does not print anything since the error is swallowed by the Promise, and I have no idea to know where the error occurred in the script.\n\n``` javascript\nvar vm = require(\"vm\");\nnew Promise((resolve, reject) => {\n    var sandbox = Object.create(null);\n    var context = vm.createContext(sandbox);\n    var script  = new vm.Script(\"?\", { filename: \"foobar\", displayErrors: false });\n    script.runInContext(context, { filename: \"foobar\", displayErrors: false });\n}).catch(err => {\n    // can't do anything\n});\n```\n\nNote that all the codes throw syntax errors, but the results are almost same for throwing runtime errors.\n\nTaken together, it seems that `displayErrors: true` does only make the error retain the information where it occurred and does not let `new vm.Script` (and `runInContext` or something) print anything.\nIn addition, there seems to be no way to know where the error occurred if it is in Promise.\n\nHere I have two questions.\n1. Is this behavior of `displayErrors: true` is correct?\n2. Are there some ways to know where the error occurred in the script for the last case?\n\nThe version of Node.js is v5.5.0.\n\nThanks.\n",
        "labels": "confirmed-bug",
        "id": 45489
    },
    {
        "title": "Inconsistent multiple extension handling between Module._findPath and Module.load",
        "body": "Let's start by making a file with multiple extensions: `test.foo.bar`\n\n``` javascript\n> fs.writeFileSync('test.foo.bar', 'NOT_JS', 'utf8')\nundefined\n```\n\nSo we already know that `require.extensions` doesn't work with multiple extensions:\n\n``` javascript\n> require.extensions['.foo.bar'] = (module, path) => console.log('required .foo.bar', path)\n[Function]\n> require('./test.foo.bar')\nReferenceError: NOT_JS is not defined\n[...stack trace elided...]\n```\n\nAnd that it will use the last component of the extension instead:\n\n``` javascript\n> require.extensions['.bar'] = (module, path) => console.log('required .bar', path)\n[Function]\n> require('./test.foo.bar')\nrequired .bar /private/tmp/test.foo.bar\n{}\n```\n\nWhich is all perfectly obvious and by design. But did you know that the path searching uses the whole extension? Which means:\n\n``` javascript\n> delete require.extensions['.foo.bar'] // Since it's never called anyway\n> require('./test')\nError: Cannot find module './test'\n[...stack trace elided...]\n```\n\nHowever:\n\n``` javascript\n> require.extensions['.foo.bar'] = \"SURPRISE!\"\n> require('./test')\nrequired .bar /private/tmp/test.foo.bar\n{}\n```\n\nIn summary: to hook the requiring of a file with multiple extensions without specifying it, you must:\n1. Set `require.extensions` for the **last component** of the extension to your hook function\n2. Set `require.extensions` for the **entire extension** to any value.\n\nThis is due to differences in how `Module._findPath` and `Module.load` deal with extensions: the former adds each extension in `require.extensions` to the basename and tests it for existence (via `tryExtensions`). The latter works the other way around; it removes everything up to the last part of the extension (via `path.extname`) and then checks if it is present in `require.extensions`.\n\nI know it's policy not to fix bugs in `module` that might help compile-to-js languages, but I figure someone else might come across the same problem and this report could be useful to them.\n",
        "labels": "confirmed-bug",
        "id": 45490
    },
    {
        "title": "process.config.variables.arm_version incorrect in armv7",
        "body": "Armv7 machine (Scaleway C1). I install node from `node-v4.2.4-linux-armv7l.tar.gz`. Run `node -p process.config.variables.arm_version`. It returns incorrect value 6. Expected correct value 7. When node 4.2.4 is compiled from source, it gives correct value 7.\n\nRun `readelf -A /usr/bin/node | grep CPU_arch:`. Gives correct value \"v7\". So the binary is armv7 but `process.config` seems incorrect.\n\nThe gist https://gist.github.com/igorklopov/8edef2199419e3fb9c99 shows that it started in 4.1.0. Node 4.0.0 was not affected.\n",
        "labels": "confirmed-bug",
        "id": 45491
    },
    {
        "title": "ssl handshake failure v0.12 or v0.11",
        "body": "Test Code\n\n``` js\nvar https = require('https');\n//var tls = require(\"tls\");\n\nvar url = require(\"url\");\n\nvar counter = 0;\n\nfunction reqHttps(path , callback){\n    var parseUrl = url.parse(path);\n\n    counter++;\n    if(counter % 1000 == 0) console.log(\"req:\" , counter);\n\n    var options = {};\n    options.hostname = parseUrl.hostname;\n    options.path = parseUrl.path;\n    options.method = 'POST';\n    options.secureProtocol = 'TLSv1_method';\n\n    options.agent =  new https.Agent({\n        host: options.hostname,\n        port: 443,\n    });\n    var req = https.request(options, function(res) {\n\n        res.on('data', function(d) {\n\n        });\n\n        res.on('end', function(d) {\n\n            callback();\n        });\n    });\n\n    req.on('error',function(err){\n        if((err +'').indexOf('EPROTO') != -1) return callback();\n        //if((err +'').indexOf('unable to verify') != -1) return callback();\n        console.log('URL: ' + path);\n        throw err;\n    });\n\n    req.end();\n\n}\n\nvar list = [];\nlist.push('https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_116x41dp.png');\nlist.push('https://www.flpil.co.il/'); // no support TLSv1_method\n\nvar randCounter = 0;\n\n\nfunction getUrl(){\n    var currId = randCounter++;\n\n    currId = currId % list.length;\n\n    return list[currId];\n}\n\n\nfor(var i =0;i<300;i++){\n    (function(){\n        function next(){\n            reqHttps(getUrl(),next);\n        }   \n        next();\n    })();\n\n}\n```\n\nOutput in node v0.12 or v.0.11\n\n```\nURL: https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_116x41dp.png\n/home/test.js:41\n        throw err;\n              ^\nError: 140321677469568:error:1409E0E5:SSL routines:SSL3_WRITE_BYTES:ssl handshake failure:../deps/openssl/openssl/ssl/s3_pkt.c:637:\n\n    at Error (native)\n```\n\nOutput in node v0.10 , v4 , v5\n\n```\nreq: 1000\nreq: 2000\nreq: 3000\n...\n```\n",
        "labels": "confirmed-bug",
        "id": 45492
    },
    {
        "title": "Possible bug in handling of error when using ES6 constants and switch statement",
        "body": "Hello! I am using Node.js 4.2.3 on OS X 10.11.2. And I ran into strange behavior of node connected with constants and `switch` statement. Assume, there is file `function-do-not-use-constant-switch.js`:\n\n``` javascript\n'use strict';\n\nconst CONSTANT = 1;\nconst ACTION = 'a';\n\n+function test() {\n  switch (ACTION) {\n    case '*':\n      const CONSTANT = 2;\n      break;\n    case 'a':\n      console.log('all is OK');\n  }\n}();\n```\n\nExecution of script results in following output and AFAIK it's correct behavior:\n\n```\n$ node function-do-not-use-constant-switch.js \nall is OK\n```\n\nThen, there is another file `function-use-constant-switch.js` where `CONSTANT` is used in `console.log()`:\n\n``` javascript\n'use strict';\n\nconst CONSTANT = 1;\nconst ACTION = 'a';\n\n+function test() {\n  switch (ACTION) {\n    case '*':\n      const CONSTANT = 2;\n      break;\n    case 'a':\n      console.log('CONSTANT=' + CONSTANT);\n  }\n}();\n```\n\nOutput of this script is a bit strange to me:\n\n```\nStacktrace (bbbbbbbb-bbbbbbbb) 0x7a9c1a04471 0x0:\n==== JS stack trace =========================================\n\nSecurity context: 0x7a9c1a37399 <JS Object>\n    1: DefaultString(aka DefaultString) [native runtime.js:659] [pc=0x27cee80d3a2e] (this=0x7a9c1a04131 <undefined>,i=0x7a9c1a04471 <the hole>)\n    2: $toString(aka ToString) [native runtime.js:569] [pc=0x27cee8038333] (this=0x7a9c1a39db1 <JS Object>,i=0x7a9c1a04471 <the hole>)\n    3: ADD(aka ADD) [native runtime.js:176] [pc=0x27cee802a700] (this=0x497bdf0e3e9 <String[9]: CONSTANT=>,i=0x7a9c1a04471 <the hole>)\n    8: test(aka test) [/Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js:12] [pc=0x27cee80be88d] (this=0x7a9c1a04131 <undefined>)\n    9: /* anonymous */ [/Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js:14] [pc=0x27cee80bea0d] (this=0xa7ced056799 <an Object with map 0x2d6fcb065c9>,exports=0xa7ced056799 <an Object with map 0x2d6fcb065c9>,require=0xa7ced0875f9 <JS Function require (SharedFunctionInfo 0x497bdf0d8f9)>,module=0xa7ced004399 <a Module with map 0x2d6fcb2fef1>,__filename=0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>,__dirname=0xa7ced088151 <String[39]: /Users/estliberitas/work/tmp/nodejs-bug>)\n   11: _compile [module.js:435] [pc=0x27cee80bdf77] (this=0xa7ced004399 <a Module with map 0x2d6fcb2fef1>,content=0xa7ced087349 <String[214]\\: 'use strict';\\n\\nconst CONSTANT = 1;\\nconst ACTION = 'a';\\n\\n+function test() {\\n  switch (ACTION) {\\n    case '*':\\n      const CONSTANT = 2;\\n      break;\\n    case 'a':\\n      console.log('CONSTANT=' + CONSTANT);\\n  }\\n}();\\n>,filename=0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>)\n   12: .js [module.js:442] [pc=0x27cee80b65cb] (this=0xa7ced07d211 <an Object with map 0x2d6fcb2f189>,module=0xa7ced004399 <a Module with map 0x2d6fcb2fef1>,filename=0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>)\n   13: load [module.js:356] [pc=0x27cee80b2f32] (this=0xa7ced004399 <a Module with map 0x2d6fcb2fef1>,filename=0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>)\n   14: _load [module.js:311] [pc=0x27cee80a8d10] (this=0xa7ced004351 <JS Function Module (SharedFunctionInfo 0x330833e9b979)>,request=0xa7ced0044c9 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>,parent=0x7a9c1a04111 <null>,isMain=0x7a9c1a043f1 <true>)\n   15: runMain [module.js:467] [pc=0x27cee80a8443] (this=0xa7ced004351 <JS Function Module (SharedFunctionInfo 0x330833e9b979)>)\n   16: startup(aka startup) [node.js:136] [pc=0x27cee8077dae] (this=0x7a9c1a04131 <undefined>)\n   17: /* anonymous */ [node.js:963] [pc=0x27cee8075d92] (this=0x7a9c1ab85c1 <JS Global Object>,process=0x7a9c1ab8499 <a process with map 0x2d6fcb1b231>)\n\n==== Details ================================================\n\n[1]: DefaultString(aka DefaultString) [native runtime.js:659] [pc=0x27cee80d3a2e] (this=0x7a9c1a04131 <undefined>,i=0x7a9c1a04471 <the hole>) {\n  // stack-allocated locals\n  var Y = 0x7a9c1a04131 <undefined>\n  var Z = 0x7a9c1a04131 <undefined>\n  var X = 0x7a9c1a04131 <undefined>\n  var N = 0x7a9c1a04131 <undefined>\n  // expression stack (top to bottom)\n  [07] : 0x497bdf2abf9 <FixedArray[16]>\n  [06] : 4\n  [05] : 0x7a9c1a3caa9 <String[8]: toString>\n  [04] : 0x7a9c1a04471 <the hole>\n--------- s o u r c e   c o d e ---------\nfunction DefaultString(i){\\x0aif(!(%_ClassOf(i)==='Symbol')){\\x0avar Y=i.toString;\\x0aif((%_ClassOf(Y)==='Function')){\\x0avar Z=%_CallFunction(i,Y);\\x0aif(IsPrimitive(Z))return Z;\\x0a}\\x0avar X=i.valueOf;\\x0aif((%_ClassOf(X)==='Function')){\\x0avar N=%_CallFunction(i,X);\\x0aif(IsPrimitive(N))return N;\\x0a}\\x0a}\\x0athrow MakeTypeError(15);\\x0a}\n-----------------------------------------\n}\n\n[2]: $toString(aka ToString) [native runtime.js:569] [pc=0x27cee8038333] (this=0x7a9c1a39db1 <JS Object>,i=0x7a9c1a04471 <the hole>) {\n  // expression stack (top to bottom)\n  [04] : 0x7a9c1a04471 <the hole>\n  [03] : 0x7a9c1a04131 <undefined>\n  [02] : 0x330833e3ab09 <JS Function DefaultString (SharedFunctionInfo 0x7a9c1a3e6d9)>\n  [01] : 0x7a9c1a04131 <undefined>\n  [00] : 0x330833e3aef9 <JS Function ToString (SharedFunctionInfo 0x7a9c1a3dda9)>\n--------- s o u r c e   c o d e ---------\nfunction ToString(i){\\x0aif((typeof(i)==='string'))return i;\\x0aif((typeof(i)==='number'))return %_NumberToString(i);\\x0aif((typeof(i)==='boolean'))return i?'true':'false';\\x0aif((i===(void 0)))return'undefined';\\x0aif((typeof(i)==='symbol'))throw MakeTypeError(112);\\x0areturn((i===null))?'null':ToString(DefaultString(i));\\x0a}\n-----------------------------------------\n}\n\n[3]: ADD(aka ADD) [native runtime.js:176] [pc=0x27cee802a700] (this=0x497bdf0e3e9 <String[9]: CONSTANT=>,i=0x7a9c1a04471 <the hole>) {\n  // stack-allocated locals\n  var o = 0x497bdf0e3e9 <String[9]: CONSTANT=>\n  var p = 0x7a9c1a04471 <the hole>\n  // expression stack (top to bottom)\n  [06] : 0x7a9c1a04471 <the hole>\n  [05] : 0x7a9c1a39db1 <JS Object>\n  [04] : 0x330833e3aef9 <JS Function ToString (SharedFunctionInfo 0x7a9c1a3dda9)>\n  [03] : 0x497bdf0e3e9 <String[9]: CONSTANT=>\n  [02] : 0x330833e39b61 <JS Function ADD (SharedFunctionInfo 0x7a9c1a3eb41)>\n--------- s o u r c e   c o d e ---------\nfunction ADD(i){\\x0aif((typeof(this)==='number')&&(typeof(i)==='number'))return %NumberAdd(this,i);\\x0aif((typeof(this)==='string')&&(typeof(i)==='string'))return %_StringAdd(this,i);\\x0avar o=%$toPrimitive(this,0);\\x0avar p=%$toPrimitive(i,0);\\x0aif((typeof(o)==='string')){\\x0areturn %_StringAdd(o,%$toString(p));\\x0a}else if((type...\n\n-----------------------------------------\n}\n\n[8]: test(aka test) [/Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js:12] [pc=0x27cee80be88d] (this=0x7a9c1a04131 <undefined>) {\n  // stack-allocated locals\n  var CONSTANT = 0x7a9c1a04471 <the hole>\n  // expression stack (top to bottom)\n  [03] : 0xa7ced0b0381 <a Console with map 0x2d6fcb3a9c9>\n  [02] : 0xa7ced0b0f29 <JS Function (SharedFunctionInfo 0x497bdf29951)>\n  [01] : 0xa7ced088619 <JS Function test (SharedFunctionInfo 0x497bdf0e5b9)>\n--------- s o u r c e   c o d e ---------\nfunction test() {\\x0a  switch (ACTION) {\\x0a    case '*':\\x0a      const CONSTANT = 2;\\x0a      break;\\x0a    case 'a':\\x0a      console.log('CONSTANT=' + CONSTANT);\\x0a  }\\x0a}\n-----------------------------------------\n}\n\n[9]: /* anonymous */ [/Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js:14] [pc=0x27cee80bea0d] (this=0xa7ced056799 <an Object with map 0x2d6fcb065c9>,exports=0xa7ced056799 <an Object with map 0x2d6fcb065c9>,require=0xa7ced0875f9 <JS Function require (SharedFunctionInfo 0x497bdf0d8f9)>,module=0xa7ced004399 <a Module with map 0x2d6fcb2fef1>,__filename=0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>,__dirname=0xa7ced088151 <String[39]: /Users/estliberitas/work/tmp/nodejs-bug>) {\n  // stack-allocated locals\n  var CONSTANT = 1\n  // heap-allocated locals\n  var ACTION = 0x7a9c1a3bfc9 <String[1]: a>\n  // expression stack (top to bottom)\n  [02] : 0x7a9c1a04131 <undefined>\n  [01] : 0xa7ced088619 <JS Function test (SharedFunctionInfo 0x497bdf0e5b9)>\n--------- s o u r c e   c o d e ---------\nfunction (exports, require, module, __filename, __dirname) { 'use strict';\\x0a\\x0aconst CONSTANT = 1;\\x0aconst ACTION = 'a';\\x0a\\x0a+function test() {\\x0a  switch (ACTION) {\\x0a    case '*':\\x0a      const CONSTANT = 2;\\x0a      break;\\x0a    case 'a':\\x0a      console.log('CONSTANT=' + CONSTANT);\\x0a  }\\x0a}();\\x0a\\x0a}\n-----------------------------------------\n}\n\n[11]: _compile [module.js:435] [pc=0x27cee80bdf77] (this=0xa7ced004399 <a Module with map 0x2d6fcb2fef1>,content=0xa7ced087349 <String[214]\\: 'use strict';\\n\\nconst CONSTANT = 1;\\nconst ACTION = 'a';\\n\\n+function test() {\\n  switch (ACTION) {\\n    case '*':\\n      const CONSTANT = 2;\\n      break;\\n    case 'a':\\n      console.log('CONSTANT=' + CONSTANT);\\n  }\\n}();\\n>,filename=0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>) {\n  // stack-allocated locals\n  var require = 0xa7ced0875f9 <JS Function require (SharedFunctionInfo 0x497bdf0d8f9)>\n  var dirname = 0xa7ced088151 <String[39]: /Users/estliberitas/work/tmp/nodejs-bug>\n  var wrapper = 0xa7ced0881c1 <String[280]\\: (function (exports, require, module, __filename, __dirname) { 'use strict';\\n\\nconst CONSTANT = 1;\\nconst ACTION = 'a';\\n\\n+function test() {\\n  switch (ACTION) {\\n    case '*':\\n      const CONSTANT = 2;\\n      break;\\n    case 'a':\\n      console.log('CONSTANT=' + CONSTANT);\\n  }\\n}();\\n\\n});>\n  var compiledWrapper = 0xa7ced0884c9 <JS Function (SharedFunctionInfo 0x497bdf0e751)>\n  var args = 0xa7ced088549 <JS Array[5]>\n  // heap-allocated locals\n  var self = 0xa7ced004399 <a Module with map 0x2d6fcb2fef1>\n  // expression stack (top to bottom)\n  [08] : 0xa7ced088549 <JS Array[5]>\n  [07] : 0xa7ced056799 <an Object with map 0x2d6fcb065c9>\n  [06] : 0xa7ced0884c9 <JS Function (SharedFunctionInfo 0x497bdf0e751)>\n  [05] : 0x7a9c1aa3c71 <JS Function apply (SharedFunctionInfo 0x7a9c1aa3be1)>\n--------- s o u r c e   c o d e ---------\nfunction (content, filename) {\\x0a  var self = this;\\x0a  // remove shebang\\x0a  content = content.replace(/^\\#\\!.*/, '');\\x0a\\x0a  function require(path) {\\x0a    return self.require(path);\\x0a  }\\x0a\\x0a  require.resolve = function(request) {\\x0a    return Module._resolveFilename(request, self);\\x0a  };\\x0a\\x0a  Object.defineProperty(require, '...\n\n-----------------------------------------\n}\n\n[12]: .js [module.js:442] [pc=0x27cee80b65cb] (this=0xa7ced07d211 <an Object with map 0x2d6fcb2f189>,module=0xa7ced004399 <a Module with map 0x2d6fcb2fef1>,filename=0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>) {\n  // stack-allocated locals\n  var content = 0xa7ced087349 <String[214]\\: 'use strict';\\n\\nconst CONSTANT = 1;\\nconst ACTION = 'a';\\n\\n+function test() {\\n  switch (ACTION) {\\n    case '*':\\n      const CONSTANT = 2;\\n      break;\\n    case 'a':\\n      console.log('CONSTANT=' + CONSTANT);\\n  }\\n}();\\n>\n  // expression stack (top to bottom)\n  [04] : 0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>\n  [03] : 0xa7ced087349 <String[214]\\: 'use strict';\\n\\nconst CONSTANT = 1;\\nconst ACTION = 'a';\\n\\n+function test() {\\n  switch (ACTION) {\\n    case '*':\\n      const CONSTANT = 2;\\n      break;\\n    case 'a':\\n      console.log('CONSTANT=' + CONSTANT);\\n  }\\n}();\\n>\n  [02] : 0xa7ced004399 <a Module with map 0x2d6fcb2fef1>\n  [01] : 0x330833ebb139 <JS Function Module._compile (SharedFunctionInfo 0x330833e9c241)>\n--------- s o u r c e   c o d e ---------\nfunction (module, filename) {\\x0a  var content = fs.readFileSync(filename, 'utf8');\\x0a  module._compile(internalModule.stripBOM(content), filename);\\x0a}\n-----------------------------------------\n}\n\n[13]: load [module.js:356] [pc=0x27cee80b2f32] (this=0xa7ced004399 <a Module with map 0x2d6fcb2fef1>,filename=0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>) {\n  // stack-allocated locals\n  var extension = 0xa7ced0864b9 <String[3]: .js>\n  // expression stack (top to bottom)\n  [04] : 0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>\n  [03] : 0xa7ced004399 <a Module with map 0x2d6fcb2fef1>\n  [02] : 0xa7ced07d211 <an Object with map 0x2d6fcb2f189>\n  [01] : 0x330833ebb1b1 <JS Function Module._extensions..js (SharedFunctionInfo 0x330833e9c2e9)>\n--------- s o u r c e   c o d e ---------\nfunction (filename) {\\x0a  debug('load ' + JSON.stringify(filename) +\\x0a        ' for module ' + JSON.stringify(this.id));\\x0a\\x0a  assert(!this.loaded);\\x0a  this.filename = filename;\\x0a  this.paths = Module._nodeModulePaths(path.dirname(filename));\\x0a\\x0a  var extension = path.extname(filename) || '.js';\\x0a  if (!Module._extensi...\n\n-----------------------------------------\n}\n\n[14]: _load [module.js:311] [pc=0x27cee80a8d10] (this=0xa7ced004351 <JS Function Module (SharedFunctionInfo 0x330833e9b979)>,request=0xa7ced0044c9 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>,parent=0x7a9c1a04111 <null>,isMain=0x7a9c1a043f1 <true>) {\n  // stack-allocated locals\n  var replModule = 0x7a9c1a04131 <undefined>\n  var filename = 0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>\n  var cachedModule = 0x7a9c1a04131 <undefined>\n  var module = 0xa7ced004399 <a Module with map 0x2d6fcb2fef1>\n  var hadException = 0x7a9c1a043f1 <true>\n  // expression stack (top to bottom)\n  [08] : 0xa7ced004421 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>\n  [07] : 0xa7ced004399 <a Module with map 0x2d6fcb2fef1>\n  [06] : 0x330833ebb0a9 <JS Function Module.load (SharedFunctionInfo 0x330833e9c0f1)>\n  [05] : 0xa7ced004211 <FixedArray[25]>\n--------- s o u r c e   c o d e ---------\nfunction (request, parent, isMain) {\\x0a  if (parent) {\\x0a    debug('Module._load REQUEST  ' + (request) + ' parent: ' + parent.id);\\x0a  }\\x0a\\x0a  // REPL is a special case, because it needs the real require.\\x0a  if (request === 'internal/repl' || request === 'repl') {\\x0a    if (Module._cache[request]) {\\x0a      return Module...\n\n-----------------------------------------\n}\n\n[15]: runMain [module.js:467] [pc=0x27cee80a8443] (this=0xa7ced004351 <JS Function Module (SharedFunctionInfo 0x330833e9b979)>) {\n  // expression stack (top to bottom)\n  [04] : 0x7a9c1a043f1 <true>\n  [03] : 0x7a9c1a04111 <null>\n  [02] : 0xa7ced0044c9 <String[71]: /Users/estliberitas/work/tmp/nodejs-bug/function-use-constant-switch.js>\n  [01] : 0xa7ced004351 <JS Function Module (SharedFunctionInfo 0x330833e9b979)>\n  [00] : 0x330833ebafc1 <JS Function Module._load (SharedFunctionInfo 0x330833e9bfa1)>\n--------- s o u r c e   c o d e ---------\nfunction () {\\x0a  // Load the main module--the command line argument.\\x0a  Module._load(process.argv[1], null, true);\\x0a  // Handle any nextTicks added in the first tick of the program\\x0a  process._tickCallback();\\x0a}\n-----------------------------------------\n}\n\n[16]: startup(aka startup) [node.js:136] [pc=0x27cee8077dae] (this=0x7a9c1a04131 <undefined>) {\n  // stack-allocated locals\n  var EventEmitter = 0xa7ced0045a9 <JS Function EventEmitter (SharedFunctionInfo 0x330833e711f9)>\n  var d = 0x7a9c1a04131 <undefined>\n  var cluster = 0x7a9c1a04131 <undefined>\n  var path = 0xa7ced004571 <an Object with map 0x2d6fcb243f1>\n  var Module = 0xa7ced004351 <JS Function Module (SharedFunctionInfo 0x330833e9b979)>\n  var vm = 0x7a9c1a04131 <undefined>\n  var fs = 0x7a9c1a04131 <undefined>\n  var internalModule = 0x7a9c1a04131 <undefined>\n  var filename = 0x7a9c1a04131 <undefined>\n  var source = 0x7a9c1a04131 <undefined>\n  var debugTimeout = 0x7a9c1a04131 <undefined>\n  var cliRepl = 0x7a9c1a04131 <undefined>\n  // heap-allocated locals\n  var code = 0x7a9c1a04131 <undefined>\n  // expression stack (top to bottom)\n  [13] : 0xa7ced004351 <JS Function Module (SharedFunctionInfo 0x330833e9b979)>\n  [12] : 0x330833ebb2b9 <JS Function Module.runMain (SharedFunctionInfo 0x330833e9c4e1)>\n--------- s o u r c e   c o d e ---------\nfunction startup() {\\x0a    var EventEmitter = NativeModule.require('events');\\x0a\\x0a    process.__proto__ = Object.create(EventEmitter.prototype, {\\x0a      constructor: {\\x0a        value: process.constructor\\x0a      }\\x0a    });\\x0a    EventEmitter.call(process);\\x0a\\x0a    process.EventEmitter = EventEmitter; // process.EventEmitter is de...\n\n-----------------------------------------\n}\n\n[17]: /* anonymous */ [node.js:963] [pc=0x27cee8075d92] (this=0x7a9c1ab85c1 <JS Global Object>,process=0x7a9c1ab8499 <a process with map 0x2d6fcb1b231>) {\n  // stack-allocated locals\n  var EXPOSE_INTERNALS = 0x7a9c1a04431 <false>\n  // heap-allocated locals\n  var process = 0x7a9c1ab8499 <a process with map 0x2d6fcb1b231>\n  var startup = 0x330833e5aa01 <JS Function startup (SharedFunctionInfo 0x7a9c1aad431)>\n  var assert = 0x330833e8e8a1 <JS Function process.assert (SharedFunctionInfo 0x330833e8e759)>\n  var addPendingUnhandledRejection = 0xa7ced029221 <JS Function addPendingUnhandledRejection (SharedFunctionInfo 0x330833e93679)>\n  var hasBeenNotifiedProperty = 0x330833e5aa49 <JS WeakMap>\n  var evalScript = 0x330833e5aa71 <JS Function evalScript (SharedFunctionInfo 0x7a9c1aad4d9)>\n  var createWritableStdioStream = 0x330833e5aab9 <JS Function createWritableStdioStream (SharedFunctionInfo 0x7a9c1aad581)>\n  var ContextifyScript = 0x7a9c1ab1039 <JS Function ContextifyScript (SharedFunctionInfo 0x7a9c1ab0fa9)>\n  var runInThisContext = 0x330833e5ab01 <JS Function runInThisContext (SharedFunctionInfo 0x7a9c1aad629)>\n  var NativeModule = 0x7a9c1ab84b1 <JS Function NativeModule (SharedFunctionInfo 0x7a9c1aad6d1)>\n  // expression stack (top to bottom)\n  [02] : 0x7a9c1a04131 <undefined>\n  [01] : 0x330833e5aa01 <JS Function startup (SharedFunctionInfo 0x7a9c1aad431)>\n--------- s o u r c e   c o d e ---------\nfunction (process) {\\x0a  this.global = this;\\x0a\\x0a  function startup() {\\x0a    var EventEmitter = NativeModule.require('events');\\x0a\\x0a    process.__proto__ = Object.create(EventEmitter.prototype, {\\x0a      constructor: {\\x0a        value: process.constructor\\x0a      }\\x0a    });\\x0a    EventEmitter.call(process);\\x0a\\x0a    process.Event...\n\n-----------------------------------------\n}\n\n=====================\n\n\nIllegal instruction: 4\n```\n\nExit code is 132.\n\nOutput of other scripts is in [gist](https://gist.github.com/estliberitas/399c498b64f7b3f2eadc).\n\nIs this a bug or not?\n\nP.S.: Big thanks for your work, it's incredible!\n",
        "labels": "confirmed-bug",
        "id": 45493
    },
    {
        "title": "Bad readline behavior with line ending characters?",
        "body": "When including a trailing newline character (or carriage return character) in a string that is supplied to a write function, an RangeError is thrown (`RangeError: Maximum call stack size exceeded`). The following code snippet shows the context:\n\n``` javascript\nelse if (trimmedLine.match(/^h(elp)?$/i)) {\n    readlineInstance.write(\"Help\\n\");\n}\n```\n\nHere is an error log I created by issuing a command that passes the console output to a text file (`npm start > console_output.txt`):\n\n```\npath\\GitHubBackup\\console\\console.js:12\n        var trimmedLine = line.trim();\n                               ^\n\nRangeError: Maximum call stack size exceeded\n    at String.trim (native)\n    at consoleOptions (path\\GitHubBackup\\console\\console.js:12:25)\n    at Interface.<anonymous> (path\\GitHubBackup\\console\\console.js:46:14)\n    at emitOne (events.js:82:20)\n    at Interface.emit (events.js:169:7)\n    at Interface._onLine (readline.js:210:10)\n    at Interface.<anonymous> (readline.js:340:12)\n    at Array.forEach (native)\n    at Interface._normalWrite (readline.js:339:11)\n    at Interface.write (readline.js:309:49)\n\nnpm ERR! Windows_NT 10.0.10586\nnpm ERR! argv \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\***\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"start\"\nnpm ERR! node v5.3.0\nnpm ERR! npm  v3.5.2\nnpm ERR! code ELIFECYCLE\nnpm ERR! github.backup@0.1.0 start: `node main.js`\nnpm ERR! Exit status 1\nnpm ERR!\nnpm ERR! Failed at the github.backup@0.1.0 start script 'node main.js'.\nnpm ERR! Make sure you have the latest version of node.js and npm installed.\nnpm ERR! If you do, this is most likely a problem with the github.backup package\n,\nnpm ERR! not with npm itself.\nnpm ERR! Tell the author that this fails on your system:\nnpm ERR!     node main.js\nnpm ERR! You can get information on how to open an issue for this project with:\nnpm ERR!     npm bugs github.backup\nnpm ERR! Or if that isn't available, you can get their info via:\nnpm ERR!     npm owner ls github.backup\nnpm ERR! There is likely additional logging output above.\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     path\\GitHubBackup\\npm-debug.log\n```\n\nThe ordinary error log doesn't show the details above, only an exit status entry:\n\n```\n(...Break...)\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\nHelp\n\nnpm ERR! Windows_NT 10.0.10586\nnpm ERR! argv \"C:\\\\Program Files\\\\nodejs\\\\node.exe\" \"C:\\\\Users\\\\***\\\\AppData\\\\Roaming\\\\npm\\\\node_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"start\"\nnpm ERR! node v5.3.0\nnpm ERR! npm  v3.5.2\nnpm ERR! code ELIFECYCLE\nnpm ERR! github.backup@0.1.0 start: `node main.js`\nnpm ERR! Exit status 3221225725\nnpm ERR!\nnpm ERR! Failed at the github.backup@0.1.0 start script 'node main.js'.\nnpm ERR! Make sure you have the latest version of node.js and npm installed.\nnpm ERR! If you do, this is most likely a problem with the github.backup package\n,\nnpm ERR! not with npm itself.\nnpm ERR! Tell the author that this fails on your system:\nnpm ERR!     node main.js\nnpm ERR! You can get information on how to open an issue for this project with:\nnpm ERR!     npm bugs github.backup\nnpm ERR! Or if that isn't available, you can get their info via:\nnpm ERR!     npm owner ls github.backup\nnpm ERR! There is likely additional logging output above.\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     path\\GitHubBackup\\npm-debug.log\n```\n\nThe full code:\n\n``` javascript\n\"use strict\"\n\n// CONSTANTS\nvar CONSOLE_PROMPT_NAME = \"GitHubBackup\";\n\n// DEPENDENCIES\nvar readline = require(\"readline\");\nconst chalk = require(\"chalk\");\n\n// -CONSOLE OPTIONS\nfunction consoleOptions(line, readlineInstance) {\n    var trimmedLine = line.trim();\n\n    if (trimmedLine.match(/^q(uit)?$/i)) {\n        readlineInstance.write(\"Closing...\");\n        readlineInstance.close();\n    }\n    else if (trimmedLine.match(/^h(elp)?$/i)) {\n        readlineInstance.write(\"Help\\n\");\n    }\n\n    readlineInstance.prompt();\n}\n\nmodule.exports = function() {\n    return {\n        // -CONSOLE FUNCTIONS\n        createConsole: function() {\n            var readlineInstance;\n\n            // Setting up a prompt using the \"readline\" module\n            readlineInstance = readline.createInterface({\n                input: process.stdin,\n                output: process.stdout\n            });\n            readlineInstance.setPrompt(chalk.green(CONSOLE_PROMPT_NAME + \">\"));\n            readlineInstance.prompt();\n\n            // Monitoring user actions\n            readlineInstance.on(\"SIGINT\", function() {\n                readlineInstance.close();\n            });\n            readlineInstance.on(\"line\", function(line) {\n                consoleOptions(line, this);\n            });\n\n            return readlineInstance;\n        }\n    };\n}\n```\n\nIs this a valid behaviour of the readline module? Note again that this only happens with trailing line endings.\n",
        "labels": "confirmed-bug",
        "id": 45494
    },
    {
        "title": "Enhanced object literals dont work with accessor keywords (possibly others)",
        "body": "i.e.\n\n``` javascript\nvar x = 123,\n    get = 456,\n    set = 789;\n\nvar a = {x} // {x: 123}\nvar b = {get} // syntax error\nvar c = {set} // syntax error\n```\n\nThis possibly falls into the v8 version and level of implementation.\n\nTested on node 4.x and 5.x with same results, works fine in chrome (47.0.2526.73) (V8 4.7.80.23)\n",
        "labels": "confirmed-bug",
        "id": 45495
    },
    {
        "title": "Node ignoring redirections when redirected to a tty",
        "body": "So, although redirects to other active file-descriptors work as expected, as do redirections to files and the `/dev/null` device, I _cannot_ redirect successfully to a different `tty`:\n\n``` sh\n$ node -e 'process.stdout.write(\"wtf!\\n\")' 1>/dev/ttys014\nwtf!\n```\n#### Example:\n\n``` txt\n# First term:                                                           â”‚# Second term:\n                                                                        â”‚\n$ tty                                                                   â”‚$ tty\n/dev/ttys013                                                            â”‚/dev/ttys014\n$ echo 'abc' 1>/dev/ttys014                                             â”‚$ cat\n$ ruby -e '$stdout.puts \"okay\"' 1>/dev/ttys014                          â”‚abc\n$ node -e 'process.stdout.write(\"wtf!\\n\")' 1>/dev/ttys014               â”‚okay\nwtf!                                                                    â”‚\n$ node -e 'process.stdout.write(\"this works\\n\")' 1>/dev/null            â”‚\n$ node -e 'process.stdout.write(\"this too\\n\")' 1>output                 â”‚\n$ cat output                                                            â”‚\nthis too                                                                â”‚\n```\n#### Environment:\n\nSystem: Mac OS X El Capitan `10.11.1`\nShell: Zsh `5.1.1 (x86_64-apple-darwin15.0.0)`\nNode: v`4.2.3`\n",
        "labels": "confirmed-bug",
        "id": 45496
    },
    {
        "title": "v5.2.0: `require` doesn't work in REPL",
        "body": "### Environment\n\n```\n$ sw_vers\nProductName:    Mac OS X\nProductVersion: 10.11.1\nBuildVersion:   15B42\n\n$ node --version\nv5.2.0\n\n$ npm --version\n3.3.12\n\n$ pwd\n/Users/shinnn/test\n\n$ npm ls underscore\ntest@ /Users/shinnn/test\nâ””â”€â”€ underscore@1.8.3\n```\n### Problem\n\nWhen I try to `require` locally installed \"underscore\" module, Node throws the following error.\n\n```\n$ node --version\nv5.2.0\n$ node\n> require('underscore')\nError: Cannot find module 'underscore'\n    at Function.Module._resolveFilename (module.js:327:15)\n    at Function.Module._load (module.js:278:25)\n    at Module.require (module.js:355:17)\n    at require (internal/module.js:13:17)\n    at repl:1:1\n    at REPLServer.defaultEval (repl.js:252:27)\n    at bound (domain.js:281:14)\n    at REPLServer.runBound [as eval] (domain.js:294:12)\n    at REPLServer.<anonymous> (repl.js:417:12)\n    at emitOne (events.js:83:20)\n```\n\nWith Node v5.1.1 it works fine.\n\n```\n$ node --version\nv5.1.1\n$ node\n> require('underscore')\n{ [Function]\n  _: [Circular],\n  VERSION: '1.8.3',\n  [...] }\n```\n\nAlso, when I directly specify the script path instead of the simple package name `underscore`, it can load the module as expected.\n\n```\n$ node --version\nv5.2.0\n$ node\n> require('./node_modules/underscore/underscore.js')\n{ [Function]\n  _: [Circular],\n  VERSION: '1.8.3',\n  [...] }\n```\n",
        "labels": "confirmed-bug",
        "id": 45497
    },
    {
        "title": "Error: 140735127326720:error:1408F119:SSL routines:SSL3_GET_RECORD:decryption failed or bad record mac",
        "body": "With latest master, I was trying to track down some flakiness in `test-tls-inception.js`, so I increased the data sent from the socket at the `b` server like this:\n\n```\ndiff --git a/test/parallel/test-tls-inception.js b/test/parallel/test-tls-inception.js\nindex df03cf9..4dc885d 100644\n--- a/test/parallel/test-tls-inception.js\n+++ b/test/parallel/test-tls-inception.js\n@@ -38,7 +38,7 @@ a = tls.createServer(options, function(socket) {\n\n // the \"target\" server\n b = tls.createServer(options, function(socket) {\n-  socket.end('hello');\n+  socket.end((new Buffer(4000)).fill('a'));\n });\n\n process.on('exit', function() {\n```\n\nand got this error:\n\n```\nevents.js:141\n      throw er; // Unhandled 'error' event\n      ^\n\nError: 140735127326720:error:1408F119:SSL routines:SSL3_GET_RECORD:decryption failed or bad record mac:../deps/openssl/openssl/ssl/s3_pkt.c:532:\n\n    at Error (native)\n```\n\nReducing the size of the `Buffer` to `3000` does not cause the error. Is this expected or a bug?\n\nThanks\n",
        "labels": "confirmed-bug",
        "id": 45498
    },
    {
        "title": "REPL syntax error when closing bracket & parenthesis are on different lines",
        "body": "I seem to be getting a syntax error `SyntaxError:  missing ) after argument list` with the following code:\n\n``` javascript\nPromise.resolve('finished').then(function(result){\n  console.log(result)\n}\n)\n```\n\nHowever if I put the closing bracket and parenthesis on the same line, there's no error:\n\n``` javascript\nPromise.resolve('finished').then(function(result){\n  console.log(result)\n})\n```\n\nTested in node 4.2.1 & node 5.1.0 on OSX 10.11.1\n",
        "labels": "confirmed-bug",
        "id": 45499
    },
    {
        "title": "fs.close twice different behavior on Windows 10",
        "body": "The following test case opens a file, and closes it twice expecting to get an Error.\n\n``` javascript\nvar assert = require('assert');\nvar fs = require('fs');\n\n// 'w+' - Open file for reading and writing.\n// The file is created (if it does not exist)\n// or truncated (if it exists).\n\nfs.open(__dirname + '/test-to-open-a-file.txt', 'w+', function(err1, fd){\n\n    console.log('open', fd);\n    fs.close(fd, function(err2){\n\n        console.log('close - should have no error', fd);\n        assert.ifError(err2);\n\n        fs.close(fd, function(err3){\n            console.log('close2 - expect an error', fd);\n            console.error(err3);\n        });\n    });\n});\n```\n\n On Linux/Mac the second close callback err3 has the following Error: `{ [Error: EBADF: bad file descriptor, close] errno: -9, code: 'EBADF', syscall: 'close' }` \n\nOn Windows 10 the second callback err3 has `null`\n",
        "labels": "confirmed-bug",
        "id": 45500
    },
    {
        "title": "FATAL ERROR: v8::ArrayBuffer::Neuter Only externalized ArrayBuffers can be neutered",
        "body": "I keep getting this error \"FATAL ERROR: v8::ArrayBuffer::Neuter Only externalized ArrayBuffers can be neutered\" when I run \"tns platform add ios\" or \"tns platform add android\"\n",
        "labels": "confirmed-bug",
        "id": 45501
    },
    {
        "title": "REPL should raise Exception immediately when it gets naturally invalid multi-line.",
        "body": "I'm using v5.0.0 on Windows.\n\nOf course this is invalid as javascript:\n\n``` javascript\na = 3.5e\n-5;\nconsole.log(a);\n```\n\nBut REPL enters multi-line editting mode:\n\n```\n> a = 3.5e\n... \n... \n... .break\n```\n\nWe have no way to exit from the mode except `.break` (or Ctrl-C), and `.break` will make nothing.\n",
        "labels": "confirmed-bug",
        "id": 45502
    },
    {
        "title": "Domains inhibit uncaughtException error handling",
        "body": "In the test case below, I would expect the `uncaughtException` handler to run (since the domain doesn't have an `error` event handler), but it doesn't.\n\nVerified with node v0.10.39 and v4.2.1.\n\n``` js\nvar domain = require('domain');\n\nvar d = domain.create();\nd.enter();\n\nprocess.on('uncaughtException', function(e) {\n  console.log('Uncaught exception: ', e);\n});\n\nsetTimeout(function() {\n  throw new Error('Bla!');\n}, 1);\n```\n",
        "labels": "confirmed-bug",
        "id": 45503
    },
    {
        "title": "Error: Cannot find module './lib'",
        "body": "Just installed node v5 and running `npm` in command line produces said error.\n\nOS X 10.10.5\n## How to Fix\n\n(For now)\n(Edited in by @Fishrock123)\n\n```\nrm -rf /usr/local/lib/node_modules/npm\n```\n",
        "labels": "confirmed-bug",
        "id": 45504
    },
    {
        "title": "a simple script to crash Node.js with an assertion failure: (loop->watchers[w->fd] == w)",
        "body": "This crash was reported several times in [1] [2] [3] [4], I also devised a simple script to reproduce the crash as below.\n\n``` js\nvar fd = 3;\nwhile (fd<1000) {\n  try {\n    var stream = new net.Socket({\n      fd: fd,\n      readable: false,\n      writable: true\n    });\n    stream.on('error', function() {});\n    stream.write('might crash');\n  } catch(e) {}\n  fd += 1;\n}\n```\n\n[1] https://github.com/joyent/libuv/issues/838\n[2] https://github.com/joyent/libuv/issues/1348\n[3] https://github.com/jeremycx/node-LDAP/issues/33\n[4] https://github.com/voodootikigod/node-serialport/issues/262\n",
        "labels": "confirmed-bug",
        "id": 45505
    },
    {
        "title": "Crash when trying to create buffers with invalid base64.",
        "body": "I've been having this problem intermittently in production, and (with the help of @kans) managed to create a reproducible test case. This is on Ubuntu 15.04 using node.js v4.2.1 (built from source):\n\n```\nggreer@lithium:~% node\n> new Buffer(\"=\" + new Array(10000).join(\"A\"), \"base64\");\nnode: ../src/node_buffer.cc:225: v8::MaybeLocal<v8::Object> node::Buffer::New(v8::Isolate*, v8::Local<v8::String>, node::encoding): Assertion `(data) != (nullptr)' failed.\nzsh: abort (core dumped)  node\nggreer@lithium:~% \n```\n\nIn the Buffer constructor (https://github.com/nodejs/node/blob/master/src/node_buffer.cc#L224), it looks like `StringBytes::Write()` fails and returns zero. Then `realloc()` is called with a length of zero. On linux, this frees the memory and returns a null pointer. Then the null assertion fails and node crashes. `realloc()` behaves differently on OS X, so this won't crash on a mac.\n",
        "labels": "confirmed-bug",
        "id": 45506
    },
    {
        "title": "Extended TypedArray reverts to parent class.",
        "body": "After creating several instances (~135 on my machine) an extended TypedArray reverts to the TypedArray it was extended from.\n\nGist: https://gist.github.com/AaronAsAChimp/354374a7e1cdc68c4d9f\nOutput:\n\n```\n[snipped ...]\nThe method \"double\" is function\nIs it still an ExtendedArray? true\nIs it still an Float64Array? true\nThe method \"double\" is undefined\nIs it still an ExtendedArray? false\nIs it still an Float64Array? true\n/folder/array-extend.js:15\n        throw new Error('Method \"double\" should not be undefined');\n        ^\n\nError: Method \"double\" should not be undefined\n    at Object.<anonymous> (/folder/array-extend.js:15:9)\n    at Module._compile (module.js:435:26)\n    at Object.Module._extensions..js (module.js:442:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:311:12)\n    at Function.Module.runMain (module.js:467:10)\n    at startup (node.js:134:18)\n    at node.js:961:3\n```\n\nThis was tested against Node v4.2.1\n",
        "labels": "confirmed-bug",
        "id": 45507
    },
    {
        "title": "repl hates comments with quotes in indented code",
        "body": "```\n$ node\n> function foo() {\n... //'\nSyntaxError: Unexpected end of input\n    at Object.exports.createScript (vm.js:24:10)\n    at REPLServer.defaultEval (repl.js:137:25)\n    at bound (domain.js:280:14)\n    at REPLServer.runBound [as eval] (domain.js:293:12)\n    at REPLServer.<anonymous> (repl.js:393:12)\n    at emitOne (events.js:82:20)\n    at REPLServer.emit (events.js:169:7)\n    at REPLServer.Interface._onLine (readline.js:210:10)\n    at REPLServer.Interface._line (readline.js:549:8)\n    at REPLServer.Interface._ttyWrite (readline.js:826:14)\n>\n```\n\nSame happens with `//\"`\n",
        "labels": "confirmed-bug",
        "id": 45508
    },
    {
        "title": "REPL quits unexpectedly during tab completion",
        "body": "Reproduction:\n1) Start the nodejs repl.\n2) Start a function; enter \"function() {\" (without quotes) and hit [ENTER].\n3) Type \"arguments.\" (without quotes) and hit [TAB].\n\nExpected:\nAvailable properties on arguments object, varying depending on strict / non-strict mode.\n\nActual:\nExit to command prompt with exit code 0.\n\nScreenshot:\n\n```\n~ $ nodejs\n> function() {\n... arguments.~ $ echo $?\n0\n```\n\nVersion:\nNodeJS 4.1 on Linux 3.19\n",
        "labels": "confirmed-bug",
        "id": 45509
    },
    {
        "title": "Issue with Node 4.x when receiving pipelined reqeusts",
        "body": "After updating to Node 4.x from 0.12.x, benchmarking by sending pipelining requests results in an initial spike of requests followed by **no** requests being processed on those connections, and those connections remaining open even after the load generator client finishes (connection leak). The same behavior does not occur when not pipelining requests, and it doesn't occur on 0.10.x or 0.12.x at all. The issue reproduces on both Linux and Windows.\n\nI'm generating load using \"wrk\" (from a remote Linux machine) and the app is the benchmark app from the [TechEmpower benchmarks](https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/JavaScript/nodejs).\n",
        "labels": "confirmed-bug",
        "id": 45510
    },
    {
        "title": "Encoding problems with umlauts in logged exception messages",
        "body": "I have the following simple script:\n\n``` js\n\"use strict\";\nconsole.log(\"Ã¼ÃœÃ¤Ã„Ã¶Ã–ÃŸ\")\nconsole.error(\"Ã¼ÃœÃ¤Ã„Ã¶Ã–ÃŸ\");\nthrow new Error(\"Ã¼ÃœÃ¤Ã„Ã¶Ã–ÃŸ\"); // or alternatively:\nconsole.assert(false, \"Ã¼ÃœÃ¤Ã„Ã¶Ã–ÃŸ\"); // throws AssertionError\n```\n\nwhich when executed logs the following:\n\n``` text\nÃ¼ÃœÃ¤Ã„Ã¶Ã–ÃŸ\nÃ¼ÃœÃ¤Ã„Ã¶Ã–ÃŸ\n\nc:\\Users\\â€¦.js:4\nthrow new Error(\"â”œâ•â”œÂ£â”œÃ±â”œÃ¤â”œÃ‚â”œÃ»â”œÆ’\");\n      ^\nError: â”œâ•â”œÂ£â”œÃ±â”œÃ¤â”œÃ‚â”œÃ»â”œÆ’\n    at Object.<anonymous> (c:\\Users\\â€¦.js:4:7)\n    at Module._compile (module.js:456:26)\n    at Object.Module._extensions..js (module.js:474:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:312:12)\n    at Function.Module.runMain (module.js:497:10)\n    at startup (node.js:119:16)\n    at node.js:906:3\n```\n\nIt seems the global exception handler does not use the appropriate output encoding, while `console` does.\nIt doesn't seem to make any difference whether I encode my script as UTF8 or anything else - the first two logs are fine, but the error message is not.\n\nAdmittedly, I'm still on node v0.10.30. Would an update help?\n",
        "labels": "confirmed-bug",
        "id": 45511
    },
    {
        "title": "cluster: suicide flag is not set on master when calling disconnect from a worker",
        "body": "From the documentation:\n\n[`worker.suicide`](https://nodejs.org/api/cluster.html#cluster_worker_suicide):\n\n> Set by calling .kill() or .disconnect(), until then it is undefined.\n\n[`worker.disconnect()`](https://nodejs.org/api/cluster.html#cluster_worker_disconnect):\n\n> In a worker, this function will close all servers, wait for the 'close' event on those servers, and then disconnect the IPC channel.\n> \n> Causes .suicide to be set.\n\nRepro:\n\n``` javascript\nvar cluster = require('cluster');\n\nif (cluster.isMaster) {\n  // Master forks and listens for events\n  var worker = cluster.fork();\n  cluster.on('disconnect', function(){\n    console.log(\"disconnect\", worker.suicide);\n  });\n  cluster.on('exit', function(){\n    console.log(\"exit\", worker.suicide);\n  });\n} else {\n  // Worker just disconnects\n  cluster.worker.disconnect();\n}\n```\n\nIn node v0.10, both log statements would print `true` for `worker.suicide`. In 41b75ca9263f368db790fbdcc3963bb1a8c5cb7e, which landed during the v0.11 branch, this was broken, and all versions up to node v4 will print `false`. This is because `worker.disconnect()`, when called from the worker, does not send the `suicide` message anymore -- only `worker.destroy()` will send that message to the master.\n",
        "labels": "confirmed-bug",
        "id": 45512
    },
    {
        "title": "NodeJS REPL first line strange behaviour",
        "body": "NodeJS 4.1.2, Windows 10 (x64), REPL:\n\n``` javascript\nC:\\Users\\admin\\Desktop>node\n> 1+1 // also ctrl+c, ctrl+d dont work here\n1+1 // wtf?\n2\n> 1+1 // now works as intended\n2\n```\n",
        "labels": "confirmed-bug",
        "id": 45513
    },
    {
        "title": "VM: When applied result of vm.runInContext in 'Object.getOwnPropertyNames(result)' ignores its own property ",
        "body": "``` js\n'use strict';\nconst vm = require('vm');\n\nconst name = {\n  firstName: 'prince'\n};\n\nconst ctx = vm.createContext(name);\nconst result = vm.runInContext('this', ctx);\nconst ownProperties = Object.getOwnPropertyNames(result);\n\nconsole.log(ownProperties.indexOf('firstName'));\nconsole.log('result.firstName', result.firstName);\nconsole.log(\"result.hasOwnProperty('firstName')\", result.hasOwnProperty('firstName'));\n\n```\n\ngives \n\n```\n$ node vmIssue.js\n-1\nresult.firstName prince\nresult.hasOwnProperty('firstName') true\n```\n\nIn the above example, `Object.getOwnPropertyNames(result)` is not returning its own property.\n\nIt affects REPL auto-completion results when `useGlobal` is false. \n",
        "labels": "confirmed-bug",
        "id": 45514
    },
    {
        "title": "http/server: request.socket.bytesRead always 0 for IncomingMessage",
        "body": "Tested with node.js v4.1.0 & v4.1.1 (v0.10.x does not have this issue)\n\nSee the following test (`parallel/test-http-bytesread.js`) to reproduce the issue;\n\n``` js\n'use strict';\nvar common = require('../common');\nvar assert = require('assert');\nvar http = require('http');\n\nvar body = 'hello world\\n';\nvar sawEnd = false;\nvar bytesReadServer = 0;\nvar bytesReadClient = 0;\n\nprocess.on('exit', function() {\n  assert(sawEnd);\n  console.log('ok');\n});\n\nvar httpServer = http.createServer(function(req, res) {\n  httpServer.close();\n\n  req.on('readable', function() {\n    var data = req.read();\n    if (data !== null) {\n      bytesReadServer += data.length;\n    }\n  });\n\n  req.on('end', function() {\n    assert(bytesReadServer > 0);\n    assert(req.socket.bytesRead > 0);\n\n    sawEnd = true;\n    res.writeHead(200, { 'Content-Type': 'text/plain' });\n    res.end(body);\n  });\n});\n\nhttpServer.listen(common.PORT, function() {\n  var req = http.request({\n    method: 'PUT',\n    port: common.PORT\n  }, function(res) {\n    res.on('readable', function() {\n      var data = res.read();\n      if (data !== null) {\n        bytesReadClient += data.length;\n      }\n    });\n\n    res.on('end', function() {\n      assert(bytesReadClient > 0);\n      assert(res.socket.bytesRead > 0);\n    });\n  });\n\n  var chunk = new Array(1024 + 1).join('7');\n  var bchunk = new Buffer(chunk);\n\n  for (var i = 0; i < 1024; i++) {\n    req.write(chunk);\n    req.write(bchunk);\n    req.write(chunk, 'hex');\n  }\n\n  req.end();\n});\n```\n\nI could not yet figure out what causes this, any help is appreciated.\n",
        "labels": "confirmed-bug",
        "id": 45515
    },
    {
        "title": "Looks like readline don't always triggers keypress events on Windows",
        "body": "Hi there, I'm the author on [Inquirer](https://github.com/SBoudrias/Inquirer.js).\n\nI would've love to have more details to report on this bug. But I don't have much currently, I'm hoping someone would be able to help in getting more precise information. Also, due to this blindness, I can't exclude totally that this is an issue with Inquirer; all I know is these bug reports started to appear on my repo recently.\n\nBasically, it looks like on Windows (since mostly Node 4.0), readlines don't always triggers keypress events the first time we initialize one. This have reported on Inquirer repository: https://github.com/SBoudrias/Inquirer.js/issues/266\n\nSome people the issue have said they've been able to reproduce using only a readline directly, but it's not super clear what they've done.\n\nOn my side, I've been unable to reproduce this bug on any Windows VM. So I really have a hard time to come up with reproducible step for you.\n",
        "labels": "confirmed-bug",
        "id": 45516
    },
    {
        "title": "New Uint8Arrays are sometimes filled with garbage",
        "body": "Unfortunately, I don't have a neat small test case, so please bear with me.\n\nOne [TweetNaCl-js](https://github.com/dchest/tweetnacl-js) test with Node.js 4.1 fails, while succeeding with 0.12 and io.js v3.3.1. The [test](https://github.com/dchest/tweetnacl-js/blob/master/test/04-secretbox.js#L17) is encrypting a message and comparing the result with a known good value. \n\nTo reproduce:\n\n```\nmkdir reproduce\ncd reproduce\ngit clone https://github.com/dchest/tweetnacl-js.git\ncd tweetnacl-js\nnpm install tape\nNACL_SRC=nacl.js node ./test/04-secretbox.js | more\n```\n\nOutput:\n\n```\nTAP version 13\n# nacl.secretbox random test vectors\nok 1 box should be created\nok 2 should be equal\nok 3 box should open\nok 4 should be equal\nok 5 box should be created\nnot ok 6 should be equal\n  ---\n    operator: equal\n    expected: 'VJViVugBhKeaOvfSlHkTzUQ='\n    actual:   'ZpRiVugBhKeaOvfSlHkTzUQ='\n    at: Test.<anonymous> (/Users/dchest/reproduce/tweetnacl-js/test/04-secretbox.js:10:17)\n  ...\n```\n\n(`actual` may be different for you)\n\nThe cause is in this function in `nacl.js`:\n\nhttps://github.com/dchest/tweetnacl-js/blob/master/nacl.js#L990\n\n``` javascript\nnacl.secretbox = function(msg, nonce, key) {\n  checkArrayTypes(msg, nonce, key);\n  checkLengths(key, nonce);\n  var m = new Uint8Array(crypto_secretbox_ZEROBYTES + msg.length); // <-- BUG HERE\n  var c = new Uint8Array(m.length);\n  for (var i = 0; i < msg.length; i++) m[i+crypto_secretbox_ZEROBYTES] = msg[i];\n  crypto_secretbox(c, m, m.length, nonce, key);\n  return c.subarray(crypto_secretbox_BOXZEROBYTES);\n};\n```\n\nThis function requires that `m` must be zero-filled.\n\nIf I add `console.log` after creating `m` to see what's there:\n\n``` javascript\nnacl.secretbox = function(msg, nonce, key) {\n  checkArrayTypes(msg, nonce, key);\n  checkLengths(key, nonce);\n  var m = new Uint8Array(crypto_secretbox_ZEROBYTES + msg.length); // <-- BUG HERE\n  console.log(m); // <--- ADDED\n  var c = new Uint8Array(m.length);\n  for (var i = 0; i < msg.length; i++) m[i+crypto_secretbox_ZEROBYTES] = msg[i];\n  crypto_secretbox(c, m, m.length, nonce, key);\n  return c.subarray(crypto_secretbox_BOXZEROBYTES);\n};\n```\n\nand run the test again, I see that `m` contains some garbage data (results differ from time to time):\n\n```\nUint8Array {\n  '0': 0,\n  '1': 0,\n  '2': 0,\n  '3': 0,\n  '4': 0,\n  '5': 0,\n  '6': 0,\n  '7': 0,\n  '8': 0,\n  '9': 0,\n  '10': 0,\n  '11': 0,\n  '12': 0,\n  '13': 0,\n  '14': 0,\n  '15': 0,\n  '16': 232,\n  '17': 0,\n  '18': 0,\n  '19': 0,\n  '20': 0,\n  '21': 0,\n  '22': 0,\n  '23': 0,\n  '24': 64,\n  '25': 231,\n  '26': 96,\n  '27': 1,\n  '28': 1,\n  '29': 0,\n  '30': 0,\n  '31': 0,\n  '32': 0 }\n```\n\nThis only happens for this particular 33-byte Uint8Array in this particular setting (e.g. I couldn't reproduce this outside of this test). I can work around this by manually zeroing the array after creating it.\n\nAny ideas? As I said, io.js v3.3.1 and previous Node versions doesn't have this bug.\n",
        "labels": "confirmed-bug",
        "id": 45517
    },
    {
        "title": "Error stack gives incorrect column number",
        "body": "Node.js appears to give incorrect column numbers in it's stack traces.  The problem is magnified when running uglified/minified code (because all the code tends to be on a single line).  Here's a trivial example that show's the problem:\n\ncode:\n\n``` javascript\n(function() { var functions = { test: function() { throw new Error('testing'); } }; functions.test(); })();\n```\n\nstacktrace:\n\n```\n/Users/mbrocato/WebstormProjects/StackTest/test.js:1\ndirname) { (function() { var functions = { test: function() { throw new Error(\n                                                                    ^\nError: testing\n    at Object.functions.test (/Users/mbrocato/WebstormProjects/StackTest/test.js:1:120)\n    at /Users/mbrocato/WebstormProjects/StackTest/test.js:1:157\n    at Object.<anonymous> (/Users/mbrocato/WebstormProjects/StackTest/test.js:1:167)\n    at Module._compile (module.js:460:26)\n    at Object.Module._extensions..js (module.js:478:10)\n    at Module.load (module.js:355:32)\n    at Function.Module._load (module.js:310:12)\n    at Function.Module.runMain (module.js:501:10)\n    at startup (node.js:129:16)\n    at node.js:814:3\n```\n\nThe correct column number is 58.  Column 120 is actually past the end of the file (the last column is 108).\n\nI've tested this using 4.0.0 and 0.12.7.  Both yield the same results.\n",
        "labels": "confirmed-bug",
        "id": 45518
    },
    {
        "title": "Node 4 breaks making 16kb or greater requests",
        "body": "Related to this PR: https://github.com/nodejs/node/pull/2355  \nIn iojs 3.2.0 the following code works, in iojs 3.3.0 and node 4 the following code throws an error.\n\n``` js\nvar Http = require('http');\nvar Url = require('url');\n\nvar server = Http.createServer(function (req, res) {\n\n    res.writeHead(200);\n    res.end();\n});\nserver.listen(8080);\n\nvar uri = Url.parse('http://localhost:8080/');\nuri.method = 'post';\nvar req = Http.request(uri);\n\nvar payload = new Array(1640).join('0123456789');\nreq.write(payload);\nreq.end();\n```\n\nError:\n\n``` sh\n_http_server.js:515\n  this._handle.readStart();\n              ^\n\nTypeError: Cannot read property 'readStart' of null\n    at Socket.onSocketResume (_http_server.js:515:15)\n    at emitNone (events.js:67:13)\n    at Socket.emit (events.js:166:7)\n    at resume_ (_stream_readable.js:712:10)\n    at doNTCallback2 (node.js:429:9)\n    at process._tickCallback (node.js:343:17)\n```\n\nIf you change the payload size to just under 16kb it works:\n\n``` js\nvar Http = require('http');\nvar Url = require('url');\n\nvar server = Http.createServer(function (req, res) {\n\n    res.writeHead(200);\n    res.end();\n});\nserver.listen(8080);\n\nvar uri = Url.parse('http://localhost:8080/');\nuri.method = 'post';\nvar req = Http.request(uri);\n\nvar payload = new Array(1639).join('0123456789');\nreq.write(payload);\nreq.end();\n```\n",
        "labels": "confirmed-bug",
        "id": 45519
    },
    {
        "title": "Crash when working with node-ffi on Windows and Mac",
        "body": "Hi,\n\nOne of the popular npm modules is node-ffi. We are using it in our code for several different calls, but one of them leads to assertion error in node 3.x or later. As the same code of the node-ffi is working fine with iojs 2.x, node 0.12.x and node 0.10.x and after discussion with node-ffi owners, I came to opening this issue.\n\nIn our code we are trying to call methods from CoreFoundation.dll, which is part of iTunes installation. When we have some short calls and our process terminates, everything is working fine. But when our process starts working for some long time, we receive Assertion error: \n\n```\nAssertion failed: (obj_data) != (nullptr), file src\\node_buffer.cc,  line 150\n```\n\nIt looks like the garbage collector had collected something that we are trying to use later.\nSo we've tried to simplify the reproduction case and we've found that we fail only when trying to create ForeignFunction for specific method of the dll. Please note - we are not using them in the test script, just using ffi.\n\nYou can find the repro script and the output when DEBUG=\\* in [this gist](https://gist.github.com/rosen-vladimirov/7f44089c8c35960b7990)\nPlease note that the **crash is on global.gc() call**.\n\nI believe the problem is not in the dll itself, as the same code is working fine with node 0.10, node 0.12, iojs 2.x\n\nWe suspect that [this change](https://github.com/nodejs/node/issues/2484) had not fixed all issues related to buffers and garbage collection.\n\nThe original issue in **[node-ffi is here](https://github.com/node-ffi/node-ffi/issues/238)**. After some time of debugging, @unbornchikken stated:\n\n> The Windows one is interesting. I've tested our latest ffi with many-many DLL-s referenced, including OpenCL from various vendors, and everything works properly. However if I reference that iTunes DLL then I get a crash. I think iTunes is doing some library initialization logic that somehow corrupts io.js 3+'s memory. I can see in the debugger that the error is about GC thinks that memory is occupied but instead it gets nullified somehow. \n\nCould you please advise what's going wrong here? I know that it is related to specific npm module, not to the node itself, but the same module is working fine in all other cases and node versions, only the call to this specific method is failing on iojs 3.x and node 4.0.0.\n\nThanks in advance for your help!\n",
        "labels": "confirmed-bug",
        "id": 45520
    },
    {
        "title": "Strange name-changing behaviour in `console.log.bind`",
        "body": "This is something I've noticed when using the latest version (`4.0.0` as of writing this), and haven't tried it in earlier versions yet.\n\nIf you call `bind()` on `console.log`, it will modify the name of the original function and also keep tacking on `bound` to the name every time you call it.\n\nREPL example:\n\n``` js\n> console.log\n[Function: bound ]\n> console.log.bind(console)\n[Function: bound bound ]\n> console.log.bind(console)\n[Function: bound bound bound ]\n> console.log.bind(console)\n[Function: bound bound bound bound ]\n> console.log.bind(console)\n[Function: bound bound bound bound bound ]\n> console.log.bind(console)\n[Function: bound bound bound bound bound bound ]\n> console.log.bind(console)\n[Function: bound bound bound bound bound bound bound ]\n> console.log.bind(console)\n[Function: bound bound bound bound bound bound bound bound ]\n> console.log.bind(console)\n[Function: bound bound bound bound bound bound bound bound bound ]\n```\n\nIt also will modify the `name`s of the other `console` functions too:\n\n``` js\n> console\nConsole {\n  log: [Function: bound bound bound bound bound bound bound bound bound ],\n  info: [Function: bound bound bound bound bound bound bound bound bound ],\n  warn: [Function: bound bound bound bound bound bound bound bound bound ],\n  error: [Function: bound bound bound bound bound bound bound bound bound ],\n  dir: [Function: bound bound bound bound bound bound bound bound bound ],\n  time: [Function: bound bound bound bound bound bound bound bound bound ],\n  timeEnd: [Function: bound bound bound bound bound bound bound bound bound ],\n  trace: [Function: bound bound bound bound bound bound bound bound bound ],\n  assert: [Function: bound bound bound bound bound bound bound bound bound ],\n  Console: [Function: Console] }\n```\n\nAnd this behaviour doesn't seem to show up for other functions:\n\n``` js\n> let test = ()=>{}\nundefined\n> test.bind(null)\n[Function: bound ]\n> test.bind(null)\n[Function: bound ]\n> test.bind(null)\n[Function: bound ]\n> test.bind(null)\n[Function: bound ]\n```\n",
        "labels": "confirmed-bug",
        "id": 45521
    },
    {
        "title": "repl: backslashes confuse the multiline parser",
        "body": "Pasting this into the REPL:\n\n``` js\nfunction x() {\n  return '\\n';\n}\n```\n\nresults in\n\n```\n> function x() {\n...   return '\\n';\nSyntaxError: Unexpected end of input\n    at Object.exports.createScript (vm.js:24:10)\n    at REPLServer.defaultEval (repl.js:137:25)\n    at bound (domain.js:250:14)\n    at REPLServer.runBound [as eval] (domain.js:263:12)\n    at REPLServer.<anonymous> (repl.js:392:12)\n    at emitOne (events.js:82:20)\n    at REPLServer.emit (events.js:169:7)\n    at REPLServer.Interface._onLine (readline.js:210:10)\n    at REPLServer.Interface._line (readline.js:546:8)\n    at REPLServer.Interface._ttyWrite (readline.js:823:14)\n```\n\ncc: @thefourtheye\n",
        "labels": "confirmed-bug",
        "id": 45522
    },
    {
        "title": "Yet another segmentation fault in node-v4.0.0-rc.1",
        "body": "```\nvar cp = require('child_process');\ncp.spawn('/bin/ls', [], {\n  stdio: [\n    process.stdin,\n    process.stdout,\n    process.stderr,\n  ]\n});\n```\n\n![image](https://cloud.githubusercontent.com/assets/13315/9715880/5be410ea-5597-11e5-9096-946e56e1f8d6.png)\n",
        "labels": "confirmed-bug",
        "id": 45523
    },
    {
        "title": "intermittent unexpected socket closure on Mac OS X",
        "body": "Ref: https://github.com/nodejs/node/issues/1100\nRef: https://github.com/joyent/node/issues/16805\n\nThe following code will throw on OS X. It might take a while but it will happen. I usually see the error before runcount hits 2000.\n\n``` javascript\n'use strict';\nconst fork = require('child_process').fork;\nconst net = require('net');\nconst count = 12;\nconst port = 12346;\n\nif (process.argv[2] === 'child') {\n  let sockets = [];\n\n  process.on('message', function(m, socket) {\n    function sendClosed(id) {\n      process.send({ id: id, status: 'closed'});\n    };\n\n    if (m.cmd === 'new') {\n      sockets.push(socket);\n    }\n\n    if (m.cmd === 'close') {\n      if (sockets[m.id].destroyed) {\n        throw new Error('socket already destroyed');\n      }\n      sockets[m.id].once('close', sendClosed.bind(null, m.id));\n      sockets[m.id].destroy();\n    }\n\n    if (m.cmd === 'clear') {\n      sockets = [];\n    }\n  });\n\n} else {\n  const child = fork(process.argv[1], ['child']);\n\n  const server = net.createServer();\n  let sockets = [];\n\n  server.on('connection', function(socket) {\n    child.send({ cmd: 'new' }, socket);\n    sockets.push(socket);\n\n    if (sockets.length === count) {\n      closeSockets(0);\n    }\n  });\n\n  function createSockets() {\n    let j = count, client;\n    while (j--) {\n      client = net.connect(port, '127.0.0.1');\n    }\n  }\n\n  server.on('listening', function() {\n    createSockets();\n  });\n\n  let runCount = 0;\n  function closeSockets(i) {\n    if (i === count) {\n      console.log('run count: ' + ++runCount);\n      child.send({ cmd: 'clear' });\n      sockets = [];\n      return createSockets();\n    }\n\n    child.once('message', function(m) {\n      server.getConnections(function(err, num) {\n        closeSockets(i + 1);\n      });\n    });\n    child.send({ id: i, cmd: 'close' });\n  };\n\n  server.listen(port, '127.0.0.1');\n}\n```\n",
        "labels": "confirmed-bug",
        "id": 45524
    },
    {
        "title": "Computed props are not properly handled",
        "body": "Repost of microsoft/typescript#4419\n\nSeems like this problem is related to v8. Following code (using iojs@3.1)\n\n``` javascript\nvar prop = 'age'\nvar val = 42\nconsole.log([{ name: \"ivan\", [prop]: val }])\nconsole.log({ name: \"ivan\", [prop]: val })\n```\n\nproduces output\n\n```\n[ { name: 'ivan' } ]\n{ name: 'ivan', age: 42 }\n```\n",
        "labels": "confirmed-bug",
        "id": 45525
    },
    {
        "title": "Non-BMP variable names don't work from the REPL",
        "body": "https://github.com/joyent/node/issues/25854\n\n> type node in the terminal, and then paste this into the console:\n> `var ð=1;`\n",
        "labels": "confirmed-bug",
        "id": 45526
    },
    {
        "title": "io.js 3.0.0 memory leak",
        "body": "See Unitech/PM2#1500 for the bug report filed with PM2 before I realized it was being caused by io.js.\n\nWith io.js 2.4.0 and 2.5.0 there were no memory leaks for that module. Perhaps it could have something to do with the new Buffer implementation?\n",
        "labels": "confirmed-bug",
        "id": 45527
    },
    {
        "title": "2.5 broken on ARMv6",
        "body": "Both, the TGZ file as well as the binary itself seem to be broken for ARMv6.\n\nUnpacking the former shows the following\n\n```\ngzip: stdin: invalid compressed data--format violated\ntar: Unexpected EOF in archive\ntar: Unexpected EOF in archive\ntar: Error is not recoverable: exiting now\n```\n\nwhile the binary exits with a segmentation fault.\n",
        "labels": "confirmed-bug",
        "id": 45528
    },
    {
        "title": "net: Create socket and immediately destroy throws `AssertionError`",
        "body": "Starting in v2.3.2, this code which used to work, started to throw an `AssertionError`:\n\n``` js\nvar net = require('net')\n\nvar socket = net.connect(5000, '1.1.1.1') // nothing listening on this address\nsocket.on('error', function (err) {\n  console.log('caught error' + err.message)\n})\nsocket.destroy()\n```\n\nWith the following exception:\n\n```\nassert.js:89\n  throw new assert.AssertionError({\n        ^\nAssertionError: false == true\n    at connect (net.js:778:10)\n    at net.js:930:7\n    at doNTCallback0 (node.js:408:9)\n    at process._tickCallback (node.js:337:13)\n    at Function.Module.runMain (module.js:473:11)\n    at startup (node.js:117:18)\n    at node.js:948:3\n```\n\nI traced the issue back to this PR by @evanlucas, reviewed by @trevnorris and @cjihrig: https://github.com/nodejs/io.js/pull/2054\n",
        "labels": "confirmed-bug",
        "id": 45529
    },
    {
        "title": "vm.runInContext: eval a strict function",
        "body": "Evaluated strict functions, when ran inside `vm.ranInContext` do not capture environment.\n\nThis works (file `test.js`):\n\n``` js\nvar code = `\nvar foo = {m: 1};\n\nfunction bar() {\n  \"use strict\";\n  return foo;\n}\n`;\n\neval(code);\n\nbar();\n```\n\nNode session:\n\n```\n> vm.runInNewContext(fs.readFileSync('/Users/dmitrys/test.js', 'utf-8'))\n{ m: 1 }\n>\n```\n\nThis doesn't:\n\n``` js\nfunction main() {\n\n  var code = `\n    var foo = {m: 1};\n\n    function bar() {\n      \"use strict\";\n      return foo;\n    }\n  `;\n\n  eval(code);\n\n  bar(); // foo is not defined\n\n}\n\nmain();\n```\n\nNode session:\n\n```\n> vm.runInNewContext(fs.readFileSync('/Users/dmitrys/test.js', 'utf-8'))\nundefined:6\n      return foo;\n             ^\nReferenceError: foo is not defined\n    at bar (eval at main (evalmachine.<anonymous>:13:8), <anonymous>:6:14)\n    at main (evalmachine.<anonymous>:15:3)\n    at evalmachine.<anonymous>:19:1\n    at ContextifyScript.Script.runInNewContext (vm.js:18:15)\n    at Object.exports.runInNewContext (vm.js:49:17)\n    at repl:1:4\n    at REPLServer.defaultEval (repl.js:154:27)\n    at bound (domain.js:254:14)\n    at REPLServer.runBound [as eval] (domain.js:267:12)\n    at REPLServer.<anonymous> (repl.js:308:12)\n```\n\nAlso the code works if there is no `\"use strict\"` for `foo`.\n",
        "labels": "confirmed-bug",
        "id": 45530
    },
    {
        "title": "require fails to load 'package.json' when the module path contains Chinese characters on Windows.",
        "body": "Reproduce steps:\n- Create a Chinese-name node module directory that contains a package.json, like\n\n```\n ä¸­æ–‡ç›®å½•\n  |-- main.js\n  |-- package.json\n```\n\nAnd the content of `package.json`: \n\n```\n{\n  \"name\": \"test\",\n  \"productName\": \"test\",\n  \"main\": \"main.js\"\n}\n```\n- Type `require(\"<Chinese-path>\")` in iojs, then Error `Error: Cannot find module XXX` will arise.\n\nIt fails on iojs v2.4 and v3.0 rc4, but works on v1.6, I believe a regression issue. What's more, it seems only fails to read the `package.json` file. If we require a absolute js path(`<Chinese-path>/main.js`), it loads the module well.\n",
        "labels": "confirmed-bug",
        "id": 45531
    },
    {
        "title": "On receiving SIGWINCH, only stdout has its rows/columns updated or resize event fired",
        "body": "I would expect that if both stdout and stderr are bound to `/dev/tty` then resizes would trigger on both `tty` objects, but this is not the case.  This can be demonstrated with a simple script:\n\n``` javascript\nfunction setup (name, tty) {\n  console.error(name, 'started with rows:', tty.rows, 'columns:', tty.columns)\n  tty.on('resize', function () {\n    console.error('\\n',name, 'resized to rows:', tty.rows, 'columns:', tty.columns)\n  })\n}\n\nsetup('stdout', process.stdout)\nsetup('stderr', process.stderr)\n\nconsole.error('sleeping for 10 seconds')\nsetTimeout(function () {}, 10000)\n```\n\nRun and try resizing the window before the timeout. You'll see update events from `stdout` but none from `stderr`.\n",
        "labels": "confirmed-bug",
        "id": 45532
    },
    {
        "title": "node-gyp: win_delay_load_hook path exceeds MAX_PATH",
        "body": "Can you add https://github.com/TooTallNate/node-gyp/commit/da23b84f84985f57ce384cf33c6851f31be8fc61 to master as a floating patch until the new version is included in npm? This commit solves path names > MAX_PATH on windows like\n\n```\nC:\\Users\\Mathias\\Desktop\\test\\testprojekt\\node_modules\\socket.io\\node_modules\\engine.io\\node_modules\\ws\\node_modules\\utf-8-validate\\build\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\..\\Program Files\\iojs\\node_modules\\npm\\node_modules\\node-gyp\\src\\win_delay_load_hook.c\n```\n",
        "labels": "confirmed-bug",
        "id": 45533
    },
    {
        "title": "Streams: req.on('end') is sometimes called, sometimes not",
        "body": "Let's say I have a `server.on('request')` handler, with the code:\n\n``` js\nreq\n      .setEncoding('utf-8')\n      .on('data', function(data) {\n        body += data;\n        if (body.length > 10) {\n          res.statusCode = 413;\n          res.end(\"Your message is too big for my little chat\");\n        }\n      })\n      .on('end', function() {\n        console.log(\"END\");\n      });\n```\n\nIf the message is too big (413) should `on('end')` event trigger?\n\nP.S. I'm asking because it does trigger in this case (10 bytes limit), but it does not trigger in the case of a larger limit (1000000 bytes limit). The behavior - sometimes it triggers and sometimes not - seems weird.\n",
        "labels": "confirmed-bug",
        "id": 45534
    },
    {
        "title": "incorrect URL parsing",
        "body": "A regression was introduced between v0.10 and v0.12 for the URL parsing of an `http.get()` request. Basically, multi-byte characters are decoded as `'binary'` instead of either\n\n1) Being decoded as UTF-8\n2) Properly decoded into their '%' counterparts.\n\nTest and additional information is located at https://github.com/joyent/node/issues/25634#issuecomment-118970793\n",
        "labels": "confirmed-bug",
        "id": 45535
    },
    {
        "title": "vm.runInContext rewrites thrown error messages",
        "body": "``` js\n\"use strict\";\nconst vm = require(\"vm\");\n\ntry {\n  vm.runInContext(\"throw new Error('boo');\", vm.createContext({}));\n} catch (e) {\n  console.log(e.message);\n}\n```\n\nShould give: `boo`\n\nInstead gives:\n\n```\n$ iojs test.js\nevalmachine.<anonymous>:1\nthrow new Error('boo');\n      ^\nboo\n```\n\nModifying the actual `.message` property here seems very, very bad.\n\n/cc @indutny since I believe you made changes to the error-message related stuff a while back.\n",
        "labels": "confirmed-bug",
        "id": 45536
    },
    {
        "title": "\"is not a function\" error points to the wrong code point",
        "body": "Hi! Stumbled upon this minor issue where an \"is not a function\" error points to the wrong code point.\n\nTest case:\n\n``` js\n// config.js\nmodule.exports = function(path) {\n    var config = require(path ? path.resolve(process.cwd(), path) : '../config');\n    return config;\n};\n```\n\n``` js\n// index.js\nvar config = require('./config')('config');\n```\n\nResult:\n\n```\nconfig.js:4\n    var config = require(path ? path.resolve(process.cwd(), path) : '../config\n                                                     ^\nTypeError: process.cwd is not a function\n    at module.exports (config.js:4:54)\n```\n\nExpected (moved the arrow):\n\n```\n    var config = require(path ? path.resolve(process.cwd(), path) : '../config\n                                     ^\n```\n\nTested with:\n- nodejs v0.12.5\n- iojs v2.3.1\n\nIt really is a minor issue, but can be confusing when debugging.\n",
        "labels": "confirmed-bug",
        "id": 45537
    },
    {
        "title": "fs.watch doesn't support Chinese characters",
        "body": "![rename](https://cloud.githubusercontent.com/assets/7411098/8449463/3ced6f06-2004-11e5-8c59-d460bb07bcc3.png)\n# info\n\nio.js, v2.3.1\nWindows 7, 64bit\n",
        "labels": "confirmed-bug",
        "id": 45538
    },
    {
        "title": "zlib.createUnzip does not throw error on unexpected end of file",
        "body": "Here's the code:\n\n``` js\nvar zlib = require('zlib');\nvar fs = require('fs');\n\nfs.createReadStream('test.gz') \n  .pipe(zlib.createGunzip()) \n  .on('error', function(err) {\n    console.log(\"ERROR\", err);\n  })\n  .pipe(fs.createWriteStream('test')) \n  .on('finish', function() {\n    console.log(\"DONE\");\n  });\n```\n\nI take a big valid `gz` file and do:\n\n```\nhead -n 100000 ~/valid.gz > test.gz\n```\n\nNow `test.gz` is an unfinished archive:\n\n```\n> gunzip -k test.gz\ngunzip: test.gz: unexpected end of file\ngunzip: test.gz: uncompress failed\n```\n\n...But the aforementioned script shows DONE on this (unfinished) archive. No error.\nThere should be.\n",
        "labels": "confirmed-bug",
        "id": 45539
    },
    {
        "title": "Closing fs streams early could call close during or before I/O",
        "body": "Suppose you `fs.createWriteStream`, pipe something into it, and then need to close the stream early because of an error somewhere else.\n\n``` javascript\nvar writeStream = fs.createWriteStream(someFile);\nsource.pipe(writeStream);\n\n// ...time passes...\n\nsource.unpipe(writeStream);\nwriteStream.close();\n```\n\nCalling `close` on the write stream in this case could cause `close` to be called on the underlying file descriptor while a write operation is still pending. Or, if more than one worker thread is being used, it's possible for the `close` to happen before the write begins.\n\nSpecifically, `WriteStream.close` does not check whether a `fs.write` operation is pending before calling `fs.close`:\n\nhttps://github.com/nodejs/io.js/blob/41951d45b6df789d7e9cf134f0029b0e791706c4/lib/fs.js#L1770\n\nIt seems like this makes it impossible to safely close a write stream early. I've never seen bad behavior from this in practice though, so maybe I'm misunderstanding something.\n\nAre we instead supposed to call `Writable.end` and should never use `WriteStream.close`?\n",
        "labels": "confirmed-bug",
        "id": 45540
    },
    {
        "title": "Win: Can't load a module with a long path",
        "body": "Since v2.2.0 (probably, related to 1bbf8d07), `require()` can't load a module with a path longer than 260 characters on Windows.\n\nv2.1.0:\n\n```\n> require('C:/Users/koichik/git/isomorphic/fluxible-demo/node_modules/webpack/node_modules/watchpack/node_modules/chokidar/node_modules/anymatch/node_modules/micromatch/node_modules/braces/node_modules/expand-range/node_modules/fill-range/node_modules/repeat-string/index.js')\n[Function: repeat]\n```\n\nv2.3.0:\n\n```\n> require('C:/Users/koichik/git/isomorphic/fluxible-demo/node_modules/webpack/node_modules/watchpack/node_modules/chokidar/node_modules/anymatch/node_modules/micromatch/node_modules/braces/node_modules/expand-range/node_modules/fill-range/node_modules/repeat-string/index.js')\nError: Cannot find module 'C:/Users/koichik/git/isomorphic/fluxible-demo/node_modules/webpack/node_modules/watchpack/node_modules/chokidar/node_modules/anymatch/node_modules/micromatch/node_modules/braces/node_modules/expand-range/node_modules/fill-range/node_modules/repeat-string/index.js'\n    at Function.Module._resolveFilename (module.js:332:15)\n    at Function.Module._load (module.js:282:25)\n    at Module.require (module.js:361:17)\n    at require (module.js:380:17)\n    at repl:1:1\n    at REPLServer.defaultEval (repl.js:154:27)\n    at bound (domain.js:254:14)\n    at REPLServer.runBound [as eval] (domain.js:267:12)\n    at REPLServer.<anonymous> (repl.js:308:12)\n    at emitOne (events.js:77:13)\n```\n",
        "labels": "confirmed-bug",
        "id": 45541
    },
    {
        "title": "util.isBuffer(...) fails on 2.3.0",
        "body": "Someone forgot to import `Buffer` in `util.js`:\n\n``` console\n$ node -v\nv2.3.0\n$ node\n> util.isBuffer('foo');\nTypeError: Expecting a function in instanceof check, but got undefined\n    at Object.isBuffer (util.js:666:25)\n    at repl:1:6\n    at REPLServer.defaultEval (repl.js:154:27)\n    at bound (domain.js:254:14)\n    at REPLServer.runBound [as eval] (domain.js:267:12)\n    at REPLServer.<anonymous> (repl.js:308:12)\n    at emitOne (events.js:77:13)\n    at REPLServer.emit (events.js:169:7)\n    at REPLServer.Interface._onLine (readline.js:209:10)\n    at REPLServer.Interface._line (readline.js:548:8)\n```\n\nWorks fine after downgrading to 2.2.1:\n\n``` console\n$ node -v\nv2.2.1\n$ node\n> util.isBuffer('foo');\nfalse\n```\n\nSeems related to [`b5b8ff1`](https://github.com/nodejs/io.js/commit/b5b8ff117c8581945d0c8c3a4b18d53f4b33b86f)\n",
        "labels": "confirmed-bug",
        "id": 45542
    },
    {
        "title": "Gulp dependencies not found",
        "body": "I have this issue also open (well, now closed but not fixed) in Gulp's GitHub repo. The problem is that Gulp has stopped working in recent IO versions (I am using Windows 8.1 and Gulp 3.9.0, and I have just updated to io.js 2.3.0). The error message is:\n\n**Cannot find module 'clone'**\n\nAnd the full log is:\n\n```\nError: Cannot find module 'clone'\n    at Function.Module._resolveFilename (module.js:332:15)\n    at Function.Module._load (module.js:282:25)\n    at Module.require (module.js:361:17)\n    at require (module.js:380:17)\n    at Object.<anonymous> (C:\\Users\\<username>\\AppData\\Roaming\\npm\\node_modules\\gulp\\node_modules\\gulp-util\\node_modules\\vinyl\\index.js:2:13)\n    at Module._compile (module.js:426:26)\n    at Object.Module._extensions..js (module.js:444:10)\n    at Module.load (module.js:351:32)\n    at Function.Module._load (module.js:306:12)\n    at Module.require (module.js:361:17)\n```\n\nI have completely removed all my global modules and even used `npm cache clean`. I have reinstalled the modules with my user and as administrator. I have done it globally and in my project directory and nothing happens. The error is still there.\n\nI have installed gulp with an older version of io.js (to avoid npm problems) and then, I have try to run gulp with the following versions of io.js (without reinstalling gulp) and the result has been the following:\n- iojs-v2.0.2-x64 --> working\n- iojs-v2.1.0-x64 --> working\n- iojs-v2.2.0-x64 --> failed\n- iojs-v2.2.1-x64 --> failed\n- iojs-v2.3.0-x64 --> failed\n\nRight now I am using **iojs-v2.1.0-x64** and it works just fine.\n\nCould you please help me?\n\nThanks\n",
        "labels": "confirmed-bug",
        "id": 45543
    },
    {
        "title": "net: server.maxConnections does not trigger error on some platforms",
        "body": "See #1881 for discussion and some details. Exceeding `server.maxConnections` on OS X (and <strike>probably</strike> others) does not trigger ECONNRESET <strike>(at least in some situations) but it seemingly should</strike> and it does on FreeBSD <strike>(and probably others)</strike>.\n",
        "labels": "confirmed-bug",
        "id": 45544
    },
    {
        "title": "npm: SSL error on v2.2.0",
        "body": "Attempting to install a module with npm fails with the following error:\n`SSL Error: https://registry.npmjs.org/test does not support SSL.`\n\nReproduced on Windows 8.1 x64 and Windows 10 x64.\n\nThe error only happens for modules that were never installed on the machine. My guess is that npm uses the local cache for known modules.\n\n```\nC:\\Users\\Michael\\test>iojs -v\nv2.2.0\n\nC:\\Users\\Michael\\test>npm -v\n2.11.0\n\nC:\\Users\\Michael\\test>npm install abc\nnpm ERR! Windows_NT 6.3.9600\nnpm ERR! argv \"C:\\\\Program Files\\\\iojs\\\\node.exe\" \"C:\\\\Program Files\\\\iojs\\\\node\n_modules\\\\npm\\\\bin\\\\npm-cli.js\" \"install\" \"abc\"\nnpm ERR! node v2.2.0\nnpm ERR! npm  v2.11.0\nnpm ERR! code ESSL\n\nnpm ERR! SSL Error: https://registry.npmjs.org/abc does not support SSL\nnpm ERR!\nnpm ERR! If you need help, you may report this error at:\nnpm ERR!     <https://github.com/npm/npm/issues>\n\nnpm ERR! Please include the following file with any support request:\nnpm ERR!     C:\\Users\\Michael\\test\\npm-debug.log\n```\n\n```\nC:\\Users\\Michael\\test2>iojs -v\nv2.1.0\n\nC:\\Users\\Michael\\test2>npm -v\n2.10.1\n\nC:\\Users\\Michael\\test2>npm install abc\nabc@0.6.1 node_modules\\abc\n```\n",
        "labels": "confirmed-bug",
        "id": 45545
    },
    {
        "title": "-r/--require flag for npm modules",
        "body": "Given the following steps:\n\n```\nnpm install heapdump\nnode -r heapdump file.js\n```\n\nI get the following error:\n\n```\nError: Cannot find module 'heapdump'\n    at Function.Module._resolveFilename (module.js:337:15)\n    at Function.Module._load (module.js:287:25)\n    at node.js:858:16\n    at Array.forEach (native)\n    at Function.startup.preloadModules (node.js:857:32)\n    at startup (node.js:95:17)\n    at node.js:963:3\n```\n\nMy expectation was the module would be resolved the same way as if I were to do:\n\n```\nrequire('heapdump')\n```\n",
        "labels": "confirmed-bug",
        "id": 45546
    },
    {
        "title": "url: parse() fails if auth contain a colon or ampersand",
        "body": "_I originally reported this at joyent/nodejs. At @jasnell suggestion, I'm reporting it here, so that the right people notice it. https://github.com/joyent/node/issues/25353_\n#### The Problem\n\nIf the user or the password component of auth contains a colon or ampersand, url.parse() fails.\n\n``` javascript\nvar url = require('url');\n\nvar user = encodeURIComponent('us:er');\nvar password = encodeURIComponent('pass:word');\nvar uri = 'http://' + user + ':' + password + '@localhost/';\nconsole.log(uri); // http://us%3Aer:pass%3Aword@localhost/\n\nvar parsed = url.parse(uri);\nconsole.log(parsed.auth); // us:er:pass:word\n```\n\nThe output of parse() is not understood by format().\n\n``` javascript\nconsole.log(url.format(parsed)); // http://us:er%3Apass%3Aword@localhost/\n```\n\nBrowsers handled it this way:\n\n``` javascript\nvar parser = document.createElement('a');\nparser.href = \"http://us%3Aer:pass%3Aword@example.com:3000/path%3Ename/?search=some%20phrase#hash\";\n\nconsole.log(parser.hash); // #hash\nconsole.log(parser.host); // example.com:3000\nconsole.log(parser.hostname); // example.com\nconsole.log(parser.href); // http://us%3Aer:pass%3Aword@example.com:3000/path%3Ename/?search=some%20phrase#hash\nconsole.log(parser.origin); // http://example.com:3000\nconsole.log(parser.password); // pass%3Aword\nconsole.log(parser.pathname); // /path%3Ename/\nconsole.log(parser.port); // 3000\nconsole.log(parser.protocol); // http:\nconsole.log(parser.search); // ?search=some%20phrase\nconsole.log(parser.username); // us%3Aer\n```\n\nI think the best solution is (like the browser) to split auth into two fields.\nI created a PR that does this: https://github.com/joyent/node/pull/25359\n",
        "labels": "confirmed-bug",
        "id": 45547
    },
    {
        "title": "Debug process didn't close after finish debugging",
        "body": "In both `io.js` and `node.js >= 0.12` have this issue.\n\nOS:\n\nosx & ubuntu 14\n\nReproduce steps:\n- Create a file:\n\na.js\n\n``` js\nconsole.log('debug');\n```\n-  run `node debug a.js`\n-  press `c` to `continue`\n\nThen the stdout should have:\n\n``` bash\n> debug\n> program terminated\n```\n\nBut currently, it only have\n\n``` bash\n> debug\n```\n-  When I try to press `c` to `continue` and make the process close, but it just stuck there waiting for v8 response.\n\nIt happen when I write my own debugger. It seems that the debug server should knows that the process is terminated, but it didn't. \n",
        "labels": "confirmed-bug",
        "id": 45548
    },
    {
        "title": "cannot resolve main script if -r options specified, flag with value specified and main script file path contains only file name.",
        "body": "```\niojs --expose_debug_as=v8debug -r ./p.js file.js\nmodule.js:339\n    throw err;\n          ^\nError: Cannot find module 'file.js'\n```\n\nWorks correctly, if \"--expose_debug_as=v8debug \" is not specified.\n\nTest project (files file.js and p.js) â€” https://dl.dropboxusercontent.com/u/43511007/s/test.zip\n",
        "labels": "confirmed-bug",
        "id": 45549
    },
    {
        "title": "gyp: `win_delay_load_hook` is false again",
        "body": "It looks like when npm was updated recently, [one](https://github.com/iojs/io.js/commit/30e83d2e84b2a3815bbd6abc22e6abed982fa7db) of the floated patches reverted the [default value for `win_delay_load_hook` in `addon.gypi`](https://github.com/iojs/io.js/commit/3bda6cbfa4a9bb073790d53bc14e85b6e575bbe5).\n",
        "labels": "confirmed-bug",
        "id": 45550
    },
    {
        "title": "`dns.resolve` fails when the io/node process starts without an active network connection",
        "body": "To reproduce:\n1. Disable your Internet connection (this needs to be done first)\n2. Start a io/node repl\n3. Enter the following into the repl and note that it fails with `ECONNREFUSED`:\n   \n   var dns = require(\"dns\");\n   dns.resolve(\"google.com\", function(err) { if (err) { console.log(err); } else { console.log(\"online\"); }})\n4. Re-enable your Internet connection\n5. Run `dns.resolve(\"google.com\", function(err) { if (err) { console.log(err); } else { console.log(\"online\"); }})` again, and note that it still fails\n\nIf the process starts before the Internet connection is disabled, it will work as expected once the connection is re-enabled.\n\nFor what it's worth, this bug doesn't affect `dns.lookup` (which according to the docs is implemented differently than `dns.resolve`).\n",
        "labels": "confirmed-bug",
        "id": 45551
    },
    {
        "title": "Race condition on history file with multiple REPLs",
        "body": "via @substack\n\n```\n<substack> found another repl history bug, if you have 2 repls open at once it doesn't lock the file\n<substack> but a bit hard to reproduce since they've got to be writing at the same time\n<substack> but I already ran into it just doing normal things with 2 repls open at once\n```\n",
        "labels": "confirmed-bug",
        "id": 45552
    },
    {
        "title": "net.listen does not emit 'listening' event when in --eval mode",
        "body": "Failing unit test submitted as PR #1581\n\nI found this when trying to confirm the format of the address object. The following hangs on most releases of node higher than 0.10.38:\n\n```\nnode -e \"require('net').createServer().listen(0, function() { console.log(this.address()); this.close(); });\"\n```\n\nIt seems that Server does not emit a listen event when no address is specified _and_ is called in eval mode.\n\nI don't fully understand _how_ the regression was introduced, but `git bisect` seemed pretty confident that it was in 5b636feaa8550ca39229e7d8805c73c72f7995dc.\n\n/to @trevnorris for the indicated commit\n/cc @piscisaureus @sam-github @brendanashworth \n",
        "labels": "confirmed-bug",
        "id": 45553
    },
    {
        "title": "url: errounous hash appended on url.format",
        "body": "This is breaking npm installs and should be fixed before 2.0.0.\n\nEncountered in https://github.com/npm/normalize-git-url/blob/master/normalize-git-url.js\n#### 1.8.1\n\n``` js\n> parsed = url.parse(\"git+ssh://git@github.com:organization/repo.git#hashbrowns\")\n> parsed.hash = ''\n> url.format(parsed)\n'git+ssh://git@github.com/:organization/repo.git'\n```\n#### 2.0.0\n\n``` js\n> parsed = url.parse(\"git+ssh://git@github.com:organization/repo.git#hashbrowns\")\n> parsed.hash = ''\n> url.format(parsed)\n> 'git+ssh://git@github.com/:organization/repo.git#'\n```\n\ncc: @petkaantonov @domenic @rvagg \n",
        "labels": "confirmed-bug",
        "id": 45554
    },
    {
        "title": "fs.write crashes on non-integer fd",
        "body": "```\nfs.write(null, new Buffer(1), 0, 1)\n\niojs: ../src/node_file.cc:782: void node::WriteBuffer(const v8::FunctionCallbackInfo<v8::Value>&): Assertion `args[0]->IsInt32()' failed.\nAborted (core dumped)\n```\n",
        "labels": "confirmed-bug",
        "id": 45555
    },
    {
        "title": "segmentation fault for buffer.copy() with no args",
        "body": "To reproduce from the command line:\n\n```\n$ iojs -e \"Buffer(10).copy()\"\n[1]    87376 segmentation fault  iojs -e \"Buffer(10).copy()\"\n```\n\nWhile this isn't valid input to `copy`, this should probably not segfault.\n\nTested on iojs 1.8.1. Same issue in node 0.12.2.\n",
        "labels": "confirmed-bug",
        "id": 45556
    },
    {
        "title": "iojs.exe randomly terminates on Windows",
        "body": "The `iojs.exe` process in question is running one of `http` and `https` servers.\n\nThe problem seems to occur if a separate `iojs` process is running, and is subsequently terminated, e.g. manually by pressing `Ctrl+C` within a Command Prompt window, then the aforementioned process would terminate as well, whether it is running in the background or in (a separate) Command Prompt window.\n",
        "labels": "confirmed-bug",
        "id": 45557
    },
    {
        "title": "undefined is passed as hostname to tls.checkServerIdentity",
        "body": "Hi all,\n\nWhen using `tls.connect(options)` with no `options.host` I get this:\n\n> Hostname/IP doesn't match certificate's altnames: \"Host: undefined. is not cert's CN: localhost\"\n\nI tried to track this and it seems [tls.checkServerIdentity](https://github.com/iojs/io.js/blob/26327757f8b342eb91df71f1fdf34a855e29aa71/lib/tls.js#L75) get called with `hostname` as `undefined`.\n\nExamining the stack, it gets called by [_tls_wrap.js:913](https://github.com/iojs/io.js/blob/26327757f8b342eb91df71f1fdf34a855e29aa71/lib/_tls_wrap.js#L913) and `hostname` is defined in [_tls_wrap.js:859](https://github.com/iojs/io.js/blob/26327757f8b342eb91df71f1fdf34a855e29aa71/lib/_tls_wrap.js#L859).\n\nAs you can see, `hostname` is `undefined` because neither `options.servername`, `options.host` nor `options.socket` are set.\n\nThe tls.connect doc says: \"If host is omitted, it defaults to localhost\", so shouldn't it actually set `options.host` to `\"localhost\"` in this case?\n\nAdding it to [defaults](https://github.com/iojs/io.js/blob/26327757f8b342eb91df71f1fdf34a855e29aa71/lib/_tls_wrap.js#L849) may solve this, but I have very little understanding of this part of the code to be sure.\n\nIs it a bug or intended?\n\nBest regards\n",
        "labels": "confirmed-bug",
        "id": 45558
    },
    {
        "title": "isNaN(Buffer.prototype) crashes",
        "body": "> isNaN(Buffer.prototype)\n> Assertion failed: ((obj_data) != (nullptr)), function StringSlice, file ../src/node_buffer.cc, line 237.\n> Abort trap: 6\n",
        "labels": "confirmed-bug",
        "id": 45559
    },
    {
        "title": "url.resolve auth issue",
        "body": "``` js\nrequire(\"url\").resolve(\n  \"http://user:pass@fakeurl2.com:80/path/resource.html?query#hash\",\n  \"http://fakeurl.com/path/resource.html?query#hash\"\n);\n```\n\nproduces `http://user:pass@fakeurl.com/path/resource.html?query#hash`\n\nNode.js has been doing this for as long as I've been using it. How can it be correct to add auth information from one absolute url to another absolute url?\n",
        "labels": "confirmed-bug",
        "id": 45560
    },
    {
        "title": "1.7.1 --shared-zlib fails",
        "body": "#1335 introduced a bug with option handling, it's using code like:\n\n```\nif b(options.shared_zlib) == True:\n```\n\n`b` returns 'true' or 'false' as a string and 'true' != True, so any builds using --shared-zlib currently fail with a linker error.\n",
        "labels": "confirmed-bug",
        "id": 45561
    },
    {
        "title": "building for mips ",
        "body": "Hi all!\n\nI am referring to issue #1032. I am building io.js 1.7.1 for mips and get following error:\n\n```\n../deps/v8/src/base/logging.cc:9:23: fatal error: execinfo.h: No such file or directory\n```\n\nApplying following patch to v8 solved my problem:\n\nhttps://codereview.chromium.org/1066573005/patch/1/10001\n\nMay I request to include the patch into the next version? \n\nMany thanks for your work on io.js \n",
        "labels": "confirmed-bug",
        "id": 45562
    },
    {
        "title": "readline: splitted escape sequences are processed incorrectly",
        "body": "I'm running io.js inside LXC container console (`lxc-console`) in Ubuntu 14.04 terminal.\n\nWhen I press and hold an arrow key, node.js sometimes receives escape sequences splitted into multiple chunks:\n\n``` sh\n$ node -e 'process.stdin.setRawMode(true);process.stdin.on(\"data\", function(d){console.log(d)})'\n<Buffer 1b 5b 44>\n<Buffer 1b 5b 44>\n<Buffer 1b>\n<Buffer 5b 44>\n<Buffer 1b 5b 44>\n```\n\nHere you can see `\\x1b[D` (arrow left) is broken into `\\x1b` + `[D`.\n\nReadline doesn't handle those, because it assumes that the entire escape sequence is contained within a data chunk. So it skips escape character itself, and `[D` is getting printed to the terminal:\n\n``` sh\n$ node\n> console.log('h[Dello world')\n```\n\nHere is a [screenshot](https://cloud.githubusercontent.com/assets/999113/7106060/ab5a54f0-e13d-11e4-9309-5893dfd1072e.gif).\n\nTrying to find a way to fix it at the moment. Any ideas?\n",
        "labels": "confirmed-bug",
        "id": 45563
    },
    {
        "title": "Illegal instruction when calling Math.exp()",
        "body": "I'm using io.js on a Raspberry Pi (Raspbian) and calling `Math.exp()` generates an `illegal instruction`.\nI have tryed many packages: iojs-v1.2.0-linux-armv6l.tar.gz, iojs-v1.4.1-linux-armv6l.tar.gz and iojs-v1.6.4-linux-armv6l.tar.gz\nFor example, a simple file with:\n\n```\nvar v = Math.exp(-0.5);\n```\n\nproduces this error.\n",
        "labels": "confirmed-bug",
        "id": 45564
    },
    {
        "title": "\"glibc detected /usr/bin/iojs: malloc(): smallbin double linked list corrupted\" in process output",
        "body": "Got the following dump in process' stdout/stderr (logfile)\n\n```\n*** glibc detected *** /usr/bin/iojs: malloc(): smallbin double linked list corrupted: 0x000000000281f160 ***\n======= Backtrace: =========\n/lib64/libc.so.6(+0x75e66)[0x7f31ab97ae66]\n/lib64/libc.so.6(+0x79c3f)[0x7f31ab97ec3f]\n/lib64/libc.so.6(__libc_malloc+0x71)[0x7f31ab97f6b1]\n/usr/bin/iojs(_ZN2v88internal8Malloced3NewEm+0xd)[0x7da39d]\n/usr/bin/iojs(_ZN2v88internal15RuntimeProfiler11OptimizeNowEv+0xf1)[0xb29511]\n/usr/bin/iojs(_ZN2v88internal10StackGuard16HandleInterruptsEv+0x202)[0x93aec2]\n[0x2d0feaa060bb]\n======= Memory map: ========\n00400000-01074000 r-xp 00000000 fd:00 133600                             /usr/bin/iojs\n01274000-0128c000 rw-p 00c74000 fd:00 133600                             /usr/bin/iojs\n0128c000-01298000 rw-p 00000000 00:00 0 \n0275b000-06231000 rw-p 00000000 00:00 0                                  [heap]\n7a500000-7a600000 rw-p 00000000 00:00 0 \n1b8c100000-1b8c200000 rw-p 00000000 00:00 0 \n5092700000-5092800000 rw-p 00000000 00:00 0 \n218afc00000-218afc15000 rw-p 00000000 00:00 0 \n2c300000000-2c301000000 rw-p 00000000 00:00 0 \n2c301000000-2c302000000 rw-p 00000000 00:00 0 \n2e664300000-2e664400000 rw-p 00000000 00:00 0 \n30427d00000-30427e00000 rw-p 00000000 00:00 0 \n32837b00000-32837c00000 rw-p 00000000 00:00 0 \n43cd9900000-43cd9a00000 rw-p 00000000 00:00 0 \n4ca1d300000-4ca1d400000 rw-p 00000000 00:00 0 \n4f2b5b00000-4f2b5c00000 rw-p 00000000 00:00 0 \n53394100000-53394306000 rw-p 00000000 00:00 0 \n54123800000-54123900000 rw-p 00000000 00:00 0 \n5cd9da00000-5cd9db00000 rw-p 00000000 00:00 0 \n5f0cfa00000-5f0cfc7d000 rw-p 00000000 00:00 0 \n6370f500000-6370f600000 rw-p 00000000 00:00 0 \n65baf900000-65bafa00000 rw-p 00000000 00:00 0 \n6a441600000-6a441700000 rw-p 00000000 00:00 0 \n6d156600000-6d156700000 rw-p 00000000 00:00 0 \n71be6000000-71be6100000 rw-p 00000000 00:00 0 \n72eeb000000-72eeb100000 rw-p 00000000 00:00 0 \n744b8200000-744b8300000 rw-p 00000000 00:00 0 \n83918200000-8391847d000 rw-p 00000000 00:00 0 \n874cd700000-874cd800000 rw-p 00000000 00:00 0 \n87639700000-87639906000 rw-p 00000000 00:00 0 \n8bd1ee00000-8bd1ef00000 rw-p 00000000 00:00 0 \n8fc02000000-8fc02100000 rw-p 00000000 00:00 0 \n9179a100000-9179a200000 rw-p 00000000 00:00 0 \n940caf00000-940cb000000 rw-p 00000000 00:00 0 \n9a8ae200000-9a8ae300000 rw-p 00000000 00:00 0 \n9af8d400000-9af8d500000 rw-p 00000000 00:00 0 \n9f391b00000-9f391c00000 rw-p 00000000 00:00 0 \n9f7dee00000-9f7def00000 rw-p 00000000 00:00 0 \na26a1e00000-a26a1f00000 rw-p 00000000 00:00 0 \na43a1800000-a43a1900000 rw-p 00000000 00:00 0 \na6498b31000-a6498f31000 ---p 00000000 00:00 0 \nba7e8b00000-ba7e8c00000 rw-p 00000000 00:00 0 \nbee4d200000-bee4d300000 rw-p 00000000 00:00 0 \nc12d7900000-c12d7a00000 rw-p 00000000 00:00 0 \nc3030800000-c3030900000 rw-p 00000000 00:00 0 \nc668df00000-c668e000000 rw-p 00000000 00:00 0 \nccce3900000-ccce3b0c000 rw-p 00000000 00:00 0 \nd28e0800000-d28e0900000 rw-p 00000000 00:00 0 \nd7e6a200000-d7e6a300000 rw-p 00000000 00:00 0 \nd8eed300000-d8eed400000 rw-p 00000000 00:00 0 \nd9778800000-d9778900000 rw-p 00000000 00:00 0 \ndda22a00000-dda22b00000 rw-p 00000000 00:00 0 \nde167b00000-de167c00000 rw-p 00000000 00:00 0 \ne5f78600000-e5f78700000 rw-p 00000000 00:00 0 \nea9e1800000-ea9e1900000 rw-p 00000000 00:00 0 \nf34ffe00000-f34fff00000 rw-p 00000000 00:00 0 \nf9b8c800000-f9b8c900000 rw-p 00000000 00:00 0 \nfcb67c00000-fcb67d00000 rw-p 00000000 00:00 0 \nfe549100000-fe549200000 rw-p 00000000 00:00 0 \nff57cc00000-ff57cd00000 rw-p 00000000 00:00 0 \n1006df000000-1006df100000 rw-p 00000000 00:00 0 \n115dbcb00000-115dbcc00000 rw-p 00000000 00:00 0 \n11cd11500000-11cd11600000 rw-p 00000000 00:00 0 \n11e31e400000-11e31e67d000 rw-p 00000000 00:00 0 \n1270c7a00000-1270c7b00000 rw-p 00000000 00:00 0 \n12a3c9e00000-12a3c9f00000 rw-p 00000000 00:00 0 \n13539ea00000-13539ec7d000 rw-p 00000000 00:00 0 \n13947e100000-13947e200000 rw-p 00000000 00:00 0 \n13c501800000-13c501900000 rw-p 00000000 00:00 0 \n1455a5e00000-1455a5f00000 rw-p 00000000 00:00 0 \n156e28000000-156e28100000 rw-p 00000000 00:00 0 \n15cec4d00000-15cec4e00000 rw-p 00000000 00:00 0 \n168b04c00000-168b04e05000 rw-p 00000000 00:00 0 \n169908200000-169908300000 rw-p 00000000 00:00 0 \n16d00da00000-16d00db00000 rw-p 00000000 00:00 0 \n16e8f4c00000-16e8f4e06000 rw-p 00000000 00:00 0 \n16fd5db00000-16fd5dc00000 rw-p 00000000 00:00 0 \n172018200000-172018300000 rw-p 00000000 00:00 0 \n174f08f00000-174f09000000 rw-p 00000000 00:00 0 \n17e748a00000-17e748b00000 rw-p 00000000 00:00 0 \n18aa08b00000-18aa08c00000 rw-p 00000000 00:00 0 \n1996a0900000-1996a0a00000 rw-p 00000000 00:00 0 \n19a67e000000-19a67e100000 rw-p 00000000 00:00 0 \n19b51c700000-19b51c800000 rw-p 00000000 00:00 0 \n19ceeba00000-19ceebb00000 rw-p 00000000 00:00 0 \n1a3bc8200000-1a3bc8300000 rw-p 00000000 00:00 0 \n1a91e5200000-1a91e5300000 rw-p 00000000 00:00 0 \n1a9a18d00000-1a9a18e00000 rw-p 00000000 00:00 0 \n1aa034700000-1aa034800000 rw-p 00000000 00:00 0 \n1b53b4000000-1b53b4100000 rw-p 00000000 00:00 0 \n1b7539400000-1b7539500000 rw-p 00000000 00:00 0 \n1c24c1bca000-1c24c1dca000 rw-p 00000000 00:00 0 \n1c50c9100000-1c50c9200000 rw-p 00000000 00:00 0 \n1cf06d700000-1cf06d800000 rw-p 00000000 00:00 0 \n1d5a6f600000-1d5a6f700000 rw-p 00000000 00:00 0 \n1d6901100000-1d6901200000 rw-p 00000000 00:00 0 \n1d8f10600000-1d8f10700000 rw-p 00000000 00:00 0 \n1e5226200000-1e5226300000 rw-p 00000000 00:00 0 \n1eb746400000-1eb74667d000 rw-p 00000000 00:00 0 \n1f7695700000-1f7695800000 rw-p 00000000 00:00 0 \n200b1c000000-200b1c100000 rw-p 00000000 00:00 0 \n20587e800000-20587e900000 rw-p 00000000 00:00 0 \n208154000000-208154100000 rw-p 00000000 00:00 0 \n2088a0c00000-2088a0d00000 rw-p 00000000 00:00 0 \n20fd77600000-20fd77700000 rw-p 00000000 00:00 0 \n211f2e900000-211f2ea00000 rw-p 00000000 00:00 0 \n212d79e00000-212d79e25000 rw-p 00000000 00:00 0 \n21ff7c000000-21ff7c100000 rw-p 00000000 00:00 0 \n220257e00000-220257f00000 rw-p 00000000 00:00 0 \n23dda3000000-23dda3100000 rw-p 00000000 00:00 0 \n23f267400000-23f267500000 rw-p 00000000 00:00 0 \n240701500000-240701600000 rw-p 00000000 00:00 0 \n245fe2b00000-245fe2c00000 rw-p 00000000 00:00 0 \n24c82e500000-24c82e706000 rw-p 00000000 00:00 0 \n24f58fb00000-24f58fc00000 rw-p 00000000 00:00 0 \n251467b00000-251467c00000 rw-p 00000000 00:00 0 \n251ba3700000-251ba3800000 rw-p 00000000 00:00 0 \n254026e00000-254026f00000 rw-p 00000000 00:00 0 \n254fb5600000-254fb5700000 rw-p 00000000 00:00 0 \n25669a700000-25669a800000 rw-p 00000000 00:00 0 \n25978df00000-25978e000000 rw-p 00000000 00:00 0 \n25c9e2c00000-25c9e2d00000 rw-p 00000000 00:00 0 \n2644c2f00000-2644c3000000 rw-p 00000000 00:00 0 \n2695b1000000-2695b1100000 rw-p 00000000 00:00 0 \n26cbc8f00000-26cbc9000000 rw-p 00000000 00:00 0 \n26d215a00000-26d215b00000 rw-p 00000000 00:00 0 \n270d2c100000-270d2c200000 rw-p 00000000 00:00 0 \n273b41000000-273b41100000 rw-p 00000000 00:00 0 \n275b99700000-275b99800000 rw-p 00000000 00:00 0 \n27d3c5100000-27d3c5200000 rw-p 00000000 00:00 0 \n27fc92500000-27fc92600000 rw-p 00000000 00:00 0 \n280767800000-280767900000 rw-p 00000000 00:00 0 \n280888500000-280888600000 rw-p 00000000 00:00 0 \n288501000000-288501100000 rw-p 00000000 00:00 0 \n28bbaef00000-28bbaf000000 rw-p 00000000 00:00 0 \n28dbc0c00000-28dbc0d00000 rw-p 00000000 00:00 0 \n295efe300000-295efe400000 rw-p 00000000 00:00 0 \n29f767c00000-29f767d00000 rw-p 00000000 00:00 0 \n2a6708900000-2a6708a00000 rw-p 00000000 00:00 0 \n2a7096300000-2a7096400000 rw-p 00000000 00:00 0 \n2acfa1800000-2acfa1900000 rw-p 00000000 00:00 0 \n2ae1d0300000-2ae1d0400000 rw-p 00000000 00:00 0 \n2b02d5700000-2b02d5800000 rw-p 00000000 00:00 0 \n2b79cb600000-2b79cb700000 rw-p 00000000 00:00 0 \n2bf6e0ec3000-2bf6e0f00000 ---p 00000000 00:00 0 \n2bf6e0f00000-2bf6e0f20000 rw-p 00000000 00:00 0 \n2bf6e0f20000-2bf6e0f23000 ---p 00000000 00:00 0 \n2c143c100000-2c143c200000 rw-p 00000000 00:00 0 \n2c31aa300000-2c31aa400000 rw-p 00000000 00:00 0 \n2c3c4ac00000-2c3c4ad00000 rw-p 00000000 00:00 0 \n2c5350100000-2c5350200000 rw-p 00000000 00:00 0 \n2ca5f3900000-2ca5f3a00000 rw-p 00000000 00:00 0 \n2cf3a4000000-2cf3a4100000 rw-p 00000000 00:00 0 \n2d0b27100000-2d0b27200000 rw-p 00000000 00:00 0 \n2d0fea546000-2d0fea700000 ---p 00000000 00:00 0 \n2d0fea700000-2d0fea705000 rw-p 00000000 00:00 0 \n2d0fea705000-2d0fea706000 ---p 00000000 00:00 0 \n2d0fea706000-2d0fea708000 rwxp 00000000 00:00 0 \n2d0fea708000-2d0fea800000 ---p 00000000 00:00 0 \n2d0fea800000-2d0fea805000 rw-p 00000000 00:00 0 \n2d0fea805000-2d0fea806000 ---p 00000000 00:00 0 \n2d0fea806000-2d0fea808000 rwxp 00000000 00:00 0 \n2d0fea808000-2d0fea900000 ---p 00000000 00:00 0 \n2d0fea900000-2d0fea905000 rw-p 00000000 00:00 0 \n2d0fea905000-2d0fea906000 ---p 00000000 00:00 0 \n2d0fea906000-2d0fea908000 rwxp 00000000 00:00 0 \n2d0fea908000-2d0feaa00000 ---p 00000000 00:00 0 \n2d0feaa00000-2d0feaa05000 rw-p 00000000 00:00 0 \n2d0feaa05000-2d0feaa06000 ---p 00000000 00:00 0 \n2d0feaa06000-2d0feaaff000 rwxp 00000000 00:00 0 \n2d0feaaff000-2d0fec900000 ---p 00000000 00:00 0 \n2d0fec900000-2d0fec905000 rw-p 00000000 00:00 0 \n2d0fec905000-2d0fec906000 ---p 00000000 00:00 0 \n2d0fec906000-2d0fec9ff000 rwxp 00000000 00:00 0 \n2d0fec9ff000-2d0ff3e00000 ---p 00000000 00:00 0 \n2d0ff3e00000-2d0ff3e05000 rw-p 00000000 00:00 0 \n2d0ff3e05000-2d0ff3e06000 ---p 00000000 00:00 0 \n2d0ff3e06000-2d0ff3eff000 rwxp 00000000 00:00 0 \n2d0ff3eff000-2d0ff4b00000 ---p 00000000 00:00 0 \n2d0ff4b00000-2d0ff4b05000 rw-p 00000000 00:00 0 \n2d0ff4b05000-2d0ff4b06000 ---p 00000000 00:00 0 \n2d0ff4b06000-2d0ff4bff000 rwxp 00000000 00:00 0 \n2d0ff4bff000-2d0ff4e00000 ---p 00000000 00:00 0 \n2d0ff4e00000-2d0ff4e05000 rw-p 00000000 00:00 0 \n2d0ff4e05000-2d0ff4e06000 ---p 00000000 00:00 0 \n2d0ff4e06000-2d0ff4eff000 rwxp 00000000 00:00 0 \n2d0ff4eff000-2d0ff5200000 ---p 00000000 00:00 0 \n2d0ff5200000-2d0ff5205000 rw-p 00000000 00:00 0 \n2d0ff5205000-2d0ff5206000 ---p 00000000 00:00 0 \n2d0ff5206000-2d0ff52ff000 rwxp 00000000 00:00 0 \n2d0ff52ff000-2d0ff5800000 ---p 00000000 00:00 0 \n2d0ff5800000-2d0ff5805000 rw-p 00000000 00:00 0 \n2d0ff5805000-2d0ff5806000 ---p 00000000 00:00 0 \n2d0ff5806000-2d0ff58ff000 rwxp 00000000 00:00 0 \n2d0ff58ff000-2d0ff5900000 ---p 00000000 00:00 0 \n2d0ff5900000-2d0ff5905000 rw-p 00000000 00:00 0 \n2d0ff5905000-2d0ff5906000 ---p 00000000 00:00 0 \n2d0ff5906000-2d0ff59ff000 rwxp 00000000 00:00 0 \n2d0ff59ff000-2d0ff5a00000 ---p 00000000 00:00 0 \n2d0ff5a00000-2d0ff5a05000 rw-p 00000000 00:00 0 \n2d0ff5a05000-2d0ff5a06000 ---p 00000000 00:00 0 \n2d0ff5a06000-2d0ff5aff000 rwxp 00000000 00:00 0 \n2d0ff5aff000-2d0ff5b00000 ---p 00000000 00:00 0 \n2d0ff5b00000-2d0ff5b05000 rw-p 00000000 00:00 0 \n2d0ff5b05000-2d0ff5b06000 ---p 00000000 00:00 0 \n2d0ff5b06000-2d0ff5bff000 rwxp 00000000 00:00 0 \n2d0ff5bff000-2d0ff5e00000 ---p 00000000 00:00 0 \n2d0ff5e00000-2d0ff5e05000 rw-p 00000000 00:00 0 \n2d0ff5e05000-2d0ff5e06000 ---p 00000000 00:00 0 \n2d0ff5e06000-2d0ff5eff000 rwxp 00000000 00:00 0 \n2d0ff5eff000-2d0ff5f00000 ---p 00000000 00:00 0 \n2d0ff5f00000-2d0ff5f05000 rw-p 00000000 00:00 0 \n2d0ff5f05000-2d0ff5f06000 ---p 00000000 00:00 0 \n2d0ff5f06000-2d0ff5fff000 rwxp 00000000 00:00 0 \n2d0ff5fff000-2d0ff6000000 ---p 00000000 00:00 0 \n2d0ff6000000-2d0ff6005000 rw-p 00000000 00:00 0 \n2d0ff6005000-2d0ff6006000 ---p 00000000 00:00 0 \n2d0ff6006000-2d0ff60ff000 rwxp 00000000 00:00 0 \n2d0ff60ff000-2d0ff6100000 ---p 00000000 00:00 0 \n2d0ff6100000-2d0ff6105000 rw-p 00000000 00:00 0 \n2d0ff6105000-2d0ff6106000 ---p 00000000 00:00 0 \n2d0ff6106000-2d0ff61ff000 rwxp 00000000 00:00 0 \n2d0ff61ff000-2d100a546000 ---p 00000000 00:00 0 \n2d1d2cf00000-2d1d2cf35000 rw-p 00000000 00:00 0 \n2d83e9d00000-2d83e9e00000 rw-p 00000000 00:00 0 \n2deac8b00000-2deac8c00000 rw-p 00000000 00:00 0 \n2eb729a00000-2eb729b00000 rw-p 00000000 00:00 0 \n2eca45e31000-2eca45e32000 r-xp 00000000 00:00 0 \n2f0f34900000-2f0f34a00000 rw-p 00000000 00:00 0 \n2fab2a300000-2fab2a400000 rw-p 00000000 00:00 0 \n30b8a6c00000-30b8a6d00000 rw-p 00000000 00:00 0 \n31113de00000-31113df41000 rw-p 00000000 00:00 0 \n31e461900000-31e461a00000 rw-p 00000000 00:00 0 \n31e67e800000-31e67e900000 rw-p 00000000 00:00 0 \n322212700000-322212800000 rw-p 00000000 00:00 0 \n32e101300000-32e101400000 rw-p 00000000 00:00 0 \n32e83dd00000-32e83de00000 rw-p 00000000 00:00 0 \n334185300000-334185400000 rw-p 00000000 00:00 0 \n335a03200000-335a03300000 rw-p 00000000 00:00 0 \n33be7ef00000-33be7f000000 rw-p 00000000 00:00 0 \n346f1da00000-346f1db00000 rw-p 00000000 00:00 0 \n351afe700000-351afe800000 rw-p 00000000 00:00 0 \n354ce2a00000-354ce2b00000 rw-p 00000000 00:00 0 \n355349d00000-355349e00000 rw-p 00000000 00:00 0 \n3571fc700000-3571fc800000 rw-p 00000000 00:00 0 \n35b481c00000-35b481d00000 rw-p 00000000 00:00 0 \n362aad700000-362aad800000 rw-p 00000000 00:00 0 \n368778a00000-368778b00000 rw-p 00000000 00:00 0 \n369009800000-369009a7d000 rw-p 00000000 00:00 0 \n369230500000-369230600000 rw-p 00000000 00:00 0 \n369c3ea00000-369c3eb00000 rw-p 00000000 00:00 0 \n369e06a00000-369e06b00000 rw-p 00000000 00:00 0 \n36fb9e700000-36fb9e800000 rw-p 00000000 00:00 0 \n37382dc00000-37382dd00000 rw-p 00000000 00:00 0 \n379056a00000-379056b00000 rw-p 00000000 00:00 0 \n37a518d00000-37a518d25000 rw-p 00000000 00:00 0 \n37c908f00000-37c909000000 rw-p 00000000 00:00 0 \n37d63a900000-37d63aa00000 rw-p 00000000 00:00 0 \n37fc37e00000-37fc37f00000 rw-p 00000000 00:00 0 \n3840db000000-3840db100000 rw-p 00000000 00:00 0 \n384211d00000-384211e00000 rw-p 00000000 00:00 0 \n389829800000-389829900000 rw-p 00000000 00:00 0 \n38b3b0e00000-38b3b0f00000 rw-p 00000000 00:00 0 \n38da0e000000-38da0e100000 rw-p 00000000 00:00 0 \n38db42000000-38db42100000 rw-p 00000000 00:00 0 \n394ad4100000-394ad4200000 rw-p 00000000 00:00 0 \n395f56c00000-395f56d00000 rw-p 00000000 00:00 0 \n39bd3bd00000-39bd3be00000 rw-p 00000000 00:00 0 \n39c7f7a00000-39c7f7b00000 rw-p 00000000 00:00 0 \n39e4f6000000-39e4f6100000 rw-p 00000000 00:00 0 \n39f8ec500000-39f8ec600000 rw-p 00000000 00:00 0 \n3a45f8100000-3a45f8200000 rw-p 00000000 00:00 0 \n3acae2b00000-3acae2c00000 rw-p 00000000 00:00 0 \n3afc9e800000-3afc9e900000 rw-p 00000000 00:00 0 \n3b2c68900000-3b2c68a00000 rw-p 00000000 00:00 0 \n3b7f05500000-3b7f05600000 rw-p 00000000 00:00 0 \n3b8042600000-3b8042700000 rw-p 00000000 00:00 0 \n3bcce0b00000-3bcce0c00000 rw-p 00000000 00:00 0 \n3c0282d00000-3c0282e00000 rw-p 00000000 00:00 0 \n3c44bc400000-3c44bc500000 rw-p 00000000 00:00 0 \n3c941e600000-3c941e700000 rw-p 00000000 00:00 0 \n3cce96c00000-3cce96d00000 rw-p 00000000 00:00 0 \n3e13ae800000-3e13ae900000 rw-p 00000000 00:00 0 \n3e298a600000-3e298a700000 rw-p 00000000 00:00 0 \n3e31ad800000-3e31ad900000 rw-p 00000000 00:00 0 \n3ef415400000-3ef415500000 rw-p 00000000 00:00 0 \n3f335a600000-3f335a700000 rw-p 00000000 00:00 0 \n3f3cece00000-3f3cecf00000 rw-p 00000000 00:00 0 \n3f9ab1c00000-3f9ab1d00000 rw-p 00000000 00:00 0 \n3fc363300000-3fc363400000 rw-p 00000000 00:00 0 \n7f318a7ff000-7f318c000000 rw-p 00000000 00:00 0 \n7f318c000000-7f318c021000 rw-p 00000000 00:00 0 \n7f318c021000-7f3190000000 ---p 00000000 00:00 0 \n7f3194000000-7f3194021000 rw-p 00000000 00:00 0 \n7f3194021000-7f3198000000 ---p 00000000 00:00 0 \n7f3198000000-7f3198021000 rw-p 00000000 00:00 0 \n7f3198021000-7f319c000000 ---p 00000000 00:00 0 \n7f319c000000-7f319c021000 rw-p 00000000 00:00 0 \n7f319c021000-7f31a0000000 ---p 00000000 00:00 0 \n7f31a0948000-7f31a0fc6000 r--s 00000000 fd:00 522459                     /var/lib/sss/mc/passwd\n7f31a0fc6000-7f31a0fcd000 r-xp 00000000 fd:00 10911                      /lib64/libnss_sss.so.2\n7f31a0fcd000-7f31a11cd000 ---p 00007000 fd:00 10911                      /lib64/libnss_sss.so.2\n7f31a11cd000-7f31a11ce000 rw-p 00007000 fd:00 10911                      /lib64/libnss_sss.so.2\n7f31a11ce000-7f31a11e4000 r-xp 00000000 fd:00 10873                      /lib64/libresolv-2.12.so\n7f31a11e4000-7f31a13e4000 ---p 00016000 fd:00 10873                      /lib64/libresolv-2.12.so\n7f31a13e4000-7f31a13e5000 r--p 00016000 fd:00 10873                      /lib64/libresolv-2.12.so\n7f31a13e5000-7f31a13e6000 rw-p 00017000 fd:00 10873                      /lib64/libresolv-2.12.so\n7f31a13e6000-7f31a13e8000 rw-p 00000000 00:00 0 \n7f31a13e8000-7f31a13ed000 r-xp 00000000 fd:00 9255                       /lib64/libnss_dns-2.12.so\n7f31a13ed000-7f31a15ec000 ---p 00005000 fd:00 9255                       /lib64/libnss_dns-2.12.so\n7f31a15ec000-7f31a15ed000 r--p 00004000 fd:00 9255                       /lib64/libnss_dns-2.12.so\n7f31a15ed000-7f31a15ee000 rw-p 00005000 fd:00 9255                       /lib64/libnss_dns-2.12.so\n7f31a15ee000-7f31a15fa000 r-xp 00000000 fd:00 1559                       /lib64/libnss_files-2.12.so\n7f31a15fa000-7f31a17fa000 ---p 0000c000 fd:00 1559                       /lib64/libnss_files-2.12.so\n7f31a17fa000-7f31a17fb000 r--p 0000c000 fd:00 1559                       /lib64/libnss_files-2.12.so\n7f31a17fb000-7f31a17fc000 rw-p 0000d000 fd:00 1559                       /lib64/libnss_files-2.12.so\n7f31a17fc000-7f31a17fd000 ---p 00000000 00:00 0 \n7f31a17fd000-7f31a21fd000 rw-p 00000000 00:00 0 \n7f31a21fd000-7f31a21fe000 ---p 00000000 00:00 0 \n7f31a21fe000-7f31a2bfe000 rw-p 00000000 00:00 0 \n7f31a2bfe000-7f31a2bff000 ---p 00000000 00:00 0 \n7f31a2bff000-7f31a35ff000 rw-p 00000000 00:00 0 \n7f31a35ff000-7f31a3600000 ---p 00000000 00:00 0 \n7f31a3600000-7f31a4000000 rw-p 00000000 00:00 0 \n7f31a4000000-7f31a4f25000 rw-p 00000000 00:00 0 \n7f31a4f25000-7f31a8000000 ---p 00000000 00:00 0 \n7f31a80ea000-7f31a80f7000 r-xp 00000000 fd:00 401921                     /usr/local/bin/ws-preproc/node_modules/hiredis/build/Release/hiredis.node\n7f31a80f7000-7f31a82f7000 ---p 0000d000 fd:00 401921                     /usr/local/bin/ws-preproc/node_modules/hiredis/build/Release/hiredis.node\n7f31a82f7000-7f31a82f8000 rw-p 0000d000 fd:00 401921                     /usr/local/bin/ws-preproc/node_modules/hiredis/build/Release/hiredis.node\n7f31a82f8000-7f31a82fb000 r-xp 00000000 fd:00 398524                     /usr/local/bin/ws-preproc/node_modules/heapdump/build/Release/addon.node\n7f31a82fb000-7f31a84fb000 ---p 00003000 fd:00 398524                     /usr/local/bin/ws-preproc/node_modules/heapdump/build/Release/addon.node\n7f31a84fb000-7f31a84fc000 rw-p 00003000 fd:00 398524                     /usr/local/bin/ws-preproc/node_modules/heapdump/build/Release/addon.node\n7f31a84fc000-7f31a84fd000 rw-p 00000000 00:00 0 \n7f31a84fd000-7f31a8500000 r-xp 00000000 fd:00 132644                     /usr/local/bin/ws-preproc/node_modules/gc-stats/build/Release/gcstats.node\n7f31a8500000-7f31a86ff000 ---p 00003000 fd:00 132644                     /usr/local/bin/ws-preproc/node_modules/gc-stats/build/Release/gcstats.node\n7f31a86ff000-7f31a8700000 rw-p 00002000 fd:00 132644                     /usr/local/bin/ws-preproc/node_modules/gc-stats/build/Release/gcstats.node\n7f31a8700000-7f31a8701000 ---p 00000000 00:00 0 \n7f31a8701000-7f31a9101000 rw-p 00000000 00:00 0 \n7f31a9101000-7f31a9102000 ---p 00000000 00:00 0 \n7f31a9102000-7f31a9b02000 rw-p 00000000 00:00 0 \n7f31a9b02000-7f31a9b03000 ---p 00000000 00:00 0 \n7f31a9b03000-7f31aa503000 rw-p 00000000 00:00 0 \n7f31aa503000-7f31aa504000 ---p 00000000 00:00 0 \n7f31aa504000-7f31aaf04000 rw-p 00000000 00:00 0 \n7f31aaf04000-7f31aaf05000 ---p 00000000 00:00 0 \n7f31aaf05000-7f31ab905000 rw-p 00000000 00:00 0 \n7f31ab905000-7f31aba8f000 r-xp 00000000 fd:00 1548                       /lib64/libc-2.12.so\n7f31aba8f000-7f31abc8f000 ---p 0018a000 fd:00 1548                       /lib64/libc-2.12.so\n7f31abc8f000-7f31abc93000 r--p 0018a000 fd:00 1548                       /lib64/libc-2.12.so\n7f31abc93000-7f31abc94000 rw-p 0018e000 fd:00 1548                       /lib64/libc-2.12.so\n7f31abc94000-7f31abc99000 rw-p 00000000 00:00 0 \n7f31abc99000-7f31abcb0000 r-xp 00000000 fd:00 1566                       /lib64/libpthread-2.12.so\n7f31abcb0000-7f31abeb0000 ---p 00017000 fd:00 1566                       /lib64/libpthread-2.12.so\n7f31abeb0000-7f31abeb1000 r--p 00017000 fd:00 1566                       /lib64/libpthread-2.12.so\n7f31abeb1000-7f31abeb2000 rw-p 00018000 fd:00 1566                       /lib64/libpthread-2.12.so\n7f31abeb2000-7f31abeb6000 rw-p 00000000 00:00 0 \n7f31abeb6000-7f31abecc000 r-xp 00000000 fd:00 10860                      /lib64/libgcc_s-4.4.7-20120601.so.1\n7f31abecc000-7f31ac0cb000 ---p 00016000 fd:00 10860                      /lib64/libgcc_s-4.4.7-20120601.so.1\n7f31ac0cb000-7f31ac0cc000 rw-p 00015000 fd:00 10860                      /lib64/libgcc_s-4.4.7-20120601.so.1\n7f31ac0cc000-7f31ac14f000 r-xp 00000000 fd:00 9185                       /lib64/libm-2.12.so\n7f31ac14f000-7f31ac34e000 ---p 00083000 fd:00 9185                       /lib64/libm-2.12.so\n7f31ac34e000-7f31ac34f000 r--p 00082000 fd:00 9185                       /lib64/libm-2.12.so\n7f31ac34f000-7f31ac350000 rw-p 00083000 fd:00 9185                       /lib64/libm-2.12.so\n7f31ac350000-7f31ac438000 r-xp 00000000 fd:00 133670                     /usr/lib64/libstdc++.so.6.0.13\n7f31ac438000-7f31ac638000 ---p 000e8000 fd:00 133670                     /usr/lib64/libstdc++.so.6.0.13\n7f31ac638000-7f31ac63f000 r--p 000e8000 fd:00 133670                     /usr/lib64/libstdc++.so.6.0.13\n7f31ac63f000-7f31ac641000 rw-p 000ef000 fd:00 133670                     /usr/lib64/libstdc++.so.6.0.13\n7f31ac641000-7f31ac656000 rw-p 00000000 00:00 0 \n7f31ac656000-7f31ac658000 r-xp 00000000 fd:00 9157                       /lib64/libdl-2.12.so\n7f31ac658000-7f31ac858000 ---p 00002000 fd:00 9157                       /lib64/libdl-2.12.so\n7f31ac858000-7f31ac859000 r--p 00002000 fd:00 9157                       /lib64/libdl-2.12.so\n7f31ac859000-7f31ac85a000 rw-p 00003000 fd:00 9157                       /lib64/libdl-2.12.so\n7f31ac85a000-7f31ac861000 r-xp 00000000 fd:00 10875                      /lib64/librt-2.12.so\n7f31ac861000-7f31aca60000 ---p 00007000 fd:00 10875                      /lib64/librt-2.12.so\n7f31aca60000-7f31aca61000 r--p 00006000 fd:00 10875                      /lib64/librt-2.12.so\n7f31aca61000-7f31aca62000 rw-p 00007000 fd:00 10875                      /lib64/librt-2.12.so\n7f31aca62000-7f31aca82000 r-xp 00000000 fd:00 10862                      /lib64/ld-2.12.so\n7f31acc71000-7f31acc77000 rw-p 00000000 00:00 0 \n7f31acc7f000-7f31acc81000 rw-p 00000000 00:00 0 \n7f31acc81000-7f31acc82000 r--p 0001f000 fd:00 10862                      /lib64/ld-2.12.so\n7f31acc82000-7f31acc83000 rw-p 00020000 fd:00 10862                      /lib64/ld-2.12.so\n7f31acc83000-7f31acc84000 rw-p 00000000 00:00 0 \n7fffba5f7000-7fffba60c000 rw-p 00000000 00:00 0                          [stack]\n7fffba62a000-7fffba62b000 r-xp 00000000 00:00 0                          [vdso]\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\n```\n\nOS and io.js version:\n\n```\n[root@****]# uname -a\nLinux **** 2.6.32-504.3.3.el6.x86_64 #1 SMP Fri Dec 12 16:05:43 EST 2014 x86_64 x86_64 x86_64 GNU/Linux\n[root@****]# iojs -v\nv1.6.2\n```\n",
        "labels": "confirmed-bug",
        "id": 45565
    },
    {
        "title": "npm@2.7.4 fails to install private git repository dependencies",
        "body": "`npm 2.7.4` included with `io.js 1.6.3` fails to install dependencies from private git repositories such as:\n\n`\n\"private\": \"git+ssh://git@github.com:org/private\" \n`\n\nError:\n\n```\nnpm ERR! Cannot read property 'charAt' of undefined \n```\n\nFor more information see npm/npm#7807\n",
        "labels": "confirmed-bug",
        "id": 45566
    },
    {
        "title": "child_process.exec TypeError: Cannot read property 'addListener' of undefined",
        "body": "Here's a code sample that triggers the error condition:\n\n``` javascript\nvar child_process = require('child_process'),\n    exec = child_process.exec,\n    children = [],\n    exitHandler = function(i,err,stdout,stderr){\n        console.log(i,err,stdout,stderr);\n    },\n    i = 0;\nfor(i=0;i<1000;i++){\n        children.push(exec('sleep 10 && echo hello',exitHandler.bind(null,i)));\n}\n```\n\nIf I do not wrap with try/catch it will crash after ~258 iterations on io.js v1.6.3 on OSX 10.10.2\n\nHere is the stack trace:\n\n```\nchild_process.js:753\n  child.stdout.addListener('data', function(chunk) {\n              ^\nTypeError: Cannot read property 'addListener' of undefined\n    at Object.exports.execFile (child_process.js:753:15)\n    at exports.exec (child_process.js:622:18)\n    at Object.<anonymous> (/Users/gcochard/iojs/test.js:10:19)\n    at Module._compile (module.js:410:26)\n    at Object.Module._extensions..js (module.js:428:10)\n    at Module.load (module.js:335:32)\n    at Function.Module._load (module.js:290:12)\n    at Function.Module.runMain (module.js:451:10)\n    at startup (node.js:123:18)\n    at node.js:867:3\n```\n\nIt seems that if a callback is passed, the general async-ism is to call it with any errors. Therefore the following:\n\n``` javascript\n  child.stdout.addListener('data', function(chunk) {...});\n```\n\nShould change to something like this:\n\n``` javascript\nif(!child.stdout || !child.stderr){\n  return errorhandler(new Error('Something went wrong'));\n}\nchild.stdout.addListener('data', function(chunk) {...});\n```\n\nAnd the error handler should also include a null check on `child.stdout` and `child.stderr`.\n\n---\n\nAdditionally, when I _do_ wrap with try/catch, it looks like it is emitting a spawn error on [line 1022](https://github.com/iojs/io.js/blob/v1.x/lib/child_process.js#L1022) which is not handled, even when adding an error listener on the child. It appears to be emitted by the `ChildProcess` object on [line 1042](https://github.com/iojs/io.js/blob/v1.x/lib/child_process.js#L1042). Its stack trace is as follows:\n\n```\nevents.js:141\n      throw er; // Unhandled 'error' event\n            ^\nError: spawn /bin/sh EAGAIN\n    at exports._errnoException (util.js:749:11)\n    at Process.ChildProcess._handle.onexit (child_process.js:1022:32)\n    at child_process.js:1114:20\n    at process._tickCallback (node.js:339:13)\n    at Function.Module.runMain (module.js:453:11)\n    at startup (node.js:123:18)\n    at node.js:867:3\n```\n\nI know this is a contrived example, but I've hit this edge case before.\n\nPlease let me know if I can clarify anything here. The expected behavior is that the script keeps running, rather than crashing io.js with a stack trace.\n",
        "labels": "confirmed-bug",
        "id": 45567
    },
    {
        "title": "No finish/close event on aborted http-response - race condition",
        "body": "When tracking requests of a HTTP-Server - with `server.on('request')` and `res.on('finish', ...)` or `res.on('close', ...)` - we noticed inconsistent results over time (requests that are never finished or closed).\n\nWe tracked this race condition down to the following reproducable test case:\n1. connection is aborted from client side\n2. socket gets destroyed (but socket-\"close\"-event still not delivered)\n3. trying to send response\n4. socket-\"close\" event delivered\n\n-> No \"close\" and no \"finish\" event on response!\n\n``` js\nvar common = require('../common');\nvar assert = require('assert');\nvar http = require('http');\n\nvar clientRequest = null;\nvar serverResponseFinishedOrClosed = 0;\n\nvar server = http.createServer(function (req, res) {\n    console.log('server: request');\n\n    res.on('finish', function () {\n        console.log('server: response finish');\n        serverResponseFinishedOrClosed++;\n    });\n    res.on('close', function () {\n        console.log('server: response close');\n        serverResponseFinishedOrClosed++;\n    });\n\n    console.log('client: aborting request');\n    clientRequest.abort();\n\n    setImmediate(function() {\n        console.log('server: tick 1' + (req.connection.destroyed ? ' (connection destroyed!)' : ''));\n\n        setImmediate(function () {\n            console.log('server: tick 2' + (req.connection.destroyed ? ' (connection destroyed!)' : ''));\n\n            console.log('server: sending response');\n            res.writeHead(200, {'Content-Type': 'text/plain'});\n            res.end('Response\\n');\n            console.log('server: res.end() returned');\n\n            setImmediate(function () {\n                server.close();\n            });\n        });\n    });\n});\n\nserver.on('listening', function () {\n    console.log('server: listening on port ' + common.PORT);\n    console.log('client: starting request');\n\n    var options = {port: common.PORT, path: '/'};\n    clientRequest = http.get(options, function () {});\n    clientRequest.on('error', function () {});\n});\n\nserver.on('connection', function (connection) {\n    console.log('server: connection');\n    connection.on('close', function () { console.log('server: connection close'); });\n});\n\nserver.on('close', function () {\n    console.log('server: close');\n    assert.equal(serverResponseFinishedOrClosed, 1, 'Expected either one \"finish\" or one \"close\" event on the response for aborted connections (got ' + serverResponseFinishedOrClosed + ')');\n});\n\nserver.listen(common.PORT);\n```\n- With one _more_ `setImmediate()` call, you get a response _close_ event (which is fine)\n- With one _less_ `setImmediate()` call, you get a response _finish_ event (which is fine)\n- Reproducable with io.js 1.6.3, io.js 1.3.0, io.js 1.1.0, node 0.12.0\n- In node 0.10 the race-condition was different: This test case works fine, but with one more `setImmediate()`, two events are delivered (finish AND close)\n",
        "labels": "confirmed-bug",
        "id": 45568
    },
    {
        "title": "core: handle._handle.close(callback) is not idempotent",
        "body": "`handle._handle.close(callback)` is not idempotent and that's because `node::HandleWrap::Close()` overrides the .close method with the callback.  This one-liner should print 'Trace' only once:\n\n```\n$ iojs -e 'var t = new (process.binding(\"timer_wrap\").Timer); t.close(console.trace); t.close()'\nTrace\n    at [eval]:1:78\n    at Object.exports.runInThisContext (vm.js:54:17)\n    at Object.<anonymous> ([eval]-wrapper:6:22)\n    at Module._compile (module.js:410:26)\n    at evalScript (node.js:475:25)\n    at startup (node.js:84:9)\n    at node.js:867:3\nTrace\n```\n",
        "labels": "confirmed-bug",
        "id": 45569
    },
    {
        "title": "timer,domain: timers don't maintain order after exception",
        "body": "``` javascript\nvar domain = require('domain').create();\n\ndomain.run(function() {\n  setTimeout(function() { throw Error('FAIL'); }, 1);\n  setTimeout(function() { console.log('timeout 1'); }, 1);\n  setTimeout(function() { console.log('timeout 2'); }, 2);\n});\n\ndomain.once('error', function() {});\n```\n\nExpected output:\n\n```\ntimeout 1\ntimeout 2\n```\n\nActual output:\n\n```\ntimeout 2\ntimeout 1\n```\n\n(EDIT: I forgot to mention that you may need to run the test a few times.)\n",
        "labels": "confirmed-bug",
        "id": 45570
    },
    {
        "title": "unref'd timers running in beforeExit time",
        "body": "When working out this test case for #1152 I came up with this:\n\n``` js\nvar assert = require(\"assert\")\nvar intervals = 0\nvar i = setInterval(function () {\n  intervals++\n  i.unref()\n  eatTime()\n}, 10)\n\nfunction eatTime() {\n  // the goal of this function is to take longer than 10ms, i.e. longer than the interval\n  var count = 0\n  while (count++ < 1e7) {\n    Math.random()\n  }\n}\n\nprocess.on(\"exit\", function () {\n  assert.equal(intervals, 1)\n})\n```\n\nNote -- this requires the patch in #1152 to even terminate, or running Node.js 0.12+ which already has that fix.\n\nI think what happens here is the blocking time causes the repeat time to trigger and the unreferenced timer gets executed in the `beforeExit` timeframe (https://github.com/joyent/node/commit/a2eeb43) when it shouldn't be. This can result in your application not terminating when it should, and functions that should not be executed being run.\n\nThis is a separate bug than #1151 (with fix #1152) and is not fixed by #1231\n",
        "labels": "confirmed-bug",
        "id": 45571
    },
    {
        "title": "path: iojs@1.6.0 breaks compatibility with previous versions",
        "body": "In iojs 1.5.1:\n\n``` js\n> path.dirname(undefined)\n'.'\n\n> path.dirname([ 'sup/dude' ])\n'sup'\n```\n\nIn iojs 1.6.0:\n\n``` js\n> path.dirname(undefined)\nTypeError: Path must be a string. Received undefined\n    at assertPath (path.js:8:11)\n    at Object.posix.dirname (path.js:539:3)\n    at repl:1:6\n    at REPLServer.defaultEval (repl.js:124:27)\n    at bound (domain.js:254:14)\n    at REPLServer.runBound [as eval] (domain.js:267:12)\n    at REPLServer.<anonymous> (repl.js:277:12)\n    at emitOne (events.js:77:13)\n    at REPLServer.emit (events.js:166:7)\n    at REPLServer.Interface._onLine (readline.js:195:10)\n\n> path.dirname([ 'sup/dude' ])\nTypeError: Path must be a string. Received [ 'sup/dude' ]\n    at assertPath (path.js:8:11)\n    at Object.posix.dirname (path.js:539:3)\n    at repl:1:6\n    at REPLServer.defaultEval (repl.js:124:27)\n    at bound (domain.js:254:14)\n    at REPLServer.runBound [as eval] (domain.js:267:12)\n    at REPLServer.<anonymous> (repl.js:277:12)\n    at emitOne (events.js:77:13)\n    at REPLServer.emit (events.js:166:7)\n    at REPLServer.Interface._onLine (readline.js:195:10)\n```\n\nThis appears to be a bug introduced by this PR: https://github.com/iojs/io.js/pull/1153.\n\nThis suddenly started causing tests in [`webtorrent`](https://www.npmjs.com/package/webtorrent) and [`browserify`](https://npmjs.com/package/browserify) to start failing. Here's an [example](https://travis-ci.org/substack/node-browserify/jobs/55104705).\n",
        "labels": "confirmed-bug",
        "id": 45572
    },
    {
        "title": "1.6.0: querystring.stringify does not work with number literals",
        "body": "1.5.1:\n\n```\n> querystring.stringify({ foo: 1 })\n'foo=1'\n```\n\n1.6.0:\n\n```\n> querystring.stringify({ foo: 1 })\n'foo='\n```\n",
        "labels": "confirmed-bug",
        "id": 45573
    },
    {
        "title": "setTimeout can fire twice",
        "body": "Test to reproduce:\n\n```\n$ ./iojs -e \"setTimeout(function() { console.log('hi'); this.unref(); this.ref(); }, 10)\"\nhi\nhi\n```\n\nI haven't had the time to investigate, but want to make sure this issue can be tracked.\n",
        "labels": "confirmed-bug",
        "id": 45574
    },
    {
        "title": "Timer's `unref` unreliable when `http` module required after using them",
        "body": "Finally narrowed this down to a (admittedly bizarre) test case -- still looking into exactly why it happens -- but generally there appears to be a race condition or off-by-one in the timer unref management if the `unref` is called and then later the `http` module is required:\n\n```\nsetImmediate(function () {\n  require(\"http\")\n})\n\nvar i = setInterval(function () {\n  setImmediate(process.exit)\n}, 10)\ni.unref()\n\nprocess.on(\"exit\", logstuff)\n\nfunction logstuff() {\n  console.log(process._getActiveHandles())\n}\n```\n\nWith 0.10 or 0.12 this logs `[]` which is expected because the interval was unreferenced.\n\nIn `io.js` you get:\n\n```\n[ { '0': [Function: listOnTimeout],\n    _idleNext: \n     { _idleTimeout: 10,\n       _idlePrev: [Circular],\n       _idleNext: [Circular],\n       _idleStart: 1218064360,\n       _onTimeout: [Function: wrapper],\n       _repeat: true,\n       _handle: [Object] },\n    _idlePrev: \n     { _idleTimeout: 10,\n       _idlePrev: [Circular],\n       _idleNext: [Circular],\n       _idleStart: 1218064360,\n       _onTimeout: [Function: wrapper],\n       _repeat: true,\n       _handle: [Object] },\n    msecs: 10 } ]\n```\n\nWhich is showing the unreferenced timer.\n\nI found this when my application was supposed to be shutting down but was being kept alive by an unreferenced setInterval timer.\n",
        "labels": "confirmed-bug",
        "id": 45575
    },
    {
        "title": "tls.connect() emitting twice an error event",
        "body": "With certain hosts (and the particular cipher settings used below) tls.connect() appears to emit an error event twice.\n\n```\nvar host='85.158.224.100';\n\nvar options = { rejectUnauthorized: false,\n    servername: host,\n    ciphers: 'EXPORT' };\n\nrequire('tls').connect(443, host, options, function() {\n    console.log('success');\n}).on('error', function(error) {\n    console.log(error);\n    console.log();\n});\n```\n\n**Actual Result**\n\n```\n{ [Error: socket hang up] code: 'ECONNRESET' }\n\n[Error: 101057795:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handsh\nake failure:openssl\\ssl\\s3_pkt.c:1293:SSL alert number 40\n101057795:error:140780E5:SSL routines:SSL23_READ:ssl handshake failure:openssl\\s\nsl\\s23_lib.c:138:\n]\n```\n\n**Expected Result**\n\n```\n[Error: 101057795:error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handsh\nake failure:openssl\\ssl\\s3_pkt.c:1293:SSL alert number 40\n101057795:error:140780E5:SSL routines:SSL23_READ:ssl handshake failure:openssl\\s\nsl\\s23_lib.c:138:\n]\n```\n\nQuick assumption would be it has something to do with SNI, as it does not occur if _servername_ is not set.\n",
        "labels": "confirmed-bug",
        "id": 45576
    },
    {
        "title": "New `Server.listen(options[, callback])` method is too picky about port being a js number",
        "body": "Really like this new new listen function, but I've found it's pickier than the others about port being a js number vs a string number, and the error is unclear (uses poor stringification of the object):\n\n```\n// Old .listen(port[, host][, callback])\nhttp.createServer(function (req, res) {\n  res.end(\"\\n\")\n}).listen(\"8005\")\n```\n\nWorks fine, converting `\"8005\"` to `8005`.\n\nWhile:\n\n```\n// New .listen(options[, callback])\nhttp.createServer(function (req, res) {\n  res.end(\"\\n\")\n}).listen({port: \"8005\"})\n```\n\nThrows:\n\n```\nError: Invalid listen argument: [object Object]\n    at Server.listen (net.js:1278:15)\n    at repl:1:56\n    at REPLServer.defaultEval (repl.js:116:27)\n    at bound (domain.js:254:14)\n    at REPLServer.runBound [as eval] (domain.js:267:12)\n    at REPLServer.<anonymous> (repl.js:269:12)\n    at emitOne (events.js:77:13)\n    at REPLServer.emit (events.js:166:7)\n    at REPLServer.Interface._onLine (readline.js:195:10)\n    at REPLServer.Interface._line (readline.js:534:8)\n```\n",
        "labels": "confirmed-bug",
        "id": 45577
    },
    {
        "title": "https: certificate validation fails when using servername option",
        "body": "`Agent#createSocket()` [overwrites](https://github.com/iojs/io.js/blob/v1.x/lib/_http_agent.js#L163) `options.servername` leading to a `tls.checkServerIdentity()` against hostname instead of servername. \n\nI usually disabled connection pooling in that case, but that is not possible anymore as `ClientRequest#constructor` always [sets an agent](https://github.com/iojs/io.js/blob/v1.x/lib/_http_client.js#L28). \n\nNot sure if this is intentional; Did I overlook something in the changelog?\n",
        "labels": "confirmed-bug",
        "id": 45578
    },
    {
        "title": "Possible memory leak in TLS(Wrap?)",
        "body": "I'm diagnosing a problem when I run paypal's npm proxy https://github.com/krakenjs/kappa when run on iojs. After 300 requests for a 50kb tarball, memory allocated grows from 250 mb base to 450 mb.\n\nI've run it under valgrind, and there's some things that look a bit suspicious around tlswrap, smalloc and some other crypto related bits. The interesting bits of the valgrind report are:\n\n```\n==31542== 827,216 bytes in 656 blocks are still reachable in loss record 1,214 of 1,223\n==31542==    at 0x4C2B6CD: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0x7450D8: CRYPTO_malloc (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x6C868B: asn1_enc_save (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x6C2866: ASN1_item_ex_d2i (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x6C14FF: asn1_template_noexp_d2i (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x6C1BAB: asn1_template_ex_d2i (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x6C2F0F: ASN1_item_d2i (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x67CC9E: ssl3_get_server_certificate (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x681323: ssl3_connect (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x67958B: ssl23_connect (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679E1A: ssl23_write (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDBCEF: _ZN4node7TLSWrap7ClearInEv.part.43 (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542== \n==31542== 1,343,488 bytes in 328 blocks are still reachable in loss record 1,215 of 1,223\n==31542==    at 0x4C2AC27: operator new[](unsigned long) (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0xCD825D: node::NodeBIO::PeekWritable(unsigned long*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCD8EEC: node::TLSWrap::OnAllocImpl(unsigned long, uv_buf_t*, void*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xD031D0: uv__read (stream.c:1089)\n==31542==    by 0xD03967: uv__stream_io (stream.c:1219)\n==31542==    by 0xD08CEC: uv__io_poll (linux-core.c:319)\n==31542==    by 0xCFA955: uv_run (core.c:324)\n==31542==    by 0xC87650: node::Start(int, char**) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x5C8E76C: (below main) (libc-start.c:226)\n==31542== \n==31542== 2,303,504 bytes in 131 blocks are still reachable in loss record 1,216 of 1,223\n==31542==    at 0x4C2B6CD: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0x7450D8: CRYPTO_malloc (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x67BBAF: ssl3_setup_write_buffer (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x67BCB1: ssl3_setup_buffers (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679000: ssl23_connect (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679CBA: ssl23_read (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDCE78: node::TLSWrap::ClearOut() (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDD2B4: node::TLSWrap::Start(v8::FunctionCallbackInfo<v8::Value> const&) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x801781: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x828E02: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x1C66A79060BA: ???\n==31542==    by 0x1C66A7CDC7AD: ???\n==31542== \n==31542== 2,323,416 bytes in 131 blocks are still reachable in loss record 1,217 of 1,223\n==31542==    at 0x4C2B6CD: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0x7450D8: CRYPTO_malloc (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x67BD5F: ssl3_setup_buffers (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679000: ssl23_connect (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679CBA: ssl23_read (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDCE78: node::TLSWrap::ClearOut() (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDD2B4: node::TLSWrap::Start(v8::FunctionCallbackInfo<v8::Value> const&) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x801781: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x828E02: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x1C66A79060BA: ???\n==31542==    by 0x1C66A7CDC7AD: ???\n==31542==    by 0x1C66A7CDC562: ???\n==31542== \n==31542== 3,464,048 bytes in 197 blocks are still reachable in loss record 1,218 of 1,223\n==31542==    at 0x4C2B6CD: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0x7450D8: CRYPTO_malloc (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x67BBAF: ssl3_setup_write_buffer (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x67BCB1: ssl3_setup_buffers (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679000: ssl23_connect (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679CBA: ssl23_read (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDCE78: node::TLSWrap::ClearOut() (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDD2B4: node::TLSWrap::Start(v8::FunctionCallbackInfo<v8::Value> const&) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x1C66A7A43345: ???\n==31542==    by 0x1C66A7EA169A: ???\n==31542==    by 0x1C66A7CDC562: ???\n==31542==    by 0x1C66A7924BC5: ???\n==31542== \n==31542== 3,493,992 bytes in 197 blocks are still reachable in loss record 1,219 of 1,223\n==31542==    at 0x4C2B6CD: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0x7450D8: CRYPTO_malloc (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x67BD5F: ssl3_setup_buffers (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679000: ssl23_connect (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x679CBA: ssl23_read (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDCE78: node::TLSWrap::ClearOut() (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDD2B4: node::TLSWrap::Start(v8::FunctionCallbackInfo<v8::Value> const&) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x1C66A7A43345: ???\n==31542==    by 0x1C66A7EA169A: ???\n==31542==    by 0x1C66A7CDC562: ???\n==31542==    by 0x1C66A7924BC5: ???\n==31542==    by 0x1C66A7C08177: ???\n==31542== \n==31542== 5,373,952 bytes in 328 blocks are still reachable in loss record 1,220 of 1,223\n==31542==    at 0x4C2AC27: operator new[](unsigned long) (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0xCD8325: node::NodeBIO::Commit(unsigned long) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDD745: node::TLSWrap::OnReadImpl(long, uv_buf_t const*, uv_handle_type, void*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xD0335E: uv__read (stream.c:1156)\n==31542==    by 0xD03967: uv__stream_io (stream.c:1219)\n==31542==    by 0xD08CEC: uv__io_poll (linux-core.c:319)\n==31542==    by 0xCFA955: uv_run (core.c:324)\n==31542==    by 0xC87650: node::Start(int, char**) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x5C8E76C: (below main) (libc-start.c:226)\n==31542== \n==31542== 7,422,722 bytes in 131 blocks are still reachable in loss record 1,221 of 1,223\n==31542==    at 0x4C2B6CD: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0xCAD6A2: node::smalloc::Alloc(v8::FunctionCallbackInfo<v8::Value> const&) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x801781: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x828E02: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x1C66A79060BA: ???\n==31542==    by 0x1C66A79B20B8: ???\n==31542==    by 0x1C66A791EA54: ???\n==31542==    by 0x1C66A791EDA0: ???\n==31542==    by 0x1C66A7D088BE: ???\n==31542==    by 0x1C66A7D084D4: ???\n==31542==    by 0x1C66A7D08272: ???\n==31542==    by 0x1C66A7924BC5: ???\n==31542== \n==31542== 11,162,414 bytes in 197 blocks are still reachable in loss record 1,222 of 1,223\n==31542==    at 0x4C2B6CD: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0xCAD6A2: node::smalloc::Alloc(v8::FunctionCallbackInfo<v8::Value> const&) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x801781: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&)) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x828E02: v8::internal::Builtin_HandleApiCall(int, v8::internal::Object**, v8::internal::Isolate*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x1C66A79060BA: ???\n==31542==    by 0x1C66A79B20B8: ???\n==31542==    by 0x1C66A791EA54: ???\n==31542==    by 0x1C66A791EDA0: ???\n==31542==    by 0x1C66A7EA5607: ???\n==31542==    by 0x1C66A7D08272: ???\n==31542==    by 0x1C66A7924BC5: ???\n==31542==    by 0x1C66A7C08177: ???\n==31542== \n==31542== 18,591,935 bytes in 20,677 blocks are still reachable in loss record 1,223 of 1,223\n==31542==    at 0x4C2B6CD: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==31542==    by 0xCD8E91: node::TLSWrap::OnAllocSelf(unsigned long, uv_buf_t*, void*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDCEA0: node::TLSWrap::ClearOut() (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xCDD7B7: node::TLSWrap::OnReadImpl(long, uv_buf_t const*, uv_handle_type, void*) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0xD0335E: uv__read (stream.c:1156)\n==31542==    by 0xD03967: uv__stream_io (stream.c:1219)\n==31542==    by 0xD08CEC: uv__io_poll (linux-core.c:319)\n==31542==    by 0xCFA955: uv_run (core.c:324)\n==31542==    by 0xC87650: node::Start(int, char**) (in /home/aredridel/t/node_modules/iojs-bin/node_modules/iojs-linux-x64/iojs-v1.4.2-linux-x64/bin/iojs)\n==31542==    by 0x5C8E76C: (below main) (libc-start.c:226)\n==31542== \n==31542== LEAK SUMMARY:\n==31542==    definitely lost: 10,464 bytes in 327 blocks\n==31542==    indirectly lost: 63,532 bytes in 3,258 blocks\n==31542==      possibly lost: 4,568 bytes in 64 blocks\n==31542==    still reachable: 69,011,541 bytes in 206,575 blocks\n==31542==         suppressed: 0 bytes in 0 blocks\n==31542== \n==31542== For counts of detected and suppressed errors, rerun with: -v\n==31542== ERROR SUMMARY: 42 errors from 42 contexts (suppressed: 2 from 2)\n```\n\nAny help or suggestions for what to look at to track this down would be wonderful.\n\nNode 0.12 and 0.10 don't show this behavior with the same code (we're stress-testing io.js in parallel to shake stuff like this loose)\n",
        "labels": "confirmed-bug",
        "id": 45579
    },
    {
        "title": "`dns.setServers` doesn't play well with async code",
        "body": "https://github.com/joyent/node/issues/9243#issuecomment-77263667 led me to realizing that the way `dns.setServers` is implemented doesn't play too well with async code.\n\nThe current target server is stored in a per-app global state, which would probably be fine with sync code, but complicates things if you want to query multiple servers with our async `resolve`.\n\nI'd propose adding an options object to `resolve` containing `servers`, while  deprecating `dns.setServers` in a major version. I think having an option object on `resolve` methods could prove useful later.\n\nNote: I haven't checked if c-ares enables per-query target servers easily, maybe @indutny can comment on that part.\n",
        "labels": "confirmed-bug",
        "id": 45580
    },
    {
        "title": "fs.readFile[Sync](\"/dev/stdin\") does not always read the entire file",
        "body": "Originally reported here: https://github.com/joyent/node/issues/7412\n\nThe root cause of the issue is that `fs.readFile()` stats the file and reads the amount of bytes specified in the `st_size` field. This works only for regular files.\n\nThe fix would be to check whether the ST_IFREG flag is set. If not, use a slower but more reliable method to read the entire file.\n\nI think this is a \"good first bug\" for new contributors.\n",
        "labels": "confirmed-bug",
        "id": 45581
    },
    {
        "title": "iojs 1.4.x, linux: ../deps/uv/src/unix/stream.c:1174: uv_shutdown; win: shutdown EPIPE",
        "body": "```\n$ uname -a\nLinux dev.qfox.ru 3.2.0-4-486 #1 Debian 3.2.51-1 i686 GNU/Linux\n```\n\nExpected as it was:\n\n```\n$ iojs -v\nv1.3.0\n$ iojs -e 'process.stdin.emit(\"end\");'\n```\n\nSilent exit.\n\nActual:\n\n```\n$ iojs -v\nv1.4.3\n$ iojs -e 'process.stdin.emit(\"end\");'\niojs: ../deps/uv/src/unix/stream.c:1174: uv_shutdown: Assertion `(stream->type == UV_TCP || stream->type == UV_NAMED_PIPE) && \"uv_shutdown (unix) only supports uv_handle_t right now\"' failed.\nÐÐ²Ð°Ñ€Ð¸Ð¹Ð½Ñ‹Ð¹ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²\n```\n\ncc @indutny\n\n**upd** Btw, this code also produces strange error on win7 x64 (running in mingw32):\n\n```\n$ iojs -v\nv1.4.3\n$ iojs -e 'process.stdin.emit(\"end\");'\nevents.js:141\n      throw er; // Unhandled 'error' event\n            ^\nError: shutdown EPIPE\n    at exports._errnoException (util.js:734:11)\n    at ReadStream.onSocketFinish (net.js:218:26)\n    at emitNone (events.js:67:13)\n    at ReadStream.emit (events.js:163:7)\n    at finishMaybe (_stream_writable.js:477:14)\n    at endWritable (_stream_writable.js:486:3)\n    at ReadStream.Writable.end (_stream_writable.js:452:5)\n    at ReadStream.Socket.end (net.js:393:31)\n    at process._tickCallback (node.js:350:11)\n```\n",
        "labels": "confirmed-bug",
        "id": 45582
    },
    {
        "title": "url.format(undefined) fails in io.js, where it works in Node.js (TypeError: Cannot read property 'auth' of undefined)",
        "body": "In node.js (tested on v0.12.0 and v0.10.33):\n\n``` sh\n$ node -e \"console.log('%j',require('url').format(undefined))\" \n\"\"\n```\n\nIn io.js (tested on v1.4.2 and v1.0.4):\n\n``` sh\n$ node -e \"console.log('%j',require('url').format(undefined))\"\nurl.js:361\n  var auth = this.auth || '';\n                 ^\nTypeError: Cannot read property 'auth' of undefined\n    at Url.format (url.js:361:18)\n    at Object.urlFormat [as format] (url.js:356:58)\n    at [eval]:1:33\n    at Object.exports.runInThisContext (vm.js:54:17)\n    at Object.<anonymous> ([eval]-wrapper:6:22)\n    at Module._compile (module.js:444:26)\n    at evalScript (node.js:477:25)\n    at startup (node.js:73:7)\n    at node.js:863:3\n```\n\nI've dug into this a little bit, and I'm not really sure why it worked in node.js - probably something to do with different V8 versions? Even though this seems to be an edge case, this is a behaviour difference, and breaks [a unit test](https://travis-ci.org/hairyhenderson/f1foo/builds/50337033) in a project of mine.\n",
        "labels": "confirmed-bug",
        "id": 45583
    },
    {
        "title": "https silently stopped working after upgrade to 1.4.1",
        "body": "`https` silently stopped working after upgrade to 1.4.1\n\nBrowsers and Postman cannot connect to https localhost as if io.js server is not running.\n\nDowngrading to 1.3.0 solves the problem\n\n```\nlet bodyParser = require('body-parser'),\n    compression = require('compression'),\n    express = require('express'),\n    fs = require('fs'),\n    https = require('https');\n\nconst SSL_OPTIONS = {\n    key: fs.readFileSync('ssl/hacksparrow-key.pem'),\n    cert: fs.readFileSync('ssl/hacksparrow-cert.pem')\n};\n\nlet app = express();\n\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({\n    extended: true\n}));\n\napp.use(compression({\n    level: 9\n}));\n\napp.use(express.static('public'));\n\nrequire('./routes')(app);\n\nhttps.createServer(SSL_OPTIONS, app).listen(8443);\nconsole.log('Listening on port 8443 ...');\n```\n",
        "labels": "confirmed-bug",
        "id": 45584
    },
    {
        "title": "Tab completion for block-scoped variables doesn't work in REPL",
        "body": "Using version 1.4.1 REPL mode, it seems that tab completion for block-scoped variables (i.e. `let` and `const` statements) doesn't show suggestions, while tab completion for variables declared with `var` or otherwise just assigned a value without a deceleration, does show up a list of suggestions.\n\nOf course, this happens in strict mode, or else I couldn't use `let` and `const`.\n",
        "labels": "confirmed-bug",
        "id": 45585
    },
    {
        "title": "EPIPE errors thrown when piping to a closed stream",
        "body": "I've also opened a related issue in the joyent/node#9279 repo about this. The \nerror message from iojs is slightly different, but just as unhelpful in this situation.\n\nFor the sake of convenience, the rest of this post is verbatim what the issue \nunder the node repo had, with the minor change in error message accounted \nfor.\n\nSo this issue seems to have been around for quite some time. The problem\nprobably affects all instances where things are piped into closed streams, but a\nvery common example that comes up in practice is piping the output of a node\nprogram to something else.\n\nLet's use this as a simple (albeit contrived) example:\n\n```\n$ iojs -e \"console.log(1);console.log(2)\" | cat\n1\n2\n```\n\nWhen piping to something that won't consume the entirety of the stream, the\nprogram crashes in a very unhelpful way:\n\n```\n$ iojs -e \"console.log(1);console.log(2);\" | head -1\n1\nevents.js:141\n      throw er; // Unhandled 'error' event\n            ^\nError: write EPIPE\n    at Object.exports._errnoException (util.js:734:11)\n    at exports._exceptionWithHostPort (util.js:757:20)\n    at WriteWrap.afterWrite (net.js:753:14)\n```\n\nCategorizing this as an error in the first place is a little strange. While I\ncan appreciate that trying to write to a closed stream is an error in theory,\nit seems really odd to crash like this when not paging through everything on\nstdout.\n\nTreating stdout as a special case may be a bit much to ask, but at the\nvery least, there should be some improvements to the error messaging here. The\nexample I gave was just using `iojs -e`, but even with a proper file, no useful\nstacktrace or messaging is provided. Maybe add something like: \n`Warning: Attempting to pipe to a closed stream (foo.js:10:12)`?\n\nI discovered this as I was piping the output of a CLI program I'd written to\n`less`. When paging all the way to the bottom, no errors would be logged, but\nexiting less before paging all the way through would consistently have the EPIPE\nerror written to stderr.\n\nRight now, there are a few workarounds. \n\nUsers can just redirect stderr to `/dev/null` like so:\n\n```\n$ 2>/dev/null iojs -e 'console.log(1);console.log(2)' | head -1\n1\n```\n\nor use the [epipebomb](https://github.com/mhart/epipebomb) module. \n\nNeither approach is ideal.\n",
        "labels": "confirmed-bug",
        "id": 45586
    },
    {
        "title": "dns.setServers() crash",
        "body": "Hi,\n\nIn a Vagrant Ubuntu environment, io.js crashes with this code:\n\n```\n$ cat dns.js\nvar dns = require('dns');\n\ndns.resolveSoa('example.org', function(err, soa){\n    console.log(soa.nsname);\n    dns.resolve4(soa.nsname, function (err, nameServers) {\n        console.log(dns.getServers());\n        dns.setServers(nameServers);\n        console.log(dns.getServers());\n    });\n});\n```\n\nExpected result:\n\n```\n$ iojs dns.js\nsns.dns.icann.org\n[ '10.0.2.3' ]\n[ '199.4.28.26' ]\n```\n\nActual result:\n\n```\n$ iojs dns.js\nsns.dns.icann.org\n[ '10.0.2.3' ]\niojs: ../deps/cares/src/ares_destroy.c:102: ares__destroy_servers_state: Assertion `ares__is_list_empty(&server->queries_to_server)' failed.\nAborted (core dumped)\n```\n\nOther informations:\n\n```\n$ cat /etc/os-release\nNAME=\"Ubuntu\"\nVERSION=\"14.04.1 LTS, Trusty Tahr\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 14.04.1 LTS\"\nVERSION_ID=\"14.04\"\nHOME_URL=\"http://www.ubuntu.com/\"\nSUPPORT_URL=\"http://help.ubuntu.com/\"\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\n$ iojs -v\nv1.2.0\n```\n\nDNS test (in `test/simple/test-dns.js`) ends successfully. This bug can be fixed by removing line 102 in `deps/cares/src/ares_destroy.c`.\nNode.js bug: https://github.com/joyent/node/issues/9243\n",
        "labels": "confirmed-bug",
        "id": 45587
    },
    {
        "title": "`iojs debug -p <pid>` starts debugger in debug client",
        "body": "```\n$ out/Release/iojs --debug-brk benchmark/http_simple.js \nDebugger listening on port 5858\n\n# from another terminal window\n$ out/Release/iojs debug -p $(pgrep iojs)\n< Error: listen EADDRINUSE :::5858\n<     at Object.exports._errnoException (util.js:734:11)\n<     at exports._exceptionWithHostPort (util.js:757:20)\n<     at Agent.Server._listen2 (net.js:1155:14)\n<     at listen (net.js:1181:10)\n<     at Agent.Server.listen (net.js:1268:5)\n<     at Object.start (_debug_agent.js:21:9)\n<     at startup (node.js:68:9)\n<     at node.js:799:3\nconnecting to port 5858... ok\nbreak in benchmark/http_simple.js:1\n> 1 var path = require('path'),\n  2     exec = require('child_process').exec,\n  3     http = require('http');\ndebug> \n```\n\nNo real harm, the debug client is still fully functional.\n",
        "labels": "confirmed-bug",
        "id": 45588
    },
    {
        "title": "spawn's stdio can result in stderr being closed in child",
        "body": "```\nvar cp = require('child_process');\nvar fs = require('fs');\n\nif (process.env.CHILD) {\n  console.error('ERROR');\n  return;\n}\n// open child stdout and stderr on our stderr\nvar options = {\n  stdio: [0, 2, 2],\n  env: { CHILD: true },\n};\nvar c = cp.spawn(process.execPath, [__filename], options);\n```\n\nResult: 'ERROR' is not printed.\n\nExcerpt from strace:\n\n```\n[pid 11780] write(2, \"ERROR\\n\", 6)      = -1 EBADF (Bad file descriptor)\n[pid 11780] write(2, \"ERROR\\n\", 6)      = -1 EBADF (Bad file descriptor)\n[pid 11780] epoll_ctl(4, EPOLL_CTL_DEL, 2, {EPOLLWRNORM|EPOLLHUP|EPOLLRDHUP|EPOLLET|0x242e0000, {u32=32767, u64=47321597480042495}}) = -1 ENOENT (No such file or directory)\n[pid 11780] write(2, \"events.js:141\\n      throw er; //\"..., 244) = -1 EBADF (Bad file descriptor)\n[pid 11780] exit_group(1)               = ?\n[pid 11785] +++ exited with 1 +++\n```\n\nThis likely a bug in libuv, but reporting it here because that's where I saw it.\n\nAffects node v0.10 and io.js.\n\n/cc @saghul @bnoordhuis  I think we tried to fix a variant of this a year or so ago.\n",
        "labels": "confirmed-bug",
        "id": 45589
    },
    {
        "title": "os x: FSEventStreamFlushSync assertions logged to console",
        "body": "after switching from node to io.js, periodically these alarming asserts get logged to the console:\n\n```\n(FSEvents.framework) FSEventStreamFlushSync(): failed assertion '(SInt64)last_id > 0LL'\n```\n\nthey seem to be caused by the `fs.watch` code. i tried digging into libuv/iojs but didn't see anything obvious. OTOH, i don't really know how much pent-up code was unleashed in the migration to io.js, so this bug may have been added a year or two ago.\n\ni can reproduce the assertion with a short script, which i'll attach. run the script 10-20 times, because it only happens about every 4th time. (i suspect a race.)\n",
        "labels": "confirmed-bug",
        "id": 45590
    },
    {
        "title": "--abort-on-uncaught-exception prevents domains from working at all (the process crashes)",
        "body": "It was fixed in node: https://github.com/joyent/node/issues/8631\n\nThis is a major issue that is preventing anyone from using domains and the very powerful `--abort-on-uncaught-exception` flag.\n",
        "labels": "confirmed-bug",
        "id": 45591
    },
    {
        "title": "Chunked stdout/stderr drops writes if terminated early.",
        "body": "Hello,\n\nI have an app which prints a long json to the output and I need to `| grep` this output in order to parse some data.\nIt works fine with Node.js but it doesn't with iojs.\nIt seems the output is chunked in some ways and grep stops before receiving all the data.\nI came to this conclusion because when I redirect the output in some file and then `cat file | grep` it works, everything is there, but `iojs app.js | grep` won't.\n\nAny ideas on this issue ?\nThanks.\n",
        "labels": "confirmed-bug",
        "id": 45592
    },
    {
        "title": "DebuggerAgent: unhandled socket error event",
        "body": "`debugger_agent` doesn't handle correctly socket closing.\n\nTest case:\n\n``` bash\nnode --debug test\n```\n\nTest.js\n\n``` js\nvar spawn = require('child_process').spawn;\n\nfunction Debugger(port) {\n  var connection = require('net').createConnection(port)\n    .on('error', console.error.bind(console))\n    .on('close', process.exit.bind(process))\n    .setEncoding('utf8');\n\n  process.on('exit', connection.end);\n}\n\nvar _debugger = spawn('node', ['-e', '(' + Debugger + ')(5858)']);\nsetTimeout(_debugger.kill.bind(_debugger), 1000);\n```\n\nAfter fix this issue by:\n\n``` diff\ndiff --git a/deps/debugger-agent/lib/_debugger_agent.js b/deps/debugger-agent/lib/_debugger_agent.js\nindex 680c5e9..13f2a9f 100644\n--- a/deps/debugger-agent/lib/_debugger_agent.js\n+++ b/deps/debugger-agent/lib/_debugger_agent.js\n@@ -97,6 +97,7 @@ function Client(agent, socket) {\n   this.on('data', this.onCommand);\n\n   var self = this;\n+  this.socket.on('error', function() {});\n   this.socket.on('close', function() {\n     self.destroy();\n   });\n```\n\nI receive next error:\n`Assertion failed: (err) == (0), file src\\agent.cc, line 164`\n`UV_EBUSY`\n\nSo, I'm incompetent to fix `uv` errors, therefore I opened this issue.\nI think this is for @indutny \n",
        "labels": "confirmed-bug",
        "id": 45593
    },
    {
        "title": "VM top level vars are lost after a few iterations",
        "body": "We use a DSL to configure a system.\nWe load it with vm.\nSometimes, for debuging purposes, we use top level variables in the DSL,\nthat are read and modified by several functions.\nAfter a few executions of these functions, modifications done by one function\nis not seen by others.\nTested with iojs-1.1.0.\nIt doesn't happen with node-0.12.0.\n\nThe following code reproduces the bug in a simplified framework.\n\nThe DSL executor:\n\n``` javascript\nvar vm = require('vm');\nvar fs = require('fs');\n\nfunction include(script) {\n  vm.runInContext(fs.readFileSync(script), ctxt, script);\n}\n\nvar jobs = [];\nfunction job(name, n, action) {\n  jobs.push({name: name, times: n, action: action});\n}\n\nvar sandbox = {\n  console: console,\n  job: job\n};\n\nvar ctxt = vm.createContext(sandbox);\n\nfunction load() {\n  for (var i = 2; i < process.argv.length; i++) include(process.argv[i]);\n}\n\nfunction execute(jobs) {\n  for (var i = 0; i < 2; i++) {\n    for (var j = 0; j < jobs.length; j++) {\n      var job = jobs[j];\n      var times = job.times;\n      var action = job.action;\n      console.info(\"Executing \" + job.name + \" (\" + times + \")\");\n      for (var k = 0; k < times; k++) {\n        action();\n      }\n    }\n  }\n}\n\nload();\nexecute(jobs);\n```\n\nA configuration script to give as argument\n\n``` javascript\nvar n = 0;\n\njob(\"Action 1\", 1000, function() {\n  n++;\n});\n\njob(\"Action 2\", 1, function() {\n  console.info(\"Action 2 output: \" + n);\n  n=0;\n});\n```\n\nExecuted with node-0.12.0 the result is as expected:\n\nExecuting Action 1 (1000)\nExecuting Action 2 (1)\nAction 2 output: 1000\nExecuting Action 1 (1000)\nExecuting Action 2 (1)\nAction 2 output: 1000\n\nExecuted with iojs-1.1.0 the result is\n\nExecuting Action 1 (1000)\nExecuting Action 2 (1)\nAction 2 output: 517\nExecuting Action 1 (1000)\nExecuting Action 2 (1)\nAction 2 output: 0\n\nThe value 517 differs on each execution.\nI suppose it depends on the V8 optimization process.\n\nProbably related to https://github.com/iojs/io.js/issues/548\nand https://github.com/joyent/node/issues/9084\n",
        "labels": "confirmed-bug",
        "id": 45594
    },
    {
        "title": "process.send() is not synchronous ",
        "body": "According to the documentation for the `child_process` module, `process.send()` should block. It seems that this is no longer the case in `v1.1.0`.\n\n``` javascript\n//parent.js\n\nvar fork = require('child_process').fork;\nvar child = fork('./child.js');\nchild.on('message', function (m) {\n    console.log('got message from child: ' + m);\n});\n\n//child.js\n\nprocess.send(new Buffer(2048));\nprocess.exit(0);\n```\n\nIn this example, if the child process attempts to send a sufficiently large object to the parent, the child process exits but does not send all of the data.  However, smaller messages (perhaps a Buffer of 1024 bytes) are successfully sent. \n\nI think this change in functionality was introduced in 07bd05ba332e078c1ba76635921f5448a3e884cf when `uv__nonblock()` was added to `uv_pipe_open()` in `deps/uv/src/unix/pipe.c`. Removing the call to `uv__nonblock()` restores the original behavior of `process.send()`.\n\nI ran into this issue on OSX 10.10.2 LLVM 6.0 (clang-600.0.56), if it helps.\n",
        "labels": "confirmed-bug",
        "id": 45595
    },
    {
        "title": "events: prefix events to prevent breaking on known object properties",
        "body": "In the EventEmitter the events are stored in an plain `Object` instance. The event names that you use are added directly as property on the object so when you event names such as `__proto__` it will break. One solution is to prefix the keys with a char such as `~`.\n\nExample case:\n\n``` js\nvar EventEmitter = require('events').EventEmitter;\nvar e = new EventEmitter();\n\ne.on('__proto__', function (bar) {\n  console.log('foo', bar);\n});\ne.emit('__proto__', 1);\n```\n\nWilling to create pull request if bug requires fixing ;)\n",
        "labels": "confirmed-bug",
        "id": 45596
    },
    {
        "title": "HTTP and HTTPS attempt only single IP, causing intermittent failures",
        "body": "Steps to reproduce:\n\nFind a host that answers a given port only on some of the returned IP addresses for its name. For instance, www.itunes.com has this problem. Then run this code:\n\n```\nrequire('https').get('https://www.itunes.com', function(res) {\n  console.log('statusCode:', res.statusCode);\n}).on('error', function(err) {\n  console.log('Error:', err);\n});\n```\n\nSince www.itunes.com resolves to three different IP addresses (see `dig www.itunes.com`) in random order, io.js will connect to a random host each time, sometimes failing and sometimes succeeding.\n\nArguably, this is broken behavior on the part of the host. However, it's reasonably common on the web. Firefox and Chrome each attempt parallel connections to all IP addresses provided in the DNS response, using the first connection to succeed. Curl attempts each IP address in sequence until it gets a successful connection or runs out of IP addresses: https://github.com/bagder/curl/blob/master/lib/connect.c#L1156\n\nIt looks like the io.js http and https libraries, through `Agent`, call into Socket.connect, which uses `dns.lookup` (returns just one IP address) instead of `dns.resolve`: https://github.com/iojs/io.js/blob/v1.x/lib/net.js#L900.\n\nIs it practical to change the Socket.connect behavior to use `dns.resolve` and try multiple IP addresses? I'm guessing that would be a fairly API-incompatible change. Another possibility: Agent could implement failure handling code that specifically catched connection refused and timeout errors, calls `dns.resolve` itself, and calls Socket.connect again with IP address arguments. This would be less performant but also a smaller API change.\n\nFor the real-world motivating example, I ran into this when writing automated tests for HTTPS Everywhere's rulesets: https://github.com/jsha/https-everywhere/blob/rules-tester/rewriter/tester.js. As-is, I get a number of false positives from hosts that appear to fail but actual work fine in a browser.\n",
        "labels": "confirmed-bug",
        "id": 45597
    },
    {
        "title": "repl: surrogate pair upsets repl / terminal",
        "body": "```\n$ out/Release/iojs\n> Buffer([0,0xD8,0,0xDC]).toString('utf16le')\n'\n# screen freezes\n```\n\nThe REPL still accepts input but no longer echoes it.  Typing in `process.exit()` cleanly shuts down the process but the terminal isn't reset, leaving it in an unusable state until you run reset(1).\n",
        "labels": "confirmed-bug",
        "id": 45598
    },
    {
        "title": "Building as static library fails",
        "body": "This issue is probably not io.js-specific, and it might be the one to be reported to gyp, but I'll try here first.\n\nI'm trying to build io.js as static library, I have just changed `'type': 'executable'` to `'type': 'static_library'` in node.gyp.\n\nI get the following error in the end:\n\n```\nerror: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool: unknown option character `W' in: -Wl,-force_load,/Users/hoho/iojs/out/Release/libopenssl.a\nUsage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool -static [-] file [...] [-filelist listfile[,dirname]] [-arch_only arch] [-sacLT] [-no_warning_for_no_symbols]\nUsage: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/libtool -dynamic [-] file [...] [-filelist listfile[,dirname]] [-arch_only arch] [-o output] [-install_name name] [-compatibility_version #] [-current_version #] [-seg1addr 0x#] [-segs_read_only_addr 0x#] [-segs_read_write_addr 0x#] [-seg_addr_table <filename>] [-seg_addr_table_filename <file_system_path>] [-all_load] [-noall_load]\nmake[1]: *** [/Users/hoho/iojs/out/Release/libiojs.a] Error 1\nmake: *** [iojs] Error 2\n```\n\nOS X Yosemite 10.10.2.\n",
        "labels": "confirmed-bug",
        "id": 45599
    },
    {
        "title": "V8 Fatal Error when trying to convert a buffered integer to string",
        "body": "IO.js Version 1.0.4\n\n```\n$ iojs\n> Date.now();\n1422508723712\n> Buffer(Date.now());\n<Buffer 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ... >\n> Buffer(Date.now()).toString('utf8');\n\n\n#\n# Fatal error in ../deps/v8/src/handles.h, line 48\n# CHECK(location_ != NULL) failed\n#\n\n==== C stack trace ===============================\n\n 1: V8_Fatal\n 2: v8::String::NewFromUtf8(v8::Isolate*, char const*, v8::String::NewStringType, int)\n 3: node::StringBytes::Encode(v8::Isolate*, char const*, unsigned long, node::encoding)\n 4: node::Buffer::Utf8Slice(v8::FunctionCallbackInfo<v8::Value> const&)\n 5: v8::internal::FunctionCallbackArguments::Call(void (*)(v8::FunctionCallbackInfo<v8::Value> const&))\n 6: ??\n 7: ??\nIllegal instruction\n```\n",
        "labels": "confirmed-bug",
        "id": 45600
    },
    {
        "title": "Certain values of --max_old_space_size cause segmentation fault",
        "body": "```\niojs --max_old_space_size=4096 simple.js\n[1]    18001 segmentation fault (core dumped)  iojs --max_old_space_size=4096 simple.js\n```\n\nThere is a pattern on values that causes segfault: `2^n + 0...3` where `n >= 12`\ne.g: 4096,4097,4098,4099,8192,8193,8194,8195 etc...\nThe rest values work fine.\n\nIssue present on v0.11.15, v1.0.4 but works fine on v0.10.36.\n\nIt's funny because the first value I tried were 4096, 8192 and I would expect most to do the same.\n\nSome info from gdb:\n\n```\nâžœ  gdb --args iojs --max_old_space_size=4096 simple.js\nGNU gdb (Ubuntu/Linaro 7.4-2012.04-0ubuntu2.1) 7.4-2012.04\n[...]\nThis GDB was configured as \"x86_64-linux-gnu\".\n[...]\nReading symbols from /home/uvv/.nvm/versions/io.js/v1.0.4/bin/iojs...done.\n(gdb) run\nStarting program: /home/uvv/.nvm/versions/io.js/v1.0.4/bin/iojs --max_old_space_size=4096 simple.js\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n[New Thread 0x7ffff6bd2700 (LWP 20376)]\n[New Thread 0x7ffff63d1700 (LWP 20377)]\n[New Thread 0x7ffff5bd0700 (LWP 20378)]\n[New Thread 0x7ffff53cf700 (LWP 20379)]\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x000000000097d9c0 in v8::internal::Heap::ClearJSFunctionResultCaches() ()\n(gdb) c\nContinuing.\n[Thread 0x7ffff53cf700 (LWP 20379) exited]\n[Thread 0x7ffff5bd0700 (LWP 20378) exited]\n[Thread 0x7ffff63d1700 (LWP 20377) exited]\n[Thread 0x7ffff6bd2700 (LWP 20376) exited]\n\nProgram terminated with signal SIGSEGV, Segmentation fault.\nThe program no longer exists.\n```\n",
        "labels": "confirmed-bug",
        "id": 45601
    },
    {
        "title": "http: regression in Upgrade header handling",
        "body": "``` javascript\n'use strict';\n\nvar assert = require('assert');\nvar http = require('http');\nvar net = require('net');\n\nvar seenUpgrade = 0;\nprocess.on('exit', function() { assert.equal(seenUpgrade, 1); });\n\nhttp.createServer(assert.fail).listen(0, '127.0.0.1', function() {\n  this.on('upgrade', function(req, conn, head) {\n    seenUpgrade += 1;\n    conn.destroy();\n    this.close();\n  });\n  var options = { host: this.address().address, port: this.address().port };\n  net.connect(options, function() {\n    this.write('GET / HTTP/1.1\\r\\n' +\n               'Upgrade: Yes, please.\\r\\n' +\n               '\\r\\n');\n  });\n});\n```\n\nWorks with joyent/node@v0.11.16 but fails with iojs@5843ae8.  The request callback is called and the 'upgrade' event doesn't fire.  I'll bisect.\n",
        "labels": "confirmed-bug",
        "id": 45602
    },
    {
        "title": "repl: repl clobbers RegExp.$1",
        "body": "```\n$ out/Release/iojs\n> RegExp.$1\n'RegExp.$1'\n> eval(RegExp.$1)\n# snip\n    at <error: RangeError: Maximum call stack size exceeded>\n```\n",
        "labels": "confirmed-bug",
        "id": 45603
    },
    {
        "title": "http: \"upgrade\" event not triggered with a Firefox client",
        "body": "Below packet from a Firefox client doesn't trigger an \"upgrade\" event. I've tested two different websocket libraries so far which aren't able to handshake when running on io.js but are able to do on node 0.10.35. Also, Chrome seems unaffected, so I suspect something in the packet itself triggering this bug.\n\nPacket from Wireshark:\n\n```\nFrame 98: 559 bytes on wire (4472 bits), 559 bytes captured (4472 bits)\nRaw packet data\nInternet Protocol Version 4, Src: 127.0.0.1 (127.0.0.1), Dst: 127.0.0.1 (127.0.0.1)\nTransmission Control Protocol, Src Port: 3258 (3258), Dst Port: 8989 (8989), Seq: 1, Ack: 1, Len: 519\nHypertext Transfer Protocol\n    GET / HTTP/1.1\\r\\n\n    Host: localhost:8989\\r\\n\n    User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:35.0) Gecko/20100101 Firefox/35.0\\r\\n\n    Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\\r\\n\n    Accept-Language: en-US,en;q=0.5\\r\\n\n    Accept-Encoding: gzip, deflate\\r\\n\n    Sec-WebSocket-Version: 13\\r\\n\n    Origin: http://localhost:8989\\r\\n\n    Sec-WebSocket-Key: LCDSLtOtfufP3W706y+1bw==\\r\\n\n    Cookie: s=tJTkrO8mlzGBz/K3HUzcf3TnS5pJbfAJJ8FtzPznnCA=\\r\\n\n    Connection: keep-alive, Upgrade\\r\\n\n    Pragma: no-cache\\r\\n\n    Cache-Control: no-cache\\r\\n\n    Upgrade: websocket\\r\\n\n    \\r\\n\n    [Full request URI: http://localhost:8989/]\n    [HTTP request 1/1]\n```\n",
        "labels": "confirmed-bug",
        "id": 45604
    },
    {
        "title": "Installation on Windows doesn't \"symlink\" iojs to node",
        "body": "I've just installed io.js v1.0.3 on my machine and it didn't create symlinks to node.\nWhen I now run `node -v` I get `v0.10.33` and when `iojs -v` I get `v1.0.3`.\nNow, this might be because:\n- windows doesn't have symlinks (so I thought, but I was just told on #io.js that it indeed has)\n- I haven't run installer as an admin (but then it should ask me for elevation)\n- it was never intended on Windows to do it (but then it creates inconsistency between platforms, not good IMO)\n\nOn a side note, I think installer should provide some info about what's gonna happen with the current node and npm installations.\n\nSome additional info:\n\n```\nInstaller file: *iojs-v1.0.3-x64*\nSystem: *Win8.1x64*\n```\n",
        "labels": "confirmed-bug",
        "id": 45605
    },
    {
        "title": "Function redefinition in vm.runInContext",
        "body": "Possible bug of iojs or perhaps v8?\n\n```\n    var vm = require('vm'), ctx = vm.createContext({});\n\n    vm.runInContext('function test(){return 0}', ctx);\n    vm.runInContext('function test(){return 1}', ctx);\n\n    var result = vm.runInContext('test()', ctx);\n    // returns 0 in io.js, but 1 in node.js\n```\n\nTested under win7 x64 and linux.\n",
        "labels": "confirmed-bug",
        "id": 45606
    },
    {
        "title": "io.js's performance counters conflict with node.js's on Windows 7 x64",
        "body": "Steps to reproduce:\n1. Install Node.js v0.10.35 with at least \"Performance counters\" checked\n2. Try to install io.js v1.0.3 with at least \"Performance counters\" checked\n\nThe installer fails and rolls back. It works just fine if you run the installer again.\n\nThis doesn't happen if \"Performance counters\" is unchecked in either of the installers. Other options don't seem to make any difference.\n\nI'll try to reproduce this on a 32-bit Windows 7 when I get home.\n",
        "labels": "confirmed-bug",
        "id": 45607
    },
    {
        "title": "unable to deal with file names that have invalid encoding",
        "body": "There is a file in my user's file system and io.js cannot use any of the fs API on it, because the file name has an invalid encoding. File names are byte arrays; not strings. This is the root of the problem.\n\nhttps://github.com/andrewrk/groovebasin/issues/383\n\nHow to reproduce (use linux):\n\n```\n$ wget https://s3.amazonaws.com/superjoe/temp/encoding-test.tar.gz\n$ tar xvf encoding-test.tar.gz \nencoding-test/\nencoding-test/test.js\nencoding-test/dir/\nencoding-test/dir/\\377\n$ cd encoding-test/\n$ cat test.js\nvar fs = require('fs');\nvar path = require('path');\nvar dir = 'dir/';\nvar list = fs.readdirSync(dir);\nvar filename = path.join(dir, list[0]);\nconsole.log(filename);\nconsole.log(fs.lstatSync(filename));\n$ node test.js \ndir/ï¿½\n\nfs.js:688\n  return binding.lstat(pathModule._makeLong(path));\n                 ^\nError: ENOENT, no such file or directory 'dir/ï¿½'\n    at Object.fs.lstatSync (fs.js:688:18)\n    at Object.<anonymous> (/home/andy/Downloads/encoding-test/test.js:7:16)\n    at Module._compile (module.js:456:26)\n    at Object.Module._extensions..js (module.js:474:10)\n    at Module.load (module.js:356:32)\n    at Function.Module._load (module.js:312:12)\n    at Function.Module.runMain (module.js:497:10)\n    at startup (node.js:119:16)\n    at node.js:906:3\n```\n",
        "labels": "confirmed-bug",
        "id": 45608
    },
    {
        "title": "test: simple/test-fs-symlink-dir-junction-relative broken on linux",
        "body": "```\n$ out/x64.release/node test/simple/test-fs-symlink-dir-junction-relative.js\nlinkData: /home/bnoordhuis/src/v0.12/test/fixtures/cycles\nlinkPath: /home/bnoordhuis/src/v0.12/test/tmp/cycles_link\nrelative target: ../fixtures/cycles\n\nassert.js:100\n  throw new assert.AssertionError({\n        ^\nAssertionError: \"/home/bnoordhuis/src/fixtures/cycles\" == \"/home/bnoordhuis/src/v0.12/test/fixtures/cycles\"\n    at /home/bnoordhuis/src/v0.12/test/simple/test-fs-symlink-dir-junction-relative.js:54:14\n    at Object.oncomplete (fs.js:95:15)\n```\n\nReverting 7014b7c0 makes no difference.  /cc @piscisaureus\n",
        "labels": "confirmed-bug",
        "id": 45609
    }
]